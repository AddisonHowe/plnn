Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 205093647

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.109150562727523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.109150562727523 | validation: 10.27114758034229]
	TIME [epoch: 80.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.35923420164156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.35923420164156 | validation: 9.463410882605816]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.526791618953652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.526791618953652 | validation: 10.669790599005545]
	TIME [epoch: 9.75 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.87705143400375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.87705143400375 | validation: 9.56781772463555]
	TIME [epoch: 9.73 sec]
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.472600784716686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.472600784716686 | validation: 10.2748267046192]
	TIME [epoch: 9.73 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.691151962851709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.691151962851709 | validation: 9.065979325618313]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.438280895342302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.438280895342302 | validation: 9.04304887623911]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.617148189020087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.617148189020087 | validation: 9.12653519606771]
	TIME [epoch: 9.74 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.431004722668277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.431004722668277 | validation: 8.902311673507652]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.908666904635371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.908666904635371 | validation: 9.108037295902738]
	TIME [epoch: 9.74 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.850724916612137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.850724916612137 | validation: 8.66492027875238]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.528748644271829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.528748644271829 | validation: 8.514825541037778]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.951100245442586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.951100245442586 | validation: 8.89316042362115]
	TIME [epoch: 9.73 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.846290049715593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.846290049715593 | validation: 8.467699286986585]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.418769974803809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.418769974803809 | validation: 8.730189594957555]
	TIME [epoch: 9.76 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.34300523559347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.34300523559347 | validation: 8.51081830783249]
	TIME [epoch: 9.74 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.067731334833244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.067731334833244 | validation: 8.531570866192878]
	TIME [epoch: 9.73 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.992557860496211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.992557860496211 | validation: 8.562684780624679]
	TIME [epoch: 9.75 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.902028801004642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.902028801004642 | validation: 8.714047939767744]
	TIME [epoch: 9.71 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.206909608942029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.206909608942029 | validation: 8.641442429540106]
	TIME [epoch: 9.71 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.869308039599093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.869308039599093 | validation: 8.58971284006074]
	TIME [epoch: 9.73 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.9448865070643695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.9448865070643695 | validation: 9.047337461575085]
	TIME [epoch: 9.74 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.278685108135317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.278685108135317 | validation: 8.529565966478739]
	TIME [epoch: 9.73 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.130282879315716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.130282879315716 | validation: 8.337792127899833]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.801954449176816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.801954449176816 | validation: 8.371335687914582]
	TIME [epoch: 9.74 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.794972468240696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.794972468240696 | validation: 8.581593003614016]
	TIME [epoch: 9.71 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.152382961233172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.152382961233172 | validation: 8.840613544775701]
	TIME [epoch: 9.72 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.368267460675577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.368267460675577 | validation: 10.17944568436445]
	TIME [epoch: 9.73 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.415413545308091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.415413545308091 | validation: 11.465189238971133]
	TIME [epoch: 9.71 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.843967944614288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.843967944614288 | validation: 10.543313648358204]
	TIME [epoch: 9.71 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.379199844462144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.379199844462144 | validation: 8.671768862454332]
	TIME [epoch: 9.73 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.936874151647631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.936874151647631 | validation: 8.644178304893654]
	TIME [epoch: 9.72 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.796534603124789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.796534603124789 | validation: 8.573987237651885]
	TIME [epoch: 9.71 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.88811187256262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.88811187256262 | validation: 8.361775632370662]
	TIME [epoch: 9.73 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.056234015788041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.056234015788041 | validation: 8.292913018601139]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.723355440995418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.723355440995418 | validation: 8.321589570739047]
	TIME [epoch: 9.73 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.678090716685017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.678090716685017 | validation: 8.331273143621086]
	TIME [epoch: 9.75 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.479622495184616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.479622495184616 | validation: 8.46195452412666]
	TIME [epoch: 9.72 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.058721262737714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.058721262737714 | validation: 8.646995620655767]
	TIME [epoch: 9.73 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.7178763946609665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7178763946609665 | validation: 8.385317240815487]
	TIME [epoch: 9.75 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.510403311714829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.510403311714829 | validation: 8.178216535952702]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.438907461517149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.438907461517149 | validation: 8.226528806056939]
	TIME [epoch: 9.73 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.778196546469033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.778196546469033 | validation: 8.308844706655332]
	TIME [epoch: 9.75 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.578260807501772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.578260807501772 | validation: 8.784298819451363]
	TIME [epoch: 9.73 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.954437947850238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.954437947850238 | validation: 8.14358069590522]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.261856084945734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.261856084945734 | validation: 8.05908541942943]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.5011174659306095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5011174659306095 | validation: 8.954209464704151]
	TIME [epoch: 9.74 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.786453820332295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.786453820332295 | validation: 7.921598458170921]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.232539099005507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.232539099005507 | validation: 7.851281731526922]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.335092960404633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.335092960404633 | validation: 8.111755385990195]
	TIME [epoch: 9.73 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.484958040293598		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 8.484958040293598 | validation: 10.45714765496493]
	TIME [epoch: 9.73 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.842404465299538		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 10.842404465299538 | validation: 9.059583264458961]
	TIME [epoch: 9.75 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.019204584507722		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 8.019204584507722 | validation: 8.316566534050331]
	TIME [epoch: 9.73 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.44690529755122		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 7.44690529755122 | validation: 8.123675871538904]
	TIME [epoch: 9.73 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.512830822995852		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 7.512830822995852 | validation: 8.032751462402333]
	TIME [epoch: 9.76 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.45804880763713		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 8.45804880763713 | validation: 8.643162486771256]
	TIME [epoch: 9.74 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.692344681062865		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 8.692344681062865 | validation: 8.493560395423344]
	TIME [epoch: 9.73 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.649047168772024		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 7.649047168772024 | validation: 8.282089190686017]
	TIME [epoch: 9.75 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.084671740170887		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 8.084671740170887 | validation: 9.547273467345615]
	TIME [epoch: 9.74 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.042202127806442		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 8.042202127806442 | validation: 8.13738333729672]
	TIME [epoch: 9.73 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3911743306286795		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 7.3911743306286795 | validation: 7.9745837397329025]
	TIME [epoch: 9.75 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.278982014176455		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 7.278982014176455 | validation: 8.12981731578106]
	TIME [epoch: 9.76 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.21835556203307		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 7.21835556203307 | validation: 7.727931290938193]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.297515184352984		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 7.297515184352984 | validation: 7.770554657156469]
	TIME [epoch: 9.76 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.20280457678265		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 7.20280457678265 | validation: 7.74417523640702]
	TIME [epoch: 9.76 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.18403834295737		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 7.18403834295737 | validation: 8.052770845539243]
	TIME [epoch: 9.74 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.482252845385266		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 7.482252845385266 | validation: 7.647430485990866]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.145205258257638		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 7.145205258257638 | validation: 7.6375329374257035]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.174135601796633		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 7.174135601796633 | validation: 7.867592102279491]
	TIME [epoch: 9.75 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.569268917088737		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 7.569268917088737 | validation: 7.740657788174221]
	TIME [epoch: 9.73 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.149529764032631		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 7.149529764032631 | validation: 7.669724515683923]
	TIME [epoch: 9.77 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.072434482521667		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 7.072434482521667 | validation: 7.231723529484964]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.20259233861171		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 7.20259233861171 | validation: 7.96096672032693]
	TIME [epoch: 9.74 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.396495542934384		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 7.396495542934384 | validation: 8.100705569981612]
	TIME [epoch: 9.76 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.559668879493698		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 7.559668879493698 | validation: 8.489055787111878]
	TIME [epoch: 9.72 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.11892633066158		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 8.11892633066158 | validation: 7.90639959042102]
	TIME [epoch: 9.73 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.628800061266655		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 7.628800061266655 | validation: 7.857707108100863]
	TIME [epoch: 9.76 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.569046223713903		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 7.569046223713903 | validation: 7.902221940365592]
	TIME [epoch: 9.74 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.498218279335117		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 7.498218279335117 | validation: 8.007697193014627]
	TIME [epoch: 9.74 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.398015201868439		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 7.398015201868439 | validation: 7.774809608942087]
	TIME [epoch: 9.75 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.347480224942362		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 7.347480224942362 | validation: 7.995491821600756]
	TIME [epoch: 9.73 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.112886056352591		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 7.112886056352591 | validation: 7.890228973863402]
	TIME [epoch: 9.72 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.1495380738530825		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 7.1495380738530825 | validation: 7.580926928086812]
	TIME [epoch: 9.75 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.082923174581912		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 7.082923174581912 | validation: 7.580167040971959]
	TIME [epoch: 9.73 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.223247832356857		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 7.223247832356857 | validation: 7.80240942896187]
	TIME [epoch: 9.73 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.070754707694118		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 7.070754707694118 | validation: 7.167536553790831]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.889677252607157		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 6.889677252607157 | validation: 7.653700461545481]
	TIME [epoch: 9.74 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.103473724979132		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 7.103473724979132 | validation: 7.524154376561812]
	TIME [epoch: 9.73 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.905531375213603		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 6.905531375213603 | validation: 7.4831361273520045]
	TIME [epoch: 9.75 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.886724608077434		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 6.886724608077434 | validation: 7.485691818156964]
	TIME [epoch: 9.73 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.82284735033203		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 6.82284735033203 | validation: 7.428120332753986]
	TIME [epoch: 9.72 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.486144786091094		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 8.486144786091094 | validation: 9.468952746655404]
	TIME [epoch: 9.74 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.351377803454136		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 9.351377803454136 | validation: 10.554355594464482]
	TIME [epoch: 9.73 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.597021589816967		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 10.597021589816967 | validation: 10.62668372308191]
	TIME [epoch: 9.73 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.793201784699821		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 10.793201784699821 | validation: 9.893842446713975]
	TIME [epoch: 9.75 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.994034579240912		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 9.994034579240912 | validation: 9.812224023952854]
	TIME [epoch: 9.73 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.406486890205523		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 9.406486890205523 | validation: 7.6482463167012655]
	TIME [epoch: 9.73 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.098979834838655		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 8.098979834838655 | validation: 7.479391720783581]
	TIME [epoch: 9.73 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.1814786455090625		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 7.1814786455090625 | validation: 7.406686673945629]
	TIME [epoch: 9.75 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.9469646899558315		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 6.9469646899558315 | validation: 7.287468969785334]
	TIME [epoch: 9.72 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.534763816956688		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 7.534763816956688 | validation: 7.007008515722332]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.687951904922412		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 6.687951904922412 | validation: 7.2040372164161015]
	TIME [epoch: 9.75 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.097427399635339		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 7.097427399635339 | validation: 7.205462878047326]
	TIME [epoch: 9.72 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.570276875769255		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 7.570276875769255 | validation: 7.898510181902079]
	TIME [epoch: 9.73 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.040403715063786		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 7.040403715063786 | validation: 6.997008451055926]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.513035457347724		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 6.513035457347724 | validation: 6.906803487011924]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.64463254683839		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 6.64463254683839 | validation: 7.9942447454888566]
	TIME [epoch: 9.73 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.209270995571515		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 8.209270995571515 | validation: 8.568600082011155]
	TIME [epoch: 9.75 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.865891783944676		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 7.865891783944676 | validation: 7.149896619851821]
	TIME [epoch: 9.72 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4188101140250255		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 6.4188101140250255 | validation: 6.71397507701234]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.235231588979782		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 6.235231588979782 | validation: 6.698938320232306]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.364515312263597		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 6.364515312263597 | validation: 7.160553890119139]
	TIME [epoch: 9.74 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.552420913429079		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 6.552420913429079 | validation: 7.789863579623702]
	TIME [epoch: 9.72 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.616069945828819		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 7.616069945828819 | validation: 8.144678202562929]
	TIME [epoch: 9.75 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.1286846691254055		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 7.1286846691254055 | validation: 7.644500782293242]
	TIME [epoch: 9.72 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.774156134550678		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 7.774156134550678 | validation: 8.590076104056442]
	TIME [epoch: 9.73 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.861611796165432		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 7.861611796165432 | validation: 8.032218336217554]
	TIME [epoch: 9.75 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.272286078661369		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 7.272286078661369 | validation: 7.419302567445559]
	TIME [epoch: 9.73 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.877012622806414		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 6.877012622806414 | validation: 7.3753531346931895]
	TIME [epoch: 9.73 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.564697946365433		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 6.564697946365433 | validation: 7.009215631498871]
	TIME [epoch: 9.76 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.365960285445515		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 6.365960285445515 | validation: 6.650037748295927]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.178574789193108		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 6.178574789193108 | validation: 6.861644584126524]
	TIME [epoch: 9.72 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.638126400071887		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 6.638126400071887 | validation: 6.306769801732983]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_123.pth
	Model improved!!!
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.676170998822315		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 6.676170998822315 | validation: 7.310539516493002]
	TIME [epoch: 9.72 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.671609459139779		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 6.671609459139779 | validation: 6.782603419991634]
	TIME [epoch: 9.71 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.13915844223154		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 6.13915844223154 | validation: 6.287171864513274]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_126.pth
	Model improved!!!
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.976251954881226		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 5.976251954881226 | validation: 6.401458859528161]
	TIME [epoch: 9.72 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9766254630453695		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 5.9766254630453695 | validation: 6.382305036429687]
	TIME [epoch: 9.71 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3338160096495235		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 6.3338160096495235 | validation: 6.833954610821311]
	TIME [epoch: 9.73 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.421584501948365		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 6.421584501948365 | validation: 6.597431483935621]
	TIME [epoch: 9.72 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.108319387956865		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 6.108319387956865 | validation: 6.4014757702620955]
	TIME [epoch: 9.71 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.027311782929336		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 6.027311782929336 | validation: 6.29178515392494]
	TIME [epoch: 9.73 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.993056925589885		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 5.993056925589885 | validation: 6.38023716678915]
	TIME [epoch: 9.71 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.949591735623294		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 5.949591735623294 | validation: 6.089540046244606]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_134.pth
	Model improved!!!
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.0371505893149955		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 6.0371505893149955 | validation: 6.367283654511856]
	TIME [epoch: 9.74 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.207682186794528		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 6.207682186794528 | validation: 6.6624973903165845]
	TIME [epoch: 9.74 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.047912006287691		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 6.047912006287691 | validation: 6.1559381093236425]
	TIME [epoch: 9.72 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.1113538010086215		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 6.1113538010086215 | validation: 6.6268363073128835]
	TIME [epoch: 9.73 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.098938356357872		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 6.098938356357872 | validation: 6.327496190302088]
	TIME [epoch: 9.73 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.033678113379199		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 6.033678113379199 | validation: 6.22719721526611]
	TIME [epoch: 9.72 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.58584929982446		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 6.58584929982446 | validation: 7.113367851745345]
	TIME [epoch: 9.72 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.2631179610458885		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 6.2631179610458885 | validation: 6.704700331338167]
	TIME [epoch: 9.74 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.2338039932038285		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 6.2338039932038285 | validation: 6.636252726885105]
	TIME [epoch: 9.72 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.201346192062172		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 6.201346192062172 | validation: 6.303354929891579]
	TIME [epoch: 9.72 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.392969963632622		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 6.392969963632622 | validation: 6.513918268455707]
	TIME [epoch: 9.74 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.167156745108362		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 6.167156745108362 | validation: 6.375952832501164]
	TIME [epoch: 9.72 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.252698252950152		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 6.252698252950152 | validation: 6.3077977526577325]
	TIME [epoch: 9.72 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.109679498697922		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 6.109679498697922 | validation: 6.337894705669332]
	TIME [epoch: 9.74 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.108813535516797		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 6.108813535516797 | validation: 6.768639910416794]
	TIME [epoch: 9.71 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.073541906875505		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 6.073541906875505 | validation: 6.117516213729617]
	TIME [epoch: 9.72 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.181877779107891		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 6.181877779107891 | validation: 6.546681002673954]
	TIME [epoch: 9.74 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.244501500510877		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 6.244501500510877 | validation: 6.414151628068449]
	TIME [epoch: 9.72 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.018244803217921		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 6.018244803217921 | validation: 6.029656999602516]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.231655071788214		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 6.231655071788214 | validation: 6.50482430608195]
	TIME [epoch: 9.74 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.231657570753691		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 6.231657570753691 | validation: 6.290873916316935]
	TIME [epoch: 9.72 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.078161950659416		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 6.078161950659416 | validation: 6.1745054938881]
	TIME [epoch: 9.7 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.943477318519279		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 5.943477318519279 | validation: 6.236886638703866]
	TIME [epoch: 9.74 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.324078640018693		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 6.324078640018693 | validation: 6.3580435897629375]
	TIME [epoch: 9.71 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.210548446852366		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 6.210548446852366 | validation: 6.429904827667796]
	TIME [epoch: 9.72 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.482083245458737		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 6.482083245458737 | validation: 6.641775434843587]
	TIME [epoch: 9.74 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.978670773283784		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 5.978670773283784 | validation: 6.281772133035193]
	TIME [epoch: 9.71 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.152268664909364		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 6.152268664909364 | validation: 6.123475793316258]
	TIME [epoch: 9.71 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.851822511250419		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 5.851822511250419 | validation: 5.970742747222593]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.052101149511235		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 6.052101149511235 | validation: 6.372879879250047]
	TIME [epoch: 9.72 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.112599780896557		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 6.112599780896557 | validation: 6.310424199043721]
	TIME [epoch: 9.71 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.060417850624269		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 6.060417850624269 | validation: 6.288346045168071]
	TIME [epoch: 9.75 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.980261775601739		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 5.980261775601739 | validation: 6.166502303069448]
	TIME [epoch: 9.73 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.103931937716934		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 6.103931937716934 | validation: 6.43305417443458]
	TIME [epoch: 9.71 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.246605434328883		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 6.246605434328883 | validation: 6.2646225572867]
	TIME [epoch: 9.74 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.007422458084134		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 6.007422458084134 | validation: 6.357672785167209]
	TIME [epoch: 9.73 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.153408634661203		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 6.153408634661203 | validation: 6.407004813929376]
	TIME [epoch: 9.72 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.115488932850175		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 6.115488932850175 | validation: 6.271164336277573]
	TIME [epoch: 9.72 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.069767642033568		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 6.069767642033568 | validation: 6.089120707436897]
	TIME [epoch: 9.74 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.797641638533043		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 5.797641638533043 | validation: 5.9089100506743835]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_174.pth
	Model improved!!!
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.777998170808379		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 5.777998170808379 | validation: 5.634581621449284]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.510961209447933		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 6.510961209447933 | validation: 6.420952317228276]
	TIME [epoch: 9.74 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.2876235366456426		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 7.2876235366456426 | validation: 6.93249850777022]
	TIME [epoch: 9.73 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3870783542015275		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 7.3870783542015275 | validation: 6.847592620982574]
	TIME [epoch: 9.72 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.509890058393701		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 7.509890058393701 | validation: 6.871060838986437]
	TIME [epoch: 9.75 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.327169942955566		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 7.327169942955566 | validation: 6.552723377781083]
	TIME [epoch: 9.73 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.955496953554089		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 6.955496953554089 | validation: 6.44249910608042]
	TIME [epoch: 9.72 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.25239561616568		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 7.25239561616568 | validation: 7.010740438228402]
	TIME [epoch: 9.75 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.588727354804654		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 7.588727354804654 | validation: 7.108025065828608]
	TIME [epoch: 9.73 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.556766275270678		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 7.556766275270678 | validation: 6.51354728826173]
	TIME [epoch: 9.72 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3825825236146		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 7.3825825236146 | validation: 7.1305023187634]
	TIME [epoch: 9.75 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.581256681572569		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 7.581256681572569 | validation: 6.5857302038840535]
	TIME [epoch: 9.73 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.23624560511486		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 7.23624560511486 | validation: 6.691157847436048]
	TIME [epoch: 9.72 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.4157718747446655		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 7.4157718747446655 | validation: 7.119867719371492]
	TIME [epoch: 9.74 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.640493356685224		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 7.640493356685224 | validation: 6.913147642719157]
	TIME [epoch: 9.72 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.158002823889658		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 7.158002823889658 | validation: 6.478413227379524]
	TIME [epoch: 9.71 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.690044139847113		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 6.690044139847113 | validation: 6.0418434762775295]
	TIME [epoch: 9.74 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.426278598819525		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 6.426278598819525 | validation: 6.179325845251704]
	TIME [epoch: 9.7 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.442273623460913		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 6.442273623460913 | validation: 5.697319932176474]
	TIME [epoch: 9.72 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.201542726721842		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 6.201542726721842 | validation: 5.764737507403177]
	TIME [epoch: 9.72 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.061911775419364		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 7.061911775419364 | validation: 8.076356383953327]
	TIME [epoch: 9.73 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.808335701225431		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 8.808335701225431 | validation: 8.93853609582011]
	TIME [epoch: 9.72 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.427118377776513		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 7.427118377776513 | validation: 6.5849126013261]
	TIME [epoch: 9.74 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.078246550436384		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 6.078246550436384 | validation: 5.84149001054733]
	TIME [epoch: 9.71 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.430152365197828		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 5.430152365197828 | validation: 5.6110512771137]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.407797771761337		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 5.407797771761337 | validation: 5.613775645702801]
	TIME [epoch: 9.73 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.5127321495863075		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 5.5127321495863075 | validation: 6.573678615775848]
	TIME [epoch: 9.72 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9856319915974305		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 5.9856319915974305 | validation: 5.571721468016283]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_202.pth
	Model improved!!!
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.593998186072296		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 5.593998186072296 | validation: 5.734332140616494]
	TIME [epoch: 9.73 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.570873724550396		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 5.570873724550396 | validation: 6.940265778190539]
	TIME [epoch: 9.73 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.885155195128242		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 6.885155195128242 | validation: 7.505003306568275]
	TIME [epoch: 9.72 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.469591771238345		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 6.469591771238345 | validation: 6.526368415255695]
	TIME [epoch: 9.73 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8603308584580756		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 6.8603308584580756 | validation: 7.470735091799138]
	TIME [epoch: 9.74 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.5934811217059295		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 6.5934811217059295 | validation: 6.2331321244222275]
	TIME [epoch: 9.72 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.85537999272672		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 5.85537999272672 | validation: 6.278020795381208]
	TIME [epoch: 9.71 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.652391636521942		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 6.652391636521942 | validation: 6.739474658990584]
	TIME [epoch: 9.74 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.683525745660978		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 6.683525745660978 | validation: 6.218663702214055]
	TIME [epoch: 9.71 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6270213800981255		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 6.6270213800981255 | validation: 5.578309388986077]
	TIME [epoch: 9.72 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.687598495343946		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 5.687598495343946 | validation: 5.112311021140049]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_213.pth
	Model improved!!!
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.1922300973057816		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 5.1922300973057816 | validation: 4.800980143520253]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_214.pth
	Model improved!!!
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.67403961614141		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 4.67403961614141 | validation: 4.617206437572263]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_215.pth
	Model improved!!!
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.295767351737832		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 4.295767351737832 | validation: 4.326328406405633]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9432370797052294		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 3.9432370797052294 | validation: 3.3262514104076377]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_217.pth
	Model improved!!!
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.408806835278584		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 3.408806835278584 | validation: 3.144946832260528]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_218.pth
	Model improved!!!
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3526512523796477		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 3.3526512523796477 | validation: 3.401419827047929]
	TIME [epoch: 9.74 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9079721783043135		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 2.9079721783043135 | validation: 2.628320848827357]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_220.pth
	Model improved!!!
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.728608175544357		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 2.728608175544357 | validation: 2.910281287820531]
	TIME [epoch: 9.72 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5993746930073014		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 2.5993746930073014 | validation: 2.57606692594114]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_222.pth
	Model improved!!!
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4724672673635255		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 2.4724672673635255 | validation: 3.3050143337475366]
	TIME [epoch: 9.72 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.632800432048921		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 2.632800432048921 | validation: 2.3370188445733673]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_224.pth
	Model improved!!!
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.310645069563912		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 2.310645069563912 | validation: 2.800055720087248]
	TIME [epoch: 9.74 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3375522144198273		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 2.3375522144198273 | validation: 2.3770814981227617]
	TIME [epoch: 9.71 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9631181580979296		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 2.9631181580979296 | validation: 3.4192272347230825]
	TIME [epoch: 9.72 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8723452550925024		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 2.8723452550925024 | validation: 2.564556078911853]
	TIME [epoch: 9.74 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.210427846473967		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 2.210427846473967 | validation: 2.4033560094888844]
	TIME [epoch: 9.72 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5867417785939315		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 2.5867417785939315 | validation: 2.2638012135321315]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_230.pth
	Model improved!!!
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.184617771805229		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 2.184617771805229 | validation: 2.4335495438309733]
	TIME [epoch: 9.74 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3096356526961244		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 2.3096356526961244 | validation: 2.3118340192945834]
	TIME [epoch: 9.71 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.417643391630564		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 2.417643391630564 | validation: 2.689791857865331]
	TIME [epoch: 9.71 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2543618669615286		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 2.2543618669615286 | validation: 2.4093041011298384]
	TIME [epoch: 9.73 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.445690341893881		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 2.445690341893881 | validation: 2.707592705511237]
	TIME [epoch: 9.71 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3849878929673896		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 2.3849878929673896 | validation: 2.505023924935606]
	TIME [epoch: 9.72 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2310073199546414		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 2.2310073199546414 | validation: 2.349162029733235]
	TIME [epoch: 9.75 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9534977495044865		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 2.9534977495044865 | validation: 2.746759674183046]
	TIME [epoch: 9.72 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.557766920283196		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 2.557766920283196 | validation: 2.5534767213019745]
	TIME [epoch: 9.72 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.130357732035808		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 2.130357732035808 | validation: 2.7139159217744555]
	TIME [epoch: 9.74 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.431916564411787		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 2.431916564411787 | validation: 2.5481122718371902]
	TIME [epoch: 9.72 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.562917057740421		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 2.562917057740421 | validation: 2.429390801230623]
	TIME [epoch: 9.72 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.362821742834091		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 2.362821742834091 | validation: 2.754089513231193]
	TIME [epoch: 9.74 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.36126367420521		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 2.36126367420521 | validation: 2.5893271646908005]
	TIME [epoch: 9.72 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3410512355989392		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 2.3410512355989392 | validation: 2.9778988727508477]
	TIME [epoch: 9.72 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7478649140799742		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 2.7478649140799742 | validation: 2.7138606386850035]
	TIME [epoch: 9.73 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6340347553451076		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 2.6340347553451076 | validation: 3.070509669126544]
	TIME [epoch: 9.73 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.339252973016816		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 2.339252973016816 | validation: 2.317982411650589]
	TIME [epoch: 9.72 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3687646937802262		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 2.3687646937802262 | validation: 2.412463421104541]
	TIME [epoch: 9.73 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.272911757684831		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 2.272911757684831 | validation: 2.1189375645360533]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_250.pth
	Model improved!!!
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.318289668426053		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 2.318289668426053 | validation: 3.3399410610049705]
	TIME [epoch: 9.73 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.352634372907263		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 2.352634372907263 | validation: 2.511670336840725]
	TIME [epoch: 9.72 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.181857092599972		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 2.181857092599972 | validation: 3.206410231773606]
	TIME [epoch: 9.74 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6827638704359793		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 2.6827638704359793 | validation: 2.2938174510843448]
	TIME [epoch: 9.72 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1307737185671947		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 2.1307737185671947 | validation: 2.075065170466458]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_255.pth
	Model improved!!!
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.930636004489541		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 1.930636004489541 | validation: 2.0619780529056397]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_256.pth
	Model improved!!!
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0444408928086486		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 2.0444408928086486 | validation: 2.8862724309250347]
	TIME [epoch: 9.71 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.739918056604753		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 2.739918056604753 | validation: 2.594480292043629]
	TIME [epoch: 9.72 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0092493271255263		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 2.0092493271255263 | validation: 2.0827484965416825]
	TIME [epoch: 9.74 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.193336178703132		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 2.193336178703132 | validation: 2.213915216637371]
	TIME [epoch: 9.72 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.190426307150892		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 2.190426307150892 | validation: 3.1407297288262384]
	TIME [epoch: 9.72 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4163434077996153		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 2.4163434077996153 | validation: 1.9822986630346036]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_262.pth
	Model improved!!!
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9856725387542695		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.9856725387542695 | validation: 2.0504137922723986]
	TIME [epoch: 9.71 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0735113663188516		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 2.0735113663188516 | validation: 2.1571069373308207]
	TIME [epoch: 9.7 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.068633747179716		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 2.068633747179716 | validation: 2.054444210423554]
	TIME [epoch: 9.73 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.375002168088519		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 2.375002168088519 | validation: 2.6008946691040182]
	TIME [epoch: 9.71 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.070072704553441		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 2.070072704553441 | validation: 2.0876290617262288]
	TIME [epoch: 9.71 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.969964892645232		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 1.969964892645232 | validation: 2.0190211116358605]
	TIME [epoch: 9.73 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9041184669309292		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.9041184669309292 | validation: 1.8962031797227696]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_269.pth
	Model improved!!!
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.265782628488845		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 2.265782628488845 | validation: 2.3441940625005326]
	TIME [epoch: 9.72 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8663367332788148		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.8663367332788148 | validation: 2.1067136366213246]
	TIME [epoch: 9.74 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0003473105476126		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 2.0003473105476126 | validation: 1.9333367953658953]
	TIME [epoch: 9.72 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.133463037749428		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 2.133463037749428 | validation: 2.1485399027274834]
	TIME [epoch: 9.71 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.916630501592369		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 1.916630501592369 | validation: 1.8462811676543505]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_274.pth
	Model improved!!!
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9264074591098992		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.9264074591098992 | validation: 2.6085507378403974]
	TIME [epoch: 9.72 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.124923937138446		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 2.124923937138446 | validation: 3.3294793139169587]
	TIME [epoch: 9.7 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.54393964719389		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 2.54393964719389 | validation: 2.0277387176821526]
	TIME [epoch: 9.72 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1853471416495385		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 2.1853471416495385 | validation: 2.1901426452310107]
	TIME [epoch: 9.71 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0829696424641773		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 2.0829696424641773 | validation: 2.2484809837013504]
	TIME [epoch: 9.7 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0346924837254723		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 2.0346924837254723 | validation: 2.106632711451755]
	TIME [epoch: 9.72 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7399005330856454		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 1.7399005330856454 | validation: 2.747375389689892]
	TIME [epoch: 9.7 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.243525364923033		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 2.243525364923033 | validation: 1.95027716278512]
	TIME [epoch: 9.7 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8047982645434253		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 1.8047982645434253 | validation: 1.8284424108593913]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_283.pth
	Model improved!!!
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3667500724236374		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 2.3667500724236374 | validation: 2.701959624263529]
	TIME [epoch: 9.71 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.081614439878326		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 2.081614439878326 | validation: 4.159681461633672]
	TIME [epoch: 9.7 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7844121822687606		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 2.7844121822687606 | validation: 1.7769790840727264]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_286.pth
	Model improved!!!
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.237532191087843		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 2.237532191087843 | validation: 2.16991808665805]
	TIME [epoch: 9.73 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9904951436120442		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 1.9904951436120442 | validation: 1.828460604643966]
	TIME [epoch: 9.71 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.806438493454324		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 1.806438493454324 | validation: 1.8007123077340255]
	TIME [epoch: 9.71 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7376331775870266		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 1.7376331775870266 | validation: 1.7814197691674236]
	TIME [epoch: 9.72 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8427455005967222		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 1.8427455005967222 | validation: 1.8993333519869502]
	TIME [epoch: 9.71 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8302063546313607		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 1.8302063546313607 | validation: 1.9305360930370945]
	TIME [epoch: 9.72 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8024467561347493		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 1.8024467561347493 | validation: 2.1656930223071225]
	TIME [epoch: 9.73 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.804758225098087		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 1.804758225098087 | validation: 2.234726209161613]
	TIME [epoch: 9.71 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.26976882355714		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 2.26976882355714 | validation: 1.7662154313517728]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_295.pth
	Model improved!!!
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.060955755746738		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 2.060955755746738 | validation: 1.8469122277566579]
	TIME [epoch: 9.73 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7396421584722677		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 1.7396421584722677 | validation: 2.4286077024633337]
	TIME [epoch: 9.71 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0391331786037745		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 2.0391331786037745 | validation: 1.7945636012990227]
	TIME [epoch: 9.7 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0141189910075967		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 2.0141189910075967 | validation: 1.9833214144588585]
	TIME [epoch: 9.73 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.899197982952525		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 1.899197982952525 | validation: 2.0643372065967314]
	TIME [epoch: 9.71 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.533138448420046		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 2.533138448420046 | validation: 1.9640562057056274]
	TIME [epoch: 9.71 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7876892159115259		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 1.7876892159115259 | validation: 2.0437386194478124]
	TIME [epoch: 9.73 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9218317932811284		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 1.9218317932811284 | validation: 1.7302502385883196]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_303.pth
	Model improved!!!
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.705838072726817		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 1.705838072726817 | validation: 2.0503387577891083]
	TIME [epoch: 9.71 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.157914685718803		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 2.157914685718803 | validation: 1.9175807534614027]
	TIME [epoch: 9.73 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7624908603959082		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.7624908603959082 | validation: 2.2570150100138533]
	TIME [epoch: 9.71 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7323211478553948		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 1.7323211478553948 | validation: 1.9362990689282118]
	TIME [epoch: 9.71 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7149229386364695		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 1.7149229386364695 | validation: 1.8094220503352705]
	TIME [epoch: 9.73 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.684547264896364		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 1.684547264896364 | validation: 1.9566601944738538]
	TIME [epoch: 9.71 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8469266452310251		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 1.8469266452310251 | validation: 1.839509748154174]
	TIME [epoch: 9.71 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.089529595974214		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 2.089529595974214 | validation: 2.0653029014186335]
	TIME [epoch: 9.73 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8617444499728013		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 1.8617444499728013 | validation: 1.660426963969868]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_312.pth
	Model improved!!!
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.93268866899484		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 1.93268866899484 | validation: 1.8749900519247944]
	TIME [epoch: 9.7 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7055984094953605		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 1.7055984094953605 | validation: 1.982519429294967]
	TIME [epoch: 9.72 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8318409656189876		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 1.8318409656189876 | validation: 1.9165090743622484]
	TIME [epoch: 9.71 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7964517068037007		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 1.7964517068037007 | validation: 1.8606300419024775]
	TIME [epoch: 9.71 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6013639763127263		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 1.6013639763127263 | validation: 1.7688927384416655]
	TIME [epoch: 9.72 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6821400605723347		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 1.6821400605723347 | validation: 1.8791240216138414]
	TIME [epoch: 9.72 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.661149049359824		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 1.661149049359824 | validation: 1.718006578319652]
	TIME [epoch: 9.7 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.633180730145071		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 1.633180730145071 | validation: 2.0840949483502094]
	TIME [epoch: 9.7 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.644851958956977		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 1.644851958956977 | validation: 1.773099241317191]
	TIME [epoch: 9.72 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6895853668361411		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 1.6895853668361411 | validation: 1.6398957016182782]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_322.pth
	Model improved!!!
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5767220028963813		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 1.5767220028963813 | validation: 1.7554610435899565]
	TIME [epoch: 9.7 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9393397286606622		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 1.9393397286606622 | validation: 1.7716941678370342]
	TIME [epoch: 9.72 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9416220339792603		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 1.9416220339792603 | validation: 1.9252448830364801]
	TIME [epoch: 9.7 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8961121167667294		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 1.8961121167667294 | validation: 1.632962740784824]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_326.pth
	Model improved!!!
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7503690983914963		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 1.7503690983914963 | validation: 1.6146116146600773]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_327.pth
	Model improved!!!
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5179113454918456		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 1.5179113454918456 | validation: 2.0114052941967513]
	TIME [epoch: 9.7 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6750396462155954		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 1.6750396462155954 | validation: 2.3777859806236727]
	TIME [epoch: 9.71 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7562096184030715		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 1.7562096184030715 | validation: 1.6680573730705408]
	TIME [epoch: 9.73 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9963551464213176		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 1.9963551464213176 | validation: 2.758740803448153]
	TIME [epoch: 9.71 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.960413566250267		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 1.960413566250267 | validation: 1.9226056278841703]
	TIME [epoch: 9.7 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.621387398291115		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 1.621387398291115 | validation: 1.9068952553343779]
	TIME [epoch: 9.73 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6685573956878925		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 1.6685573956878925 | validation: 1.7629110088195412]
	TIME [epoch: 9.7 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.695140788245773		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 1.695140788245773 | validation: 1.936622489178995]
	TIME [epoch: 9.7 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7165368034252857		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 1.7165368034252857 | validation: 1.8190456055976338]
	TIME [epoch: 9.73 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5546271508129685		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 1.5546271508129685 | validation: 1.6862094875348193]
	TIME [epoch: 9.71 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4882699427118102		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 1.4882699427118102 | validation: 1.8012782304929857]
	TIME [epoch: 9.7 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0031216110599095		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 2.0031216110599095 | validation: 1.9428840298056258]
	TIME [epoch: 9.72 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.606965403445821		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 1.606965403445821 | validation: 1.696617602896372]
	TIME [epoch: 9.71 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6453875445350519		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 1.6453875445350519 | validation: 1.7044081682938106]
	TIME [epoch: 9.7 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0597460438678086		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 2.0597460438678086 | validation: 2.2150195420681773]
	TIME [epoch: 9.73 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.607125612242837		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 1.607125612242837 | validation: 1.543478997791453]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_343.pth
	Model improved!!!
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4798217246683474		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 1.4798217246683474 | validation: 1.635351920341423]
	TIME [epoch: 9.7 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5527333079061145		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 1.5527333079061145 | validation: 1.6749153832886734]
	TIME [epoch: 9.72 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8991254357536913		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 1.8991254357536913 | validation: 1.6055194779116584]
	TIME [epoch: 9.71 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6776814575430834		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 1.6776814575430834 | validation: 1.5448323865200146]
	TIME [epoch: 9.7 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.608471579399398		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 1.608471579399398 | validation: 1.6878879361991421]
	TIME [epoch: 9.72 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5900462868457903		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 1.5900462868457903 | validation: 1.9988891669983804]
	TIME [epoch: 9.71 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6183980790125712		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 1.6183980790125712 | validation: 1.9072165730928128]
	TIME [epoch: 9.69 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5104006359609183		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 1.5104006359609183 | validation: 1.6224811638349792]
	TIME [epoch: 9.71 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7822958965191034		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 1.7822958965191034 | validation: 1.570628599761199]
	TIME [epoch: 9.7 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.545520946938501		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 1.545520946938501 | validation: 1.9738718392463221]
	TIME [epoch: 9.7 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8141836488600251		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 1.8141836488600251 | validation: 1.5328228175968832]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_354.pth
	Model improved!!!
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6639851044463374		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 1.6639851044463374 | validation: 2.089068692184631]
	TIME [epoch: 9.73 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5740349080194698		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 1.5740349080194698 | validation: 1.498012364964366]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_356.pth
	Model improved!!!
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4929286711182885		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 1.4929286711182885 | validation: 1.6916721777583041]
	TIME [epoch: 9.7 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6082042792192586		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 1.6082042792192586 | validation: 1.7497280007688505]
	TIME [epoch: 9.72 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7498328767761577		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 1.7498328767761577 | validation: 2.5415055614339868]
	TIME [epoch: 9.7 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0888395428023845		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 2.0888395428023845 | validation: 1.658483759233206]
	TIME [epoch: 9.7 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5583780466669406		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 1.5583780466669406 | validation: 1.65800420118756]
	TIME [epoch: 9.71 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.432596774848856		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 1.432596774848856 | validation: 1.6026070273529007]
	TIME [epoch: 9.7 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4614027643725538		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 1.4614027643725538 | validation: 2.2837842485419375]
	TIME [epoch: 9.7 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.657212876754258		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 1.657212876754258 | validation: 1.5507046435579088]
	TIME [epoch: 9.72 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5792288291044945		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 1.5792288291044945 | validation: 1.6605954188587968]
	TIME [epoch: 9.7 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4785495960362742		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 1.4785495960362742 | validation: 1.5433428279891832]
	TIME [epoch: 9.7 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4283179109657198		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 1.4283179109657198 | validation: 1.5810796215384748]
	TIME [epoch: 9.72 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4607955501516983		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 1.4607955501516983 | validation: 2.5138311303931995]
	TIME [epoch: 9.7 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7404437278925287		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 1.7404437278925287 | validation: 2.123775490758245]
	TIME [epoch: 9.69 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5953665654623848		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 1.5953665654623848 | validation: 1.5545617130527345]
	TIME [epoch: 9.72 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5981228708064308		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 1.5981228708064308 | validation: 1.66640476399482]
	TIME [epoch: 9.7 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5724951101366018		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 1.5724951101366018 | validation: 1.695933515391729]
	TIME [epoch: 9.71 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.622786367264591		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 1.622786367264591 | validation: 1.7739326996087528]
	TIME [epoch: 9.73 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5351593309164726		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 1.5351593309164726 | validation: 3.210954357458323]
	TIME [epoch: 9.7 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0263878624396314		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 2.0263878624396314 | validation: 1.725504471599096]
	TIME [epoch: 9.7 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.437931247492493		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 1.437931247492493 | validation: 1.4782771742282805]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_376.pth
	Model improved!!!
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.600489220018741		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 1.600489220018741 | validation: 1.54857714786512]
	TIME [epoch: 9.71 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3756453222852918		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 1.3756453222852918 | validation: 2.1357523565402796]
	TIME [epoch: 9.7 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.605437878815891		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 1.605437878815891 | validation: 2.4503253957238478]
	TIME [epoch: 9.72 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6348424169999263		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 1.6348424169999263 | validation: 1.5914701504166908]
	TIME [epoch: 9.7 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.360575553405786		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 1.360575553405786 | validation: 1.4874821428575116]
	TIME [epoch: 9.7 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7319679397499939		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 1.7319679397499939 | validation: 1.4402774928977278]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_382.pth
	Model improved!!!
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4154431775344118		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 1.4154431775344118 | validation: 1.4971321111972464]
	TIME [epoch: 9.72 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.492701304652178		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 1.492701304652178 | validation: 1.4894234686268146]
	TIME [epoch: 9.72 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4877683979250313		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 1.4877683979250313 | validation: 1.5064282988054851]
	TIME [epoch: 9.73 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.466743184543596		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 1.466743184543596 | validation: 1.7709015567863413]
	TIME [epoch: 9.72 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4430058263263497		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 1.4430058263263497 | validation: 1.5607358752582383]
	TIME [epoch: 9.72 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.470839580972346		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 1.470839580972346 | validation: 1.502362486966382]
	TIME [epoch: 9.72 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4721012775346316		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 1.4721012775346316 | validation: 1.5558230143647342]
	TIME [epoch: 9.74 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4279330944142044		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 1.4279330944142044 | validation: 1.578304111239579]
	TIME [epoch: 9.72 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4505259207696461		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 1.4505259207696461 | validation: 1.5796677904313117]
	TIME [epoch: 9.72 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.371749704557648		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 1.371749704557648 | validation: 1.9818074605708285]
	TIME [epoch: 9.74 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.560442785622719		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 1.560442785622719 | validation: 1.5901571905749274]
	TIME [epoch: 9.72 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.374123071931454		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 1.374123071931454 | validation: 1.7523437400138164]
	TIME [epoch: 9.71 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4768054202020748		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 1.4768054202020748 | validation: 1.4701138814874763]
	TIME [epoch: 9.74 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.396197382154118		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 1.396197382154118 | validation: 1.6349221504374012]
	TIME [epoch: 9.71 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.362920852997638		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 1.362920852997638 | validation: 1.4041217588839805]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_397.pth
	Model improved!!!
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4050897059753051		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 1.4050897059753051 | validation: 1.529283856977871]
	TIME [epoch: 9.75 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7073322411866794		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 1.7073322411866794 | validation: 1.5477973326461325]
	TIME [epoch: 9.71 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3321435729983584		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 1.3321435729983584 | validation: 1.4484871843298073]
	TIME [epoch: 9.71 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4288777786716742		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 1.4288777786716742 | validation: 1.590507688237024]
	TIME [epoch: 9.74 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3833629941726262		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 1.3833629941726262 | validation: 1.415285377039007]
	TIME [epoch: 9.71 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5212389385323855		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 1.5212389385323855 | validation: 1.4903094257079768]
	TIME [epoch: 9.71 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.384883055149273		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 1.384883055149273 | validation: 1.7156597467415384]
	TIME [epoch: 9.74 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7005659738694088		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 1.7005659738694088 | validation: 1.4291834833457862]
	TIME [epoch: 9.71 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.353970981033449		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 1.353970981033449 | validation: 1.3670869245572959]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_406.pth
	Model improved!!!
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2848137707663576		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 1.2848137707663576 | validation: 1.5114127758857376]
	TIME [epoch: 9.74 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.377951186292835		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 1.377951186292835 | validation: 1.4879711258750263]
	TIME [epoch: 9.72 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4812125409540653		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 1.4812125409540653 | validation: 1.484211380022946]
	TIME [epoch: 9.71 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3532347893448475		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 1.3532347893448475 | validation: 1.4826474318562715]
	TIME [epoch: 9.74 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.359494216751035		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 1.359494216751035 | validation: 1.4897096941287027]
	TIME [epoch: 9.72 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6931722744167383		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 1.6931722744167383 | validation: 2.480584860439965]
	TIME [epoch: 9.71 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7033653409752325		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 1.7033653409752325 | validation: 1.3577253097110997]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_413.pth
	Model improved!!!
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3239738348111865		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 1.3239738348111865 | validation: 1.9570068279835318]
	TIME [epoch: 9.72 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5633206123191188		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 1.5633206123191188 | validation: 2.5991928240620554]
	TIME [epoch: 9.71 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.303501107471217		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 2.303501107471217 | validation: 1.5169463962607648]
	TIME [epoch: 9.74 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6292784606233723		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 1.6292784606233723 | validation: 1.3653292096816358]
	TIME [epoch: 9.72 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2964456879441482		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 1.2964456879441482 | validation: 1.3960414316892367]
	TIME [epoch: 9.72 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.487892836066909		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 1.487892836066909 | validation: 1.3403198248627302]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_419.pth
	Model improved!!!
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.478848931940518		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 1.478848931940518 | validation: 1.4451083297898135]
	TIME [epoch: 9.73 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5192836822652895		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 1.5192836822652895 | validation: 1.3791297496453365]
	TIME [epoch: 9.72 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3825448480570817		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 1.3825448480570817 | validation: 1.559234963597841]
	TIME [epoch: 9.74 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3291277858073953		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 1.3291277858073953 | validation: 1.486234857487125]
	TIME [epoch: 9.74 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3867845264096448		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 1.3867845264096448 | validation: 3.110404146269027]
	TIME [epoch: 9.72 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1757303620968385		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 2.1757303620968385 | validation: 1.3716029934246572]
	TIME [epoch: 9.73 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.25144740714096		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 1.25144740714096 | validation: 1.4781084959391342]
	TIME [epoch: 9.74 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3568753693890976		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 1.3568753693890976 | validation: 1.4274634998232147]
	TIME [epoch: 9.73 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4197372589798463		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 1.4197372589798463 | validation: 1.4348461367434202]
	TIME [epoch: 9.72 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6127234920460594		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 1.6127234920460594 | validation: 1.4789939082307593]
	TIME [epoch: 9.74 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4125305406850108		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 1.4125305406850108 | validation: 1.7107793272076937]
	TIME [epoch: 9.72 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3870607842911362		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 1.3870607842911362 | validation: 1.7371069756654982]
	TIME [epoch: 9.73 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.583645564340813		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 1.583645564340813 | validation: 1.3381570379553438]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_432.pth
	Model improved!!!
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3854942273076432		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 1.3854942273076432 | validation: 1.5670611070240268]
	TIME [epoch: 9.72 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3986085612103483		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 1.3986085612103483 | validation: 1.5347653127025327]
	TIME [epoch: 9.71 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.351228789565265		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 1.351228789565265 | validation: 1.361443531072793]
	TIME [epoch: 9.74 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2753255470341653		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 1.2753255470341653 | validation: 1.3918733698390993]
	TIME [epoch: 9.72 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.309897349049174		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 1.309897349049174 | validation: 1.2585179753824038]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_437.pth
	Model improved!!!
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3531312385137688		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 1.3531312385137688 | validation: 1.7971007758875113]
	TIME [epoch: 9.73 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3475479247538962		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 1.3475479247538962 | validation: 1.2599610794380198]
	TIME [epoch: 9.7 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2423117264637273		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 1.2423117264637273 | validation: 1.4402850504251956]
	TIME [epoch: 9.71 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3324031682707984		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 1.3324031682707984 | validation: 1.5267325656397202]
	TIME [epoch: 9.73 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3643777474483219		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 1.3643777474483219 | validation: 1.3226032739666493]
	TIME [epoch: 9.7 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2339968435729487		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 1.2339968435729487 | validation: 1.7429956834363123]
	TIME [epoch: 9.71 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.450140397105428		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 1.450140397105428 | validation: 1.4509623101534856]
	TIME [epoch: 9.73 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2496860235938818		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 1.2496860235938818 | validation: 1.2847071567616462]
	TIME [epoch: 9.71 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1721377740902994		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 1.1721377740902994 | validation: 1.8325007109355844]
	TIME [epoch: 9.71 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.322660946620095		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 1.322660946620095 | validation: 1.2955999489886665]
	TIME [epoch: 9.72 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2253478530016393		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 1.2253478530016393 | validation: 1.3440323090107915]
	TIME [epoch: 9.71 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2103496357496222		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 1.2103496357496222 | validation: 1.8706287449914465]
	TIME [epoch: 9.71 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7416598922554853		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 1.7416598922554853 | validation: 1.425972106737642]
	TIME [epoch: 9.72 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.281363380819727		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 1.281363380819727 | validation: 1.5627892745223342]
	TIME [epoch: 9.71 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2341650271015552		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 1.2341650271015552 | validation: 1.2690234894205923]
	TIME [epoch: 9.7 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5232348902890134		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 1.5232348902890134 | validation: 1.2714294056432565]
	TIME [epoch: 9.72 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2150654410443977		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 1.2150654410443977 | validation: 1.8777802933503238]
	TIME [epoch: 9.71 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3512080945041265		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 1.3512080945041265 | validation: 1.312474871309858]
	TIME [epoch: 9.7 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3341710990219842		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 1.3341710990219842 | validation: 1.7602405514536872]
	TIME [epoch: 9.71 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.304700403393786		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 1.304700403393786 | validation: 1.5433366030635192]
	TIME [epoch: 9.72 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7362391760953393		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 1.7362391760953393 | validation: 3.145892410068329]
	TIME [epoch: 9.7 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7055189780983042		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 1.7055189780983042 | validation: 1.557961772107975]
	TIME [epoch: 9.71 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.239113512875739		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 1.239113512875739 | validation: 1.5680471866320156]
	TIME [epoch: 9.72 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.406631551742596		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 1.406631551742596 | validation: 1.267091308922942]
	TIME [epoch: 9.7 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2076899465113118		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 1.2076899465113118 | validation: 1.2276828377549394]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_462.pth
	Model improved!!!
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.292015102084682		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 1.292015102084682 | validation: 2.538508357342285]
	TIME [epoch: 9.72 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.914878420303123		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 1.914878420303123 | validation: 1.468724056389734]
	TIME [epoch: 9.7 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3849852344280809		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 1.3849852344280809 | validation: 1.860203563043219]
	TIME [epoch: 9.71 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7633858915076879		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 1.7633858915076879 | validation: 1.2991219553362776]
	TIME [epoch: 9.73 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.260414398055378		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 1.260414398055378 | validation: 1.5728066156035858]
	TIME [epoch: 9.71 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.33095939245312		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 1.33095939245312 | validation: 1.4247351198947669]
	TIME [epoch: 9.7 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1947087443655104		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 1.1947087443655104 | validation: 1.280597350361626]
	TIME [epoch: 9.72 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1405729583371533		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 1.1405729583371533 | validation: 1.3815342001297943]
	TIME [epoch: 9.7 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1846251549393099		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 1.1846251549393099 | validation: 1.2573641446128705]
	TIME [epoch: 9.7 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1542093259770714		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 1.1542093259770714 | validation: 1.3525078210040666]
	TIME [epoch: 9.72 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1508198585069331		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 1.1508198585069331 | validation: 1.2955557602129613]
	TIME [epoch: 9.7 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.151836659026867		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 1.151836659026867 | validation: 1.2038753307809098]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_474.pth
	Model improved!!!
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1301286478892822		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 1.1301286478892822 | validation: 1.1656022532193364]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_475.pth
	Model improved!!!
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1969045269404117		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 1.1969045269404117 | validation: 1.2101334329409292]
	TIME [epoch: 9.7 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1231733643858814		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 1.1231733643858814 | validation: 1.429833164588699]
	TIME [epoch: 9.7 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2475996429828706		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 1.2475996429828706 | validation: 1.2613218548737968]
	TIME [epoch: 9.71 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.179891631364836		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 1.179891631364836 | validation: 1.1932019467643955]
	TIME [epoch: 9.7 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1725089144125778		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 1.1725089144125778 | validation: 1.1642063288266546]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_480.pth
	Model improved!!!
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.129267592422903		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 1.129267592422903 | validation: 1.2848068260375203]
	TIME [epoch: 9.72 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1592081326786385		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 1.1592081326786385 | validation: 1.262620770839632]
	TIME [epoch: 9.7 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3568703363492691		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 1.3568703363492691 | validation: 1.2125452408146884]
	TIME [epoch: 9.7 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.111019694172499		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 1.111019694172499 | validation: 1.2093053407471204]
	TIME [epoch: 9.71 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1374520183897827		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 1.1374520183897827 | validation: 1.1506725538741847]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_485.pth
	Model improved!!!
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.075837921395545		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 1.075837921395545 | validation: 1.1605370868304916]
	TIME [epoch: 9.7 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3020966324771936		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 1.3020966324771936 | validation: 1.1308423092025515]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_487.pth
	Model improved!!!
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.228111997181483		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 1.228111997181483 | validation: 1.177530620934336]
	TIME [epoch: 9.7 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.131534727821352		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 1.131534727821352 | validation: 1.1543078899900832]
	TIME [epoch: 9.71 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1142541017863556		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 1.1142541017863556 | validation: 1.2069535302115273]
	TIME [epoch: 9.71 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1904567388908982		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 1.1904567388908982 | validation: 1.1201194846058726]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_491.pth
	Model improved!!!
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0942808523647163		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 1.0942808523647163 | validation: 1.1364189862350973]
	TIME [epoch: 9.7 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1256714577793923		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 1.1256714577793923 | validation: 1.2776760344309814]
	TIME [epoch: 9.71 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2310515607345205		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 1.2310515607345205 | validation: 1.4494885032686153]
	TIME [epoch: 9.71 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7922546984646346		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 1.7922546984646346 | validation: 1.5789066023213008]
	TIME [epoch: 9.71 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.163454288794527		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 1.163454288794527 | validation: 1.2479691779819346]
	TIME [epoch: 9.7 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1768493674774643		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 1.1768493674774643 | validation: 1.1684895345692992]
	TIME [epoch: 9.72 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1118009995270681		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 1.1118009995270681 | validation: 1.2372221860146435]
	TIME [epoch: 9.71 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1048681757617853		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 1.1048681757617853 | validation: 1.101078771003404]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_499.pth
	Model improved!!!
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0330632796805461		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 1.0330632796805461 | validation: 1.1332694630139317]
	TIME [epoch: 9.72 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1263467399872475		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 1.1263467399872475 | validation: 1.2602616735031142]
	TIME [epoch: 9.7 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.422142211392849		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 1.422142211392849 | validation: 1.2109728350562252]
	TIME [epoch: 9.69 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.082377960974778		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 1.082377960974778 | validation: 1.1585982549078977]
	TIME [epoch: 9.71 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.038636540299675		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 1.038636540299675 | validation: 1.348534588489939]
	TIME [epoch: 9.7 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2008767567193324		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 1.2008767567193324 | validation: 1.2615422686354074]
	TIME [epoch: 9.71 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1963364631445814		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 1.1963364631445814 | validation: 1.191176925641382]
	TIME [epoch: 9.72 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.063725754487852		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 1.063725754487852 | validation: 1.1642996296660588]
	TIME [epoch: 9.7 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0379273891223753		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 1.0379273891223753 | validation: 1.089057367263292]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_508.pth
	Model improved!!!
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1778303080217267		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 1.1778303080217267 | validation: 1.0796092548446903]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_509.pth
	Model improved!!!
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1538622515909247		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 1.1538622515909247 | validation: 2.2639789009457285]
	TIME [epoch: 9.7 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.511151223644626		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 1.511151223644626 | validation: 1.0806947582670272]
	TIME [epoch: 9.7 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0627459537956527		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 1.0627459537956527 | validation: 1.146030822120331]
	TIME [epoch: 9.72 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0329078847760411		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 1.0329078847760411 | validation: 1.1384976040559445]
	TIME [epoch: 9.7 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.423298204996443		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 1.423298204996443 | validation: 1.074974814481644]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_514.pth
	Model improved!!!
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0574574428965648		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 1.0574574428965648 | validation: 1.019090829954449]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_515.pth
	Model improved!!!
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1559101624861277		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 1.1559101624861277 | validation: 1.1371132275305305]
	TIME [epoch: 9.7 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0565841828658915		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 1.0565841828658915 | validation: 1.0791807974987868]
	TIME [epoch: 9.7 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.315285986518066		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 1.315285986518066 | validation: 1.0979631983463414]
	TIME [epoch: 9.71 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9924368574707947		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.9924368574707947 | validation: 1.3009330905818792]
	TIME [epoch: 9.71 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.058362022060729		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 1.058362022060729 | validation: 1.6872807662126696]
	TIME [epoch: 9.7 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2917563612781575		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 1.2917563612781575 | validation: 1.0621743685166212]
	TIME [epoch: 9.72 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0194251891640576		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 1.0194251891640576 | validation: 1.418067201507528]
	TIME [epoch: 9.7 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1387350293321803		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 1.1387350293321803 | validation: 1.2152702193130567]
	TIME [epoch: 9.69 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0903211205398613		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 1.0903211205398613 | validation: 1.0560006710417569]
	TIME [epoch: 9.71 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0619678188780157		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 1.0619678188780157 | validation: 1.2950043446581838]
	TIME [epoch: 9.7 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1230792928671227		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 1.1230792928671227 | validation: 1.4868947372883077]
	TIME [epoch: 9.7 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0578474296384128		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 1.0578474296384128 | validation: 1.034665281987747]
	TIME [epoch: 9.7 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9977579877038931		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.9977579877038931 | validation: 1.0593329004299552]
	TIME [epoch: 9.72 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1219828605490274		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 1.1219828605490274 | validation: 1.0853696886459745]
	TIME [epoch: 9.69 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0169872047826274		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 1.0169872047826274 | validation: 1.0389535195844384]
	TIME [epoch: 9.7 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0023254153798413		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 1.0023254153798413 | validation: 1.0529592937125674]
	TIME [epoch: 9.72 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.043348742386744		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 1.043348742386744 | validation: 0.9988030396492932]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_532.pth
	Model improved!!!
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9812481293760589		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.9812481293760589 | validation: 1.3613439311035862]
	TIME [epoch: 9.7 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0643880101467564		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 1.0643880101467564 | validation: 1.2340700859028366]
	TIME [epoch: 9.72 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6517129469709881		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 1.6517129469709881 | validation: 1.0807355014963762]
	TIME [epoch: 9.7 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.025078920008611		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 1.025078920008611 | validation: 1.0240972049736998]
	TIME [epoch: 9.69 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0175227815039296		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 1.0175227815039296 | validation: 0.9994368655149514]
	TIME [epoch: 9.71 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0108159249246218		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 1.0108159249246218 | validation: 1.0213618343044275]
	TIME [epoch: 9.69 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6907483665578673		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 1.6907483665578673 | validation: 1.146338869401794]
	TIME [epoch: 9.69 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.018515229384247		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 1.018515229384247 | validation: 0.9952643946879479]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_540.pth
	Model improved!!!
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0294697986941137		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 1.0294697986941137 | validation: 1.1378018821280886]
	TIME [epoch: 9.7 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.012153047612046		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 1.012153047612046 | validation: 1.009550343317614]
	TIME [epoch: 9.7 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0557484612100503		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 1.0557484612100503 | validation: 1.428834118245673]
	TIME [epoch: 9.73 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0788710738948653		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 1.0788710738948653 | validation: 0.9791063781223914]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_544.pth
	Model improved!!!
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9691532662477049		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.9691532662477049 | validation: 1.0101724755647865]
	TIME [epoch: 9.71 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0000137045645523		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 1.0000137045645523 | validation: 1.0391867311461591]
	TIME [epoch: 9.73 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0300769754386996		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 1.0300769754386996 | validation: 1.235230523155189]
	TIME [epoch: 9.71 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.054756888516545		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 1.054756888516545 | validation: 0.9971169694176478]
	TIME [epoch: 9.72 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9638020456034383		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.9638020456034383 | validation: 1.003651671054724]
	TIME [epoch: 9.73 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0449235440170284		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 1.0449235440170284 | validation: 0.9256748297444964]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_550.pth
	Model improved!!!
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9899428624373435		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.9899428624373435 | validation: 0.9524440226628577]
	TIME [epoch: 9.69 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9405465821529699		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.9405465821529699 | validation: 1.0045877283856286]
	TIME [epoch: 9.71 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9747396987464432		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.9747396987464432 | validation: 0.9157750143669787]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_553.pth
	Model improved!!!
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9139795916477844		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.9139795916477844 | validation: 1.1101261897432064]
	TIME [epoch: 9.71 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.144756436852464		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 1.144756436852464 | validation: 0.931491500876527]
	TIME [epoch: 9.72 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9861089062854738		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.9861089062854738 | validation: 0.9227311047998279]
	TIME [epoch: 9.72 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.024957795774578		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 1.024957795774578 | validation: 1.0164590170185523]
	TIME [epoch: 9.7 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1818986631627368		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 1.1818986631627368 | validation: 1.0084956944367012]
	TIME [epoch: 9.71 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0111304089021327		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 1.0111304089021327 | validation: 0.9366566135984485]
	TIME [epoch: 9.72 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0151234848608062		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 1.0151234848608062 | validation: 1.0661248505498173]
	TIME [epoch: 9.7 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9625207914487415		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.9625207914487415 | validation: 0.9947136518596645]
	TIME [epoch: 9.71 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9326427059624327		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.9326427059624327 | validation: 0.9049810168760803]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_562.pth
	Model improved!!!
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9090142672891446		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.9090142672891446 | validation: 0.9033443076193252]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_563.pth
	Model improved!!!
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9252205169166967		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.9252205169166967 | validation: 1.1441130768932641]
	TIME [epoch: 9.72 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9628773750932698		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.9628773750932698 | validation: 0.9935541994378119]
	TIME [epoch: 9.72 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9395428725867235		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.9395428725867235 | validation: 1.007682990537508]
	TIME [epoch: 9.71 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9730638351698312		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.9730638351698312 | validation: 0.9661496846733988]
	TIME [epoch: 9.71 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.020575823712197		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 1.020575823712197 | validation: 0.9510114490580677]
	TIME [epoch: 9.72 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9297292289614608		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.9297292289614608 | validation: 1.1486118057643413]
	TIME [epoch: 9.71 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9565647747245943		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.9565647747245943 | validation: 0.874515329637186]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_570.pth
	Model improved!!!
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8800332324433713		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.8800332324433713 | validation: 0.9849945654356854]
	TIME [epoch: 9.72 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9588899302953795		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.9588899302953795 | validation: 0.9659802016027412]
	TIME [epoch: 9.7 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9337463554980747		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.9337463554980747 | validation: 0.9788503595386036]
	TIME [epoch: 9.71 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9198204923857155		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.9198204923857155 | validation: 1.0487950002093707]
	TIME [epoch: 9.73 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0085311585534134		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 1.0085311585534134 | validation: 0.9970988935095263]
	TIME [epoch: 9.71 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9446761860546046		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.9446761860546046 | validation: 0.8964519460752629]
	TIME [epoch: 9.71 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.867490588709504		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.867490588709504 | validation: 0.9615608060248622]
	TIME [epoch: 9.73 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9048780524029038		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.9048780524029038 | validation: 1.6486519868778038]
	TIME [epoch: 9.71 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1247129656240182		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 1.1247129656240182 | validation: 0.935038630000535]
	TIME [epoch: 9.71 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8782526997461393		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.8782526997461393 | validation: 1.048386315871734]
	TIME [epoch: 9.73 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9259658826594881		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.9259658826594881 | validation: 1.1676263223390688]
	TIME [epoch: 9.71 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2877307430984335		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 1.2877307430984335 | validation: 0.9761056317613444]
	TIME [epoch: 9.71 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9414463533356979		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.9414463533356979 | validation: 0.9112205104444427]
	TIME [epoch: 9.73 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8607678670032449		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.8607678670032449 | validation: 0.9207450555634084]
	TIME [epoch: 9.71 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8581331307197531		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.8581331307197531 | validation: 0.9704629035608122]
	TIME [epoch: 9.71 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8787909433223152		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.8787909433223152 | validation: 0.9192406695385714]
	TIME [epoch: 9.73 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9072119578134048		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.9072119578134048 | validation: 0.9108451658872262]
	TIME [epoch: 9.71 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8533899139561418		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.8533899139561418 | validation: 0.9404332715087196]
	TIME [epoch: 9.71 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8716175352117388		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.8716175352117388 | validation: 0.9256467213255661]
	TIME [epoch: 9.73 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8583373774136207		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.8583373774136207 | validation: 0.9946213967496566]
	TIME [epoch: 9.71 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8670601297790219		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.8670601297790219 | validation: 1.032383547436905]
	TIME [epoch: 9.71 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9299263125369105		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.9299263125369105 | validation: 0.914193229929229]
	TIME [epoch: 9.73 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8629700849225669		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.8629700849225669 | validation: 0.8701244518414484]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_593.pth
	Model improved!!!
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8903130140101119		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.8903130140101119 | validation: 0.8601772494048373]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_594.pth
	Model improved!!!
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8640173841979184		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.8640173841979184 | validation: 0.926654299751429]
	TIME [epoch: 9.73 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8915054365090258		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.8915054365090258 | validation: 0.9040234931181698]
	TIME [epoch: 9.71 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8674956598612992		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.8674956598612992 | validation: 0.9325289161423999]
	TIME [epoch: 9.71 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9108107828956282		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.9108107828956282 | validation: 1.0079268178855674]
	TIME [epoch: 9.71 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8508877176592193		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.8508877176592193 | validation: 0.8619019940533403]
	TIME [epoch: 9.73 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8711325781791508		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.8711325781791508 | validation: 1.1132694640273397]
	TIME [epoch: 9.71 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9449441755865289		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.9449441755865289 | validation: 1.0240355827036174]
	TIME [epoch: 9.72 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9454143871340467		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.9454143871340467 | validation: 1.065312126853723]
	TIME [epoch: 9.73 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4450588657909418		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 1.4450588657909418 | validation: 1.1374952604414699]
	TIME [epoch: 9.71 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0106193579086162		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 1.0106193579086162 | validation: 0.8622927749235112]
	TIME [epoch: 9.71 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.85347784975023		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.85347784975023 | validation: 1.0373942432657937]
	TIME [epoch: 9.74 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0906105157967716		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 1.0906105157967716 | validation: 1.1856754178583984]
	TIME [epoch: 9.71 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8914657017643611		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.8914657017643611 | validation: 0.9077674445781446]
	TIME [epoch: 9.71 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8318550346769807		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.8318550346769807 | validation: 0.8814556501496174]
	TIME [epoch: 9.73 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9643093337220359		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.9643093337220359 | validation: 1.1680706694180152]
	TIME [epoch: 9.71 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9086686800087941		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.9086686800087941 | validation: 0.9138949375141198]
	TIME [epoch: 9.71 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8293263257014664		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.8293263257014664 | validation: 0.8081991187863014]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_611.pth
	Model improved!!!
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8792488949487218		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.8792488949487218 | validation: 0.9273243135201543]
	TIME [epoch: 9.71 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.935272501942427		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.935272501942427 | validation: 1.132583687357447]
	TIME [epoch: 9.7 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8940541325041801		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.8940541325041801 | validation: 0.9508531261360349]
	TIME [epoch: 9.72 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.870740029043945		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.870740029043945 | validation: 1.107350364267401]
	TIME [epoch: 9.7 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9255394366953281		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.9255394366953281 | validation: 0.825454955026032]
	TIME [epoch: 9.7 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8578281965981891		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.8578281965981891 | validation: 0.893995443757819]
	TIME [epoch: 9.73 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8484647979854515		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.8484647979854515 | validation: 0.932807179139934]
	TIME [epoch: 9.7 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8673370604060626		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.8673370604060626 | validation: 1.0394289718926428]
	TIME [epoch: 9.7 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.851229530338057		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.851229530338057 | validation: 0.9191841133060433]
	TIME [epoch: 9.72 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8939492837645929		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.8939492837645929 | validation: 1.1193040355308244]
	TIME [epoch: 9.7 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.904797537108559		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.904797537108559 | validation: 0.9543779057418103]
	TIME [epoch: 9.71 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8413112010565458		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.8413112010565458 | validation: 0.8789231580827339]
	TIME [epoch: 9.72 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8277437660685998		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.8277437660685998 | validation: 0.8277959994942188]
	TIME [epoch: 9.7 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8179941045921122		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.8179941045921122 | validation: 0.8215174837347127]
	TIME [epoch: 9.7 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8545898732944444		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.8545898732944444 | validation: 1.2700849192775405]
	TIME [epoch: 9.72 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2611431965606088		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 1.2611431965606088 | validation: 0.9165112150678141]
	TIME [epoch: 9.71 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8175173854445326		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.8175173854445326 | validation: 0.8225111021104669]
	TIME [epoch: 9.7 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7861938544946231		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.7861938544946231 | validation: 0.8412715119108571]
	TIME [epoch: 9.72 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7888127557853037		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.7888127557853037 | validation: 0.8556958937759628]
	TIME [epoch: 9.71 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.843328847509253		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.843328847509253 | validation: 1.0328996943417763]
	TIME [epoch: 9.71 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8376011790676163		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.8376011790676163 | validation: 0.8614417373478054]
	TIME [epoch: 9.71 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7983498453060001		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.7983498453060001 | validation: 0.8997114573869525]
	TIME [epoch: 9.71 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8094498546007272		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.8094498546007272 | validation: 0.8576335839468672]
	TIME [epoch: 9.7 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.805363062037779		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.805363062037779 | validation: 0.8027363773675902]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_635.pth
	Model improved!!!
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8034039946530344		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.8034039946530344 | validation: 0.8197473477719052]
	TIME [epoch: 9.72 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7941781381985283		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.7941781381985283 | validation: 0.870387712938447]
	TIME [epoch: 9.71 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8580431372281254		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.8580431372281254 | validation: 0.8969761266593534]
	TIME [epoch: 9.71 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.799092646647326		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.799092646647326 | validation: 1.023337883649547]
	TIME [epoch: 9.73 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9812489086446922		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.9812489086446922 | validation: 0.8154186139169687]
	TIME [epoch: 9.7 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8456707921404967		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.8456707921404967 | validation: 0.8571503280660554]
	TIME [epoch: 9.7 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7543291326606862		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.7543291326606862 | validation: 0.8326306663095341]
	TIME [epoch: 9.72 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7728055622974713		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.7728055622974713 | validation: 0.8395309654094291]
	TIME [epoch: 9.71 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7462786474820003		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.7462786474820003 | validation: 0.8117981615507448]
	TIME [epoch: 9.7 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7470615796930147		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.7470615796930147 | validation: 0.7911915539222946]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_645.pth
	Model improved!!!
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7469031518459378		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.7469031518459378 | validation: 0.7840187656049353]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_646.pth
	Model improved!!!
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.790311055342042		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.790311055342042 | validation: 0.8006814942131226]
	TIME [epoch: 9.71 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7385814290564849		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.7385814290564849 | validation: 1.0870016200244337]
	TIME [epoch: 9.72 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.895633610216008		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.895633610216008 | validation: 0.8345151449387848]
	TIME [epoch: 9.7 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7476386144779659		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.7476386144779659 | validation: 0.8058867250595795]
	TIME [epoch: 9.71 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7793203018916091		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.7793203018916091 | validation: 0.9960954639585066]
	TIME [epoch: 9.72 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8454043058588192		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.8454043058588192 | validation: 0.7540419399480728]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_652.pth
	Model improved!!!
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.761421242307341		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.761421242307341 | validation: 0.809550063701058]
	TIME [epoch: 9.7 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9207396578061114		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.9207396578061114 | validation: 0.787812903982475]
	TIME [epoch: 9.72 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7761349382277147		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.7761349382277147 | validation: 0.7839736497349524]
	TIME [epoch: 9.71 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7318714743142135		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.7318714743142135 | validation: 0.7751287417942437]
	TIME [epoch: 9.69 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7560372373040956		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.7560372373040956 | validation: 0.7757631010803941]
	TIME [epoch: 9.72 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7275566012326496		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.7275566012326496 | validation: 0.8153187812833329]
	TIME [epoch: 9.71 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7428154017632865		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.7428154017632865 | validation: 0.7811578299163406]
	TIME [epoch: 9.7 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7488673478325609		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.7488673478325609 | validation: 0.9091542869287408]
	TIME [epoch: 9.72 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9774168331791406		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.9774168331791406 | validation: 0.7571375378530156]
	TIME [epoch: 9.7 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7459861966929506		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.7459861966929506 | validation: 0.7807807803325116]
	TIME [epoch: 9.7 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7577329977382361		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.7577329977382361 | validation: 0.8209506994727809]
	TIME [epoch: 9.71 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7374534667250475		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.7374534667250475 | validation: 0.7490313569032364]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_664.pth
	Model improved!!!
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7174883408116434		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.7174883408116434 | validation: 0.7309572541366017]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_665.pth
	Model improved!!!
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7517677868006066		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.7517677868006066 | validation: 0.8001443976834705]
	TIME [epoch: 9.71 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7690063168238128		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.7690063168238128 | validation: 0.7944126429916106]
	TIME [epoch: 9.71 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7978456930786872		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.7978456930786872 | validation: 0.9035946218157254]
	TIME [epoch: 9.69 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8013807846387744		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.8013807846387744 | validation: 0.7913259032574256]
	TIME [epoch: 9.7 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7682161331012829		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.7682161331012829 | validation: 0.7721622864923109]
	TIME [epoch: 9.71 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7308960450466209		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.7308960450466209 | validation: 0.8054208239734914]
	TIME [epoch: 9.69 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7981201221572074		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.7981201221572074 | validation: 0.8711401208452236]
	TIME [epoch: 9.69 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7488465606494962		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.7488465606494962 | validation: 0.8066641191859923]
	TIME [epoch: 9.71 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7363056070941776		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.7363056070941776 | validation: 0.7568733369455661]
	TIME [epoch: 9.7 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7196069513396331		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.7196069513396331 | validation: 0.749754699421135]
	TIME [epoch: 9.69 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7452635461456693		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.7452635461456693 | validation: 0.7817268801833668]
	TIME [epoch: 9.71 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7414028726797108		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.7414028726797108 | validation: 0.7246252721609052]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_677.pth
	Model improved!!!
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.772202712236773		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.772202712236773 | validation: 1.0346507629193453]
	TIME [epoch: 9.7 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.063236273515878		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 1.063236273515878 | validation: 0.8102960364740304]
	TIME [epoch: 9.72 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8412405706850311		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.8412405706850311 | validation: 0.8273774238081575]
	TIME [epoch: 9.7 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7804393173635065		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.7804393173635065 | validation: 0.7024646842331842]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_681.pth
	Model improved!!!
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7171584563273855		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.7171584563273855 | validation: 0.7766802696262005]
	TIME [epoch: 9.71 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7533702500037222		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.7533702500037222 | validation: 0.8034620154882356]
	TIME [epoch: 9.69 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.741772489477011		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.741772489477011 | validation: 0.8887458918929738]
	TIME [epoch: 9.7 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8742334703635889		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.8742334703635889 | validation: 0.7286774407502666]
	TIME [epoch: 9.71 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7277621941370005		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.7277621941370005 | validation: 0.706004167520032]
	TIME [epoch: 9.7 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7012066770747266		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.7012066770747266 | validation: 0.7384122683624341]
	TIME [epoch: 9.7 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7344639645153551		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.7344639645153551 | validation: 0.7032055068188902]
	TIME [epoch: 9.71 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.700609033999462		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.700609033999462 | validation: 0.6961950750509474]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_689.pth
	Model improved!!!
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7505375256993445		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.7505375256993445 | validation: 0.7068048024842079]
	TIME [epoch: 9.7 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7408621798312582		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.7408621798312582 | validation: 0.7754555540181061]
	TIME [epoch: 9.71 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7904856369660935		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.7904856369660935 | validation: 0.7891155454470891]
	TIME [epoch: 9.7 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7478093571720688		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.7478093571720688 | validation: 0.7320046499391041]
	TIME [epoch: 9.69 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7239713417587279		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.7239713417587279 | validation: 0.7109614695287796]
	TIME [epoch: 9.71 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7138751074676163		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.7138751074676163 | validation: 0.7809715835749438]
	TIME [epoch: 9.7 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7212347131465892		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.7212347131465892 | validation: 0.828700263108789]
	TIME [epoch: 9.69 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.815423141902385		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.815423141902385 | validation: 0.7217362835906317]
	TIME [epoch: 9.71 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7860224139319237		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.7860224139319237 | validation: 0.7170096836598795]
	TIME [epoch: 9.71 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6922375442443911		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.6922375442443911 | validation: 0.7644690634894526]
	TIME [epoch: 9.69 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7234050139386733		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.7234050139386733 | validation: 0.77010268016135]
	TIME [epoch: 9.7 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7549365119946746		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.7549365119946746 | validation: 0.7006777625074422]
	TIME [epoch: 9.71 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269567637096296		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.7269567637096296 | validation: 0.7104082497325374]
	TIME [epoch: 9.7 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7053818466663784		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.7053818466663784 | validation: 0.7055921336297731]
	TIME [epoch: 9.71 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6896041031308494		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.6896041031308494 | validation: 0.6715428524827501]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_704.pth
	Model improved!!!
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7082097625327857		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.7082097625327857 | validation: 0.6925782352024038]
	TIME [epoch: 9.7 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7328244008771981		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.7328244008771981 | validation: 0.8725009542557485]
	TIME [epoch: 9.7 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7255258389509504		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.7255258389509504 | validation: 0.7391867383124339]
	TIME [epoch: 9.71 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6769647108269622		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.6769647108269622 | validation: 0.7015380668725868]
	TIME [epoch: 9.7 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6868059381182172		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.6868059381182172 | validation: 0.6780708218674982]
	TIME [epoch: 9.7 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6787749657933728		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.6787749657933728 | validation: 0.6895540050991248]
	TIME [epoch: 9.72 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.672367808084803		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.672367808084803 | validation: 0.7177064333638413]
	TIME [epoch: 9.7 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6623388165433213		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.6623388165433213 | validation: 0.6941516944114531]
	TIME [epoch: 9.7 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7533674694277496		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.7533674694277496 | validation: 0.7166471867798069]
	TIME [epoch: 9.73 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6919495102703845		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.6919495102703845 | validation: 0.6887798174811118]
	TIME [epoch: 9.7 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6929543249881354		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.6929543249881354 | validation: 0.6562312293604917]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_715.pth
	Model improved!!!
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6872474049985516		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.6872474049985516 | validation: 0.6755946302259216]
	TIME [epoch: 9.71 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7360546203913712		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.7360546203913712 | validation: 0.7408522145421209]
	TIME [epoch: 9.69 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7887727303520591		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.7887727303520591 | validation: 0.7876944599542673]
	TIME [epoch: 9.7 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7388235722022719		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.7388235722022719 | validation: 0.8086063261512466]
	TIME [epoch: 9.72 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7462682743380704		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.7462682743380704 | validation: 0.7366718644596089]
	TIME [epoch: 9.69 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7136117690657034		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.7136117690657034 | validation: 0.7362386586531676]
	TIME [epoch: 9.7 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6733506117219246		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.6733506117219246 | validation: 0.7471738043141803]
	TIME [epoch: 9.72 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7616161946700685		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.7616161946700685 | validation: 0.7463805376559379]
	TIME [epoch: 9.7 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6762810133648032		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.6762810133648032 | validation: 0.7082595541374479]
	TIME [epoch: 9.69 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7484033251739323		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.7484033251739323 | validation: 0.6833263443876147]
	TIME [epoch: 9.71 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7185528341425247		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.7185528341425247 | validation: 0.6793728634653052]
	TIME [epoch: 9.7 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7186772651808078		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.7186772651808078 | validation: 0.7316527627008199]
	TIME [epoch: 9.7 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7602144933158596		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.7602144933158596 | validation: 0.6851354629215497]
	TIME [epoch: 9.7 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6825389506906709		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.6825389506906709 | validation: 0.7537494269610134]
	TIME [epoch: 9.71 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7124455931641046		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.7124455931641046 | validation: 0.661328009395847]
	TIME [epoch: 9.7 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6679512369063707		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.6679512369063707 | validation: 0.6865095117560932]
	TIME [epoch: 9.7 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6953747542497887		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.6953747542497887 | validation: 0.8429190560519538]
	TIME [epoch: 9.71 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.724071079758969		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.724071079758969 | validation: 0.7005839679566404]
	TIME [epoch: 9.7 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6686896361845726		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.6686896361845726 | validation: 0.6744182244984972]
	TIME [epoch: 9.7 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6924575897899594		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.6924575897899594 | validation: 0.7481540739927206]
	TIME [epoch: 9.71 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6969523631294151		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.6969523631294151 | validation: 0.665354200331095]
	TIME [epoch: 9.69 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6481975238457696		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.6481975238457696 | validation: 0.7091870047574688]
	TIME [epoch: 9.7 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6629462475022503		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.6629462475022503 | validation: 0.7114389163022773]
	TIME [epoch: 9.72 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6905788488993083		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.6905788488993083 | validation: 0.7457884864825468]
	TIME [epoch: 9.69 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8014297359779992		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.8014297359779992 | validation: 0.68849919253645]
	TIME [epoch: 9.69 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488143353011794		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.6488143353011794 | validation: 0.6486712340792888]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_741.pth
	Model improved!!!
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6606710359668917		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.6606710359668917 | validation: 0.6464210224400903]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_742.pth
	Model improved!!!
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7013227405563063		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.7013227405563063 | validation: 0.9026471859043779]
	TIME [epoch: 9.7 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7795551895249199		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.7795551895249199 | validation: 0.7144360800594709]
	TIME [epoch: 9.71 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622922361261171		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.6622922361261171 | validation: 0.7286568123822145]
	TIME [epoch: 9.7 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6547790499270583		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.6547790499270583 | validation: 0.6777207011440354]
	TIME [epoch: 9.7 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6763639137069514		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.6763639137069514 | validation: 0.7282719855651502]
	TIME [epoch: 9.72 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6674485332928766		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.6674485332928766 | validation: 0.7427150788464391]
	TIME [epoch: 9.69 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6669982422570948		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.6669982422570948 | validation: 0.7439094084670694]
	TIME [epoch: 9.7 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6548190222120253		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.6548190222120253 | validation: 0.7677924482712549]
	TIME [epoch: 9.71 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6570467453522983		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.6570467453522983 | validation: 0.7421572276636005]
	TIME [epoch: 9.7 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7013969349425417		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.7013969349425417 | validation: 0.68496301640222]
	TIME [epoch: 9.7 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456072191841		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.6456072191841 | validation: 0.6986923476711331]
	TIME [epoch: 9.71 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6586943504096326		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.6586943504096326 | validation: 0.7307377125464983]
	TIME [epoch: 9.7 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6431541579079321		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.6431541579079321 | validation: 0.7093116643312639]
	TIME [epoch: 9.7 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6599097503105023		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.6599097503105023 | validation: 0.6569906558245221]
	TIME [epoch: 9.72 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6469767969023504		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.6469767969023504 | validation: 0.6851093141731727]
	TIME [epoch: 9.7 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6562954600888254		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.6562954600888254 | validation: 0.695345218902384]
	TIME [epoch: 9.7 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6416868781262333		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.6416868781262333 | validation: 0.7538360610780632]
	TIME [epoch: 9.71 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6460975034433312		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.6460975034433312 | validation: 0.6795939146033092]
	TIME [epoch: 9.69 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6193976315544649		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.6193976315544649 | validation: 0.774942657763788]
	TIME [epoch: 9.69 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6462608628517914		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.6462608628517914 | validation: 0.7161802390601492]
	TIME [epoch: 9.7 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6272411240790707		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.6272411240790707 | validation: 0.7658529247841906]
	TIME [epoch: 9.71 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7649126905596056		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.7649126905596056 | validation: 0.8542936677467331]
	TIME [epoch: 9.69 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7266279843401938		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.7266279843401938 | validation: 0.6741031760043807]
	TIME [epoch: 9.7 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6575506029671832		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.6575506029671832 | validation: 0.7488965079747029]
	TIME [epoch: 9.71 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6801588995739861		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.6801588995739861 | validation: 0.7486259010333812]
	TIME [epoch: 9.7 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441350004682834		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.6441350004682834 | validation: 0.6967309791306431]
	TIME [epoch: 9.71 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7205555028776416		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.7205555028776416 | validation: 0.728843357095879]
	TIME [epoch: 9.72 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6515065595538795		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.6515065595538795 | validation: 0.7148466231507914]
	TIME [epoch: 9.69 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6288146910501695		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.6288146910501695 | validation: 0.6651314734921813]
	TIME [epoch: 9.7 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6482457863792712		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.6482457863792712 | validation: 0.6815763274762981]
	TIME [epoch: 9.72 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468443125860939		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.6468443125860939 | validation: 0.8023591428251909]
	TIME [epoch: 9.7 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7381316365749333		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.7381316365749333 | validation: 0.9215262222286508]
	TIME [epoch: 9.7 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6834447871017986		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.6834447871017986 | validation: 0.677225709320787]
	TIME [epoch: 9.72 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.612973193545683		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.612973193545683 | validation: 0.7253208085775285]
	TIME [epoch: 9.7 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6256814393852066		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.6256814393852066 | validation: 0.679987981428718]
	TIME [epoch: 9.7 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6175905584191447		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.6175905584191447 | validation: 0.6439868471955955]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_778.pth
	Model improved!!!
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6517022672236774		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.6517022672236774 | validation: 0.6596389412703251]
	TIME [epoch: 9.72 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6180891882951645		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.6180891882951645 | validation: 0.6546207382669837]
	TIME [epoch: 9.7 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5973877966904475		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.5973877966904475 | validation: 0.7809809747403386]
	TIME [epoch: 9.73 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7213982149057914		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.7213982149057914 | validation: 0.7870749744908418]
	TIME [epoch: 9.71 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6439511323035926		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.6439511323035926 | validation: 0.6719115151180333]
	TIME [epoch: 9.71 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6130535097220835		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.6130535097220835 | validation: 0.6809802325659997]
	TIME [epoch: 9.72 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422464606387593		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.6422464606387593 | validation: 0.7259691582426779]
	TIME [epoch: 9.72 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6187229982439012		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.6187229982439012 | validation: 0.6573066159165595]
	TIME [epoch: 9.71 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6472576910167721		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.6472576910167721 | validation: 0.7764943717492299]
	TIME [epoch: 9.72 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6962591902727013		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.6962591902727013 | validation: 0.6870386118232323]
	TIME [epoch: 9.71 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117795264451424		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.6117795264451424 | validation: 0.6431274928780346]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_789.pth
	Model improved!!!
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5888783339089522		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.5888783339089522 | validation: 0.6331234319923151]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_790.pth
	Model improved!!!
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6224797052604154		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.6224797052604154 | validation: 0.6453290380849489]
	TIME [epoch: 9.71 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6135517397401098		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.6135517397401098 | validation: 0.6739417907084484]
	TIME [epoch: 9.7 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6149740810199054		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.6149740810199054 | validation: 0.632212479447722]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_793.pth
	Model improved!!!
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.588346098929489		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.588346098929489 | validation: 0.6751061686865885]
	TIME [epoch: 9.71 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945296703069982		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.5945296703069982 | validation: 0.6710092819368957]
	TIME [epoch: 9.7 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6197916285943152		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.6197916285943152 | validation: 0.7087748769269092]
	TIME [epoch: 9.71 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6147731655928452		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.6147731655928452 | validation: 0.6376432577267397]
	TIME [epoch: 9.7 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6170215558826003		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.6170215558826003 | validation: 0.705399207767702]
	TIME [epoch: 9.7 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6077834890900409		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.6077834890900409 | validation: 0.6391377943450087]
	TIME [epoch: 9.69 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.607003706439252		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.607003706439252 | validation: 0.7811765947461656]
	TIME [epoch: 9.71 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556431978089945		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.6556431978089945 | validation: 0.6647478181732316]
	TIME [epoch: 9.7 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391423974666819		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.6391423974666819 | validation: 0.748688054892117]
	TIME [epoch: 9.7 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6875252767610911		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.6875252767610911 | validation: 0.6675425644161225]
	TIME [epoch: 9.72 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5890622895549844		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.5890622895549844 | validation: 0.6434965116000845]
	TIME [epoch: 9.69 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5889727760709388		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.5889727760709388 | validation: 0.6915115015002556]
	TIME [epoch: 9.7 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.586198166963207		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.586198166963207 | validation: 0.6418156835822302]
	TIME [epoch: 9.72 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5957893414326746		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.5957893414326746 | validation: 0.6733567119313898]
	TIME [epoch: 9.69 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5939554600256471		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.5939554600256471 | validation: 0.6794674203758503]
	TIME [epoch: 9.7 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5987850725644192		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.5987850725644192 | validation: 0.7040598114881484]
	TIME [epoch: 9.71 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5947482907757665		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.5947482907757665 | validation: 0.6915914353026884]
	TIME [epoch: 9.7 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6100979581679307		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.6100979581679307 | validation: 0.6952740969785787]
	TIME [epoch: 9.69 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6844115004730753		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.6844115004730753 | validation: 0.7958268530823343]
	TIME [epoch: 9.72 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6929123850369099		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.6929123850369099 | validation: 0.6631793477543806]
	TIME [epoch: 9.68 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5759866156155851		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.5759866156155851 | validation: 0.6549939960588119]
	TIME [epoch: 9.69 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.644306611284738		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.644306611284738 | validation: 0.6646475516615357]
	TIME [epoch: 9.7 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6103777746576379		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.6103777746576379 | validation: 0.6736023528872292]
	TIME [epoch: 9.69 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.587211103160038		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.587211103160038 | validation: 0.6763917966902449]
	TIME [epoch: 9.7 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.598369404084932		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.598369404084932 | validation: 0.7212919792388546]
	TIME [epoch: 9.72 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6121588832130366		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.6121588832130366 | validation: 0.6496901376915741]
	TIME [epoch: 9.69 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5842063635546071		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.5842063635546071 | validation: 0.6440603515159242]
	TIME [epoch: 9.69 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6050194948411359		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.6050194948411359 | validation: 0.6587405131779639]
	TIME [epoch: 9.71 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5674852683628625		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.5674852683628625 | validation: 0.6967431314092056]
	TIME [epoch: 9.7 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5866527356684152		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.5866527356684152 | validation: 0.6291063142061069]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_823.pth
	Model improved!!!
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5805257800345084		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.5805257800345084 | validation: 0.6949088647526942]
	TIME [epoch: 9.72 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.667522735682794		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.667522735682794 | validation: 0.9011478225226391]
	TIME [epoch: 9.7 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8405265431374629		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.8405265431374629 | validation: 0.8464228343730495]
	TIME [epoch: 9.71 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6966351786679497		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.6966351786679497 | validation: 0.7539314129343224]
	TIME [epoch: 9.71 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185879925954315		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.6185879925954315 | validation: 0.6382355074702312]
	TIME [epoch: 9.71 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948390203481244		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.5948390203481244 | validation: 0.6586388868889234]
	TIME [epoch: 9.7 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.578810499633678		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.578810499633678 | validation: 0.6197339263365427]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_830.pth
	Model improved!!!
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5755734677893595		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.5755734677893595 | validation: 0.644507951405964]
	TIME [epoch: 9.71 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.587958566832979		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.587958566832979 | validation: 0.6430477074077406]
	TIME [epoch: 9.69 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5762745105422521		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.5762745105422521 | validation: 0.6371213259166614]
	TIME [epoch: 9.7 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.622551690848165		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.622551690848165 | validation: 0.681469548776278]
	TIME [epoch: 9.7 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6381972026962474		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.6381972026962474 | validation: 0.7692116500023201]
	TIME [epoch: 9.7 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622237901130021		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.6622237901130021 | validation: 0.6257076873207998]
	TIME [epoch: 9.69 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5893003007419463		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.5893003007419463 | validation: 0.6512486078926625]
	TIME [epoch: 9.71 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5865377205314717		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.5865377205314717 | validation: 0.6403483287203814]
	TIME [epoch: 9.69 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5868343265924901		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.5868343265924901 | validation: 0.615543792178722]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_839.pth
	Model improved!!!
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5789055371630318		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.5789055371630318 | validation: 0.6293709022296539]
	TIME [epoch: 9.72 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.586694136285803		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.586694136285803 | validation: 0.6467823445599674]
	TIME [epoch: 9.7 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749139938856358		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.5749139938856358 | validation: 0.6231077631967111]
	TIME [epoch: 9.69 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5649231991257194		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.5649231991257194 | validation: 0.6348551407187814]
	TIME [epoch: 9.71 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5867864852929141		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.5867864852929141 | validation: 0.6782499271078555]
	TIME [epoch: 9.69 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.564145913870696		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.564145913870696 | validation: 0.6067116402968371]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_845.pth
	Model improved!!!
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5730936606535308		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.5730936606535308 | validation: 0.7009310301755418]
	TIME [epoch: 9.72 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5879224483855129		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.5879224483855129 | validation: 0.6173341036755621]
	TIME [epoch: 9.69 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5606945791616077		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.5606945791616077 | validation: 0.6411127921639652]
	TIME [epoch: 9.7 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5678233736415416		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.5678233736415416 | validation: 0.6068969424964875]
	TIME [epoch: 9.71 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5734216508725135		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.5734216508725135 | validation: 0.6009549034445714]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_850.pth
	Model improved!!!
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764923420788058		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.5764923420788058 | validation: 0.6295616367210418]
	TIME [epoch: 9.7 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5583580099350495		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.5583580099350495 | validation: 0.5984760903895471]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_852.pth
	Model improved!!!
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5705665500408089		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.5705665500408089 | validation: 0.6135117744230639]
	TIME [epoch: 9.7 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.562701286502382		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.562701286502382 | validation: 0.6128660944003866]
	TIME [epoch: 9.7 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.553715045514187		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.553715045514187 | validation: 0.5998108424340854]
	TIME [epoch: 9.72 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5499887554456989		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.5499887554456989 | validation: 0.6169883235963154]
	TIME [epoch: 9.7 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5502176259435958		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.5502176259435958 | validation: 0.6146650190607718]
	TIME [epoch: 9.7 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5579506727582986		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.5579506727582986 | validation: 0.6955347966047133]
	TIME [epoch: 9.72 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5756429060891557		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.5756429060891557 | validation: 0.6236742872212465]
	TIME [epoch: 9.71 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5582909212177353		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.5582909212177353 | validation: 0.6292727853182603]
	TIME [epoch: 9.69 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5714604506542909		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.5714604506542909 | validation: 0.6541471098377514]
	TIME [epoch: 9.71 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5786719510656703		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.5786719510656703 | validation: 0.6092768007754805]
	TIME [epoch: 9.71 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5689233114229799		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.5689233114229799 | validation: 0.604430249984204]
	TIME [epoch: 9.7 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5497308115203117		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.5497308115203117 | validation: 0.594838529520582]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_864.pth
	Model improved!!!
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5577185083822818		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.5577185083822818 | validation: 0.6325905756113372]
	TIME [epoch: 9.71 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5471962323068558		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.5471962323068558 | validation: 0.5928815912788901]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_866.pth
	Model improved!!!
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5573715800623263		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.5573715800623263 | validation: 0.5992381574865269]
	TIME [epoch: 9.71 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5524968256444145		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.5524968256444145 | validation: 0.613788476129005]
	TIME [epoch: 9.71 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5588511680954165		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.5588511680954165 | validation: 0.7437352652435487]
	TIME [epoch: 9.7 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6832870965459253		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.6832870965459253 | validation: 0.7433520291210057]
	TIME [epoch: 9.7 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.606532966170969		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.606532966170969 | validation: 0.6553850761755856]
	TIME [epoch: 9.72 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5916151893799976		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.5916151893799976 | validation: 0.623938649811722]
	TIME [epoch: 9.7 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5557152823305598		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.5557152823305598 | validation: 0.6544187889124125]
	TIME [epoch: 9.7 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5634094689790952		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.5634094689790952 | validation: 0.6394281356911096]
	TIME [epoch: 9.73 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5613463752249819		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.5613463752249819 | validation: 0.646334821555786]
	TIME [epoch: 9.7 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5534574108334629		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.5534574108334629 | validation: 0.6509782774029571]
	TIME [epoch: 9.7 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.585025073635155		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.585025073635155 | validation: 0.6167481533296434]
	TIME [epoch: 9.72 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5545293685246961		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.5545293685246961 | validation: 0.6017983305458074]
	TIME [epoch: 9.71 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5667618518019323		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.5667618518019323 | validation: 0.5978384435331974]
	TIME [epoch: 9.71 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5573132068123324		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.5573132068123324 | validation: 0.6641340923135141]
	TIME [epoch: 9.73 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5756010539613066		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.5756010539613066 | validation: 0.6347110460192023]
	TIME [epoch: 9.71 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5571508453232401		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.5571508453232401 | validation: 0.5918984417476485]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_882.pth
	Model improved!!!
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5593662942522715		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.5593662942522715 | validation: 0.6689944495308302]
	TIME [epoch: 9.73 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5616642760967187		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.5616642760967187 | validation: 0.6222469107041931]
	TIME [epoch: 9.7 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5476460709433517		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.5476460709433517 | validation: 0.6522168559311919]
	TIME [epoch: 9.7 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5550320334722659		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.5550320334722659 | validation: 0.5800561223178035]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_886.pth
	Model improved!!!
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5629517043729845		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.5629517043729845 | validation: 0.6109440615818034]
	TIME [epoch: 9.7 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5477004919116901		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.5477004919116901 | validation: 0.5870053985425713]
	TIME [epoch: 9.71 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5559563342118433		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.5559563342118433 | validation: 0.5893245974794283]
	TIME [epoch: 9.72 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5596049909086855		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.5596049909086855 | validation: 0.6487828276409396]
	TIME [epoch: 9.71 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5400530123115337		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.5400530123115337 | validation: 0.6398282256468152]
	TIME [epoch: 9.71 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.539268718855769		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.539268718855769 | validation: 0.6056492197025983]
	TIME [epoch: 9.72 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5633621524473377		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.5633621524473377 | validation: 0.6081524927310388]
	TIME [epoch: 9.7 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5569680584570961		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.5569680584570961 | validation: 0.6245353333476779]
	TIME [epoch: 9.7 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.565481027357128		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.565481027357128 | validation: 0.6231873995563961]
	TIME [epoch: 9.72 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5385031469183005		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.5385031469183005 | validation: 0.6029166174989697]
	TIME [epoch: 9.7 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5455523692210144		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.5455523692210144 | validation: 0.6333358160568588]
	TIME [epoch: 9.7 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.568411244928756		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.568411244928756 | validation: 0.6773638674555941]
	TIME [epoch: 9.72 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.591725683809792		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.591725683809792 | validation: 0.601096676199442]
	TIME [epoch: 9.7 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363019342747043		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.5363019342747043 | validation: 0.6097059240890296]
	TIME [epoch: 9.7 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.537054973933832		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.537054973933832 | validation: 0.6089391282987536]
	TIME [epoch: 9.71 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.549506054194659		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.549506054194659 | validation: 0.6487137355959325]
	TIME [epoch: 9.72 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6133436355770622		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.6133436355770622 | validation: 0.6822123880645207]
	TIME [epoch: 9.7 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459227407506639		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.6459227407506639 | validation: 0.6581626565947916]
	TIME [epoch: 9.71 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5920782869826814		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.5920782869826814 | validation: 0.6235425791957884]
	TIME [epoch: 9.72 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373664214727665		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.5373664214727665 | validation: 0.6265331624815478]
	TIME [epoch: 9.7 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5366878294603238		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.5366878294603238 | validation: 0.6028411713564831]
	TIME [epoch: 9.7 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5527720897498596		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.5527720897498596 | validation: 0.6421963694640656]
	TIME [epoch: 9.73 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5815550985381287		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.5815550985381287 | validation: 0.6310595504133468]
	TIME [epoch: 9.7 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5471011257067179		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.5471011257067179 | validation: 0.602866063738829]
	TIME [epoch: 9.7 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347234624259767		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.5347234624259767 | validation: 0.6480586145095276]
	TIME [epoch: 9.72 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628229906262752		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.5628229906262752 | validation: 0.6284598411299814]
	TIME [epoch: 9.7 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5623180889794048		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.5623180889794048 | validation: 0.6449372737540545]
	TIME [epoch: 9.7 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546420780946586		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.5546420780946586 | validation: 0.6088163176564452]
	TIME [epoch: 9.73 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5882135567300196		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.5882135567300196 | validation: 0.6415285435684822]
	TIME [epoch: 9.7 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094589080076992		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.6094589080076992 | validation: 0.6139917859350555]
	TIME [epoch: 9.7 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452778678664497		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.5452778678664497 | validation: 0.6303298285212354]
	TIME [epoch: 9.72 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5614424120724982		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.5614424120724982 | validation: 0.5970145689024804]
	TIME [epoch: 9.7 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5380196349368085		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.5380196349368085 | validation: 0.5831982577135219]
	TIME [epoch: 9.7 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5441273451928853		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.5441273451928853 | validation: 0.6077490996848257]
	TIME [epoch: 9.72 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5222290408475668		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.5222290408475668 | validation: 0.6338052884287789]
	TIME [epoch: 9.7 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5479457634601309		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.5479457634601309 | validation: 0.6147485888923641]
	TIME [epoch: 9.7 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344573601058475		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.5344573601058475 | validation: 0.6101312931026461]
	TIME [epoch: 9.72 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469267961065363		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.5469267961065363 | validation: 0.6240509952850701]
	TIME [epoch: 9.71 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.534845504676669		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.534845504676669 | validation: 0.6117508804774694]
	TIME [epoch: 9.7 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5478772751004714		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.5478772751004714 | validation: 0.6363531797117487]
	TIME [epoch: 9.72 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5338327618900706		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.5338327618900706 | validation: 0.610143886299067]
	TIME [epoch: 9.7 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335492832878721		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.5335492832878721 | validation: 0.6324496672776229]
	TIME [epoch: 9.7 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5585376094302189		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.5585376094302189 | validation: 0.6211867674317761]
	TIME [epoch: 9.71 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.611801187479776		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.611801187479776 | validation: 0.645421968007575]
	TIME [epoch: 9.71 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5888197136180512		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.5888197136180512 | validation: 0.625272347552637]
	TIME [epoch: 9.7 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5427477114901138		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.5427477114901138 | validation: 0.6322974255724898]
	TIME [epoch: 9.71 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5547685521369097		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.5547685521369097 | validation: 0.6416897013286141]
	TIME [epoch: 9.71 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5488678030996473		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.5488678030996473 | validation: 0.5912787391284346]
	TIME [epoch: 9.7 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5403292452301536		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.5403292452301536 | validation: 0.6045093294406201]
	TIME [epoch: 9.7 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440232865311933		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.5440232865311933 | validation: 0.6262951984390569]
	TIME [epoch: 9.72 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417945455786415		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.5417945455786415 | validation: 0.6107771308501763]
	TIME [epoch: 9.7 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201065875306535		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.5201065875306535 | validation: 0.6218898615668599]
	TIME [epoch: 9.7 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.54468074184374		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.54468074184374 | validation: 0.6131311005317788]
	TIME [epoch: 9.72 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.534455901259473		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.534455901259473 | validation: 0.6029867536787629]
	TIME [epoch: 9.7 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5379949238705526		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.5379949238705526 | validation: 0.6254849285780653]
	TIME [epoch: 9.7 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352062280874532		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.5352062280874532 | validation: 0.5758407298581483]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_942.pth
	Model improved!!!
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.52258874776914		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.52258874776914 | validation: 0.5735966658841323]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_943.pth
	Model improved!!!
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5202829994359488		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.5202829994359488 | validation: 0.6021829494967877]
	TIME [epoch: 9.7 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5434862474850434		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.5434862474850434 | validation: 0.605737646968132]
	TIME [epoch: 9.73 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5301897817299162		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.5301897817299162 | validation: 0.5909119579889837]
	TIME [epoch: 9.7 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.529470744708203		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.529470744708203 | validation: 0.5881235650178931]
	TIME [epoch: 9.7 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302489909872412		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.5302489909872412 | validation: 0.6437084937432109]
	TIME [epoch: 9.72 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5424755838088624		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.5424755838088624 | validation: 0.6854010540643245]
	TIME [epoch: 9.7 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5806423452950924		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.5806423452950924 | validation: 0.6972219401932559]
	TIME [epoch: 9.7 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5906522469573605		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.5906522469573605 | validation: 0.6785366780731773]
	TIME [epoch: 9.72 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5582205363437249		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.5582205363437249 | validation: 0.6301343121700986]
	TIME [epoch: 9.71 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5365626757349811		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.5365626757349811 | validation: 0.593246119617987]
	TIME [epoch: 9.71 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5267615599013078		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.5267615599013078 | validation: 0.6448890154949121]
	TIME [epoch: 9.72 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5209355852891545		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.5209355852891545 | validation: 0.5884599738785218]
	TIME [epoch: 9.72 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260178401672856		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.5260178401672856 | validation: 0.5640426294883834]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_956.pth
	Model improved!!!
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5229988112143193		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.5229988112143193 | validation: 0.630288241541215]
	TIME [epoch: 9.72 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274137733368909		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.5274137733368909 | validation: 0.5747885592223874]
	TIME [epoch: 9.7 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233949394881614		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.5233949394881614 | validation: 0.5788903069559591]
	TIME [epoch: 9.7 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184885422337806		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.5184885422337806 | validation: 0.5694837848374943]
	TIME [epoch: 9.71 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5141011213158572		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.5141011213158572 | validation: 0.6186133806059617]
	TIME [epoch: 9.7 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516024920768066		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.5516024920768066 | validation: 0.608091275803052]
	TIME [epoch: 9.7 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.533180102870298		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.533180102870298 | validation: 0.6193797556459942]
	TIME [epoch: 9.71 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5405097284772313		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.5405097284772313 | validation: 0.5985954714889157]
	TIME [epoch: 9.7 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.506275103491525		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.506275103491525 | validation: 0.5831076785480375]
	TIME [epoch: 9.69 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402501633329461		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.5402501633329461 | validation: 0.6342387101827146]
	TIME [epoch: 9.7 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5229927872067784		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.5229927872067784 | validation: 0.5680123356593317]
	TIME [epoch: 9.72 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5151652887546924		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.5151652887546924 | validation: 0.5839297919056086]
	TIME [epoch: 9.7 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5122404808625411		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.5122404808625411 | validation: 0.5745012338112073]
	TIME [epoch: 9.7 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.522246882239991		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.522246882239991 | validation: 0.5727771767416276]
	TIME [epoch: 9.71 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5123194328882048		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.5123194328882048 | validation: 0.5649796131074356]
	TIME [epoch: 9.69 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195159204535003		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.5195159204535003 | validation: 0.6170993438198015]
	TIME [epoch: 9.69 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251691479196188		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.5251691479196188 | validation: 0.6490678794014985]
	TIME [epoch: 9.73 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5253325617788801		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.5253325617788801 | validation: 0.57130039263097]
	TIME [epoch: 9.69 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5132041137889932		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.5132041137889932 | validation: 0.5480598486803078]
	TIME [epoch: 9.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_975.pth
	Model improved!!!
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212867012994273		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.5212867012994273 | validation: 0.6425099645249118]
	TIME [epoch: 9.72 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5359287812233573		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.5359287812233573 | validation: 0.6132585784313398]
	TIME [epoch: 9.7 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5327592987595143		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.5327592987595143 | validation: 0.6090182723073776]
	TIME [epoch: 9.69 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.513994076664736		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.513994076664736 | validation: 0.6008734443927048]
	TIME [epoch: 9.71 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5120672633789206		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.5120672633789206 | validation: 0.5879934939469107]
	TIME [epoch: 9.68 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5268700698835298		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.5268700698835298 | validation: 0.5921581789366889]
	TIME [epoch: 9.68 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5294068431138259		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.5294068431138259 | validation: 0.5656212893068175]
	TIME [epoch: 9.7 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194118153449446		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.5194118153449446 | validation: 0.6007895787376372]
	TIME [epoch: 9.69 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.551389621544526		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.551389621544526 | validation: 0.6024922339824904]
	TIME [epoch: 9.69 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5319081482149733		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.5319081482149733 | validation: 0.6025520909047848]
	TIME [epoch: 9.71 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178415412723163		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.5178415412723163 | validation: 0.5952615472231352]
	TIME [epoch: 9.68 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286303044113139		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.5286303044113139 | validation: 0.5809922356885248]
	TIME [epoch: 9.69 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5072257258610231		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.5072257258610231 | validation: 0.5477283971205531]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r5_20240218_115020/states/model_tr_study5_988.pth
	Model improved!!!
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046024466798942		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.5046024466798942 | validation: 0.5786443147187331]
	TIME [epoch: 9.69 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5312975266028745		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.5312975266028745 | validation: 0.5860826897423873]
	TIME [epoch: 9.69 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407198499363878		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.5407198499363878 | validation: 0.5847776777287008]
	TIME [epoch: 9.71 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223376350072955		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.5223376350072955 | validation: 0.5701653049536503]
	TIME [epoch: 9.68 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5093699944145884		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.5093699944145884 | validation: 0.5890186703279001]
	TIME [epoch: 9.69 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5170162964736559		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.5170162964736559 | validation: 0.5768650576364028]
	TIME [epoch: 9.7 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5076808248894433		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.5076808248894433 | validation: 0.5637600118495513]
	TIME [epoch: 9.7 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5442842335137706		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.5442842335137706 | validation: 0.5799260343774162]
	TIME [epoch: 9.68 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275006607536229		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.5275006607536229 | validation: 0.5667594354961659]
	TIME [epoch: 9.69 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5052711558618824		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.5052711558618824 | validation: 0.5853158292086467]
	TIME [epoch: 9.69 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4962927194707768		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.4962927194707768 | validation: 0.5649124616085915]
	TIME [epoch: 9.69 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5052957267898821		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.5052957267898821 | validation: 0.577455250520205]
	TIME [epoch: 9.69 sec]
Finished training in 9845.942 seconds.
