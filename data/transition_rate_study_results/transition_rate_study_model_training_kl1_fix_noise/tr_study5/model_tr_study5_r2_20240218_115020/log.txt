Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r2', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 95876381

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.986188830534497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.986188830534497 | validation: 10.651089167945939]
	TIME [epoch: 80.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.120211984467975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.120211984467975 | validation: 10.60361326442883]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.618208591501551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.618208591501551 | validation: 10.361280724463882]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.675973203814726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.675973203814726 | validation: 9.502945255528118]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.38790589786684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.38790589786684 | validation: 9.31898126505758]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 10.20188125910184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.20188125910184 | validation: 9.223903308212057]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.929329431929931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.929329431929931 | validation: 9.106457995072883]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.654860697749108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.654860697749108 | validation: 9.204020635200695]
	TIME [epoch: 9.52 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.496081783934093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.496081783934093 | validation: 9.305564325991496]
	TIME [epoch: 9.51 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.025874990298378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.025874990298378 | validation: 7.748139453575418]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.80653963475506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.80653963475506 | validation: 7.789963572169825]
	TIME [epoch: 9.55 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.6998322737087195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6998322737087195 | validation: 8.204233526930372]
	TIME [epoch: 9.53 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.496559302054653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.496559302054653 | validation: 7.2904398771029655]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.495764510267756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.495764510267756 | validation: 7.469491613729348]
	TIME [epoch: 9.55 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.2299681385484265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2299681385484265 | validation: 7.00010457300622]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.322926816683041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.322926816683041 | validation: 10.850068258989747]
	TIME [epoch: 9.5 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.139784278796075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.139784278796075 | validation: 11.633411525087068]
	TIME [epoch: 9.51 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 11.205084608943793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.205084608943793 | validation: 10.421925558452406]
	TIME [epoch: 9.53 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.300521581973777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.300521581973777 | validation: 9.828735630071249]
	TIME [epoch: 9.51 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.800211432164058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.800211432164058 | validation: 9.727902448582233]
	TIME [epoch: 9.52 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.789116080766613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.789116080766613 | validation: 9.726806543872206]
	TIME [epoch: 9.53 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.706301876109194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.706301876109194 | validation: 9.611524435088672]
	TIME [epoch: 9.52 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.642003680048493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.642003680048493 | validation: 9.396822394096956]
	TIME [epoch: 9.52 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.453657027360254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.453657027360254 | validation: 9.596379661026853]
	TIME [epoch: 9.53 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.725033261768239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.725033261768239 | validation: 9.385697539624562]
	TIME [epoch: 9.53 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.64557112835915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.64557112835915 | validation: 9.281112203817957]
	TIME [epoch: 9.51 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.706512491568253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.706512491568253 | validation: 6.543236668509528]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.182449216779723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.182449216779723 | validation: 6.529994538230755]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.005817962613746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.005817962613746 | validation: 6.709076328808278]
	TIME [epoch: 9.52 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.776718440609624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.776718440609624 | validation: 6.290836707689744]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.736075420869035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.736075420869035 | validation: 6.632894395074953]
	TIME [epoch: 9.51 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.7162129211505635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7162129211505635 | validation: 6.188717744583512]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.653243639928727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.653243639928727 | validation: 6.227824937816364]
	TIME [epoch: 9.5 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.654956203438415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.654956203438415 | validation: 6.202999146316747]
	TIME [epoch: 9.5 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.6783080617753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6783080617753 | validation: 6.159675106493071]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.863937611472787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.863937611472787 | validation: 6.142606805245848]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.1557437962058845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1557437962058845 | validation: 8.854093851055419]
	TIME [epoch: 9.5 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.363332039419161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.363332039419161 | validation: 7.006976593358221]
	TIME [epoch: 9.53 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.200418016062659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.200418016062659 | validation: 6.96583824845337]
	TIME [epoch: 9.51 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.098377463681265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.098377463681265 | validation: 7.024376121759981]
	TIME [epoch: 9.51 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.935198782897752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.935198782897752 | validation: 6.856083454355075]
	TIME [epoch: 9.51 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.795440687448936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.795440687448936 | validation: 8.108538289406056]
	TIME [epoch: 9.54 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.53632599220835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.53632599220835 | validation: 8.515634661964611]
	TIME [epoch: 9.5 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.1350798966722335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1350798966722335 | validation: 6.799121582877767]
	TIME [epoch: 9.5 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.486148331304828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.486148331304828 | validation: 6.96436186370875]
	TIME [epoch: 9.51 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.395666161134701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.395666161134701 | validation: 6.562488019777306]
	TIME [epoch: 9.5 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.410174613801262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.410174613801262 | validation: 6.464171035157101]
	TIME [epoch: 9.5 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.293530822001965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.293530822001965 | validation: 6.983021505855908]
	TIME [epoch: 9.49 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.785607428981035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.785607428981035 | validation: 6.692833351324547]
	TIME [epoch: 9.53 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.382196414996431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.382196414996431 | validation: 7.071564647531564]
	TIME [epoch: 9.5 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.679226685639135		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 6.679226685639135 | validation: 7.9961682208646385]
	TIME [epoch: 9.5 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.009765709049108		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 7.009765709049108 | validation: 6.532458006830973]
	TIME [epoch: 9.52 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.371491565771929		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.371491565771929 | validation: 6.886121159896021]
	TIME [epoch: 9.51 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.14611868125301		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 6.14611868125301 | validation: 6.501350085541083]
	TIME [epoch: 9.5 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.039069726508146		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 6.039069726508146 | validation: 6.129880154950898]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.334944388341225		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 6.334944388341225 | validation: 6.474744928382574]
	TIME [epoch: 9.51 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.493058232430167		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 6.493058232430167 | validation: 8.93526952009002]
	TIME [epoch: 9.5 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.278892075573907		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 9.278892075573907 | validation: 8.443769661416614]
	TIME [epoch: 9.5 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.123558721401869		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 9.123558721401869 | validation: 8.2574286972838]
	TIME [epoch: 9.52 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.108262400756427		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 9.108262400756427 | validation: 8.583401485012686]
	TIME [epoch: 9.5 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.000580247677084		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 9.000580247677084 | validation: 8.11949525896747]
	TIME [epoch: 9.5 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.853313768470162		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 8.853313768470162 | validation: 7.6039864258770296]
	TIME [epoch: 9.51 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.357020152706081		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 8.357020152706081 | validation: 8.020408480345916]
	TIME [epoch: 9.55 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.545309539943178		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 7.545309539943178 | validation: 5.260394261613776]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.507368576351782		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 6.507368576351782 | validation: 6.2317759188869335]
	TIME [epoch: 9.51 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.05719164755719		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 6.05719164755719 | validation: 4.916880061155537]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.30995156401912		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 7.30995156401912 | validation: 5.834418655570665]
	TIME [epoch: 9.52 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.303399271297432		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 6.303399271297432 | validation: 5.696377085441643]
	TIME [epoch: 9.52 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.052283309845083		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.052283309845083 | validation: 5.381573538114698]
	TIME [epoch: 9.53 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.394076214932331		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 6.394076214932331 | validation: 4.950609575410992]
	TIME [epoch: 9.54 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.25960104039603		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 6.25960104039603 | validation: 4.4680571759848045]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.747838578712783		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 5.747838578712783 | validation: 4.877431579862668]
	TIME [epoch: 9.51 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.616690595585226		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.616690595585226 | validation: 4.619980651277785]
	TIME [epoch: 9.54 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.573861467301509		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 5.573861467301509 | validation: 4.223773944768516]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.893445744884053		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 5.893445744884053 | validation: 4.3082345297463265]
	TIME [epoch: 9.51 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.342200159970595		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 5.342200159970595 | validation: 4.18785926572319]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.861241445233419		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 5.861241445233419 | validation: 5.20835800124539]
	TIME [epoch: 9.52 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.396690430477764		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 7.396690430477764 | validation: 4.473174599925967]
	TIME [epoch: 9.5 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.262568803269906		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 5.262568803269906 | validation: 4.046760869571354]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.225286890879518		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 5.225286890879518 | validation: 4.135397694463363]
	TIME [epoch: 9.54 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.300222437701155		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 5.300222437701155 | validation: 4.048488008045931]
	TIME [epoch: 9.52 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.791639806032821		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 7.791639806032821 | validation: 5.578800052102438]
	TIME [epoch: 9.51 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.834462623356662		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 5.834462623356662 | validation: 4.297234973878856]
	TIME [epoch: 9.52 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.457861980097658		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 5.457861980097658 | validation: 4.004703458889315]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.150489537424242		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 5.150489537424242 | validation: 4.081795264475113]
	TIME [epoch: 9.5 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.017368300489752		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 6.017368300489752 | validation: 4.693362613672576]
	TIME [epoch: 9.49 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.387065175921128		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 5.387065175921128 | validation: 4.049829763421598]
	TIME [epoch: 9.52 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.116823767846006		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 5.116823767846006 | validation: 4.7480834900571205]
	TIME [epoch: 9.49 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.185043873729012		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 5.185043873729012 | validation: 4.0928363328926665]
	TIME [epoch: 9.5 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.59419665061632		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 5.59419665061632 | validation: 6.146271137161321]
	TIME [epoch: 9.51 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.050826717512753		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 6.050826717512753 | validation: 5.400127138977723]
	TIME [epoch: 9.51 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9317438444381265		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 5.9317438444381265 | validation: 4.789590364180088]
	TIME [epoch: 9.49 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.562366256310179		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 5.562366256310179 | validation: 4.101773076906112]
	TIME [epoch: 9.49 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.678984452324867		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 5.678984452324867 | validation: 5.0138976343566]
	TIME [epoch: 9.51 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.014060179304414		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 6.014060179304414 | validation: 3.9904284740737173]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.763014061683719		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 5.763014061683719 | validation: 4.331188784242575]
	TIME [epoch: 9.5 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.252171005794575		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 5.252171005794575 | validation: 3.822124249366592]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.8895915713028515		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 4.8895915713028515 | validation: 3.679935422238583]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.130451917487228		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 5.130451917487228 | validation: 5.80803842599445]
	TIME [epoch: 9.5 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.341162540935905		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 5.341162540935905 | validation: 4.293769121832172]
	TIME [epoch: 9.49 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.281815692550468		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 5.281815692550468 | validation: 4.088940337274059]
	TIME [epoch: 9.52 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.374854991259996		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 5.374854991259996 | validation: 5.175440844907094]
	TIME [epoch: 9.49 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.364300032623447		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 5.364300032623447 | validation: 8.326904902416379]
	TIME [epoch: 9.5 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4968913391519605		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 6.4968913391519605 | validation: 4.0218995956762935]
	TIME [epoch: 9.51 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.059937033417346		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 5.059937033417346 | validation: 3.7579730951260424]
	TIME [epoch: 9.5 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.769891671195193		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 4.769891671195193 | validation: 4.83970394326306]
	TIME [epoch: 9.5 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.919249112729102		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 4.919249112729102 | validation: 3.8998962549705665]
	TIME [epoch: 9.51 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.920224253354957		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 4.920224253354957 | validation: 3.6749801919879235]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.0080711745392446		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 5.0080711745392446 | validation: 4.699498187644285]
	TIME [epoch: 9.51 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.03007874877009		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 5.03007874877009 | validation: 3.890539325476014]
	TIME [epoch: 9.51 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.682210643708254		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 4.682210643708254 | validation: 3.937639085302069]
	TIME [epoch: 9.52 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.58184992391441		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 4.58184992391441 | validation: 3.929045206076013]
	TIME [epoch: 9.5 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.509956065136153		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 4.509956065136153 | validation: 4.1270150219562804]
	TIME [epoch: 9.5 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.507323190535013		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 5.507323190535013 | validation: 4.717483024159895]
	TIME [epoch: 9.5 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.662899065593249		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 4.662899065593249 | validation: 3.724748386172596]
	TIME [epoch: 9.52 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.378724308658926		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 4.378724308658926 | validation: 3.3701758385920324]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_116.pth
	Model improved!!!
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.087562600047564		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 4.087562600047564 | validation: 4.13480952951243]
	TIME [epoch: 9.5 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6805875325082233		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 3.6805875325082233 | validation: 2.6571466073446355]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_118.pth
	Model improved!!!
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7135456543721146		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 2.7135456543721146 | validation: 1.9334488451042828]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_119.pth
	Model improved!!!
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5422373547316126		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 2.5422373547316126 | validation: 1.9892186647091563]
	TIME [epoch: 9.5 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.360264700763977		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 2.360264700763977 | validation: 6.894262193279291]
	TIME [epoch: 9.51 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.118158913056995		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 6.118158913056995 | validation: 3.09764394209442]
	TIME [epoch: 9.51 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.638427105648003		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 2.638427105648003 | validation: 1.9409016563224313]
	TIME [epoch: 9.5 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2444534110759577		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 2.2444534110759577 | validation: 2.85284519890672]
	TIME [epoch: 9.49 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2164410579219154		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 2.2164410579219154 | validation: 1.7682951489838892]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_125.pth
	Model improved!!!
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.098793244038494		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 2.098793244038494 | validation: 2.296506885605227]
	TIME [epoch: 9.5 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3137837171484263		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 2.3137837171484263 | validation: 1.9640941348802061]
	TIME [epoch: 9.5 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.30520630079777		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 2.30520630079777 | validation: 1.981682549228704]
	TIME [epoch: 9.51 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3526824184665545		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 2.3526824184665545 | validation: 2.102868725399836]
	TIME [epoch: 9.5 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5293522708703833		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.5293522708703833 | validation: 2.3086124808118846]
	TIME [epoch: 9.5 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5892538734576296		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 2.5892538734576296 | validation: 4.016755491678165]
	TIME [epoch: 9.49 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.732866223517381		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 2.732866223517381 | validation: 1.8585123266674146]
	TIME [epoch: 9.52 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2264882916652815		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 2.2264882916652815 | validation: 3.0680371585256343]
	TIME [epoch: 9.48 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.336548541389616		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 2.336548541389616 | validation: 1.7968777953261201]
	TIME [epoch: 9.49 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.905139048291974		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 2.905139048291974 | validation: 2.593105014191341]
	TIME [epoch: 9.51 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.361643423071102		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 2.361643423071102 | validation: 2.030923307704196]
	TIME [epoch: 9.5 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9830846146317533		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 1.9830846146317533 | validation: 1.8637013672017884]
	TIME [epoch: 9.5 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9635921456937755		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 1.9635921456937755 | validation: 1.7997374046775028]
	TIME [epoch: 9.49 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5230375036617665		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 2.5230375036617665 | validation: 2.2218613281824116]
	TIME [epoch: 9.52 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9416140835125373		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 1.9416140835125373 | validation: 2.110040646836118]
	TIME [epoch: 9.49 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.271374284138679		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 2.271374284138679 | validation: 1.8653886666510646]
	TIME [epoch: 9.5 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1730933355095905		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 2.1730933355095905 | validation: 2.147397528501364]
	TIME [epoch: 9.52 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2031583516820747		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 2.2031583516820747 | validation: 1.8135657777253296]
	TIME [epoch: 9.5 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3030525739527445		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 2.3030525739527445 | validation: 2.7326618828640394]
	TIME [epoch: 9.5 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4873090481748337		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 2.4873090481748337 | validation: 2.012417967232512]
	TIME [epoch: 9.5 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.089545340668439		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 2.089545340668439 | validation: 1.6463915929305355]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_146.pth
	Model improved!!!
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1751605468364703		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 2.1751605468364703 | validation: 1.881215235898936]
	TIME [epoch: 9.5 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2140658146963945		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 2.2140658146963945 | validation: 2.2608972086509818]
	TIME [epoch: 9.49 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2532913890216775		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.2532913890216775 | validation: 2.3118177461844316]
	TIME [epoch: 9.52 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0612024685300936		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 2.0612024685300936 | validation: 1.999483156482752]
	TIME [epoch: 9.5 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8801211420877064		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 1.8801211420877064 | validation: 1.8673715352966167]
	TIME [epoch: 9.49 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1367668070237915		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 2.1367668070237915 | validation: 2.1820433741332823]
	TIME [epoch: 9.49 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0824401233808145		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 2.0824401233808145 | validation: 1.7835784005292517]
	TIME [epoch: 9.52 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.006408737034577		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 2.006408737034577 | validation: 1.955579633745419]
	TIME [epoch: 9.49 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9070679444279803		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 1.9070679444279803 | validation: 1.92982469703064]
	TIME [epoch: 9.49 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.004197233011195		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 2.004197233011195 | validation: 2.4419705297933887]
	TIME [epoch: 9.51 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.139574285210455		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 2.139574285210455 | validation: 1.7956632377199058]
	TIME [epoch: 9.5 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8860761076643864		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 1.8860761076643864 | validation: 1.7935492134279936]
	TIME [epoch: 9.49 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0339766863217412		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 2.0339766863217412 | validation: 1.9126583368069938]
	TIME [epoch: 9.48 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.859805079912218		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 1.859805079912218 | validation: 1.6835919730471767]
	TIME [epoch: 9.52 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8767529880576759		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 1.8767529880576759 | validation: 1.7991913133618271]
	TIME [epoch: 9.49 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.061611791581505		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 2.061611791581505 | validation: 2.391342277261878]
	TIME [epoch: 9.49 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.029919118201269		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 2.029919118201269 | validation: 2.067454675552792]
	TIME [epoch: 9.52 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0329804120152524		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 2.0329804120152524 | validation: 1.9840471997248403]
	TIME [epoch: 9.5 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8857039562899338		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 1.8857039562899338 | validation: 2.077276071766466]
	TIME [epoch: 9.5 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8370858543759432		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 1.8370858543759432 | validation: 1.6327457865108852]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_166.pth
	Model improved!!!
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.764892313954973		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 1.764892313954973 | validation: 1.557476930310884]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_167.pth
	Model improved!!!
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.972465033261512		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.972465033261512 | validation: 1.6540986078906397]
	TIME [epoch: 9.5 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.020776272844366		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 2.020776272844366 | validation: 2.862882684199084]
	TIME [epoch: 9.5 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3886043393710428		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 2.3886043393710428 | validation: 1.662199333093482]
	TIME [epoch: 9.52 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.643652301870872		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 1.643652301870872 | validation: 1.6048989166244025]
	TIME [epoch: 9.5 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9913615365407957		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 1.9913615365407957 | validation: 1.7822940878757692]
	TIME [epoch: 9.51 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7424293743026849		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 1.7424293743026849 | validation: 1.8151647049744195]
	TIME [epoch: 9.51 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8937753034666556		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 1.8937753034666556 | validation: 1.5904745175085473]
	TIME [epoch: 9.52 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6027324251596131		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 1.6027324251596131 | validation: 1.6510958057064204]
	TIME [epoch: 9.5 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7016432513923085		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 1.7016432513923085 | validation: 1.4887609120971923]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_176.pth
	Model improved!!!
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.633317415552252		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 1.633317415552252 | validation: 1.4625050276529559]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6970325858224444		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 1.6970325858224444 | validation: 1.7927545016336826]
	TIME [epoch: 9.5 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.651985921182489		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 1.651985921182489 | validation: 1.7455269861203515]
	TIME [epoch: 9.49 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7058232560018385		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 1.7058232560018385 | validation: 2.022260608017508]
	TIME [epoch: 9.49 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7054831813852624		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 2.7054831813852624 | validation: 1.809480912215192]
	TIME [epoch: 9.51 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.744848825988857		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 1.744848825988857 | validation: 1.8050518730887806]
	TIME [epoch: 9.48 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8069405577479931		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 1.8069405577479931 | validation: 1.620253367885244]
	TIME [epoch: 9.48 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.729784569916914		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 1.729784569916914 | validation: 1.652261335365658]
	TIME [epoch: 9.51 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8149287472988604		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 1.8149287472988604 | validation: 1.6398540499493208]
	TIME [epoch: 9.47 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6982387674904573		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 1.6982387674904573 | validation: 1.7419183200269928]
	TIME [epoch: 9.49 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6899063732250617		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 1.6899063732250617 | validation: 1.8276130225664815]
	TIME [epoch: 9.49 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8440122966942023		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 1.8440122966942023 | validation: 2.426666511355379]
	TIME [epoch: 9.51 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7504162678139121		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 1.7504162678139121 | validation: 1.4030389537014174]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5379534082362931		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 1.5379534082362931 | validation: 1.7446061008976883]
	TIME [epoch: 9.5 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7239005723162433		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 1.7239005723162433 | validation: 1.5852761184329416]
	TIME [epoch: 9.51 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5770400646179206		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 1.5770400646179206 | validation: 1.398766833580657]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_192.pth
	Model improved!!!
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1224270730772368		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 2.1224270730772368 | validation: 1.5192078870239254]
	TIME [epoch: 9.52 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6674327171199905		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 1.6674327171199905 | validation: 1.9404147747303537]
	TIME [epoch: 9.55 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9116264965743142		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 1.9116264965743142 | validation: 2.8212203944162413]
	TIME [epoch: 9.52 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.844016536953672		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 1.844016536953672 | validation: 1.6872614393087673]
	TIME [epoch: 9.52 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.745358742466577		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 1.745358742466577 | validation: 1.364982792428385]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.692115631974738		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 1.692115631974738 | validation: 1.919717067498246]
	TIME [epoch: 9.54 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8627326299006526		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 1.8627326299006526 | validation: 1.861183269110308]
	TIME [epoch: 9.52 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7761173082850714		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 1.7761173082850714 | validation: 1.6937957697326698]
	TIME [epoch: 9.52 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7009049183375429		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 1.7009049183375429 | validation: 1.4986897709507618]
	TIME [epoch: 9.54 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.545785287586946		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 1.545785287586946 | validation: 1.5923632818965328]
	TIME [epoch: 9.52 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0555923468697554		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 2.0555923468697554 | validation: 2.9516683335556024]
	TIME [epoch: 9.52 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4355829034972905		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 2.4355829034972905 | validation: 2.212772444836881]
	TIME [epoch: 9.52 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9682949766929405		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 1.9682949766929405 | validation: 1.3913235148589957]
	TIME [epoch: 9.55 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4556820245970818		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.4556820245970818 | validation: 1.559469332655126]
	TIME [epoch: 9.52 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5294085924719196		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 1.5294085924719196 | validation: 1.9833476462564528]
	TIME [epoch: 9.52 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9150565738487664		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 1.9150565738487664 | validation: 1.7517728497872498]
	TIME [epoch: 9.54 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6991857544221216		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 1.6991857544221216 | validation: 1.5118897278933248]
	TIME [epoch: 9.52 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6980164948766003		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 1.6980164948766003 | validation: 1.6005139666675445]
	TIME [epoch: 9.51 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5316735436053208		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 1.5316735436053208 | validation: 1.3583829039539526]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.539892160428287		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 1.539892160428287 | validation: 1.4668373897350706]
	TIME [epoch: 9.54 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4819076695186282		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 1.4819076695186282 | validation: 1.543093812843331]
	TIME [epoch: 9.52 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5932204232988374		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 1.5932204232988374 | validation: 2.0076311515903478]
	TIME [epoch: 9.52 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6390117452284065		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 1.6390117452284065 | validation: 1.6126114762205093]
	TIME [epoch: 9.54 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0032956847189163		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 2.0032956847189163 | validation: 1.5709195431131884]
	TIME [epoch: 9.52 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5391455542692647		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 1.5391455542692647 | validation: 1.3804414410036407]
	TIME [epoch: 9.52 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6172745501540302		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 1.6172745501540302 | validation: 1.4499980593898738]
	TIME [epoch: 9.52 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5898714791761352		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 1.5898714791761352 | validation: 1.405177944399652]
	TIME [epoch: 9.54 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.580054510311796		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 1.580054510311796 | validation: 1.7534527744080357]
	TIME [epoch: 9.52 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.574879616012776		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 1.574879616012776 | validation: 1.2749536939445043]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_221.pth
	Model improved!!!
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5540253423195005		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 1.5540253423195005 | validation: 1.4751960840931129]
	TIME [epoch: 9.54 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3742198317793881		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 1.3742198317793881 | validation: 1.5509287131080203]
	TIME [epoch: 9.52 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4816056322475233		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 1.4816056322475233 | validation: 1.4507084479216672]
	TIME [epoch: 9.52 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3086905006696608		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 1.3086905006696608 | validation: 1.4357145977340329]
	TIME [epoch: 9.53 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5076937871205467		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 1.5076937871205467 | validation: 1.612908031975471]
	TIME [epoch: 9.55 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5763135388673348		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 1.5763135388673348 | validation: 1.2594733742419462]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_227.pth
	Model improved!!!
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2287083166118853		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 1.2287083166118853 | validation: 1.2466656931788629]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_228.pth
	Model improved!!!
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7016931248583482		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 1.7016931248583482 | validation: 1.4777212054674977]
	TIME [epoch: 9.54 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4039715348213602		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.4039715348213602 | validation: 1.3878546062295083]
	TIME [epoch: 9.52 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4530726185539653		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 1.4530726185539653 | validation: 1.2337761605264177]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_231.pth
	Model improved!!!
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3201212814303658		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 1.3201212814303658 | validation: 1.3605707868278345]
	TIME [epoch: 9.52 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3663815859198165		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 1.3663815859198165 | validation: 1.1832266624021983]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_233.pth
	Model improved!!!
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4966677549603333		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 1.4966677549603333 | validation: 1.2211726127345939]
	TIME [epoch: 9.52 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.359511508671416		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.359511508671416 | validation: 1.9391502802136396]
	TIME [epoch: 9.5 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6139448955189266		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 1.6139448955189266 | validation: 1.6146015933802833]
	TIME [epoch: 9.53 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6479770119910906		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 1.6479770119910906 | validation: 1.6144805039366619]
	TIME [epoch: 9.5 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5165701370192868		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 1.5165701370192868 | validation: 2.8904820904562922]
	TIME [epoch: 9.5 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.962319783476607		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 1.962319783476607 | validation: 1.39733620337252]
	TIME [epoch: 9.53 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4815039417267837		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 1.4815039417267837 | validation: 1.4944734980910221]
	TIME [epoch: 9.51 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4165319289986749		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 1.4165319289986749 | validation: 1.5604703364675703]
	TIME [epoch: 9.51 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2963215684149283		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 1.2963215684149283 | validation: 1.4547236382056747]
	TIME [epoch: 9.51 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2764614635652096		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 1.2764614635652096 | validation: 1.169176923267297]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_243.pth
	Model improved!!!
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3380435838992464		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.3380435838992464 | validation: 1.7473140006246666]
	TIME [epoch: 9.51 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.358685897100494		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 1.358685897100494 | validation: 1.399822736086323]
	TIME [epoch: 9.5 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3184528368006803		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 1.3184528368006803 | validation: 1.1723516091293467]
	TIME [epoch: 9.52 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.194085724768045		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 1.194085724768045 | validation: 1.343445360524417]
	TIME [epoch: 9.5 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4484113491178694		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 1.4484113491178694 | validation: 1.7548176568347083]
	TIME [epoch: 9.5 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5205300357249596		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 1.5205300357249596 | validation: 1.1475082182447307]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_249.pth
	Model improved!!!
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2599946961422273		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 1.2599946961422273 | validation: 1.177910398242167]
	TIME [epoch: 9.53 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2484794998547155		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 1.2484794998547155 | validation: 1.2621581308032919]
	TIME [epoch: 9.5 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.386352032529771		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.386352032529771 | validation: 1.9162397941615599]
	TIME [epoch: 9.5 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.406061965418073		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 1.406061965418073 | validation: 1.2308070402645779]
	TIME [epoch: 9.52 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.187635917481845		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 1.187635917481845 | validation: 2.071482502966692]
	TIME [epoch: 9.51 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6595873223244737		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 1.6595873223244737 | validation: 1.393161300309725]
	TIME [epoch: 9.5 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4174158807071096		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 1.4174158807071096 | validation: 1.1037224913455195]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_256.pth
	Model improved!!!
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2785194783228762		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 1.2785194783228762 | validation: 1.6697174361075104]
	TIME [epoch: 9.51 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.495619367957598		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 1.495619367957598 | validation: 1.246689219855117]
	TIME [epoch: 9.5 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3356055433572582		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 1.3356055433572582 | validation: 1.5880186484215517]
	TIME [epoch: 9.5 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3302470004738833		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 1.3302470004738833 | validation: 1.619881977305263]
	TIME [epoch: 9.53 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2935972759752568		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 1.2935972759752568 | validation: 1.6664693121609317]
	TIME [epoch: 9.5 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5022425389479703		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 1.5022425389479703 | validation: 1.1647152224544806]
	TIME [epoch: 9.5 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1323901092243982		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.1323901092243982 | validation: 1.2696315339816053]
	TIME [epoch: 9.51 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.156202035259823		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 1.156202035259823 | validation: 1.3688549714549247]
	TIME [epoch: 9.52 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.229163697387134		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 1.229163697387134 | validation: 1.1655624032294511]
	TIME [epoch: 9.5 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2966163835361673		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 1.2966163835361673 | validation: 1.2301140939627033]
	TIME [epoch: 9.5 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3697928915197575		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 1.3697928915197575 | validation: 1.3465408801469745]
	TIME [epoch: 9.53 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1892344692412031		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 1.1892344692412031 | validation: 1.1678729614553496]
	TIME [epoch: 9.5 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1678609981978478		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.1678609981978478 | validation: 1.1569714025733673]
	TIME [epoch: 9.5 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.21072706926831		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 1.21072706926831 | validation: 1.1411722372922728]
	TIME [epoch: 9.5 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1095815233230106		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.1095815233230106 | validation: 1.1722956898115]
	TIME [epoch: 9.52 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.095787284129614		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 1.095787284129614 | validation: 1.190098278990284]
	TIME [epoch: 9.5 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2658713755749724		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 1.2658713755749724 | validation: 1.2708004413422094]
	TIME [epoch: 9.5 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3835396347190918		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 1.3835396347190918 | validation: 1.4338255253222048]
	TIME [epoch: 9.52 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1590493656998693		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.1590493656998693 | validation: 1.1303971538675948]
	TIME [epoch: 9.5 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3358700373148797		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 1.3358700373148797 | validation: 1.3705684949555024]
	TIME [epoch: 9.5 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.138348065935731		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 1.138348065935731 | validation: 1.2719486280648689]
	TIME [epoch: 9.51 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1378765116848253		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 1.1378765116848253 | validation: 1.2325153864392595]
	TIME [epoch: 9.51 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1927895578435703		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 1.1927895578435703 | validation: 1.1591657750480249]
	TIME [epoch: 9.51 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.209974879520413		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 1.209974879520413 | validation: 1.1214155946981723]
	TIME [epoch: 9.51 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2813739413726275		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 1.2813739413726275 | validation: 1.0309378771304372]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_281.pth
	Model improved!!!
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1127183770939844		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 1.1127183770939844 | validation: 1.6380477606525141]
	TIME [epoch: 9.51 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3131368630780182		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 1.3131368630780182 | validation: 1.1428948224693558]
	TIME [epoch: 9.49 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1108594616214011		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 1.1108594616214011 | validation: 1.220522396774398]
	TIME [epoch: 9.52 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1835561609770853		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 1.1835561609770853 | validation: 1.11280843630028]
	TIME [epoch: 9.51 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0399731123290088		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 1.0399731123290088 | validation: 1.1428417674904836]
	TIME [epoch: 9.5 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0985894925621826		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 1.0985894925621826 | validation: 1.2751564239914563]
	TIME [epoch: 9.5 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1172717768361227		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 1.1172717768361227 | validation: 1.1645188258521062]
	TIME [epoch: 9.52 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.130084778586016		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 1.130084778586016 | validation: 1.3792609820804003]
	TIME [epoch: 9.51 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.396664725028478		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 1.396664725028478 | validation: 1.147092916233912]
	TIME [epoch: 9.5 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1562172361788332		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 1.1562172361788332 | validation: 1.490184759426906]
	TIME [epoch: 9.52 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2434450400877313		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 1.2434450400877313 | validation: 1.1225971921664721]
	TIME [epoch: 9.51 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0544862549065814		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 1.0544862549065814 | validation: 1.2571053574395292]
	TIME [epoch: 9.5 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0972025016577232		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 1.0972025016577232 | validation: 1.2921100399015817]
	TIME [epoch: 9.5 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1200609585683914		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 1.1200609585683914 | validation: 1.5879258535429386]
	TIME [epoch: 9.52 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0925740060101297		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 1.0925740060101297 | validation: 1.1019488941100835]
	TIME [epoch: 9.51 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1587317229367273		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 1.1587317229367273 | validation: 1.1814799413140007]
	TIME [epoch: 9.5 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1904877819348338		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 1.1904877819348338 | validation: 1.5655441234805263]
	TIME [epoch: 9.52 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4202897429913208		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 1.4202897429913208 | validation: 2.039987519418358]
	TIME [epoch: 9.5 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4122514003964244		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 1.4122514003964244 | validation: 1.2136496492993376]
	TIME [epoch: 9.5 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.069387177531078		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 1.069387177531078 | validation: 1.2377576855258476]
	TIME [epoch: 9.51 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.043587768333497		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 1.043587768333497 | validation: 1.1001545648438973]
	TIME [epoch: 9.53 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1658598467416184		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 1.1658598467416184 | validation: 1.132938424089084]
	TIME [epoch: 9.5 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.988888928455388		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 0.988888928455388 | validation: 1.4033615190599675]
	TIME [epoch: 9.51 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2151614518570892		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 1.2151614518570892 | validation: 0.9385375878409243]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1388065626503998		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.1388065626503998 | validation: 1.1751292839235716]
	TIME [epoch: 9.51 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.170900799991628		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 1.170900799991628 | validation: 1.0240773071144926]
	TIME [epoch: 9.49 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0373830256504624		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 1.0373830256504624 | validation: 1.1432292766991277]
	TIME [epoch: 9.5 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0266053678660674		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 1.0266053678660674 | validation: 1.186631302539922]
	TIME [epoch: 9.51 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2835827274004425		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 1.2835827274004425 | validation: 1.1568469539829882]
	TIME [epoch: 9.51 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1042098381521295		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 1.1042098381521295 | validation: 1.1057250256871698]
	TIME [epoch: 9.5 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9810164852121981		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.9810164852121981 | validation: 1.118942671092542]
	TIME [epoch: 9.52 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2015478878374062		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 1.2015478878374062 | validation: 1.423040153806519]
	TIME [epoch: 9.5 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1999889941901198		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 1.1999889941901198 | validation: 1.026247238793265]
	TIME [epoch: 9.5 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1102188930140051		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 1.1102188930140051 | validation: 1.055742619363782]
	TIME [epoch: 9.5 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.238842090940852		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 1.238842090940852 | validation: 1.1048186505177762]
	TIME [epoch: 9.52 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9372908350804648		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.9372908350804648 | validation: 1.0311412060389118]
	TIME [epoch: 9.5 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0554050594866524		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 1.0554050594866524 | validation: 1.1579888346417364]
	TIME [epoch: 9.49 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9909838211056246		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.9909838211056246 | validation: 1.155391638023259]
	TIME [epoch: 9.51 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9859613068678981		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.9859613068678981 | validation: 2.2618666001308894]
	TIME [epoch: 9.51 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8247423306907244		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 1.8247423306907244 | validation: 1.4581550991392072]
	TIME [epoch: 9.5 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0837579701073494		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 1.0837579701073494 | validation: 1.0254738518632645]
	TIME [epoch: 9.5 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9292277373546254		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.9292277373546254 | validation: 1.3236237441254042]
	TIME [epoch: 9.52 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3050904002597927		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 1.3050904002597927 | validation: 1.1614238482551882]
	TIME [epoch: 9.5 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9875100207284803		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.9875100207284803 | validation: 0.8821982264671033]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_325.pth
	Model improved!!!
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.140270236904867		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 1.140270236904867 | validation: 1.1484826252879365]
	TIME [epoch: 9.52 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.060732839239829		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 1.060732839239829 | validation: 1.0010435956801889]
	TIME [epoch: 9.5 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9775126865047614		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.9775126865047614 | validation: 1.0582522916277637]
	TIME [epoch: 9.51 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9986079439849405		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 0.9986079439849405 | validation: 0.9999692099763717]
	TIME [epoch: 9.51 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9110219206663712		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 0.9110219206663712 | validation: 0.9396752904054094]
	TIME [epoch: 9.52 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8694196412359236		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.8694196412359236 | validation: 1.0287997079712443]
	TIME [epoch: 9.5 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1265257133674873		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 1.1265257133674873 | validation: 1.2075129231123212]
	TIME [epoch: 9.51 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1250187858736158		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 1.1250187858736158 | validation: 1.1360435651703684]
	TIME [epoch: 9.52 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.948830904219769		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.948830904219769 | validation: 1.306394247312159]
	TIME [epoch: 9.51 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.895899054676697		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 0.895899054676697 | validation: 0.9400980796306823]
	TIME [epoch: 9.5 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.942409602499262		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.942409602499262 | validation: 0.8549743989088581]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_336.pth
	Model improved!!!
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9682583752016777		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.9682583752016777 | validation: 0.9548424217157515]
	TIME [epoch: 9.52 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8909162167481126		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.8909162167481126 | validation: 1.064883552493779]
	TIME [epoch: 9.5 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9071206570767444		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.9071206570767444 | validation: 0.8255270462355375]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_339.pth
	Model improved!!!
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8080375146289013		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.8080375146289013 | validation: 0.9162897489558373]
	TIME [epoch: 9.52 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9213163753607659		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.9213163753607659 | validation: 0.8650327806857261]
	TIME [epoch: 9.5 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8521241519519307		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.8521241519519307 | validation: 0.9106217318552962]
	TIME [epoch: 9.49 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8697295081908314		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.8697295081908314 | validation: 0.9926936647252339]
	TIME [epoch: 9.51 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9108194328046533		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.9108194328046533 | validation: 0.8489703299842579]
	TIME [epoch: 9.52 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9079579002255634		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.9079579002255634 | validation: 1.0413947061250455]
	TIME [epoch: 9.5 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0049012350980273		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 1.0049012350980273 | validation: 0.9512804095950014]
	TIME [epoch: 9.5 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9087393639123411		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.9087393639123411 | validation: 0.9830623473898681]
	TIME [epoch: 9.52 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2044529667604924		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 1.2044529667604924 | validation: 1.1577326305815983]
	TIME [epoch: 9.5 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1806335981963094		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 1.1806335981963094 | validation: 0.8352765668621087]
	TIME [epoch: 9.5 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.866707561354621		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.866707561354621 | validation: 0.8762850170619981]
	TIME [epoch: 9.51 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9039039834113796		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.9039039834113796 | validation: 0.868805565938092]
	TIME [epoch: 9.51 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.859795920433282		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.859795920433282 | validation: 0.9743227182544288]
	TIME [epoch: 9.5 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7963257669419946		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 0.7963257669419946 | validation: 0.7875489030145261]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_353.pth
	Model improved!!!
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8186036657949769		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.8186036657949769 | validation: 0.7698802935216247]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_354.pth
	Model improved!!!
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9377287250003578		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.9377287250003578 | validation: 1.1019381660563492]
	TIME [epoch: 9.51 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1171905475882458		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 1.1171905475882458 | validation: 1.0121823094155522]
	TIME [epoch: 9.51 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9662441605929372		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 0.9662441605929372 | validation: 1.5133651370418018]
	TIME [epoch: 9.52 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0895972487870003		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 1.0895972487870003 | validation: 0.8795830385792022]
	TIME [epoch: 9.52 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0219894928567472		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 1.0219894928567472 | validation: 1.2725369404455698]
	TIME [epoch: 9.49 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0770556597348064		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 1.0770556597348064 | validation: 0.843362562512472]
	TIME [epoch: 9.5 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8610230151547071		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.8610230151547071 | validation: 0.7886860224304775]
	TIME [epoch: 9.52 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7849868213513209		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.7849868213513209 | validation: 0.8198802274768693]
	TIME [epoch: 9.5 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7868982880633328		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.7868982880633328 | validation: 0.7651073763242714]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_363.pth
	Model improved!!!
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7941916254199827		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.7941916254199827 | validation: 1.0305507290438631]
	TIME [epoch: 9.54 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8509377263579332		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.8509377263579332 | validation: 0.8307757904212585]
	TIME [epoch: 9.52 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4495244946406736		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 1.4495244946406736 | validation: 2.388946849311503]
	TIME [epoch: 9.5 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3455171065323452		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 1.3455171065323452 | validation: 1.1311617068903923]
	TIME [epoch: 9.5 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1207461391395737		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 1.1207461391395737 | validation: 0.9675165233922445]
	TIME [epoch: 9.54 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9497156098977279		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.9497156098977279 | validation: 0.9826662898253077]
	TIME [epoch: 9.51 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8603039004075506		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.8603039004075506 | validation: 0.9489093679061972]
	TIME [epoch: 9.5 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.842699272804599		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.842699272804599 | validation: 1.219717102792729]
	TIME [epoch: 9.52 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2409467973323838		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 1.2409467973323838 | validation: 1.0872639513183482]
	TIME [epoch: 9.52 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9567745989926355		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.9567745989926355 | validation: 0.9883526120477928]
	TIME [epoch: 9.51 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8542619439753784		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.8542619439753784 | validation: 0.8533510436654939]
	TIME [epoch: 9.52 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7598703699193756		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.7598703699193756 | validation: 0.9639647561027375]
	TIME [epoch: 9.53 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8666645798936405		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.8666645798936405 | validation: 1.9600519652321442]
	TIME [epoch: 9.52 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.399438288096346		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 1.399438288096346 | validation: 1.0924701811907387]
	TIME [epoch: 9.52 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8335553559086286		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.8335553559086286 | validation: 0.8825897687467602]
	TIME [epoch: 9.53 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7759793824926434		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.7759793824926434 | validation: 0.8872325891234318]
	TIME [epoch: 9.52 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9951299659864198		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.9951299659864198 | validation: 1.4962105663267433]
	TIME [epoch: 9.5 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0305188534829028		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 1.0305188534829028 | validation: 0.9952595989137857]
	TIME [epoch: 9.51 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8882178035186084		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.8882178035186084 | validation: 1.0093946639422167]
	TIME [epoch: 9.53 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9371969052078237		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.9371969052078237 | validation: 1.0840089273281002]
	TIME [epoch: 9.51 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9616557099919391		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.9616557099919391 | validation: 0.9149257528268763]
	TIME [epoch: 9.5 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9258842160079993		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.9258842160079993 | validation: 0.9263430059240849]
	TIME [epoch: 9.52 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9243557253567427		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.9243557253567427 | validation: 0.9383610581131251]
	TIME [epoch: 9.5 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8859928699629529		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.8859928699629529 | validation: 0.9480433684280348]
	TIME [epoch: 9.5 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9764380273111583		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.9764380273111583 | validation: 0.9878438707718772]
	TIME [epoch: 9.51 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9172090514407627		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.9172090514407627 | validation: 0.8411917794188918]
	TIME [epoch: 9.51 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7871344238196147		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.7871344238196147 | validation: 0.8791847587393998]
	TIME [epoch: 9.51 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8094481961919191		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.8094481961919191 | validation: 0.9147264438510451]
	TIME [epoch: 9.5 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9816810690131408		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.9816810690131408 | validation: 0.898200327384821]
	TIME [epoch: 9.53 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9429159274015444		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.9429159274015444 | validation: 0.8340801093742263]
	TIME [epoch: 9.51 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7316676046679533		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.7316676046679533 | validation: 0.8327701730150939]
	TIME [epoch: 9.5 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7691999431871615		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.7691999431871615 | validation: 0.7839191996407499]
	TIME [epoch: 9.51 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7394252164874098		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.7394252164874098 | validation: 0.7940144186467797]
	TIME [epoch: 9.52 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7725398914154085		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.7725398914154085 | validation: 0.9348380073718664]
	TIME [epoch: 9.5 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8743638303803382		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.8743638303803382 | validation: 0.857956273800551]
	TIME [epoch: 9.5 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9315850593850332		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.9315850593850332 | validation: 0.8423585914208076]
	TIME [epoch: 9.52 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8300598691651391		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.8300598691651391 | validation: 0.8645841537024984]
	TIME [epoch: 9.51 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8315721231280067		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.8315721231280067 | validation: 0.9660783125617559]
	TIME [epoch: 9.5 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9634688554511293		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.9634688554511293 | validation: 0.8877028385957572]
	TIME [epoch: 9.5 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.884918282401934		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.884918282401934 | validation: 1.5426998229479707]
	TIME [epoch: 9.51 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0568308528488592		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 1.0568308528488592 | validation: 1.0489721966549395]
	TIME [epoch: 9.5 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9376178093141379		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.9376178093141379 | validation: 1.1225879888600216]
	TIME [epoch: 9.5 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.049963446805375		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 1.049963446805375 | validation: 0.8464057685798614]
	TIME [epoch: 9.52 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8387566100712167		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.8387566100712167 | validation: 0.9282894888568984]
	TIME [epoch: 9.5 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8606192305464969		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.8606192305464969 | validation: 0.9709978051541654]
	TIME [epoch: 9.5 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8952346250493323		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.8952346250493323 | validation: 1.18925683936992]
	TIME [epoch: 9.5 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0263804038278728		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 1.0263804038278728 | validation: 0.8249118669078185]
	TIME [epoch: 9.51 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9459375203228951		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.9459375203228951 | validation: 0.845116738005697]
	TIME [epoch: 9.5 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8080974615851488		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.8080974615851488 | validation: 0.8543922987309095]
	TIME [epoch: 9.5 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8019568850773391		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.8019568850773391 | validation: 1.1062840381144603]
	TIME [epoch: 9.51 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8411514298881743		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.8411514298881743 | validation: 0.7970260628754174]
	TIME [epoch: 9.5 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7750545490382461		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.7750545490382461 | validation: 0.7666968148436331]
	TIME [epoch: 9.5 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7110916250212498		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.7110916250212498 | validation: 0.824392693549034]
	TIME [epoch: 9.5 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7675572982283165		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.7675572982283165 | validation: 0.7391356673542393]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_417.pth
	Model improved!!!
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537262926305459		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.7537262926305459 | validation: 0.8930622996122758]
	TIME [epoch: 9.5 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8940082947294916		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.8940082947294916 | validation: 0.8825505151685132]
	TIME [epoch: 9.49 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7713402362193218		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.7713402362193218 | validation: 0.816430543893583]
	TIME [epoch: 9.52 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7598633374962988		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.7598633374962988 | validation: 0.9883381199213043]
	TIME [epoch: 9.5 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8590522405186045		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.8590522405186045 | validation: 0.854571555099177]
	TIME [epoch: 9.49 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9388518682499356		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.9388518682499356 | validation: 0.9948848505525782]
	TIME [epoch: 9.5 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8286657687727667		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.8286657687727667 | validation: 0.8567904899697238]
	TIME [epoch: 9.5 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7821988041463064		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 0.7821988041463064 | validation: 0.7559569237818312]
	TIME [epoch: 9.5 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7329751843406569		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.7329751843406569 | validation: 0.709617282157512]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_426.pth
	Model improved!!!
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7393391646185105		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.7393391646185105 | validation: 0.8842017011810418]
	TIME [epoch: 9.53 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0805247321662956		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 1.0805247321662956 | validation: 0.8906718115555964]
	TIME [epoch: 9.51 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7963832300817021		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.7963832300817021 | validation: 1.0538588600040788]
	TIME [epoch: 9.5 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9341614244564574		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.9341614244564574 | validation: 0.8483999990194588]
	TIME [epoch: 9.52 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8146951763537075		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.8146951763537075 | validation: 0.778822348904266]
	TIME [epoch: 9.51 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7837425415176528		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.7837425415176528 | validation: 0.8206054222592465]
	TIME [epoch: 9.5 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.765623316866664		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.765623316866664 | validation: 0.8060760331020845]
	TIME [epoch: 9.5 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8673480107207482		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.8673480107207482 | validation: 1.0368555902844028]
	TIME [epoch: 9.51 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0184056241131532		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 1.0184056241131532 | validation: 0.9955432559237265]
	TIME [epoch: 9.5 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8588833265091493		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.8588833265091493 | validation: 0.822672134298053]
	TIME [epoch: 9.5 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7361302160633524		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.7361302160633524 | validation: 0.8656871526728331]
	TIME [epoch: 9.52 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8129258354432063		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.8129258354432063 | validation: 0.7725204520343303]
	TIME [epoch: 9.5 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7651960625244977		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.7651960625244977 | validation: 1.4485190735767597]
	TIME [epoch: 9.5 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9252885327183218		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.9252885327183218 | validation: 1.0473790271761463]
	TIME [epoch: 9.5 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9126864775722556		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.9126864775722556 | validation: 0.8162953334873498]
	TIME [epoch: 9.51 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6989803072827003		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.6989803072827003 | validation: 0.7195784114304752]
	TIME [epoch: 9.49 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7218938955648497		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.7218938955648497 | validation: 0.7193247022676963]
	TIME [epoch: 9.5 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8305128881247207		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.8305128881247207 | validation: 0.8829939047024234]
	TIME [epoch: 9.52 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8359795274248079		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.8359795274248079 | validation: 0.7428920958253887]
	TIME [epoch: 9.5 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6626389637846929		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.6626389637846929 | validation: 0.8306411621596945]
	TIME [epoch: 9.5 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8243752486224661		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.8243752486224661 | validation: 0.7694132298311804]
	TIME [epoch: 9.5 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.707072969163025		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.707072969163025 | validation: 0.7924770502871763]
	TIME [epoch: 9.52 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6625218130301502		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.6625218130301502 | validation: 0.7676689241026518]
	TIME [epoch: 9.5 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7658461581778921		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.7658461581778921 | validation: 1.1744314284279411]
	TIME [epoch: 9.5 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.088078183728086		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 1.088078183728086 | validation: 1.0609614346641352]
	TIME [epoch: 9.52 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1052246666102818		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 1.1052246666102818 | validation: 0.7884321288203856]
	TIME [epoch: 9.51 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9397616685614805		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.9397616685614805 | validation: 0.8428874721384995]
	TIME [epoch: 9.49 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9249527548302202		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.9249527548302202 | validation: 0.7498123153047027]
	TIME [epoch: 9.5 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7271083508553566		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.7271083508553566 | validation: 1.0054796602026255]
	TIME [epoch: 9.53 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1918801269449002		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 1.1918801269449002 | validation: 0.9608591798850296]
	TIME [epoch: 9.5 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8798584834762051		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.8798584834762051 | validation: 0.9482587176409291]
	TIME [epoch: 9.5 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.85063032628928		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.85063032628928 | validation: 0.7586988161735068]
	TIME [epoch: 9.51 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.829267050413692		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.829267050413692 | validation: 0.8061641901335413]
	TIME [epoch: 9.5 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7389679346533986		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.7389679346533986 | validation: 0.7340308357882523]
	TIME [epoch: 9.5 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8843685602555731		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.8843685602555731 | validation: 0.7802417590396539]
	TIME [epoch: 9.49 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6948466044643464		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.6948466044643464 | validation: 0.7415122548312622]
	TIME [epoch: 9.53 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.798992127267035		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.798992127267035 | validation: 0.9663787336847273]
	TIME [epoch: 9.49 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7882999932168466		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.7882999932168466 | validation: 0.9235235982716319]
	TIME [epoch: 9.48 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8577654364600626		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.8577654364600626 | validation: 0.8283129562960359]
	TIME [epoch: 9.51 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7789607447186504		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.7789607447186504 | validation: 0.7382766108092923]
	TIME [epoch: 9.49 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.667069850959142		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.667069850959142 | validation: 0.7291067695001557]
	TIME [epoch: 9.49 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377091419699724		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.6377091419699724 | validation: 0.7385192164480532]
	TIME [epoch: 9.49 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355238798061886		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.6355238798061886 | validation: 0.6153977213311219]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_469.pth
	Model improved!!!
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6493449263808972		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.6493449263808972 | validation: 1.0518155988078148]
	TIME [epoch: 9.51 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7487098683336777		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.7487098683336777 | validation: 0.7178859936113392]
	TIME [epoch: 9.51 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323463046106148		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.6323463046106148 | validation: 0.6908583900004343]
	TIME [epoch: 9.53 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6102091191280375		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.6102091191280375 | validation: 0.7262237449008965]
	TIME [epoch: 9.51 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7507862968441361		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.7507862968441361 | validation: 1.1274479740183474]
	TIME [epoch: 9.5 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7045667081535336		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.7045667081535336 | validation: 0.6753896839930417]
	TIME [epoch: 9.51 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9340646760244322		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.9340646760244322 | validation: 0.8773817272589792]
	TIME [epoch: 9.52 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7526947294508666		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.7526947294508666 | validation: 0.8008262959790049]
	TIME [epoch: 9.5 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6593013863232574		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.6593013863232574 | validation: 0.842932916738221]
	TIME [epoch: 9.51 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8045051727485865		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.8045051727485865 | validation: 0.9357826888142106]
	TIME [epoch: 9.51 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7877155234263679		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.7877155234263679 | validation: 0.8541727653598693]
	TIME [epoch: 9.51 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.741924545906085		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.741924545906085 | validation: 0.7526439171430676]
	TIME [epoch: 9.5 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7773994135485081		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.7773994135485081 | validation: 1.1103115844115514]
	TIME [epoch: 9.51 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0045808046846787		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 1.0045808046846787 | validation: 0.7117827195408459]
	TIME [epoch: 9.51 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8137284039740423		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.8137284039740423 | validation: 0.9946455263036892]
	TIME [epoch: 9.5 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8240556072787703		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.8240556072787703 | validation: 0.7110146159398201]
	TIME [epoch: 9.5 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6698351701551638		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.6698351701551638 | validation: 0.7046384076288977]
	TIME [epoch: 9.52 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8772798115914728		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.8772798115914728 | validation: 0.971454237633781]
	TIME [epoch: 9.49 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7975942861144676		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.7975942861144676 | validation: 0.7397365859381474]
	TIME [epoch: 9.49 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.630775283842228		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.630775283842228 | validation: 0.7380075307641275]
	TIME [epoch: 9.5 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.65124107301282		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.65124107301282 | validation: 0.9987299578638275]
	TIME [epoch: 9.51 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.723934373119125		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.723934373119125 | validation: 0.6739546819694628]
	TIME [epoch: 9.49 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6135347042255119		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.6135347042255119 | validation: 0.7686074648145906]
	TIME [epoch: 9.49 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6869518685946322		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.6869518685946322 | validation: 0.713479852023022]
	TIME [epoch: 9.51 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6985929552786312		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.6985929552786312 | validation: 0.819013386501052]
	TIME [epoch: 9.49 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7052508282947352		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.7052508282947352 | validation: 0.9011503082808421]
	TIME [epoch: 9.49 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8077893126147435		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.8077893126147435 | validation: 0.7978739667303185]
	TIME [epoch: 9.49 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6560736263442025		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.6560736263442025 | validation: 0.7512656320525306]
	TIME [epoch: 9.51 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6590625499637803		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.6590625499637803 | validation: 0.7957263186619673]
	TIME [epoch: 9.49 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488845158261661		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.6488845158261661 | validation: 0.6965032514673968]
	TIME [epoch: 9.49 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.70710179542398		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.70710179542398 | validation: 0.6857054786487484]
	TIME [epoch: 9.52 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6989209230108249		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.6989209230108249 | validation: 0.8650430328154601]
	TIME [epoch: 9.49 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.847816356095441		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.847816356095441 | validation: 0.7826269988372546]
	TIME [epoch: 9.49 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6851543461340567		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.6851543461340567 | validation: 0.7801495345277871]
	TIME [epoch: 9.5 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502092759374432		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.6502092759374432 | validation: 0.8724789570808791]
	TIME [epoch: 9.51 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7267691565432696		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.7267691565432696 | validation: 0.7593043963171031]
	TIME [epoch: 9.49 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6413421701310151		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.6413421701310151 | validation: 0.6733867159133194]
	TIME [epoch: 9.49 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362464340169665		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.6362464340169665 | validation: 0.7212667996923966]
	TIME [epoch: 9.51 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6215162944465255		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.6215162944465255 | validation: 0.6910608431372641]
	TIME [epoch: 9.49 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.608002020683707		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.608002020683707 | validation: 0.674805920997086]
	TIME [epoch: 9.5 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.628574300085349		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.628574300085349 | validation: 0.6648090702661782]
	TIME [epoch: 9.51 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6074364179617493		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.6074364179617493 | validation: 0.7205336695224213]
	TIME [epoch: 9.51 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5990071599980175		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.5990071599980175 | validation: 0.7181544586836052]
	TIME [epoch: 9.5 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7837387202468526		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.7837387202468526 | validation: 0.6043394596193643]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_513.pth
	Model improved!!!
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5688247285424746		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.5688247285424746 | validation: 0.6966834338263689]
	TIME [epoch: 9.53 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5884233451096081		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.5884233451096081 | validation: 0.6360501382282624]
	TIME [epoch: 9.51 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5814517568753917		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.5814517568753917 | validation: 0.6485840680491974]
	TIME [epoch: 9.5 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5645008461359482		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.5645008461359482 | validation: 0.7750810147642884]
	TIME [epoch: 9.52 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360616092782161		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.6360616092782161 | validation: 0.7780412313588735]
	TIME [epoch: 9.51 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6425769373724248		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.6425769373724248 | validation: 0.6917420459387781]
	TIME [epoch: 9.5 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6145792510954754		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.6145792510954754 | validation: 0.8327569066356912]
	TIME [epoch: 9.5 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.679559051655293		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.679559051655293 | validation: 0.9984277062308513]
	TIME [epoch: 9.51 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8360428422692813		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.8360428422692813 | validation: 1.2005875730341942]
	TIME [epoch: 9.5 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8347182097447664		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.8347182097447664 | validation: 0.7263494678542086]
	TIME [epoch: 9.49 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6366387998273274		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.6366387998273274 | validation: 0.7530829650815235]
	TIME [epoch: 9.52 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6661526908115275		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.6661526908115275 | validation: 0.6407749692234451]
	TIME [epoch: 9.5 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5998538132821174		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.5998538132821174 | validation: 0.6587913375316033]
	TIME [epoch: 9.49 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.576100031166531		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.576100031166531 | validation: 0.6285097385423742]
	TIME [epoch: 9.5 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6597635361469812		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.6597635361469812 | validation: 0.6237917506422871]
	TIME [epoch: 9.52 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764182715635673		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.5764182715635673 | validation: 0.6744601842794434]
	TIME [epoch: 9.5 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8671959374672549		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.8671959374672549 | validation: 0.7645470015240458]
	TIME [epoch: 9.5 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8226332997013802		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.8226332997013802 | validation: 0.7563730763124701]
	TIME [epoch: 9.51 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6265761853372767		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.6265761853372767 | validation: 0.6815548438349072]
	TIME [epoch: 9.5 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898613322243729		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.5898613322243729 | validation: 0.6971005818779766]
	TIME [epoch: 9.49 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6418239716115265		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.6418239716115265 | validation: 0.8187805430182595]
	TIME [epoch: 9.5 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6155293433350681		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.6155293433350681 | validation: 0.724747898416245]
	TIME [epoch: 9.51 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6846531718696548		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.6846531718696548 | validation: 0.6836452146121239]
	TIME [epoch: 9.5 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498369537972127		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.6498369537972127 | validation: 0.8412615781275011]
	TIME [epoch: 9.49 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7092665673629297		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.7092665673629297 | validation: 0.6841206456572752]
	TIME [epoch: 9.52 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6053461883537262		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.6053461883537262 | validation: 0.7064848646555265]
	TIME [epoch: 9.5 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6842829162281134		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.6842829162281134 | validation: 0.6990362944175377]
	TIME [epoch: 9.5 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6068619796900793		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.6068619796900793 | validation: 0.5856890361144037]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_541.pth
	Model improved!!!
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6047821805375401		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.6047821805375401 | validation: 0.7144775231344626]
	TIME [epoch: 9.53 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6690369705296271		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.6690369705296271 | validation: 0.8307717219260571]
	TIME [epoch: 9.51 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6324339428650216		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.6324339428650216 | validation: 0.6095977510865823]
	TIME [epoch: 9.5 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5936625231148509		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.5936625231148509 | validation: 0.6775247638030908]
	TIME [epoch: 9.52 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7162900241984443		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.7162900241984443 | validation: 0.6545441044522378]
	TIME [epoch: 9.51 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5875578014224498		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.5875578014224498 | validation: 0.6963053228203188]
	TIME [epoch: 9.5 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6062490653088956		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.6062490653088956 | validation: 0.635948588900814]
	TIME [epoch: 9.5 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5418950544495156		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.5418950544495156 | validation: 0.5719970279230843]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_549.pth
	Model improved!!!
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6184025557564448		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.6184025557564448 | validation: 0.7598385053720484]
	TIME [epoch: 9.5 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6281931507696508		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.6281931507696508 | validation: 0.6693434522667988]
	TIME [epoch: 9.5 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.569597791819781		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.569597791819781 | validation: 0.6677350002829643]
	TIME [epoch: 9.53 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5736108122408331		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.5736108122408331 | validation: 0.6588401507070084]
	TIME [epoch: 9.52 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5852117636299988		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.5852117636299988 | validation: 0.6310857777978959]
	TIME [epoch: 9.51 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.594843370851615		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.594843370851615 | validation: 0.6404383436065184]
	TIME [epoch: 9.52 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6361804998102691		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.6361804998102691 | validation: 0.6690987877735318]
	TIME [epoch: 9.53 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5896192542523501		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.5896192542523501 | validation: 0.6254178060994434]
	TIME [epoch: 9.51 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6849222139915365		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.6849222139915365 | validation: 0.8690223460639703]
	TIME [epoch: 9.52 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7915643386255374		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.7915643386255374 | validation: 0.7089410944847089]
	TIME [epoch: 9.54 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981437054092074		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.5981437054092074 | validation: 0.7040518527052214]
	TIME [epoch: 9.52 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.630908084403633		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.630908084403633 | validation: 0.6978734085031727]
	TIME [epoch: 9.51 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6588019083500358		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.6588019083500358 | validation: 0.8807234227159885]
	TIME [epoch: 9.52 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7457581190604908		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.7457581190604908 | validation: 0.8822478034645557]
	TIME [epoch: 9.53 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.714396976346382		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.714396976346382 | validation: 0.6582656995809549]
	TIME [epoch: 9.51 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.572059300449578		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.572059300449578 | validation: 0.6372230216775145]
	TIME [epoch: 9.51 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5298498616673806		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.5298498616673806 | validation: 0.6277506186040904]
	TIME [epoch: 9.53 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602233356064008		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.5602233356064008 | validation: 0.6059173882951726]
	TIME [epoch: 9.52 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5770220506936881		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.5770220506936881 | validation: 0.5989729182526994]
	TIME [epoch: 9.52 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335645943523721		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.5335645943523721 | validation: 0.6219267041686808]
	TIME [epoch: 9.53 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241699049881754		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.5241699049881754 | validation: 0.6230447215916789]
	TIME [epoch: 9.53 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6634785825311631		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.6634785825311631 | validation: 0.6569016123044783]
	TIME [epoch: 9.52 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5619126193085485		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.5619126193085485 | validation: 0.5877702042607929]
	TIME [epoch: 9.52 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5786273954677339		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.5786273954677339 | validation: 0.6685944496774966]
	TIME [epoch: 9.53 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7029773315830381		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.7029773315830381 | validation: 0.7981926122779828]
	TIME [epoch: 9.52 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7333643704305646		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.7333643704305646 | validation: 0.6975764238947052]
	TIME [epoch: 9.51 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5683148190310668		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.5683148190310668 | validation: 0.6124451256285031]
	TIME [epoch: 9.53 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6860061382738051		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.6860061382738051 | validation: 0.7432688797254667]
	TIME [epoch: 9.52 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6944178991384886		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.6944178991384886 | validation: 0.6570876005589809]
	TIME [epoch: 9.52 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6511530855816405		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.6511530855816405 | validation: 0.6908705532892829]
	TIME [epoch: 9.51 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6631743154192677		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.6631743154192677 | validation: 0.6087939080996317]
	TIME [epoch: 9.54 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5385348380487057		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.5385348380487057 | validation: 0.6206191686777135]
	TIME [epoch: 9.52 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5517133263334664		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.5517133263334664 | validation: 0.5458658372356763]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_582.pth
	Model improved!!!
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5919440591445561		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.5919440591445561 | validation: 0.7396719776736467]
	TIME [epoch: 9.53 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6919192744596867		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.6919192744596867 | validation: 0.6342078081004769]
	TIME [epoch: 9.52 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5455346082186674		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.5455346082186674 | validation: 0.5882105831223016]
	TIME [epoch: 9.51 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6662326935662017		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.6662326935662017 | validation: 0.7100142626204925]
	TIME [epoch: 9.51 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6216951553340528		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.6216951553340528 | validation: 0.7047537724347376]
	TIME [epoch: 9.54 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.637341368934706		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.637341368934706 | validation: 0.5922694979724151]
	TIME [epoch: 9.51 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5384162472715925		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.5384162472715925 | validation: 0.6139146129096438]
	TIME [epoch: 9.51 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5477172791393732		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.5477172791393732 | validation: 0.5811080777115547]
	TIME [epoch: 9.53 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.521447764181866		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.521447764181866 | validation: 0.5705471586456313]
	TIME [epoch: 9.52 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.585776245731799		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.585776245731799 | validation: 0.6366373409344209]
	TIME [epoch: 9.51 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6906437469169092		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.6906437469169092 | validation: 0.7356171575530098]
	TIME [epoch: 9.51 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6304051392428512		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.6304051392428512 | validation: 0.5976484919021656]
	TIME [epoch: 9.54 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5765995241956962		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.5765995241956962 | validation: 0.6305242131652741]
	TIME [epoch: 9.51 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5671067085341928		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.5671067085341928 | validation: 0.7453830319803075]
	TIME [epoch: 9.51 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5691549185388987		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.5691549185388987 | validation: 0.6342364298332285]
	TIME [epoch: 9.53 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322932930724971		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.5322932930724971 | validation: 0.6258840012487558]
	TIME [epoch: 9.52 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5500152093807579		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.5500152093807579 | validation: 0.5878176232588538]
	TIME [epoch: 9.51 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5738030202348676		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.5738030202348676 | validation: 0.6400456904546071]
	TIME [epoch: 9.51 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5343431454087835		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.5343431454087835 | validation: 0.5729664270729197]
	TIME [epoch: 9.53 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323985923736894		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.5323985923736894 | validation: 0.5588725214200161]
	TIME [epoch: 9.51 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.518218635884236		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.518218635884236 | validation: 0.5815819724654994]
	TIME [epoch: 9.51 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5298224030451916		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.5298224030451916 | validation: 0.6003132907561044]
	TIME [epoch: 9.53 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6453954021413356		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.6453954021413356 | validation: 0.7230802396237721]
	TIME [epoch: 9.51 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391434678110961		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.6391434678110961 | validation: 0.625268490763053]
	TIME [epoch: 9.51 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6186754849891615		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.6186754849891615 | validation: 0.6847584615287482]
	TIME [epoch: 9.51 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5905187869253778		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.5905187869253778 | validation: 0.6344678689819184]
	TIME [epoch: 9.53 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.599361811463453		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.599361811463453 | validation: 0.5924139027431186]
	TIME [epoch: 9.51 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5697890174572116		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.5697890174572116 | validation: 0.6118884435947767]
	TIME [epoch: 9.51 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5574599763258858		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.5574599763258858 | validation: 0.8863430465600141]
	TIME [epoch: 9.53 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7016113296196729		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.7016113296196729 | validation: 0.7167816929368265]
	TIME [epoch: 9.51 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310006617609611		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.6310006617609611 | validation: 0.7062662232451811]
	TIME [epoch: 9.51 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5712335949102509		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.5712335949102509 | validation: 0.605629704486628]
	TIME [epoch: 9.51 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5146134133349738		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.5146134133349738 | validation: 0.5880619587636059]
	TIME [epoch: 9.53 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.51957229940258		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.51957229940258 | validation: 0.6165236220430005]
	TIME [epoch: 9.51 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5996229788907772		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.5996229788907772 | validation: 0.6117815831064806]
	TIME [epoch: 9.51 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5339292661268059		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.5339292661268059 | validation: 0.617219897462089]
	TIME [epoch: 9.53 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230671380586438		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.5230671380586438 | validation: 0.7239430546432195]
	TIME [epoch: 9.51 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5949532581444424		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.5949532581444424 | validation: 0.6516271805785027]
	TIME [epoch: 9.5 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408494661554113		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.5408494661554113 | validation: 0.5795266253464891]
	TIME [epoch: 9.51 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5282508439550219		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.5282508439550219 | validation: 0.5677905217983605]
	TIME [epoch: 9.52 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5137337926999956		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.5137337926999956 | validation: 0.5883388982334201]
	TIME [epoch: 9.5 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5694555386927377		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.5694555386927377 | validation: 0.7867086380579386]
	TIME [epoch: 9.5 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.647656609449929		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.647656609449929 | validation: 0.5997035825042828]
	TIME [epoch: 9.53 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5792776649920961		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.5792776649920961 | validation: 0.5992788972167644]
	TIME [epoch: 9.51 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5699977573957817		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.5699977573957817 | validation: 0.5961847194258972]
	TIME [epoch: 9.51 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6003736496944477		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.6003736496944477 | validation: 0.7118420750906375]
	TIME [epoch: 9.51 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339116066736248		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.6339116066736248 | validation: 0.6029590130776482]
	TIME [epoch: 9.52 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5327117663903926		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.5327117663903926 | validation: 0.6079060080144612]
	TIME [epoch: 9.5 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5858408571257118		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.5858408571257118 | validation: 0.6312530360481586]
	TIME [epoch: 9.5 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6258276266527261		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.6258276266527261 | validation: 0.7680353839971218]
	TIME [epoch: 9.53 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.691537157626707		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.691537157626707 | validation: 0.6568793688585425]
	TIME [epoch: 9.51 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5616741852264288		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.5616741852264288 | validation: 0.6030087370237803]
	TIME [epoch: 9.51 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5597081993312656		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.5597081993312656 | validation: 0.6528573250185999]
	TIME [epoch: 9.51 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5642296651583966		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.5642296651583966 | validation: 0.5803954865055009]
	TIME [epoch: 9.52 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344478165829963		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.5344478165829963 | validation: 0.5752724427490749]
	TIME [epoch: 9.51 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5603107057859904		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.5603107057859904 | validation: 0.6774872406857789]
	TIME [epoch: 9.5 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350040627267112		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.5350040627267112 | validation: 0.5727456672219373]
	TIME [epoch: 9.52 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.548095617904749		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.548095617904749 | validation: 0.7590747267909622]
	TIME [epoch: 9.51 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5931772263322553		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.5931772263322553 | validation: 0.6017152897295982]
	TIME [epoch: 9.5 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5159621500079338		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.5159621500079338 | validation: 0.5918001483730567]
	TIME [epoch: 9.51 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5412973255540101		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.5412973255540101 | validation: 0.5507772599617929]
	TIME [epoch: 9.51 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4905710511862287		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.4905710511862287 | validation: 0.5696895638297756]
	TIME [epoch: 9.5 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5507403018774651		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.5507403018774651 | validation: 0.5718123836070921]
	TIME [epoch: 9.51 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6058409155651707		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.6058409155651707 | validation: 0.7342055932906698]
	TIME [epoch: 9.53 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6802038810445239		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.6802038810445239 | validation: 0.6232878473733077]
	TIME [epoch: 9.51 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.602950412431076		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.602950412431076 | validation: 0.6173312099999608]
	TIME [epoch: 9.5 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6527130910525847		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.6527130910525847 | validation: 0.6583277967789883]
	TIME [epoch: 9.52 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6902834076416825		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.6902834076416825 | validation: 0.6805808191828637]
	TIME [epoch: 9.51 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5969377164346718		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.5969377164346718 | validation: 0.5534609136722994]
	TIME [epoch: 9.51 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.55191738237067		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.55191738237067 | validation: 0.584623319998319]
	TIME [epoch: 9.51 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297066841456861		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.5297066841456861 | validation: 0.6281580737352731]
	TIME [epoch: 9.53 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.657251437443033		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.657251437443033 | validation: 0.6599133539329408]
	TIME [epoch: 9.51 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7028899012569708		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.7028899012569708 | validation: 0.7968323769009706]
	TIME [epoch: 9.5 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430251000509524		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.6430251000509524 | validation: 0.599418431666235]
	TIME [epoch: 9.52 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5119849379515328		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.5119849379515328 | validation: 0.5519752671352444]
	TIME [epoch: 9.51 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062499937014449		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.5062499937014449 | validation: 0.5773867207846766]
	TIME [epoch: 9.5 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5382236321876303		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.5382236321876303 | validation: 0.6336833107449634]
	TIME [epoch: 9.5 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5684118671913989		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.5684118671913989 | validation: 0.7117507058429113]
	TIME [epoch: 9.53 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498372267383946		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.6498372267383946 | validation: 0.6895886119387268]
	TIME [epoch: 9.51 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5861602939670847		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.5861602939670847 | validation: 0.5750508500426833]
	TIME [epoch: 9.51 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5149454657722703		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.5149454657722703 | validation: 0.5960676434237944]
	TIME [epoch: 9.52 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5436220512557098		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.5436220512557098 | validation: 0.6540921725418205]
	TIME [epoch: 9.51 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6148920121350149		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.6148920121350149 | validation: 0.702745554275965]
	TIME [epoch: 9.51 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6257213719860933		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.6257213719860933 | validation: 0.6191473807775926]
	TIME [epoch: 9.56 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5801180883035382		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.5801180883035382 | validation: 0.6160596504807888]
	TIME [epoch: 9.52 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408139425233944		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.5408139425233944 | validation: 0.5864536487624029]
	TIME [epoch: 9.51 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5190376231448008		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.5190376231448008 | validation: 0.5754249255857978]
	TIME [epoch: 9.5 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6472115375027871		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.6472115375027871 | validation: 0.729785063346035]
	TIME [epoch: 9.53 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8005550981880463		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.8005550981880463 | validation: 0.7588668641154184]
	TIME [epoch: 9.51 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411696839400998		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.6411696839400998 | validation: 0.5597576239014619]
	TIME [epoch: 9.5 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5824011703657237		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.5824011703657237 | validation: 0.5859609779181332]
	TIME [epoch: 9.51 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410453357543129		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.5410453357543129 | validation: 0.6246898775175638]
	TIME [epoch: 9.52 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5047792407693964		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.5047792407693964 | validation: 0.5752989468586455]
	TIME [epoch: 9.51 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5035261905786685		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.5035261905786685 | validation: 0.5731801692373706]
	TIME [epoch: 9.51 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5596095413683495		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.5596095413683495 | validation: 0.6214479582682613]
	TIME [epoch: 9.52 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5331382277442536		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.5331382277442536 | validation: 0.5184451859912942]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_678.pth
	Model improved!!!
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5000813651517143		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.5000813651517143 | validation: 0.5649346496347496]
	TIME [epoch: 9.51 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495182268040502		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.5495182268040502 | validation: 0.6403764839684817]
	TIME [epoch: 9.5 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5535821151586173		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.5535821151586173 | validation: 0.5302561357334642]
	TIME [epoch: 9.52 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248972550582923		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.5248972550582923 | validation: 0.6068178517026234]
	TIME [epoch: 9.5 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5751344403502304		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.5751344403502304 | validation: 0.5972606657537404]
	TIME [epoch: 9.5 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6472397379110455		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.6472397379110455 | validation: 0.7019848697139173]
	TIME [epoch: 9.52 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6987993246442867		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.6987993246442867 | validation: 0.6804846442831161]
	TIME [epoch: 9.51 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7340894352330951		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.7340894352330951 | validation: 0.7577505222462727]
	TIME [epoch: 9.5 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6984240923679097		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.6984240923679097 | validation: 0.713408258298548]
	TIME [epoch: 9.51 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6020801274706538		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.6020801274706538 | validation: 0.556462956802678]
	TIME [epoch: 9.52 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49127164001347856		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.49127164001347856 | validation: 0.5594800570117276]
	TIME [epoch: 9.5 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5232358130733763		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.5232358130733763 | validation: 0.6136498474762212]
	TIME [epoch: 9.5 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5437914906770206		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.5437914906770206 | validation: 0.6052286001206689]
	TIME [epoch: 9.53 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5489468093454916		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.5489468093454916 | validation: 0.5873872832190757]
	TIME [epoch: 9.5 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5025746663844728		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.5025746663844728 | validation: 0.5797180960391611]
	TIME [epoch: 9.5 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5054572209792083		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.5054572209792083 | validation: 0.5113131706450075]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_694.pth
	Model improved!!!
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49348197300223384		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.49348197300223384 | validation: 0.5511647338040985]
	TIME [epoch: 9.52 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5099122296517793		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.5099122296517793 | validation: 0.5537965700901479]
	TIME [epoch: 9.5 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050145507782673		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.5050145507782673 | validation: 0.5562826414176602]
	TIME [epoch: 9.5 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47912153076010944		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.47912153076010944 | validation: 0.5239215007417947]
	TIME [epoch: 9.52 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5131079905898766		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.5131079905898766 | validation: 0.6072986791714579]
	TIME [epoch: 9.5 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5117652309617582		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.5117652309617582 | validation: 0.5514964723251987]
	TIME [epoch: 9.5 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201798126151475		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.5201798126151475 | validation: 0.5834713478655038]
	TIME [epoch: 9.5 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5612034088644503		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.5612034088644503 | validation: 0.5010073979948129]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_702.pth
	Model improved!!!
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.50320154606517		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.50320154606517 | validation: 0.5398803065510879]
	TIME [epoch: 9.5 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5127633738294894		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.5127633738294894 | validation: 0.5037447106291105]
	TIME [epoch: 9.5 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46811683056418624		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.46811683056418624 | validation: 0.5068892196772974]
	TIME [epoch: 9.52 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4879852323181676		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.4879852323181676 | validation: 0.5759026037121625]
	TIME [epoch: 9.49 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5433042842425073		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.5433042842425073 | validation: 0.7365145580203568]
	TIME [epoch: 9.5 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5903978386919295		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.5903978386919295 | validation: 0.597398204459726]
	TIME [epoch: 9.51 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402027507589353		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.5402027507589353 | validation: 0.5797144083097031]
	TIME [epoch: 9.51 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5120295983462219		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.5120295983462219 | validation: 0.5054125816035994]
	TIME [epoch: 9.49 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.523789854266844		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.523789854266844 | validation: 0.5091422580137281]
	TIME [epoch: 9.49 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4836526352892266		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.4836526352892266 | validation: 0.5340529454899866]
	TIME [epoch: 9.52 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47361076846975275		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.47361076846975275 | validation: 0.5308195712924946]
	TIME [epoch: 9.5 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5054009116169833		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.5054009116169833 | validation: 0.5443250462230284]
	TIME [epoch: 9.5 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5153845928816463		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.5153845928816463 | validation: 0.61536615807142]
	TIME [epoch: 9.52 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5007160151575635		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.5007160151575635 | validation: 0.4995876377304086]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_716.pth
	Model improved!!!
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46231852181928745		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.46231852181928745 | validation: 0.5225809250076788]
	TIME [epoch: 9.5 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48527766793318194		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.48527766793318194 | validation: 0.5686580253822449]
	TIME [epoch: 9.49 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.513264402549261		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.513264402549261 | validation: 0.5743961911842893]
	TIME [epoch: 9.53 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046310127786894		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.5046310127786894 | validation: 0.5564646061354882]
	TIME [epoch: 9.5 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.493145766957348		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.493145766957348 | validation: 0.5295722718241301]
	TIME [epoch: 9.51 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4684307256453694		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.4684307256453694 | validation: 0.52004515489472]
	TIME [epoch: 9.52 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4674999672342996		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.4674999672342996 | validation: 0.5266070434042335]
	TIME [epoch: 9.51 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48767017463979395		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.48767017463979395 | validation: 0.5717668946500531]
	TIME [epoch: 9.5 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5102844085365306		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.5102844085365306 | validation: 0.5156774546312916]
	TIME [epoch: 9.51 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4945742385393584		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.4945742385393584 | validation: 0.5192530386545442]
	TIME [epoch: 9.54 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4578539375223685		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.4578539375223685 | validation: 0.5204419926970436]
	TIME [epoch: 9.51 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4679400780882947		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.4679400780882947 | validation: 0.5050725663560229]
	TIME [epoch: 9.51 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4594683964095424		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.4594683964095424 | validation: 0.5214615813404601]
	TIME [epoch: 9.53 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4618466503607571		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.4618466503607571 | validation: 0.5308602239219193]
	TIME [epoch: 9.51 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4643477381388218		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.4643477381388218 | validation: 0.5093217254590695]
	TIME [epoch: 9.5 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48356299419699084		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.48356299419699084 | validation: 0.5552171604734163]
	TIME [epoch: 9.5 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5372218502722026		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.5372218502722026 | validation: 0.5656036314138636]
	TIME [epoch: 9.54 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5341182458829602		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.5341182458829602 | validation: 0.5664702615559848]
	TIME [epoch: 9.51 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49972851939305035		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.49972851939305035 | validation: 0.5517434250942335]
	TIME [epoch: 9.5 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4859179300987986		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.4859179300987986 | validation: 0.5069390341654022]
	TIME [epoch: 9.52 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47191497549008804		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.47191497549008804 | validation: 0.5217646058152158]
	TIME [epoch: 9.51 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4693621336931235		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.4693621336931235 | validation: 0.519710684836978]
	TIME [epoch: 9.5 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47388917754622406		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.47388917754622406 | validation: 0.5250531720679671]
	TIME [epoch: 9.51 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46887908430990227		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.46887908430990227 | validation: 0.5514693633321588]
	TIME [epoch: 9.54 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4945847854968021		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.4945847854968021 | validation: 0.5348681195093581]
	TIME [epoch: 9.51 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48939356355549923		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.48939356355549923 | validation: 0.529437198593966]
	TIME [epoch: 9.51 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.476552454076133		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.476552454076133 | validation: 0.5252015756839686]
	TIME [epoch: 9.53 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48623506637513003		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.48623506637513003 | validation: 0.5511364184896883]
	TIME [epoch: 9.51 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47982045167689263		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.47982045167689263 | validation: 0.5272554947977155]
	TIME [epoch: 9.51 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4966463862144672		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.4966463862144672 | validation: 0.5776895299104321]
	TIME [epoch: 9.51 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.506678861189475		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.506678861189475 | validation: 0.5395513422612986]
	TIME [epoch: 9.53 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5043641067068965		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.5043641067068965 | validation: 0.5706674802313967]
	TIME [epoch: 9.5 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4946973637301408		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.4946973637301408 | validation: 0.5210970532205844]
	TIME [epoch: 9.51 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46806847065402685		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.46806847065402685 | validation: 0.5107377264167114]
	TIME [epoch: 9.52 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4640966814473691		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.4640966814473691 | validation: 0.5141946191568958]
	TIME [epoch: 9.51 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4610801990913226		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.4610801990913226 | validation: 0.5070163372108898]
	TIME [epoch: 9.51 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45638871005545595		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.45638871005545595 | validation: 0.5182458354790497]
	TIME [epoch: 9.51 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4990158349472192		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.4990158349472192 | validation: 0.5493111930063301]
	TIME [epoch: 9.52 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4794122164259285		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.4794122164259285 | validation: 0.5160898668334225]
	TIME [epoch: 9.5 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49669249713073726		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.49669249713073726 | validation: 0.546690107024714]
	TIME [epoch: 9.5 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5298080811844919		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.5298080811844919 | validation: 0.5252079466170961]
	TIME [epoch: 9.55 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4737879279577829		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.4737879279577829 | validation: 0.5491010266594863]
	TIME [epoch: 9.51 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46205349058888884		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.46205349058888884 | validation: 0.5148927056375869]
	TIME [epoch: 9.5 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4529482132953633		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.4529482132953633 | validation: 0.5201046636719024]
	TIME [epoch: 9.51 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46378814479624353		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.46378814479624353 | validation: 0.5709969555439606]
	TIME [epoch: 9.52 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124036588846882		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.5124036588846882 | validation: 0.6161136737152914]
	TIME [epoch: 9.5 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5134496559444598		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.5134496559444598 | validation: 0.5577333105783887]
	TIME [epoch: 9.5 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46305166085340693		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.46305166085340693 | validation: 0.5135151505392807]
	TIME [epoch: 9.52 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45588205238488105		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.45588205238488105 | validation: 0.5052296539348692]
	TIME [epoch: 9.5 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.434061513713771		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.434061513713771 | validation: 0.5038223402388311]
	TIME [epoch: 9.5 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46653053564050107		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.46653053564050107 | validation: 0.5177505125096199]
	TIME [epoch: 9.5 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4612972687631064		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.4612972687631064 | validation: 0.5144436131908781]
	TIME [epoch: 9.52 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47220700505566693		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.47220700505566693 | validation: 0.5189598433572933]
	TIME [epoch: 9.5 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47366483853133257		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.47366483853133257 | validation: 0.5527406452779092]
	TIME [epoch: 9.5 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48553110210537753		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.48553110210537753 | validation: 0.5130803475604291]
	TIME [epoch: 9.51 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47660261037422635		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.47660261037422635 | validation: 0.5276280502428932]
	TIME [epoch: 9.5 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48325637256120474		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.48325637256120474 | validation: 0.4943111925927373]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_773.pth
	Model improved!!!
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45310087505188096		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.45310087505188096 | validation: 0.5133727485595015]
	TIME [epoch: 9.5 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46213032718890956		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.46213032718890956 | validation: 0.4949018716822844]
	TIME [epoch: 9.5 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4530538555244026		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.4530538555244026 | validation: 0.5015220671122208]
	TIME [epoch: 9.49 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45566501255927455		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.45566501255927455 | validation: 0.49415656433042493]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_777.pth
	Model improved!!!
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47164325446246547		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.47164325446246547 | validation: 0.49067991374655207]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_778.pth
	Model improved!!!
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.478995290893074		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.478995290893074 | validation: 0.5178888656494074]
	TIME [epoch: 9.49 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4809824808180932		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.4809824808180932 | validation: 0.4983061759440122]
	TIME [epoch: 9.49 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4645926012281182		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.4645926012281182 | validation: 0.5032354899866432]
	TIME [epoch: 9.51 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4719759630806835		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.4719759630806835 | validation: 0.4983609894946082]
	TIME [epoch: 9.51 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4476756798765277		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.4476756798765277 | validation: 0.4965620222447818]
	TIME [epoch: 9.5 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48215359048902007		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.48215359048902007 | validation: 0.545208191885201]
	TIME [epoch: 9.5 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5072963050203032		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.5072963050203032 | validation: 0.5296683299700284]
	TIME [epoch: 9.51 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49616928136837907		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.49616928136837907 | validation: 0.581702136308106]
	TIME [epoch: 9.49 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5550553252213123		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.5550553252213123 | validation: 0.5987236698400331]
	TIME [epoch: 9.49 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5084091758583192		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.5084091758583192 | validation: 0.5507097286054643]
	TIME [epoch: 9.5 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237642480067033		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.5237642480067033 | validation: 0.56861458588368]
	TIME [epoch: 9.5 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340326638499159		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.5340326638499159 | validation: 0.5507461316696055]
	TIME [epoch: 9.49 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.572539354879356		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.572539354879356 | validation: 0.58769542214873]
	TIME [epoch: 9.49 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6563002591431693		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.6563002591431693 | validation: 0.674364646677987]
	TIME [epoch: 9.52 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6172080623187124		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.6172080623187124 | validation: 0.5688292459935472]
	TIME [epoch: 9.49 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5795264573728331		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.5795264573728331 | validation: 0.5639532003654031]
	TIME [epoch: 9.49 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5052222973544188		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.5052222973544188 | validation: 0.5246697950308024]
	TIME [epoch: 9.51 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46330290850643074		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.46330290850643074 | validation: 0.5688695766985444]
	TIME [epoch: 9.49 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5093633506630455		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.5093633506630455 | validation: 0.5480191078224698]
	TIME [epoch: 9.49 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48454270440410624		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.48454270440410624 | validation: 0.5308776031806108]
	TIME [epoch: 9.49 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4869947216480234		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.4869947216480234 | validation: 0.521947089792406]
	TIME [epoch: 9.52 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.504646525340772		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.504646525340772 | validation: 0.5682314532643886]
	TIME [epoch: 9.49 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.51121511952453		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.51121511952453 | validation: 0.5211234717651084]
	TIME [epoch: 9.49 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4747764923825807		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.4747764923825807 | validation: 0.5375709998910193]
	TIME [epoch: 9.51 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.483288966166821		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.483288966166821 | validation: 0.5519888789322027]
	TIME [epoch: 9.49 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4908735735094937		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.4908735735094937 | validation: 0.5673361579892563]
	TIME [epoch: 9.48 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4821164292973686		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.4821164292973686 | validation: 0.5347636457461336]
	TIME [epoch: 9.49 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48095363376135936		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.48095363376135936 | validation: 0.5440011808722208]
	TIME [epoch: 9.51 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050223214958646		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.5050223214958646 | validation: 0.5250840377049887]
	TIME [epoch: 9.49 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4715883981152106		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.4715883981152106 | validation: 0.5483854774813238]
	TIME [epoch: 9.49 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49780857588957794		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.49780857588957794 | validation: 0.548343112585913]
	TIME [epoch: 9.51 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47380798231662624		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.47380798231662624 | validation: 0.5180270700025245]
	TIME [epoch: 9.5 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4533547693622172		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.4533547693622172 | validation: 0.49214821958805444]
	TIME [epoch: 9.49 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45207575345359075		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.45207575345359075 | validation: 0.5464279669320693]
	TIME [epoch: 9.48 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4524370741108387		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.4524370741108387 | validation: 0.5147731314048819]
	TIME [epoch: 9.51 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44919790127013803		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.44919790127013803 | validation: 0.552552988809868]
	TIME [epoch: 9.49 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4662608711644586		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.4662608711644586 | validation: 0.5254842515054541]
	TIME [epoch: 9.49 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47764741457341753		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.47764741457341753 | validation: 0.5398545858762994]
	TIME [epoch: 9.51 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4713433136530182		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.4713433136530182 | validation: 0.5698794256156531]
	TIME [epoch: 9.49 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4938321405988161		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.4938321405988161 | validation: 0.511302035399742]
	TIME [epoch: 9.48 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4733796735259818		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.4733796735259818 | validation: 0.5183066611597499]
	TIME [epoch: 9.5 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4522330619344254		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.4522330619344254 | validation: 0.5085052506693131]
	TIME [epoch: 9.51 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45134714710237755		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.45134714710237755 | validation: 0.5378702153274247]
	TIME [epoch: 9.49 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4668716562655436		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.4668716562655436 | validation: 0.4987499827205963]
	TIME [epoch: 9.49 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4709178575604872		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.4709178575604872 | validation: 0.517230198027909]
	TIME [epoch: 9.51 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4654519686184869		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.4654519686184869 | validation: 0.5188506653123439]
	TIME [epoch: 9.49 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45373520239318915		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.45373520239318915 | validation: 0.5087077976647489]
	TIME [epoch: 9.49 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.470043938288952		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.470043938288952 | validation: 0.523748676818206]
	TIME [epoch: 9.49 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4727293988621124		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.4727293988621124 | validation: 0.5272682647998551]
	TIME [epoch: 9.51 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46679434491892946		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.46679434491892946 | validation: 0.5046255698411414]
	TIME [epoch: 9.49 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45394229287739957		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.45394229287739957 | validation: 0.4993454012239966]
	TIME [epoch: 9.49 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47573909787860186		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.47573909787860186 | validation: 0.49148940380010603]
	TIME [epoch: 9.51 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48987368555022404		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.48987368555022404 | validation: 0.5268795245130782]
	TIME [epoch: 9.49 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5236806017844668		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.5236806017844668 | validation: 0.5322542207610051]
	TIME [epoch: 9.49 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787360968785585		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.5787360968785585 | validation: 0.6317591277301474]
	TIME [epoch: 9.49 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5954879029308087		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.5954879029308087 | validation: 0.5552149042715345]
	TIME [epoch: 9.5 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.517290504742658		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.517290504742658 | validation: 0.5276161020886849]
	TIME [epoch: 9.49 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4867708542071929		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.4867708542071929 | validation: 0.5198097044974366]
	TIME [epoch: 9.49 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48645394431168654		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.48645394431168654 | validation: 0.5616306086829788]
	TIME [epoch: 9.51 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48498192153191777		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.48498192153191777 | validation: 0.533427496931376]
	TIME [epoch: 9.49 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46761654582181755		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.46761654582181755 | validation: 0.49667093812232876]
	TIME [epoch: 9.49 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4620927389107292		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.4620927389107292 | validation: 0.5277983800450126]
	TIME [epoch: 9.5 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46453019937975143		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.46453019937975143 | validation: 0.5505964790201243]
	TIME [epoch: 9.51 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48180666142474526		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.48180666142474526 | validation: 0.553640066933459]
	TIME [epoch: 9.49 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4708682158671846		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.4708682158671846 | validation: 0.5103001990774506]
	TIME [epoch: 9.49 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45048764367581634		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.45048764367581634 | validation: 0.4851197403020557]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_844.pth
	Model improved!!!
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4644283338465338		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.4644283338465338 | validation: 0.5306382673145466]
	TIME [epoch: 9.49 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46853238706692724		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.46853238706692724 | validation: 0.49884244312349446]
	TIME [epoch: 9.48 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576614338944707		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.4576614338944707 | validation: 0.5103225652255243]
	TIME [epoch: 9.49 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4788387614392712		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.4788387614392712 | validation: 0.5188283137929657]
	TIME [epoch: 9.5 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4790329207588685		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.4790329207588685 | validation: 0.5206207138430068]
	TIME [epoch: 9.48 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48435741342000993		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.48435741342000993 | validation: 0.5170618611063276]
	TIME [epoch: 9.48 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5014953342835623		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.5014953342835623 | validation: 0.5725496896555763]
	TIME [epoch: 9.51 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5415244790856365		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.5415244790856365 | validation: 0.6545499487472091]
	TIME [epoch: 9.49 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5825451776800488		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.5825451776800488 | validation: 0.5709003289566382]
	TIME [epoch: 9.48 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4904495021385792		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.4904495021385792 | validation: 0.5649957758434634]
	TIME [epoch: 9.49 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233119452816891		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.5233119452816891 | validation: 0.5599251209949371]
	TIME [epoch: 9.5 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4817067903816638		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.4817067903816638 | validation: 0.5011076332737976]
	TIME [epoch: 9.48 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4724740491191464		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.4724740491191464 | validation: 0.5104268461961464]
	TIME [epoch: 9.49 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4572235676092074		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.4572235676092074 | validation: 0.4856987561065486]
	TIME [epoch: 9.5 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46581725199404334		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.46581725199404334 | validation: 0.5197697104638774]
	TIME [epoch: 9.48 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49180717761255704		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.49180717761255704 | validation: 0.4850093968873614]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_860.pth
	Model improved!!!
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45521407255313895		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.45521407255313895 | validation: 0.48965409496425594]
	TIME [epoch: 9.5 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47309235785680703		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.47309235785680703 | validation: 0.5427796718317359]
	TIME [epoch: 9.49 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49851627795505465		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.49851627795505465 | validation: 0.5238222091749603]
	TIME [epoch: 9.49 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4492676421527639		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.4492676421527639 | validation: 0.49331757484637356]
	TIME [epoch: 9.49 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43712552576573654		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.43712552576573654 | validation: 0.4767954310053568]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_865.pth
	Model improved!!!
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4338804544563654		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.4338804544563654 | validation: 0.4909703755349928]
	TIME [epoch: 9.49 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4290887823705858		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.4290887823705858 | validation: 0.4827441552609291]
	TIME [epoch: 9.48 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43169564105501584		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.43169564105501584 | validation: 0.480442089614689]
	TIME [epoch: 9.5 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43795754527483144		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.43795754527483144 | validation: 0.5022734933626443]
	TIME [epoch: 9.49 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48976195454061394		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.48976195454061394 | validation: 0.5579469454079933]
	TIME [epoch: 9.48 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5370250247598224		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.5370250247598224 | validation: 0.5512670271491866]
	TIME [epoch: 9.49 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023703961326411		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.5023703961326411 | validation: 0.5297806748097712]
	TIME [epoch: 9.51 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47804285373638383		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.47804285373638383 | validation: 0.5162348426793415]
	TIME [epoch: 9.49 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47279720256400426		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.47279720256400426 | validation: 0.5078231620131056]
	TIME [epoch: 9.48 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4534083721131486		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.4534083721131486 | validation: 0.500229417849925]
	TIME [epoch: 9.51 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4804195544889908		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.4804195544889908 | validation: 0.5414110078792106]
	TIME [epoch: 9.49 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4940893281472144		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.4940893281472144 | validation: 0.48964664749016296]
	TIME [epoch: 9.48 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4568433205513721		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.4568433205513721 | validation: 0.5160656059227747]
	TIME [epoch: 9.48 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44642439297460096		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.44642439297460096 | validation: 0.500487289709509]
	TIME [epoch: 9.51 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44445360803021083		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.44445360803021083 | validation: 0.5055538826377212]
	TIME [epoch: 9.48 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43622814130090193		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.43622814130090193 | validation: 0.5065152706854744]
	TIME [epoch: 9.48 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4394203705907109		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.4394203705907109 | validation: 0.4933289643162094]
	TIME [epoch: 9.5 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42776034357962234		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.42776034357962234 | validation: 0.4853324885299638]
	TIME [epoch: 9.49 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44940211212778314		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.44940211212778314 | validation: 0.5144218272234621]
	TIME [epoch: 9.48 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4342034056936216		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.4342034056936216 | validation: 0.5002819316359559]
	TIME [epoch: 9.48 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44211042169198683		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.44211042169198683 | validation: 0.4905981293385613]
	TIME [epoch: 9.5 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4669559844093795		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.4669559844093795 | validation: 0.5201410376104112]
	TIME [epoch: 9.48 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49996246071568357		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.49996246071568357 | validation: 0.5226352946295443]
	TIME [epoch: 9.48 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.477787840870225		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.477787840870225 | validation: 0.49440561507504527]
	TIME [epoch: 9.5 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4651151541237958		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.4651151541237958 | validation: 0.5217010582316527]
	TIME [epoch: 9.49 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182009396697069		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.5182009396697069 | validation: 0.5673951176130544]
	TIME [epoch: 9.48 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5663099538057628		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.5663099538057628 | validation: 0.5931678017316167]
	TIME [epoch: 9.48 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5714808543968385		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.5714808543968385 | validation: 0.5680271248032335]
	TIME [epoch: 9.5 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4719182620271433		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.4719182620271433 | validation: 0.5156538589383058]
	TIME [epoch: 9.48 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4564693446660394		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.4564693446660394 | validation: 0.5249784558230648]
	TIME [epoch: 9.48 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4414256752886768		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.4414256752886768 | validation: 0.4876446853640208]
	TIME [epoch: 9.5 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43912468409757627		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.43912468409757627 | validation: 0.4743555867433966]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_897.pth
	Model improved!!!
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4310523310501078		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.4310523310501078 | validation: 0.4678481666902236]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_898.pth
	Model improved!!!
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4356358377511869		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.4356358377511869 | validation: 0.484121985938277]
	TIME [epoch: 9.49 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4239285513878491		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.4239285513878491 | validation: 0.47524462114827504]
	TIME [epoch: 9.5 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44295373187344145		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.44295373187344145 | validation: 0.4827139327095783]
	TIME [epoch: 9.48 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4451928188376		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.4451928188376 | validation: 0.4886888455082892]
	TIME [epoch: 9.48 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4320856375465432		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.4320856375465432 | validation: 0.49913399513256823]
	TIME [epoch: 9.5 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4432691809143976		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.4432691809143976 | validation: 0.4849315213274179]
	TIME [epoch: 9.48 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.435919976089333		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.435919976089333 | validation: 0.5020749000599759]
	TIME [epoch: 9.48 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4414745952959979		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.4414745952959979 | validation: 0.48392316418053777]
	TIME [epoch: 9.49 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44144889203995774		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.44144889203995774 | validation: 0.48073741707520434]
	TIME [epoch: 9.5 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45149831676566354		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.45149831676566354 | validation: 0.4937760364700451]
	TIME [epoch: 9.48 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4414591502736084		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.4414591502736084 | validation: 0.5001087050045817]
	TIME [epoch: 9.49 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4291731448343886		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.4291731448343886 | validation: 0.46971646727238237]
	TIME [epoch: 9.51 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4306743211078845		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.4306743211078845 | validation: 0.46809156665764035]
	TIME [epoch: 9.48 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4292549247017036		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.4292549247017036 | validation: 0.46923237668934437]
	TIME [epoch: 9.48 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42392254210620395		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.42392254210620395 | validation: 0.48168125632126546]
	TIME [epoch: 9.48 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44244579845299936		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.44244579845299936 | validation: 0.5059663807489916]
	TIME [epoch: 9.5 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45447028850540844		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.45447028850540844 | validation: 0.5154559913772835]
	TIME [epoch: 9.48 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4399465329647743		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.4399465329647743 | validation: 0.49212606299519635]
	TIME [epoch: 9.48 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4306505746731414		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.4306505746731414 | validation: 0.5025693692148548]
	TIME [epoch: 9.5 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43743498570851996		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.43743498570851996 | validation: 0.490985669095734]
	TIME [epoch: 9.48 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4299592062838239		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.4299592062838239 | validation: 0.4792914415654396]
	TIME [epoch: 9.48 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4310680988331209		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.4310680988331209 | validation: 0.4862372256403584]
	TIME [epoch: 9.49 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42964857429585723		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.42964857429585723 | validation: 0.4899046426776135]
	TIME [epoch: 9.51 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42994535794820443		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.42994535794820443 | validation: 0.47983918654928465]
	TIME [epoch: 9.48 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4364201713063315		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.4364201713063315 | validation: 0.5017128465132545]
	TIME [epoch: 9.49 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4331207428737506		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.4331207428737506 | validation: 0.46522728445150363]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_924.pth
	Model improved!!!
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4411704702954477		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.4411704702954477 | validation: 0.5117796865184568]
	TIME [epoch: 9.49 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43276987460299254		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.43276987460299254 | validation: 0.4672657886748411]
	TIME [epoch: 9.49 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43181664949633236		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.43181664949633236 | validation: 0.4736380285256713]
	TIME [epoch: 9.49 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43078001173640157		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.43078001173640157 | validation: 0.47929309628736533]
	TIME [epoch: 9.5 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4253072561310258		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.4253072561310258 | validation: 0.46592940953611406]
	TIME [epoch: 9.49 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42412596000279923		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.42412596000279923 | validation: 0.4728821312562954]
	TIME [epoch: 9.49 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.434320390826163		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.434320390826163 | validation: 0.48914343402975574]
	TIME [epoch: 9.51 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4293666297758755		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.4293666297758755 | validation: 0.46775998745718556]
	TIME [epoch: 9.49 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4234960605799463		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.4234960605799463 | validation: 0.45951788030170193]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_933.pth
	Model improved!!!
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4225689387697999		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.4225689387697999 | validation: 0.48037486534326507]
	TIME [epoch: 9.5 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4163539036773288		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.4163539036773288 | validation: 0.4684134016598654]
	TIME [epoch: 9.5 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182693605908872		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.4182693605908872 | validation: 0.4810882021531366]
	TIME [epoch: 9.48 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4214117738210975		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.4214117738210975 | validation: 0.481937323438961]
	TIME [epoch: 9.49 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42932136231674145		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.42932136231674145 | validation: 0.49856738765044184]
	TIME [epoch: 9.5 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43497087185284045		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.43497087185284045 | validation: 0.506336911031907]
	TIME [epoch: 9.48 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.425840448987665		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.425840448987665 | validation: 0.4753409177755287]
	TIME [epoch: 9.48 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44536705107974717		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.44536705107974717 | validation: 0.4881917967840464]
	TIME [epoch: 9.5 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4286937386020752		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.4286937386020752 | validation: 0.48191056557554235]
	TIME [epoch: 9.49 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4402905595649149		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.4402905595649149 | validation: 0.49073293722689015]
	TIME [epoch: 9.49 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.441954373672618		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.441954373672618 | validation: 0.4971009009139188]
	TIME [epoch: 9.49 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4296202948324295		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.4296202948324295 | validation: 0.5001750400763879]
	TIME [epoch: 9.51 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.433306816036377		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.433306816036377 | validation: 0.4909215181636485]
	TIME [epoch: 9.49 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4364458592081307		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.4364458592081307 | validation: 0.4871859332884351]
	TIME [epoch: 9.49 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43586522696488295		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.43586522696488295 | validation: 0.4872096544090274]
	TIME [epoch: 9.5 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4493125749862739		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.4493125749862739 | validation: 0.48867809698343095]
	TIME [epoch: 9.5 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4359626814318278		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.4359626814318278 | validation: 0.4893699569086523]
	TIME [epoch: 9.49 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4330904734027431		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.4330904734027431 | validation: 0.47145270333862016]
	TIME [epoch: 9.49 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4323783787819814		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.4323783787819814 | validation: 0.5005960231207425]
	TIME [epoch: 9.5 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4451979597644623		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.4451979597644623 | validation: 0.48673404455355535]
	TIME [epoch: 9.49 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46951729727094393		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.46951729727094393 | validation: 0.5193836597234329]
	TIME [epoch: 9.48 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4805092777005523		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.4805092777005523 | validation: 0.49504404722247314]
	TIME [epoch: 9.51 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4480850365763442		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.4480850365763442 | validation: 0.47476730354089897]
	TIME [epoch: 9.49 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4398920400282922		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.4398920400282922 | validation: 0.45732031912181237]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_957.pth
	Model improved!!!
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.436770192543605		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.436770192543605 | validation: 0.4853671916257521]
	TIME [epoch: 9.48 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43444839234576477		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.43444839234576477 | validation: 0.47574600188170535]
	TIME [epoch: 9.51 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43610969157139945		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.43610969157139945 | validation: 0.48064902574488927]
	TIME [epoch: 9.48 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43981566119359805		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.43981566119359805 | validation: 0.4987503448795241]
	TIME [epoch: 9.48 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4228480274866864		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.4228480274866864 | validation: 0.486175534596675]
	TIME [epoch: 9.5 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.426612076889448		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.426612076889448 | validation: 0.49813190605858587]
	TIME [epoch: 9.49 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43300446400858483		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.43300446400858483 | validation: 0.4855621473381116]
	TIME [epoch: 9.48 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42695642303587533		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.42695642303587533 | validation: 0.4890808362318167]
	TIME [epoch: 9.48 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4372487359877061		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.4372487359877061 | validation: 0.5022145035007304]
	TIME [epoch: 9.5 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4334441683086448		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.4334441683086448 | validation: 0.4883954898668654]
	TIME [epoch: 9.48 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42594676437792584		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.42594676437792584 | validation: 0.4868408381416137]
	TIME [epoch: 9.48 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196462229419353		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.4196462229419353 | validation: 0.4760363019071451]
	TIME [epoch: 9.51 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43235081127200015		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.43235081127200015 | validation: 0.4839240438906001]
	TIME [epoch: 9.49 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4401473797010227		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.4401473797010227 | validation: 0.5041685436896813]
	TIME [epoch: 9.48 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43019858671459765		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.43019858671459765 | validation: 0.48568921682525806]
	TIME [epoch: 9.48 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4256135534107567		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.4256135534107567 | validation: 0.4800307873866228]
	TIME [epoch: 9.5 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41964393883066425		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.41964393883066425 | validation: 0.4575200442765484]
	TIME [epoch: 9.49 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.418139334888021		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.418139334888021 | validation: 0.47378100352823393]
	TIME [epoch: 9.48 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.432151390763772		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.432151390763772 | validation: 0.49253828546968065]
	TIME [epoch: 9.5 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4218690689238497		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.4218690689238497 | validation: 0.4527979586637428]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study5/model_tr_study5_r2_20240218_115020/states/model_tr_study5_977.pth
	Model improved!!!
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4248638906881171		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.4248638906881171 | validation: 0.46762753233183046]
	TIME [epoch: 9.5 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42981445857509737		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.42981445857509737 | validation: 0.47233344743065764]
	TIME [epoch: 9.49 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151225492755217		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.4151225492755217 | validation: 0.4667085025461634]
	TIME [epoch: 9.51 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42692563862890703		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.42692563862890703 | validation: 0.4763538549780938]
	TIME [epoch: 9.49 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4244499719258285		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.4244499719258285 | validation: 0.47073161868917823]
	TIME [epoch: 9.49 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43945731742282634		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.43945731742282634 | validation: 0.48936707879900115]
	TIME [epoch: 9.51 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4485723113151635		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.4485723113151635 | validation: 0.46913247291789534]
	TIME [epoch: 9.5 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43575695679044707		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.43575695679044707 | validation: 0.47371458087105495]
	TIME [epoch: 9.49 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4276219771790636		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.4276219771790636 | validation: 0.48395423246167296]
	TIME [epoch: 9.49 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4324209339316131		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.4324209339316131 | validation: 0.4724150628805521]
	TIME [epoch: 9.51 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42345262704161424		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.42345262704161424 | validation: 0.4901218749420517]
	TIME [epoch: 9.5 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4303063261659771		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.4303063261659771 | validation: 0.47531195187528114]
	TIME [epoch: 9.49 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.431168924043174		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.431168924043174 | validation: 0.5060195846363587]
	TIME [epoch: 9.51 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4428330276526721		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.4428330276526721 | validation: 0.48919962734075795]
	TIME [epoch: 9.49 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43005833932049586		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.43005833932049586 | validation: 0.4905907933270446]
	TIME [epoch: 9.49 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42792850437846586		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.42792850437846586 | validation: 0.46379573600682317]
	TIME [epoch: 9.49 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4257077568675814		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.4257077568675814 | validation: 0.48144881454911853]
	TIME [epoch: 9.51 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42769651155952493		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.42769651155952493 | validation: 0.46145198042051905]
	TIME [epoch: 9.49 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40724291998774653		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.40724291998774653 | validation: 0.4817379498705162]
	TIME [epoch: 9.5 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229888245181906		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.4229888245181906 | validation: 0.4736033720293093]
	TIME [epoch: 9.5 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.417323172326839		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.417323172326839 | validation: 0.4677384436819584]
	TIME [epoch: 9.49 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41694023461188756		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.41694023461188756 | validation: 0.5044326515016616]
	TIME [epoch: 9.48 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4355638609759966		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.4355638609759966 | validation: 0.5123508107531363]
	TIME [epoch: 9.48 sec]
Finished training in 9620.331 seconds.
