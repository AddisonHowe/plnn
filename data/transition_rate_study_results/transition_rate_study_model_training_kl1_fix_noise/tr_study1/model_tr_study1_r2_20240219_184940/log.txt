Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r2', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 391297343

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/20] avg loss: 10.249904969778651		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.609735615065253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.929820292421953 | validation: 9.913943963276902]
	TIME [epoch: 78.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/20] avg loss: 9.1173699587399		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.096093368819618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.106731663779758 | validation: 9.073347790109418]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/20] avg loss: 8.699822233151062		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.924760045532253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.312291139341657 | validation: 7.462746267523686]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/20] avg loss: 7.819847264549873		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.08485717646292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.452352220506398 | validation: 7.577278313005806]
	TIME [epoch: 8.36 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.817025518004646		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.3012245038558365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.559125010930243 | validation: 6.0051431823381325]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.012545974244555		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.33956848305447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.676057228649513 | validation: 3.8220071973790377]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.396240821390508		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.303040093633599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.349640457512054 | validation: 4.150562962969268]
	TIME [epoch: 8.33 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.002385886887641		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5197919495409615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.761088918214301 | validation: 2.8395160100316073]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.948918608908528		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1985500665170106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.573734337712769 | validation: 3.0628887877945843]
	TIME [epoch: 8.34 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.013731585146812		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.860506988694289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9371192869205505 | validation: 2.4546781642300997]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.274502557219671		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.5246376429151565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8995701000674137 | validation: 3.2375574892619436]
	TIME [epoch: 8.35 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.50654754030106		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.1797161895433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.34313186492218 | validation: 1.9260358925356913]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.0247601462240072		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9141459017630702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9694530239935386 | validation: 1.815736687736357]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.8571232486486025		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.9003168457922146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8787200472204084 | validation: 1.6002711908188594]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7912605588100043		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6820273802161225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.736643969513063 | validation: 1.5876799398837824]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.7144844955052665		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5259916732211685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6202380843632174 | validation: 1.6399454220904153]
	TIME [epoch: 8.36 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4997462803418617		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5898185755409184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.54478242794139 | validation: 1.481285020463506]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6884461349068673		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5642109742257324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6263285545663 | validation: 1.6273847350347512]
	TIME [epoch: 8.32 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.6027107722262275		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5503661820318972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5765384771290625 | validation: 2.171843344149269]
	TIME [epoch: 8.32 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.640315017238677		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5075078701616014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5739114437001391 | validation: 1.7704944207894242]
	TIME [epoch: 8.35 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.496355604270931		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5510588630939517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5237072336824413 | validation: 1.7437497586839557]
	TIME [epoch: 8.32 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4877975748346686		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4407540896171522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4642758322259106 | validation: 1.4370212591994835]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.510297131614248		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5209955275314357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5156463295728415 | validation: 1.5655682425336344]
	TIME [epoch: 8.34 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5210632091825884		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3952694904561165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4581663498193522 | validation: 1.8463065224659638]
	TIME [epoch: 8.35 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5448061549179997		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5198825388325554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5323443468752775 | validation: 1.623390273310377]
	TIME [epoch: 8.32 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.5290858531766074		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5126248997741656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5208553764753865 | validation: 1.5592515229692858]
	TIME [epoch: 8.33 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4613034140761165		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3810991363338228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4212012752049694 | validation: 1.4788214016303265]
	TIME [epoch: 8.31 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.4607432646219078		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4436784057075658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4522108351647371 | validation: 1.717805044227638]
	TIME [epoch: 8.34 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3653672751754278		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4421597536153274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4037635143953775 | validation: 1.6226375823111434]
	TIME [epoch: 8.32 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3234769088555416		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4616268737730445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3925518913142931 | validation: 1.3252162285326623]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3812489061255229		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3537611020477982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3675050040866605 | validation: 1.5528860711559822]
	TIME [epoch: 8.35 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.716579260981927		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3503645624341252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5334719117080262 | validation: 1.4730568039400995]
	TIME [epoch: 8.34 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.273254088103074		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3436819609367276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3084680245199005 | validation: 1.3603936843023596]
	TIME [epoch: 8.32 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2817500731544063		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4440372550280611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3628936640912337 | validation: 1.5721093331787075]
	TIME [epoch: 8.33 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3894808991995116		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2627266954623457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3261037973309286 | validation: 1.403079276007365]
	TIME [epoch: 8.35 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3465896600221376		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.820660476487528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.583625068254833 | validation: 1.6702571657273102]
	TIME [epoch: 8.34 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2232069017805265		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2951693265493207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2591881141649237 | validation: 1.3565347067026128]
	TIME [epoch: 8.33 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2712096917981603		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.275775482041427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2734925869197935 | validation: 1.2210171440413715]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.186147717891817		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3347894377766774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2604685778342468 | validation: 1.3267832102774082]
	TIME [epoch: 8.34 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1916218117158262		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.265849310662035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2287355611889303 | validation: 1.5029058897230527]
	TIME [epoch: 8.33 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.250518938435516		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.222594252573772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.236556595504644 | validation: 1.3006626544471735]
	TIME [epoch: 8.32 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2714552475070884		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.163170749945299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2173129987261935 | validation: 1.3009357475596262]
	TIME [epoch: 8.32 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2591953982856532		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2753170141058097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2672562061957315 | validation: 1.1921403818231573]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1381068197495536		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1941311638120156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1661189917807846 | validation: 1.2452310346391222]
	TIME [epoch: 8.34 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.3092090348842946		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.070959442431969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1900842386581318 | validation: 1.329025770009396]
	TIME [epoch: 8.31 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2961925253134878		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2384866148124245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2673395700629562 | validation: 1.31768251536708]
	TIME [epoch: 8.31 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0809113925004836		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2105608652276745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1457361288640793 | validation: 1.3191554747154217]
	TIME [epoch: 8.33 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.077498995655385		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1989009256928544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1381999606741198 | validation: 1.0299550257098031]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1071019618731488		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1663538964860627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.136727929179606 | validation: 1.1807919401966518]
	TIME [epoch: 8.31 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.066489231414143		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2103542670118832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.138421749213013 | validation: 1.237208326497691]
	TIME [epoch: 8.31 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0355913587634409		[learning rate: 0.0099894]
		[batch 20/20] avg loss: 1.1308502161282323		[learning rate: 0.0099776]
	Learning Rate: 0.00997759
	LOSS [training: 1.0832207874458368 | validation: 1.2879712486513182]
	TIME [epoch: 8.33 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1154624158889073		[learning rate: 0.0099658]
		[batch 20/20] avg loss: 1.1772816258186676		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.1463720208537875 | validation: 1.2471913116745448]
	TIME [epoch: 8.32 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0955057052693111		[learning rate: 0.0099423]
		[batch 20/20] avg loss: 1.0542059128976096		[learning rate: 0.0099306]
	Learning Rate: 0.00993057
	LOSS [training: 1.0748558090834603 | validation: 1.2230374749763109]
	TIME [epoch: 8.31 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1461346127498495		[learning rate: 0.0099189]
		[batch 20/20] avg loss: 1.1348342035241286		[learning rate: 0.0099071]
	Learning Rate: 0.00990715
	LOSS [training: 1.140484408136989 | validation: 1.0339738504258877]
	TIME [epoch: 8.31 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9546565572829534		[learning rate: 0.0098955]
		[batch 20/20] avg loss: 1.129433865565253		[learning rate: 0.0098838]
	Learning Rate: 0.00988378
	LOSS [training: 1.0420452114241032 | validation: 0.9337696746099227]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0189343768142705		[learning rate: 0.0098721]
		[batch 20/20] avg loss: 1.0225776581368637		[learning rate: 0.0098605]
	Learning Rate: 0.00986047
	LOSS [training: 1.0207560174755672 | validation: 1.0520167557753513]
	TIME [epoch: 8.34 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0266736748344898		[learning rate: 0.0098488]
		[batch 20/20] avg loss: 1.0778990897654848		[learning rate: 0.0098372]
	Learning Rate: 0.00983721
	LOSS [training: 1.0522863822999873 | validation: 1.142668473650636]
	TIME [epoch: 8.32 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0900227039956154		[learning rate: 0.0098256]
		[batch 20/20] avg loss: 1.0713438445844816		[learning rate: 0.009814]
	Learning Rate: 0.009814
	LOSS [training: 1.0806832742900485 | validation: 0.9568300027533512]
	TIME [epoch: 8.32 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0553611343728762		[learning rate: 0.0098024]
		[batch 20/20] avg loss: 1.0431240867481895		[learning rate: 0.0097909]
	Learning Rate: 0.00979085
	LOSS [training: 1.0492426105605328 | validation: 1.0091549170222278]
	TIME [epoch: 8.35 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.016222032782608		[learning rate: 0.0097793]
		[batch 20/20] avg loss: 1.0702092060477006		[learning rate: 0.0097678]
	Learning Rate: 0.00976776
	LOSS [training: 1.0432156194151543 | validation: 1.1114095099709131]
	TIME [epoch: 8.33 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.926524162949177		[learning rate: 0.0097562]
		[batch 20/20] avg loss: 0.9597755884645615		[learning rate: 0.0097447]
	Learning Rate: 0.00974472
	LOSS [training: 0.9431498757068691 | validation: 1.0638465545065754]
	TIME [epoch: 8.33 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9536069636712565		[learning rate: 0.0097332]
		[batch 20/20] avg loss: 0.8569812061364391		[learning rate: 0.0097217]
	Learning Rate: 0.00972173
	LOSS [training: 0.905294084903848 | validation: 1.1035597096101537]
	TIME [epoch: 8.31 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1091187711548545		[learning rate: 0.0097103]
		[batch 20/20] avg loss: 0.815213381175157		[learning rate: 0.0096988]
	Learning Rate: 0.0096988
	LOSS [training: 0.962166076165006 | validation: 1.21507603333826]
	TIME [epoch: 8.34 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1543828755406875		[learning rate: 0.0096874]
		[batch 20/20] avg loss: 0.9517314390094394		[learning rate: 0.0096759]
	Learning Rate: 0.00967592
	LOSS [training: 1.0530571572750635 | validation: 0.8655206024019839]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.810649716549723		[learning rate: 0.0096645]
		[batch 20/20] avg loss: 1.005780201987165		[learning rate: 0.0096531]
	Learning Rate: 0.0096531
	LOSS [training: 0.908214959268444 | validation: 1.7155255535411769]
	TIME [epoch: 8.32 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8636740702306147		[learning rate: 0.0096417]
		[batch 20/20] avg loss: 0.9777638362067268		[learning rate: 0.0096303]
	Learning Rate: 0.00963033
	LOSS [training: 0.9207189532186707 | validation: 1.6205355281713223]
	TIME [epoch: 8.32 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2956426806070744		[learning rate: 0.009619]
		[batch 20/20] avg loss: 1.1756356630587326		[learning rate: 0.0096076]
	Learning Rate: 0.00960761
	LOSS [training: 1.2356391718329032 | validation: 0.6937027171148218]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8636974536695841		[learning rate: 0.0095963]
		[batch 20/20] avg loss: 0.9658714854396248		[learning rate: 0.0095849]
	Learning Rate: 0.00958495
	LOSS [training: 0.9147844695546045 | validation: 1.1108103107704825]
	TIME [epoch: 8.35 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.336468902391203		[learning rate: 0.0095736]
		[batch 20/20] avg loss: 0.8618423989110345		[learning rate: 0.0095623]
	Learning Rate: 0.00956234
	LOSS [training: 1.0991556506511189 | validation: 0.7403112480914961]
	TIME [epoch: 8.34 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7928226375604029		[learning rate: 0.0095511]
		[batch 20/20] avg loss: 0.9034730143377171		[learning rate: 0.0095398]
	Learning Rate: 0.00953978
	LOSS [training: 0.8481478259490599 | validation: 0.8715881744572317]
	TIME [epoch: 8.34 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9560464982704785		[learning rate: 0.0095285]
		[batch 20/20] avg loss: 1.0280015343801876		[learning rate: 0.0095173]
	Learning Rate: 0.00951728
	LOSS [training: 0.9920240163253331 | validation: 0.9529613117161799]
	TIME [epoch: 8.37 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8298062708238589		[learning rate: 0.009506]
		[batch 20/20] avg loss: 0.7873184596830093		[learning rate: 0.0094948]
	Learning Rate: 0.00949483
	LOSS [training: 0.8085623652534342 | validation: 0.8976327688112217]
	TIME [epoch: 8.34 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7971625020532261		[learning rate: 0.0094836]
		[batch 20/20] avg loss: 0.8288763708401834		[learning rate: 0.0094724]
	Learning Rate: 0.00947243
	LOSS [training: 0.8130194364467048 | validation: 0.9312157989691903]
	TIME [epoch: 8.34 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8795123464733298		[learning rate: 0.0094613]
		[batch 20/20] avg loss: 1.0377194851106863		[learning rate: 0.0094501]
	Learning Rate: 0.00945009
	LOSS [training: 0.9586159157920081 | validation: 1.6899220478179289]
	TIME [epoch: 8.34 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8898256953371242		[learning rate: 0.0094389]
		[batch 20/20] avg loss: 0.7923710501665979		[learning rate: 0.0094278]
	Learning Rate: 0.0094278
	LOSS [training: 0.8410983727518611 | validation: 0.9414709792904996]
	TIME [epoch: 8.37 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7717302074395415		[learning rate: 0.0094167]
		[batch 20/20] avg loss: 0.7335282166102272		[learning rate: 0.0094056]
	Learning Rate: 0.00940556
	LOSS [training: 0.7526292120248843 | validation: 1.2489326570882568]
	TIME [epoch: 8.34 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8933561915794668		[learning rate: 0.0093945]
		[batch 20/20] avg loss: 0.796900250061044		[learning rate: 0.0093834]
	Learning Rate: 0.00938337
	LOSS [training: 0.8451282208202555 | validation: 0.7327128457184553]
	TIME [epoch: 8.34 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7014983934834412		[learning rate: 0.0093723]
		[batch 20/20] avg loss: 0.9803426740762214		[learning rate: 0.0093612]
	Learning Rate: 0.00936124
	LOSS [training: 0.8409205337798312 | validation: 0.5287572982696859]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6871166336555411		[learning rate: 0.0093502]
		[batch 20/20] avg loss: 0.7767593104582905		[learning rate: 0.0093392]
	Learning Rate: 0.00933916
	LOSS [training: 0.7319379720569157 | validation: 1.4297249198808606]
	TIME [epoch: 8.37 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.779675240465076		[learning rate: 0.0093281]
		[batch 20/20] avg loss: 0.8004327124266319		[learning rate: 0.0093171]
	Learning Rate: 0.00931713
	LOSS [training: 0.7900539764458541 | validation: 0.7607795041889042]
	TIME [epoch: 8.34 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8619482560928438		[learning rate: 0.0093061]
		[batch 20/20] avg loss: 0.8671651252950369		[learning rate: 0.0092951]
	Learning Rate: 0.00929515
	LOSS [training: 0.8645566906939403 | validation: 0.5988520661617366]
	TIME [epoch: 8.34 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6816580833349455		[learning rate: 0.0092842]
		[batch 20/20] avg loss: 0.7230107111637194		[learning rate: 0.0092732]
	Learning Rate: 0.00927322
	LOSS [training: 0.7023343972493323 | validation: 1.5332758633490515]
	TIME [epoch: 8.33 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7791785982431635		[learning rate: 0.0092623]
		[batch 20/20] avg loss: 0.6824895595749783		[learning rate: 0.0092514]
	Learning Rate: 0.00925135
	LOSS [training: 0.7308340789090708 | validation: 1.102576915904019]
	TIME [epoch: 8.37 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7589229995304799		[learning rate: 0.0092404]
		[batch 20/20] avg loss: 0.7510877863444654		[learning rate: 0.0092295]
	Learning Rate: 0.00922953
	LOSS [training: 0.7550053929374727 | validation: 0.7132989865446282]
	TIME [epoch: 8.34 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6594371862068067		[learning rate: 0.0092186]
		[batch 20/20] avg loss: 0.6129724681749555		[learning rate: 0.0092078]
	Learning Rate: 0.00920776
	LOSS [training: 0.6362048271908809 | validation: 1.8871232665847004]
	TIME [epoch: 8.34 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9318728982592003		[learning rate: 0.0091969]
		[batch 20/20] avg loss: 0.7007357115272687		[learning rate: 0.009186]
	Learning Rate: 0.00918604
	LOSS [training: 0.8163043048932345 | validation: 1.7576730427198552]
	TIME [epoch: 8.34 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7509148799659346		[learning rate: 0.0091752]
		[batch 20/20] avg loss: 0.6476869059953764		[learning rate: 0.0091644]
	Learning Rate: 0.00916437
	LOSS [training: 0.6993008929806555 | validation: 0.43759708249323576]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240219_184940/states/model_tr_study1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0641251214646652		[learning rate: 0.0091536]
		[batch 20/20] avg loss: 0.7316675222542053		[learning rate: 0.0091428]
	Learning Rate: 0.00914275
	LOSS [training: 0.8978963218594351 | validation: 0.5899954555831339]
	TIME [epoch: 8.33 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5673214594839509		[learning rate: 0.009132]
		[batch 20/20] avg loss: 0.8537630127866069		[learning rate: 0.0091212]
	Learning Rate: 0.00912119
	LOSS [training: 0.7105422361352787 | validation: 1.3052974368389316]
	TIME [epoch: 8.33 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8508436220219151		[learning rate: 0.0091104]
		[batch 20/20] avg loss: 0.68492559052003		[learning rate: 0.0090997]
	Learning Rate: 0.00909967
	LOSS [training: 0.7678846062709724 | validation: 0.6178763882038324]
	TIME [epoch: 8.34 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7118136821473436		[learning rate: 0.0090889]
		[batch 20/20] avg loss: 0.9943333458223075		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.8530735139848258 | validation: 1.8290531569720325]
	TIME [epoch: 8.37 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7636434105215827		[learning rate: 0.0090675]
		[batch 20/20] avg loss: 0.7804396379704733		[learning rate: 0.0090568]
	Learning Rate: 0.00905679
	LOSS [training: 0.7720415242460279 | validation: 0.5409956975451073]
	TIME [epoch: 8.33 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8008083148763842		[learning rate: 0.0090461]
		[batch 20/20] avg loss: 0.8013943924707767		[learning rate: 0.0090354]
	Learning Rate: 0.00903543
	LOSS [training: 0.8011013536735805 | validation: 0.45069667429230376]
	TIME [epoch: 8.33 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6405621828884478		[learning rate: 0.0090248]
		[batch 20/20] avg loss: 0.697407502247717		[learning rate: 0.0090141]
	Learning Rate: 0.00901411
	LOSS [training: 0.6689848425680824 | validation: 0.7796672341860835]
	TIME [epoch: 8.33 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7944302593039136		[learning rate: 0.0090035]
		[batch 20/20] avg loss: 0.7824072099635605		[learning rate: 0.0089929]
	Learning Rate: 0.00899285
	LOSS [training: 0.788418734633737 | validation: 0.48828181354735745]
	TIME [epoch: 8.36 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6223572238581256		[learning rate: 0.0089822]
		[batch 20/20] avg loss: 0.6715910254368829		[learning rate: 0.0089716]
	Learning Rate: 0.00897164
	LOSS [training: 0.6469741246475043 | validation: 0.8262860385013066]
	TIME [epoch: 8.33 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6343844730705813		[learning rate: 0.0089611]
		[batch 20/20] avg loss: 0.6783323697973029		[learning rate: 0.0089505]
	Learning Rate: 0.00895048
	LOSS [training: 0.6563584214339421 | validation: 0.8627651448302718]
	TIME [epoch: 8.33 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5987214503274052		[learning rate: 0.0089399]
		[batch 20/20] avg loss: 0.8345032773529246		[learning rate: 0.0089294]
	Learning Rate: 0.00892936
	LOSS [training: 0.7166123638401649 | validation: 0.44813605938348766]
	TIME [epoch: 8.33 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6470797331407735		[learning rate: 0.0089188]
		[batch 20/20] avg loss: 0.7229071915314963		[learning rate: 0.0089083]
	Learning Rate: 0.0089083
	LOSS [training: 0.684993462336135 | validation: 0.48831110987069626]
	TIME [epoch: 8.36 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5380133473080307		[learning rate: 0.0088978]
		[batch 20/20] avg loss: 0.6625650389475867		[learning rate: 0.0088873]
	Learning Rate: 0.00888729
	LOSS [training: 0.6002891931278088 | validation: 0.9030918985069643]
	TIME [epoch: 8.33 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.857505845538974		[learning rate: 0.0088768]
		[batch 20/20] avg loss: 0.6055813464800401		[learning rate: 0.0088663]
	Learning Rate: 0.00886632
	LOSS [training: 0.7315435960095072 | validation: 1.2922831143956162]
	TIME [epoch: 8.32 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.79324791841022		[learning rate: 0.0088559]
		[batch 20/20] avg loss: 0.7109747779397366		[learning rate: 0.0088454]
	Learning Rate: 0.00884541
	LOSS [training: 0.7521113481749783 | validation: 0.9035567471093695]
	TIME [epoch: 8.32 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7351300261889084		[learning rate: 0.008835]
		[batch 20/20] avg loss: 0.5894363327806712		[learning rate: 0.0088245]
	Learning Rate: 0.00882454
	LOSS [training: 0.6622831794847899 | validation: 0.5451788883443556]
	TIME [epoch: 8.36 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8146954347997657		[learning rate: 0.0088141]
		[batch 20/20] avg loss: 4.6210451274310405		[learning rate: 0.0088037]
	Learning Rate: 0.00880373
	LOSS [training: 2.717870281115403 | validation: 5.0564423833388465]
	TIME [epoch: 8.33 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0134682667725214		[learning rate: 0.0087933]
		[batch 20/20] avg loss: 3.3913035178984146		[learning rate: 0.008783]
	Learning Rate: 0.00878296
	LOSS [training: 3.202385892335468 | validation: 4.958005153008923]
	TIME [epoch: 8.33 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.6979069671605496		[learning rate: 0.0087726]
		[batch 20/20] avg loss: 2.6247459686557097		[learning rate: 0.0087622]
	Learning Rate: 0.00876225
	LOSS [training: 2.6613264679081294 | validation: 4.115278676405247]
	TIME [epoch: 8.33 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.5170390909602363		[learning rate: 0.0087519]
		[batch 20/20] avg loss: 1.4719562896641074		[learning rate: 0.0087416]
	Learning Rate: 0.00874158
	LOSS [training: 1.994497690312172 | validation: 3.5731480170581107]
	TIME [epoch: 8.36 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.9771358890379735		[learning rate: 0.0087313]
		[batch 20/20] avg loss: 8.133220405686288		[learning rate: 0.008721]
	Learning Rate: 0.00872096
	LOSS [training: 6.555178147362132 | validation: 8.565878429629192]
	TIME [epoch: 8.33 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/20] avg loss: 7.713540362953566		[learning rate: 0.0087107]
		[batch 20/20] avg loss: 3.282007283835817		[learning rate: 0.0087004]
	Learning Rate: 0.00870038
	LOSS [training: 5.4977738233946924 | validation: 4.500089729238188]
	TIME [epoch: 8.33 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.661860293060302		[learning rate: 0.0086901]
		[batch 20/20] avg loss: 3.8926339423951584		[learning rate: 0.0086799]
	Learning Rate: 0.00867986
	LOSS [training: 3.2772471177277303 | validation: 5.1648163113245635]
	TIME [epoch: 8.32 sec]
EPOCH 111/2000:
	Training over batches...
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.05
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.025
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.0125
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.00625
