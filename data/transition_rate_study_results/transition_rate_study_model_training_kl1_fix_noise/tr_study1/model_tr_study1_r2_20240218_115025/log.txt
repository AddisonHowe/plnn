Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r2', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4180238284

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 10.916611414890227		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.946819602702925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.431715508796577 | validation: 10.241948998086482]
	TIME [epoch: 79.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 9.6982033669914		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.015438433532784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.356820900262093 | validation: 8.810998711860721]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 8.177075570980438		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.0460262424695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.611550906724967 | validation: 8.326023605451683]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 7.030629847371533		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.272388872257698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.651509359814616 | validation: 7.29477734718127]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.6172325136278785		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.647133813735383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.13218316368163 | validation: 5.484488024670595]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 4.402972885633824		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.9361630252839475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.169567955458886 | validation: 5.240493443203777]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.9284435501075037		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.712720841302145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8205821957048243 | validation: 5.089624641049255]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.6897053587654396		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.8371625003103795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.76343392953791 | validation: 4.996915795927147]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.671983780577275		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.6653080206709205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.668645900624097 | validation: 4.920199381013224]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.7393979057699958		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5751287286830236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.65726331722651 | validation: 5.214264319061691]
	TIME [epoch: 8.37 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.4260315497341183		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.7585855798717676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5923085648029427 | validation: 4.994878572570577]
	TIME [epoch: 8.36 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.6499887502381725		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5309963907800777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.590492570509125 | validation: 5.330750300898915]
	TIME [epoch: 8.38 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.453952171352582		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.7380326546588734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.595992413005728 | validation: 5.474556491606716]
	TIME [epoch: 8.4 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.7740114219953242		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5664126441418844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6702120330686037 | validation: 5.061685833058991]
	TIME [epoch: 8.37 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.5349747127035878		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.558056078262122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5465153954828543 | validation: 5.250382446260875]
	TIME [epoch: 8.37 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.589769353528923		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.53880101482214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5642851841755308 | validation: 4.505352063631668]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.800251860036974		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.61972666484003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2099892624385027 | validation: 1.9176638329773668]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.3341207058389872		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.2922800554227734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3132003806308803 | validation: 2.0003983040383435]
	TIME [epoch: 8.38 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.111481512773474		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.282257183671258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1968693482223656 | validation: 1.885175498444441]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.105962493400824		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.025679479077623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.065820986239223 | validation: 1.9509705467192744]
	TIME [epoch: 8.36 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0107058528425		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8359330627689663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9233194578057335 | validation: 2.0350415482464426]
	TIME [epoch: 8.39 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.1654066781062538		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8718290088109046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0186178434585798 | validation: 1.8613134171429877]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7762373651635912		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7999876552805785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7881125102220854 | validation: 1.5518155247489074]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8206097628298543		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7282432073647804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7744264850973177 | validation: 1.5224678677740735]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.599325422299907		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.547481160827245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.573403291563576 | validation: 1.7786755418328906]
	TIME [epoch: 8.39 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5582844803473574		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6827002585214281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.620492369434393 | validation: 1.433373143259479]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4079381165722198		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7513492143507636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.579643665461492 | validation: 1.701236072877932]
	TIME [epoch: 8.38 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5753372990964598		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.352610009514663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4639736543055615 | validation: 1.6142612175169246]
	TIME [epoch: 8.37 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3799249193769516		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3798915551492237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3799082372630875 | validation: 1.4152876464224113]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2539460634585629		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.451454303130857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.35270018329471 | validation: 1.4501239653218976]
	TIME [epoch: 8.38 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.403145833693801		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2604266765826266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3317862551382138 | validation: 1.7652436883855462]
	TIME [epoch: 8.39 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3961727093680514		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4853462579806487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.44075948367435 | validation: 2.381082141976435]
	TIME [epoch: 8.38 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5072425549827366		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3544749986248998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4308587768038181 | validation: 1.8735240604505297]
	TIME [epoch: 8.39 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.374764394406782		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4123196878987916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3935420411527868 | validation: 1.650821708344029]
	TIME [epoch: 8.4 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3203336113989574		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.334272441081962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3273030262404597 | validation: 1.268144973410125]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.267069699993462		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3517266244726476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3093981622330548 | validation: 1.323784582721136]
	TIME [epoch: 8.39 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.326845734823089		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4009057031799734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3638757190015314 | validation: 1.6530832624437473]
	TIME [epoch: 8.38 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.325342552245769		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3686035699483852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3469730610970772 | validation: 1.2762666735832435]
	TIME [epoch: 8.38 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2343493121608304		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3816016878945565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3079755000276934 | validation: 1.2732738162898507]
	TIME [epoch: 8.38 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4153252267289842		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3044823151786085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3599037709537962 | validation: 1.272262550683728]
	TIME [epoch: 8.36 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3226069716808404		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2734922390228856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.298049605351863 | validation: 1.1724395761635766]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.563705790300162		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.368242786591967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4659742884460645 | validation: 1.1588387376803144]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.190525816180222		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.186808942601043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1886673793906322 | validation: 1.7580582188224345]
	TIME [epoch: 8.36 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3749981740357586		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3526678372219603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3638330056288592 | validation: 1.4595158567303628]
	TIME [epoch: 8.36 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3998781791303327		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1738434352715883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2868608072009604 | validation: 1.2277260891171111]
	TIME [epoch: 8.39 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2839410757678296		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2847411718444532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2843411238061413 | validation: 1.2060906744311406]
	TIME [epoch: 8.37 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2687678282746848		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.275439127424247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2721034778494658 | validation: 1.251967611523521]
	TIME [epoch: 8.35 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1953222891575557		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2607143450458493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2280183171017025 | validation: 1.2755570039441455]
	TIME [epoch: 8.37 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2316911701540347		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.0885048238989854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.16009799702651 | validation: 1.436514680017724]
	TIME [epoch: 8.38 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1432739836196988		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.207909551511324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1755917675655112 | validation: 1.069602043090019]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1531578048154065		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 1.346122506227638		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.2496401555215222 | validation: 0.9650239025359246]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.179824325449491		[learning rate: 0.00993]
		[batch 20/20] avg loss: 1.3233431762485008		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.251583750848996 | validation: 1.5079455551294823]
	TIME [epoch: 8.34 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.294586076987937		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 1.30450267639605		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.2995443766919936 | validation: 0.9390049766272581]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.213688371031035		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 1.0962703591558447		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 1.15497936509344 | validation: 1.1069821481558721]
	TIME [epoch: 8.35 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1660951465317657		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 1.2064500917199283		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.186272619125847 | validation: 1.1300939064585815]
	TIME [epoch: 8.35 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.286002123592688		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 1.2495926226526046		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.2677973731226464 | validation: 1.0993306068725253]
	TIME [epoch: 8.36 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0742135418787093		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 1.0903341151148893		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.0822738284967994 | validation: 0.8984682775578179]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1169755399973327		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 1.0139606794765956		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.0654681097369643 | validation: 0.8946093584201855]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0687136106396802		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 1.2193566116061012		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.1440351111228908 | validation: 1.689835149557307]
	TIME [epoch: 8.35 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1203666946865851		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 1.1117544002011148		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.1160605474438499 | validation: 0.8222930161860067]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1943701640699647		[learning rate: 0.009506]
		[batch 20/20] avg loss: 1.264472383837702		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 1.2294212739538333 | validation: 1.0877638611026081]
	TIME [epoch: 8.4 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3384158641423636		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 1.1057828883224798		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 1.2220993762324217 | validation: 1.2367611367510378]
	TIME [epoch: 8.36 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.154234685258938		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 1.0254240208264023		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.0898293530426701 | validation: 1.237061965622256]
	TIME [epoch: 8.33 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0200041098276542		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 1.1464047939332935		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 1.0832044518804738 | validation: 2.5226368851204874]
	TIME [epoch: 8.36 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0892640309858108		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 1.0147025816508117		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 1.0519833063183113 | validation: 1.044739005912576]
	TIME [epoch: 8.4 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8891038108978744		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 0.9843689213172022		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.9367363661075382 | validation: 0.9774922702044717]
	TIME [epoch: 8.35 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.053247213765451		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 1.3518070211185058		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.2025271174419787 | validation: 0.8454031331054236]
	TIME [epoch: 8.36 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9610931302294997		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 0.8729117110610064		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.9170024206452532 | validation: 0.8191774788176573]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9146591288910855		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 0.8596991280777304		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.887179128484408 | validation: 1.152611541527265]
	TIME [epoch: 8.37 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0998306814747791		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 0.868364152273964		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.9840974168743715 | validation: 0.8996435339409745]
	TIME [epoch: 8.35 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8433626633757438		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 0.9989029404340899		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.921132801904917 | validation: 0.8056596289496903]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.128240491896596		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 0.9139756938335764		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 1.0211080928650862 | validation: 0.8295106924764198]
	TIME [epoch: 8.36 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8366274497676063		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 0.8151589823873359		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.825893216077471 | validation: 0.7675049336541176]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9271768038605313		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 0.7523940804553291		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.8397854421579304 | validation: 0.8588595612193168]
	TIME [epoch: 8.36 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7975992835210637		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 0.8977468685813417		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.8476730760512027 | validation: 0.9277975869486641]
	TIME [epoch: 8.37 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0378183920305166		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 0.7284666190966973		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.883142505563607 | validation: 0.563674868597325]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6724490071634247		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 0.743734468622548		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.7080917378929864 | validation: 1.0556088848917367]
	TIME [epoch: 8.38 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.732798613019692		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 1.0469672028825159		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.889882907951104 | validation: 0.7308371372618139]
	TIME [epoch: 8.38 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.771805758887248		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 0.6763068284958355		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.7240562936915417 | validation: 0.5691773216476892]
	TIME [epoch: 8.36 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9525720781284243		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 0.9006665863864617		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.9266193322574431 | validation: 0.5133785327391223]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0798173307472527		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 0.8653811343090727		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.9725992325281629 | validation: 1.0720384366780773]
	TIME [epoch: 8.39 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6825757023735467		[learning rate: 0.008586]
		[batch 20/20] avg loss: 0.7174147396497054		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.6999952210116261 | validation: 0.6952894030544514]
	TIME [epoch: 8.35 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6475645673958491		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 0.7360316074469099		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.6917980874213794 | validation: 0.5964776171639804]
	TIME [epoch: 8.36 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7423788030427461		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 0.8760849303247429		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.8092318666837446 | validation: 0.6809907603829759]
	TIME [epoch: 8.36 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7904623447450028		[learning rate: 0.008462]
		[batch 20/20] avg loss: 0.6090531040989298		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.6997577244219662 | validation: 0.7622324532008771]
	TIME [epoch: 8.38 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7027430830747646		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 0.9105545888365063		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.8066488359556354 | validation: 1.7151297631012665]
	TIME [epoch: 8.35 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7211378653139849		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 0.7769531700155755		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.7490455176647803 | validation: 0.6567965387144498]
	TIME [epoch: 8.37 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0545249347242014		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 0.6028928898462806		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.8287089122852409 | validation: 0.619127365750918]
	TIME [epoch: 8.37 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5929390661314493		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 0.6808969755910558		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.6369180208612524 | validation: 0.6883508553531978]
	TIME [epoch: 8.37 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7205252703518447		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 0.7067227338001172		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.7136240020759812 | validation: 0.6050726936449918]
	TIME [epoch: 8.36 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6098423748273316		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 0.6691095257832399		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.6394759503052858 | validation: 0.6532637802443932]
	TIME [epoch: 8.33 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6480272036650697		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 0.6904141857977321		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.6692206947314009 | validation: 0.4834593395681079]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5748674143111847		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 0.6078235821480067		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.5913454982295956 | validation: 0.3573824528149541]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5079162964640832		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 0.6249241936367863		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.5664202450504348 | validation: 0.6282270698314104]
	TIME [epoch: 8.33 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5137189186689529		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 0.49973646405162897		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.506727691360291 | validation: 0.5442943096688029]
	TIME [epoch: 8.35 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.61805893173809		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 0.5662933851070924		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.5921761584225913 | validation: 0.7446770528008688]
	TIME [epoch: 8.38 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0057394855487733		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 0.5602590389484993		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.7829992622486363 | validation: 0.6475927572768113]
	TIME [epoch: 8.35 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.584421711991628		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 0.5425839935626439		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.563502852777136 | validation: 0.6896060578279284]
	TIME [epoch: 8.36 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5900939676612794		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 0.6024628078806933		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.5962783877709864 | validation: 0.31347791845752093]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.459932200945283		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 0.620985565943173		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.5404588834442279 | validation: 0.6109076078004864]
	TIME [epoch: 8.35 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5241752307750558		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 0.552376885461348		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.5382760581182019 | validation: 0.5150036185318996]
	TIME [epoch: 8.36 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5633650240176008		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 0.48647210352766024		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.5249185637726305 | validation: 0.7037298652320898]
	TIME [epoch: 8.37 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4654307087230958		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 0.48805466766487876		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.47674268819398735 | validation: 0.4193267705990954]
	TIME [epoch: 8.34 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48980467060946997		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 0.4860152039337269		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.4879099372715984 | validation: 0.43828111226778727]
	TIME [epoch: 8.38 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5493328087643659		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 0.5895359675482841		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.5694343881563251 | validation: 0.7236276294035086]
	TIME [epoch: 8.39 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5323923805639497		[learning rate: 0.007643]
		[batch 20/20] avg loss: 0.49517124030642085		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.5137818104351852 | validation: 0.40450726459995984]
	TIME [epoch: 8.34 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5253226410793881		[learning rate: 0.007606]
		[batch 20/20] avg loss: 0.5726396392565938		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.5489811401679908 | validation: 0.6370059977830083]
	TIME [epoch: 8.36 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6059977228222647		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 0.6417372677734771		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.6238674952978708 | validation: 0.3495419706288463]
	TIME [epoch: 8.39 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4922023771374229		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 0.6981170494668459		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.5951597133021342 | validation: 0.4036288856744022]
	TIME [epoch: 8.35 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5853310263326875		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 0.45900629209016036		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.522168659211424 | validation: 0.45838420898845744]
	TIME [epoch: 8.36 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49568458928015807		[learning rate: 0.00746]
		[batch 20/20] avg loss: 0.40022907971603655		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.4479568344980973 | validation: 0.5774330674466003]
	TIME [epoch: 8.36 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45749067857690723		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 0.5497550624109464		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.5036228704939267 | validation: 0.4264061150756727]
	TIME [epoch: 8.37 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4302928913442452		[learning rate: 0.007388]
		[batch 20/20] avg loss: 0.5433203797484241		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.48680663554633463 | validation: 0.7890745351378532]
	TIME [epoch: 8.36 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43295994119838016		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 0.5123082861795594		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.47263411368896985 | validation: 0.8443192676011938]
	TIME [epoch: 8.38 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.439680694761175		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 0.5349862960865932		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.48733349542388404 | validation: 0.3313299703748414]
	TIME [epoch: 8.35 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43110952822089554		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 0.5276254650590997		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.47936749663999756 | validation: 0.576117017230847]
	TIME [epoch: 8.39 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6067084282121533		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 0.48284644115611536		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.5447774346841344 | validation: 0.4111460397242853]
	TIME [epoch: 8.37 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5040827911702618		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 0.5875063187465904		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.5457945549584261 | validation: 0.6646238622967298]
	TIME [epoch: 8.35 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5766373928380503		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 0.39926907471219186		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.4879532337751211 | validation: 0.48832693352662004]
	TIME [epoch: 8.37 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46422064977859534		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 0.43764859059687977		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.4509346201877375 | validation: 0.3162999675367247]
	TIME [epoch: 8.39 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4292130613064913		[learning rate: 0.007107]
		[batch 20/20] avg loss: 0.453077808456036		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.44114543488126357 | validation: 0.6429341741869354]
	TIME [epoch: 8.34 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8809414185852953		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 0.4694926539047362		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.6752170362450156 | validation: 0.4236833778965297]
	TIME [epoch: 8.35 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5764529664710104		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 0.4229767367194362		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.49971485159522333 | validation: 0.5843343307339565]
	TIME [epoch: 8.37 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4270238110301575		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 0.4691230852518739		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.4480734481410158 | validation: 0.9234198224931909]
	TIME [epoch: 8.37 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5490863625787049		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 0.5030559992107098		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.5260711808947074 | validation: 0.6817157706680478]
	TIME [epoch: 8.35 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4927345049204348		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 0.423774494661843		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.45825449979113886 | validation: 0.5425301691817673]
	TIME [epoch: 8.35 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.428532691479737		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 0.44718249598678383		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.4378575937332604 | validation: 0.3572848899359317]
	TIME [epoch: 8.37 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36066038291408153		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 0.592256491504233		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.4764584372091572 | validation: 0.3473358811729301]
	TIME [epoch: 8.37 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4784683094714495		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 0.4614153166224145		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.4699418130469321 | validation: 0.44991894051644904]
	TIME [epoch: 8.35 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4561808377140343		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 0.44502227298088837		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.45060155534746127 | validation: 1.1170696293401494]
	TIME [epoch: 8.36 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5186114883997678		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 0.40204474685403707		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.4603281176269024 | validation: 0.5258669753167539]
	TIME [epoch: 8.36 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41458412727052485		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 0.3878614051534214		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.40122276621197306 | validation: 0.3501709041742546]
	TIME [epoch: 8.37 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42399668976205396		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 0.4749639809544689		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.4494803353582614 | validation: 0.5843309151295221]
	TIME [epoch: 8.36 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5309021020293329		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 0.5172381771032317		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.5240701395662823 | validation: 0.4541426467318501]
	TIME [epoch: 8.37 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45511656798920663		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 0.4514329139310167		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.4532747409601117 | validation: 0.4747787035193096]
	TIME [epoch: 8.35 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4546598488917799		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 0.3855283805784924		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.42009411473513625 | validation: 0.449118002521542]
	TIME [epoch: 8.38 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45611156892063176		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 0.3829021987768371		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.41950688384873436 | validation: 0.3808630038544614]
	TIME [epoch: 8.41 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4022832345824103		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 0.45777813012461577		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.43003068235351316 | validation: 0.4303156571702437]
	TIME [epoch: 8.34 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.56839264883133		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 0.5220527582440775		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.5452227035377039 | validation: 0.40134095347267273]
	TIME [epoch: 8.35 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5383836221399603		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 0.36547922880889405		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.45193142547442705 | validation: 0.3022750815926224]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_140.pth
	Model improved!!!
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3707400451887237		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 0.39038325529721546		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.3805616502429695 | validation: 0.33539651720127783]
	TIME [epoch: 8.34 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.44951320734327166		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 0.48807525740206376		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.4687942323726677 | validation: 0.3829334130539725]
	TIME [epoch: 8.34 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40802940837164475		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 0.3889602873225674		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.39849484784710604 | validation: 0.43623942730186105]
	TIME [epoch: 8.36 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29858462128929275		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 0.5079405733222394		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.40326259730576614 | validation: 0.4427682078032602]
	TIME [epoch: 8.36 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4091879315080623		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 0.36048276214495056		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.3848353468265065 | validation: 0.3525125614316696]
	TIME [epoch: 8.34 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3898255718426705		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 0.32843650161234156		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.35913103672750607 | validation: 0.2550170599370534]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_146.pth
	Model improved!!!
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41072380560513244		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 0.6386856152504548		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.5247047104277935 | validation: 0.44212013420205115]
	TIME [epoch: 8.35 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41215052255426743		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 0.41783840195818867		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.41499446225622805 | validation: 0.5391935917818118]
	TIME [epoch: 8.37 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4086829794727612		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 0.3922756835759901		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.40047933152437565 | validation: 0.22026729980164686]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_149.pth
	Model improved!!!
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3568078302256269		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 0.37138866662304937		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.36409824842433813 | validation: 0.21959807404827836]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7196274505376289		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 0.9482525481704209		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.833939999354025 | validation: 0.7402175523951059]
	TIME [epoch: 8.34 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5355210122668623		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 0.5000230128466371		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.5177720125567498 | validation: 0.5425234191349175]
	TIME [epoch: 8.38 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38544589964815906		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 0.44980336917822605		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.41762463441319253 | validation: 0.273315030586148]
	TIME [epoch: 8.33 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46555500098821756		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 0.38779425098784254		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.4266746259880301 | validation: 0.41373172853124185]
	TIME [epoch: 8.34 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37428080791655793		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 0.385412381292226		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.379846594604392 | validation: 0.28708971005577943]
	TIME [epoch: 8.35 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3499165649728023		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 0.3282906178382011		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.3391035914055017 | validation: 0.2968096532957497]
	TIME [epoch: 8.36 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49469103709541723		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 0.41423264830859213		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.4544618427020047 | validation: 0.3556326850791248]
	TIME [epoch: 8.34 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42472628732193235		[learning rate: 0.00594]
		[batch 20/20] avg loss: 0.36015213687268155		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.3924392120973069 | validation: 0.39510059341256076]
	TIME [epoch: 8.35 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4850292021873063		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 0.37327761403827825		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.42915340811279223 | validation: 0.4032765096764426]
	TIME [epoch: 8.33 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39870732918008106		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 0.44100902352045723		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.4198581763502691 | validation: 0.46170846766161705]
	TIME [epoch: 8.35 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3357683197062061		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 0.40145843665935643		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.3686133781827813 | validation: 0.34175791659462407]
	TIME [epoch: 8.34 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3764866639588217		[learning rate: 0.005826]
		[batch 20/20] avg loss: 0.41338311911292813		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.3949348915358748 | validation: 0.29126050577590806]
	TIME [epoch: 8.35 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.40104072098721416		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 0.37940752139380607		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.39022412119051014 | validation: 0.5288379818102027]
	TIME [epoch: 8.33 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41865548458160895		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 0.28901560659919207		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.3538355455904004 | validation: 0.5006495946914014]
	TIME [epoch: 8.35 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41139646151270215		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 0.3460276120632898		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.37871203678799603 | validation: 0.9096223095318898]
	TIME [epoch: 8.33 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4778157119215566		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 0.3938483849039051		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.4358320484127309 | validation: 0.30312812263158667]
	TIME [epoch: 8.36 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36554851536525806		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 0.4331549384624024		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.3993517269138301 | validation: 0.6137520820102943]
	TIME [epoch: 8.34 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3574356644289005		[learning rate: 0.005659]
		[batch 20/20] avg loss: 0.33678075702751287		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.3471082107282067 | validation: 0.28541603907438856]
	TIME [epoch: 8.35 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31050582225580275		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 0.31794464891608853		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.3142252355859457 | validation: 0.20863391611521642]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_169.pth
	Model improved!!!
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.372180706627953		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.3420597847839391		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.357120245705946 | validation: 0.1794744213950989]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_170.pth
	Model improved!!!
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28599313722741		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.49558871717010283		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.39079092719875635 | validation: 0.41870207482366517]
	TIME [epoch: 8.38 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39564457454724977		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 0.3333178560461562		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.36448121529670297 | validation: 0.42014750502680565]
	TIME [epoch: 8.4 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3693170801106134		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.2602021636757786		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.31475962189319595 | validation: 0.2215836987586367]
	TIME [epoch: 8.39 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3725521099518478		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 0.3869048365594628		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.3797284732556553 | validation: 0.2712732011366847]
	TIME [epoch: 8.39 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36823989179394906		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 0.568340234988898		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.4682900633914235 | validation: 0.4029560560796064]
	TIME [epoch: 8.37 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36662600657801453		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.4468750935176892		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.4067505500478519 | validation: 0.6304170382774887]
	TIME [epoch: 8.41 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34804321020937534		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.3141618534563243		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.3311025318328497 | validation: 0.5836880625094543]
	TIME [epoch: 8.41 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2952957503296834		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 0.29978677793026287		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.29754126412997317 | validation: 0.261023041907131]
	TIME [epoch: 8.38 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39148841806105555		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 0.2742544735793276		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.3328714458201915 | validation: 0.3347933623490239]
	TIME [epoch: 8.37 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2801427650762691		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.30587407984060133		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.29300842245843517 | validation: 0.3389748538291396]
	TIME [epoch: 8.42 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3680933355043729		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 0.38050873545198427		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.3743010354781786 | validation: 0.36536732099519875]
	TIME [epoch: 8.4 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4377182566677571		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 0.41495525866441163		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.4263367576660844 | validation: 0.8116280843103643]
	TIME [epoch: 8.37 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43443408908381304		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 0.3448818225325693		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.38965795580819124 | validation: 0.2549868078101625]
	TIME [epoch: 8.37 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4217970551290862		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 0.4328166092060415		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.42730683216756377 | validation: 0.28593532175104963]
	TIME [epoch: 8.42 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5099336846389325		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.4091918126343817		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.45956274863665714 | validation: 0.3412260195795833]
	TIME [epoch: 8.4 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3276604726596012		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 0.28287487999647554		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.3052676763280383 | validation: 0.4354292363842982]
	TIME [epoch: 8.38 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34605537835807654		[learning rate: 0.005161]
		[batch 20/20] avg loss: 0.33719195445746086		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.34162366640776876 | validation: 0.311765447242522]
	TIME [epoch: 8.38 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29728108364360095		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.271451153681442		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.2843661186625215 | validation: 0.22544189537858247]
	TIME [epoch: 8.43 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33496899904259336		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 0.3514589960667448		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.34321399755466897 | validation: 0.19335820163045694]
	TIME [epoch: 8.38 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.312651959785449		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 0.33437456589721093		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.3235132628413301 | validation: 0.42946518119525195]
	TIME [epoch: 8.37 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3275459352569594		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 0.3299125117506485		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.3287292235038039 | validation: 0.2469642251609721]
	TIME [epoch: 8.4 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32282297852053643		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 0.30936362331117284		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.31609330091585464 | validation: 0.36840715967668763]
	TIME [epoch: 8.43 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3486716090569629		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.25054496562952017		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.29960828734324146 | validation: 0.302478685621779]
	TIME [epoch: 8.37 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3440082651876194		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 0.3115677779269665		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.32778802155729303 | validation: 0.5400850802007566]
	TIME [epoch: 8.38 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3830102610324387		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.3247347380707174		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.35387249955157796 | validation: 0.2938899639780405]
	TIME [epoch: 8.39 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3288988519215546		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 0.5763324570212509		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.45261565447140273 | validation: 0.374919349805239]
	TIME [epoch: 8.4 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29707400840291165		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 0.29688433002064557		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.2969791692117786 | validation: 0.5195728707893428]
	TIME [epoch: 8.39 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2933092510170173		[learning rate: 0.004893]
		[batch 20/20] avg loss: 0.3606635570838912		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.32698640405045426 | validation: 0.237443385589211]
	TIME [epoch: 8.4 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26964258819641335		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.318695509623925		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.2941690489101692 | validation: 0.2693181307724781]
	TIME [epoch: 8.37 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25488214496852335		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.3077508020754615		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.28131647352199246 | validation: 0.8055647772979226]
	TIME [epoch: 8.41 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31812430026995114		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 0.3248419728564823		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.32148313656321664 | validation: 0.48862934644253453]
	TIME [epoch: 8.4 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28871404158782343		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.27189909422634967		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.2803065679070865 | validation: 0.24549171614261794]
	TIME [epoch: 8.37 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3351339685461934		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.27105181713056564		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.3030928928383795 | validation: 0.352603546868108]
	TIME [epoch: 8.38 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25817532260901155		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.24644576837620352		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.25231054549260756 | validation: 0.31878154396978375]
	TIME [epoch: 8.43 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2595659592261509		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.3238513683830608		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.2917086638046058 | validation: 0.22135130794228705]
	TIME [epoch: 8.38 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.35527436546548635		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.384642064861349		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.36995821516341776 | validation: 0.3041739187535683]
	TIME [epoch: 8.38 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30946257501510166		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.3445461187641101		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.3270043468896059 | validation: 0.2647676940811976]
	TIME [epoch: 8.4 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25265295860412074		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 0.3325822878843636		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.29261762324424223 | validation: 0.6149121067164196]
	TIME [epoch: 8.43 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3478757764251096		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.21645788539410157		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.28216683090960565 | validation: 0.49059252072944737]
	TIME [epoch: 8.37 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2816105083581216		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 0.2946493918288721		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.28812995009349684 | validation: 0.1872105602259316]
	TIME [epoch: 8.39 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3227798394805144		[learning rate: 0.0045942]
		[batch 20/20] avg loss: 0.2715456016143968		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.2971627205474556 | validation: 0.2581932980038306]
	TIME [epoch: 8.41 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2617865576092002		[learning rate: 0.004572]
		[batch 20/20] avg loss: 0.3163659866667915		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.28907627213799586 | validation: 0.27700056497147657]
	TIME [epoch: 8.4 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2675043923564947		[learning rate: 0.0045499]
		[batch 20/20] avg loss: 0.26739883980172235		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.2674516160791084 | validation: 0.2736469944706709]
	TIME [epoch: 8.38 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22423265871798867		[learning rate: 0.0045279]
		[batch 20/20] avg loss: 0.3245351121385908		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.27438388542828973 | validation: 0.3723794271480092]
	TIME [epoch: 8.4 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3061933847802608		[learning rate: 0.004506]
		[batch 20/20] avg loss: 0.32242294716163944		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.3143081659709502 | validation: 0.3534377066711113]
	TIME [epoch: 8.4 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.384143965041342		[learning rate: 0.0044842]
		[batch 20/20] avg loss: 0.2744123786291864		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.3292781718352642 | validation: 0.5830830629998357]
	TIME [epoch: 8.39 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34257894087918966		[learning rate: 0.0044625]
		[batch 20/20] avg loss: 0.28265141979509656		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.31261518033714314 | validation: 0.16203766913508239]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_217.pth
	Model improved!!!
EPOCH 218/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3078650068169149		[learning rate: 0.0044409]
		[batch 20/20] avg loss: 0.2760102132199115		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.2919376100184133 | validation: 0.3628135152656592]
	TIME [epoch: 8.39 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3317232887553181		[learning rate: 0.0044195]
		[batch 20/20] avg loss: 0.23684766803215904		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.28428547839373863 | validation: 0.31416622909251823]
	TIME [epoch: 8.39 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23198273844309064		[learning rate: 0.0043981]
		[batch 20/20] avg loss: 0.257595706561646		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.2447892225023683 | validation: 0.32970086682206035]
	TIME [epoch: 8.38 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2658413814627075		[learning rate: 0.0043768]
		[batch 20/20] avg loss: 0.2484962189957654		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.2571688002292365 | validation: 0.16240191620695782]
	TIME [epoch: 8.39 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21686944887907927		[learning rate: 0.0043556]
		[batch 20/20] avg loss: 0.22952371918356396		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.22319658403132162 | validation: 0.1899625008271295]
	TIME [epoch: 8.38 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2512990559463541		[learning rate: 0.0043346]
		[batch 20/20] avg loss: 0.2686652929508463		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.2599821744486003 | validation: 0.2589011120448892]
	TIME [epoch: 8.39 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3216757915191574		[learning rate: 0.0043136]
		[batch 20/20] avg loss: 0.24961137540391048		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.28564358346153396 | validation: 0.3026323103541073]
	TIME [epoch: 8.4 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22353965252797417		[learning rate: 0.0042928]
		[batch 20/20] avg loss: 0.221305608131222		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.2224226303295981 | validation: 0.31828456363705887]
	TIME [epoch: 8.39 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20945262719142085		[learning rate: 0.004272]
		[batch 20/20] avg loss: 0.32866424793137883		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.2690584375613999 | validation: 0.3813063703597979]
	TIME [epoch: 8.37 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30539159670165167		[learning rate: 0.0042513]
		[batch 20/20] avg loss: 0.2707685618347765		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.2880800792682141 | validation: 0.5747787546141283]
	TIME [epoch: 8.39 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2877294757680856		[learning rate: 0.0042308]
		[batch 20/20] avg loss: 0.25088413781607927		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.2693068067920824 | validation: 0.2551353421869963]
	TIME [epoch: 8.39 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23699745038844502		[learning rate: 0.0042103]
		[batch 20/20] avg loss: 0.2925884272482088		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.26479293881832694 | validation: 0.6347692569496974]
	TIME [epoch: 8.38 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3311990109283965		[learning rate: 0.00419]
		[batch 20/20] avg loss: 0.3097761703898823		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.32048759065913934 | validation: 0.24977684886714263]
	TIME [epoch: 8.36 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2608554854380433		[learning rate: 0.0041697]
		[batch 20/20] avg loss: 0.23844229242817364		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.2496488889331085 | validation: 0.2508555413327995]
	TIME [epoch: 8.39 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23775795772097125		[learning rate: 0.0041495]
		[batch 20/20] avg loss: 0.2777603317851861		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.25775914475307865 | validation: 0.26218532591276]
	TIME [epoch: 8.41 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27651624678301673		[learning rate: 0.0041295]
		[batch 20/20] avg loss: 0.26816413293797076		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.27234018986049374 | validation: 0.23664570652547132]
	TIME [epoch: 8.37 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24706248938492878		[learning rate: 0.0041095]
		[batch 20/20] avg loss: 0.20928449780683142		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.22817349359588013 | validation: 0.2446164040088994]
	TIME [epoch: 8.37 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3645116034611819		[learning rate: 0.0040896]
		[batch 20/20] avg loss: 0.23407406621768626		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.2992928348394341 | validation: 0.3856436602742537]
	TIME [epoch: 8.4 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2798686046213878		[learning rate: 0.0040699]
		[batch 20/20] avg loss: 0.23616133612697698		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.2580149703741824 | validation: 0.26736501903193577]
	TIME [epoch: 8.38 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23485718272837267		[learning rate: 0.0040502]
		[batch 20/20] avg loss: 0.3156319298623948		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.2752445562953837 | validation: 0.44101192187856475]
	TIME [epoch: 8.36 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25485421949746206		[learning rate: 0.0040306]
		[batch 20/20] avg loss: 0.2536790740911996		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.2542666467943308 | validation: 0.17445554615253406]
	TIME [epoch: 8.38 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3103829888396123		[learning rate: 0.0040111]
		[batch 20/20] avg loss: 0.313069376335958		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.31172618258778517 | validation: 0.18356887763017113]
	TIME [epoch: 8.39 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2246739000217676		[learning rate: 0.0039917]
		[batch 20/20] avg loss: 0.28961634835241895		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.25714512418709334 | validation: 0.15638968705603395]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_240.pth
	Model improved!!!
EPOCH 241/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2478337826674276		[learning rate: 0.0039724]
		[batch 20/20] avg loss: 0.3300527758822142		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.2889432792748209 | validation: 0.23435616466095138]
	TIME [epoch: 8.37 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3326172217140795		[learning rate: 0.0039532]
		[batch 20/20] avg loss: 0.2630028026628253		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.29781001218845243 | validation: 0.2645104090505326]
	TIME [epoch: 8.38 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24236296032444846		[learning rate: 0.0039341]
		[batch 20/20] avg loss: 0.17896882984194842		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.21066589508319847 | validation: 0.7242753178594772]
	TIME [epoch: 8.38 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3160702412809662		[learning rate: 0.003915]
		[batch 20/20] avg loss: 0.24952618725122044		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.28279821426609336 | validation: 0.16513914491781267]
	TIME [epoch: 8.4 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2606963633560567		[learning rate: 0.0038961]
		[batch 20/20] avg loss: 0.23016126584896396		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.24542881460251037 | validation: 0.4655295724923228]
	TIME [epoch: 8.39 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31435345453968633		[learning rate: 0.0038773]
		[batch 20/20] avg loss: 0.24724607256304482		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.2807997635513656 | validation: 0.24975577909134944]
	TIME [epoch: 8.39 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21260766416347487		[learning rate: 0.0038585]
		[batch 20/20] avg loss: 0.23199037568086428		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.22229901992216955 | validation: 0.6380058963195656]
	TIME [epoch: 8.42 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2678900292277512		[learning rate: 0.0038399]
		[batch 20/20] avg loss: 0.23070142945178587		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.24929572933976857 | validation: 0.3423167835875911]
	TIME [epoch: 8.4 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22645698745139553		[learning rate: 0.0038213]
		[batch 20/20] avg loss: 0.22869991010884805		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.2275784487801218 | validation: 0.16064212356310476]
	TIME [epoch: 8.39 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23755669950350505		[learning rate: 0.0038028]
		[batch 20/20] avg loss: 0.238276428214005		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.23791656385875498 | validation: 0.20145832918772758]
	TIME [epoch: 8.38 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27285147688351785		[learning rate: 0.0037844]
		[batch 20/20] avg loss: 0.1845135773239112		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.2286825271037145 | validation: 0.32277590737495904]
	TIME [epoch: 8.39 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23215525666746487		[learning rate: 0.0037661]
		[batch 20/20] avg loss: 0.24303943940079206		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.2375973480341284 | validation: 0.5088551106897977]
	TIME [epoch: 8.37 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2824937373492566		[learning rate: 0.0037479]
		[batch 20/20] avg loss: 0.2532301900325866		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.26786196369092163 | validation: 0.23956635344311056]
	TIME [epoch: 8.39 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2243216211947779		[learning rate: 0.0037298]
		[batch 20/20] avg loss: 0.23667373252640572		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.2304976768605918 | validation: 0.30709361797371126]
	TIME [epoch: 8.36 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2989154086859095		[learning rate: 0.0037118]
		[batch 20/20] avg loss: 0.2637446380623098		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.2813300233741097 | validation: 0.23359375595271892]
	TIME [epoch: 8.41 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2880407346966195		[learning rate: 0.0036938]
		[batch 20/20] avg loss: 0.278053283826139		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.2830470092613792 | validation: 0.18490791048818256]
	TIME [epoch: 8.4 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2105191632506615		[learning rate: 0.0036759]
		[batch 20/20] avg loss: 0.27802967521285804		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.24427441923175972 | validation: 0.34096427974895277]
	TIME [epoch: 8.36 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27747603283591415		[learning rate: 0.0036582]
		[batch 20/20] avg loss: 0.23131849987154865		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.2543972663537314 | validation: 0.3631783425273595]
	TIME [epoch: 8.39 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2620448330760946		[learning rate: 0.0036405]
		[batch 20/20] avg loss: 0.18600820752893643		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.22402652030251552 | validation: 0.15071854550894265]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_259.pth
	Model improved!!!
EPOCH 260/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2193105732474573		[learning rate: 0.0036229]
		[batch 20/20] avg loss: 0.18470916317681801		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.20200986821213768 | validation: 0.2228250182707019]
	TIME [epoch: 8.38 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.259366263055234		[learning rate: 0.0036053]
		[batch 20/20] avg loss: 0.21394709366813927		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.23665667836168663 | validation: 0.23663271506746367]
	TIME [epoch: 8.39 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22820967795003022		[learning rate: 0.0035879]
		[batch 20/20] avg loss: 0.17865542283781613		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.20343255039392316 | validation: 0.38706259886697]
	TIME [epoch: 8.37 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.287364193250526		[learning rate: 0.0035706]
		[batch 20/20] avg loss: 0.24357331891992445		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.26546875608522524 | validation: 0.13204137231707436]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_263.pth
	Model improved!!!
EPOCH 264/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18961514892956227		[learning rate: 0.0035533]
		[batch 20/20] avg loss: 0.22979477311034632		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.20970496101995426 | validation: 0.23070115718338524]
	TIME [epoch: 8.38 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19041001962766407		[learning rate: 0.0035361]
		[batch 20/20] avg loss: 0.297502392266194		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.243956205946929 | validation: 0.19660533616286738]
	TIME [epoch: 8.37 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19072037051445598		[learning rate: 0.003519]
		[batch 20/20] avg loss: 0.23993172709221106		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.21532604880333345 | validation: 0.28533295550435334]
	TIME [epoch: 8.39 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22008474913624054		[learning rate: 0.003502]
		[batch 20/20] avg loss: 0.2008589533415769		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.21047185123890877 | validation: 0.14982498299139968]
	TIME [epoch: 8.39 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2062082716617178		[learning rate: 0.0034851]
		[batch 20/20] avg loss: 0.26808527547226435		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.237146773566991 | validation: 0.45624979865290083]
	TIME [epoch: 8.38 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26117226758387363		[learning rate: 0.0034682]
		[batch 20/20] avg loss: 0.1696584233448706		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.21541534546437208 | validation: 0.25028556602008817]
	TIME [epoch: 8.39 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21230570370543203		[learning rate: 0.0034514]
		[batch 20/20] avg loss: 0.2141026646538507		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.2132041841796414 | validation: 0.26515778365877174]
	TIME [epoch: 8.37 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.211096434729431		[learning rate: 0.0034347]
		[batch 20/20] avg loss: 0.16960471700491495		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.19035057586717294 | validation: 0.18473258308405885]
	TIME [epoch: 8.4 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23779546914215244		[learning rate: 0.0034181]
		[batch 20/20] avg loss: 0.2026577533437149		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.2202266112429337 | validation: 0.23423012043928093]
	TIME [epoch: 8.39 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2223566014118335		[learning rate: 0.0034016]
		[batch 20/20] avg loss: 0.22327753510505827		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.22281706825844588 | validation: 0.33172055794358724]
	TIME [epoch: 8.36 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2203838677419828		[learning rate: 0.0033852]
		[batch 20/20] avg loss: 0.19948233142481087		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.20993309958339684 | validation: 0.19040736357676427]
	TIME [epoch: 8.39 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2087264235092488		[learning rate: 0.0033688]
		[batch 20/20] avg loss: 0.2561823961757398		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.23245440984249433 | validation: 0.210310795874793]
	TIME [epoch: 8.4 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2963727780908407		[learning rate: 0.0033525]
		[batch 20/20] avg loss: 0.19912070744666419		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.24774674276875247 | validation: 0.20472643975627522]
	TIME [epoch: 8.36 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2515414976043773		[learning rate: 0.0033363]
		[batch 20/20] avg loss: 0.19429370267195922		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.22291760013816822 | validation: 0.17527462409510816]
	TIME [epoch: 8.38 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19517662118175166		[learning rate: 0.0033202]
		[batch 20/20] avg loss: 0.20232664589255694		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.19875163353715428 | validation: 0.2134590448016969]
	TIME [epoch: 8.37 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2047697807210307		[learning rate: 0.0033041]
		[batch 20/20] avg loss: 0.21564555612345462		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.21020766842224264 | validation: 0.17071048781774095]
	TIME [epoch: 8.39 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.249045894991304		[learning rate: 0.0032881]
		[batch 20/20] avg loss: 0.22897864841007265		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.2390122717006883 | validation: 0.15388695339306163]
	TIME [epoch: 8.39 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19281653877304844		[learning rate: 0.0032722]
		[batch 20/20] avg loss: 0.15977122290791623		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.17629388084048236 | validation: 0.4336959486561766]
	TIME [epoch: 8.37 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29761830749997986		[learning rate: 0.0032564]
		[batch 20/20] avg loss: 0.2038085166017421		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.25071341205086095 | validation: 0.3627061281388926]
	TIME [epoch: 8.36 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21699880297015897		[learning rate: 0.0032406]
		[batch 20/20] avg loss: 0.265939689431435		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.24146924620079696 | validation: 0.4916823927496298]
	TIME [epoch: 8.41 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2566759062682184		[learning rate: 0.003225]
		[batch 20/20] avg loss: 0.189856688916132		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.22326629759217523 | validation: 0.3961588049696824]
	TIME [epoch: 8.36 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23379897305437747		[learning rate: 0.0032094]
		[batch 20/20] avg loss: 0.2148702031569209		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.22433458810564924 | validation: 0.27214148708834507]
	TIME [epoch: 8.36 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20285496687699123		[learning rate: 0.0031939]
		[batch 20/20] avg loss: 0.1948371635809208		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.198846065228956 | validation: 0.16422125776145224]
	TIME [epoch: 8.38 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21371531840268018		[learning rate: 0.0031784]
		[batch 20/20] avg loss: 0.21489460111274541		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.21430495975771274 | validation: 0.27605458723541393]
	TIME [epoch: 8.4 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21753073213455928		[learning rate: 0.003163]
		[batch 20/20] avg loss: 0.18928169566713593		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.20340621390084762 | validation: 0.25860823977202807]
	TIME [epoch: 8.36 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2329479031281009		[learning rate: 0.0031477]
		[batch 20/20] avg loss: 0.2040047566289977		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.2184763298785493 | validation: 0.2666711893961841]
	TIME [epoch: 8.37 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20994584551394543		[learning rate: 0.0031325]
		[batch 20/20] avg loss: 0.20009848973816688		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.20502216762605613 | validation: 0.25041586821595835]
	TIME [epoch: 8.38 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24747573709835136		[learning rate: 0.0031174]
		[batch 20/20] avg loss: 0.3285296665819785		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.28800270184016497 | validation: 0.20010415734046125]
	TIME [epoch: 8.4 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23118907816008333		[learning rate: 0.0031023]
		[batch 20/20] avg loss: 0.2705329045555146		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.25086099135779893 | validation: 0.194452824045373]
	TIME [epoch: 8.36 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16737552752947027		[learning rate: 0.0030873]
		[batch 20/20] avg loss: 0.20183162313615735		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.18460357533281382 | validation: 0.1703764397069744]
	TIME [epoch: 8.37 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18747876418316028		[learning rate: 0.0030724]
		[batch 20/20] avg loss: 0.19786273242084879		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.19267074830200454 | validation: 0.2441080305290848]
	TIME [epoch: 8.38 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21585925799673739		[learning rate: 0.0030575]
		[batch 20/20] avg loss: 0.18376603985824008		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.1998126489274887 | validation: 0.21682738020788228]
	TIME [epoch: 8.39 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16848087620562097		[learning rate: 0.0030427]
		[batch 20/20] avg loss: 0.17306216175656466		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.17077151898109283 | validation: 0.1443228554026733]
	TIME [epoch: 8.38 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1784270072500517		[learning rate: 0.003028]
		[batch 20/20] avg loss: 0.16328015949636512		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.17085358337320838 | validation: 0.1880484310843329]
	TIME [epoch: 8.38 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24900624925725187		[learning rate: 0.0030134]
		[batch 20/20] avg loss: 0.22845889183306034		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.2387325705451561 | validation: 0.18928167835433143]
	TIME [epoch: 8.35 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19756980307817082		[learning rate: 0.0029988]
		[batch 20/20] avg loss: 0.18402621200145544		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.19079800753981316 | validation: 0.17197122713622254]
	TIME [epoch: 8.39 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16722908066964853		[learning rate: 0.0029843]
		[batch 20/20] avg loss: 0.18255418289637643		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.17489163178301248 | validation: 0.1579360197819598]
	TIME [epoch: 8.38 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19894506522625038		[learning rate: 0.0029699]
		[batch 20/20] avg loss: 0.16872906675217053		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.18383706598921043 | validation: 0.20968880243770088]
	TIME [epoch: 8.37 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26692812519796616		[learning rate: 0.0029555]
		[batch 20/20] avg loss: 0.17353064448996064		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.22022938484396343 | validation: 0.21397330678032722]
	TIME [epoch: 8.36 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19908173517056715		[learning rate: 0.0029412]
		[batch 20/20] avg loss: 0.21212280222889177		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.20560226869972947 | validation: 0.3364285592959549]
	TIME [epoch: 8.41 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23274221204988402		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.19069704786374073		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.2117196299568124 | validation: 0.16581690744910677]
	TIME [epoch: 8.38 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23225299139222133		[learning rate: 0.0029128]
		[batch 20/20] avg loss: 0.1984965290918135		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.21537476024201738 | validation: 0.17504444507949835]
	TIME [epoch: 8.36 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17533381771212503		[learning rate: 0.0028987]
		[batch 20/20] avg loss: 0.20241455318011722		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.18887418544612114 | validation: 0.1903428093400216]
	TIME [epoch: 8.36 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2371815198447978		[learning rate: 0.0028847]
		[batch 20/20] avg loss: 0.15767155976387753		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.1974265398043376 | validation: 0.18252432104271044]
	TIME [epoch: 8.42 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17642663702236122		[learning rate: 0.0028708]
		[batch 20/20] avg loss: 0.21084554012240048		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.19363608857238088 | validation: 0.1752756408228558]
	TIME [epoch: 8.37 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16862745350352745		[learning rate: 0.0028569]
		[batch 20/20] avg loss: 0.19689887932192301		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.18276316641272522 | validation: 0.19849791403988842]
	TIME [epoch: 8.36 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18303151916160992		[learning rate: 0.0028431]
		[batch 20/20] avg loss: 0.16956785642927394		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.17629968779544192 | validation: 0.15148360956060813]
	TIME [epoch: 8.39 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.167122515299213		[learning rate: 0.0028293]
		[batch 20/20] avg loss: 0.2603593618243896		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.2137409385618013 | validation: 0.34852838201301667]
	TIME [epoch: 8.39 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19200394317580188		[learning rate: 0.0028157]
		[batch 20/20] avg loss: 0.1648879375858484		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.17844594038082512 | validation: 0.16119442351342764]
	TIME [epoch: 8.36 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16049645632202802		[learning rate: 0.002802]
		[batch 20/20] avg loss: 0.19713630619188838		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.17881638125695817 | validation: 0.22792331168702207]
	TIME [epoch: 8.38 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17620635087989353		[learning rate: 0.0027885]
		[batch 20/20] avg loss: 0.15318203830854232		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.16469419459421794 | validation: 0.21731635610002473]
	TIME [epoch: 8.38 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20297416333303295		[learning rate: 0.002775]
		[batch 20/20] avg loss: 0.18414730734483806		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.1935607353389355 | validation: 0.15906976260085423]
	TIME [epoch: 8.38 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2086129948920588		[learning rate: 0.0027616]
		[batch 20/20] avg loss: 0.20296583352892825		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.20578941421049354 | validation: 0.2953907222333526]
	TIME [epoch: 8.36 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23918763387970537		[learning rate: 0.0027482]
		[batch 20/20] avg loss: 0.2102890941374115		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.22473836400855846 | validation: 0.3353737507044731]
	TIME [epoch: 8.38 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19912331790639493		[learning rate: 0.0027349]
		[batch 20/20] avg loss: 0.23856645144975336		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.21884488467807411 | validation: 0.3881568835497912]
	TIME [epoch: 8.38 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21482351383710513		[learning rate: 0.0027217]
		[batch 20/20] avg loss: 0.22144665974373412		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.21813508679041957 | validation: 0.23957574623209027]
	TIME [epoch: 8.37 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2044353649631408		[learning rate: 0.0027086]
		[batch 20/20] avg loss: 0.1971990446133059		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.20081720478822335 | validation: 0.15917851201429348]
	TIME [epoch: 8.37 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16975384334619315		[learning rate: 0.0026955]
		[batch 20/20] avg loss: 0.20941886739351231		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.18958635536985274 | validation: 0.15383907903585708]
	TIME [epoch: 8.37 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16239712862069797		[learning rate: 0.0026824]
		[batch 20/20] avg loss: 0.1604994374257677		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.16144828302323283 | validation: 0.22559060750126061]
	TIME [epoch: 8.37 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1897274956044027		[learning rate: 0.0026694]
		[batch 20/20] avg loss: 0.16246240758494807		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.1760949515946754 | validation: 0.23640879907780574]
	TIME [epoch: 8.37 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17733132800837856		[learning rate: 0.0026565]
		[batch 20/20] avg loss: 0.165910992989988		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.17162116049918325 | validation: 0.1652189339282562]
	TIME [epoch: 8.38 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18460172428803828		[learning rate: 0.0026437]
		[batch 20/20] avg loss: 0.1895662528713667		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.1870839885797025 | validation: 0.21045909837653254]
	TIME [epoch: 8.36 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19486107239297626		[learning rate: 0.0026309]
		[batch 20/20] avg loss: 0.17061928063449164		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.18274017651373398 | validation: 0.3295184755600366]
	TIME [epoch: 8.38 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1935521547416924		[learning rate: 0.0026182]
		[batch 20/20] avg loss: 0.19264060680060954		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.19309638077115096 | validation: 0.1695983304163507]
	TIME [epoch: 8.4 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1730489547900166		[learning rate: 0.0026055]
		[batch 20/20] avg loss: 0.17795703646277433		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.17550299562639543 | validation: 0.23095533618795663]
	TIME [epoch: 8.37 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1592995119552145		[learning rate: 0.0025929]
		[batch 20/20] avg loss: 0.13752169606071146		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.148410604007963 | validation: 0.16197313905017535]
	TIME [epoch: 8.35 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18572848511195947		[learning rate: 0.0025804]
		[batch 20/20] avg loss: 0.15387809816190104		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.16980329163693025 | validation: 0.3258338897112336]
	TIME [epoch: 8.39 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1912163934849595		[learning rate: 0.0025679]
		[batch 20/20] avg loss: 0.14820527034488953		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.16971083191492448 | validation: 0.19163826504600462]
	TIME [epoch: 8.37 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18016328338314053		[learning rate: 0.0025555]
		[batch 20/20] avg loss: 0.19830173007236535		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.189232506727753 | validation: 0.2751496614818444]
	TIME [epoch: 8.35 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29328975874321495		[learning rate: 0.0025431]
		[batch 20/20] avg loss: 0.18933988411416017		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.2413148214286875 | validation: 0.1508454196376961]
	TIME [epoch: 8.38 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17425236205261946		[learning rate: 0.0025308]
		[batch 20/20] avg loss: 0.17557482230173155		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.17491359217717548 | validation: 0.22474036083767393]
	TIME [epoch: 8.38 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18572708245146277		[learning rate: 0.0025186]
		[batch 20/20] avg loss: 0.13196772252852512		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.15884740248999393 | validation: 0.16282339712466126]
	TIME [epoch: 8.37 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19723188084852933		[learning rate: 0.0025064]
		[batch 20/20] avg loss: 0.18384890297112194		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.1905403919098256 | validation: 0.12443028726918046]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_336.pth
	Model improved!!!
EPOCH 337/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14554190565814923		[learning rate: 0.0024943]
		[batch 20/20] avg loss: 0.15290539446023554		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.1492236500591924 | validation: 0.1684854176094464]
	TIME [epoch: 8.35 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1747734118756739		[learning rate: 0.0024822]
		[batch 20/20] avg loss: 0.15351445023627394		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.16414393105597394 | validation: 0.1617963441480415]
	TIME [epoch: 8.37 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15992663577256577		[learning rate: 0.0024702]
		[batch 20/20] avg loss: 0.15019444398301285		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.1550605398777893 | validation: 0.19602197963385729]
	TIME [epoch: 8.38 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18942179867042847		[learning rate: 0.0024583]
		[batch 20/20] avg loss: 0.2096251595718503		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.19952347912113938 | validation: 0.17047672836424405]
	TIME [epoch: 8.35 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16804278892033797		[learning rate: 0.0024464]
		[batch 20/20] avg loss: 0.1452279695361188		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.15663537922822837 | validation: 0.15075840898191759]
	TIME [epoch: 8.35 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16021158271157804		[learning rate: 0.0024346]
		[batch 20/20] avg loss: 0.16839156172802333		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.16430157221980068 | validation: 0.17244399580749128]
	TIME [epoch: 8.39 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16244381168054678		[learning rate: 0.0024228]
		[batch 20/20] avg loss: 0.1635557477970935		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.1629997797388201 | validation: 0.20564403142898577]
	TIME [epoch: 8.36 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15970858836125074		[learning rate: 0.0024111]
		[batch 20/20] avg loss: 0.1600968591661835		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.15990272376371711 | validation: 0.18784825222069665]
	TIME [epoch: 8.34 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16628223473892295		[learning rate: 0.0023994]
		[batch 20/20] avg loss: 0.1894414840585384		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.17786185939873067 | validation: 0.22337323775491863]
	TIME [epoch: 8.37 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16082636457859792		[learning rate: 0.0023878]
		[batch 20/20] avg loss: 0.17254978064477627		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.16668807261168708 | validation: 0.13089136927672246]
	TIME [epoch: 8.37 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1573113431797182		[learning rate: 0.0023763]
		[batch 20/20] avg loss: 0.15391032373213703		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.1556108334559276 | validation: 0.13849499411982688]
	TIME [epoch: 8.35 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19043665258226175		[learning rate: 0.0023648]
		[batch 20/20] avg loss: 0.16636408832692332		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.1784003704545925 | validation: 0.2317558012902425]
	TIME [epoch: 8.36 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1388137113735059		[learning rate: 0.0023533]
		[batch 20/20] avg loss: 0.1959655603425211		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.1673896358580135 | validation: 0.26224960548274606]
	TIME [epoch: 8.35 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20076369497535218		[learning rate: 0.002342]
		[batch 20/20] avg loss: 0.17187005160364296		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.1863168732894976 | validation: 0.15374539002893875]
	TIME [epoch: 8.36 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2280797046680647		[learning rate: 0.0023306]
		[batch 20/20] avg loss: 0.18607842115314316		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.2070790629106039 | validation: 0.1717956263206107]
	TIME [epoch: 8.37 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1634914786703477		[learning rate: 0.0023194]
		[batch 20/20] avg loss: 0.18488818327713763		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.17418983097374266 | validation: 0.1879200372461514]
	TIME [epoch: 8.36 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1729541526295188		[learning rate: 0.0023081]
		[batch 20/20] avg loss: 0.16189985708918844		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.16742700485935363 | validation: 0.22084005950795377]
	TIME [epoch: 8.34 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14894212031633985		[learning rate: 0.002297]
		[batch 20/20] avg loss: 0.15190994640527658		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.1504260333608082 | validation: 0.13327128920954018]
	TIME [epoch: 8.37 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13012764327497237		[learning rate: 0.0022859]
		[batch 20/20] avg loss: 0.1550526144096421		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.14259012884230723 | validation: 0.31607925396706804]
	TIME [epoch: 8.38 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1935535961650741		[learning rate: 0.0022748]
		[batch 20/20] avg loss: 0.1779703606277347		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.18576197839640435 | validation: 0.15295707042530196]
	TIME [epoch: 8.35 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1780911740113981		[learning rate: 0.0022638]
		[batch 20/20] avg loss: 0.23514197546061708		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.20661657473600764 | validation: 0.12136377967040471]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_357.pth
	Model improved!!!
EPOCH 358/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15853049029471117		[learning rate: 0.0022529]
		[batch 20/20] avg loss: 0.15540243726034583		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.1569664637775285 | validation: 0.2060393767157454]
	TIME [epoch: 8.38 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15287795258569312		[learning rate: 0.002242]
		[batch 20/20] avg loss: 0.17724393071268435		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.16506094164918872 | validation: 0.12942765375504628]
	TIME [epoch: 8.37 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20048311784915404		[learning rate: 0.0022311]
		[batch 20/20] avg loss: 0.16708071855720902		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.18378191820318154 | validation: 0.12976048123496287]
	TIME [epoch: 8.34 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17374937567084975		[learning rate: 0.0022203]
		[batch 20/20] avg loss: 0.197293288569793		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.1855213321203214 | validation: 0.2123793235905301]
	TIME [epoch: 8.34 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1578449692741922		[learning rate: 0.0022096]
		[batch 20/20] avg loss: 0.1733469786062722		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.16559597394023223 | validation: 0.2561494840157732]
	TIME [epoch: 8.38 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15290660798982333		[learning rate: 0.0021989]
		[batch 20/20] avg loss: 0.16614064024663866		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.159523624118231 | validation: 0.1540139264642372]
	TIME [epoch: 8.36 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1733715531210637		[learning rate: 0.0021883]
		[batch 20/20] avg loss: 0.1642821482112673		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.1688268506661655 | validation: 0.15967274560907216]
	TIME [epoch: 8.35 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17192392481219249		[learning rate: 0.0021777]
		[batch 20/20] avg loss: 0.14727559436881896		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.1595997595905057 | validation: 0.15538186254348627]
	TIME [epoch: 8.35 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14237113636679327		[learning rate: 0.0021672]
		[batch 20/20] avg loss: 0.14742532489009724		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.14489823062844526 | validation: 0.19188889097141604]
	TIME [epoch: 8.39 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14729702604471712		[learning rate: 0.0021567]
		[batch 20/20] avg loss: 0.15151691010183557		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.1494069680732763 | validation: 0.1877105683829962]
	TIME [epoch: 8.36 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19045882855983498		[learning rate: 0.0021463]
		[batch 20/20] avg loss: 0.15561409589789207		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.17303646222886354 | validation: 0.20876948087501132]
	TIME [epoch: 8.34 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1628876714650229		[learning rate: 0.0021359]
		[batch 20/20] avg loss: 0.16508519155917728		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.16398643151210007 | validation: 0.18251167699449605]
	TIME [epoch: 8.36 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1500254140202287		[learning rate: 0.0021256]
		[batch 20/20] avg loss: 0.13017674047251562		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.14010107724637216 | validation: 0.13524122483119488]
	TIME [epoch: 8.39 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19148936197553595		[learning rate: 0.0021153]
		[batch 20/20] avg loss: 0.16295193446342304		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.17722064821947953 | validation: 0.1880240101729035]
	TIME [epoch: 8.36 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1365914736081125		[learning rate: 0.0021051]
		[batch 20/20] avg loss: 0.14139681832094542		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.13899414596452894 | validation: 0.13219328699049043]
	TIME [epoch: 8.35 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12942586114258897		[learning rate: 0.0020949]
		[batch 20/20] avg loss: 0.16859179685667716		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.14900882899963303 | validation: 0.23723841798076095]
	TIME [epoch: 8.37 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15759542780573704		[learning rate: 0.0020847]
		[batch 20/20] avg loss: 0.1490594796856489		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.15332745374569298 | validation: 0.16558134319822287]
	TIME [epoch: 8.38 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15078400604078013		[learning rate: 0.0020747]
		[batch 20/20] avg loss: 0.13691344694189514		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.14384872649133768 | validation: 0.18648961729770297]
	TIME [epoch: 8.34 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16824652524328482		[learning rate: 0.0020646]
		[batch 20/20] avg loss: 0.18253115405352205		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.17538883964840346 | validation: 0.18517093021875944]
	TIME [epoch: 8.36 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1576911611005334		[learning rate: 0.0020546]
		[batch 20/20] avg loss: 0.15968583208068463		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.15868849659060905 | validation: 0.1824795724738664]
	TIME [epoch: 8.37 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17837880807111955		[learning rate: 0.0020447]
		[batch 20/20] avg loss: 0.15865545704452716		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.16851713255782336 | validation: 0.20899747612381236]
	TIME [epoch: 8.38 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1850754306208723		[learning rate: 0.0020348]
		[batch 20/20] avg loss: 0.1791972868145225		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.18213635871769746 | validation: 0.389561918146772]
	TIME [epoch: 8.36 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1688565455964745		[learning rate: 0.002025]
		[batch 20/20] avg loss: 0.13313309560301756		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.15099482059974606 | validation: 0.18934569673271212]
	TIME [epoch: 8.37 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16396171172877022		[learning rate: 0.0020152]
		[batch 20/20] avg loss: 0.15891061391142952		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.1614361628200999 | validation: 0.20185049397192537]
	TIME [epoch: 8.36 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13471994445026209		[learning rate: 0.0020054]
		[batch 20/20] avg loss: 0.17715294681666466		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.1559364456334634 | validation: 0.25994664432549974]
	TIME [epoch: 8.37 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15021109307065456		[learning rate: 0.0019957]
		[batch 20/20] avg loss: 0.16355939452888668		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.15688524379977065 | validation: 0.2351823639335931]
	TIME [epoch: 8.36 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19173758350174205		[learning rate: 0.0019861]
		[batch 20/20] avg loss: 0.13971347579776955		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.16572552964975584 | validation: 0.15416178544436465]
	TIME [epoch: 8.38 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1444515671097091		[learning rate: 0.0019765]
		[batch 20/20] avg loss: 0.12581835129833033		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.1351349592040197 | validation: 0.1656869861856943]
	TIME [epoch: 8.35 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16195904973742534		[learning rate: 0.0019669]
		[batch 20/20] avg loss: 0.15900797861435895		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.16048351417589218 | validation: 0.17514567178086335]
	TIME [epoch: 8.38 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18699741254898197		[learning rate: 0.0019574]
		[batch 20/20] avg loss: 0.18623414487479778		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.1866157787118899 | validation: 0.1450017851617274]
	TIME [epoch: 8.38 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14323992842146926		[learning rate: 0.001948]
		[batch 20/20] avg loss: 0.17277923392680786		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.15800958117413857 | validation: 0.14915362139074173]
	TIME [epoch: 8.36 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15428644012226111		[learning rate: 0.0019385]
		[batch 20/20] avg loss: 0.1265776815094494		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.14043206081585524 | validation: 0.16334931141501027]
	TIME [epoch: 8.35 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1560763512138745		[learning rate: 0.0019292]
		[batch 20/20] avg loss: 0.15458729043037686		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.15533182082212568 | validation: 0.14224202880654313]
	TIME [epoch: 8.39 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12736999340959393		[learning rate: 0.0019198]
		[batch 20/20] avg loss: 0.16883357705319652		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.14810178523139522 | validation: 0.16365596882437727]
	TIME [epoch: 8.38 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17428704101066467		[learning rate: 0.0019105]
		[batch 20/20] avg loss: 0.1473930644184855		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.16084005271457508 | validation: 0.16793018017109806]
	TIME [epoch: 8.35 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14317414891084734		[learning rate: 0.0019013]
		[batch 20/20] avg loss: 0.20175257658316056		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.17246336274700397 | validation: 0.1599347758048515]
	TIME [epoch: 8.37 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13744770307274562		[learning rate: 0.0018921]
		[batch 20/20] avg loss: 0.1526390392377055		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.1450433711552256 | validation: 0.17225784562807517]
	TIME [epoch: 8.4 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11834195678393007		[learning rate: 0.001883]
		[batch 20/20] avg loss: 0.16313831797511966		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.14074013737952482 | validation: 0.16910169395280392]
	TIME [epoch: 8.36 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13505093275626529		[learning rate: 0.0018739]
		[batch 20/20] avg loss: 0.1392018041745286		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.13712636846539691 | validation: 0.167224946124628]
	TIME [epoch: 8.36 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14584123214136674		[learning rate: 0.0018648]
		[batch 20/20] avg loss: 0.14391298547479878		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.14487710880808274 | validation: 0.21677744688462197]
	TIME [epoch: 8.38 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14476316266856828		[learning rate: 0.0018558]
		[batch 20/20] avg loss: 0.14148890281291043		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.14312603274073937 | validation: 0.13605834717840118]
	TIME [epoch: 8.39 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15024909994611857		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.12905921460185904		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.1396541572739888 | validation: 0.11314299216282941]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_399.pth
	Model improved!!!
EPOCH 400/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1198935475269852		[learning rate: 0.0018379]
		[batch 20/20] avg loss: 0.1399304124619969		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.12991197999449106 | validation: 0.12503504717399078]
	TIME [epoch: 8.38 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11075253604476931		[learning rate: 0.001829]
		[batch 20/20] avg loss: 0.14920746760609377		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.1299800018254315 | validation: 0.10913451939319395]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_401.pth
	Model improved!!!
EPOCH 402/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13033737144553637		[learning rate: 0.0018201]
		[batch 20/20] avg loss: 0.16308672562923496		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.14671204853738565 | validation: 0.16636436180090847]
	TIME [epoch: 8.37 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15118664159312348		[learning rate: 0.0018113]
		[batch 20/20] avg loss: 0.1276914235562317		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.13943903257467757 | validation: 0.1384793082774247]
	TIME [epoch: 8.37 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12528802885776724		[learning rate: 0.0018026]
		[batch 20/20] avg loss: 0.13818365736016083		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.131735843108964 | validation: 0.190133544566361]
	TIME [epoch: 8.36 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12799952304225806		[learning rate: 0.0017939]
		[batch 20/20] avg loss: 0.1258548447233478		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.1269271838828029 | validation: 0.11489202307296736]
	TIME [epoch: 8.35 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11184549432198543		[learning rate: 0.0017852]
		[batch 20/20] avg loss: 0.13080729132759272		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.12132639282478905 | validation: 0.13189431610767804]
	TIME [epoch: 8.39 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11909003022359033		[learning rate: 0.0017766]
		[batch 20/20] avg loss: 0.11686671705278726		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.11797837363818879 | validation: 0.18732223313494253]
	TIME [epoch: 8.36 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15713734848508293		[learning rate: 0.001768]
		[batch 20/20] avg loss: 0.11479885183650465		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.13596810016079378 | validation: 0.21300031698499622]
	TIME [epoch: 8.34 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1312113794910407		[learning rate: 0.0017594]
		[batch 20/20] avg loss: 0.13665220024249564		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.13393178986676815 | validation: 0.14314739862142925]
	TIME [epoch: 8.35 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1290947652236738		[learning rate: 0.0017509]
		[batch 20/20] avg loss: 0.11841989342308545		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.12375732932337961 | validation: 0.18926063783657354]
	TIME [epoch: 8.4 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12312278347148417		[learning rate: 0.0017424]
		[batch 20/20] avg loss: 0.1267361558018733		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.12492946963667877 | validation: 0.1461156921121187]
	TIME [epoch: 8.35 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13718595070151515		[learning rate: 0.001734]
		[batch 20/20] avg loss: 0.13040960202072818		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.13379777636112167 | validation: 0.18711172359806458]
	TIME [epoch: 8.34 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12860473778967918		[learning rate: 0.0017256]
		[batch 20/20] avg loss: 0.13194586115662427		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.1302752994731517 | validation: 0.2135419247143641]
	TIME [epoch: 8.35 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15164537962024446		[learning rate: 0.0017173]
		[batch 20/20] avg loss: 0.14933671279305427		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.15049104620664935 | validation: 0.1864336194122195]
	TIME [epoch: 8.4 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15808924198056107		[learning rate: 0.001709]
		[batch 20/20] avg loss: 0.1601666239962533		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.1591279329884072 | validation: 0.17761446739345144]
	TIME [epoch: 8.35 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13560325754567748		[learning rate: 0.0017007]
		[batch 20/20] avg loss: 0.10875957120839393		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.12218141437703571 | validation: 0.12791516047801976]
	TIME [epoch: 8.34 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13875481758078628		[learning rate: 0.0016925]
		[batch 20/20] avg loss: 0.13060998163746645		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.13468239960912637 | validation: 0.10962996343635327]
	TIME [epoch: 8.36 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11488190461305861		[learning rate: 0.0016843]
		[batch 20/20] avg loss: 0.12747880645539172		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.12118035553422515 | validation: 0.14111817503750856]
	TIME [epoch: 8.4 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12021195119972014		[learning rate: 0.0016762]
		[batch 20/20] avg loss: 0.12609806930502548		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.12315501025237281 | validation: 0.2509442890607807]
	TIME [epoch: 8.36 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14459493653146788		[learning rate: 0.0016681]
		[batch 20/20] avg loss: 0.13807257445769267		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.14133375549458027 | validation: 0.1521131076787119]
	TIME [epoch: 8.34 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13716887416947462		[learning rate: 0.00166]
		[batch 20/20] avg loss: 0.14893632060314177		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.1430525973863082 | validation: 0.26661717779807287]
	TIME [epoch: 8.37 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14727505197982732		[learning rate: 0.001652]
		[batch 20/20] avg loss: 0.12368636511051093		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.1354807085451691 | validation: 0.16510415302693107]
	TIME [epoch: 8.4 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14505657883353396		[learning rate: 0.001644]
		[batch 20/20] avg loss: 0.12887083674862432		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.13696370779107914 | validation: 0.10105893265572745]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_423.pth
	Model improved!!!
EPOCH 424/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10822005477096235		[learning rate: 0.001636]
		[batch 20/20] avg loss: 0.1237642269323764		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.11599214085166938 | validation: 0.19246182841780682]
	TIME [epoch: 8.35 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18333346934969963		[learning rate: 0.0016281]
		[batch 20/20] avg loss: 0.12356332707157355		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.15344839821063663 | validation: 0.12610341824635912]
	TIME [epoch: 8.36 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10471437028574553		[learning rate: 0.0016202]
		[batch 20/20] avg loss: 0.15653845555519447		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.13062641292047003 | validation: 0.1386469689886354]
	TIME [epoch: 8.38 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14687513302403027		[learning rate: 0.0016124]
		[batch 20/20] avg loss: 0.12124319794173974		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.13405916548288505 | validation: 0.15730683478784072]
	TIME [epoch: 8.33 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11959982252922488		[learning rate: 0.0016046]
		[batch 20/20] avg loss: 0.1265866916123745		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.1230932570707997 | validation: 0.15058959571726785]
	TIME [epoch: 8.34 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11838481569766315		[learning rate: 0.0015968]
		[batch 20/20] avg loss: 0.12002565900582633		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.11920523735174474 | validation: 0.20217892299863743]
	TIME [epoch: 8.37 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12416964043138448		[learning rate: 0.0015891]
		[batch 20/20] avg loss: 0.10595575362557481		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.11506269702847967 | validation: 0.12212393359082133]
	TIME [epoch: 8.36 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12002256234706103		[learning rate: 0.0015814]
		[batch 20/20] avg loss: 0.14547700919080425		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.13274978576893265 | validation: 0.2672858387277681]
	TIME [epoch: 8.33 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13097259678608328		[learning rate: 0.0015738]
		[batch 20/20] avg loss: 0.12516684637524983		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.12806972158066654 | validation: 0.14848900966307418]
	TIME [epoch: 8.35 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13573129593760752		[learning rate: 0.0015662]
		[batch 20/20] avg loss: 0.12349676010388932		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.12961402802074845 | validation: 0.1449178270891642]
	TIME [epoch: 8.37 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10649240250431305		[learning rate: 0.0015586]
		[batch 20/20] avg loss: 0.10939971642783013		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.10794605946607158 | validation: 0.11127895613159422]
	TIME [epoch: 8.35 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12940056642205325		[learning rate: 0.0015511]
		[batch 20/20] avg loss: 0.14109959963739832		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.1352500830297258 | validation: 0.16709306751536074]
	TIME [epoch: 8.33 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1513701221793304		[learning rate: 0.0015436]
		[batch 20/20] avg loss: 0.1506629780033822		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.15101655009135628 | validation: 0.16351958251182447]
	TIME [epoch: 8.36 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17128009644887904		[learning rate: 0.0015361]
		[batch 20/20] avg loss: 0.15715473814835698		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.16421741729861802 | validation: 0.16500745127182076]
	TIME [epoch: 8.37 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14948430944525168		[learning rate: 0.0015287]
		[batch 20/20] avg loss: 0.12483884477885938		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.1371615771120555 | validation: 0.1789994432914199]
	TIME [epoch: 8.35 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13140774017017082		[learning rate: 0.0015213]
		[batch 20/20] avg loss: 0.12770343090492045		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.1295555855375456 | validation: 0.14179625213609523]
	TIME [epoch: 8.35 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10857779621117032		[learning rate: 0.0015139]
		[batch 20/20] avg loss: 0.12878324081706735		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.11868051851411884 | validation: 0.13901214335118398]
	TIME [epoch: 8.37 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12635962250300187		[learning rate: 0.0015066]
		[batch 20/20] avg loss: 0.15757008056035193		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.14196485153167693 | validation: 0.19566936428810172]
	TIME [epoch: 8.36 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1439066755624237		[learning rate: 0.0014993]
		[batch 20/20] avg loss: 0.13941427855682226		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.14166047705962295 | validation: 0.21613949578920294]
	TIME [epoch: 8.34 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17327045904815513		[learning rate: 0.0014921]
		[batch 20/20] avg loss: 0.12681768995895049		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.1500440745035528 | validation: 0.13980009537648044]
	TIME [epoch: 8.33 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12090391367478077		[learning rate: 0.0014849]
		[batch 20/20] avg loss: 0.12278255333122132		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.12184323350300108 | validation: 0.18658264401522784]
	TIME [epoch: 8.36 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1260943042818457		[learning rate: 0.0014777]
		[batch 20/20] avg loss: 0.17479579392058692		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.1504450491012163 | validation: 0.17399412521219437]
	TIME [epoch: 8.37 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15189424066873958		[learning rate: 0.0014705]
		[batch 20/20] avg loss: 0.15472731446761687		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.15331077756817826 | validation: 0.2757713291889558]
	TIME [epoch: 8.35 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13313906483604301		[learning rate: 0.0014634]
		[batch 20/20] avg loss: 0.1265183982983757		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.12982873156720937 | validation: 0.13189847722410378]
	TIME [epoch: 8.34 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10915911850810281		[learning rate: 0.0014563]
		[batch 20/20] avg loss: 0.1190104730132937		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.11408479576069826 | validation: 0.10782604480210066]
	TIME [epoch: 8.36 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14081070765058365		[learning rate: 0.0014493]
		[batch 20/20] avg loss: 0.13305175139552952		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.13693122952305656 | validation: 0.1587771828928091]
	TIME [epoch: 8.36 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14753156629845032		[learning rate: 0.0014423]
		[batch 20/20] avg loss: 0.12702867110600932		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.13728011870222984 | validation: 0.1425445971342185]
	TIME [epoch: 8.35 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13985217994814042		[learning rate: 0.0014353]
		[batch 20/20] avg loss: 0.16305615034927226		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.15145416514870633 | validation: 0.1711499339973161]
	TIME [epoch: 8.35 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.151753254851744		[learning rate: 0.0014284]
		[batch 20/20] avg loss: 0.1276467303381848		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.1396999925949644 | validation: 0.16689192535115696]
	TIME [epoch: 8.36 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13293005840753253		[learning rate: 0.0014215]
		[batch 20/20] avg loss: 0.15011760740662708		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.14152383290707976 | validation: 0.10719021809324304]
	TIME [epoch: 8.36 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11636894429046248		[learning rate: 0.0014146]
		[batch 20/20] avg loss: 0.13652394966074238		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.12644644697560242 | validation: 0.11586074743966795]
	TIME [epoch: 8.35 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11089589399719073		[learning rate: 0.0014078]
		[batch 20/20] avg loss: 0.1373489631569965		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.12412242857709362 | validation: 0.19898407622387088]
	TIME [epoch: 8.35 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14403694446514254		[learning rate: 0.0014009]
		[batch 20/20] avg loss: 0.1432727222675335		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.14365483336633803 | validation: 0.11760896826538098]
	TIME [epoch: 8.36 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13870990958048		[learning rate: 0.0013942]
		[batch 20/20] avg loss: 0.12242880669217157		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.13056935813632578 | validation: 0.12794048790166274]
	TIME [epoch: 8.35 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11259770611061959		[learning rate: 0.0013874]
		[batch 20/20] avg loss: 0.10919558841132593		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.11089664726097274 | validation: 0.10617549747884457]
	TIME [epoch: 8.35 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12008210588797505		[learning rate: 0.0013807]
		[batch 20/20] avg loss: 0.11537202015405776		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.11772706302101636 | validation: 0.14387360964758614]
	TIME [epoch: 8.36 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12480317354153062		[learning rate: 0.001374]
		[batch 20/20] avg loss: 0.12822680968019756		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.1265149916108641 | validation: 0.14426181552369266]
	TIME [epoch: 8.36 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14598914661495524		[learning rate: 0.0013674]
		[batch 20/20] avg loss: 0.15389993222160553		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.1499445394182804 | validation: 0.22321462992014413]
	TIME [epoch: 8.35 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14858958036497105		[learning rate: 0.0013608]
		[batch 20/20] avg loss: 0.13751375216808942		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.14305166626653026 | validation: 0.16123904580871654]
	TIME [epoch: 8.36 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11681923177031137		[learning rate: 0.0013542]
		[batch 20/20] avg loss: 0.11104308296259957		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.1139311573664555 | validation: 0.17754876432082758]
	TIME [epoch: 8.37 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1462690902805049		[learning rate: 0.0013477]
		[batch 20/20] avg loss: 0.11342519679135343		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.12984714353592913 | validation: 0.14197431251953707]
	TIME [epoch: 8.34 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14035987768292155		[learning rate: 0.0013411]
		[batch 20/20] avg loss: 0.1331999113673575		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.13677989452513953 | validation: 0.12329884065601951]
	TIME [epoch: 8.36 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1141759289595797		[learning rate: 0.0013347]
		[batch 20/20] avg loss: 0.11978218598142436		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.11697905747050204 | validation: 0.12789088848272082]
	TIME [epoch: 8.37 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0959351038375493		[learning rate: 0.0013282]
		[batch 20/20] avg loss: 0.14101311409415088		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.11847410896585009 | validation: 0.18050730906320178]
	TIME [epoch: 8.35 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11112021007264768		[learning rate: 0.0013218]
		[batch 20/20] avg loss: 0.12033837831253505		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.1157292941925914 | validation: 0.11669310403651294]
	TIME [epoch: 8.33 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1009129698038524		[learning rate: 0.0013154]
		[batch 20/20] avg loss: 0.11001838436704985		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.10546567708545111 | validation: 0.16779820290332265]
	TIME [epoch: 8.38 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1209966651148415		[learning rate: 0.001309]
		[batch 20/20] avg loss: 0.1266970093812237		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.12384683724803262 | validation: 0.16792299896609764]
	TIME [epoch: 8.36 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10637810326828176		[learning rate: 0.0013027]
		[batch 20/20] avg loss: 0.11969231251897858		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.11303520789363017 | validation: 0.16021832099972896]
	TIME [epoch: 8.34 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12011532811650247		[learning rate: 0.0012964]
		[batch 20/20] avg loss: 0.12489303978149498		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.12250418394899873 | validation: 0.12965506538536087]
	TIME [epoch: 8.34 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11169672961154739		[learning rate: 0.0012901]
		[batch 20/20] avg loss: 0.13202419239477176		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.12186046100315957 | validation: 0.12707219864412034]
	TIME [epoch: 8.37 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14717425158507472		[learning rate: 0.0012839]
		[batch 20/20] avg loss: 0.14017890108190306		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.1436765763334889 | validation: 0.14644196544912702]
	TIME [epoch: 8.36 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12015769872703908		[learning rate: 0.0012777]
		[batch 20/20] avg loss: 0.11605351761802526		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.11810560817253217 | validation: 0.21140879226683218]
	TIME [epoch: 8.34 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12589329501096475		[learning rate: 0.0012715]
		[batch 20/20] avg loss: 0.10969595949221736		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.11779462725159104 | validation: 0.16347272272792962]
	TIME [epoch: 8.34 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14230171251723897		[learning rate: 0.0012653]
		[batch 20/20] avg loss: 0.11969795870406266		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.13099983561065082 | validation: 0.1951135476311114]
	TIME [epoch: 8.37 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12122115718757631		[learning rate: 0.0012592]
		[batch 20/20] avg loss: 0.13558727405443677		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.12840421562100654 | validation: 0.180696253425522]
	TIME [epoch: 8.34 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14010179802775027		[learning rate: 0.0012531]
		[batch 20/20] avg loss: 0.14214877640417167		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.14112528721596101 | validation: 0.13209543427665194]
	TIME [epoch: 8.33 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11586184446884576		[learning rate: 0.0012471]
		[batch 20/20] avg loss: 0.16226487336049683		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.13906335891467128 | validation: 0.13733393214655676]
	TIME [epoch: 8.35 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1256765717818985		[learning rate: 0.0012411]
		[batch 20/20] avg loss: 0.13477753845502588		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.1302270551184622 | validation: 0.14991363063577692]
	TIME [epoch: 8.36 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1333803178839435		[learning rate: 0.001235]
		[batch 20/20] avg loss: 0.1133757259714554		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.12337802192769945 | validation: 0.16245375239396415]
	TIME [epoch: 8.35 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13001297117912508		[learning rate: 0.0012291]
		[batch 20/20] avg loss: 0.13255349507564168		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.13128323312738338 | validation: 0.11875319708442011]
	TIME [epoch: 8.35 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10383837518061345		[learning rate: 0.0012231]
		[batch 20/20] avg loss: 0.11171656228675841		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.10777746873368595 | validation: 0.19688746039115673]
	TIME [epoch: 8.36 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1055641355320553		[learning rate: 0.0012172]
		[batch 20/20] avg loss: 0.12359752779301873		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.114580831662537 | validation: 0.25617363371007434]
	TIME [epoch: 8.37 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12014174959495197		[learning rate: 0.0012113]
		[batch 20/20] avg loss: 0.10131917448508221		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.1107304620400171 | validation: 0.11517796385007245]
	TIME [epoch: 8.36 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10157893626307879		[learning rate: 0.0012055]
		[batch 20/20] avg loss: 0.12881839188777988		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.11519866407542936 | validation: 0.13259901346568284]
	TIME [epoch: 8.36 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12889254237966527		[learning rate: 0.0011996]
		[batch 20/20] avg loss: 0.09889566160707583		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.11389410199337054 | validation: 0.1300411403599561]
	TIME [epoch: 8.35 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10657465285379439		[learning rate: 0.0011938]
		[batch 20/20] avg loss: 0.1098410142224637		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.10820783353812904 | validation: 0.1980790569451934]
	TIME [epoch: 8.37 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.133602296323095		[learning rate: 0.0011881]
		[batch 20/20] avg loss: 0.1153319823573132		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.12446713934020415 | validation: 0.1619845314773031]
	TIME [epoch: 8.38 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1069833368208474		[learning rate: 0.0011823]
		[batch 20/20] avg loss: 0.10925442108682268		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.10811887895383507 | validation: 0.13607999482375696]
	TIME [epoch: 8.34 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1100457702099745		[learning rate: 0.0011766]
		[batch 20/20] avg loss: 0.11091598482777468		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.11048087751887459 | validation: 0.16755568463595358]
	TIME [epoch: 8.35 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11256634993013112		[learning rate: 0.0011709]
		[batch 20/20] avg loss: 0.1047318087579546		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.10864907934404285 | validation: 0.1272531277548007]
	TIME [epoch: 8.39 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1218323926439037		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.11755191757010683		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.11969215510700526 | validation: 0.09837125889495299]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_494.pth
	Model improved!!!
EPOCH 495/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11305966138035713		[learning rate: 0.0011596]
		[batch 20/20] avg loss: 0.14135437920809787		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.12720702029422748 | validation: 0.1518097889660856]
	TIME [epoch: 8.33 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13693393472492957		[learning rate: 0.001154]
		[batch 20/20] avg loss: 0.12560156628243013		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.13126775050367984 | validation: 0.12311010612658166]
	TIME [epoch: 8.36 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1401201894788478		[learning rate: 0.0011484]
		[batch 20/20] avg loss: 0.11457183001868061		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.1273460097487642 | validation: 0.18779882089804525]
	TIME [epoch: 8.36 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11574092090704083		[learning rate: 0.0011429]
		[batch 20/20] avg loss: 0.11549241877969903		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.1156166698433699 | validation: 0.15593757422173493]
	TIME [epoch: 8.37 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10416742087808965		[learning rate: 0.0011374]
		[batch 20/20] avg loss: 0.0908771912416276		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.09752230605985863 | validation: 0.11353057867314899]
	TIME [epoch: 8.35 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1265836381292513		[learning rate: 0.0011319]
		[batch 20/20] avg loss: 0.1718906957955167		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.14923716696238404 | validation: 0.1541513870614002]
	TIME [epoch: 8.34 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10151032636631425		[learning rate: 0.0011264]
		[batch 20/20] avg loss: 0.10355992620522785		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.10253512628577104 | validation: 0.1352809595277955]
	TIME [epoch: 8.36 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.117058610741783		[learning rate: 0.0011209]
		[batch 20/20] avg loss: 0.11562865166387995		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.11634363120283146 | validation: 0.12423696459479491]
	TIME [epoch: 8.37 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11948081872695412		[learning rate: 0.0011155]
		[batch 20/20] avg loss: 0.10634833044189244		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.11291457458442329 | validation: 0.1915201686200982]
	TIME [epoch: 8.34 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1164051373342081		[learning rate: 0.0011101]
		[batch 20/20] avg loss: 0.09558117190818563		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.10599315462119689 | validation: 0.14536363402793567]
	TIME [epoch: 8.33 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11464855776775865		[learning rate: 0.0011047]
		[batch 20/20] avg loss: 0.10241090704813183		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.10852973240794521 | validation: 0.11677268052634619]
	TIME [epoch: 8.38 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12628860173203543		[learning rate: 0.0010994]
		[batch 20/20] avg loss: 0.1222253234515448		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.12425696259179012 | validation: 0.11278186775611415]
	TIME [epoch: 8.35 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10495317041120791		[learning rate: 0.0010941]
		[batch 20/20] avg loss: 0.09741848306674702		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.10118582673897747 | validation: 0.1377880475702401]
	TIME [epoch: 8.34 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11463343461505986		[learning rate: 0.0010888]
		[batch 20/20] avg loss: 0.12247883984708027		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.11855613723107009 | validation: 0.19964918041297586]
	TIME [epoch: 8.36 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11074672786752526		[learning rate: 0.0010835]
		[batch 20/20] avg loss: 0.09242339835603489		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.10158506311178009 | validation: 0.13458856084190648]
	TIME [epoch: 8.37 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12398322663537616		[learning rate: 0.0010783]
		[batch 20/20] avg loss: 0.13449197822462672		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.12923760243000146 | validation: 0.13899947382695824]
	TIME [epoch: 8.34 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11105933115034405		[learning rate: 0.0010731]
		[batch 20/20] avg loss: 0.11844254798079161		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.11475093956556784 | validation: 0.13700469411713878]
	TIME [epoch: 8.36 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1132959072111488		[learning rate: 0.0010679]
		[batch 20/20] avg loss: 0.13456487089903255		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.12393038905509068 | validation: 0.16099830982768198]
	TIME [epoch: 8.34 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1377795397503015		[learning rate: 0.0010627]
		[batch 20/20] avg loss: 0.11330082884053919		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.12554018429542035 | validation: 0.12224697216234537]
	TIME [epoch: 8.37 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10215858608390056		[learning rate: 0.0010576]
		[batch 20/20] avg loss: 0.10242938825135221		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.10229398716762639 | validation: 0.11385293282880285]
	TIME [epoch: 8.37 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10056002210906805		[learning rate: 0.0010525]
		[batch 20/20] avg loss: 0.10691020899825024		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.10373511555365914 | validation: 0.12781087822109938]
	TIME [epoch: 8.35 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11991090147327714		[learning rate: 0.0010474]
		[batch 20/20] avg loss: 0.10148068347733404		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.11069579247530559 | validation: 0.1172628372162608]
	TIME [epoch: 8.34 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10416472369929704		[learning rate: 0.0010423]
		[batch 20/20] avg loss: 0.11065253378011577		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.10740862873970639 | validation: 0.11676337561047212]
	TIME [epoch: 8.39 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0992405442289687		[learning rate: 0.0010373]
		[batch 20/20] avg loss: 0.09788755435410817		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.09856404929153842 | validation: 0.10310017256883418]
	TIME [epoch: 8.35 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09728482029850062		[learning rate: 0.0010323]
		[batch 20/20] avg loss: 0.11303750790451002		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.1051611641015053 | validation: 0.10784028809263577]
	TIME [epoch: 8.34 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0921884992346936		[learning rate: 0.0010273]
		[batch 20/20] avg loss: 0.10836938439686886		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.10027894181578123 | validation: 0.16237464496482948]
	TIME [epoch: 8.35 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09228004621921053		[learning rate: 0.0010223]
		[batch 20/20] avg loss: 0.10594698783676393		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.09911351702798724 | validation: 0.11282068074290044]
	TIME [epoch: 8.39 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11900392368815368		[learning rate: 0.0010174]
		[batch 20/20] avg loss: 0.09803398937337962		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.10851895653076667 | validation: 0.13483903198500408]
	TIME [epoch: 8.33 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09120483055550807		[learning rate: 0.0010124]
		[batch 20/20] avg loss: 0.11583107380689454		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.10351795218120133 | validation: 0.17395153315312145]
	TIME [epoch: 8.35 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11345011337670266		[learning rate: 0.0010075]
		[batch 20/20] avg loss: 0.12098941223622448		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.11721976280646355 | validation: 0.20240117690568932]
	TIME [epoch: 8.35 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12187935874494016		[learning rate: 0.0010027]
		[batch 20/20] avg loss: 0.11447750373358578		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.11817843123926294 | validation: 0.14076775738969413]
	TIME [epoch: 8.35 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10633199823046491		[learning rate: 0.00099782]
		[batch 20/20] avg loss: 0.10356074448193861		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.10494637135620177 | validation: 0.1659387530927704]
	TIME [epoch: 8.35 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1128688282627122		[learning rate: 0.000993]
		[batch 20/20] avg loss: 0.12005705346988349		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.11646294086629785 | validation: 0.1130569561919883]
	TIME [epoch: 8.36 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11312711391674166		[learning rate: 0.00098819]
		[batch 20/20] avg loss: 0.1062001705580586		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.10966364223740013 | validation: 0.1267385217243821]
	TIME [epoch: 8.34 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11149219214691805		[learning rate: 0.00098341]
		[batch 20/20] avg loss: 0.11441033460833554		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.11295126337762677 | validation: 0.12361760920996154]
	TIME [epoch: 8.37 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10719227202579065		[learning rate: 0.00097866]
		[batch 20/20] avg loss: 0.10035124195494065		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.10377175699036564 | validation: 0.15122120482232385]
	TIME [epoch: 8.36 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10336631427359463		[learning rate: 0.00097393]
		[batch 20/20] avg loss: 0.09046905332369201		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.09691768379864332 | validation: 0.10791036458471667]
	TIME [epoch: 8.35 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11154388115443428		[learning rate: 0.00096922]
		[batch 20/20] avg loss: 0.12504381697224257		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.11829384906333842 | validation: 0.15962159335217008]
	TIME [epoch: 8.34 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10310805192432997		[learning rate: 0.00096453]
		[batch 20/20] avg loss: 0.10927913047425133		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.10619359119929064 | validation: 0.11892757911205896]
	TIME [epoch: 8.38 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.097080213440028		[learning rate: 0.00095987]
		[batch 20/20] avg loss: 0.10337649312714		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.100228353283584 | validation: 0.12006949509841935]
	TIME [epoch: 8.36 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09946540429379422		[learning rate: 0.00095522]
		[batch 20/20] avg loss: 0.10738585592797541		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.10342563011088482 | validation: 0.11460825163156899]
	TIME [epoch: 8.34 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10205429496648136		[learning rate: 0.0009506]
		[batch 20/20] avg loss: 0.10348623198811804		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.1027702634772997 | validation: 0.13794236086255046]
	TIME [epoch: 8.33 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11827444532360272		[learning rate: 0.00094601]
		[batch 20/20] avg loss: 0.11649383002510931		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.11738413767435603 | validation: 0.12328388242289433]
	TIME [epoch: 8.38 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11216818031106071		[learning rate: 0.00094143]
		[batch 20/20] avg loss: 0.1140595662578181		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.1131138732844394 | validation: 0.1468333448780269]
	TIME [epoch: 8.36 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08971218905915591		[learning rate: 0.00093688]
		[batch 20/20] avg loss: 0.0989235550468969		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.0943178720530264 | validation: 0.13370230022182122]
	TIME [epoch: 8.34 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08880683220357523		[learning rate: 0.00093235]
		[batch 20/20] avg loss: 0.09353218272689122		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.09116950746523322 | validation: 0.1335377527632211]
	TIME [epoch: 8.34 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10355395242609866		[learning rate: 0.00092784]
		[batch 20/20] avg loss: 0.11549891045623195		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.10952643144116529 | validation: 0.17897455515657454]
	TIME [epoch: 8.38 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11901665711133755		[learning rate: 0.00092335]
		[batch 20/20] avg loss: 0.11961595577268999		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.11931630644201377 | validation: 0.11703522859179152]
	TIME [epoch: 8.35 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10045887062617095		[learning rate: 0.00091889]
		[batch 20/20] avg loss: 0.09249214215328011		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.09647550638972552 | validation: 0.10227999603949572]
	TIME [epoch: 8.33 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10765761979558283		[learning rate: 0.00091445]
		[batch 20/20] avg loss: 0.09383345910145283		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.10074553944851786 | validation: 0.14684572205697094]
	TIME [epoch: 8.35 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09937956314079488		[learning rate: 0.00091002]
		[batch 20/20] avg loss: 0.11245820292485113		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.10591888303282301 | validation: 0.11102308432921293]
	TIME [epoch: 8.38 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10167287922956825		[learning rate: 0.00090562]
		[batch 20/20] avg loss: 0.1088789943880335		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.10527593680880087 | validation: 0.12768334412327215]
	TIME [epoch: 8.32 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12087415783042879		[learning rate: 0.00090124]
		[batch 20/20] avg loss: 0.10931694470335185		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.11509555126689035 | validation: 0.14246502072986286]
	TIME [epoch: 8.34 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11120936578893403		[learning rate: 0.00089689]
		[batch 20/20] avg loss: 0.11082310567248796		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.111016235730711 | validation: 0.1548299996104293]
	TIME [epoch: 8.34 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10405812157115965		[learning rate: 0.00089255]
		[batch 20/20] avg loss: 0.10487771497263702		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.10446791827189834 | validation: 0.1552094958223967]
	TIME [epoch: 8.36 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11799414175213814		[learning rate: 0.00088823]
		[batch 20/20] avg loss: 0.11484309287512866		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.11641861731363343 | validation: 0.1111989954117167]
	TIME [epoch: 8.33 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11872823007936147		[learning rate: 0.00088394]
		[batch 20/20] avg loss: 0.12714508468551428		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.12293665738243789 | validation: 0.21195406042969356]
	TIME [epoch: 8.36 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10470177613542822		[learning rate: 0.00087966]
		[batch 20/20] avg loss: 0.10755930978599618		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.10613054296071218 | validation: 0.11222484931747224]
	TIME [epoch: 8.35 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0994664695956886		[learning rate: 0.00087541]
		[batch 20/20] avg loss: 0.12275925906051252		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.11111286432810057 | validation: 0.16514781854930063]
	TIME [epoch: 8.36 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11741763675288888		[learning rate: 0.00087117]
		[batch 20/20] avg loss: 0.11548138339770313		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.116449510075296 | validation: 0.1260943016025052]
	TIME [epoch: 8.34 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10740013248133448		[learning rate: 0.00086696]
		[batch 20/20] avg loss: 0.11133881572321927		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.10936947410227686 | validation: 0.16553054125001535]
	TIME [epoch: 8.35 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09712063621666135		[learning rate: 0.00086277]
		[batch 20/20] avg loss: 0.10655762911647401		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.10183913266656767 | validation: 0.12897436827966158]
	TIME [epoch: 8.33 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0919709572337368		[learning rate: 0.0008586]
		[batch 20/20] avg loss: 0.08994278455939159		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.09095687089656418 | validation: 0.1029586520698547]
	TIME [epoch: 8.37 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08925303106864464		[learning rate: 0.00085445]
		[batch 20/20] avg loss: 0.11117868522684975		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.10021585814774721 | validation: 0.12146559075837282]
	TIME [epoch: 8.36 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09570655673984503		[learning rate: 0.00085031]
		[batch 20/20] avg loss: 0.11469341120880339		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.1051999839743242 | validation: 0.1255809746074945]
	TIME [epoch: 8.33 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08619223974198023		[learning rate: 0.0008462]
		[batch 20/20] avg loss: 0.09295690260932137		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.0895745711756508 | validation: 0.10360006643137959]
	TIME [epoch: 8.34 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08876186569404668		[learning rate: 0.00084211]
		[batch 20/20] avg loss: 0.09644011701399077		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.09260099135401871 | validation: 0.1296481514804636]
	TIME [epoch: 8.38 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08808633078838449		[learning rate: 0.00083804]
		[batch 20/20] avg loss: 0.09301596721397509		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.09055114900117978 | validation: 0.14821484319252654]
	TIME [epoch: 8.32 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09436541613545704		[learning rate: 0.00083398]
		[batch 20/20] avg loss: 0.08598310262632998		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.09017425938089352 | validation: 0.10475131771900692]
	TIME [epoch: 8.34 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10346212590488686		[learning rate: 0.00082995]
		[batch 20/20] avg loss: 0.10213493087080665		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.10279852838784675 | validation: 0.10370147782643169]
	TIME [epoch: 8.35 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09680796840238123		[learning rate: 0.00082594]
		[batch 20/20] avg loss: 0.09619071044778986		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.09649933942508555 | validation: 0.11397902053097213]
	TIME [epoch: 8.36 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11570648785789044		[learning rate: 0.00082194]
		[batch 20/20] avg loss: 0.1051083154733337		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.1104074016656121 | validation: 0.1126843691344193]
	TIME [epoch: 8.36 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0997614679163167		[learning rate: 0.00081797]
		[batch 20/20] avg loss: 0.15387717234626155		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.12681932013128913 | validation: 0.20606885266814562]
	TIME [epoch: 8.34 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09498383686933148		[learning rate: 0.00081401]
		[batch 20/20] avg loss: 0.10876954833327165		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.10187669260130158 | validation: 0.1366223634547119]
	TIME [epoch: 8.35 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10272705496605061		[learning rate: 0.00081008]
		[batch 20/20] avg loss: 0.10141591083772568		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.10207148290188814 | validation: 0.12669677447997293]
	TIME [epoch: 8.39 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10363300823002938		[learning rate: 0.00080616]
		[batch 20/20] avg loss: 0.10084475984988923		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.10223888403995929 | validation: 0.13665675265225746]
	TIME [epoch: 8.32 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10728316803414784		[learning rate: 0.00080226]
		[batch 20/20] avg loss: 0.09803490883391022		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.10265903843402904 | validation: 0.13316640822875916]
	TIME [epoch: 8.35 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11440186914020238		[learning rate: 0.00079838]
		[batch 20/20] avg loss: 0.1101485508348432		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.11227520998752279 | validation: 0.20190758611925735]
	TIME [epoch: 8.35 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12571168538773086		[learning rate: 0.00079452]
		[batch 20/20] avg loss: 0.10426319560366386		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.11498744049569735 | validation: 0.12185212270579154]
	TIME [epoch: 8.36 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11239432992709963		[learning rate: 0.00079068]
		[batch 20/20] avg loss: 0.1241770887717381		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.11828570934941887 | validation: 0.1498825791800769]
	TIME [epoch: 8.36 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09987934776482081		[learning rate: 0.00078686]
		[batch 20/20] avg loss: 0.10269801338426598		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.1012886805745434 | validation: 0.10324055232226476]
	TIME [epoch: 8.33 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0968773311791356		[learning rate: 0.00078305]
		[batch 20/20] avg loss: 0.10066052397638792		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.09876892757776176 | validation: 0.11296413447901807]
	TIME [epoch: 8.35 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12014746435316359		[learning rate: 0.00077926]
		[batch 20/20] avg loss: 0.1108943292031375		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.11552089677815058 | validation: 0.13322689006317207]
	TIME [epoch: 8.38 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11622083249533803		[learning rate: 0.00077549]
		[batch 20/20] avg loss: 0.10845729954512476		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.1123390660202314 | validation: 0.1032736055322476]
	TIME [epoch: 8.33 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1049533044036008		[learning rate: 0.00077174]
		[batch 20/20] avg loss: 0.10809942932066648		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.10652636686213364 | validation: 0.17947806827009744]
	TIME [epoch: 8.36 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11919884479465566		[learning rate: 0.00076801]
		[batch 20/20] avg loss: 0.13471597605230803		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.12695741042348183 | validation: 0.11969715681919726]
	TIME [epoch: 8.33 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11910535079977447		[learning rate: 0.0007643]
		[batch 20/20] avg loss: 0.1308123044282889		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.1249588276140317 | validation: 0.1238780963139038]
	TIME [epoch: 8.37 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11075083073306365		[learning rate: 0.0007606]
		[batch 20/20] avg loss: 0.10486377653059784		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.10780730363183073 | validation: 0.11248751878759973]
	TIME [epoch: 8.35 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1035259619499334		[learning rate: 0.00075692]
		[batch 20/20] avg loss: 0.10335307926753859		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.103439520608736 | validation: 0.12440644262934011]
	TIME [epoch: 8.33 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12082655001527046		[learning rate: 0.00075326]
		[batch 20/20] avg loss: 0.09900975864307433		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.1099181543291724 | validation: 0.11564438578118978]
	TIME [epoch: 8.34 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10475184343136146		[learning rate: 0.00074962]
		[batch 20/20] avg loss: 0.08768900320744603		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.09622042331940373 | validation: 0.12096510898974414]
	TIME [epoch: 8.38 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0861169132911282		[learning rate: 0.000746]
		[batch 20/20] avg loss: 0.09414810833389566		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.09013251081251193 | validation: 0.1225962343544103]
	TIME [epoch: 8.33 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10459370308231349		[learning rate: 0.00074239]
		[batch 20/20] avg loss: 0.11107257088456564		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.10783313698343955 | validation: 0.15939157245593932]
	TIME [epoch: 8.34 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09182217726330552		[learning rate: 0.0007388]
		[batch 20/20] avg loss: 0.10548288256423391		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.0986525299137697 | validation: 0.15228334516725578]
	TIME [epoch: 8.35 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09848247002069276		[learning rate: 0.00073523]
		[batch 20/20] avg loss: 0.0851063906656074		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.09179443034315007 | validation: 0.10575918002627129]
	TIME [epoch: 8.35 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08438391911417766		[learning rate: 0.00073167]
		[batch 20/20] avg loss: 0.08680048413834787		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.08559220162626277 | validation: 0.1258736045900145]
	TIME [epoch: 8.35 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08388923471746379		[learning rate: 0.00072813]
		[batch 20/20] avg loss: 0.09970404200329425		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.09179663836037903 | validation: 0.1063521417996437]
	TIME [epoch: 8.35 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08850254133557092		[learning rate: 0.00072461]
		[batch 20/20] avg loss: 0.08173715956763349		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.0851198504516022 | validation: 0.0953392304058072]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_592.pth
	Model improved!!!
EPOCH 593/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10870324531985975		[learning rate: 0.00072111]
		[batch 20/20] avg loss: 0.10534606282254208		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.10702465407120092 | validation: 0.11898898350367058]
	TIME [epoch: 8.38 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08673011847256362		[learning rate: 0.00071762]
		[batch 20/20] avg loss: 0.10277945184513756		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.09475478515885058 | validation: 0.16394378868099277]
	TIME [epoch: 8.33 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1002205759076404		[learning rate: 0.00071415]
		[batch 20/20] avg loss: 0.09723693090076066		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.09872875340420051 | validation: 0.13611325304676694]
	TIME [epoch: 8.33 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09120508825962814		[learning rate: 0.0007107]
		[batch 20/20] avg loss: 0.10675753861985622		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.09898131343974217 | validation: 0.16066370973567295]
	TIME [epoch: 8.36 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09498136321429801		[learning rate: 0.00070726]
		[batch 20/20] avg loss: 0.08589190592055285		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.0904366345674254 | validation: 0.10124123160858822]
	TIME [epoch: 8.35 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09817824454307829		[learning rate: 0.00070384]
		[batch 20/20] avg loss: 0.09110069832878477		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.09463947143593152 | validation: 0.14827036108635622]
	TIME [epoch: 8.34 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09911326136461013		[learning rate: 0.00070044]
		[batch 20/20] avg loss: 0.1000128718668752		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.09956306661574268 | validation: 0.12778605679656355]
	TIME [epoch: 8.36 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10688972146957462		[learning rate: 0.00069705]
		[batch 20/20] avg loss: 0.08890533951725241		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.09789753049341351 | validation: 0.1479272321197702]
	TIME [epoch: 8.33 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08525539511682055		[learning rate: 0.00069368]
		[batch 20/20] avg loss: 0.0894057666327644		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.08733058087479247 | validation: 0.12133137546470271]
	TIME [epoch: 8.35 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1170528574999038		[learning rate: 0.00069032]
		[batch 20/20] avg loss: 0.0955081833925362		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.10628052044622001 | validation: 0.11646809022457652]
	TIME [epoch: 8.35 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10085433477107657		[learning rate: 0.00068699]
		[batch 20/20] avg loss: 0.11176813818115741		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.10631123647611702 | validation: 0.14375924160387565]
	TIME [epoch: 8.31 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10796837287811867		[learning rate: 0.00068366]
		[batch 20/20] avg loss: 0.10249996130346709		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.10523416709079288 | validation: 0.16761400009800537]
	TIME [epoch: 8.33 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10074447039129457		[learning rate: 0.00068036]
		[batch 20/20] avg loss: 0.09517658795071404		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.0979605291710043 | validation: 0.11433323087673522]
	TIME [epoch: 8.36 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09156209533946155		[learning rate: 0.00067707]
		[batch 20/20] avg loss: 0.0868487576465206		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.08920542649299106 | validation: 0.12442980689797406]
	TIME [epoch: 8.33 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07212059170798372		[learning rate: 0.00067379]
		[batch 20/20] avg loss: 0.09864298845533612		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.0853817900816599 | validation: 0.124337737629401]
	TIME [epoch: 8.32 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10163774572536051		[learning rate: 0.00067053]
		[batch 20/20] avg loss: 0.10468608691312523		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.1031619163192429 | validation: 0.1339812173354547]
	TIME [epoch: 8.35 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10316099246852169		[learning rate: 0.00066729]
		[batch 20/20] avg loss: 0.10383568456621503		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.10349833851736837 | validation: 0.21671018097333367]
	TIME [epoch: 8.35 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12647609312040273		[learning rate: 0.00066406]
		[batch 20/20] avg loss: 0.11469461745904652		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.12058535528972465 | validation: 0.12615734950758672]
	TIME [epoch: 8.33 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10895368171639519		[learning rate: 0.00066085]
		[batch 20/20] avg loss: 0.08983505410080897		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.09939436790860208 | validation: 0.13626246846124604]
	TIME [epoch: 8.35 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10704437178740381		[learning rate: 0.00065766]
		[batch 20/20] avg loss: 0.09472277705110152		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.10088357441925266 | validation: 0.14786850502164078]
	TIME [epoch: 8.34 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09402154368267748		[learning rate: 0.00065448]
		[batch 20/20] avg loss: 0.0923003573492334		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.09316095051595545 | validation: 0.1261100989396102]
	TIME [epoch: 8.34 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0921031277347566		[learning rate: 0.00065131]
		[batch 20/20] avg loss: 0.09371187971276299		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.09290750372375978 | validation: 0.10658193878942203]
	TIME [epoch: 8.35 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0869223366788108		[learning rate: 0.00064816]
		[batch 20/20] avg loss: 0.08961026719325117		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.088266301936031 | validation: 0.11096831689388859]
	TIME [epoch: 8.33 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08458033623298815		[learning rate: 0.00064503]
		[batch 20/20] avg loss: 0.08854071412013702		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.08656052517656258 | validation: 0.1200218700124874]
	TIME [epoch: 8.35 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08481898422136395		[learning rate: 0.00064191]
		[batch 20/20] avg loss: 0.10425002557618526		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.0945345048987746 | validation: 0.11433955730305609]
	TIME [epoch: 8.36 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09222345642642629		[learning rate: 0.00063881]
		[batch 20/20] avg loss: 0.08276145298188649		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.0874924547041564 | validation: 0.12794266301970988]
	TIME [epoch: 8.32 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10071653646873087		[learning rate: 0.00063572]
		[batch 20/20] avg loss: 0.08811896212758238		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.09441774929815663 | validation: 0.11920319159259653]
	TIME [epoch: 8.33 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09339321705020011		[learning rate: 0.00063264]
		[batch 20/20] avg loss: 0.09540372675531657		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.09439847190275834 | validation: 0.11530430524312034]
	TIME [epoch: 8.37 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09340930421986675		[learning rate: 0.00062958]
		[batch 20/20] avg loss: 0.09403769988170155		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.09372350205078415 | validation: 0.10208399897573303]
	TIME [epoch: 8.34 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08556741915625954		[learning rate: 0.00062654]
		[batch 20/20] avg loss: 0.09104327117674996		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.08830534516650473 | validation: 0.11825477413629737]
	TIME [epoch: 8.34 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09808323601998992		[learning rate: 0.00062351]
		[batch 20/20] avg loss: 0.10919602909954884		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.10363963255976935 | validation: 0.127786321949618]
	TIME [epoch: 8.34 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08546574023393122		[learning rate: 0.00062049]
		[batch 20/20] avg loss: 0.1009346781014753		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.09320020916770325 | validation: 0.13409788095612843]
	TIME [epoch: 8.34 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09293012208896481		[learning rate: 0.00061749]
		[batch 20/20] avg loss: 0.08613644400080674		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.08953328304488577 | validation: 0.1370616596473309]
	TIME [epoch: 8.36 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09433420767812352		[learning rate: 0.00061451]
		[batch 20/20] avg loss: 0.10148000144018024		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.09790710455915189 | validation: 0.1376864573162891]
	TIME [epoch: 8.32 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09949759308293529		[learning rate: 0.00061153]
		[batch 20/20] avg loss: 0.0997562027869708		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.09962689793495305 | validation: 0.12112201786299799]
	TIME [epoch: 8.32 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0996893765101102		[learning rate: 0.00060858]
		[batch 20/20] avg loss: 0.08367564826294589		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.09168251238652805 | validation: 0.11297984229847034]
	TIME [epoch: 8.37 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10154459921320196		[learning rate: 0.00060563]
		[batch 20/20] avg loss: 0.07896285697038453		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.09025372809179324 | validation: 0.12701476528443184]
	TIME [epoch: 8.34 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09341922599426362		[learning rate: 0.00060271]
		[batch 20/20] avg loss: 0.09391489481582363		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.09366706040504363 | validation: 0.11458212393480416]
	TIME [epoch: 8.34 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09871510638480617		[learning rate: 0.00059979]
		[batch 20/20] avg loss: 0.1065236952712723		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.10261940082803925 | validation: 0.13451593898319045]
	TIME [epoch: 8.35 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10003811459648473		[learning rate: 0.00059689]
		[batch 20/20] avg loss: 0.09697016705381556		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.09850414082515016 | validation: 0.12352113511154159]
	TIME [epoch: 8.34 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08991494823511512		[learning rate: 0.000594]
		[batch 20/20] avg loss: 0.0864495901355136		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.08818226918531434 | validation: 0.15543997843330848]
	TIME [epoch: 8.36 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0911744435426631		[learning rate: 0.00059113]
		[batch 20/20] avg loss: 0.1126468984981567		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.10191067102040989 | validation: 0.1913351093708407]
	TIME [epoch: 8.34 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10782319596409459		[learning rate: 0.00058827]
		[batch 20/20] avg loss: 0.08796627660774822		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.09789473628592141 | validation: 0.11618355006468098]
	TIME [epoch: 8.34 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0905310649050774		[learning rate: 0.00058543]
		[batch 20/20] avg loss: 0.07625447889482113		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.08339277189994926 | validation: 0.1118259102611415]
	TIME [epoch: 8.38 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09093298306543361		[learning rate: 0.0005826]
		[batch 20/20] avg loss: 0.08691625746714358		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.0889246202662886 | validation: 0.0992127960311256]
	TIME [epoch: 8.35 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09340853275760777		[learning rate: 0.00057978]
		[batch 20/20] avg loss: 0.08934508977649627		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.09137681126705202 | validation: 0.1260036962011783]
	TIME [epoch: 8.35 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10778311672981722		[learning rate: 0.00057698]
		[batch 20/20] avg loss: 0.08937764947320123		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.09858038310150921 | validation: 0.09626747131735545]
	TIME [epoch: 8.35 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09081138564233535		[learning rate: 0.00057419]
		[batch 20/20] avg loss: 0.08677778528814357		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.08879458546523947 | validation: 0.12428599628498252]
	TIME [epoch: 8.36 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09312058889345468		[learning rate: 0.00057141]
		[batch 20/20] avg loss: 0.10334960258235455		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.09823509573790459 | validation: 0.12143385390697006]
	TIME [epoch: 8.38 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10169894636307067		[learning rate: 0.00056865]
		[batch 20/20] avg loss: 0.08995922295686094		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.0958290846599658 | validation: 0.1327523583681283]
	TIME [epoch: 8.34 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09020835562874832		[learning rate: 0.0005659]
		[batch 20/20] avg loss: 0.08218731472309335		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.08619783517592083 | validation: 0.10436916525216705]
	TIME [epoch: 8.35 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08877887908234722		[learning rate: 0.00056316]
		[batch 20/20] avg loss: 0.08120629485599935		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.08499258696917329 | validation: 0.12267542070337749]
	TIME [epoch: 8.38 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09279240282932086		[learning rate: 0.00056044]
		[batch 20/20] avg loss: 0.08439134129384765		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.08859187206158425 | validation: 0.1354925020938662]
	TIME [epoch: 8.34 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08711505392795028		[learning rate: 0.00055773]
		[batch 20/20] avg loss: 0.07765965358745658		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.08238735375770342 | validation: 0.10950004593239179]
	TIME [epoch: 8.35 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08392841235378334		[learning rate: 0.00055503]
		[batch 20/20] avg loss: 0.08407503293537669		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.08400172264458003 | validation: 0.13086711666850676]
	TIME [epoch: 8.36 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08445978643354095		[learning rate: 0.00055235]
		[batch 20/20] avg loss: 0.088327970605584		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.08639387851956248 | validation: 0.11820311553754739]
	TIME [epoch: 8.35 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08576702485777224		[learning rate: 0.00054967]
		[batch 20/20] avg loss: 0.0878984972322406		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.0868327610450064 | validation: 0.09153397219362186]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_649.pth
	Model improved!!!
EPOCH 650/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09975045628015367		[learning rate: 0.00054702]
		[batch 20/20] avg loss: 0.07797778918045106		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.08886412273030235 | validation: 0.11381053863455524]
	TIME [epoch: 8.34 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08984654770796824		[learning rate: 0.00054437]
		[batch 20/20] avg loss: 0.10665146262176965		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.09824900516486895 | validation: 0.11988668640675967]
	TIME [epoch: 8.31 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09175434467681935		[learning rate: 0.00054174]
		[batch 20/20] avg loss: 0.08749286007257209		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.08962360237469572 | validation: 0.10889016762048379]
	TIME [epoch: 8.36 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09200198818931106		[learning rate: 0.00053912]
		[batch 20/20] avg loss: 0.09007192113882709		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.0910369546640691 | validation: 0.11597644240806139]
	TIME [epoch: 8.34 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09041557445758655		[learning rate: 0.00053651]
		[batch 20/20] avg loss: 0.08601955296907728		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.08821756371333192 | validation: 0.1524551613606931]
	TIME [epoch: 8.3 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09847710623309132		[learning rate: 0.00053392]
		[batch 20/20] avg loss: 0.09396620036399136		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.09622165329854135 | validation: 0.12031881596243094]
	TIME [epoch: 8.33 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09006282465253232		[learning rate: 0.00053134]
		[batch 20/20] avg loss: 0.0887333189500017		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.08939807180126699 | validation: 0.1324715467654874]
	TIME [epoch: 8.35 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09633065425128888		[learning rate: 0.00052877]
		[batch 20/20] avg loss: 0.1026892832361203		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.09950996874370459 | validation: 0.13280949089073318]
	TIME [epoch: 8.32 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09204376290616374		[learning rate: 0.00052621]
		[batch 20/20] avg loss: 0.09022917343286325		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.09113646816951348 | validation: 0.1588134631251144]
	TIME [epoch: 8.34 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08599002888456082		[learning rate: 0.00052366]
		[batch 20/20] avg loss: 0.08452202982638415		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.08525602935547248 | validation: 0.1264601399999789]
	TIME [epoch: 8.34 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07733640041849504		[learning rate: 0.00052113]
		[batch 20/20] avg loss: 0.10553786897927404		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.09143713469888455 | validation: 0.11958138243290778]
	TIME [epoch: 8.34 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08913844003403261		[learning rate: 0.00051861]
		[batch 20/20] avg loss: 0.10901635895365266		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.09907739949384263 | validation: 0.13599499811637067]
	TIME [epoch: 8.34 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08889139528364126		[learning rate: 0.0005161]
		[batch 20/20] avg loss: 0.0813565975272867		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.085123996405464 | validation: 0.11771462499200352]
	TIME [epoch: 8.33 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08444249161007547		[learning rate: 0.00051361]
		[batch 20/20] avg loss: 0.08881620889845447		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.08662935025426496 | validation: 0.1298515872988878]
	TIME [epoch: 8.32 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1057824475818457		[learning rate: 0.00051112]
		[batch 20/20] avg loss: 0.09607650570016489		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.1009294766410053 | validation: 0.11565209018914421]
	TIME [epoch: 8.34 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08905633503308753		[learning rate: 0.00050865]
		[batch 20/20] avg loss: 0.08778016000821617		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.08841824752065187 | validation: 0.13438476262838614]
	TIME [epoch: 8.35 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09508527227615218		[learning rate: 0.00050619]
		[batch 20/20] avg loss: 0.08312892567272004		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.0891070989744361 | validation: 0.18351387279969908]
	TIME [epoch: 8.33 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0910377420532553		[learning rate: 0.00050374]
		[batch 20/20] avg loss: 0.09657329561668056		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.09380551883496793 | validation: 0.12904193085259053]
	TIME [epoch: 8.32 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08556123566947337		[learning rate: 0.00050131]
		[batch 20/20] avg loss: 0.07324121174207134		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.07940122370577235 | validation: 0.10041124729098376]
	TIME [epoch: 8.35 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08433576552442168		[learning rate: 0.00049888]
		[batch 20/20] avg loss: 0.08204066304539197		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.08318821428490683 | validation: 0.11247600387298991]
	TIME [epoch: 8.35 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.091454369591053		[learning rate: 0.00049647]
		[batch 20/20] avg loss: 0.08150560463576206		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.08647998711340756 | validation: 0.11640056244813611]
	TIME [epoch: 8.32 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09294319810361659		[learning rate: 0.00049407]
		[batch 20/20] avg loss: 0.09171916598105886		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.09233118204233773 | validation: 0.12343808593369202]
	TIME [epoch: 8.33 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08679285747484598		[learning rate: 0.00049168]
		[batch 20/20] avg loss: 0.09038528851439494		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.08858907299462046 | validation: 0.11295349140969213]
	TIME [epoch: 8.36 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08936180535319074		[learning rate: 0.0004893]
		[batch 20/20] avg loss: 0.08529842309912537		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.08733011422615808 | validation: 0.10346177628584402]
	TIME [epoch: 8.31 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07645490278463496		[learning rate: 0.00048694]
		[batch 20/20] avg loss: 0.08538425793575213		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.08091958036019355 | validation: 0.1727395677756425]
	TIME [epoch: 8.31 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09027362927036206		[learning rate: 0.00048458]
		[batch 20/20] avg loss: 0.0833727158692533		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.08682317256980768 | validation: 0.10621672418771635]
	TIME [epoch: 8.33 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0845548919529074		[learning rate: 0.00048224]
		[batch 20/20] avg loss: 0.0932193539522971		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.08888712295260223 | validation: 0.12340474180850111]
	TIME [epoch: 8.35 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09249646265524016		[learning rate: 0.00047991]
		[batch 20/20] avg loss: 0.08432006011785867		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.0884082613865494 | validation: 0.112883508768616]
	TIME [epoch: 8.31 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08335246712771899		[learning rate: 0.00047759]
		[batch 20/20] avg loss: 0.0922715274750335		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.08781199730137626 | validation: 0.10778862604883077]
	TIME [epoch: 8.31 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09010123104309677		[learning rate: 0.00047528]
		[batch 20/20] avg loss: 0.08127372823729376		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.08568747964019527 | validation: 0.10811286290459529]
	TIME [epoch: 8.34 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09523267741238174		[learning rate: 0.00047298]
		[batch 20/20] avg loss: 0.08150605556533008		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.0883693664888559 | validation: 0.10874127243111034]
	TIME [epoch: 8.35 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08380774191459639		[learning rate: 0.00047069]
		[batch 20/20] avg loss: 0.10225214656807542		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.0930299442413359 | validation: 0.09805933357416383]
	TIME [epoch: 8.31 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08140451051286193		[learning rate: 0.00046842]
		[batch 20/20] avg loss: 0.10858477935339697		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.09499464493312945 | validation: 0.13848593285211527]
	TIME [epoch: 8.32 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08964598702840351		[learning rate: 0.00046615]
		[batch 20/20] avg loss: 0.08707930604982206		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.08836264653911281 | validation: 0.1252492158678369]
	TIME [epoch: 8.33 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09195877857944967		[learning rate: 0.0004639]
		[batch 20/20] avg loss: 0.08801468508861518		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.08998673183403244 | validation: 0.12790318409516693]
	TIME [epoch: 8.34 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0850434027451652		[learning rate: 0.00046165]
		[batch 20/20] avg loss: 0.08633675984151438		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.0856900812933398 | validation: 0.12207479023207968]
	TIME [epoch: 8.32 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08224580081675328		[learning rate: 0.00045942]
		[batch 20/20] avg loss: 0.08395306230596553		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.08309943156135939 | validation: 0.11849836325127401]
	TIME [epoch: 8.31 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08293274270118414		[learning rate: 0.0004572]
		[batch 20/20] avg loss: 0.0827974404804839		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.08286509159083402 | validation: 0.10433589925488475]
	TIME [epoch: 8.32 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07940337875909542		[learning rate: 0.00045499]
		[batch 20/20] avg loss: 0.08209536871187746		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.08074937373548643 | validation: 0.09411613306961057]
	TIME [epoch: 8.35 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08334447424676805		[learning rate: 0.00045279]
		[batch 20/20] avg loss: 0.08600388550928392		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.08467417987802597 | validation: 0.10467610750856975]
	TIME [epoch: 8.31 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08279472160702497		[learning rate: 0.0004506]
		[batch 20/20] avg loss: 0.0862349103986108		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.08451481600281788 | validation: 0.1063096289212386]
	TIME [epoch: 8.31 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08357393293112622		[learning rate: 0.00044842]
		[batch 20/20] avg loss: 0.090832547936617		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.08720324043387162 | validation: 0.12423300723625268]
	TIME [epoch: 8.32 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08172665618322507		[learning rate: 0.00044625]
		[batch 20/20] avg loss: 0.0831030735803154		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.08241486488177022 | validation: 0.14550805250688653]
	TIME [epoch: 8.36 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09272602057291782		[learning rate: 0.00044409]
		[batch 20/20] avg loss: 0.08241894038836259		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.08757248048064023 | validation: 0.13065021729067663]
	TIME [epoch: 8.33 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08157233837442578		[learning rate: 0.00044195]
		[batch 20/20] avg loss: 0.07923053127161106		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.08040143482301843 | validation: 0.09788885273843423]
	TIME [epoch: 8.31 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08656717352890043		[learning rate: 0.00043981]
		[batch 20/20] avg loss: 0.10792093518154074		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.09724405435522057 | validation: 0.1290839510025012]
	TIME [epoch: 8.31 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0744327487244318		[learning rate: 0.00043768]
		[batch 20/20] avg loss: 0.09546949648255809		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.08495112260349494 | validation: 0.12234073496390566]
	TIME [epoch: 8.35 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07493956783768158		[learning rate: 0.00043556]
		[batch 20/20] avg loss: 0.07155981084943028		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.07324968934355591 | validation: 0.10342192712985974]
	TIME [epoch: 8.34 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07422803099187791		[learning rate: 0.00043346]
		[batch 20/20] avg loss: 0.07836605841012798		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.07629704470100294 | validation: 0.11993108851349038]
	TIME [epoch: 8.31 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0803386999158994		[learning rate: 0.00043136]
		[batch 20/20] avg loss: 0.07811292372572787		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.07922581182081362 | validation: 0.10512958643310313]
	TIME [epoch: 8.3 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07951316668974714		[learning rate: 0.00042928]
		[batch 20/20] avg loss: 0.07860906407843468		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.07906111538409091 | validation: 0.12304895341386696]
	TIME [epoch: 8.36 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09036721263655946		[learning rate: 0.0004272]
		[batch 20/20] avg loss: 0.07750460775550967		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.08393591019603455 | validation: 0.1151574398976543]
	TIME [epoch: 8.33 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07838326521071246		[learning rate: 0.00042513]
		[batch 20/20] avg loss: 0.08988190218236733		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.08413258369653989 | validation: 0.11598353135465624]
	TIME [epoch: 8.32 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08019117082559		[learning rate: 0.00042308]
		[batch 20/20] avg loss: 0.07916632100142565		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.07967874591350782 | validation: 0.10768455217553996]
	TIME [epoch: 8.31 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07629951958494476		[learning rate: 0.00042103]
		[batch 20/20] avg loss: 0.08009953898493695		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.07819952928494084 | validation: 0.10350256993907764]
	TIME [epoch: 8.35 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08318627357269137		[learning rate: 0.000419]
		[batch 20/20] avg loss: 0.08448798399636812		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.08383712878452974 | validation: 0.09773556959223606]
	TIME [epoch: 8.34 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07399299885171531		[learning rate: 0.00041697]
		[batch 20/20] avg loss: 0.07757654112061078		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.07578476998616304 | validation: 0.10079950326842659]
	TIME [epoch: 8.33 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07988944545890371		[learning rate: 0.00041495]
		[batch 20/20] avg loss: 0.08347756417574964		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.08168350481732667 | validation: 0.09704151481941321]
	TIME [epoch: 8.34 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08357439368728889		[learning rate: 0.00041295]
		[batch 20/20] avg loss: 0.08186798436938722		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.08272118902833805 | validation: 0.10033367758633796]
	TIME [epoch: 8.37 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09434969072094221		[learning rate: 0.00041095]
		[batch 20/20] avg loss: 0.08230411468279722		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.08832690270186971 | validation: 0.10923630631175554]
	TIME [epoch: 8.35 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09806918898427104		[learning rate: 0.00040896]
		[batch 20/20] avg loss: 0.08207290080541445		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.09007104489484274 | validation: 0.1555195626416755]
	TIME [epoch: 8.34 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09623132996505572		[learning rate: 0.00040699]
		[batch 20/20] avg loss: 0.09657350552602476		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.09640241774554023 | validation: 0.1245076146651812]
	TIME [epoch: 8.34 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08304545193305943		[learning rate: 0.00040502]
		[batch 20/20] avg loss: 0.08390174383053481		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.08347359788179713 | validation: 0.10704792035035621]
	TIME [epoch: 8.36 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08043898107762137		[learning rate: 0.00040306]
		[batch 20/20] avg loss: 0.08497473125695933		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.08270685616729036 | validation: 0.11356315800706465]
	TIME [epoch: 8.31 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09717097914762247		[learning rate: 0.00040111]
		[batch 20/20] avg loss: 0.09935481338881974		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.0982628962682211 | validation: 0.11463005822858117]
	TIME [epoch: 8.31 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07388747899409447		[learning rate: 0.00039917]
		[batch 20/20] avg loss: 0.09056649779044443		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.08222698839226945 | validation: 0.13328891379910152]
	TIME [epoch: 8.33 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09556763455802794		[learning rate: 0.00039724]
		[batch 20/20] avg loss: 0.08707530941352665		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.09132147198577731 | validation: 0.1282483185695475]
	TIME [epoch: 8.35 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08549319252104184		[learning rate: 0.00039532]
		[batch 20/20] avg loss: 0.08151820542749287		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.08350569897426735 | validation: 0.10973384169788793]
	TIME [epoch: 8.32 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0782439313502007		[learning rate: 0.00039341]
		[batch 20/20] avg loss: 0.07902193299243344		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.07863293217131706 | validation: 0.1125033278111131]
	TIME [epoch: 8.31 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08098947928272898		[learning rate: 0.0003915]
		[batch 20/20] avg loss: 0.07612152992967043		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.07855550460619971 | validation: 0.11878609308505915]
	TIME [epoch: 8.33 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09537361328071801		[learning rate: 0.00038961]
		[batch 20/20] avg loss: 0.08549377545963129		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.09043369437017466 | validation: 0.12643783766615935]
	TIME [epoch: 8.36 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08418994039638349		[learning rate: 0.00038773]
		[batch 20/20] avg loss: 0.07476145191408899		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.07947569615523623 | validation: 0.10644368954261715]
	TIME [epoch: 8.32 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07961651054290811		[learning rate: 0.00038585]
		[batch 20/20] avg loss: 0.07325175754694445		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.07643413404492629 | validation: 0.09617601116960679]
	TIME [epoch: 8.32 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09594984300108142		[learning rate: 0.00038399]
		[batch 20/20] avg loss: 0.07825930322863531		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.08710457311485839 | validation: 0.09346446194937948]
	TIME [epoch: 8.32 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08424885907835447		[learning rate: 0.00038213]
		[batch 20/20] avg loss: 0.07552155100573552		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.07988520504204498 | validation: 0.12429831918178248]
	TIME [epoch: 8.35 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08029481379042604		[learning rate: 0.00038028]
		[batch 20/20] avg loss: 0.07244809169264434		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.0763714527415352 | validation: 0.08956401471632242]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_725.pth
	Model improved!!!
EPOCH 726/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07338730995062033		[learning rate: 0.00037844]
		[batch 20/20] avg loss: 0.07962946096123555		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.07650838545592793 | validation: 0.1124336207323033]
	TIME [epoch: 8.33 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0762324992844565		[learning rate: 0.00037661]
		[batch 20/20] avg loss: 0.07561580711585146		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.07592415320015398 | validation: 0.11632821066408244]
	TIME [epoch: 8.34 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08195445504712337		[learning rate: 0.00037479]
		[batch 20/20] avg loss: 0.09755842916582949		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.08975644210647642 | validation: 0.1276828588213877]
	TIME [epoch: 8.34 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07900753003029205		[learning rate: 0.00037298]
		[batch 20/20] avg loss: 0.08342838648969479		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.08121795825999341 | validation: 0.11439038614340893]
	TIME [epoch: 8.33 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08868015999411509		[learning rate: 0.00037118]
		[batch 20/20] avg loss: 0.08799950278168434		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.0883398313878997 | validation: 0.11847997675173917]
	TIME [epoch: 8.34 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09080784957329968		[learning rate: 0.00036938]
		[batch 20/20] avg loss: 0.07852351130693844		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.08466568044011905 | validation: 0.12082519153848535]
	TIME [epoch: 8.32 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08448187574415743		[learning rate: 0.00036759]
		[batch 20/20] avg loss: 0.08464419392702767		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.08456303483559255 | validation: 0.105631495590467]
	TIME [epoch: 8.34 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08522067127017949		[learning rate: 0.00036582]
		[batch 20/20] avg loss: 0.08979145123735002		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.08750606125376477 | validation: 0.1059846784668793]
	TIME [epoch: 8.34 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08204459536089145		[learning rate: 0.00036405]
		[batch 20/20] avg loss: 0.07640950788562553		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.07922705162325848 | validation: 0.10128711022193268]
	TIME [epoch: 8.32 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0773378022554566		[learning rate: 0.00036229]
		[batch 20/20] avg loss: 0.08694954775234945		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.08214367500390302 | validation: 0.11340138667663219]
	TIME [epoch: 8.32 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0814690937213151		[learning rate: 0.00036053]
		[batch 20/20] avg loss: 0.07862322647887256		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.08004616010009383 | validation: 0.11559153914100073]
	TIME [epoch: 8.35 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08703792540553945		[learning rate: 0.00035879]
		[batch 20/20] avg loss: 0.08206653180900542		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.08455222860727243 | validation: 0.1066102079155093]
	TIME [epoch: 8.34 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07870978549088362		[learning rate: 0.00035706]
		[batch 20/20] avg loss: 0.08699665644253732		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.08285322096671047 | validation: 0.10148895952409726]
	TIME [epoch: 8.31 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08495437172158728		[learning rate: 0.00035533]
		[batch 20/20] avg loss: 0.07622570871504512		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.0805900402183162 | validation: 0.09079815159994943]
	TIME [epoch: 8.32 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07551482984126534		[learning rate: 0.00035361]
		[batch 20/20] avg loss: 0.08309120147404815		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.07930301565765674 | validation: 0.09792222112221623]
	TIME [epoch: 8.36 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07807604757289363		[learning rate: 0.0003519]
		[batch 20/20] avg loss: 0.08324654900574865		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.08066129828932114 | validation: 0.12468666680026153]
	TIME [epoch: 8.33 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07572871130195995		[learning rate: 0.0003502]
		[batch 20/20] avg loss: 0.0835288390354848		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.07962877516872238 | validation: 0.09773649046467142]
	TIME [epoch: 8.31 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08414131534986967		[learning rate: 0.00034851]
		[batch 20/20] avg loss: 0.09123752572508939		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.08768942053747955 | validation: 0.10547737159979396]
	TIME [epoch: 8.33 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07990150242219987		[learning rate: 0.00034682]
		[batch 20/20] avg loss: 0.08553949282023925		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.08272049762121955 | validation: 0.10501930072812074]
	TIME [epoch: 8.36 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08013231655495774		[learning rate: 0.00034514]
		[batch 20/20] avg loss: 0.08131279633602889		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.08072255644549332 | validation: 0.10580665584651816]
	TIME [epoch: 8.31 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08743479634252516		[learning rate: 0.00034347]
		[batch 20/20] avg loss: 0.07592310264781435		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.08167894949516975 | validation: 0.11040255187691067]
	TIME [epoch: 8.33 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08176247132542838		[learning rate: 0.00034181]
		[batch 20/20] avg loss: 0.07637609697465594		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.07906928415004219 | validation: 0.09830600984486829]
	TIME [epoch: 8.34 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07672159352393595		[learning rate: 0.00034016]
		[batch 20/20] avg loss: 0.07730356513531098		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.07701257932962348 | validation: 0.0934706871894719]
	TIME [epoch: 8.34 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07522171683235143		[learning rate: 0.00033852]
		[batch 20/20] avg loss: 0.07755207872310474		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.07638689777772807 | validation: 0.11187985060724742]
	TIME [epoch: 8.33 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08135123387104638		[learning rate: 0.00033688]
		[batch 20/20] avg loss: 0.07737324541591103		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.0793622396434787 | validation: 0.12095521036842577]
	TIME [epoch: 8.34 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0892801444552183		[learning rate: 0.00033525]
		[batch 20/20] avg loss: 0.0826841980965176		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.08598217127586794 | validation: 0.10739140247110252]
	TIME [epoch: 8.32 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07582450865066755		[learning rate: 0.00033363]
		[batch 20/20] avg loss: 0.08378529941640385		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.07980490403353568 | validation: 0.10309129690119564]
	TIME [epoch: 8.36 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0850752301863016		[learning rate: 0.00033202]
		[batch 20/20] avg loss: 0.07979428001436602		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.0824347551003338 | validation: 0.09774749090401288]
	TIME [epoch: 8.33 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08682409822453149		[learning rate: 0.00033041]
		[batch 20/20] avg loss: 0.07914018964525477		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.0829821439348931 | validation: 0.10181341930781537]
	TIME [epoch: 8.31 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07944159668223624		[learning rate: 0.00032881]
		[batch 20/20] avg loss: 0.07311741495687396		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.07627950581955509 | validation: 0.10212892809817775]
	TIME [epoch: 8.33 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08156365938302165		[learning rate: 0.00032722]
		[batch 20/20] avg loss: 0.07732018677914373		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.0794419230810827 | validation: 0.11081312343194841]
	TIME [epoch: 8.37 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08481544582813734		[learning rate: 0.00032564]
		[batch 20/20] avg loss: 0.07367929250721324		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.0792473691676753 | validation: 0.11344749098045151]
	TIME [epoch: 8.31 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08457241508468341		[learning rate: 0.00032406]
		[batch 20/20] avg loss: 0.06986106249023041		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.07721673878745693 | validation: 0.09758454515274469]
	TIME [epoch: 8.33 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07239115841680607		[learning rate: 0.0003225]
		[batch 20/20] avg loss: 0.07798390186084649		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.07518753013882627 | validation: 0.1227287188629802]
	TIME [epoch: 8.34 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08264346600981735		[learning rate: 0.00032094]
		[batch 20/20] avg loss: 0.07880425281537011		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.08072385941259372 | validation: 0.09881685548921922]
	TIME [epoch: 8.34 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08142606693699089		[learning rate: 0.00031939]
		[batch 20/20] avg loss: 0.08072975039396277		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.08107790866547683 | validation: 0.11621884734991195]
	TIME [epoch: 8.32 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08606303111959737		[learning rate: 0.00031784]
		[batch 20/20] avg loss: 0.07898572298776448		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.08252437705368092 | validation: 0.11173719284460566]
	TIME [epoch: 8.34 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07671551337880428		[learning rate: 0.0003163]
		[batch 20/20] avg loss: 0.07829665753510447		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.07750608545695437 | validation: 0.09830126120219737]
	TIME [epoch: 8.34 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08300176958067303		[learning rate: 0.00031477]
		[batch 20/20] avg loss: 0.07988501064061833		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.08144339011064569 | validation: 0.12704989357913482]
	TIME [epoch: 8.34 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07879855101098886		[learning rate: 0.00031325]
		[batch 20/20] avg loss: 0.0794930572145853		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.07914580411278707 | validation: 0.10279239877481404]
	TIME [epoch: 8.31 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08143239127430456		[learning rate: 0.00031174]
		[batch 20/20] avg loss: 0.08157294130274965		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.08150266628852712 | validation: 0.1012655563084721]
	TIME [epoch: 8.33 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.075510223047691		[learning rate: 0.00031023]
		[batch 20/20] avg loss: 0.08257342281630496		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.07904182293199799 | validation: 0.1143206037240477]
	TIME [epoch: 8.33 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07908835318366972		[learning rate: 0.00030873]
		[batch 20/20] avg loss: 0.07915363721454768		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.07912099519910869 | validation: 0.09994371894217327]
	TIME [epoch: 8.36 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0744691245124446		[learning rate: 0.00030724]
		[batch 20/20] avg loss: 0.08123693856169126		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.07785303153706793 | validation: 0.1295066726866378]
	TIME [epoch: 8.32 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08865451613875988		[learning rate: 0.00030575]
		[batch 20/20] avg loss: 0.08969752359906816		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.08917601986891402 | validation: 0.10780430238096828]
	TIME [epoch: 8.32 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07659613695080893		[learning rate: 0.00030427]
		[batch 20/20] avg loss: 0.07947098789984001		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.07803356242532448 | validation: 0.10176685626220622]
	TIME [epoch: 8.32 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08180153805442289		[learning rate: 0.0003028]
		[batch 20/20] avg loss: 0.08147042571438207		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.08163598188440248 | validation: 0.10881697227081627]
	TIME [epoch: 8.37 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08174811420197282		[learning rate: 0.00030134]
		[batch 20/20] avg loss: 0.08309533716330522		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.08242172568263902 | validation: 0.1031420558752695]
	TIME [epoch: 8.34 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0811610384538032		[learning rate: 0.00029988]
		[batch 20/20] avg loss: 0.08657512129559444		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.08386807987469883 | validation: 0.10864007185169773]
	TIME [epoch: 8.34 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08274645861703014		[learning rate: 0.00029843]
		[batch 20/20] avg loss: 0.08064970354152126		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.0816980810792757 | validation: 0.12946916618212348]
	TIME [epoch: 8.32 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09128302490384278		[learning rate: 0.00029699]
		[batch 20/20] avg loss: 0.07931236228763092		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.08529769359573684 | validation: 0.11668147938762419]
	TIME [epoch: 8.35 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06941219900157437		[learning rate: 0.00029555]
		[batch 20/20] avg loss: 0.07410550314614411		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.07175885107385924 | validation: 0.09988725439141646]
	TIME [epoch: 8.33 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07665213059815304		[learning rate: 0.00029412]
		[batch 20/20] avg loss: 0.07621918399244829		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.07643565729530066 | validation: 0.1037373979169435]
	TIME [epoch: 8.33 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07074390395092979		[learning rate: 0.0002927]
		[batch 20/20] avg loss: 0.07877992578204054		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.07476191486648517 | validation: 0.12109656995025997]
	TIME [epoch: 8.33 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08391115179764932		[learning rate: 0.00029128]
		[batch 20/20] avg loss: 0.07701971426595691		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.08046543303180315 | validation: 0.09286447296974996]
	TIME [epoch: 8.33 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07573045906940491		[learning rate: 0.00028987]
		[batch 20/20] avg loss: 0.08271226676797452		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.07922136291868973 | validation: 0.10394503083517312]
	TIME [epoch: 8.32 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07675648783703137		[learning rate: 0.00028847]
		[batch 20/20] avg loss: 0.07545275194257348		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.07610461988980241 | validation: 0.08868320459947027]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_782.pth
	Model improved!!!
EPOCH 783/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07322767129431806		[learning rate: 0.00028708]
		[batch 20/20] avg loss: 0.07502507964955824		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.07412637547193815 | validation: 0.10162983176485033]
	TIME [epoch: 8.33 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07937666733993262		[learning rate: 0.00028569]
		[batch 20/20] avg loss: 0.07613891345510054		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.0777577903975166 | validation: 0.1057028076208957]
	TIME [epoch: 8.34 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08172773802701422		[learning rate: 0.00028431]
		[batch 20/20] avg loss: 0.07074016577977646		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.07623395190339535 | validation: 0.10573398128384094]
	TIME [epoch: 8.33 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07386825498734195		[learning rate: 0.00028293]
		[batch 20/20] avg loss: 0.07655051970821579		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.07520938734777885 | validation: 0.1355189371016794]
	TIME [epoch: 8.34 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08310051782014002		[learning rate: 0.00028157]
		[batch 20/20] avg loss: 0.0750819024195113		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.07909121011982569 | validation: 0.11398284095461175]
	TIME [epoch: 8.32 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08601061968699315		[learning rate: 0.0002802]
		[batch 20/20] avg loss: 0.08204802007046531		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.08402931987872923 | validation: 0.1111811166618079]
	TIME [epoch: 8.34 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07725049965161875		[learning rate: 0.00027885]
		[batch 20/20] avg loss: 0.09165769414315875		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.08445409689738874 | validation: 0.10712814519554617]
	TIME [epoch: 8.31 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08574814446536023		[learning rate: 0.0002775]
		[batch 20/20] avg loss: 0.0832798803079242		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.08451401238664223 | validation: 0.11231162692638531]
	TIME [epoch: 8.32 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07777206607781756		[learning rate: 0.00027616]
		[batch 20/20] avg loss: 0.08495661414226098		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.08136434011003928 | validation: 0.11770069073665454]
	TIME [epoch: 8.33 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07677587879467807		[learning rate: 0.00027482]
		[batch 20/20] avg loss: 0.06941051362921666		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.07309319621194736 | validation: 0.10361395005612167]
	TIME [epoch: 8.35 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0830770014071683		[learning rate: 0.00027349]
		[batch 20/20] avg loss: 0.07336055631639504		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.07821877886178168 | validation: 0.1015263897351116]
	TIME [epoch: 8.31 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06887696517945198		[learning rate: 0.00027217]
		[batch 20/20] avg loss: 0.07211486999465043		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.07049591758705122 | validation: 0.09575429517162826]
	TIME [epoch: 8.33 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07528886502355218		[learning rate: 0.00027086]
		[batch 20/20] avg loss: 0.0730233985917074		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.07415613180762978 | validation: 0.10526432880497134]
	TIME [epoch: 8.32 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0728655456626292		[learning rate: 0.00026955]
		[batch 20/20] avg loss: 0.0825621903266185		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.07771386799462385 | validation: 0.10452664022869883]
	TIME [epoch: 8.35 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07225792212474773		[learning rate: 0.00026824]
		[batch 20/20] avg loss: 0.07371844246719313		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.07298818229597044 | validation: 0.09445334429480669]
	TIME [epoch: 8.33 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07859985371955548		[learning rate: 0.00026694]
		[batch 20/20] avg loss: 0.07221685623594906		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.07540835497775226 | validation: 0.10693401360097349]
	TIME [epoch: 8.33 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09522887068262212		[learning rate: 0.00026565]
		[batch 20/20] avg loss: 0.08314698527012476		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.08918792797637344 | validation: 0.10922039300658291]
	TIME [epoch: 8.33 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07900453251328357		[learning rate: 0.00026437]
		[batch 20/20] avg loss: 0.07127533322827634		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.07513993287077995 | validation: 0.11705287321901696]
	TIME [epoch: 8.34 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08169418588284516		[learning rate: 0.00026309]
		[batch 20/20] avg loss: 0.0794230525724137		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.08055861922762944 | validation: 0.10958761403496965]
	TIME [epoch: 8.32 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08295319473453336		[learning rate: 0.00026182]
		[batch 20/20] avg loss: 0.077749187866237		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.08035119130038516 | validation: 0.10450507307570059]
	TIME [epoch: 8.32 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07209901749726384		[learning rate: 0.00026055]
		[batch 20/20] avg loss: 0.08602615063140093		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.07906258406433239 | validation: 0.11477800371516574]
	TIME [epoch: 8.33 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07978861588609065		[learning rate: 0.00025929]
		[batch 20/20] avg loss: 0.07965848665473453		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.07972355127041258 | validation: 0.10838086242539356]
	TIME [epoch: 8.35 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08420808252084408		[learning rate: 0.00025804]
		[batch 20/20] avg loss: 0.08054510619474028		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.08237659435779218 | validation: 0.1402356771696433]
	TIME [epoch: 8.32 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08904901985826852		[learning rate: 0.00025679]
		[batch 20/20] avg loss: 0.08092728169784488		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.08498815077805669 | validation: 0.11840385303316739]
	TIME [epoch: 8.31 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0715792286344323		[learning rate: 0.00025555]
		[batch 20/20] avg loss: 0.0816397716790241		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.07660950015672817 | validation: 0.09893517102313432]
	TIME [epoch: 8.31 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07587828512940724		[learning rate: 0.00025431]
		[batch 20/20] avg loss: 0.08126131631006044		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.07856980071973386 | validation: 0.11335838539202853]
	TIME [epoch: 8.33 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08501445032217553		[learning rate: 0.00025308]
		[batch 20/20] avg loss: 0.07774408063086911		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.08137926547652233 | validation: 0.09873827866879537]
	TIME [epoch: 8.32 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09291640150718045		[learning rate: 0.00025186]
		[batch 20/20] avg loss: 0.08082993110729256		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.0868731663072365 | validation: 0.10229734626928372]
	TIME [epoch: 8.33 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0886174015139159		[learning rate: 0.00025064]
		[batch 20/20] avg loss: 0.08024901672342591		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.08443320911867089 | validation: 0.09977570998601416]
	TIME [epoch: 8.3 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08162244107129243		[learning rate: 0.00024943]
		[batch 20/20] avg loss: 0.0814462620457073		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.08153435155849988 | validation: 0.11023700960882102]
	TIME [epoch: 8.32 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08012697028849156		[learning rate: 0.00024822]
		[batch 20/20] avg loss: 0.07925266139393411		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.07968981584121283 | validation: 0.10764897656334024]
	TIME [epoch: 8.32 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08013328849798644		[learning rate: 0.00024702]
		[batch 20/20] avg loss: 0.08215442294670157		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.08114385572234403 | validation: 0.1114619333828926]
	TIME [epoch: 8.33 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07739275916078966		[learning rate: 0.00024583]
		[batch 20/20] avg loss: 0.08390080317888007		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.08064678116983487 | validation: 0.1080724563476203]
	TIME [epoch: 8.3 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07776966456833653		[learning rate: 0.00024464]
		[batch 20/20] avg loss: 0.07062351607204106		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.07419659032018881 | validation: 0.11083101727943516]
	TIME [epoch: 8.32 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08320051699786189		[learning rate: 0.00024346]
		[batch 20/20] avg loss: 0.0835901982175491		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.0833953576077055 | validation: 0.11606620858694898]
	TIME [epoch: 8.31 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0763244154548599		[learning rate: 0.00024228]
		[batch 20/20] avg loss: 0.07583043851864406		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.07607742698675199 | validation: 0.10432492289389941]
	TIME [epoch: 8.33 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0767356034943202		[learning rate: 0.00024111]
		[batch 20/20] avg loss: 0.08087028134869884		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.07880294242150951 | validation: 0.12088586957460314]
	TIME [epoch: 8.32 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08685281788453134		[learning rate: 0.00023994]
		[batch 20/20] avg loss: 0.08009710432600839		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.08347496110526986 | validation: 0.10678757103633615]
	TIME [epoch: 8.33 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08027399829185045		[learning rate: 0.00023878]
		[batch 20/20] avg loss: 0.08343616091781922		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.08185507960483483 | validation: 0.12825896147416138]
	TIME [epoch: 8.31 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08984482414888535		[learning rate: 0.00023763]
		[batch 20/20] avg loss: 0.07698250064953872		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.08341366239921202 | validation: 0.10984314732792683]
	TIME [epoch: 8.33 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07536575226485502		[learning rate: 0.00023648]
		[batch 20/20] avg loss: 0.0754011102152265		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.07538343124004075 | validation: 0.11904928616395262]
	TIME [epoch: 8.32 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07734891598930352		[learning rate: 0.00023533]
		[batch 20/20] avg loss: 0.07801065357469203		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.07767978478199777 | validation: 0.10196931974413506]
	TIME [epoch: 8.32 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0804431525067045		[learning rate: 0.0002342]
		[batch 20/20] avg loss: 0.0743333774349654		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.07738826497083497 | validation: 0.09513147057630719]
	TIME [epoch: 8.33 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07702080266783422		[learning rate: 0.00023306]
		[batch 20/20] avg loss: 0.07313803643463675		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.07507941955123547 | validation: 0.1029623912953949]
	TIME [epoch: 8.31 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06299378672006489		[learning rate: 0.00023194]
		[batch 20/20] avg loss: 0.07842054782610633		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.0707071672730856 | validation: 0.12893909077190185]
	TIME [epoch: 8.31 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08129507299005287		[learning rate: 0.00023081]
		[batch 20/20] avg loss: 0.0793247385282452		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.08030990575914904 | validation: 0.10132716042278014]
	TIME [epoch: 8.33 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08563255246955163		[learning rate: 0.0002297]
		[batch 20/20] avg loss: 0.07075709723503357		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.07819482485229261 | validation: 0.11750097299235149]
	TIME [epoch: 8.34 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07490862029598486		[learning rate: 0.00022859]
		[batch 20/20] avg loss: 0.07756958280121007		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.07623910154859746 | validation: 0.1182449645946556]
	TIME [epoch: 8.31 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0708938469516127		[learning rate: 0.00022748]
		[batch 20/20] avg loss: 0.07694726612803851		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.07392055653982561 | validation: 0.1049167362168993]
	TIME [epoch: 8.33 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07177644598260208		[learning rate: 0.00022638]
		[batch 20/20] avg loss: 0.07721686441213653		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.0744966551973693 | validation: 0.1139360045344995]
	TIME [epoch: 8.35 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08060913675704981		[learning rate: 0.00022529]
		[batch 20/20] avg loss: 0.07682792880708605		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.07871853278206793 | validation: 0.12936996142624532]
	TIME [epoch: 8.31 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08565991508460884		[learning rate: 0.0002242]
		[batch 20/20] avg loss: 0.07198105145555304		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.07882048327008094 | validation: 0.10829763895873781]
	TIME [epoch: 8.33 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07786222379572162		[learning rate: 0.00022311]
		[batch 20/20] avg loss: 0.08336892264350447		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.08061557321961306 | validation: 0.09070414027250666]
	TIME [epoch: 8.34 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07027866693164363		[learning rate: 0.00022203]
		[batch 20/20] avg loss: 0.0746471661748748		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.07246291655325922 | validation: 0.09580219245183887]
	TIME [epoch: 8.32 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07507563932489648		[learning rate: 0.00022096]
		[batch 20/20] avg loss: 0.0826121969414901		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.07884391813319327 | validation: 0.1274636324698277]
	TIME [epoch: 8.33 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07990182977323793		[learning rate: 0.00021989]
		[batch 20/20] avg loss: 0.08696432568157472		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.08343307772740631 | validation: 0.10615760624960623]
	TIME [epoch: 8.32 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07629203869942422		[learning rate: 0.00021883]
		[batch 20/20] avg loss: 0.07312754330015864		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.07470979099979143 | validation: 0.1022384365042927]
	TIME [epoch: 8.33 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07616589162100683		[learning rate: 0.00021777]
		[batch 20/20] avg loss: 0.07783449229535985		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.07700019195818336 | validation: 0.09937041824121218]
	TIME [epoch: 8.35 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08380643269728735		[learning rate: 0.00021672]
		[batch 20/20] avg loss: 0.07491691638039497		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.07936167453884119 | validation: 0.1120145034901858]
	TIME [epoch: 8.31 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07712770998986918		[learning rate: 0.00021567]
		[batch 20/20] avg loss: 0.07618699535518463		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.0766573526725269 | validation: 0.10618374743760492]
	TIME [epoch: 8.33 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07259190127716693		[learning rate: 0.00021463]
		[batch 20/20] avg loss: 0.07978961961953412		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.07619076044835053 | validation: 0.13234784269091607]
	TIME [epoch: 8.33 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08005801868708354		[learning rate: 0.00021359]
		[batch 20/20] avg loss: 0.0826256928067928		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.08134185574693815 | validation: 0.10654457029680355]
	TIME [epoch: 8.34 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07983527901243327		[learning rate: 0.00021256]
		[batch 20/20] avg loss: 0.07652675698029239		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.07818101799636282 | validation: 0.11466989777840574]
	TIME [epoch: 8.33 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08418439848535489		[learning rate: 0.00021153]
		[batch 20/20] avg loss: 0.07416691385768763		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.07917565617152125 | validation: 0.1026565072324892]
	TIME [epoch: 8.32 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07277766721161684		[learning rate: 0.00021051]
		[batch 20/20] avg loss: 0.07474683418794877		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.07376225069978282 | validation: 0.09382796477716288]
	TIME [epoch: 8.33 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0674950079133742		[learning rate: 0.00020949]
		[batch 20/20] avg loss: 0.08193107336716031		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.07471304064026726 | validation: 0.09723782532529135]
	TIME [epoch: 8.35 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06748176033989499		[learning rate: 0.00020847]
		[batch 20/20] avg loss: 0.07556439759874742		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.07152307896932121 | validation: 0.10541813591430306]
	TIME [epoch: 8.32 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06985094044777623		[learning rate: 0.00020747]
		[batch 20/20] avg loss: 0.07607431782105208		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.07296262913441416 | validation: 0.11028169061626246]
	TIME [epoch: 8.31 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07237664613983771		[learning rate: 0.00020646]
		[batch 20/20] avg loss: 0.08108623498295879		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.07673144056139826 | validation: 0.09296143317086483]
	TIME [epoch: 8.35 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07231129482579567		[learning rate: 0.00020546]
		[batch 20/20] avg loss: 0.07859634759226526		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.07545382120903046 | validation: 0.1084210729655791]
	TIME [epoch: 8.34 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07177916545520745		[learning rate: 0.00020447]
		[batch 20/20] avg loss: 0.07883731173314294		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.07530823859417521 | validation: 0.09193475168742143]
	TIME [epoch: 8.31 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07883816748785515		[learning rate: 0.00020348]
		[batch 20/20] avg loss: 0.07439381393463187		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.0766159907112435 | validation: 0.10770359746086663]
	TIME [epoch: 8.34 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08122735630613516		[learning rate: 0.0002025]
		[batch 20/20] avg loss: 0.08401301086507464		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.08262018358560488 | validation: 0.11952370683632815]
	TIME [epoch: 8.33 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08457332925301837		[learning rate: 0.00020152]
		[batch 20/20] avg loss: 0.076605883772466		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.08058960651274218 | validation: 0.10443007610182432]
	TIME [epoch: 8.34 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06976434245957405		[learning rate: 0.00020054]
		[batch 20/20] avg loss: 0.08104671223223779		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.07540552734590593 | validation: 0.11082868325951281]
	TIME [epoch: 8.33 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07963028966345415		[learning rate: 0.00019957]
		[batch 20/20] avg loss: 0.06946511711794709		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.0745477033907006 | validation: 0.10322366519939927]
	TIME [epoch: 8.31 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06915089451987486		[learning rate: 0.00019861]
		[batch 20/20] avg loss: 0.06866075911123379		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.06890582681555432 | validation: 0.09246551151215586]
	TIME [epoch: 8.35 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07805525933849947		[learning rate: 0.00019765]
		[batch 20/20] avg loss: 0.07267448247218092		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.07536487090534019 | validation: 0.11892966885900434]
	TIME [epoch: 8.33 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07369989747476072		[learning rate: 0.00019669]
		[batch 20/20] avg loss: 0.07050356879790298		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.07210173313633185 | validation: 0.10803065848797558]
	TIME [epoch: 8.31 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07118069655312301		[learning rate: 0.00019574]
		[batch 20/20] avg loss: 0.07414987732628493		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.07266528693970395 | validation: 0.09929412920114677]
	TIME [epoch: 8.32 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07273689187049515		[learning rate: 0.0001948]
		[batch 20/20] avg loss: 0.07598442689595085		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.07436065938322302 | validation: 0.12107621603172498]
	TIME [epoch: 8.34 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07508885268893835		[learning rate: 0.00019385]
		[batch 20/20] avg loss: 0.07340606684421228		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.07424745976657529 | validation: 0.09189075836150207]
	TIME [epoch: 8.32 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06843253916847472		[learning rate: 0.00019292]
		[batch 20/20] avg loss: 0.07220534490222462		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.07031894203534969 | validation: 0.09864325080591094]
	TIME [epoch: 8.31 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0741203624734464		[learning rate: 0.00019198]
		[batch 20/20] avg loss: 0.06905503977693225		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.07158770112518932 | validation: 0.1259610008820716]
	TIME [epoch: 8.32 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07702705988888561		[learning rate: 0.00019105]
		[batch 20/20] avg loss: 0.07875312094674687		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.07789009041781624 | validation: 0.09319474559023214]
	TIME [epoch: 8.33 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08167330322296343		[learning rate: 0.00019013]
		[batch 20/20] avg loss: 0.0745638344849419		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.07811856885395266 | validation: 0.09856045774152405]
	TIME [epoch: 8.32 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06786645100016371		[learning rate: 0.00018921]
		[batch 20/20] avg loss: 0.06909572794614002		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.06848108947315186 | validation: 0.09736486129382718]
	TIME [epoch: 8.32 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07332059468024366		[learning rate: 0.0001883]
		[batch 20/20] avg loss: 0.0783755330235409		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.07584806385189227 | validation: 0.10683178378474736]
	TIME [epoch: 8.32 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07344284009709834		[learning rate: 0.00018739]
		[batch 20/20] avg loss: 0.07664120733140209		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.07504202371425021 | validation: 0.11703321013217376]
	TIME [epoch: 8.32 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06950504991495093		[learning rate: 0.00018648]
		[batch 20/20] avg loss: 0.07623921014741272		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.07287213003118181 | validation: 0.10419625204102304]
	TIME [epoch: 8.33 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07731722072277328		[learning rate: 0.00018558]
		[batch 20/20] avg loss: 0.07721194895863426		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.07726458484070378 | validation: 0.09515563370797503]
	TIME [epoch: 8.33 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07020879800454471		[learning rate: 0.00018468]
		[batch 20/20] avg loss: 0.07063967489641722		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.07042423645048097 | validation: 0.09271405059592246]
	TIME [epoch: 8.31 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07402623473150531		[learning rate: 0.00018379]
		[batch 20/20] avg loss: 0.06582250039434641		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.06992436756292586 | validation: 0.11007437741212955]
	TIME [epoch: 8.33 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07411866959003709		[learning rate: 0.0001829]
		[batch 20/20] avg loss: 0.06836115330537126		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.07123991144770417 | validation: 0.09439685862251178]
	TIME [epoch: 8.34 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07015725923925645		[learning rate: 0.00018201]
		[batch 20/20] avg loss: 0.06921250707042079		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.0696848831548386 | validation: 0.10422154217390409]
	TIME [epoch: 8.31 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07024203630508027		[learning rate: 0.00018113]
		[batch 20/20] avg loss: 0.0695406878542524		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.06989136207966633 | validation: 0.08917195822652976]
	TIME [epoch: 8.31 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07346652533290807		[learning rate: 0.00018026]
		[batch 20/20] avg loss: 0.07110378122802022		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.07228515328046413 | validation: 0.08877120039579002]
	TIME [epoch: 8.34 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07224030054602433		[learning rate: 0.00017939]
		[batch 20/20] avg loss: 0.07223335895736996		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.07223682975169715 | validation: 0.1034361362433263]
	TIME [epoch: 8.32 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07321604059435208		[learning rate: 0.00017852]
		[batch 20/20] avg loss: 0.08251664999546218		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.07786634529490712 | validation: 0.11157379458154057]
	TIME [epoch: 8.31 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07541124842907501		[learning rate: 0.00017766]
		[batch 20/20] avg loss: 0.07035062622085787		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.07288093732496645 | validation: 0.10059447126140313]
	TIME [epoch: 8.32 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.063746251467228		[learning rate: 0.0001768]
		[batch 20/20] avg loss: 0.07215571431610071		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.06795098289166436 | validation: 0.09879975368689684]
	TIME [epoch: 8.34 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0677102392145424		[learning rate: 0.00017594]
		[batch 20/20] avg loss: 0.07128773554591292		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.06949898738022767 | validation: 0.09388991598668162]
	TIME [epoch: 8.31 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07463074245086074		[learning rate: 0.00017509]
		[batch 20/20] avg loss: 0.07282813246810228		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.0737294374594815 | validation: 0.10009393633222531]
	TIME [epoch: 8.33 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07594557607398777		[learning rate: 0.00017424]
		[batch 20/20] avg loss: 0.0865144399138772		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.0812300079939325 | validation: 0.10158407193840957]
	TIME [epoch: 8.31 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07359303762611484		[learning rate: 0.0001734]
		[batch 20/20] avg loss: 0.07459591041525002		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.07409447402068244 | validation: 0.10403231674560198]
	TIME [epoch: 8.33 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07508995504496303		[learning rate: 0.00017256]
		[batch 20/20] avg loss: 0.07717923970557354		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.07613459737526829 | validation: 0.1035848389485684]
	TIME [epoch: 8.33 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07055154828249238		[learning rate: 0.00017173]
		[batch 20/20] avg loss: 0.06826210640851336		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.06940682734550288 | validation: 0.10616509657292128]
	TIME [epoch: 8.31 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07781824503022679		[learning rate: 0.0001709]
		[batch 20/20] avg loss: 0.07137648672782759		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.07459736587902718 | validation: 0.09215029604438914]
	TIME [epoch: 8.3 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07163995427886709		[learning rate: 0.00017007]
		[batch 20/20] avg loss: 0.0644518037742871		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.06804587902657709 | validation: 0.09460978228503363]
	TIME [epoch: 8.34 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06465362061403548		[learning rate: 0.00016925]
		[batch 20/20] avg loss: 0.07218916453342263		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.06842139257372906 | validation: 0.1017056759194815]
	TIME [epoch: 8.31 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0737002245163343		[learning rate: 0.00016843]
		[batch 20/20] avg loss: 0.06581119214917064		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.06975570833275246 | validation: 0.10085271363523451]
	TIME [epoch: 8.31 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07086745088041982		[learning rate: 0.00016762]
		[batch 20/20] avg loss: 0.07181414790975646		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.07134079939508813 | validation: 0.10345052677226509]
	TIME [epoch: 8.33 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07653657879204376		[learning rate: 0.00016681]
		[batch 20/20] avg loss: 0.0727951388805818		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.07466585883631278 | validation: 0.08890235904501037]
	TIME [epoch: 8.33 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.071293233638518		[learning rate: 0.000166]
		[batch 20/20] avg loss: 0.0714318285791319		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.07136253110882497 | validation: 0.09625160065961996]
	TIME [epoch: 8.32 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07445333272384573		[learning rate: 0.0001652]
		[batch 20/20] avg loss: 0.06985585435757828		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.072154593540712 | validation: 0.09285850997236011]
	TIME [epoch: 8.33 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07131153043704735		[learning rate: 0.0001644]
		[batch 20/20] avg loss: 0.08050082763178307		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.07590617903441521 | validation: 0.09377854172321044]
	TIME [epoch: 8.31 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07329197413745711		[learning rate: 0.0001636]
		[batch 20/20] avg loss: 0.07417056477708696		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.07373126945727201 | validation: 0.11303247390913952]
	TIME [epoch: 8.32 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07201276357335842		[learning rate: 0.00016281]
		[batch 20/20] avg loss: 0.07438326380143748		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.07319801368739795 | validation: 0.0994605313479794]
	TIME [epoch: 8.33 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07176382970805656		[learning rate: 0.00016202]
		[batch 20/20] avg loss: 0.07220806763143454		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.07198594866974553 | validation: 0.09685735695737789]
	TIME [epoch: 8.32 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07707872796580978		[learning rate: 0.00016124]
		[batch 20/20] avg loss: 0.06324758617247705		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.07016315706914343 | validation: 0.10055142926961749]
	TIME [epoch: 8.3 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06907790027702256		[learning rate: 0.00016046]
		[batch 20/20] avg loss: 0.07592551374795188		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.07250170701248722 | validation: 0.10517916994964527]
	TIME [epoch: 8.34 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07348987653969821		[learning rate: 0.00015968]
		[batch 20/20] avg loss: 0.07093200967828646		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.07221094310899234 | validation: 0.11600206437749642]
	TIME [epoch: 8.32 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07391079804296978		[learning rate: 0.00015891]
		[batch 20/20] avg loss: 0.07636381267292526		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.07513730535794752 | validation: 0.10215953505206213]
	TIME [epoch: 8.3 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07023133898118032		[learning rate: 0.00015814]
		[batch 20/20] avg loss: 0.07357154174165974		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.07190144036142003 | validation: 0.10141119120367363]
	TIME [epoch: 8.31 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07027241724575983		[learning rate: 0.00015738]
		[batch 20/20] avg loss: 0.08013516759814646		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.07520379242195316 | validation: 0.09735587234943013]
	TIME [epoch: 8.34 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0732327609695731		[learning rate: 0.00015662]
		[batch 20/20] avg loss: 0.071321029575626		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.07227689527259953 | validation: 0.10601494404775155]
	TIME [epoch: 8.31 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0699488857688418		[learning rate: 0.00015586]
		[batch 20/20] avg loss: 0.0750090491616274		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.0724789674652346 | validation: 0.10215972779639232]
	TIME [epoch: 8.31 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07358520195331052		[learning rate: 0.00015511]
		[batch 20/20] avg loss: 0.07502007777275976		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.07430263986303513 | validation: 0.11318708096136851]
	TIME [epoch: 8.32 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07723315104218824		[learning rate: 0.00015436]
		[batch 20/20] avg loss: 0.07472330404105487		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.07597822754162155 | validation: 0.0994623324966399]
	TIME [epoch: 8.32 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07667053590182049		[learning rate: 0.00015361]
		[batch 20/20] avg loss: 0.06870809397504046		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.07268931493843048 | validation: 0.10759704132421319]
	TIME [epoch: 8.31 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07256925679744942		[learning rate: 0.00015287]
		[batch 20/20] avg loss: 0.07168145731461847		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.07212535705603394 | validation: 0.11147966994971831]
	TIME [epoch: 8.31 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08260053120855812		[learning rate: 0.00015213]
		[batch 20/20] avg loss: 0.08263597066780178		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.08261825093817993 | validation: 0.10574887225763248]
	TIME [epoch: 8.32 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07325979950568383		[learning rate: 0.00015139]
		[batch 20/20] avg loss: 0.07514428605656584		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.07420204278112483 | validation: 0.09333563028370005]
	TIME [epoch: 8.32 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06867555315647247		[learning rate: 0.00015066]
		[batch 20/20] avg loss: 0.06950204626882363		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.06908879971264806 | validation: 0.10365251457067945]
	TIME [epoch: 8.32 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07583115264512995		[learning rate: 0.00014993]
		[batch 20/20] avg loss: 0.07031181068021627		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.07307148166267312 | validation: 0.10354276125669512]
	TIME [epoch: 8.33 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07015863654394454		[learning rate: 0.00014921]
		[batch 20/20] avg loss: 0.06932222264650326		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.06974042959522388 | validation: 0.0923649113256972]
	TIME [epoch: 8.3 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.071741987050771		[learning rate: 0.00014849]
		[batch 20/20] avg loss: 0.07503776930171895		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.07338987817624497 | validation: 0.110173060287549]
	TIME [epoch: 8.33 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0707706540718537		[learning rate: 0.00014777]
		[batch 20/20] avg loss: 0.07162248643064263		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.07119657025124816 | validation: 0.10132662459070371]
	TIME [epoch: 8.33 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07577157856740627		[learning rate: 0.00014705]
		[batch 20/20] avg loss: 0.07565655265035912		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.07571406560888269 | validation: 0.10582610644229508]
	TIME [epoch: 8.31 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07680827138117301		[learning rate: 0.00014634]
		[batch 20/20] avg loss: 0.0721829519464252		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.0744956116637991 | validation: 0.09318498861984621]
	TIME [epoch: 8.3 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08010622305620325		[learning rate: 0.00014563]
		[batch 20/20] avg loss: 0.07083405545715042		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.07547013925667685 | validation: 0.10565105782611443]
	TIME [epoch: 8.34 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06902557799949899		[learning rate: 0.00014493]
		[batch 20/20] avg loss: 0.07094667675383509		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.06998612737666704 | validation: 0.10208893140727932]
	TIME [epoch: 8.33 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07337807478560751		[learning rate: 0.00014423]
		[batch 20/20] avg loss: 0.0718308596610246		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.07260446722331607 | validation: 0.10084710137014291]
	TIME [epoch: 8.3 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06568008872242839		[learning rate: 0.00014353]
		[batch 20/20] avg loss: 0.07202671036891196		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.06885339954567017 | validation: 0.10532243841661416]
	TIME [epoch: 8.3 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0687076674586987		[learning rate: 0.00014284]
		[batch 20/20] avg loss: 0.07718310884648225		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.07294538815259047 | validation: 0.10688735868456545]
	TIME [epoch: 8.35 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0714293003508667		[learning rate: 0.00014215]
		[batch 20/20] avg loss: 0.07263478806863718		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.07203204420975194 | validation: 0.10967500623736991]
	TIME [epoch: 8.32 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07613435550994749		[learning rate: 0.00014146]
		[batch 20/20] avg loss: 0.07256199393310823		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.07434817472152785 | validation: 0.11516351564181232]
	TIME [epoch: 8.3 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07907558950485963		[learning rate: 0.00014078]
		[batch 20/20] avg loss: 0.0717003323136799		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.07538796090926975 | validation: 0.10330100119315563]
	TIME [epoch: 8.33 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06950231938365514		[learning rate: 0.00014009]
		[batch 20/20] avg loss: 0.07563728415947997		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.07256980177156755 | validation: 0.09622648444649697]
	TIME [epoch: 8.33 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0767538639078995		[learning rate: 0.00013942]
		[batch 20/20] avg loss: 0.06498285641576929		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.07086836016183437 | validation: 0.09325660217183039]
	TIME [epoch: 8.31 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08174790495307144		[learning rate: 0.00013874]
		[batch 20/20] avg loss: 0.06864019059557158		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.07519404777432151 | validation: 0.10117271324510957]
	TIME [epoch: 8.32 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07369486599035409		[learning rate: 0.00013807]
		[batch 20/20] avg loss: 0.07414178971231525		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.07391832785133465 | validation: 0.10195929030516311]
	TIME [epoch: 8.33 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06848510411604929		[learning rate: 0.0001374]
		[batch 20/20] avg loss: 0.07668063830956526		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.07258287121280728 | validation: 0.09514967394790344]
	TIME [epoch: 8.32 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07942376897870428		[learning rate: 0.00013674]
		[batch 20/20] avg loss: 0.07051706187906073		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.07497041542888251 | validation: 0.10611554896336176]
	TIME [epoch: 8.32 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07239035436486609		[learning rate: 0.00013608]
		[batch 20/20] avg loss: 0.06320188203324008		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.06779611819905307 | validation: 0.11187685845177626]
	TIME [epoch: 8.33 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07428259183316362		[learning rate: 0.00013542]
		[batch 20/20] avg loss: 0.07448190971369903		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.07438225077343133 | validation: 0.10580333354272475]
	TIME [epoch: 8.31 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.067323142207855		[learning rate: 0.00013477]
		[batch 20/20] avg loss: 0.07248793155882541		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.0699055368833402 | validation: 0.10065734464383579]
	TIME [epoch: 8.32 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06945296426426222		[learning rate: 0.00013411]
		[batch 20/20] avg loss: 0.07408469410418664		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.07176882918422445 | validation: 0.10030188443945799]
	TIME [epoch: 8.32 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06512516640954158		[learning rate: 0.00013347]
		[batch 20/20] avg loss: 0.07435650708083476		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.06974083674518818 | validation: 0.1117204012871976]
	TIME [epoch: 8.32 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.069919854786438		[learning rate: 0.00013282]
		[batch 20/20] avg loss: 0.0706435623994199		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.07028170859292895 | validation: 0.10076406760207465]
	TIME [epoch: 8.31 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08038844081943582		[learning rate: 0.00013218]
		[batch 20/20] avg loss: 0.07354109638932378		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.0769647686043798 | validation: 0.0952430689581024]
	TIME [epoch: 8.32 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0719503618673732		[learning rate: 0.00013154]
		[batch 20/20] avg loss: 0.06418070190740413		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.06806553188738867 | validation: 0.10239308991336991]
	TIME [epoch: 8.32 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0662182655427009		[learning rate: 0.0001309]
		[batch 20/20] avg loss: 0.07369317452264659		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.06995572003267375 | validation: 0.10089030220459427]
	TIME [epoch: 8.32 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07621999475116881		[learning rate: 0.00013027]
		[batch 20/20] avg loss: 0.06875468752396875		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.07248734113756879 | validation: 0.10556372116349674]
	TIME [epoch: 8.31 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07600644091047494		[learning rate: 0.00012964]
		[batch 20/20] avg loss: 0.06801876688005873		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.07201260389526683 | validation: 0.11231158351250281]
	TIME [epoch: 8.32 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07194489845271207		[learning rate: 0.00012901]
		[batch 20/20] avg loss: 0.07526866460890283		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.07360678153080746 | validation: 0.09886808328447486]
	TIME [epoch: 8.32 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06943961697912945		[learning rate: 0.00012839]
		[batch 20/20] avg loss: 0.07001193409855813		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.06972577553884379 | validation: 0.10068017047196205]
	TIME [epoch: 8.32 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07553627412265355		[learning rate: 0.00012777]
		[batch 20/20] avg loss: 0.06882355483031302		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.07217991447648331 | validation: 0.09656676803783043]
	TIME [epoch: 8.32 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07008657372377841		[learning rate: 0.00012715]
		[batch 20/20] avg loss: 0.07529161197166043		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.0726890928477194 | validation: 0.0982845371414733]
	TIME [epoch: 8.33 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06801647771752019		[learning rate: 0.00012653]
		[batch 20/20] avg loss: 0.07052887898536271		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.06927267835144146 | validation: 0.09136845160105012]
	TIME [epoch: 8.34 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07638283811557514		[learning rate: 0.00012592]
		[batch 20/20] avg loss: 0.07359579563638854		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.07498931687598184 | validation: 0.09749351100557622]
	TIME [epoch: 8.31 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06853993647615857		[learning rate: 0.00012531]
		[batch 20/20] avg loss: 0.07115136808247323		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.06984565227931591 | validation: 0.09773962004127085]
	TIME [epoch: 8.31 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07214289175166332		[learning rate: 0.00012471]
		[batch 20/20] avg loss: 0.06927830963847217		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.07071060069506777 | validation: 0.10175085167043521]
	TIME [epoch: 8.35 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07651074703027314		[learning rate: 0.00012411]
		[batch 20/20] avg loss: 0.07363300396258318		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.07507187549642816 | validation: 0.11172279789717485]
	TIME [epoch: 8.31 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07501442871131432		[learning rate: 0.0001235]
		[batch 20/20] avg loss: 0.07259357638131045		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.0738040025463124 | validation: 0.09173056146053164]
	TIME [epoch: 8.31 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07137861178711705		[learning rate: 0.00012291]
		[batch 20/20] avg loss: 0.06329609965438623		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.06733735572075165 | validation: 0.10724751455480337]
	TIME [epoch: 8.33 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0718769237967893		[learning rate: 0.00012231]
		[batch 20/20] avg loss: 0.07687927834674953		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.07437810107176941 | validation: 0.1086619474759619]
	TIME [epoch: 8.32 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06989180963156309		[learning rate: 0.00012172]
		[batch 20/20] avg loss: 0.06789645358139217		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.06889413160647764 | validation: 0.10184453931750932]
	TIME [epoch: 8.31 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06739481484384834		[learning rate: 0.00012113]
		[batch 20/20] avg loss: 0.07542012247307911		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.07140746865846373 | validation: 0.10991036866641198]
	TIME [epoch: 8.32 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0797634291494648		[learning rate: 0.00012055]
		[batch 20/20] avg loss: 0.06410660922298016		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.07193501918622248 | validation: 0.09766975843866774]
	TIME [epoch: 8.31 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07868664376346299		[learning rate: 0.00011996]
		[batch 20/20] avg loss: 0.06601980357955725		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.0723532236715101 | validation: 0.09342299519772895]
	TIME [epoch: 8.34 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07550579606207528		[learning rate: 0.00011938]
		[batch 20/20] avg loss: 0.0653153342709502		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.07041056516651273 | validation: 0.08762038072118464]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_964.pth
	Model improved!!!
EPOCH 965/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06834584263291416		[learning rate: 0.00011881]
		[batch 20/20] avg loss: 0.06765988217655275		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.06800286240473344 | validation: 0.09501831270835279]
	TIME [epoch: 8.3 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0647370770831732		[learning rate: 0.00011823]
		[batch 20/20] avg loss: 0.07472941591908598		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.06973324650112958 | validation: 0.0922966981779061]
	TIME [epoch: 8.32 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06420157864528303		[learning rate: 0.00011766]
		[batch 20/20] avg loss: 0.06579455893177757		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.06499806878853032 | validation: 0.100287053939942]
	TIME [epoch: 8.34 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0725560270763935		[learning rate: 0.00011709]
		[batch 20/20] avg loss: 0.06554254793670242		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.06904928750654796 | validation: 0.09776329837347453]
	TIME [epoch: 8.3 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06694888567885257		[learning rate: 0.00011653]
		[batch 20/20] avg loss: 0.06712935824967775		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.06703912196426515 | validation: 0.09716789958317393]
	TIME [epoch: 8.3 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07605844440808072		[learning rate: 0.00011596]
		[batch 20/20] avg loss: 0.0792402972413006		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.07764937082469066 | validation: 0.09237541090542806]
	TIME [epoch: 8.32 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07345659847309478		[learning rate: 0.0001154]
		[batch 20/20] avg loss: 0.06612602167355844		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.06979131007332663 | validation: 0.0955280784519674]
	TIME [epoch: 8.33 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0654997192625842		[learning rate: 0.00011484]
		[batch 20/20] avg loss: 0.06562575891428404		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.06556273908843413 | validation: 0.09102911330123385]
	TIME [epoch: 8.3 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07069033034342945		[learning rate: 0.00011429]
		[batch 20/20] avg loss: 0.06369381998646603		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.06719207516494771 | validation: 0.09368965765976987]
	TIME [epoch: 8.31 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0708151321121433		[learning rate: 0.00011374]
		[batch 20/20] avg loss: 0.06848863668854019		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.06965188440034174 | validation: 0.09221886894264504]
	TIME [epoch: 8.32 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06488658016823953		[learning rate: 0.00011319]
		[batch 20/20] avg loss: 0.07557907283683556		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.07023282650253754 | validation: 0.09257591593361544]
	TIME [epoch: 8.33 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06564967212854592		[learning rate: 0.00011264]
		[batch 20/20] avg loss: 0.07435445410127374		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.07000206311490983 | validation: 0.09351675636380208]
	TIME [epoch: 8.31 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07115417854717576		[learning rate: 0.00011209]
		[batch 20/20] avg loss: 0.06651262011129641		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.06883339932923609 | validation: 0.0816293265081889]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r2_20240218_115025/states/model_tr_study1_977.pth
	Model improved!!!
EPOCH 978/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07329796349692105		[learning rate: 0.00011155]
		[batch 20/20] avg loss: 0.07446486683966644		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.07388141516829375 | validation: 0.0973145084131605]
	TIME [epoch: 8.33 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07125936333559896		[learning rate: 0.00011101]
		[batch 20/20] avg loss: 0.06673484775207755		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.06899710554383826 | validation: 0.09359715273548583]
	TIME [epoch: 8.33 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07168915703808723		[learning rate: 0.00011047]
		[batch 20/20] avg loss: 0.06610761357489547		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.06889838530649135 | validation: 0.11140521242516829]
	TIME [epoch: 8.31 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07026961151769633		[learning rate: 0.00010994]
		[batch 20/20] avg loss: 0.07499707863638966		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.07263334507704297 | validation: 0.10879168440367419]
	TIME [epoch: 8.3 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07177522127659332		[learning rate: 0.00010941]
		[batch 20/20] avg loss: 0.07827487739367045		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.07502504933513189 | validation: 0.09882769179571901]
	TIME [epoch: 8.32 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07430629584317719		[learning rate: 0.00010888]
		[batch 20/20] avg loss: 0.0638641905332141		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.06908524318819563 | validation: 0.10478107365112749]
	TIME [epoch: 8.34 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06973691211817648		[learning rate: 0.00010835]
		[batch 20/20] avg loss: 0.07540423024818901		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.07257057118318275 | validation: 0.10159694574153054]
	TIME [epoch: 8.3 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07008573636874332		[learning rate: 0.00010783]
		[batch 20/20] avg loss: 0.07100686223053322		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.07054629929963827 | validation: 0.0923282622919306]
	TIME [epoch: 8.29 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06692448527366868		[learning rate: 0.00010731]
		[batch 20/20] avg loss: 0.0734855602689106		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.07020502277128962 | validation: 0.10075536994444215]
	TIME [epoch: 8.32 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06978691995523059		[learning rate: 0.00010679]
		[batch 20/20] avg loss: 0.0691484497738221		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.06946768486452634 | validation: 0.09611805498248]
	TIME [epoch: 8.34 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06257651199225002		[learning rate: 0.00010627]
		[batch 20/20] avg loss: 0.0696654251821041		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.06612096858717707 | validation: 0.09846327097410099]
	TIME [epoch: 8.31 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06268280942275359		[learning rate: 0.00010576]
		[batch 20/20] avg loss: 0.06912932819695766		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.06590606880985564 | validation: 0.10187603756502873]
	TIME [epoch: 8.3 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06978676617271615		[learning rate: 0.00010525]
		[batch 20/20] avg loss: 0.062493589139360886		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.06614017765603852 | validation: 0.09781460496134778]
	TIME [epoch: 8.31 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06681641325416232		[learning rate: 0.00010474]
		[batch 20/20] avg loss: 0.06603729929024318		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.06642685627220277 | validation: 0.10389149361379045]
	TIME [epoch: 8.34 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07197226230309778		[learning rate: 0.00010423]
		[batch 20/20] avg loss: 0.06360372961333684		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.0677879959582173 | validation: 0.09009692226424323]
	TIME [epoch: 8.31 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06719281647032674		[learning rate: 0.00010373]
		[batch 20/20] avg loss: 0.06925552898033789		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.06822417272533232 | validation: 0.09329193043528256]
	TIME [epoch: 8.29 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06985983873399643		[learning rate: 0.00010323]
		[batch 20/20] avg loss: 0.06809245099706109		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.06897614486552878 | validation: 0.09461787116212537]
	TIME [epoch: 8.31 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06844451077110073		[learning rate: 0.00010273]
		[batch 20/20] avg loss: 0.06135570609748857		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.06490010843429465 | validation: 0.10123695677471745]
	TIME [epoch: 8.34 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07035208067728428		[learning rate: 0.00010223]
		[batch 20/20] avg loss: 0.0657840758464992		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.06806807826189175 | validation: 0.09644270716139956]
	TIME [epoch: 8.32 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06280841371367527		[learning rate: 0.00010174]
		[batch 20/20] avg loss: 0.07252273420225776		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.06766557395796652 | validation: 0.11167272560744995]
	TIME [epoch: 8.3 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0770778672897924		[learning rate: 0.00010124]
		[batch 20/20] avg loss: 0.06706207897474528		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.07206997313226884 | validation: 0.08828203794129315]
	TIME [epoch: 8.3 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06309807753269285		[learning rate: 0.00010075]
		[batch 20/20] avg loss: 0.06375172208622781		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.06342489980946034 | validation: 0.09323276576719666]
	TIME [epoch: 8.35 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07247832451671143		[learning rate: 0.00010027]
		[batch 20/20] avg loss: 0.06584640513534165		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.06916236482602656 | validation: 0.10864558195649582]
	TIME [epoch: 8.32 sec]
Finished training in 8457.502 seconds.
