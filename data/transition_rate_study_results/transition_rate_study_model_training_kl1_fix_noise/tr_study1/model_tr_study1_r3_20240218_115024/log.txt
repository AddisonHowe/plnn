Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r3', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3334440468

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/20] avg loss: 9.474343567718597		[learning rate: 0.01]
		[batch 20/20] avg loss: 8.46133737100018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.967840469359388 | validation: 7.873292914481085]
	TIME [epoch: 70.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/20] avg loss: 8.187780202548732		[learning rate: 0.01]
		[batch 20/20] avg loss: 8.132354000850029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.16006710169938 | validation: 7.1864090874806195]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/20] avg loss: 7.487809475583552		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.521209672759828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.504509574171689 | validation: 8.172631016366793]
	TIME [epoch: 8.68 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 10/20] avg loss: 7.269801890535833		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.486993890721065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.878397890628449 | validation: 5.188194753329926]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.6797751069007845		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.8839097002912055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.281842403595995 | validation: 5.089739842902974]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/20] avg loss: 5.030455995658555		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.314974687472345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.672715341565449 | validation: 3.383702329876922]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/20] avg loss: 4.082163042617053		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5230414908752588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.802602266746157 | validation: 2.6748811422173446]
	TIME [epoch: 8.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/20] avg loss: 3.6289115367293325		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.910559699266276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2697356179978043 | validation: 2.114986459779033]
	TIME [epoch: 8.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.749624396109242		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0232796680367904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8864520320730174 | validation: 3.394764496459175]
	TIME [epoch: 8.71 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.9592319525663013		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.326327860342512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.642779906454406 | validation: 3.112933875197702]
	TIME [epoch: 8.7 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.3644284404271603		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7897255251985653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5770769828128626 | validation: 1.6737563702894094]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.1199702569587746		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.1409058105561756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.130438033757475 | validation: 1.6485188521370433]
	TIME [epoch: 8.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8392335025780688		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.1094969261289456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9743652143535075 | validation: 1.4606479815912157]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.9577993220694623		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.000790554140003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9792949381047322 | validation: 1.4937140245009373]
	TIME [epoch: 8.73 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8985593331211479		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8577813827471523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.87817035793415 | validation: 1.604085530800027]
	TIME [epoch: 8.75 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8170386400200491		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8756527682305362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8463457041252926 | validation: 1.4610367196572072]
	TIME [epoch: 8.75 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.449432534798931		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7671410580808309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1082867964398817 | validation: 1.5540703447097368]
	TIME [epoch: 8.74 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/20] avg loss: 2.0655325085784964		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7250761513992625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8953043299888797 | validation: 1.9502338805084822]
	TIME [epoch: 8.73 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7738218066288074		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.824762865068908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.799292335848858 | validation: 1.4193057399770184]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.934630986863361		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.8881322180529778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9113816024581691 | validation: 2.4940151393320584]
	TIME [epoch: 8.74 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.8611397983971525		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7516641349707995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8064019666839761 | validation: 1.8306429048034694]
	TIME [epoch: 8.73 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.609427090636801		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.0693903717818514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.839408731209327 | validation: 1.43502169627603]
	TIME [epoch: 8.73 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.482461993542906		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.1721152854698613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8272886395063836 | validation: 1.3746651395398928]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4965279303472343		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.612850542495492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5546892364213634 | validation: 1.4200945196717978]
	TIME [epoch: 8.74 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7396256267269155		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6222415874162208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6809336070715684 | validation: 1.2609229256959218]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.624328292725303		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6444334472888726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.634380870007088 | validation: 1.3669617970839734]
	TIME [epoch: 8.72 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.9378812457244714		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.1046015633632895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0212414045438805 | validation: 1.4109528483041047]
	TIME [epoch: 8.73 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.528435956861337		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.6026346489727388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.565535302917038 | validation: 1.6879833576328223]
	TIME [epoch: 8.73 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.707774985179206		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5681734442283608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.637974214703783 | validation: 1.516558661912569]
	TIME [epoch: 8.75 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.6395552234696287		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5957740601590507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6176646418143399 | validation: 1.3340916701600216]
	TIME [epoch: 8.74 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.601789052824196		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5887555662272466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.595272309525721 | validation: 1.4398042268911562]
	TIME [epoch: 8.72 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.7312574301363568		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.478089162881695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.604673296509026 | validation: 1.2623203013842426]
	TIME [epoch: 8.72 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.479376964798958		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5041013228495077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.491739143824233 | validation: 1.2856993963633057]
	TIME [epoch: 8.71 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5496795034339303		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7652562076884493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.65746785556119 | validation: 2.391619427986114]
	TIME [epoch: 8.74 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5800040594220812		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.7070030967118963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6435035780669889 | validation: 1.4632828806391878]
	TIME [epoch: 8.74 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5763784094043425		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.598081429625126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5872299195147341 | validation: 1.235762957588944]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5941689538034889		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4228471152635243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5085080345335065 | validation: 1.4227560593389166]
	TIME [epoch: 8.71 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4069065051977667		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.480916925269462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.443911715233614 | validation: 1.4408113052669833]
	TIME [epoch: 8.71 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5444176824337958		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.621883454501371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5831505684675833 | validation: 1.1966152609476755]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3578802550310527		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5900445128646925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4739623839478724 | validation: 1.147114669789155]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4087677894116326		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5311798569976405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4699738232046367 | validation: 1.1998886236856983]
	TIME [epoch: 8.73 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5024090279287838		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5367902661788986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5195996470538415 | validation: 1.655525668850844]
	TIME [epoch: 8.71 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5817495144969271		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.571231463330827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5764904889138776 | validation: 1.4009329924402778]
	TIME [epoch: 8.71 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.404139926640273		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.516499889852608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4603199082464406 | validation: 1.2726919218443185]
	TIME [epoch: 8.73 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3831007800416741		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4365356308638333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4098182054527537 | validation: 1.2328703272582737]
	TIME [epoch: 8.71 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4127790383163048		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.331248100062288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3720135691892965 | validation: 1.2564460688659473]
	TIME [epoch: 8.71 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.4539567082176572		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3965631410841648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4252599246509108 | validation: 1.3891643985940916]
	TIME [epoch: 8.7 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3173555396389691		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4118282033999274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.364591871519448 | validation: 1.6358550873392965]
	TIME [epoch: 8.72 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.5864696670906195		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.3677108268947866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.477090246992703 | validation: 1.0806766845393971]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2285427884662554		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4832748927845798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3559088406254178 | validation: 1.0617242919986571]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3898081360262189		[learning rate: 0.0099782]
		[batch 20/20] avg loss: 1.4507534138688447		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.4202807749475315 | validation: 1.1083201981774458]
	TIME [epoch: 8.72 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2901871058836947		[learning rate: 0.00993]
		[batch 20/20] avg loss: 1.3371345235076832		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 1.3136608146956887 | validation: 1.7866552547792738]
	TIME [epoch: 8.7 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.226889233534354		[learning rate: 0.0098819]
		[batch 20/20] avg loss: 1.3199711879593614		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 1.2734302107468578 | validation: 1.3610039063286372]
	TIME [epoch: 8.73 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2049814267099856		[learning rate: 0.0098341]
		[batch 20/20] avg loss: 1.255341460719001		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 1.2301614437144934 | validation: 1.5431193285677516]
	TIME [epoch: 8.73 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2059780541324365		[learning rate: 0.0097866]
		[batch 20/20] avg loss: 1.3674328376993121		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.2867054459158747 | validation: 1.0676508986028557]
	TIME [epoch: 8.73 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.3553392434960856		[learning rate: 0.0097393]
		[batch 20/20] avg loss: 1.2914717620787193		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 1.3234055027874025 | validation: 1.0778936271745219]
	TIME [epoch: 8.73 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2838214236365812		[learning rate: 0.0096922]
		[batch 20/20] avg loss: 1.1094964737833786		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 1.1966589487099801 | validation: 1.8658686157554831]
	TIME [epoch: 8.73 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2931522339869452		[learning rate: 0.0096453]
		[batch 20/20] avg loss: 1.3991210469929685		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.346136640489957 | validation: 1.072621135114947]
	TIME [epoch: 8.73 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2778418410597363		[learning rate: 0.0095987]
		[batch 20/20] avg loss: 1.1884311321187746		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 1.2331364865892556 | validation: 1.3450607196722393]
	TIME [epoch: 8.71 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2534056983401225		[learning rate: 0.0095522]
		[batch 20/20] avg loss: 1.1718764051077841		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.2126410517239532 | validation: 0.8989918274348931]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.172776523234782		[learning rate: 0.009506]
		[batch 20/20] avg loss: 1.1337024779254512		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 1.1532395005801166 | validation: 0.9161314445849081]
	TIME [epoch: 8.72 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1369221290252165		[learning rate: 0.0094601]
		[batch 20/20] avg loss: 1.1666483824536926		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 1.1517852557394543 | validation: 0.7947791170339489]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9791486297573737		[learning rate: 0.0094143]
		[batch 20/20] avg loss: 1.1754372456457043		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 1.077292937701539 | validation: 1.2851422166444118]
	TIME [epoch: 8.75 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.2319330612954982		[learning rate: 0.0093688]
		[batch 20/20] avg loss: 0.8948251182909646		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 1.0633790897932314 | validation: 1.0462986450544445]
	TIME [epoch: 8.73 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.069702223151729		[learning rate: 0.0093235]
		[batch 20/20] avg loss: 0.9430462599599089		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 1.006374241555819 | validation: 0.8139656000268718]
	TIME [epoch: 8.73 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9634105320052896		[learning rate: 0.0092784]
		[batch 20/20] avg loss: 0.8578530089166394		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.9106317704609642 | validation: 0.6880661163519208]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.0537397925144847		[learning rate: 0.0092335]
		[batch 20/20] avg loss: 1.0305799705939127		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 1.0421598815541986 | validation: 0.7482610504838328]
	TIME [epoch: 8.72 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9071557120171692		[learning rate: 0.0091889]
		[batch 20/20] avg loss: 0.8971720505734442		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.9021638812953064 | validation: 0.7197399951589992]
	TIME [epoch: 8.75 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9360015835181684		[learning rate: 0.0091445]
		[batch 20/20] avg loss: 0.7976124935392698		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.8668070385287192 | validation: 0.8154511803866147]
	TIME [epoch: 8.73 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8288786120426798		[learning rate: 0.0091002]
		[batch 20/20] avg loss: 0.9358370908569682		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.8823578514498239 | validation: 0.7417546845258938]
	TIME [epoch: 8.73 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.9298344810998668		[learning rate: 0.0090562]
		[batch 20/20] avg loss: 0.8091088307898611		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.869471655944864 | validation: 0.5295989932678378]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7821548574524891		[learning rate: 0.0090124]
		[batch 20/20] avg loss: 0.9033516286544725		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.8427532430534808 | validation: 0.6221373753357194]
	TIME [epoch: 8.73 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8325373937044948		[learning rate: 0.0089689]
		[batch 20/20] avg loss: 0.7043714228071346		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.7684544082558148 | validation: 1.0339692156908995]
	TIME [epoch: 8.73 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8513528109494063		[learning rate: 0.0089255]
		[batch 20/20] avg loss: 0.871546091122718		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.861449451036062 | validation: 1.0022776707667314]
	TIME [epoch: 8.72 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8796933170867025		[learning rate: 0.0088823]
		[batch 20/20] avg loss: 0.8642742611202875		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.871983789103495 | validation: 0.45885910155605936]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_75.pth
	Model improved!!!
EPOCH 76/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7139644271879392		[learning rate: 0.0088394]
		[batch 20/20] avg loss: 0.7609195262110232		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.7374419766994811 | validation: 0.7019638670905899]
	TIME [epoch: 8.73 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.756740306553717		[learning rate: 0.0087966]
		[batch 20/20] avg loss: 0.8675721268130661		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.8121562166833917 | validation: 0.876975754664874]
	TIME [epoch: 8.75 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8558372448315017		[learning rate: 0.0087541]
		[batch 20/20] avg loss: 0.7461782357638096		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.8010077402976556 | validation: 0.5466812580168339]
	TIME [epoch: 8.74 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7741918765957471		[learning rate: 0.0087117]
		[batch 20/20] avg loss: 0.8779146060344406		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.8260532413150937 | validation: 0.741899110529412]
	TIME [epoch: 8.73 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6459711249504717		[learning rate: 0.0086696]
		[batch 20/20] avg loss: 0.8829158527527433		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.7644434888516075 | validation: 0.4611489689480017]
	TIME [epoch: 8.73 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7614617884593117		[learning rate: 0.0086277]
		[batch 20/20] avg loss: 0.7984563432821895		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.7799590658707507 | validation: 0.6336706300954823]
	TIME [epoch: 8.73 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6641318897579503		[learning rate: 0.008586]
		[batch 20/20] avg loss: 0.6422535861835335		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.6531927379707418 | validation: 0.86559638027794]
	TIME [epoch: 8.76 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8762532429135446		[learning rate: 0.0085445]
		[batch 20/20] avg loss: 0.6356928564584652		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.7559730496860049 | validation: 0.591829743789376]
	TIME [epoch: 8.73 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8513029734780911		[learning rate: 0.0085031]
		[batch 20/20] avg loss: 0.5983443240366847		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.724823648757388 | validation: 0.6439531288687952]
	TIME [epoch: 8.73 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8344026641079388		[learning rate: 0.008462]
		[batch 20/20] avg loss: 0.7984450930166418		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.8164238785622903 | validation: 0.43187154039505055]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6424623549034453		[learning rate: 0.0084211]
		[batch 20/20] avg loss: 0.6896567902190871		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.6660595725612664 | validation: 0.6541744219927902]
	TIME [epoch: 8.73 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8236114334907786		[learning rate: 0.0083804]
		[batch 20/20] avg loss: 0.7013503723796755		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.762480902935227 | validation: 0.6542137887014455]
	TIME [epoch: 8.73 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6814252744135221		[learning rate: 0.0083398]
		[batch 20/20] avg loss: 0.7469750614287645		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.7142001679211433 | validation: 0.7311112116028935]
	TIME [epoch: 8.73 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.656414010910571		[learning rate: 0.0082995]
		[batch 20/20] avg loss: 0.7394405409193039		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.6979272759149375 | validation: 0.5165189066379487]
	TIME [epoch: 8.73 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7418885672373792		[learning rate: 0.0082594]
		[batch 20/20] avg loss: 0.7685006812149531		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.7551946242261662 | validation: 0.4348179604905368]
	TIME [epoch: 8.74 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6779611825107108		[learning rate: 0.0082194]
		[batch 20/20] avg loss: 0.6664289933777081		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.6721950879442097 | validation: 0.7292855910174321]
	TIME [epoch: 8.74 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7136650946390795		[learning rate: 0.0081797]
		[batch 20/20] avg loss: 0.6838265081736843		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.6987458014063819 | validation: 0.4103688976859864]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 10/20] avg loss: 1.1793326888300102		[learning rate: 0.0081401]
		[batch 20/20] avg loss: 0.7370824352166048		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.9582075620233075 | validation: 0.4623608439753798]
	TIME [epoch: 8.72 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.763605620969721		[learning rate: 0.0081008]
		[batch 20/20] avg loss: 0.6923328461895281		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.7279692335796245 | validation: 0.5345316901615306]
	TIME [epoch: 8.73 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7154432361255887		[learning rate: 0.0080616]
		[batch 20/20] avg loss: 0.6623905911604705		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.6889169136430295 | validation: 0.9070760425827556]
	TIME [epoch: 8.73 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6731177654355223		[learning rate: 0.0080226]
		[batch 20/20] avg loss: 0.6436221576165833		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.6583699615260528 | validation: 0.587197223276526]
	TIME [epoch: 8.74 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7499156922815056		[learning rate: 0.0079838]
		[batch 20/20] avg loss: 0.7930557221235491		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.7714857072025273 | validation: 1.5715705374072546]
	TIME [epoch: 8.75 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8849217714115307		[learning rate: 0.0079452]
		[batch 20/20] avg loss: 0.6918177379882343		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.7883697546998825 | validation: 0.4001114310722283]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5880572702470711		[learning rate: 0.0079068]
		[batch 20/20] avg loss: 0.6507196380496535		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.6193884541483623 | validation: 0.8527092493611946]
	TIME [epoch: 8.73 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6390795506808529		[learning rate: 0.0078685]
		[batch 20/20] avg loss: 0.6533158881977156		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.6461977194392843 | validation: 0.6091202986529662]
	TIME [epoch: 8.71 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.720039599183715		[learning rate: 0.0078305]
		[batch 20/20] avg loss: 0.6643061308536454		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.6921728650186804 | validation: 0.784077026679538]
	TIME [epoch: 8.75 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6439966539711395		[learning rate: 0.0077926]
		[batch 20/20] avg loss: 0.7869250817295139		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.7154608678503267 | validation: 0.867350377060038]
	TIME [epoch: 8.72 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7211905155900951		[learning rate: 0.0077549]
		[batch 20/20] avg loss: 0.6718865888773875		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.6965385522337413 | validation: 0.9955720730414723]
	TIME [epoch: 8.72 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8628594322707119		[learning rate: 0.0077174]
		[batch 20/20] avg loss: 0.7457023861173393		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.8042809091940256 | validation: 0.5771393419918063]
	TIME [epoch: 8.73 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7621572361114122		[learning rate: 0.0076801]
		[batch 20/20] avg loss: 0.6494262127421095		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.7057917244267607 | validation: 0.7265231165729372]
	TIME [epoch: 8.74 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6509561483477697		[learning rate: 0.007643]
		[batch 20/20] avg loss: 0.6657931228725359		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.6583746356101529 | validation: 0.6594624419338433]
	TIME [epoch: 8.74 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.818871326648488		[learning rate: 0.007606]
		[batch 20/20] avg loss: 0.8792067860405087		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.8490390563444985 | validation: 0.4616062389871501]
	TIME [epoch: 8.73 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.696327132793626		[learning rate: 0.0075692]
		[batch 20/20] avg loss: 0.6413168602328525		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.6688219965132393 | validation: 0.4482361633500487]
	TIME [epoch: 8.73 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6753902051022898		[learning rate: 0.0075326]
		[batch 20/20] avg loss: 0.7670338635401929		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.7212120343212411 | validation: 1.1904404786253697]
	TIME [epoch: 8.73 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8229775165015966		[learning rate: 0.0074962]
		[batch 20/20] avg loss: 0.8346720650508622		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.8288247907762294 | validation: 0.3131917527705764]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6427143313480425		[learning rate: 0.00746]
		[batch 20/20] avg loss: 0.8453815893497435		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.7440479603488929 | validation: 0.36364807720979303]
	TIME [epoch: 8.76 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7273445315008663		[learning rate: 0.0074239]
		[batch 20/20] avg loss: 0.5862084707606146		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.6567765011307405 | validation: 1.0112584072291342]
	TIME [epoch: 8.74 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7496007428849862		[learning rate: 0.007388]
		[batch 20/20] avg loss: 0.6540650801090877		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.7018329114970369 | validation: 0.4625602117849714]
	TIME [epoch: 8.74 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.678073978439315		[learning rate: 0.0073523]
		[batch 20/20] avg loss: 0.6471013038923996		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.6625876411658573 | validation: 0.5432613536970583]
	TIME [epoch: 8.73 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5993750313887508		[learning rate: 0.0073167]
		[batch 20/20] avg loss: 0.5685375630376004		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.5839562972131755 | validation: 0.40080241842365566]
	TIME [epoch: 8.76 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6480671730776042		[learning rate: 0.0072813]
		[batch 20/20] avg loss: 1.0505537654781176		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.8493104692778608 | validation: 1.4165114359081428]
	TIME [epoch: 8.73 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6235196448480982		[learning rate: 0.0072461]
		[batch 20/20] avg loss: 0.6598618709530156		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.6416907579005571 | validation: 0.6742521256090894]
	TIME [epoch: 8.73 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6338622614560201		[learning rate: 0.0072111]
		[batch 20/20] avg loss: 0.5862673081681672		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.6100647848120937 | validation: 0.34823459507967575]
	TIME [epoch: 8.73 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5916160927825347		[learning rate: 0.0071762]
		[batch 20/20] avg loss: 0.6615543058018005		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.6265851992921676 | validation: 0.3340585238054116]
	TIME [epoch: 8.74 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5697409744025166		[learning rate: 0.0071415]
		[batch 20/20] avg loss: 0.6739326366684391		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.6218368055354777 | validation: 0.7568582830062212]
	TIME [epoch: 8.75 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6119371870651723		[learning rate: 0.007107]
		[batch 20/20] avg loss: 0.7512791721679463		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.6816081796165593 | validation: 0.9312205634176174]
	TIME [epoch: 8.74 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5964314645861771		[learning rate: 0.0070726]
		[batch 20/20] avg loss: 0.5921475540946698		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.5942895093404235 | validation: 0.476567548145896]
	TIME [epoch: 8.74 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5764756363779873		[learning rate: 0.0070384]
		[batch 20/20] avg loss: 0.5106789435875984		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.5435772899827928 | validation: 0.8445550931820933]
	TIME [epoch: 8.73 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.8643900266261031		[learning rate: 0.0070044]
		[batch 20/20] avg loss: 0.6235337572567988		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.743961891941451 | validation: 0.35862187791491795]
	TIME [epoch: 8.72 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6265052226686002		[learning rate: 0.0069705]
		[batch 20/20] avg loss: 0.5508237666661826		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.5886644946673913 | validation: 0.6011964475147201]
	TIME [epoch: 8.74 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6982894326184277		[learning rate: 0.0069368]
		[batch 20/20] avg loss: 0.5692270633958699		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.6337582480071489 | validation: 0.36640944815623755]
	TIME [epoch: 8.72 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6373942441600324		[learning rate: 0.0069032]
		[batch 20/20] avg loss: 0.5467468104339351		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.5920705272969837 | validation: 0.30184769881822726]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5550287661265285		[learning rate: 0.0068699]
		[batch 20/20] avg loss: 0.5908978277405839		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.5729632969335563 | validation: 0.37288019549187845]
	TIME [epoch: 8.81 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5467290412034796		[learning rate: 0.0068366]
		[batch 20/20] avg loss: 0.5368110367516084		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.541770038977544 | validation: 0.3475592709760407]
	TIME [epoch: 8.74 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.653286493984074		[learning rate: 0.0068036]
		[batch 20/20] avg loss: 0.44215734824111347		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.5477219211125938 | validation: 0.5924414324480625]
	TIME [epoch: 8.76 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5418224618963079		[learning rate: 0.0067707]
		[batch 20/20] avg loss: 0.5256010914855243		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.533711776690916 | validation: 0.3363614040366333]
	TIME [epoch: 8.74 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5789803188995609		[learning rate: 0.0067379]
		[batch 20/20] avg loss: 0.5492453531499306		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.5641128360247457 | validation: 0.7612515649244329]
	TIME [epoch: 8.75 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4996851425085699		[learning rate: 0.0067053]
		[batch 20/20] avg loss: 0.541125070093498		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.5204051063010339 | validation: 1.2969693067459114]
	TIME [epoch: 8.73 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7491825471227629		[learning rate: 0.0066729]
		[batch 20/20] avg loss: 0.644683116446837		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.6969328317847998 | validation: 0.5128413374939418]
	TIME [epoch: 8.75 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5415774781024665		[learning rate: 0.0066406]
		[batch 20/20] avg loss: 0.47108951949715844		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.5063334987998125 | validation: 0.913119949086029]
	TIME [epoch: 8.73 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.7194294678317619		[learning rate: 0.0066085]
		[batch 20/20] avg loss: 0.46286856666303633		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.5911490172473993 | validation: 0.5557775615626397]
	TIME [epoch: 8.74 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5531105644681		[learning rate: 0.0065766]
		[batch 20/20] avg loss: 0.6386205053248849		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.5958655348964925 | validation: 0.7440686119003077]
	TIME [epoch: 8.73 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.552666289398785		[learning rate: 0.0065448]
		[batch 20/20] avg loss: 0.5517452731952824		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.5522057812970338 | validation: 0.4411833459905617]
	TIME [epoch: 8.73 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6959973918476001		[learning rate: 0.0065131]
		[batch 20/20] avg loss: 0.4868449079201139		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.5914211498838571 | validation: 0.4441830141621188]
	TIME [epoch: 8.73 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5977980620017854		[learning rate: 0.0064816]
		[batch 20/20] avg loss: 0.5779979301184979		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.5878979960601417 | validation: 0.45768320453967287]
	TIME [epoch: 8.74 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5726762889978262		[learning rate: 0.0064503]
		[batch 20/20] avg loss: 0.5253061413956885		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.5489912151967572 | validation: 0.5371527819568755]
	TIME [epoch: 8.73 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5359615199131127		[learning rate: 0.0064191]
		[batch 20/20] avg loss: 0.6405799367431537		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.5882707283281332 | validation: 0.7138539734371555]
	TIME [epoch: 8.72 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.626637600086804		[learning rate: 0.0063881]
		[batch 20/20] avg loss: 0.5548579574368794		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.5907477787618415 | validation: 0.40369670005458186]
	TIME [epoch: 8.73 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.660493265098535		[learning rate: 0.0063572]
		[batch 20/20] avg loss: 0.5453004826905918		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.6028968738945635 | validation: 0.5441216114664549]
	TIME [epoch: 8.75 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.518512925691629		[learning rate: 0.0063264]
		[batch 20/20] avg loss: 0.4259021581443035		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.4722075419179662 | validation: 0.28589403825096965]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4936425380060803		[learning rate: 0.0062958]
		[batch 20/20] avg loss: 0.4654136567445145		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.47952809737529745 | validation: 0.4015179406135157]
	TIME [epoch: 8.75 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4653722442791649		[learning rate: 0.0062654]
		[batch 20/20] avg loss: 0.5144955428629807		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.48993389357107286 | validation: 0.7140152810423281]
	TIME [epoch: 8.75 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.6019584196788739		[learning rate: 0.0062351]
		[batch 20/20] avg loss: 0.5749925769684258		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.5884754983236499 | validation: 0.3933399288389185]
	TIME [epoch: 8.75 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47943142990834964		[learning rate: 0.0062049]
		[batch 20/20] avg loss: 0.6347510862696594		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.5570912580890045 | validation: 0.5907889713147043]
	TIME [epoch: 8.75 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5027328458021867		[learning rate: 0.0061749]
		[batch 20/20] avg loss: 0.6048111312906779		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.5537719885464323 | validation: 0.4388115805409395]
	TIME [epoch: 8.74 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.689636708693038		[learning rate: 0.0061451]
		[batch 20/20] avg loss: 0.5636705744871716		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.626653641590105 | validation: 0.34747919822024276]
	TIME [epoch: 8.74 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4821837933288246		[learning rate: 0.0061153]
		[batch 20/20] avg loss: 0.5200862776311944		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.5011350354800095 | validation: 0.4502391298636499]
	TIME [epoch: 8.74 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5253492640638419		[learning rate: 0.0060858]
		[batch 20/20] avg loss: 0.604187834124807		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.5647685490943244 | validation: 0.7568872248067662]
	TIME [epoch: 8.75 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.508931068039437		[learning rate: 0.0060563]
		[batch 20/20] avg loss: 0.4571474425787926		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.48303925530911485 | validation: 0.42202858769061175]
	TIME [epoch: 8.73 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.46804952321437493		[learning rate: 0.0060271]
		[batch 20/20] avg loss: 0.5007594295560599		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.4844044763852173 | validation: 0.822374612919972]
	TIME [epoch: 8.72 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.727743254917782		[learning rate: 0.0059979]
		[batch 20/20] avg loss: 0.6309137657035951		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.6793285103106885 | validation: 0.24252000013746478]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_156.pth
	Model improved!!!
EPOCH 157/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38191423645249234		[learning rate: 0.0059689]
		[batch 20/20] avg loss: 0.5709778318828173		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.47644603416765474 | validation: 0.6131577216471844]
	TIME [epoch: 8.73 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.555519686670133		[learning rate: 0.00594]
		[batch 20/20] avg loss: 0.49770717627224537		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.5266134314711891 | validation: 0.3603285546137925]
	TIME [epoch: 8.75 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.42013309824666445		[learning rate: 0.0059113]
		[batch 20/20] avg loss: 0.6416972085192826		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.5309151533829736 | validation: 0.4451507132689143]
	TIME [epoch: 8.73 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5849217924790564		[learning rate: 0.0058827]
		[batch 20/20] avg loss: 0.4351390771405307		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.5100304348097937 | validation: 0.5121251072685771]
	TIME [epoch: 8.74 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49305174792410683		[learning rate: 0.0058543]
		[batch 20/20] avg loss: 0.4323823973328139		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.46271707262846035 | validation: 0.2722375993971663]
	TIME [epoch: 8.74 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41745629607985685		[learning rate: 0.005826]
		[batch 20/20] avg loss: 0.5177363508092637		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.46759632344456037 | validation: 0.6367356547018459]
	TIME [epoch: 8.74 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5284858125804964		[learning rate: 0.0057978]
		[batch 20/20] avg loss: 0.4762994023939541		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.5023926074872251 | validation: 0.3051455098772557]
	TIME [epoch: 8.76 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45988723625211414		[learning rate: 0.0057698]
		[batch 20/20] avg loss: 0.3333389985202598		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.396613117386187 | validation: 0.27481527022493124]
	TIME [epoch: 8.74 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5266275975289287		[learning rate: 0.0057419]
		[batch 20/20] avg loss: 0.3955283665054717		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.4610779820172003 | validation: 0.4473551529953158]
	TIME [epoch: 8.75 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4942344287320373		[learning rate: 0.0057141]
		[batch 20/20] avg loss: 0.4023266029911139		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.4482805158615756 | validation: 0.33133889044082016]
	TIME [epoch: 8.75 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5037544333687366		[learning rate: 0.0056865]
		[batch 20/20] avg loss: 0.5290801104649471		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.5164172719168418 | validation: 0.49300159679210054]
	TIME [epoch: 8.73 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4348021020719502		[learning rate: 0.005659]
		[batch 20/20] avg loss: 0.5106978822181869		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.4727499921450685 | validation: 0.7137354810951215]
	TIME [epoch: 8.74 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39026667910256196		[learning rate: 0.0056316]
		[batch 20/20] avg loss: 0.4353453199456074		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.41280599952408475 | validation: 0.30490101905083583]
	TIME [epoch: 8.74 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36976619587938087		[learning rate: 0.0056044]
		[batch 20/20] avg loss: 0.3196067661287474		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.34468648100406407 | validation: 0.30244617910990257]
	TIME [epoch: 8.72 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.426307565242858		[learning rate: 0.0055773]
		[batch 20/20] avg loss: 0.32046393627238323		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.37338575075762065 | validation: 0.4698360038174915]
	TIME [epoch: 8.75 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.45958207185080163		[learning rate: 0.0055503]
		[batch 20/20] avg loss: 0.4246462460352804		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.44211415894304107 | validation: 0.6162749160851422]
	TIME [epoch: 8.75 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41220794401521604		[learning rate: 0.0055235]
		[batch 20/20] avg loss: 0.4106750246392948		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.4114414843272554 | validation: 0.3069727041557575]
	TIME [epoch: 8.77 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.48558675934778933		[learning rate: 0.0054967]
		[batch 20/20] avg loss: 0.3846989910660189		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.4351428752069042 | validation: 0.3338760071117242]
	TIME [epoch: 8.74 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4491211376171621		[learning rate: 0.0054702]
		[batch 20/20] avg loss: 0.38802734169034625		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.4185742396537542 | validation: 0.39199482437344146]
	TIME [epoch: 8.73 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39237020151091556		[learning rate: 0.0054437]
		[batch 20/20] avg loss: 0.5131485498872123		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.45275937569906394 | validation: 0.41962234243129176]
	TIME [epoch: 8.72 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3064268458164189		[learning rate: 0.0054174]
		[batch 20/20] avg loss: 0.48900121554099074		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.39771403067870476 | validation: 1.1668809009793075]
	TIME [epoch: 8.75 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5646347640047521		[learning rate: 0.0053912]
		[batch 20/20] avg loss: 0.4227348364043396		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.49368480020454586 | validation: 0.28124790034044383]
	TIME [epoch: 8.76 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43633609853995675		[learning rate: 0.0053651]
		[batch 20/20] avg loss: 0.44586605287536096		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.4411010757076589 | validation: 0.8699968756384057]
	TIME [epoch: 8.74 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5024167481912948		[learning rate: 0.0053392]
		[batch 20/20] avg loss: 0.4462606224698563		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.47433868533057566 | validation: 0.5875888770525586]
	TIME [epoch: 8.73 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3456023961092663		[learning rate: 0.0053133]
		[batch 20/20] avg loss: 0.36289546766374287		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.3542489318865045 | validation: 0.42651183411776483]
	TIME [epoch: 8.71 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4008567372073394		[learning rate: 0.0052877]
		[batch 20/20] avg loss: 0.41453711337261956		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.4076969252899795 | validation: 0.3143439135421159]
	TIME [epoch: 8.73 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37541400545348136		[learning rate: 0.0052621]
		[batch 20/20] avg loss: 0.3883499711216401		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.3818819882875607 | validation: 0.33970838496211997]
	TIME [epoch: 8.73 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3510601116261948		[learning rate: 0.0052366]
		[batch 20/20] avg loss: 0.42174640126349694		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.38640325644484597 | validation: 0.3542850771284573]
	TIME [epoch: 8.73 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4115980226230497		[learning rate: 0.0052113]
		[batch 20/20] avg loss: 0.36833132347045977		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.38996467304675486 | validation: 0.2222350393505944]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_185.pth
	Model improved!!!
EPOCH 186/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36495603860690246		[learning rate: 0.0051861]
		[batch 20/20] avg loss: 0.45632787592737134		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.41064195726713687 | validation: 0.35524421855909566]
	TIME [epoch: 8.74 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3520296637907762		[learning rate: 0.005161]
		[batch 20/20] avg loss: 0.4142370296923188		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.38313334674154753 | validation: 0.3434870369160022]
	TIME [epoch: 8.77 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.49780815120455435		[learning rate: 0.0051361]
		[batch 20/20] avg loss: 0.4076540908222288		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.4527311210133916 | validation: 0.25260725978028836]
	TIME [epoch: 8.75 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.432609200108885		[learning rate: 0.0051112]
		[batch 20/20] avg loss: 0.31626525567652713		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.37443722789270606 | validation: 0.34691870879622744]
	TIME [epoch: 8.73 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33952621813058814		[learning rate: 0.0050865]
		[batch 20/20] avg loss: 0.46324012291954064		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.40138317052506445 | validation: 0.6622213061774663]
	TIME [epoch: 8.73 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.5129175042073044		[learning rate: 0.0050619]
		[batch 20/20] avg loss: 0.4148726279754961		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.4638950660914004 | validation: 0.4737905810467855]
	TIME [epoch: 8.74 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4288381747644549		[learning rate: 0.0050374]
		[batch 20/20] avg loss: 0.42134986795592366		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.42509402136018926 | validation: 0.3796670791955609]
	TIME [epoch: 8.75 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39671814397667593		[learning rate: 0.0050131]
		[batch 20/20] avg loss: 0.373393874773247		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.3850560093749614 | validation: 0.2828109585791226]
	TIME [epoch: 8.76 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39323120737267003		[learning rate: 0.0049888]
		[batch 20/20] avg loss: 0.37164411675889547		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.38243766206578267 | validation: 0.16171651644940077]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.41675146567133475		[learning rate: 0.0049647]
		[batch 20/20] avg loss: 0.508882747178515		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.46281710642492485 | validation: 0.3003821964105287]
	TIME [epoch: 8.75 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3844933619776806		[learning rate: 0.0049407]
		[batch 20/20] avg loss: 0.3567047148588124		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.37059903841824654 | validation: 0.25595389624729753]
	TIME [epoch: 8.73 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4948020779348369		[learning rate: 0.0049168]
		[batch 20/20] avg loss: 0.3949787293288394		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.44489040363183807 | validation: 0.29288233985663303]
	TIME [epoch: 8.75 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30040661920228207		[learning rate: 0.004893]
		[batch 20/20] avg loss: 0.3893444064855712		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.34487551284392665 | validation: 0.4157590895859666]
	TIME [epoch: 8.75 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.43138239963521824		[learning rate: 0.0048694]
		[batch 20/20] avg loss: 0.3796943114538403		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.4055383555445293 | validation: 0.4026895083127394]
	TIME [epoch: 8.74 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38320320068533		[learning rate: 0.0048458]
		[batch 20/20] avg loss: 0.32918335326751047		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.3561932769764203 | validation: 0.26239819395717107]
	TIME [epoch: 8.75 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.37599854582354597		[learning rate: 0.0048224]
		[batch 20/20] avg loss: 0.31050119068062887		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.34324986825208736 | validation: 0.2145357916158741]
	TIME [epoch: 8.75 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29117189605782035		[learning rate: 0.0047991]
		[batch 20/20] avg loss: 0.2950837205707006		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.2931278083142604 | validation: 0.282051476543639]
	TIME [epoch: 8.77 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3151188694743922		[learning rate: 0.0047759]
		[batch 20/20] avg loss: 0.3867655732983929		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.3509422213863926 | validation: 0.5664533254961259]
	TIME [epoch: 8.76 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3554648251779239		[learning rate: 0.0047528]
		[batch 20/20] avg loss: 0.4554774359453407		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.40547113056163225 | validation: 0.2912408885331511]
	TIME [epoch: 8.73 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28375170541800526		[learning rate: 0.0047298]
		[batch 20/20] avg loss: 0.3744165341621696		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.32908411979008745 | validation: 0.281721498292114]
	TIME [epoch: 8.74 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.34469677069518845		[learning rate: 0.0047069]
		[batch 20/20] avg loss: 0.3313518445416886		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.3380243076184385 | validation: 0.6537969544221103]
	TIME [epoch: 8.75 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3280221941994383		[learning rate: 0.0046842]
		[batch 20/20] avg loss: 0.3646103446885295		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.3463162694439839 | validation: 0.40341877304431456]
	TIME [epoch: 8.78 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.47861315528458903		[learning rate: 0.0046615]
		[batch 20/20] avg loss: 0.32007002521979		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.39934159025218957 | validation: 0.2635064606938478]
	TIME [epoch: 8.74 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4093734324094379		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.3299588885589321		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.369666160484185 | validation: 0.30234018138978497]
	TIME [epoch: 8.74 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2949812696439015		[learning rate: 0.0046165]
		[batch 20/20] avg loss: 0.2949312508136284		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.2949562602287649 | validation: 0.2553465200191386]
	TIME [epoch: 8.73 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.38964826069975506		[learning rate: 0.0045942]
		[batch 20/20] avg loss: 0.40457822072425564		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.3971132407120054 | validation: 0.24364566579248065]
	TIME [epoch: 8.75 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3985859068519667		[learning rate: 0.004572]
		[batch 20/20] avg loss: 0.3167213819368603		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.35765364439441344 | validation: 0.3687870140880587]
	TIME [epoch: 8.77 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.39623233513063355		[learning rate: 0.0045499]
		[batch 20/20] avg loss: 0.36750803263823545		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.38187018388443444 | validation: 0.3140235938068626]
	TIME [epoch: 8.76 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.32367008306655387		[learning rate: 0.0045279]
		[batch 20/20] avg loss: 0.3642531437451561		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.3439616134058549 | validation: 0.30887954385305394]
	TIME [epoch: 8.76 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36333593074998044		[learning rate: 0.004506]
		[batch 20/20] avg loss: 0.3739129618819008		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.3686244463159406 | validation: 0.24864348626681654]
	TIME [epoch: 8.75 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.31989657672265326		[learning rate: 0.0044842]
		[batch 20/20] avg loss: 0.36137516852970325		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.3406358726261783 | validation: 0.43343815647594963]
	TIME [epoch: 8.75 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36136083473029457		[learning rate: 0.0044625]
		[batch 20/20] avg loss: 0.35849331772820553		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.35992707622925 | validation: 0.5058798964152177]
	TIME [epoch: 8.77 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2797213793676204		[learning rate: 0.0044409]
		[batch 20/20] avg loss: 0.31692940014904386		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.2983253897583321 | validation: 0.29207133869965435]
	TIME [epoch: 8.76 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33710704782170764		[learning rate: 0.0044195]
		[batch 20/20] avg loss: 0.2855725156478739		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.3113397817347908 | validation: 0.3432196399018892]
	TIME [epoch: 8.74 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33314481097432613		[learning rate: 0.0043981]
		[batch 20/20] avg loss: 0.33083908775982057		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.3319919493670733 | validation: 0.20104315284543642]
	TIME [epoch: 8.74 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3101679294618083		[learning rate: 0.0043768]
		[batch 20/20] avg loss: 0.29020438045496083		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.3001861549583845 | validation: 0.2057261125547909]
	TIME [epoch: 8.78 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3083876548192647		[learning rate: 0.0043556]
		[batch 20/20] avg loss: 0.3203563888213353		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.3143720218203 | validation: 0.43955850194972457]
	TIME [epoch: 8.74 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3082057817722377		[learning rate: 0.0043346]
		[batch 20/20] avg loss: 0.3147584505302524		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.31148211615124505 | validation: 0.24230985212736356]
	TIME [epoch: 8.73 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29167671257102573		[learning rate: 0.0043136]
		[batch 20/20] avg loss: 0.2830017380946107		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.28733922533281825 | validation: 0.1845295778668512]
	TIME [epoch: 8.73 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2721050283293717		[learning rate: 0.0042928]
		[batch 20/20] avg loss: 0.2647048311673749		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.2684049297483734 | validation: 0.8061234673553446]
	TIME [epoch: 8.74 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3637153810955009		[learning rate: 0.004272]
		[batch 20/20] avg loss: 0.29766571410153525		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.33069054759851807 | validation: 0.21941437267282524]
	TIME [epoch: 8.77 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.342720087426697		[learning rate: 0.0042513]
		[batch 20/20] avg loss: 0.28399686142971625		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.31335847442820663 | validation: 0.4650709587111058]
	TIME [epoch: 8.74 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3840511385269825		[learning rate: 0.0042308]
		[batch 20/20] avg loss: 0.3220045182990621		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.3530278284130223 | validation: 0.19591610418224983]
	TIME [epoch: 8.73 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.346746549150752		[learning rate: 0.0042103]
		[batch 20/20] avg loss: 0.30064528775109295		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.3236959184509225 | validation: 0.4674469563214022]
	TIME [epoch: 8.75 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4113057560979726		[learning rate: 0.00419]
		[batch 20/20] avg loss: 0.30080307570205644		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.3560544159000144 | validation: 0.16832681880637193]
	TIME [epoch: 8.74 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29977355637938136		[learning rate: 0.0041697]
		[batch 20/20] avg loss: 0.3502477166269228		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.32501063650315204 | validation: 0.20166641856818426]
	TIME [epoch: 8.77 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3338308357619347		[learning rate: 0.0041495]
		[batch 20/20] avg loss: 0.35101928707478924		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.34242506141836193 | validation: 0.1729555253060706]
	TIME [epoch: 8.74 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.4137162381137191		[learning rate: 0.0041295]
		[batch 20/20] avg loss: 0.29730978224406035		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.3555130101788897 | validation: 0.29015651764219547]
	TIME [epoch: 8.75 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29648198236294554		[learning rate: 0.0041095]
		[batch 20/20] avg loss: 0.3200599127037686		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.3082709475333571 | validation: 0.1733612560834947]
	TIME [epoch: 8.74 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25111139257292814		[learning rate: 0.0040896]
		[batch 20/20] avg loss: 0.2935076897477939		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.2723095411603611 | validation: 0.3081400372076113]
	TIME [epoch: 8.75 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27647341383849267		[learning rate: 0.0040699]
		[batch 20/20] avg loss: 0.29098889196632005		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.28373115290240636 | validation: 0.25490867701126296]
	TIME [epoch: 8.75 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30963900028656655		[learning rate: 0.0040502]
		[batch 20/20] avg loss: 0.32863264152938215		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.3191358209079743 | validation: 0.6151481983062416]
	TIME [epoch: 8.73 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36519194770222596		[learning rate: 0.0040306]
		[batch 20/20] avg loss: 0.27879397087494273		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.32199295928858435 | validation: 0.29408566824754806]
	TIME [epoch: 8.74 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29130212910031367		[learning rate: 0.0040111]
		[batch 20/20] avg loss: 0.33337772452136144		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.31233992681083755 | validation: 0.32341894900916646]
	TIME [epoch: 8.72 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2762816741021156		[learning rate: 0.0039917]
		[batch 20/20] avg loss: 0.4865125950408237		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.3813971345714696 | validation: 0.22181277669137817]
	TIME [epoch: 8.75 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2518709839352312		[learning rate: 0.0039724]
		[batch 20/20] avg loss: 0.31433990435012527		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.28310544414267824 | validation: 0.5604996530351268]
	TIME [epoch: 8.75 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2828015065264695		[learning rate: 0.0039532]
		[batch 20/20] avg loss: 0.28226297484001084		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.2825322406832401 | validation: 0.7413556942741293]
	TIME [epoch: 8.75 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36096467090834333		[learning rate: 0.0039341]
		[batch 20/20] avg loss: 0.2842352106978994		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.3225999408031214 | validation: 0.29010720535883927]
	TIME [epoch: 8.75 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3092718241702335		[learning rate: 0.003915]
		[batch 20/20] avg loss: 0.2601451760903104		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.28470850013027194 | validation: 0.16647487003187955]
	TIME [epoch: 8.75 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28154058668650134		[learning rate: 0.0038961]
		[batch 20/20] avg loss: 0.24271780549747363		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.2621291960919875 | validation: 0.680035229760336]
	TIME [epoch: 8.77 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.36799360179666535		[learning rate: 0.0038773]
		[batch 20/20] avg loss: 0.27379957119920595		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.32089658649793573 | validation: 0.29931063805395175]
	TIME [epoch: 8.76 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2872199148359688		[learning rate: 0.0038585]
		[batch 20/20] avg loss: 0.3491783370210037		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.3181991259284862 | validation: 0.3827875462605736]
	TIME [epoch: 8.74 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27774652939493055		[learning rate: 0.0038399]
		[batch 20/20] avg loss: 0.3232444290753137		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.3004954792351221 | validation: 0.23982267626351117]
	TIME [epoch: 8.76 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3267111724043398		[learning rate: 0.0038213]
		[batch 20/20] avg loss: 0.2950991942523473		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.31090518332834355 | validation: 0.36970816975499476]
	TIME [epoch: 8.75 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3103667998695504		[learning rate: 0.0038028]
		[batch 20/20] avg loss: 0.3331416285433008		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.3217542142064256 | validation: 0.281196545010851]
	TIME [epoch: 8.75 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3142206969619122		[learning rate: 0.0037844]
		[batch 20/20] avg loss: 0.2437861869973738		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.279003441979643 | validation: 0.2664134470428504]
	TIME [epoch: 8.75 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3776055659852512		[learning rate: 0.0037661]
		[batch 20/20] avg loss: 0.29875005132283483		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.338177808654043 | validation: 0.24310419938673014]
	TIME [epoch: 8.73 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3765267377299389		[learning rate: 0.0037479]
		[batch 20/20] avg loss: 0.29586089244883484		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.33619381508938684 | validation: 0.18716655144187624]
	TIME [epoch: 8.75 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.33559240473208496		[learning rate: 0.0037298]
		[batch 20/20] avg loss: 0.3363490998242102		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.3359707522781477 | validation: 0.21434586531087566]
	TIME [epoch: 8.77 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27047810256345195		[learning rate: 0.0037118]
		[batch 20/20] avg loss: 0.3226932591864643		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.2965856808749582 | validation: 0.3506690784547842]
	TIME [epoch: 8.78 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3743530963369167		[learning rate: 0.0036938]
		[batch 20/20] avg loss: 0.3112449591468584		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.34279902774188753 | validation: 0.2675581977742147]
	TIME [epoch: 8.75 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2889598715769153		[learning rate: 0.0036759]
		[batch 20/20] avg loss: 0.3139885036959618		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.3014741876364385 | validation: 0.3608451687336666]
	TIME [epoch: 8.73 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27096034625908744		[learning rate: 0.0036582]
		[batch 20/20] avg loss: 0.2965037424278089		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.2837320443434482 | validation: 0.331172871813814]
	TIME [epoch: 8.73 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2889083416732257		[learning rate: 0.0036405]
		[batch 20/20] avg loss: 0.24956599800134605		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.2692371698372859 | validation: 0.2649659496081396]
	TIME [epoch: 8.72 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2775000546303808		[learning rate: 0.0036229]
		[batch 20/20] avg loss: 0.3187692526305198		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.2981346536304502 | validation: 0.229591554116114]
	TIME [epoch: 8.75 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.290480892031599		[learning rate: 0.0036053]
		[batch 20/20] avg loss: 0.27275180210618816		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.2816163470688935 | validation: 0.3939179119042395]
	TIME [epoch: 8.73 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2660864673281101		[learning rate: 0.0035879]
		[batch 20/20] avg loss: 0.25779907674687813		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.2619427720374941 | validation: 0.37035142185208314]
	TIME [epoch: 8.73 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3831145597441313		[learning rate: 0.0035706]
		[batch 20/20] avg loss: 0.25835975032857006		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.3207371550363507 | validation: 0.1806142872155173]
	TIME [epoch: 8.7 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25602295660326324		[learning rate: 0.0035533]
		[batch 20/20] avg loss: 0.2563428969799527		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.256182926791608 | validation: 0.1746906907323441]
	TIME [epoch: 8.73 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2511567899412831		[learning rate: 0.0035361]
		[batch 20/20] avg loss: 0.27431221375550646		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.26273450184839475 | validation: 0.3665892380836258]
	TIME [epoch: 8.7 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28783971788868246		[learning rate: 0.003519]
		[batch 20/20] avg loss: 0.2619822867760358		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.27491100233235916 | validation: 0.2885326288673445]
	TIME [epoch: 8.71 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3370793353966246		[learning rate: 0.003502]
		[batch 20/20] avg loss: 0.3235792966121559		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.33032931600439036 | validation: 0.17292051690121604]
	TIME [epoch: 8.71 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3103230524229049		[learning rate: 0.0034851]
		[batch 20/20] avg loss: 0.31877561131473076		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.3145493318688179 | validation: 0.23084575968638008]
	TIME [epoch: 8.7 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2420960045837691		[learning rate: 0.0034682]
		[batch 20/20] avg loss: 0.28078287941911223		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.26143944200144065 | validation: 0.48186577503134154]
	TIME [epoch: 8.75 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3081711767925298		[learning rate: 0.0034514]
		[batch 20/20] avg loss: 0.27968046850505146		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.29392582264879064 | validation: 0.20622307722817243]
	TIME [epoch: 8.69 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24848678362583243		[learning rate: 0.0034347]
		[batch 20/20] avg loss: 0.2930123978893022		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.2707495907575674 | validation: 0.3646260909829377]
	TIME [epoch: 8.71 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24734434304747954		[learning rate: 0.0034181]
		[batch 20/20] avg loss: 0.34472045813558616		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.2960324005915328 | validation: 0.24001774035615486]
	TIME [epoch: 8.69 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24421296223472289		[learning rate: 0.0034016]
		[batch 20/20] avg loss: 0.2885699583330285		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.2663914602838758 | validation: 0.20599320169617324]
	TIME [epoch: 8.71 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24269990238572747		[learning rate: 0.0033852]
		[batch 20/20] avg loss: 0.2746623483654773		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.2586811253756024 | validation: 0.357808355794067]
	TIME [epoch: 8.74 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.29683354866346945		[learning rate: 0.0033688]
		[batch 20/20] avg loss: 0.2360059748662465		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.26641976176485793 | validation: 0.18375862322094558]
	TIME [epoch: 8.71 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30587005360300046		[learning rate: 0.0033525]
		[batch 20/20] avg loss: 0.2831862043149021		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.2945281289589513 | validation: 0.23364703244111307]
	TIME [epoch: 8.7 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2588730221017891		[learning rate: 0.0033363]
		[batch 20/20] avg loss: 0.28579364912485566		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.27233333561332235 | validation: 0.32304717191062743]
	TIME [epoch: 8.68 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2619305215750597		[learning rate: 0.0033202]
		[batch 20/20] avg loss: 0.22019281868423177		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.24106167012964574 | validation: 0.3345249279882856]
	TIME [epoch: 8.7 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27943105701796644		[learning rate: 0.0033041]
		[batch 20/20] avg loss: 0.31280287138842783		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.29611696420319716 | validation: 0.2617413404465716]
	TIME [epoch: 8.71 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22307692035951657		[learning rate: 0.0032881]
		[batch 20/20] avg loss: 0.27793787085284516		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.25050739560618085 | validation: 0.2665561067981465]
	TIME [epoch: 8.69 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2746617774368657		[learning rate: 0.0032722]
		[batch 20/20] avg loss: 0.23213030094480488		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.2533960391908353 | validation: 0.3972517213993986]
	TIME [epoch: 8.7 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3002721268433811		[learning rate: 0.0032564]
		[batch 20/20] avg loss: 0.256554015390993		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.278413071117187 | validation: 0.15885890678270892]
	TIME [epoch: 8.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_282.pth
	Model improved!!!
EPOCH 283/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21731919888211326		[learning rate: 0.0032406]
		[batch 20/20] avg loss: 0.32101338628094384		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.2691662925815286 | validation: 0.35625447211580363]
	TIME [epoch: 8.75 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25636312886122337		[learning rate: 0.003225]
		[batch 20/20] avg loss: 0.2083577665783615		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.23236044771979242 | validation: 0.12526348146794516]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2200312391931365		[learning rate: 0.0032094]
		[batch 20/20] avg loss: 0.2298029968340239		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.2249171180135802 | validation: 0.34990958093597435]
	TIME [epoch: 8.75 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.27826033223042385		[learning rate: 0.0031939]
		[batch 20/20] avg loss: 0.2415593716792884		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.25990985195485616 | validation: 0.201882080317013]
	TIME [epoch: 8.75 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24843781668137144		[learning rate: 0.0031784]
		[batch 20/20] avg loss: 0.22779279158963064		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.23811530413550103 | validation: 0.11199170735828837]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2151448310326874		[learning rate: 0.003163]
		[batch 20/20] avg loss: 0.22979002321137076		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.2224674271220291 | validation: 0.24570250679664826]
	TIME [epoch: 8.76 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17788471238910294		[learning rate: 0.0031477]
		[batch 20/20] avg loss: 0.23899849438236215		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.2084416033857326 | validation: 0.31676661247704363]
	TIME [epoch: 8.77 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.231014861081817		[learning rate: 0.0031325]
		[batch 20/20] avg loss: 0.20367519137677498		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.2173450262292959 | validation: 0.2014708032432275]
	TIME [epoch: 8.74 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2603818979850595		[learning rate: 0.0031174]
		[batch 20/20] avg loss: 0.24619213751092786		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.25328701774799367 | validation: 0.25100457318057073]
	TIME [epoch: 8.73 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22645606952172154		[learning rate: 0.0031023]
		[batch 20/20] avg loss: 0.25635635726909106		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.2414062133954063 | validation: 0.2497387988543704]
	TIME [epoch: 8.73 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20804394260135153		[learning rate: 0.0030873]
		[batch 20/20] avg loss: 0.22140047532858845		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.21472220896497 | validation: 0.27612528249014273]
	TIME [epoch: 8.75 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2639237291264759		[learning rate: 0.0030724]
		[batch 20/20] avg loss: 0.3587348872171484		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.31132930817181215 | validation: 0.2770428837991077]
	TIME [epoch: 8.75 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23694516692062756		[learning rate: 0.0030575]
		[batch 20/20] avg loss: 0.2805017986765909		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.25872348279860924 | validation: 0.22007290465711415]
	TIME [epoch: 8.75 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25228037025631744		[learning rate: 0.0030427]
		[batch 20/20] avg loss: 0.24387373030445123		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.2480770502803844 | validation: 0.23366129038690875]
	TIME [epoch: 8.74 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25343800080173673		[learning rate: 0.003028]
		[batch 20/20] avg loss: 0.2237514819496907		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.23859474137571374 | validation: 0.27715270155325045]
	TIME [epoch: 8.75 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24216403701872916		[learning rate: 0.0030134]
		[batch 20/20] avg loss: 0.22348500061807827		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.23282451881840371 | validation: 0.29271697784922396]
	TIME [epoch: 8.75 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2854163050044337		[learning rate: 0.0029988]
		[batch 20/20] avg loss: 0.1844952455509708		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.23495577527770223 | validation: 0.20404164076295517]
	TIME [epoch: 8.77 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22672638620789937		[learning rate: 0.0029843]
		[batch 20/20] avg loss: 0.2034600457459151		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.21509321597690723 | validation: 0.20012569969882668]
	TIME [epoch: 8.75 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25266233752774664		[learning rate: 0.0029699]
		[batch 20/20] avg loss: 0.20830364763810733		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.23048299258292698 | validation: 0.14860889732385205]
	TIME [epoch: 8.75 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25200480271434017		[learning rate: 0.0029555]
		[batch 20/20] avg loss: 0.3150763795485574		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.28354059113144875 | validation: 0.307117556466437]
	TIME [epoch: 8.74 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21659091815582326		[learning rate: 0.0029412]
		[batch 20/20] avg loss: 0.21185035368854752		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.21422063592218538 | validation: 0.21938390604677563]
	TIME [epoch: 8.75 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21963586316851233		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.36917621711769677		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.2944060401431045 | validation: 0.17053827202312757]
	TIME [epoch: 8.77 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23192440776079123		[learning rate: 0.0029128]
		[batch 20/20] avg loss: 0.3303628112065135		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.2811436094836524 | validation: 0.17366891325530537]
	TIME [epoch: 8.74 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2757017112252371		[learning rate: 0.0028987]
		[batch 20/20] avg loss: 0.20370750394551457		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.2397046075853758 | validation: 0.19144581450978848]
	TIME [epoch: 8.75 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2522368757384194		[learning rate: 0.0028847]
		[batch 20/20] avg loss: 0.2962036418212063		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.27422025877981276 | validation: 0.1733739997709396]
	TIME [epoch: 8.75 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20005384707840604		[learning rate: 0.0028708]
		[batch 20/20] avg loss: 0.24182119957281478		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.2209375233256104 | validation: 0.18601955299120793]
	TIME [epoch: 8.75 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21960028738162465		[learning rate: 0.0028569]
		[batch 20/20] avg loss: 0.21936862093622128		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.219484454158923 | validation: 0.28178790621334526]
	TIME [epoch: 8.78 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2649271461902997		[learning rate: 0.0028431]
		[batch 20/20] avg loss: 0.19532691772889352		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.23012703195959663 | validation: 0.2481050195787011]
	TIME [epoch: 8.76 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.28931798920578844		[learning rate: 0.0028293]
		[batch 20/20] avg loss: 0.26445085548380787		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.2768844223447982 | validation: 0.191171362032793]
	TIME [epoch: 8.76 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26042163021405196		[learning rate: 0.0028157]
		[batch 20/20] avg loss: 0.2454624342043203		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.2529420322091861 | validation: 0.17781420040993812]
	TIME [epoch: 8.76 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.26032299403981435		[learning rate: 0.002802]
		[batch 20/20] avg loss: 0.2232374720736517		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.24178023305673305 | validation: 0.25465128254553204]
	TIME [epoch: 8.75 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2673098457755644		[learning rate: 0.0027885]
		[batch 20/20] avg loss: 0.2222587303249341		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.24478428805024924 | validation: 0.16230484550040872]
	TIME [epoch: 8.77 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20704027562963226		[learning rate: 0.002775]
		[batch 20/20] avg loss: 0.2170146191012675		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.21202744736544984 | validation: 0.1996989286780847]
	TIME [epoch: 8.78 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.25182698433276296		[learning rate: 0.0027616]
		[batch 20/20] avg loss: 0.24545363684823207		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.2486403105904976 | validation: 0.3034955915669356]
	TIME [epoch: 8.75 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1962682921237686		[learning rate: 0.0027482]
		[batch 20/20] avg loss: 0.2432795555099026		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.21977392381683564 | validation: 0.1643429366626523]
	TIME [epoch: 8.76 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19285186925195635		[learning rate: 0.0027349]
		[batch 20/20] avg loss: 0.286191363815146		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.23952161653355114 | validation: 0.25226699570099315]
	TIME [epoch: 8.75 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21126102139217523		[learning rate: 0.0027217]
		[batch 20/20] avg loss: 0.18276047602917697		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.19701074871067611 | validation: 0.19662825636604353]
	TIME [epoch: 8.76 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23512412826645274		[learning rate: 0.0027086]
		[batch 20/20] avg loss: 0.24864475891519708		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.24188444359082495 | validation: 0.21552617545005165]
	TIME [epoch: 8.78 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18983630920431646		[learning rate: 0.0026955]
		[batch 20/20] avg loss: 0.24938896012996642		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.21961263466714143 | validation: 0.19339611677160762]
	TIME [epoch: 8.76 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21234641592529085		[learning rate: 0.0026824]
		[batch 20/20] avg loss: 0.23596169846618703		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.22415405719573894 | validation: 0.41201884523376386]
	TIME [epoch: 8.75 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.3057167502958421		[learning rate: 0.0026694]
		[batch 20/20] avg loss: 0.2857855801850864		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.2957511652404643 | validation: 0.3056806943626099]
	TIME [epoch: 8.75 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.30128538352173795		[learning rate: 0.0026565]
		[batch 20/20] avg loss: 0.24406551184323866		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.27267544768248825 | validation: 0.13166242960550442]
	TIME [epoch: 8.75 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23341551938989294		[learning rate: 0.0026437]
		[batch 20/20] avg loss: 0.2195777251043344		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.2264966222471137 | validation: 0.15330446839320253]
	TIME [epoch: 8.76 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22353540525618493		[learning rate: 0.0026309]
		[batch 20/20] avg loss: 0.23613989864108514		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.22983765194863498 | validation: 0.36864964340157]
	TIME [epoch: 8.77 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24930618251153244		[learning rate: 0.0026182]
		[batch 20/20] avg loss: 0.2016869859370823		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.22549658422430738 | validation: 0.14806808070657063]
	TIME [epoch: 8.76 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18976450209903922		[learning rate: 0.0026055]
		[batch 20/20] avg loss: 0.20757290623069152		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.19866870416486535 | validation: 0.22080817790941845]
	TIME [epoch: 8.75 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21222741936517725		[learning rate: 0.0025929]
		[batch 20/20] avg loss: 0.18699029239278303		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.1996088558789801 | validation: 0.31319960491107623]
	TIME [epoch: 8.74 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2239833538243651		[learning rate: 0.0025804]
		[batch 20/20] avg loss: 0.2006938921228149		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.21233862297359002 | validation: 0.29344266802619134]
	TIME [epoch: 8.77 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21740636290289786		[learning rate: 0.0025679]
		[batch 20/20] avg loss: 0.18391937515202775		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.20066286902746283 | validation: 0.2625639255135417]
	TIME [epoch: 8.74 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2527648191352142		[learning rate: 0.0025555]
		[batch 20/20] avg loss: 0.26417203861954297		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.25846842887737853 | validation: 0.13316285350148754]
	TIME [epoch: 8.73 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2632249243978647		[learning rate: 0.0025431]
		[batch 20/20] avg loss: 0.2217476172089472		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.2424862708034059 | validation: 0.16274932746126217]
	TIME [epoch: 8.74 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18772302078756392		[learning rate: 0.0025308]
		[batch 20/20] avg loss: 0.23864624057945177		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.21318463068350785 | validation: 0.20416119926806026]
	TIME [epoch: 8.74 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21076435453940662		[learning rate: 0.0025186]
		[batch 20/20] avg loss: 0.21000255717751032		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.21038345585845847 | validation: 0.23917566950843816]
	TIME [epoch: 8.77 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24990627369641757		[learning rate: 0.0025064]
		[batch 20/20] avg loss: 0.24091709950822954		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.2454116866023235 | validation: 0.17598663174665483]
	TIME [epoch: 8.74 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19712274139750363		[learning rate: 0.0024943]
		[batch 20/20] avg loss: 0.171766443677001		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.18444459253725232 | validation: 0.2748252656035207]
	TIME [epoch: 8.75 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22779591392744808		[learning rate: 0.0024822]
		[batch 20/20] avg loss: 0.22892560812455648		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.22836076102600228 | validation: 0.2975206636494063]
	TIME [epoch: 8.74 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24670736718899158		[learning rate: 0.0024702]
		[batch 20/20] avg loss: 0.20594979849183614		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.22632858284041388 | validation: 0.10525354849147524]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_339.pth
	Model improved!!!
EPOCH 340/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17295672236590065		[learning rate: 0.0024583]
		[batch 20/20] avg loss: 0.16742667572274247		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.17019169904432158 | validation: 0.2668471154898183]
	TIME [epoch: 8.77 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2633898393623873		[learning rate: 0.0024464]
		[batch 20/20] avg loss: 0.18861638746442874		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.22600311341340804 | validation: 0.1677412906836074]
	TIME [epoch: 8.75 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19341142981209747		[learning rate: 0.0024346]
		[batch 20/20] avg loss: 0.2265067197932004		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.20995907480264897 | validation: 0.14521761814741968]
	TIME [epoch: 8.76 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18928281945949682		[learning rate: 0.0024228]
		[batch 20/20] avg loss: 0.17573901984736615		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.18251091965343152 | validation: 0.24890601147170485]
	TIME [epoch: 8.76 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20537913433275454		[learning rate: 0.0024111]
		[batch 20/20] avg loss: 0.20618697307313877		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.20578305370294664 | validation: 0.14283865787660463]
	TIME [epoch: 8.76 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15548508656039764		[learning rate: 0.0023994]
		[batch 20/20] avg loss: 0.1817282890122426		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.16860668778632013 | validation: 0.11471868803569002]
	TIME [epoch: 8.78 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18808873590734027		[learning rate: 0.0023878]
		[batch 20/20] avg loss: 0.22066905176299106		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.2043788938351656 | validation: 0.17307771752748208]
	TIME [epoch: 8.77 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19792720454656676		[learning rate: 0.0023763]
		[batch 20/20] avg loss: 0.18700292168459767		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.1924650631155822 | validation: 0.14058759910730367]
	TIME [epoch: 8.76 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19941262474716012		[learning rate: 0.0023648]
		[batch 20/20] avg loss: 0.21153027648366277		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.20547145061541144 | validation: 0.19481919419830712]
	TIME [epoch: 8.76 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19822783259238014		[learning rate: 0.0023533]
		[batch 20/20] avg loss: 0.22426131915950806		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.21124457587594409 | validation: 0.17554548248630958]
	TIME [epoch: 8.76 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2275627483396704		[learning rate: 0.002342]
		[batch 20/20] avg loss: 0.1705427630049604		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.19905275567231537 | validation: 0.1611677585575949]
	TIME [epoch: 8.77 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21469694277576953		[learning rate: 0.0023306]
		[batch 20/20] avg loss: 0.20846509606873856		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.21158101942225405 | validation: 0.21255618696013226]
	TIME [epoch: 8.77 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21819765487669135		[learning rate: 0.0023194]
		[batch 20/20] avg loss: 0.18418289503559623		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.20119027495614378 | validation: 0.16190920146357846]
	TIME [epoch: 8.77 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18230167329678187		[learning rate: 0.0023081]
		[batch 20/20] avg loss: 0.17897394133980943		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.18063780731829565 | validation: 0.2487135675169789]
	TIME [epoch: 8.76 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18016107122152403		[learning rate: 0.002297]
		[batch 20/20] avg loss: 0.22377570735357094		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.20196838928754746 | validation: 0.1424426820445569]
	TIME [epoch: 8.76 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17603076078413954		[learning rate: 0.0022859]
		[batch 20/20] avg loss: 0.19310484886107254		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.18456780482260604 | validation: 0.2209435026140593]
	TIME [epoch: 8.75 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2039338849013383		[learning rate: 0.0022748]
		[batch 20/20] avg loss: 0.21557630521949753		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.20975509506041795 | validation: 0.1967381285866573]
	TIME [epoch: 8.79 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20141192051971565		[learning rate: 0.0022638]
		[batch 20/20] avg loss: 0.21957126742519334		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.21049159397245445 | validation: 0.12513639652934155]
	TIME [epoch: 8.75 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22039494824490288		[learning rate: 0.0022529]
		[batch 20/20] avg loss: 0.20878580049018458		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.21459037436754377 | validation: 0.27222068986636017]
	TIME [epoch: 8.76 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.23921011552414306		[learning rate: 0.002242]
		[batch 20/20] avg loss: 0.27946278191520735		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.25933644871967515 | validation: 0.23733677900110148]
	TIME [epoch: 8.75 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.240578627125337		[learning rate: 0.0022311]
		[batch 20/20] avg loss: 0.27626581298164143		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.25842222005348925 | validation: 0.16890073793007823]
	TIME [epoch: 8.74 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18251391072008402		[learning rate: 0.0022203]
		[batch 20/20] avg loss: 0.21451163954411837		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.19851277513210122 | validation: 0.18313742585533951]
	TIME [epoch: 8.79 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2436757856202126		[learning rate: 0.0022096]
		[batch 20/20] avg loss: 0.271641615273313		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.25765870044676287 | validation: 0.1792020416989359]
	TIME [epoch: 8.76 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2290693206575634		[learning rate: 0.0021989]
		[batch 20/20] avg loss: 0.18910064516646513		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.20908498291201433 | validation: 0.1976584017350952]
	TIME [epoch: 8.75 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1650527211427877		[learning rate: 0.0021883]
		[batch 20/20] avg loss: 0.17477020748360814		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.16991146431319792 | validation: 0.11766248497988166]
	TIME [epoch: 8.76 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18435150149691762		[learning rate: 0.0021777]
		[batch 20/20] avg loss: 0.22647537974388188		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.2054134406203997 | validation: 0.17086699191425575]
	TIME [epoch: 8.76 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17899777315299717		[learning rate: 0.0021672]
		[batch 20/20] avg loss: 0.20989758877267853		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.19444768096283782 | validation: 0.25615158649899117]
	TIME [epoch: 8.78 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21929901114405065		[learning rate: 0.0021567]
		[batch 20/20] avg loss: 0.21636001741952557		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.2178295142817881 | validation: 0.23474854425258787]
	TIME [epoch: 8.76 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18454816204514396		[learning rate: 0.0021463]
		[batch 20/20] avg loss: 0.21688994671443124		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.2007190543797876 | validation: 0.19382936104876264]
	TIME [epoch: 8.74 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.22373451926798543		[learning rate: 0.0021359]
		[batch 20/20] avg loss: 0.17398760863562657		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.19886106395180603 | validation: 0.1568704251915267]
	TIME [epoch: 8.76 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16473720353753651		[learning rate: 0.0021256]
		[batch 20/20] avg loss: 0.1823394398847564		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.17353832171114647 | validation: 0.19838967000083493]
	TIME [epoch: 8.74 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18812401716520946		[learning rate: 0.0021153]
		[batch 20/20] avg loss: 0.18919151015751698		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.18865776366136325 | validation: 0.21984011995251168]
	TIME [epoch: 8.77 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1900209073460038		[learning rate: 0.0021051]
		[batch 20/20] avg loss: 0.29239012152870314		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.24120551443735344 | validation: 0.247644575158185]
	TIME [epoch: 8.77 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19073253629567744		[learning rate: 0.0020949]
		[batch 20/20] avg loss: 0.24141617991294334		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.2160743581043104 | validation: 0.30824097749248625]
	TIME [epoch: 8.75 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2770356700748036		[learning rate: 0.0020847]
		[batch 20/20] avg loss: 0.18440053452190458		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.23071810229835407 | validation: 0.23958528892379838]
	TIME [epoch: 8.74 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2619457738307872		[learning rate: 0.0020747]
		[batch 20/20] avg loss: 0.18321976752684793		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.22258277067881754 | validation: 0.12109844600310096]
	TIME [epoch: 8.74 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16113445812219584		[learning rate: 0.0020646]
		[batch 20/20] avg loss: 0.21338225923918097		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.1872583586806884 | validation: 0.13754065115043806]
	TIME [epoch: 8.76 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16783648946833796		[learning rate: 0.0020546]
		[batch 20/20] avg loss: 0.2378162196864207		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.20282635457737927 | validation: 0.1402958396127489]
	TIME [epoch: 8.76 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17590823110445847		[learning rate: 0.0020447]
		[batch 20/20] avg loss: 0.2096579889531803		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.1927831100288194 | validation: 0.1722950335746827]
	TIME [epoch: 8.76 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1737976847661146		[learning rate: 0.0020348]
		[batch 20/20] avg loss: 0.20051453563588595		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.18715611020100026 | validation: 0.1379579415766444]
	TIME [epoch: 8.75 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14928965826033477		[learning rate: 0.002025]
		[batch 20/20] avg loss: 0.19772505289456627		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.1735073555774505 | validation: 0.2097294640488767]
	TIME [epoch: 8.75 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17342638667122934		[learning rate: 0.0020152]
		[batch 20/20] avg loss: 0.17922716769163077		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.17632677718143008 | validation: 0.1826677431360594]
	TIME [epoch: 8.74 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1965619054198908		[learning rate: 0.0020054]
		[batch 20/20] avg loss: 0.16619569453404937		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.1813787999769701 | validation: 0.3094162744759704]
	TIME [epoch: 8.78 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18545191043816897		[learning rate: 0.0019957]
		[batch 20/20] avg loss: 0.16938152587246982		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.1774167181553194 | validation: 0.17517319392656153]
	TIME [epoch: 8.76 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18716931473842766		[learning rate: 0.0019861]
		[batch 20/20] avg loss: 0.1812443474273018		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.18420683108286473 | validation: 0.23873213691714407]
	TIME [epoch: 8.75 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17006602285933067		[learning rate: 0.0019765]
		[batch 20/20] avg loss: 0.20712037081115242		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.18859319683524156 | validation: 0.2294669247411946]
	TIME [epoch: 8.75 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18721812622439		[learning rate: 0.0019669]
		[batch 20/20] avg loss: 0.18976254214306246		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.1884903341837262 | validation: 0.12762347070067495]
	TIME [epoch: 8.76 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18348291387813037		[learning rate: 0.0019574]
		[batch 20/20] avg loss: 0.17226015217335752		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.17787153302574393 | validation: 0.15212119475138053]
	TIME [epoch: 8.77 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17315606268342004		[learning rate: 0.001948]
		[batch 20/20] avg loss: 0.22796131686760948		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.20055868977551472 | validation: 0.15484118947544426]
	TIME [epoch: 8.76 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.24984554052664842		[learning rate: 0.0019385]
		[batch 20/20] avg loss: 0.27309354726858664		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.26146954389761756 | validation: 0.12360348986563799]
	TIME [epoch: 8.74 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13724028538098193		[learning rate: 0.0019292]
		[batch 20/20] avg loss: 0.20066757181692277		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.16895392859895234 | validation: 0.23452555959738103]
	TIME [epoch: 8.76 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21754447894840617		[learning rate: 0.0019198]
		[batch 20/20] avg loss: 0.17652326154072218		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.19703387024456417 | validation: 0.13817287812423737]
	TIME [epoch: 8.75 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1691345385785974		[learning rate: 0.0019105]
		[batch 20/20] avg loss: 0.19397146648982785		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.18155300253421264 | validation: 0.15347136937515485]
	TIME [epoch: 8.77 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15753252583410204		[learning rate: 0.0019013]
		[batch 20/20] avg loss: 0.20631511221064042		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.18192381902237126 | validation: 0.13215130375137962]
	TIME [epoch: 8.75 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1855917213113665		[learning rate: 0.0018921]
		[batch 20/20] avg loss: 0.20050167884138964		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.19304670007637806 | validation: 0.16751748342389186]
	TIME [epoch: 8.74 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15174752833536484		[learning rate: 0.001883]
		[batch 20/20] avg loss: 0.13972208394471652		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.14573480614004067 | validation: 0.18321894012673315]
	TIME [epoch: 8.74 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18258633573989136		[learning rate: 0.0018739]
		[batch 20/20] avg loss: 0.1856990491675885		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.18414269245373996 | validation: 0.1673277645557315]
	TIME [epoch: 8.74 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1715250756801635		[learning rate: 0.0018648]
		[batch 20/20] avg loss: 0.15543834588839506		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.16348171078427928 | validation: 0.12960310698480815]
	TIME [epoch: 8.75 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18240570136941553		[learning rate: 0.0018558]
		[batch 20/20] avg loss: 0.17952793399094458		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.1809668176801801 | validation: 0.14605616859040915]
	TIME [epoch: 8.76 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1629181640759339		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.20142972701025963		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.18217394554309677 | validation: 0.11161147509661068]
	TIME [epoch: 8.76 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14051666068063692		[learning rate: 0.0018379]
		[batch 20/20] avg loss: 0.1725665538555719		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.1565416072681044 | validation: 0.12217688350042522]
	TIME [epoch: 8.75 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.20439570858034317		[learning rate: 0.001829]
		[batch 20/20] avg loss: 0.1546758016914023		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.17953575513587275 | validation: 0.11799550131466213]
	TIME [epoch: 8.75 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1595445404473569		[learning rate: 0.0018201]
		[batch 20/20] avg loss: 0.14460380436132977		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.15207417240434334 | validation: 0.1861355583551278]
	TIME [epoch: 8.76 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15461457425931138		[learning rate: 0.0018113]
		[batch 20/20] avg loss: 0.1750474750209378		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.1648310246401246 | validation: 0.18143425911672537]
	TIME [epoch: 8.76 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21077356770131783		[learning rate: 0.0018026]
		[batch 20/20] avg loss: 0.15195658841064824		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.18136507805598304 | validation: 0.16395677728512822]
	TIME [epoch: 8.75 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19640069001953786		[learning rate: 0.0017939]
		[batch 20/20] avg loss: 0.17978006864149393		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.18809037933051592 | validation: 0.1563945282545175]
	TIME [epoch: 8.75 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1900863054550558		[learning rate: 0.0017852]
		[batch 20/20] avg loss: 0.22451496779951313		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.20730063662728443 | validation: 0.49989667848563923]
	TIME [epoch: 8.75 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21346604673137973		[learning rate: 0.0017766]
		[batch 20/20] avg loss: 0.1599577509188193		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.1867118988250995 | validation: 0.1535521043748328]
	TIME [epoch: 8.74 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16836500098408752		[learning rate: 0.001768]
		[batch 20/20] avg loss: 0.16949102973166705		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.16892801535787733 | validation: 0.1304501233162318]
	TIME [epoch: 8.77 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18545569745883242		[learning rate: 0.0017594]
		[batch 20/20] avg loss: 0.2037293591202268		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.1945925282895296 | validation: 0.18511314167883014]
	TIME [epoch: 8.75 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21137305759066477		[learning rate: 0.0017509]
		[batch 20/20] avg loss: 0.1750843911560544		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.19322872437335953 | validation: 0.16987295808378075]
	TIME [epoch: 8.75 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1492671330385563		[learning rate: 0.0017424]
		[batch 20/20] avg loss: 0.18888429658554842		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.16907571481205233 | validation: 0.13307619738203263]
	TIME [epoch: 8.76 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16663343508470133		[learning rate: 0.001734]
		[batch 20/20] avg loss: 0.18623782723480753		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.1764356311597544 | validation: 0.1710266825726421]
	TIME [epoch: 8.76 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14328454161419013		[learning rate: 0.0017256]
		[batch 20/20] avg loss: 0.1608224839998254		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.1520535128070078 | validation: 0.15579287746624632]
	TIME [epoch: 8.77 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1708474075715818		[learning rate: 0.0017173]
		[batch 20/20] avg loss: 0.143877218301491		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.1573623129365364 | validation: 0.10513250353605975]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_414.pth
	Model improved!!!
EPOCH 415/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1647623991052011		[learning rate: 0.001709]
		[batch 20/20] avg loss: 0.1772260003094015		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.1709941997073013 | validation: 0.13935432043588314]
	TIME [epoch: 8.75 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.170446762925024		[learning rate: 0.0017007]
		[batch 20/20] avg loss: 0.1540989056849826		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.16227283430500333 | validation: 0.20033020840101323]
	TIME [epoch: 8.73 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16074914321576478		[learning rate: 0.0016925]
		[batch 20/20] avg loss: 0.1402425615527559		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.1504958523842604 | validation: 0.10659508136142218]
	TIME [epoch: 8.75 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14207785246277538		[learning rate: 0.0016843]
		[batch 20/20] avg loss: 0.1810377079849785		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.16155778022387696 | validation: 0.1772467783824559]
	TIME [epoch: 8.78 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15615700755446574		[learning rate: 0.0016762]
		[batch 20/20] avg loss: 0.14427053311253746		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.15021377033350164 | validation: 0.16962679556910876]
	TIME [epoch: 8.75 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1822673795718979		[learning rate: 0.0016681]
		[batch 20/20] avg loss: 0.19210196604427734		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.18718467280808762 | validation: 0.16740043404411054]
	TIME [epoch: 8.75 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2646700306358048		[learning rate: 0.00166]
		[batch 20/20] avg loss: 0.18472813906608976		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.22469908485094728 | validation: 0.11833488826537593]
	TIME [epoch: 8.73 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18848675615725394		[learning rate: 0.001652]
		[batch 20/20] avg loss: 0.18340612962849884		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.1859464428928764 | validation: 0.1471323414803665]
	TIME [epoch: 8.74 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16845157091608404		[learning rate: 0.001644]
		[batch 20/20] avg loss: 0.15937524255086835		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.1639134067334762 | validation: 0.09324074667498007]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_423.pth
	Model improved!!!
EPOCH 424/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1848142882317023		[learning rate: 0.001636]
		[batch 20/20] avg loss: 0.22840509195844821		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.20660969009507527 | validation: 0.20746093574891694]
	TIME [epoch: 8.73 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1751487992409918		[learning rate: 0.0016281]
		[batch 20/20] avg loss: 0.15281888837638113		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.16398384380868647 | validation: 0.14199095923872537]
	TIME [epoch: 8.73 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1546247323075805		[learning rate: 0.0016202]
		[batch 20/20] avg loss: 0.19237361467998731		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.1734991734937839 | validation: 0.146665751014324]
	TIME [epoch: 8.72 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15816949989119383		[learning rate: 0.0016124]
		[batch 20/20] avg loss: 0.15304536411831737		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.15560743200475557 | validation: 0.13646966652316522]
	TIME [epoch: 8.7 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16621779879639437		[learning rate: 0.0016046]
		[batch 20/20] avg loss: 0.17431111138737138		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.17026445509188287 | validation: 0.10221658407441175]
	TIME [epoch: 8.71 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12615713920507737		[learning rate: 0.0015968]
		[batch 20/20] avg loss: 0.15687617892006353		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.1415166590625705 | validation: 0.16601079426089999]
	TIME [epoch: 8.71 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2046710874833137		[learning rate: 0.0015891]
		[batch 20/20] avg loss: 0.17540549635584046		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.19003829191957708 | validation: 0.12939170690909846]
	TIME [epoch: 8.71 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14731264164372723		[learning rate: 0.0015814]
		[batch 20/20] avg loss: 0.1396374227122173		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.14347503217797225 | validation: 0.10297170132919425]
	TIME [epoch: 8.71 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1385829298525458		[learning rate: 0.0015738]
		[batch 20/20] avg loss: 0.20094853287555545		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.16976573136405065 | validation: 0.10047103533315024]
	TIME [epoch: 8.72 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1380456107469284		[learning rate: 0.0015662]
		[batch 20/20] avg loss: 0.1562440076355902		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.14714480919125933 | validation: 0.15366916461111943]
	TIME [epoch: 8.72 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18432378576888614		[learning rate: 0.0015586]
		[batch 20/20] avg loss: 0.17465281186140316		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.17948829881514466 | validation: 0.1890774530585923]
	TIME [epoch: 8.73 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.2016100906507409		[learning rate: 0.0015511]
		[batch 20/20] avg loss: 0.1636180800374948		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.18261408534411783 | validation: 0.22606629580005622]
	TIME [epoch: 8.7 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1912796045606177		[learning rate: 0.0015436]
		[batch 20/20] avg loss: 0.1992740727879495		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.19527683867428364 | validation: 0.11451092632083784]
	TIME [epoch: 8.71 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.19336408040368644		[learning rate: 0.0015361]
		[batch 20/20] avg loss: 0.12343938232540703		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.15840173136454674 | validation: 0.1498340328342116]
	TIME [epoch: 8.7 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15927088729010172		[learning rate: 0.0015287]
		[batch 20/20] avg loss: 0.17035013680668495		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.1648105120483934 | validation: 0.13736549193010567]
	TIME [epoch: 8.71 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13265856030974205		[learning rate: 0.0015213]
		[batch 20/20] avg loss: 0.14253174342468414		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.1375951518672131 | validation: 0.16787288761932231]
	TIME [epoch: 8.73 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16610014597803363		[learning rate: 0.0015139]
		[batch 20/20] avg loss: 0.16554190127880605		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.16582102362841986 | validation: 0.16491487354413764]
	TIME [epoch: 8.72 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15877664691235674		[learning rate: 0.0015066]
		[batch 20/20] avg loss: 0.15861990816009222		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.1586982775362245 | validation: 0.18230447047759202]
	TIME [epoch: 8.7 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15998382662843574		[learning rate: 0.0014993]
		[batch 20/20] avg loss: 0.1552980039830237		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.1576409153057297 | validation: 0.15050781691296958]
	TIME [epoch: 8.7 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13847155568257258		[learning rate: 0.0014921]
		[batch 20/20] avg loss: 0.14931130668020962		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.1438914311813911 | validation: 0.1708758378289612]
	TIME [epoch: 8.7 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14702434508793788		[learning rate: 0.0014849]
		[batch 20/20] avg loss: 0.17398351539399007		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.16050393024096393 | validation: 0.15698503564410962]
	TIME [epoch: 8.74 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18303181356937967		[learning rate: 0.0014777]
		[batch 20/20] avg loss: 0.1554827418451667		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.16925727770727317 | validation: 0.1410936873524133]
	TIME [epoch: 8.71 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13548735022163347		[learning rate: 0.0014705]
		[batch 20/20] avg loss: 0.17014562385928803		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.15281648704046075 | validation: 0.13765468544885828]
	TIME [epoch: 8.73 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1397847212515333		[learning rate: 0.0014634]
		[batch 20/20] avg loss: 0.18038634852030352		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.16008553488591842 | validation: 0.20540541997976064]
	TIME [epoch: 8.72 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16212697478093893		[learning rate: 0.0014563]
		[batch 20/20] avg loss: 0.15195787491640256		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.15704242484867076 | validation: 0.1337966258349419]
	TIME [epoch: 8.72 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1737625292959679		[learning rate: 0.0014493]
		[batch 20/20] avg loss: 0.1327158938264275		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.15323921156119774 | validation: 0.18900687563929214]
	TIME [epoch: 8.72 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1342870267389118		[learning rate: 0.0014423]
		[batch 20/20] avg loss: 0.1290196016434882		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.13165331419119997 | validation: 0.16441307625553503]
	TIME [epoch: 8.74 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13993181446032021		[learning rate: 0.0014353]
		[batch 20/20] avg loss: 0.1671339520575877		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.15353288325895392 | validation: 0.16049460000899124]
	TIME [epoch: 8.72 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17462897172480274		[learning rate: 0.0014284]
		[batch 20/20] avg loss: 0.15501359829295233		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.16482128500887755 | validation: 0.1237768165300055]
	TIME [epoch: 8.72 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1283391244799318		[learning rate: 0.0014215]
		[batch 20/20] avg loss: 0.17358633094082956		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.1509627277103807 | validation: 0.17334750879263564]
	TIME [epoch: 8.73 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15885040966908517		[learning rate: 0.0014146]
		[batch 20/20] avg loss: 0.1760589659276596		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.1674546877983724 | validation: 0.17437698370692747]
	TIME [epoch: 8.72 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13477576927461296		[learning rate: 0.0014078]
		[batch 20/20] avg loss: 0.12265160620925394		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.12871368774193345 | validation: 0.13931211671881819]
	TIME [epoch: 8.73 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15225899079842362		[learning rate: 0.0014009]
		[batch 20/20] avg loss: 0.13958865711980706		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.14592382395911532 | validation: 0.21867428804992856]
	TIME [epoch: 8.72 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16287047032076601		[learning rate: 0.0013942]
		[batch 20/20] avg loss: 0.1659169484278434		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.16439370937430467 | validation: 0.11956234700104532]
	TIME [epoch: 8.71 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.152056831770716		[learning rate: 0.0013874]
		[batch 20/20] avg loss: 0.12903737580526975		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.14054710378799287 | validation: 0.10754178099748286]
	TIME [epoch: 8.72 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16036595314493957		[learning rate: 0.0013807]
		[batch 20/20] avg loss: 0.12334502323056624		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.1418554881877529 | validation: 0.10731821764512614]
	TIME [epoch: 8.71 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14517363308365092		[learning rate: 0.001374]
		[batch 20/20] avg loss: 0.13760607874265673		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.14138985591315384 | validation: 0.10443512845908218]
	TIME [epoch: 8.74 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1259501889020512		[learning rate: 0.0013674]
		[batch 20/20] avg loss: 0.14151030529540515		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.13373024709872816 | validation: 0.11315626566533232]
	TIME [epoch: 8.72 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1494776276155902		[learning rate: 0.0013608]
		[batch 20/20] avg loss: 0.16322174220655172		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.15634968491107096 | validation: 0.12240112609737447]
	TIME [epoch: 8.72 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14174226412537622		[learning rate: 0.0013542]
		[batch 20/20] avg loss: 0.13772738596654194		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.13973482504595908 | validation: 0.13036593493118173]
	TIME [epoch: 8.71 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14909753863873648		[learning rate: 0.0013477]
		[batch 20/20] avg loss: 0.1331703327869768		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.14113393571285662 | validation: 0.10618783856664038]
	TIME [epoch: 8.72 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1560631591631974		[learning rate: 0.0013411]
		[batch 20/20] avg loss: 0.13235755247994288		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.1442103558215701 | validation: 0.1376288787957806]
	TIME [epoch: 8.74 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15575406503438396		[learning rate: 0.0013347]
		[batch 20/20] avg loss: 0.15019282805554365		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.15297344654496378 | validation: 0.13733612805210282]
	TIME [epoch: 8.71 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14916823014557817		[learning rate: 0.0013282]
		[batch 20/20] avg loss: 0.1301896695896295		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.13967894986760385 | validation: 0.1075926836470815]
	TIME [epoch: 8.72 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12338934127305454		[learning rate: 0.0013218]
		[batch 20/20] avg loss: 0.1451748717324226		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.13428210650273859 | validation: 0.19062851056368346]
	TIME [epoch: 8.72 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17217790709911818		[learning rate: 0.0013154]
		[batch 20/20] avg loss: 0.1411834893938006		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.15668069824645942 | validation: 0.14745124589716865]
	TIME [epoch: 8.72 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16632026527642463		[learning rate: 0.001309]
		[batch 20/20] avg loss: 0.21478388498524112		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.19055207513083286 | validation: 0.19147106481702186]
	TIME [epoch: 8.75 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13739156456063636		[learning rate: 0.0013027]
		[batch 20/20] avg loss: 0.16964934449138996		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.1535204545260132 | validation: 0.11335561822525633]
	TIME [epoch: 8.71 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1321373487343684		[learning rate: 0.0012964]
		[batch 20/20] avg loss: 0.14218069190559074		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.13715902031997956 | validation: 0.1628809057707462]
	TIME [epoch: 8.73 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17337019838891526		[learning rate: 0.0012901]
		[batch 20/20] avg loss: 0.17899219626145785		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.17618119732518658 | validation: 0.15105068534546534]
	TIME [epoch: 8.71 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14066552125038365		[learning rate: 0.0012839]
		[batch 20/20] avg loss: 0.1415697885142929		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.14111765488233824 | validation: 0.1151606448533393]
	TIME [epoch: 8.73 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11699161916116821		[learning rate: 0.0012777]
		[batch 20/20] avg loss: 0.1415251819999123		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.12925840058054022 | validation: 0.09989286089236066]
	TIME [epoch: 8.73 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1904845612840271		[learning rate: 0.0012715]
		[batch 20/20] avg loss: 0.12496742623477966		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.15772599375940344 | validation: 0.12777266213353247]
	TIME [epoch: 8.74 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14305330368348426		[learning rate: 0.0012653]
		[batch 20/20] avg loss: 0.14680607672670154		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.14492969020509286 | validation: 0.11897056521520792]
	TIME [epoch: 8.73 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.126003917296673		[learning rate: 0.0012592]
		[batch 20/20] avg loss: 0.1359141104896197		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.13095901389314638 | validation: 0.08787415219696831]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_478.pth
	Model improved!!!
EPOCH 479/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14877694166675978		[learning rate: 0.0012531]
		[batch 20/20] avg loss: 0.16774908428693863		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.15826301297684922 | validation: 0.19365216403924693]
	TIME [epoch: 8.73 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14074442447662755		[learning rate: 0.0012471]
		[batch 20/20] avg loss: 0.1455188713631884		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.14313164791990796 | validation: 0.1390057855561795]
	TIME [epoch: 8.75 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13991395771590434		[learning rate: 0.0012411]
		[batch 20/20] avg loss: 0.11828237986943475		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.12909816879266953 | validation: 0.1256455438489546]
	TIME [epoch: 8.74 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16438703607252797		[learning rate: 0.001235]
		[batch 20/20] avg loss: 0.13756931023997124		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.15097817315624956 | validation: 0.12197237057749541]
	TIME [epoch: 8.72 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12037166123530552		[learning rate: 0.0012291]
		[batch 20/20] avg loss: 0.11997565795492666		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.12017365959511608 | validation: 0.13326276222674005]
	TIME [epoch: 8.72 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12233691654506348		[learning rate: 0.0012231]
		[batch 20/20] avg loss: 0.12109604880692826		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.12171648267599586 | validation: 0.107614579800214]
	TIME [epoch: 8.73 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16959039160146605		[learning rate: 0.0012172]
		[batch 20/20] avg loss: 0.16934918922026448		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.16946979041086527 | validation: 0.1666569431180113]
	TIME [epoch: 8.72 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16844434341115888		[learning rate: 0.0012113]
		[batch 20/20] avg loss: 0.14656147489199384		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.15750290915157636 | validation: 0.1544014619263071]
	TIME [epoch: 8.77 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15707968143590137		[learning rate: 0.0012055]
		[batch 20/20] avg loss: 0.14319631647620526		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.15013799895605334 | validation: 0.13637325209718448]
	TIME [epoch: 8.74 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.17125209664114802		[learning rate: 0.0011996]
		[batch 20/20] avg loss: 0.15302748826402282		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.16213979245258542 | validation: 0.10068853269517591]
	TIME [epoch: 8.75 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14046481006520678		[learning rate: 0.0011938]
		[batch 20/20] avg loss: 0.1529267823504209		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.14669579620781384 | validation: 0.149032607439229]
	TIME [epoch: 8.72 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.21046594376376476		[learning rate: 0.0011881]
		[batch 20/20] avg loss: 0.14206865114026215		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.17626729745201347 | validation: 0.09847015920961869]
	TIME [epoch: 8.73 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11757308772750585		[learning rate: 0.0011823]
		[batch 20/20] avg loss: 0.1148543485108797		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.11621371811919279 | validation: 0.097003399112949]
	TIME [epoch: 8.75 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13897690402656943		[learning rate: 0.0011766]
		[batch 20/20] avg loss: 0.13627191250030507		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.13762440826343728 | validation: 0.1408917053163154]
	TIME [epoch: 8.75 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13423695030932137		[learning rate: 0.0011709]
		[batch 20/20] avg loss: 0.14718106960323957		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.14070900995628047 | validation: 0.1927482013562647]
	TIME [epoch: 8.74 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11211494432433575		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.12610793466319753		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.11911143949376664 | validation: 0.20640185526832078]
	TIME [epoch: 8.75 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14875433653373954		[learning rate: 0.0011596]
		[batch 20/20] avg loss: 0.11207379342887722		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.13041406498130836 | validation: 0.08426436048279844]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_495.pth
	Model improved!!!
EPOCH 496/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11397663998040455		[learning rate: 0.001154]
		[batch 20/20] avg loss: 0.13752444612740952		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.12575054305390704 | validation: 0.09065657830714478]
	TIME [epoch: 8.74 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12466698803140397		[learning rate: 0.0011484]
		[batch 20/20] avg loss: 0.1263589677307		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.125512977881052 | validation: 0.10617971218544262]
	TIME [epoch: 8.72 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1297989527126904		[learning rate: 0.0011429]
		[batch 20/20] avg loss: 0.15288515353207724		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.14134205312238385 | validation: 0.11028518783994293]
	TIME [epoch: 8.73 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12754988442597331		[learning rate: 0.0011374]
		[batch 20/20] avg loss: 0.16129321181856832		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.14442154812227082 | validation: 0.10733359883682127]
	TIME [epoch: 8.74 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1119081809044069		[learning rate: 0.0011319]
		[batch 20/20] avg loss: 0.14115139072714372		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.12652978581577531 | validation: 0.12806093160648044]
	TIME [epoch: 8.74 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1381296217057643		[learning rate: 0.0011264]
		[batch 20/20] avg loss: 0.1403021714999501		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.13921589660285721 | validation: 0.1233081677471756]
	TIME [epoch: 8.75 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15113536831750654		[learning rate: 0.0011209]
		[batch 20/20] avg loss: 0.1630470989930438		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.15709123365527516 | validation: 0.17122943266459434]
	TIME [epoch: 8.74 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15023756372732144		[learning rate: 0.0011155]
		[batch 20/20] avg loss: 0.12513579530690536		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.1376866795171134 | validation: 0.15447138510916622]
	TIME [epoch: 8.74 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1300399041879969		[learning rate: 0.0011101]
		[batch 20/20] avg loss: 0.15529527883406474		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.14266759151103087 | validation: 0.15421405020837553]
	TIME [epoch: 8.74 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15125557901229397		[learning rate: 0.0011047]
		[batch 20/20] avg loss: 0.114153239110555		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.13270440906142447 | validation: 0.1410768898083185]
	TIME [epoch: 8.74 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.18244649550322134		[learning rate: 0.0010994]
		[batch 20/20] avg loss: 0.13501485954704945		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.1587306775251354 | validation: 0.15103264490767698]
	TIME [epoch: 8.74 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.16182204327647484		[learning rate: 0.0010941]
		[batch 20/20] avg loss: 0.1303153841001316		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.14606871368830324 | validation: 0.08987906583973355]
	TIME [epoch: 8.76 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15193624970132025		[learning rate: 0.0010888]
		[batch 20/20] avg loss: 0.15227476226745162		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.15210550598438594 | validation: 0.12923566440138964]
	TIME [epoch: 8.75 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14881216959303015		[learning rate: 0.0010835]
		[batch 20/20] avg loss: 0.1511644339705363		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.1499883017817832 | validation: 0.10979617956911816]
	TIME [epoch: 8.74 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13295926102879316		[learning rate: 0.0010783]
		[batch 20/20] avg loss: 0.12959118470777486		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.131275222868284 | validation: 0.14351326283950747]
	TIME [epoch: 8.74 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14148011710641645		[learning rate: 0.0010731]
		[batch 20/20] avg loss: 0.1191276544945048		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.13030388580046062 | validation: 0.10545951946703115]
	TIME [epoch: 8.73 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12827246882126347		[learning rate: 0.0010679]
		[batch 20/20] avg loss: 0.12578023644250116		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.1270263526318823 | validation: 0.15034985701428596]
	TIME [epoch: 8.76 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12488311370652252		[learning rate: 0.0010627]
		[batch 20/20] avg loss: 0.11861884886334254		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.12175098128493252 | validation: 0.101320376205714]
	TIME [epoch: 8.74 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12688925016864028		[learning rate: 0.0010576]
		[batch 20/20] avg loss: 0.11481319812850202		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.12085122414857112 | validation: 0.13830222239160933]
	TIME [epoch: 8.73 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14642307480166789		[learning rate: 0.0010525]
		[batch 20/20] avg loss: 0.11138576681621404		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.128904420808941 | validation: 0.11695639984777889]
	TIME [epoch: 8.74 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12603550012334014		[learning rate: 0.0010474]
		[batch 20/20] avg loss: 0.13241781589090082		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.12922665800712047 | validation: 0.12293711859014902]
	TIME [epoch: 8.74 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1235267026930601		[learning rate: 0.0010423]
		[batch 20/20] avg loss: 0.12034546631523617		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.12193608450414813 | validation: 0.12636868765111378]
	TIME [epoch: 8.76 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11282413729199166		[learning rate: 0.0010373]
		[batch 20/20] avg loss: 0.1352907183332366		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.12405742781261411 | validation: 0.13126793084153376]
	TIME [epoch: 8.72 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13162945758363764		[learning rate: 0.0010323]
		[batch 20/20] avg loss: 0.12358043210552865		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.12760494484458315 | validation: 0.10959047052073914]
	TIME [epoch: 8.74 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13525852501306262		[learning rate: 0.0010273]
		[batch 20/20] avg loss: 0.12417879175455118		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.12971865838380692 | validation: 0.15362105015977862]
	TIME [epoch: 8.74 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12156267626028831		[learning rate: 0.0010223]
		[batch 20/20] avg loss: 0.11531889702016691		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.11844078664022764 | validation: 0.11544890167979086]
	TIME [epoch: 8.73 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13943022977165245		[learning rate: 0.0010174]
		[batch 20/20] avg loss: 0.11693298033908588		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.12818160505536916 | validation: 0.11059734167434272]
	TIME [epoch: 8.76 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14254608743238942		[learning rate: 0.0010124]
		[batch 20/20] avg loss: 0.1325839673906376		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.1375650274115135 | validation: 0.08090026038566409]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_523.pth
	Model improved!!!
EPOCH 524/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12306176391155817		[learning rate: 0.0010075]
		[batch 20/20] avg loss: 0.11822594677743352		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.12064385534449584 | validation: 0.10386900598506744]
	TIME [epoch: 8.75 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1338261991228878		[learning rate: 0.0010027]
		[batch 20/20] avg loss: 0.13137316285905234		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.13259968099097003 | validation: 0.09769381691325488]
	TIME [epoch: 8.74 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10321185714910583		[learning rate: 0.00099782]
		[batch 20/20] avg loss: 0.107925944906791		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.10556890102794843 | validation: 0.12370519476085781]
	TIME [epoch: 8.75 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12781334323270774		[learning rate: 0.000993]
		[batch 20/20] avg loss: 0.13183325297466686		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.1298232981036873 | validation: 0.13604048257079837]
	TIME [epoch: 8.76 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12071295747794411		[learning rate: 0.00098819]
		[batch 20/20] avg loss: 0.1059083786415056		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.11331066805972487 | validation: 0.09638264319244366]
	TIME [epoch: 8.75 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.125394561851657		[learning rate: 0.00098341]
		[batch 20/20] avg loss: 0.13958551390025264		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.1324900378759548 | validation: 0.10658619473708765]
	TIME [epoch: 8.75 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11239224831778312		[learning rate: 0.00097866]
		[batch 20/20] avg loss: 0.12786380554924176		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.12012802693351246 | validation: 0.16997966384433244]
	TIME [epoch: 8.73 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13202870758971127		[learning rate: 0.00097393]
		[batch 20/20] avg loss: 0.12557565632902978		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.1288021819593705 | validation: 0.09749747307129517]
	TIME [epoch: 8.75 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1402545573865225		[learning rate: 0.00096922]
		[batch 20/20] avg loss: 0.12079319333752433		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.13052387536202342 | validation: 0.10547777125071164]
	TIME [epoch: 8.76 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10258423792847185		[learning rate: 0.00096453]
		[batch 20/20] avg loss: 0.1184835007027997		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.11053386931563577 | validation: 0.09798677268311334]
	TIME [epoch: 8.77 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1441103206005285		[learning rate: 0.00095987]
		[batch 20/20] avg loss: 0.11371573696432477		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.12891302878242664 | validation: 0.09336553426414343]
	TIME [epoch: 8.75 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12569260241236135		[learning rate: 0.00095522]
		[batch 20/20] avg loss: 0.10959988084373311		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.11764624162804724 | validation: 0.0931246113749755]
	TIME [epoch: 8.76 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.108063359670548		[learning rate: 0.0009506]
		[batch 20/20] avg loss: 0.1120989573320813		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.11008115850131465 | validation: 0.10857597728378528]
	TIME [epoch: 8.74 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14121265313404094		[learning rate: 0.00094601]
		[batch 20/20] avg loss: 0.12151247697615197		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.13136256505509644 | validation: 0.1111880480165205]
	TIME [epoch: 8.74 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11072096100134468		[learning rate: 0.00094143]
		[batch 20/20] avg loss: 0.1319064921429881		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.12131372657216637 | validation: 0.1330438841626136]
	TIME [epoch: 8.76 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.15769747561042302		[learning rate: 0.00093688]
		[batch 20/20] avg loss: 0.14926158381036078		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.15347952971039192 | validation: 0.172243034238376]
	TIME [epoch: 8.74 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13656047291042056		[learning rate: 0.00093235]
		[batch 20/20] avg loss: 0.1210131924699678		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.1287868326901942 | validation: 0.13753096153644498]
	TIME [epoch: 8.74 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10924373935947133		[learning rate: 0.00092784]
		[batch 20/20] avg loss: 0.12885215183811602		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.11904794559879368 | validation: 0.13485147946400758]
	TIME [epoch: 8.74 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12697181621875636		[learning rate: 0.00092335]
		[batch 20/20] avg loss: 0.11726727815033688		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.12211954718454662 | validation: 0.16661537386757297]
	TIME [epoch: 8.73 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14553404110920148		[learning rate: 0.00091889]
		[batch 20/20] avg loss: 0.11123531484063595		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.1283846779749187 | validation: 0.15408271868248696]
	TIME [epoch: 8.75 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13832040952395247		[learning rate: 0.00091445]
		[batch 20/20] avg loss: 0.14838833408889848		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.14335437180642546 | validation: 0.14524084496050524]
	TIME [epoch: 8.73 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12561178506537782		[learning rate: 0.00091002]
		[batch 20/20] avg loss: 0.13073209153491203		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.12817193830014492 | validation: 0.10777886468881837]
	TIME [epoch: 8.72 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11319486761231964		[learning rate: 0.00090562]
		[batch 20/20] avg loss: 0.12745864626813283		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.12032675694022625 | validation: 0.12365645543840692]
	TIME [epoch: 8.72 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.127765481927205		[learning rate: 0.00090124]
		[batch 20/20] avg loss: 0.1346410144152178		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.1312032481712114 | validation: 0.14676224179026617]
	TIME [epoch: 8.72 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12598499245260136		[learning rate: 0.00089689]
		[batch 20/20] avg loss: 0.12775944945918655		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.12687222095589396 | validation: 0.09194473858283325]
	TIME [epoch: 8.74 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10933462931861886		[learning rate: 0.00089255]
		[batch 20/20] avg loss: 0.14877039356984964		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.1290525114442343 | validation: 0.10877487905758157]
	TIME [epoch: 8.73 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11209615260181612		[learning rate: 0.00088823]
		[batch 20/20] avg loss: 0.11315747656059241		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.11262681458120424 | validation: 0.08765108701667484]
	TIME [epoch: 8.73 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10723113259839315		[learning rate: 0.00088394]
		[batch 20/20] avg loss: 0.11531009145654883		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.11127061202747099 | validation: 0.12127424772713956]
	TIME [epoch: 8.71 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1287561167679265		[learning rate: 0.00087966]
		[batch 20/20] avg loss: 0.11528437874837975		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.12202024775815315 | validation: 0.09288752985259138]
	TIME [epoch: 8.73 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11665046664250667		[learning rate: 0.00087541]
		[batch 20/20] avg loss: 0.11479329079263442		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.11572187871757053 | validation: 0.11105345968151722]
	TIME [epoch: 8.75 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14592478699465058		[learning rate: 0.00087117]
		[batch 20/20] avg loss: 0.1259819457069841		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.13595336635081737 | validation: 0.124571530786434]
	TIME [epoch: 8.74 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10544387999510071		[learning rate: 0.00086696]
		[batch 20/20] avg loss: 0.11428390664677619		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.10986389332093845 | validation: 0.11382862665491786]
	TIME [epoch: 8.73 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11157773522407295		[learning rate: 0.00086277]
		[batch 20/20] avg loss: 0.1009193801042689		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.10624855766417092 | validation: 0.13328131997762685]
	TIME [epoch: 8.73 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11167236152607359		[learning rate: 0.0008586]
		[batch 20/20] avg loss: 0.10223866861471698		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.10695551507039527 | validation: 0.10277191282316872]
	TIME [epoch: 8.72 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10088262366786378		[learning rate: 0.00085445]
		[batch 20/20] avg loss: 0.10691055938548369		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.10389659152667372 | validation: 0.10671176429957085]
	TIME [epoch: 8.72 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0955336543000043		[learning rate: 0.00085031]
		[batch 20/20] avg loss: 0.1195381754714302		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.10753591488571723 | validation: 0.09981541617285]
	TIME [epoch: 8.73 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12378410033312841		[learning rate: 0.0008462]
		[batch 20/20] avg loss: 0.11414452909020371		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.11896431471166605 | validation: 0.10008192186100391]
	TIME [epoch: 8.73 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10443556760043764		[learning rate: 0.00084211]
		[batch 20/20] avg loss: 0.0990827089509564		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.10175913827569702 | validation: 0.07939235831400243]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_561.pth
	Model improved!!!
EPOCH 562/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10135560414476093		[learning rate: 0.00083804]
		[batch 20/20] avg loss: 0.10776388191430382		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.10455974302953237 | validation: 0.09906312932670408]
	TIME [epoch: 8.73 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11515495960257364		[learning rate: 0.00083398]
		[batch 20/20] avg loss: 0.12845444908429055		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.12180470434343209 | validation: 0.09394966707448231]
	TIME [epoch: 8.74 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10515606709328698		[learning rate: 0.00082995]
		[batch 20/20] avg loss: 0.12088171105069276		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.11301888907198987 | validation: 0.15791075771778337]
	TIME [epoch: 8.73 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12326766973423595		[learning rate: 0.00082594]
		[batch 20/20] avg loss: 0.11551913196888156		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.11939340085155874 | validation: 0.09652077968003267]
	TIME [epoch: 8.7 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12445256409335267		[learning rate: 0.00082194]
		[batch 20/20] avg loss: 0.10223295381352801		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.11334275895344034 | validation: 0.11568982382682673]
	TIME [epoch: 8.7 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11688096538220863		[learning rate: 0.00081797]
		[batch 20/20] avg loss: 0.13333667653063963		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.12510882095642412 | validation: 0.13517625319780197]
	TIME [epoch: 8.71 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1115951415412548		[learning rate: 0.00081401]
		[batch 20/20] avg loss: 0.11025983711917833		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.11092748933021657 | validation: 0.10608008546584566]
	TIME [epoch: 8.72 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.116210365845055		[learning rate: 0.00081008]
		[batch 20/20] avg loss: 0.12165578754609423		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.11893307669557462 | validation: 0.16887434868506887]
	TIME [epoch: 8.73 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.14094705297057994		[learning rate: 0.00080616]
		[batch 20/20] avg loss: 0.11962635382578575		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.13028670339818288 | validation: 0.10036059977249939]
	TIME [epoch: 8.71 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1167763755227074		[learning rate: 0.00080226]
		[batch 20/20] avg loss: 0.15517882763054622		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.1359776015766268 | validation: 0.11010216107848239]
	TIME [epoch: 8.71 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09866342349468439		[learning rate: 0.00079838]
		[batch 20/20] avg loss: 0.10742434885260466		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.1030438861736445 | validation: 0.08614980097764817]
	TIME [epoch: 8.73 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10565373770577566		[learning rate: 0.00079452]
		[batch 20/20] avg loss: 0.1311867756444007		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.1184202566750882 | validation: 0.09710575834538707]
	TIME [epoch: 8.74 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12049074152423758		[learning rate: 0.00079068]
		[batch 20/20] avg loss: 0.11938128627833675		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.11993601390128716 | validation: 0.17064887953554314]
	TIME [epoch: 8.75 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1434329663776357		[learning rate: 0.00078686]
		[batch 20/20] avg loss: 0.11704024381687957		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.1302366050972576 | validation: 0.09490236021032258]
	TIME [epoch: 8.75 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.110295447984088		[learning rate: 0.00078305]
		[batch 20/20] avg loss: 0.12071516073142625		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.11550530435775712 | validation: 0.10695717243761454]
	TIME [epoch: 8.74 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11162542807446116		[learning rate: 0.00077926]
		[batch 20/20] avg loss: 0.1273672708997164		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.11949634948708879 | validation: 0.11036862368641305]
	TIME [epoch: 8.74 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11346377404663774		[learning rate: 0.00077549]
		[batch 20/20] avg loss: 0.10255964932671177		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.10801171168667478 | validation: 0.08362552610143939]
	TIME [epoch: 8.73 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09566318732686517		[learning rate: 0.00077174]
		[batch 20/20] avg loss: 0.11138104735677361		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.10352211734181938 | validation: 0.11717640466305017]
	TIME [epoch: 8.75 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11892229090024745		[learning rate: 0.00076801]
		[batch 20/20] avg loss: 0.11185641277314443		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.11538935183669594 | validation: 0.14349697678973597]
	TIME [epoch: 8.74 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12524418873527662		[learning rate: 0.0007643]
		[batch 20/20] avg loss: 0.10692906329269998		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.1160866260139883 | validation: 0.101787092890898]
	TIME [epoch: 8.73 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11521308149323584		[learning rate: 0.0007606]
		[batch 20/20] avg loss: 0.09893723578466619		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.107075158638951 | validation: 0.09210349792662859]
	TIME [epoch: 8.74 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12080501554271827		[learning rate: 0.00075692]
		[batch 20/20] avg loss: 0.12751744515345792		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.12416123034808808 | validation: 0.11544313461665977]
	TIME [epoch: 8.74 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11250154892280721		[learning rate: 0.00075326]
		[batch 20/20] avg loss: 0.11057171632271375		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.11153663262276048 | validation: 0.1523469485400831]
	TIME [epoch: 8.73 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10796390125309141		[learning rate: 0.00074962]
		[batch 20/20] avg loss: 0.10039504915442984		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.10417947520376063 | validation: 0.10010020827390656]
	TIME [epoch: 8.73 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10713126202651047		[learning rate: 0.000746]
		[batch 20/20] avg loss: 0.1005901853288983		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.10386072367770435 | validation: 0.12826326186718615]
	TIME [epoch: 8.73 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1153024916792282		[learning rate: 0.00074239]
		[batch 20/20] avg loss: 0.09332112499761779		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.10431180833842299 | validation: 0.09117358450758684]
	TIME [epoch: 8.73 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1083054545806387		[learning rate: 0.0007388]
		[batch 20/20] avg loss: 0.09981393097170099		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.10405969277616985 | validation: 0.1002442183873339]
	TIME [epoch: 8.74 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09486536814989731		[learning rate: 0.00073523]
		[batch 20/20] avg loss: 0.1040694023785588		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.09946738526422805 | validation: 0.09881870248907715]
	TIME [epoch: 8.74 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10628231968560083		[learning rate: 0.00073167]
		[batch 20/20] avg loss: 0.1278860344718303		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.11708417707871559 | validation: 0.10756848623254375]
	TIME [epoch: 8.75 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11005127022526298		[learning rate: 0.00072813]
		[batch 20/20] avg loss: 0.11680364185389272		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.11342745603957786 | validation: 0.1054188356315238]
	TIME [epoch: 8.73 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09346236833063701		[learning rate: 0.00072461]
		[batch 20/20] avg loss: 0.12013140818508146		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.10679688825785927 | validation: 0.11089687875009002]
	TIME [epoch: 8.73 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12124505941598991		[learning rate: 0.00072111]
		[batch 20/20] avg loss: 0.12495164728101474		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.12309835334850232 | validation: 0.1344036001184209]
	TIME [epoch: 8.73 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.13803765005716412		[learning rate: 0.00071762]
		[batch 20/20] avg loss: 0.10038136598817755		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.1192095080226708 | validation: 0.07983583178373928]
	TIME [epoch: 8.73 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10404837238948725		[learning rate: 0.00071415]
		[batch 20/20] avg loss: 0.10372832265340119		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.10388834752144424 | validation: 0.09126651662860383]
	TIME [epoch: 8.76 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10266167049309378		[learning rate: 0.0007107]
		[batch 20/20] avg loss: 0.09704539944970506		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.09985353497139944 | validation: 0.09170850672348638]
	TIME [epoch: 8.75 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11109702988635664		[learning rate: 0.00070726]
		[batch 20/20] avg loss: 0.1580206385696555		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.13455883422800607 | validation: 0.13695682544233004]
	TIME [epoch: 8.74 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11885703322799826		[learning rate: 0.00070384]
		[batch 20/20] avg loss: 0.08747493744254396		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.10316598533527113 | validation: 0.13717148547682673]
	TIME [epoch: 8.74 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11864109199548131		[learning rate: 0.00070044]
		[batch 20/20] avg loss: 0.09713578257862039		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.10788843728705085 | validation: 0.10059784309748465]
	TIME [epoch: 8.73 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10831583821469466		[learning rate: 0.00069705]
		[batch 20/20] avg loss: 0.10561426658559232		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.10696505240014349 | validation: 0.08779683649131104]
	TIME [epoch: 8.76 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10961314701158613		[learning rate: 0.00069368]
		[batch 20/20] avg loss: 0.11898430603931691		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.11429872652545155 | validation: 0.09835927553830448]
	TIME [epoch: 8.75 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.100808593582287		[learning rate: 0.00069032]
		[batch 20/20] avg loss: 0.10752727503124344		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.10416793430676523 | validation: 0.21209662020228107]
	TIME [epoch: 8.74 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.12905157009148865		[learning rate: 0.00068699]
		[batch 20/20] avg loss: 0.10739124212011805		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.11822140610580337 | validation: 0.10818285149441295]
	TIME [epoch: 8.74 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08817057241659432		[learning rate: 0.00068366]
		[batch 20/20] avg loss: 0.1063666833939376		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.09726862790526594 | validation: 0.10626244467722262]
	TIME [epoch: 8.74 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1285317823574458		[learning rate: 0.00068036]
		[batch 20/20] avg loss: 0.10349972611927523		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.1160157542383605 | validation: 0.09230210145957868]
	TIME [epoch: 8.76 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09159765574464257		[learning rate: 0.00067707]
		[batch 20/20] avg loss: 0.1145548415854585		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.10307624866505054 | validation: 0.10940080199818789]
	TIME [epoch: 8.72 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10846621775231817		[learning rate: 0.00067379]
		[batch 20/20] avg loss: 0.1110840066076028		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.10977511217996047 | validation: 0.08524045294799697]
	TIME [epoch: 8.72 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09913616302635624		[learning rate: 0.00067053]
		[batch 20/20] avg loss: 0.1028175101571243		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.10097683659174025 | validation: 0.08726111144374739]
	TIME [epoch: 8.73 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10277704499009584		[learning rate: 0.00066729]
		[batch 20/20] avg loss: 0.10298746264691568		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.10288225381850573 | validation: 0.09739491406103572]
	TIME [epoch: 8.75 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.134359087281797		[learning rate: 0.00066406]
		[batch 20/20] avg loss: 0.10493684013492746		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.11964796370836221 | validation: 0.10305595709948052]
	TIME [epoch: 8.76 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09680486508434649		[learning rate: 0.00066085]
		[batch 20/20] avg loss: 0.09354057988713058		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.09517272248573852 | validation: 0.09101817143872581]
	TIME [epoch: 8.77 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10352700466177475		[learning rate: 0.00065766]
		[batch 20/20] avg loss: 0.10581685277911253		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.10467192872044365 | validation: 0.10469725937444768]
	TIME [epoch: 8.75 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10481753499580868		[learning rate: 0.00065448]
		[batch 20/20] avg loss: 0.10269665637026204		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.10375709568303537 | validation: 0.08868194803977565]
	TIME [epoch: 8.75 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10692498523047182		[learning rate: 0.00065131]
		[batch 20/20] avg loss: 0.09593574070500356		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.1014303629677377 | validation: 0.1042859298423977]
	TIME [epoch: 8.73 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10658973664242233		[learning rate: 0.00064816]
		[batch 20/20] avg loss: 0.10721983281419338		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.10690478472830786 | validation: 0.12786415767149722]
	TIME [epoch: 8.74 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10989377724876559		[learning rate: 0.00064503]
		[batch 20/20] avg loss: 0.12428789684959281		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.11709083704917919 | validation: 0.12061354873221386]
	TIME [epoch: 8.76 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10472774715798264		[learning rate: 0.00064191]
		[batch 20/20] avg loss: 0.09574309790730973		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.1002354225326462 | validation: 0.10262900468774529]
	TIME [epoch: 8.75 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11168124476942168		[learning rate: 0.00063881]
		[batch 20/20] avg loss: 0.11319191373421796		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.11243657925181982 | validation: 0.10429081809257296]
	TIME [epoch: 8.74 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09388780910334597		[learning rate: 0.00063572]
		[batch 20/20] avg loss: 0.12026846435601071		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.10707813672967832 | validation: 0.209289035666226]
	TIME [epoch: 8.74 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1319439292820221		[learning rate: 0.00063264]
		[batch 20/20] avg loss: 0.11365865534080484		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.12280129231141343 | validation: 0.08782808841212894]
	TIME [epoch: 8.74 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10037738666565135		[learning rate: 0.00062958]
		[batch 20/20] avg loss: 0.1291232461302924		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.11475031639797188 | validation: 0.20366498598854216]
	TIME [epoch: 8.75 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1327266410179386		[learning rate: 0.00062654]
		[batch 20/20] avg loss: 0.11985380189023014		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.12629022145408436 | validation: 0.10608482568473873]
	TIME [epoch: 8.74 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10801596636976725		[learning rate: 0.00062351]
		[batch 20/20] avg loss: 0.09039862946275379		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.09920729791626053 | validation: 0.09077730287607184]
	TIME [epoch: 8.75 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10148092756176372		[learning rate: 0.00062049]
		[batch 20/20] avg loss: 0.11206129280585705		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.1067711101838104 | validation: 0.09970874218740455]
	TIME [epoch: 8.75 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10544103903030802		[learning rate: 0.00061749]
		[batch 20/20] avg loss: 0.09805129491946321		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.10174616697488562 | validation: 0.09481834423085661]
	TIME [epoch: 8.74 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0950931679034177		[learning rate: 0.00061451]
		[batch 20/20] avg loss: 0.12653695542823382		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.11081506166582578 | validation: 0.08993772883628257]
	TIME [epoch: 8.77 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10236502285453646		[learning rate: 0.00061153]
		[batch 20/20] avg loss: 0.1011890204330037		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.10177702164377007 | validation: 0.10148510324256729]
	TIME [epoch: 8.73 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10990861743119158		[learning rate: 0.00060858]
		[batch 20/20] avg loss: 0.10218061236158986		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.10604461489639075 | validation: 0.09200876376546038]
	TIME [epoch: 8.74 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09812151677919766		[learning rate: 0.00060563]
		[batch 20/20] avg loss: 0.09897152144790727		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.09854651911355247 | validation: 0.11362743829293519]
	TIME [epoch: 8.73 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09767082052345183		[learning rate: 0.00060271]
		[batch 20/20] avg loss: 0.09632457854072911		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.09699769953209046 | validation: 0.11054038354223444]
	TIME [epoch: 8.74 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10675096425201969		[learning rate: 0.00059979]
		[batch 20/20] avg loss: 0.09500245225251368		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.10087670825226669 | validation: 0.09533665351397727]
	TIME [epoch: 8.75 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09824397138101865		[learning rate: 0.00059689]
		[batch 20/20] avg loss: 0.09874435256530083		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.09849416197315974 | validation: 0.08671868651931333]
	TIME [epoch: 8.75 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08748652331590617		[learning rate: 0.000594]
		[batch 20/20] avg loss: 0.10175625424773253		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.09462138878181935 | validation: 0.088419893223455]
	TIME [epoch: 8.74 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11129361046036997		[learning rate: 0.00059113]
		[batch 20/20] avg loss: 0.09088009222698894		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.10108685134367945 | validation: 0.0939318008832036]
	TIME [epoch: 8.74 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09901494169949152		[learning rate: 0.00058827]
		[batch 20/20] avg loss: 0.12033553113280764		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.10967523641614958 | validation: 0.1098919692534654]
	TIME [epoch: 8.74 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10755566068506214		[learning rate: 0.00058543]
		[batch 20/20] avg loss: 0.10619686707978027		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.10687626388242122 | validation: 0.08525222870566232]
	TIME [epoch: 8.76 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10933952286514355		[learning rate: 0.0005826]
		[batch 20/20] avg loss: 0.087304809342214		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.09832216610367879 | validation: 0.08885636443020971]
	TIME [epoch: 8.77 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10130913851018178		[learning rate: 0.00057978]
		[batch 20/20] avg loss: 0.10291280938559848		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.10211097394789012 | validation: 0.11460208689286448]
	TIME [epoch: 8.75 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09412832520455094		[learning rate: 0.00057698]
		[batch 20/20] avg loss: 0.10168149417860192		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.09790490969157642 | validation: 0.13392492048208812]
	TIME [epoch: 8.75 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10224822695407636		[learning rate: 0.00057419]
		[batch 20/20] avg loss: 0.09994464569233677		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.10109643632320657 | validation: 0.0888344860434231]
	TIME [epoch: 8.75 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11114006731542096		[learning rate: 0.00057141]
		[batch 20/20] avg loss: 0.11200740917830201		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.11157373824686148 | validation: 0.08822838008623125]
	TIME [epoch: 8.76 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10589664926377018		[learning rate: 0.00056865]
		[batch 20/20] avg loss: 0.09615192555602965		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.10102428740989991 | validation: 0.07998194319397237]
	TIME [epoch: 8.76 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10842067481369673		[learning rate: 0.0005659]
		[batch 20/20] avg loss: 0.12157354647913954		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.11499711064641815 | validation: 0.09178633557034349]
	TIME [epoch: 8.76 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09946369038360278		[learning rate: 0.00056316]
		[batch 20/20] avg loss: 0.08598615015027956		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.09272492026694118 | validation: 0.07273502906360843]
	TIME [epoch: 8.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_644.pth
	Model improved!!!
EPOCH 645/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08964447946684982		[learning rate: 0.00056044]
		[batch 20/20] avg loss: 0.09851378643429386		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.09407913295057187 | validation: 0.09718148639264326]
	TIME [epoch: 8.75 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10143958733059855		[learning rate: 0.00055773]
		[batch 20/20] avg loss: 0.08249775751723708		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.0919686724239178 | validation: 0.07549734781347496]
	TIME [epoch: 8.75 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09151690262470578		[learning rate: 0.00055503]
		[batch 20/20] avg loss: 0.11249001065057837		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.10200345663764207 | validation: 0.07481421751699949]
	TIME [epoch: 8.76 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09361610997102061		[learning rate: 0.00055235]
		[batch 20/20] avg loss: 0.09954541333433452		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.09658076165267757 | validation: 0.10326565210283745]
	TIME [epoch: 8.76 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09552230639385614		[learning rate: 0.00054967]
		[batch 20/20] avg loss: 0.10000244586837989		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.09776237613111802 | validation: 0.1019324048668682]
	TIME [epoch: 8.74 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0981385880859431		[learning rate: 0.00054702]
		[batch 20/20] avg loss: 0.09607050913921793		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.09710454861258053 | validation: 0.10738111048498464]
	TIME [epoch: 8.74 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10487938370207764		[learning rate: 0.00054437]
		[batch 20/20] avg loss: 0.10898438623268325		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.10693188496738044 | validation: 0.10072703239754098]
	TIME [epoch: 8.76 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1106165767685617		[learning rate: 0.00054174]
		[batch 20/20] avg loss: 0.10382676639699887		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.10722167158278026 | validation: 0.08976861250533463]
	TIME [epoch: 8.77 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09978281764554346		[learning rate: 0.00053912]
		[batch 20/20] avg loss: 0.09784591091441097		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.09881436427997721 | validation: 0.09327418208474374]
	TIME [epoch: 8.75 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11357704616002581		[learning rate: 0.00053651]
		[batch 20/20] avg loss: 0.09107371371168757		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.1023253799358567 | validation: 0.07884905875651137]
	TIME [epoch: 8.75 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.090757437052166		[learning rate: 0.00053392]
		[batch 20/20] avg loss: 0.09312575264794848		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.09194159485005723 | validation: 0.09798054361243821]
	TIME [epoch: 8.76 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10621122516160957		[learning rate: 0.00053134]
		[batch 20/20] avg loss: 0.09809608905103316		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.10215365710632138 | validation: 0.10310350693384021]
	TIME [epoch: 8.75 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08758459586416656		[learning rate: 0.00052877]
		[batch 20/20] avg loss: 0.09112461694510864		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.08935460640463758 | validation: 0.11612444317149068]
	TIME [epoch: 8.77 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10185947310094186		[learning rate: 0.00052621]
		[batch 20/20] avg loss: 0.11284370252772995		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.10735158781433589 | validation: 0.08067363217416677]
	TIME [epoch: 8.76 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0984712721415371		[learning rate: 0.00052366]
		[batch 20/20] avg loss: 0.11153806334622988		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.10500466774388346 | validation: 0.0843334024853202]
	TIME [epoch: 8.75 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09717394924491077		[learning rate: 0.00052113]
		[batch 20/20] avg loss: 0.09065916492739676		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.09391655708615379 | validation: 0.08014774956067619]
	TIME [epoch: 8.75 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09231232829638807		[learning rate: 0.00051861]
		[batch 20/20] avg loss: 0.1025042596071011		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.09740829395174459 | validation: 0.07998020026152673]
	TIME [epoch: 8.75 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09290292622558607		[learning rate: 0.0005161]
		[batch 20/20] avg loss: 0.11022903380784599		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.10156598001671605 | validation: 0.09373081934280746]
	TIME [epoch: 8.75 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10175177285936396		[learning rate: 0.00051361]
		[batch 20/20] avg loss: 0.08734045840905331		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.09454611563420862 | validation: 0.09281199240335912]
	TIME [epoch: 8.78 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09665294680052444		[learning rate: 0.00051112]
		[batch 20/20] avg loss: 0.08927021021356683		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.09296157850704563 | validation: 0.10109136199296703]
	TIME [epoch: 8.75 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09543050511317193		[learning rate: 0.00050865]
		[batch 20/20] avg loss: 0.08698744480058238		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.09120897495687715 | validation: 0.07345088507806416]
	TIME [epoch: 8.75 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09460995775105178		[learning rate: 0.00050619]
		[batch 20/20] avg loss: 0.10271835263043057		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.09866415519074116 | validation: 0.0925121534792421]
	TIME [epoch: 8.75 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10325053894923586		[learning rate: 0.00050374]
		[batch 20/20] avg loss: 0.08574414230754465		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.09449734062839024 | validation: 0.13966059212448917]
	TIME [epoch: 8.76 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10376126119434481		[learning rate: 0.00050131]
		[batch 20/20] avg loss: 0.08918420569998721		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.09647273344716602 | validation: 0.09245310140980524]
	TIME [epoch: 8.77 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09736126008968121		[learning rate: 0.00049888]
		[batch 20/20] avg loss: 0.11374859651992981		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.1055549283048055 | validation: 0.08928280723436163]
	TIME [epoch: 8.76 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09286647114068038		[learning rate: 0.00049647]
		[batch 20/20] avg loss: 0.09022870651703212		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.09154758882885625 | validation: 0.07833111233601733]
	TIME [epoch: 8.76 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09282147360921468		[learning rate: 0.00049407]
		[batch 20/20] avg loss: 0.08973570116238962		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.09127858738580215 | validation: 0.1080054040314335]
	TIME [epoch: 8.75 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09796864301138623		[learning rate: 0.00049168]
		[batch 20/20] avg loss: 0.0921395126229538		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.09505407781717 | validation: 0.07659551988940543]
	TIME [epoch: 8.77 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.092156267528176		[learning rate: 0.0004893]
		[batch 20/20] avg loss: 0.09413730979042792		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.09314678865930198 | validation: 0.11452569152912492]
	TIME [epoch: 8.77 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11548064563603463		[learning rate: 0.00048694]
		[batch 20/20] avg loss: 0.090246561524398		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.10286360358021632 | validation: 0.0969614420703602]
	TIME [epoch: 8.76 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09941646066822066		[learning rate: 0.00048458]
		[batch 20/20] avg loss: 0.09660109460207036		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.09800877763514551 | validation: 0.1389817698968186]
	TIME [epoch: 8.75 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11596199627964303		[learning rate: 0.00048224]
		[batch 20/20] avg loss: 0.1018870064747222		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.10892450137718261 | validation: 0.09080132983936884]
	TIME [epoch: 8.75 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10952027744513235		[learning rate: 0.00047991]
		[batch 20/20] avg loss: 0.11052597407333078		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.11002312575923157 | validation: 0.11719614853156576]
	TIME [epoch: 8.75 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09685623839338955		[learning rate: 0.00047759]
		[batch 20/20] avg loss: 0.09387818366438491		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.09536721102888723 | validation: 0.06861772770894929]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_678.pth
	Model improved!!!
EPOCH 679/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09750536271419193		[learning rate: 0.00047528]
		[batch 20/20] avg loss: 0.0870241144184408		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.09226473856631637 | validation: 0.07741296004515409]
	TIME [epoch: 8.76 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09163328463348636		[learning rate: 0.00047298]
		[batch 20/20] avg loss: 0.08259605759815511		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.08711467111582075 | validation: 0.08839927166401394]
	TIME [epoch: 8.76 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.1017143198283071		[learning rate: 0.00047069]
		[batch 20/20] avg loss: 0.09268930669228195		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.09720181326029452 | validation: 0.07229474606771376]
	TIME [epoch: 8.76 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0925584742299265		[learning rate: 0.00046842]
		[batch 20/20] avg loss: 0.09044552332631947		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.09150199877812298 | validation: 0.09180891319795727]
	TIME [epoch: 8.76 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09785738461775079		[learning rate: 0.00046615]
		[batch 20/20] avg loss: 0.10409607008646256		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.10097672735210665 | validation: 0.09522232114048967]
	TIME [epoch: 8.79 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08984085993277056		[learning rate: 0.0004639]
		[batch 20/20] avg loss: 0.09619094771372225		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.0930159038232464 | validation: 0.10732807136181821]
	TIME [epoch: 8.76 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10772371484225145		[learning rate: 0.00046165]
		[batch 20/20] avg loss: 0.0999347812595364		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.10382924805089393 | validation: 0.09399985467848536]
	TIME [epoch: 8.76 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10221272771805416		[learning rate: 0.00045942]
		[batch 20/20] avg loss: 0.09183230056427723		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.09702251414116568 | validation: 0.11510505410056049]
	TIME [epoch: 8.76 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10820996831358551		[learning rate: 0.0004572]
		[batch 20/20] avg loss: 0.09743285757767603		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.10282141294563077 | validation: 0.08876362381890615]
	TIME [epoch: 8.75 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09379291789456672		[learning rate: 0.00045499]
		[batch 20/20] avg loss: 0.1046438889557566		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.09921840342516165 | validation: 0.0846192442944857]
	TIME [epoch: 8.76 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09190883944702759		[learning rate: 0.00045279]
		[batch 20/20] avg loss: 0.09872827362936774		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.09531855653819762 | validation: 0.07297842234352103]
	TIME [epoch: 8.76 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0817558529943714		[learning rate: 0.0004506]
		[batch 20/20] avg loss: 0.11561194400932195		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.0986838985018467 | validation: 0.12056949203043318]
	TIME [epoch: 8.75 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10502387863282761		[learning rate: 0.00044842]
		[batch 20/20] avg loss: 0.09235584247934057		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.09868986055608409 | validation: 0.0850122085415235]
	TIME [epoch: 8.76 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09054350672167902		[learning rate: 0.00044625]
		[batch 20/20] avg loss: 0.08891947208596342		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.08973148940382122 | validation: 0.08110937453185822]
	TIME [epoch: 8.76 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09397697999008006		[learning rate: 0.00044409]
		[batch 20/20] avg loss: 0.08261717846294082		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.08829707922651045 | validation: 0.09453056146544399]
	TIME [epoch: 8.76 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08893406619416269		[learning rate: 0.00044195]
		[batch 20/20] avg loss: 0.1012313272015735		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.0950826966978681 | validation: 0.09395805143156624]
	TIME [epoch: 8.77 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09163125500655762		[learning rate: 0.00043981]
		[batch 20/20] avg loss: 0.09314010972839014		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.09238568236747387 | validation: 0.09144158114363664]
	TIME [epoch: 8.76 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08726908574930096		[learning rate: 0.00043768]
		[batch 20/20] avg loss: 0.112277963803238		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.0997735247762695 | validation: 0.07300904671570274]
	TIME [epoch: 8.75 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07725495628136403		[learning rate: 0.00043556]
		[batch 20/20] avg loss: 0.09119775601974564		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.08422635615055485 | validation: 0.07518453973627298]
	TIME [epoch: 8.74 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08473684435240761		[learning rate: 0.00043346]
		[batch 20/20] avg loss: 0.09158284403330617		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.0881598441928569 | validation: 0.09566148709741734]
	TIME [epoch: 8.76 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08311672665467618		[learning rate: 0.00043136]
		[batch 20/20] avg loss: 0.08936272546176173		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.08623972605821895 | validation: 0.09343686643053953]
	TIME [epoch: 8.78 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08762758327485498		[learning rate: 0.00042928]
		[batch 20/20] avg loss: 0.10502573884552124		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.09632666106018813 | validation: 0.07965304565903372]
	TIME [epoch: 8.75 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09158558078156678		[learning rate: 0.0004272]
		[batch 20/20] avg loss: 0.09426312324930572		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.09292435201543625 | validation: 0.07688631301402353]
	TIME [epoch: 8.75 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08519777027780187		[learning rate: 0.00042513]
		[batch 20/20] avg loss: 0.08365104119740085		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.08442440573760138 | validation: 0.09647294671594893]
	TIME [epoch: 8.74 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0903669375727639		[learning rate: 0.00042308]
		[batch 20/20] avg loss: 0.10313388011977928		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.09675040884627158 | validation: 0.07404423893120142]
	TIME [epoch: 8.75 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08318065044476186		[learning rate: 0.00042103]
		[batch 20/20] avg loss: 0.08458474805359983		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.08388269924918083 | validation: 0.08736826845719645]
	TIME [epoch: 8.77 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08007871156963298		[learning rate: 0.000419]
		[batch 20/20] avg loss: 0.08940496068036788		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.08474183612500044 | validation: 0.08618698496572001]
	TIME [epoch: 8.75 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0878583511604753		[learning rate: 0.00041697]
		[batch 20/20] avg loss: 0.09341626994800815		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.09063731055424172 | validation: 0.08930737654812372]
	TIME [epoch: 8.76 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09584598900784787		[learning rate: 0.00041495]
		[batch 20/20] avg loss: 0.10810825643093729		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.10197712271939256 | validation: 0.12071672565618581]
	TIME [epoch: 8.76 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0980357234366552		[learning rate: 0.00041295]
		[batch 20/20] avg loss: 0.10660088145007514		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.10231830244336518 | validation: 0.09199947309391503]
	TIME [epoch: 8.75 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10349765075472177		[learning rate: 0.00041095]
		[batch 20/20] avg loss: 0.07765227825899822		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.09057496450685999 | validation: 0.08199775513155205]
	TIME [epoch: 8.77 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09041399553591814		[learning rate: 0.00040896]
		[batch 20/20] avg loss: 0.08389702257773048		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.08715550905682432 | validation: 0.07075456089159181]
	TIME [epoch: 8.76 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09021764956341767		[learning rate: 0.00040699]
		[batch 20/20] avg loss: 0.0860100915656141		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.08811387056451589 | validation: 0.09481587391954018]
	TIME [epoch: 8.76 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09360171849911056		[learning rate: 0.00040502]
		[batch 20/20] avg loss: 0.08308332797841358		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.08834252323876206 | validation: 0.06582003366110585]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_712.pth
	Model improved!!!
EPOCH 713/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08486093893229278		[learning rate: 0.00040306]
		[batch 20/20] avg loss: 0.07819566211029125		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.08152830052129202 | validation: 0.096622006754424]
	TIME [epoch: 8.75 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10227275146908141		[learning rate: 0.00040111]
		[batch 20/20] avg loss: 0.08728174178510131		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.09477724662709136 | validation: 0.09900133078220108]
	TIME [epoch: 8.77 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09055662162327598		[learning rate: 0.00039917]
		[batch 20/20] avg loss: 0.09140899055045101		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.0909828060868635 | validation: 0.08898500450583186]
	TIME [epoch: 8.75 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09949109091402039		[learning rate: 0.00039724]
		[batch 20/20] avg loss: 0.07969850326096893		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.08959479708749465 | validation: 0.08212950210202224]
	TIME [epoch: 8.75 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09257183626751046		[learning rate: 0.00039532]
		[batch 20/20] avg loss: 0.0928278180956936		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.09269982718160202 | validation: 0.08715886641034155]
	TIME [epoch: 8.74 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09762020237979645		[learning rate: 0.00039341]
		[batch 20/20] avg loss: 0.08908701377869441		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.09335360807924545 | validation: 0.08204931054124262]
	TIME [epoch: 8.76 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0906345700946579		[learning rate: 0.0003915]
		[batch 20/20] avg loss: 0.0871237646388129		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.08887916736673539 | validation: 0.08887667041323871]
	TIME [epoch: 8.76 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11077548265792847		[learning rate: 0.00038961]
		[batch 20/20] avg loss: 0.08250536081010404		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.09664042173401624 | validation: 0.10600698532836421]
	TIME [epoch: 8.78 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08713450952485738		[learning rate: 0.00038773]
		[batch 20/20] avg loss: 0.08004893194500787		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.08359172073493262 | validation: 0.0922746128725754]
	TIME [epoch: 8.76 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08876292968921314		[learning rate: 0.00038585]
		[batch 20/20] avg loss: 0.0951158915983763		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.09193941064379471 | validation: 0.08973386462547375]
	TIME [epoch: 8.75 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10161879788957302		[learning rate: 0.00038399]
		[batch 20/20] avg loss: 0.09753050270801603		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.09957465029879452 | validation: 0.09392096608896755]
	TIME [epoch: 8.76 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09203422537350706		[learning rate: 0.00038213]
		[batch 20/20] avg loss: 0.09417052231878784		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.09310237384614742 | validation: 0.10009148904576196]
	TIME [epoch: 8.76 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08212081185524647		[learning rate: 0.00038028]
		[batch 20/20] avg loss: 0.09279081781871938		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.08745581483698293 | validation: 0.08264155070489904]
	TIME [epoch: 8.78 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.088648457508906		[learning rate: 0.00037844]
		[batch 20/20] avg loss: 0.09124779792412395		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.08994812771651499 | validation: 0.07094927168290471]
	TIME [epoch: 8.77 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08583324573493141		[learning rate: 0.00037661]
		[batch 20/20] avg loss: 0.09200547926607128		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.08891936250050134 | validation: 0.09761879232965154]
	TIME [epoch: 8.75 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0853845932495468		[learning rate: 0.00037479]
		[batch 20/20] avg loss: 0.08594269674562384		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.08566364499758532 | validation: 0.09199564321088453]
	TIME [epoch: 8.75 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09798785652758377		[learning rate: 0.00037298]
		[batch 20/20] avg loss: 0.09204523931227972		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.09501654791993172 | validation: 0.07641998799670993]
	TIME [epoch: 8.75 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09098768717543304		[learning rate: 0.00037118]
		[batch 20/20] avg loss: 0.08477091313561358		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.0878793001555233 | validation: 0.07337431401343825]
	TIME [epoch: 8.77 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08588755080979753		[learning rate: 0.00036938]
		[batch 20/20] avg loss: 0.08172114704802379		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.08380434892891066 | validation: 0.09717966936519166]
	TIME [epoch: 8.76 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09276877884866884		[learning rate: 0.00036759]
		[batch 20/20] avg loss: 0.08054900168279573		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.0866588902657323 | validation: 0.07991630553449572]
	TIME [epoch: 8.76 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08303201325610282		[learning rate: 0.00036582]
		[batch 20/20] avg loss: 0.08810745702519182		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.08556973514064733 | validation: 0.07812274678406021]
	TIME [epoch: 8.75 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08596331723235033		[learning rate: 0.00036405]
		[batch 20/20] avg loss: 0.09178338567427932		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.08887335145331483 | validation: 0.0755526441970509]
	TIME [epoch: 8.75 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08889292783951848		[learning rate: 0.00036229]
		[batch 20/20] avg loss: 0.08061742292692245		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.08475517538322046 | validation: 0.07844632897077894]
	TIME [epoch: 8.78 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07784699859398492		[learning rate: 0.00036053]
		[batch 20/20] avg loss: 0.09393802160972639		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.08589251010185565 | validation: 0.1009210582304882]
	TIME [epoch: 8.75 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.089248711305291		[learning rate: 0.00035879]
		[batch 20/20] avg loss: 0.08228281309536102		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.085765762200326 | validation: 0.10437983239953347]
	TIME [epoch: 8.75 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0862103216727899		[learning rate: 0.00035706]
		[batch 20/20] avg loss: 0.09743828919984131		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.0918243054363156 | validation: 0.08685338365007193]
	TIME [epoch: 8.75 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09124604903027003		[learning rate: 0.00035533]
		[batch 20/20] avg loss: 0.09915085850077773		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.0951984537655239 | validation: 0.07704748491737115]
	TIME [epoch: 8.74 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08951178760457576		[learning rate: 0.00035361]
		[batch 20/20] avg loss: 0.08562603033079413		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.08756890896768496 | validation: 0.08423483986555189]
	TIME [epoch: 8.78 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0867758515070433		[learning rate: 0.0003519]
		[batch 20/20] avg loss: 0.08585526923873334		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.08631556037288832 | validation: 0.08301631020396777]
	TIME [epoch: 8.75 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08449788142185666		[learning rate: 0.0003502]
		[batch 20/20] avg loss: 0.10215231606436073		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.09332509874310868 | validation: 0.11164156020302284]
	TIME [epoch: 8.76 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09336118304850405		[learning rate: 0.00034851]
		[batch 20/20] avg loss: 0.09144083884259205		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.09240101094554803 | validation: 0.09867751255475721]
	TIME [epoch: 8.74 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.11103085239419674		[learning rate: 0.00034682]
		[batch 20/20] avg loss: 0.0944301271228571		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.10273048975852692 | validation: 0.09303014231052648]
	TIME [epoch: 8.74 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09821949143583104		[learning rate: 0.00034514]
		[batch 20/20] avg loss: 0.09224506139048014		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.0952322764131556 | validation: 0.10322602925015939]
	TIME [epoch: 8.75 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09245939382306383		[learning rate: 0.00034347]
		[batch 20/20] avg loss: 0.07811389374533913		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.08528664378420146 | validation: 0.07469314791649298]
	TIME [epoch: 8.77 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08093778774981476		[learning rate: 0.00034181]
		[batch 20/20] avg loss: 0.08503873551295346		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.0829882616313841 | validation: 0.11451742866074927]
	TIME [epoch: 8.76 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08831089172764436		[learning rate: 0.00034016]
		[batch 20/20] avg loss: 0.0830534516464896		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.08568217168706697 | validation: 0.08947433146203185]
	TIME [epoch: 8.75 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09363956556458684		[learning rate: 0.00033852]
		[batch 20/20] avg loss: 0.09352788578147414		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.09358372567303049 | validation: 0.08375912192482746]
	TIME [epoch: 8.76 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08416162139387297		[learning rate: 0.00033688]
		[batch 20/20] avg loss: 0.08578254430541872		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.08497208284964583 | validation: 0.07922094530347377]
	TIME [epoch: 8.76 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08039287298148069		[learning rate: 0.00033525]
		[batch 20/20] avg loss: 0.088693849729055		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.08454336135526785 | validation: 0.07159321188034452]
	TIME [epoch: 8.76 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09361688986490228		[learning rate: 0.00033363]
		[batch 20/20] avg loss: 0.09380345354159109		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.09371017170324669 | validation: 0.07924251770660859]
	TIME [epoch: 8.75 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10212731512872245		[learning rate: 0.00033202]
		[batch 20/20] avg loss: 0.09423157667950796		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.09817944590411519 | validation: 0.07588827700135106]
	TIME [epoch: 8.76 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08273643638034184		[learning rate: 0.00033041]
		[batch 20/20] avg loss: 0.08984200453092776		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.08628922045563481 | validation: 0.07801693538268849]
	TIME [epoch: 8.74 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08517919979618829		[learning rate: 0.00032881]
		[batch 20/20] avg loss: 0.10736650518939128		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.09627285249278979 | validation: 0.14012075288604825]
	TIME [epoch: 8.75 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.10317204789032312		[learning rate: 0.00032722]
		[batch 20/20] avg loss: 0.08571596840108661		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.09444400814570486 | validation: 0.07410920439584491]
	TIME [epoch: 8.77 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08742427767798133		[learning rate: 0.00032564]
		[batch 20/20] avg loss: 0.08050377072794726		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.08396402420296428 | validation: 0.08277720375935475]
	TIME [epoch: 8.75 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09136528024616367		[learning rate: 0.00032406]
		[batch 20/20] avg loss: 0.08066104602061262		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.08601316313338817 | validation: 0.0835763900342236]
	TIME [epoch: 8.75 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0829409586879446		[learning rate: 0.0003225]
		[batch 20/20] avg loss: 0.08737456660418805		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.08515776264606634 | validation: 0.08079040663338602]
	TIME [epoch: 8.74 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08719327270062456		[learning rate: 0.00032094]
		[batch 20/20] avg loss: 0.09471187168758308		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.09095257219410381 | validation: 0.0843672743518436]
	TIME [epoch: 8.75 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07985721128070974		[learning rate: 0.00031939]
		[batch 20/20] avg loss: 0.09356864733123234		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.08671292930597105 | validation: 0.0924931598112772]
	TIME [epoch: 8.77 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08765626574026944		[learning rate: 0.00031784]
		[batch 20/20] avg loss: 0.08607199147347101		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.08686412860687022 | validation: 0.07471894228620592]
	TIME [epoch: 8.76 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08402762059705182		[learning rate: 0.0003163]
		[batch 20/20] avg loss: 0.0908437740973367		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.08743569734719427 | validation: 0.09224178612833775]
	TIME [epoch: 8.76 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08029514685580451		[learning rate: 0.00031477]
		[batch 20/20] avg loss: 0.08504198328330607		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.08266856506955528 | validation: 0.09866641106850874]
	TIME [epoch: 8.75 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08211858971388378		[learning rate: 0.00031325]
		[batch 20/20] avg loss: 0.08286577905342463		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.08249218438365422 | validation: 0.09110843311233527]
	TIME [epoch: 8.75 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08995176718292597		[learning rate: 0.00031174]
		[batch 20/20] avg loss: 0.08142328704780785		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.08568752711536691 | validation: 0.09902787711724043]
	TIME [epoch: 8.77 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0844811286843648		[learning rate: 0.00031023]
		[batch 20/20] avg loss: 0.0912155898501269		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.08784835926724585 | validation: 0.10039653146563984]
	TIME [epoch: 8.76 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08959616794730196		[learning rate: 0.00030873]
		[batch 20/20] avg loss: 0.07917065235364663		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.08438341015047428 | validation: 0.08909403629157273]
	TIME [epoch: 8.75 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08274178123677173		[learning rate: 0.00030724]
		[batch 20/20] avg loss: 0.08748431028254175		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.08511304575965675 | validation: 0.10326141185560692]
	TIME [epoch: 8.74 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0827469932893136		[learning rate: 0.00030575]
		[batch 20/20] avg loss: 0.08427323678844678		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.0835101150388802 | validation: 0.0852892408760273]
	TIME [epoch: 8.74 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08032755780531373		[learning rate: 0.00030427]
		[batch 20/20] avg loss: 0.08284135317282657		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.08158445548907015 | validation: 0.07896593406725075]
	TIME [epoch: 8.78 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08938520779569845		[learning rate: 0.0003028]
		[batch 20/20] avg loss: 0.07969851793196628		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.08454186286383238 | validation: 0.07548223207158632]
	TIME [epoch: 8.75 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07789683058952326		[learning rate: 0.00030134]
		[batch 20/20] avg loss: 0.07789633464107644		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.07789658261529986 | validation: 0.08829397532752137]
	TIME [epoch: 8.76 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09236750374334589		[learning rate: 0.00029988]
		[batch 20/20] avg loss: 0.07682830025842716		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.08459790200088653 | validation: 0.07434109258647537]
	TIME [epoch: 8.76 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09271180366353984		[learning rate: 0.00029843]
		[batch 20/20] avg loss: 0.10627987174809042		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.09949583770581513 | validation: 0.0949315771848962]
	TIME [epoch: 8.75 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08680780120044743		[learning rate: 0.00029699]
		[batch 20/20] avg loss: 0.08614663036186099		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.08647721578115422 | validation: 0.10123868014978235]
	TIME [epoch: 8.76 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07776612477307783		[learning rate: 0.00029555]
		[batch 20/20] avg loss: 0.08623467800989988		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.08200040139148884 | validation: 0.07417344910959366]
	TIME [epoch: 8.76 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08732245288069408		[learning rate: 0.00029412]
		[batch 20/20] avg loss: 0.0920580510754587		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.08969025197807638 | validation: 0.08794577343810114]
	TIME [epoch: 8.75 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07822647488625456		[learning rate: 0.0002927]
		[batch 20/20] avg loss: 0.0887917491268221		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.08350911200653832 | validation: 0.07380893992691503]
	TIME [epoch: 8.75 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08643557096349104		[learning rate: 0.00029128]
		[batch 20/20] avg loss: 0.08895600168716046		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.08769578632532575 | validation: 0.08167884064646347]
	TIME [epoch: 8.75 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08225823299147661		[learning rate: 0.00028987]
		[batch 20/20] avg loss: 0.09111163694153276		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.08668493496650469 | validation: 0.07855979356402921]
	TIME [epoch: 8.76 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0791034671771542		[learning rate: 0.00028847]
		[batch 20/20] avg loss: 0.08063370683445534		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.07986858700580478 | validation: 0.07619400330827447]
	TIME [epoch: 8.76 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07323242780305908		[learning rate: 0.00028708]
		[batch 20/20] avg loss: 0.08785752527819017		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.08054497654062463 | validation: 0.08642213445121935]
	TIME [epoch: 8.74 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0803474511672224		[learning rate: 0.00028569]
		[batch 20/20] avg loss: 0.07886487235182234		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.07960616175952236 | validation: 0.0733899128182561]
	TIME [epoch: 8.74 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09929886229585172		[learning rate: 0.00028431]
		[batch 20/20] avg loss: 0.09484749565648394		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.09707317897616782 | validation: 0.0893403332743666]
	TIME [epoch: 8.74 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09139445220665052		[learning rate: 0.00028293]
		[batch 20/20] avg loss: 0.07568967048120954		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.08354206134393002 | validation: 0.0831292227217165]
	TIME [epoch: 8.74 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08448885195795741		[learning rate: 0.00028157]
		[batch 20/20] avg loss: 0.08959732836311932		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.08704309016053835 | validation: 0.06364594032259059]
	TIME [epoch: 8.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_787.pth
	Model improved!!!
EPOCH 788/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09303723579996963		[learning rate: 0.0002802]
		[batch 20/20] avg loss: 0.09740727631579389		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.09522225605788179 | validation: 0.08174158783685787]
	TIME [epoch: 8.77 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08362509235066098		[learning rate: 0.00027885]
		[batch 20/20] avg loss: 0.08392697697172866		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.08377603466119482 | validation: 0.07539177440089684]
	TIME [epoch: 8.76 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0777317931708416		[learning rate: 0.0002775]
		[batch 20/20] avg loss: 0.07691557878219402		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.0773236859765178 | validation: 0.07084751678992736]
	TIME [epoch: 8.76 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07858183958915978		[learning rate: 0.00027616]
		[batch 20/20] avg loss: 0.07820096205794903		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.07839140082355439 | validation: 0.06845468576558741]
	TIME [epoch: 8.77 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07874952683177569		[learning rate: 0.00027482]
		[batch 20/20] avg loss: 0.08157275030097563		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.08016113856637566 | validation: 0.09888988479476721]
	TIME [epoch: 8.78 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08741808968865067		[learning rate: 0.00027349]
		[batch 20/20] avg loss: 0.08751647772904612		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.08746728370884839 | validation: 0.07328589824017524]
	TIME [epoch: 8.76 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09074969664264747		[learning rate: 0.00027217]
		[batch 20/20] avg loss: 0.08909066511683598		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.08992018087974173 | validation: 0.0819134448233657]
	TIME [epoch: 8.76 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07712005978531258		[learning rate: 0.00027086]
		[batch 20/20] avg loss: 0.09247860442455638		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.08479933210493448 | validation: 0.09602743877550356]
	TIME [epoch: 8.76 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08553419694085054		[learning rate: 0.00026955]
		[batch 20/20] avg loss: 0.0848630135863619		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.0851986052636062 | validation: 0.08988239022682773]
	TIME [epoch: 8.76 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08185616156395195		[learning rate: 0.00026824]
		[batch 20/20] avg loss: 0.08567511237252488		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.08376563696823842 | validation: 0.0804826075466535]
	TIME [epoch: 8.78 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08852536060704423		[learning rate: 0.00026694]
		[batch 20/20] avg loss: 0.08441286059054755		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.08646911059879589 | validation: 0.07935976745451276]
	TIME [epoch: 8.75 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08171178364891625		[learning rate: 0.00026565]
		[batch 20/20] avg loss: 0.08491445348859385		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.08331311856875505 | validation: 0.0847161690121667]
	TIME [epoch: 8.76 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0939313716523618		[learning rate: 0.00026437]
		[batch 20/20] avg loss: 0.07391603800823529		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.08392370483029855 | validation: 0.06697957238511469]
	TIME [epoch: 8.76 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0776768396056167		[learning rate: 0.00026309]
		[batch 20/20] avg loss: 0.0802580755146364		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.07896745756012653 | validation: 0.08083476556638515]
	TIME [epoch: 8.76 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08808514330865602		[learning rate: 0.00026182]
		[batch 20/20] avg loss: 0.09318927195195567		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.09063720763030583 | validation: 0.08370573944517724]
	TIME [epoch: 8.77 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08605462616459288		[learning rate: 0.00026055]
		[batch 20/20] avg loss: 0.08954524224436758		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.08779993420448022 | validation: 0.08196406294962444]
	TIME [epoch: 8.77 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08334862118419643		[learning rate: 0.00025929]
		[batch 20/20] avg loss: 0.09046023411739347		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.08690442765079498 | validation: 0.0906704098298915]
	TIME [epoch: 8.76 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08498285069955376		[learning rate: 0.00025804]
		[batch 20/20] avg loss: 0.07456928624290712		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.07977606847123045 | validation: 0.08976988651058586]
	TIME [epoch: 8.76 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08410956057755407		[learning rate: 0.00025679]
		[batch 20/20] avg loss: 0.08485516749531194		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.08448236403643301 | validation: 0.07921037152794308]
	TIME [epoch: 8.75 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07353853156351856		[learning rate: 0.00025555]
		[batch 20/20] avg loss: 0.08494801571930383		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.07924327364141119 | validation: 0.08236223454440306]
	TIME [epoch: 8.77 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08382051122602362		[learning rate: 0.00025431]
		[batch 20/20] avg loss: 0.08983020080092907		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.08682535601347635 | validation: 0.07621393072924953]
	TIME [epoch: 8.77 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08715754690556402		[learning rate: 0.00025308]
		[batch 20/20] avg loss: 0.09376084648898199		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.090459196697273 | validation: 0.07809857550380815]
	TIME [epoch: 8.76 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08357743409946608		[learning rate: 0.00025186]
		[batch 20/20] avg loss: 0.07694459211904954		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.08026101310925782 | validation: 0.07324333693771617]
	TIME [epoch: 8.76 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08060628435562012		[learning rate: 0.00025064]
		[batch 20/20] avg loss: 0.08551238597767864		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.08305933516664937 | validation: 0.07099870366256819]
	TIME [epoch: 8.75 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07555000602210085		[learning rate: 0.00024943]
		[batch 20/20] avg loss: 0.07864312234133702		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.07709656418171892 | validation: 0.0756593564219819]
	TIME [epoch: 8.75 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08139522833168014		[learning rate: 0.00024822]
		[batch 20/20] avg loss: 0.08185432074015216		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.08162477453591617 | validation: 0.07599238810588496]
	TIME [epoch: 8.78 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0838300632265061		[learning rate: 0.00024702]
		[batch 20/20] avg loss: 0.07727200572409824		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.08055103447530217 | validation: 0.073049202286578]
	TIME [epoch: 8.77 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07885301245647214		[learning rate: 0.00024583]
		[batch 20/20] avg loss: 0.08423165029402034		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.08154233137524625 | validation: 0.0841550968932036]
	TIME [epoch: 8.77 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09143484510261454		[learning rate: 0.00024464]
		[batch 20/20] avg loss: 0.08142707661973869		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.0864309608611766 | validation: 0.06814976852723952]
	TIME [epoch: 8.76 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0789440671592607		[learning rate: 0.00024346]
		[batch 20/20] avg loss: 0.0791894091591314		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.07906673815919606 | validation: 0.09889107675352174]
	TIME [epoch: 8.76 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09495673934608795		[learning rate: 0.00024228]
		[batch 20/20] avg loss: 0.07646399254075069		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.08571036594341933 | validation: 0.08898641278373953]
	TIME [epoch: 8.79 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07237436530809542		[learning rate: 0.00024111]
		[batch 20/20] avg loss: 0.07842218798451359		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.07539827664630451 | validation: 0.06871972518638433]
	TIME [epoch: 8.77 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07499210326626238		[learning rate: 0.00023994]
		[batch 20/20] avg loss: 0.07713899430403152		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.07606554878514696 | validation: 0.08390936452253883]
	TIME [epoch: 8.76 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08358164773755539		[learning rate: 0.00023878]
		[batch 20/20] avg loss: 0.07797741419727078		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.08077953096741308 | validation: 0.08712802386604909]
	TIME [epoch: 8.77 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07972848813982202		[learning rate: 0.00023763]
		[batch 20/20] avg loss: 0.08050472828990063		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.08011660821486132 | validation: 0.07955287635694125]
	TIME [epoch: 8.78 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08162784084770809		[learning rate: 0.00023648]
		[batch 20/20] avg loss: 0.08375633588541054		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.08269208836655931 | validation: 0.09329719781808715]
	TIME [epoch: 8.79 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07548443956192744		[learning rate: 0.00023533]
		[batch 20/20] avg loss: 0.0907970595488562		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.08314074955539182 | validation: 0.08026777645010304]
	TIME [epoch: 8.77 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07804153881091756		[learning rate: 0.0002342]
		[batch 20/20] avg loss: 0.07752698908403624		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.07778426394747691 | validation: 0.07753299418054813]
	TIME [epoch: 8.75 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07112039009040462		[learning rate: 0.00023306]
		[batch 20/20] avg loss: 0.07840027875173493		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.07476033442106977 | validation: 0.06294575722342964]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_826.pth
	Model improved!!!
EPOCH 827/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08025633126017057		[learning rate: 0.00023194]
		[batch 20/20] avg loss: 0.07646010304997472		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.07835821715507264 | validation: 0.06845501749683272]
	TIME [epoch: 8.75 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07571540728552793		[learning rate: 0.00023081]
		[batch 20/20] avg loss: 0.08092892905553224		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.07832216817053009 | validation: 0.06851629645536295]
	TIME [epoch: 8.77 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08119731438738718		[learning rate: 0.0002297]
		[batch 20/20] avg loss: 0.0773003430702315		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.07924882872880933 | validation: 0.07456603163682124]
	TIME [epoch: 8.77 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07570728930729928		[learning rate: 0.00022859]
		[batch 20/20] avg loss: 0.07925925692929894		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.07748327311829911 | validation: 0.08644443340077027]
	TIME [epoch: 8.76 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08476120141260854		[learning rate: 0.00022748]
		[batch 20/20] avg loss: 0.08481416384263979		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.08478768262762416 | validation: 0.07035292131582074]
	TIME [epoch: 8.76 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08037576202812728		[learning rate: 0.00022638]
		[batch 20/20] avg loss: 0.07766240480361698		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.07901908341587213 | validation: 0.0707781696571638]
	TIME [epoch: 8.76 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09209016769185534		[learning rate: 0.00022529]
		[batch 20/20] avg loss: 0.08894687257802505		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.09051852013494018 | validation: 0.07429205970430675]
	TIME [epoch: 8.76 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07358853965369427		[learning rate: 0.0002242]
		[batch 20/20] avg loss: 0.08164674600270735		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.07761764282820081 | validation: 0.0707283242359022]
	TIME [epoch: 8.78 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07486213916691853		[learning rate: 0.00022311]
		[batch 20/20] avg loss: 0.0754721449048795		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.075167142035899 | validation: 0.07476283590395194]
	TIME [epoch: 8.76 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.09632686601500344		[learning rate: 0.00022203]
		[batch 20/20] avg loss: 0.07813982600693112		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.0872333460109673 | validation: 0.0788650392344184]
	TIME [epoch: 8.76 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0845735004850255		[learning rate: 0.00022096]
		[batch 20/20] avg loss: 0.07925718542181656		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.08191534295342102 | validation: 0.10059706009471409]
	TIME [epoch: 8.76 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08834201014920434		[learning rate: 0.00021989]
		[batch 20/20] avg loss: 0.07502353844552503		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.0816827742973647 | validation: 0.06521367009609348]
	TIME [epoch: 8.76 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07442380485425601		[learning rate: 0.00021883]
		[batch 20/20] avg loss: 0.07800529959310089		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.07621455222367847 | validation: 0.07182599253866244]
	TIME [epoch: 8.76 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07953502967358053		[learning rate: 0.00021777]
		[batch 20/20] avg loss: 0.07836938782642297		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.07895220875000176 | validation: 0.07070212899429063]
	TIME [epoch: 8.75 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08342472091739625		[learning rate: 0.00021672]
		[batch 20/20] avg loss: 0.08771732820478381		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.08557102456109003 | validation: 0.1001156456417446]
	TIME [epoch: 8.76 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08640232895575653		[learning rate: 0.00021567]
		[batch 20/20] avg loss: 0.0917726728596822		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.08908750090771936 | validation: 0.08804766974520219]
	TIME [epoch: 8.76 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08057117840901003		[learning rate: 0.00021463]
		[batch 20/20] avg loss: 0.0684944920829185		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.07453283524596424 | validation: 0.07121893199253453]
	TIME [epoch: 8.76 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07697661117284868		[learning rate: 0.00021359]
		[batch 20/20] avg loss: 0.0810363458747226		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.07900647852378564 | validation: 0.07157236536997924]
	TIME [epoch: 8.79 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08175073392843794		[learning rate: 0.00021256]
		[batch 20/20] avg loss: 0.07551649822267856		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.07863361607555824 | validation: 0.06968580655818801]
	TIME [epoch: 8.75 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08219956597693526		[learning rate: 0.00021153]
		[batch 20/20] avg loss: 0.07548729116048078		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.07884342856870803 | validation: 0.07300230665238219]
	TIME [epoch: 8.76 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08117211416529928		[learning rate: 0.00021051]
		[batch 20/20] avg loss: 0.0783400090800904		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.07975606162269486 | validation: 0.08030379750407811]
	TIME [epoch: 8.75 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08454753264582911		[learning rate: 0.00020949]
		[batch 20/20] avg loss: 0.07795528980548086		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.08125141122565496 | validation: 0.07326082819891022]
	TIME [epoch: 8.76 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08238925329859512		[learning rate: 0.00020847]
		[batch 20/20] avg loss: 0.07888342107432823		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.08063633718646168 | validation: 0.07302494913830095]
	TIME [epoch: 8.79 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08323030589629307		[learning rate: 0.00020747]
		[batch 20/20] avg loss: 0.07198185779481588		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.07760608184555447 | validation: 0.08164927604875777]
	TIME [epoch: 8.76 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07678731172996588		[learning rate: 0.00020646]
		[batch 20/20] avg loss: 0.07455417801254723		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.07567074487125654 | validation: 0.06391649326115756]
	TIME [epoch: 8.76 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0859003057710112		[learning rate: 0.00020546]
		[batch 20/20] avg loss: 0.07078484243187994		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.07834257410144559 | validation: 0.07939847295671669]
	TIME [epoch: 8.74 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07063217246524353		[learning rate: 0.00020447]
		[batch 20/20] avg loss: 0.07508275636003457		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.07285746441263906 | validation: 0.08336831730585839]
	TIME [epoch: 8.75 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.078298138825858		[learning rate: 0.00020348]
		[batch 20/20] avg loss: 0.08192003223307284		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.08010908552946541 | validation: 0.08349794337515265]
	TIME [epoch: 8.79 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07956119965574722		[learning rate: 0.0002025]
		[batch 20/20] avg loss: 0.08111251274001288		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.08033685619788006 | validation: 0.07329857954540933]
	TIME [epoch: 8.76 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06936723599562827		[learning rate: 0.00020152]
		[batch 20/20] avg loss: 0.08293713398210974		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.07615218498886901 | validation: 0.068520746278958]
	TIME [epoch: 8.76 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07852580057719173		[learning rate: 0.00020054]
		[batch 20/20] avg loss: 0.07841956292723379		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.07847268175221275 | validation: 0.07841350769791591]
	TIME [epoch: 8.76 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07605464848913537		[learning rate: 0.00019957]
		[batch 20/20] avg loss: 0.08928370749128635		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.08266917799021087 | validation: 0.09052172508794173]
	TIME [epoch: 8.76 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08155311824534281		[learning rate: 0.00019861]
		[batch 20/20] avg loss: 0.07973511496229972		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.08064411660382124 | validation: 0.07373430457870349]
	TIME [epoch: 8.77 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08273751532630919		[learning rate: 0.00019765]
		[batch 20/20] avg loss: 0.08010548219699987		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.08142149876165454 | validation: 0.08349476210476409]
	TIME [epoch: 8.77 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07566578517897231		[learning rate: 0.00019669]
		[batch 20/20] avg loss: 0.07417900139882995		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.07492239328890114 | validation: 0.07606087715779031]
	TIME [epoch: 8.77 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07081255318163271		[learning rate: 0.00019574]
		[batch 20/20] avg loss: 0.07459346585861612		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.0727030095201244 | validation: 0.072213700628292]
	TIME [epoch: 8.76 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08168377282299025		[learning rate: 0.0001948]
		[batch 20/20] avg loss: 0.06715637798602188		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.07442007540450607 | validation: 0.07697575490967988]
	TIME [epoch: 8.77 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07185472805092616		[learning rate: 0.00019385]
		[batch 20/20] avg loss: 0.07613411350676179		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.07399442077884398 | validation: 0.07201078793895282]
	TIME [epoch: 8.77 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07045117422225004		[learning rate: 0.00019292]
		[batch 20/20] avg loss: 0.08707114375290666		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.07876115898757836 | validation: 0.07539349811926337]
	TIME [epoch: 8.78 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07111478249109753		[learning rate: 0.00019198]
		[batch 20/20] avg loss: 0.07709365266557386		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.07410421757833571 | validation: 0.06638786726078197]
	TIME [epoch: 8.76 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07934458710198583		[learning rate: 0.00019105]
		[batch 20/20] avg loss: 0.07291161925593977		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.07612810317896282 | validation: 0.07444494124756551]
	TIME [epoch: 8.75 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07989077462646606		[learning rate: 0.00019013]
		[batch 20/20] avg loss: 0.07900783765323996		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.07944930613985299 | validation: 0.0785248040482876]
	TIME [epoch: 8.75 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07923869204574001		[learning rate: 0.00018921]
		[batch 20/20] avg loss: 0.07459784220582581		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.07691826712578291 | validation: 0.06870110816303265]
	TIME [epoch: 8.77 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07394221442307987		[learning rate: 0.0001883]
		[batch 20/20] avg loss: 0.08076930993790046		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.07735576218049016 | validation: 0.07151987054584025]
	TIME [epoch: 8.78 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07489434712480517		[learning rate: 0.00018739]
		[batch 20/20] avg loss: 0.0781033470720087		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.07649884709840694 | validation: 0.07633562937600237]
	TIME [epoch: 8.77 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07849016744531674		[learning rate: 0.00018648]
		[batch 20/20] avg loss: 0.08134091460225659		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.07991554102378665 | validation: 0.06862567818562568]
	TIME [epoch: 8.75 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0743185957081844		[learning rate: 0.00018558]
		[batch 20/20] avg loss: 0.07427296042227557		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.07429577806523 | validation: 0.07307357915336962]
	TIME [epoch: 8.76 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07531375698448925		[learning rate: 0.00018468]
		[batch 20/20] avg loss: 0.0816816634715413		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.07849771022801529 | validation: 0.06972016352136567]
	TIME [epoch: 8.76 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07858914017687031		[learning rate: 0.00018379]
		[batch 20/20] avg loss: 0.08080475247879053		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.07969694632783039 | validation: 0.07287878115877724]
	TIME [epoch: 8.78 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06810026733161785		[learning rate: 0.0001829]
		[batch 20/20] avg loss: 0.08526913752445404		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.07668470242803593 | validation: 0.09549197939350915]
	TIME [epoch: 8.76 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0758706148844431		[learning rate: 0.00018201]
		[batch 20/20] avg loss: 0.06790364561244557		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.07188713024844433 | validation: 0.07773111744119632]
	TIME [epoch: 8.76 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08344200252481564		[learning rate: 0.00018113]
		[batch 20/20] avg loss: 0.08026757908894236		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.081854790806879 | validation: 0.06608498343873807]
	TIME [epoch: 8.75 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07721793460626633		[learning rate: 0.00018026]
		[batch 20/20] avg loss: 0.0797360287170604		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.07847698166166335 | validation: 0.07100969135311144]
	TIME [epoch: 8.74 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08291524610097986		[learning rate: 0.00017939]
		[batch 20/20] avg loss: 0.07844462410809219		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.08067993510453604 | validation: 0.07621240222039258]
	TIME [epoch: 8.77 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07304069265866052		[learning rate: 0.00017852]
		[batch 20/20] avg loss: 0.07960660595238626		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.07632364930552338 | validation: 0.06971710531551328]
	TIME [epoch: 8.75 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07552318990075606		[learning rate: 0.00017766]
		[batch 20/20] avg loss: 0.0795572730514007		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.0775402314760784 | validation: 0.07547373238354457]
	TIME [epoch: 8.77 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08014422006289329		[learning rate: 0.0001768]
		[batch 20/20] avg loss: 0.07018429495858362		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.07516425751073848 | validation: 0.0673748995755265]
	TIME [epoch: 8.75 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07299554496490805		[learning rate: 0.00017594]
		[batch 20/20] avg loss: 0.0784107997534598		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.07570317235918393 | validation: 0.08824719588032354]
	TIME [epoch: 8.76 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08605449872725791		[learning rate: 0.00017509]
		[batch 20/20] avg loss: 0.07717576785477447		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.08161513329101618 | validation: 0.07510532012685807]
	TIME [epoch: 8.78 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07570203199878447		[learning rate: 0.00017424]
		[batch 20/20] avg loss: 0.07256845318268372		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.0741352425907341 | validation: 0.08569763929017124]
	TIME [epoch: 8.76 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07771253818082377		[learning rate: 0.0001734]
		[batch 20/20] avg loss: 0.0804650188048766		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.07908877849285019 | validation: 0.07274937683982552]
	TIME [epoch: 8.77 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0773982413779976		[learning rate: 0.00017256]
		[batch 20/20] avg loss: 0.07979506315026172		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.07859665226412965 | validation: 0.07024872813266228]
	TIME [epoch: 8.76 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07838203921927663		[learning rate: 0.00017173]
		[batch 20/20] avg loss: 0.06999040508409275		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.07418622215168469 | validation: 0.07662196624791273]
	TIME [epoch: 8.76 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07621850525906305		[learning rate: 0.0001709]
		[batch 20/20] avg loss: 0.07227325673925336		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.07424588099915821 | validation: 0.06534117428503339]
	TIME [epoch: 8.77 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.075192888197913		[learning rate: 0.00017007]
		[batch 20/20] avg loss: 0.0751453212847792		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.07516910474134611 | validation: 0.06722804851577316]
	TIME [epoch: 8.78 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07189523876760415		[learning rate: 0.00016925]
		[batch 20/20] avg loss: 0.07312346864916197		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.07250935370838306 | validation: 0.07497055870631601]
	TIME [epoch: 8.76 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07107023750635931		[learning rate: 0.00016843]
		[batch 20/20] avg loss: 0.07502027418937385		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.07304525584786657 | validation: 0.07597170968143128]
	TIME [epoch: 8.75 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07979704206442086		[learning rate: 0.00016762]
		[batch 20/20] avg loss: 0.06884004929572778		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.07431854568007433 | validation: 0.07394616831535783]
	TIME [epoch: 8.75 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07739356725119151		[learning rate: 0.00016681]
		[batch 20/20] avg loss: 0.06695377926677115		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.07217367325898134 | validation: 0.0636007148544102]
	TIME [epoch: 8.77 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07211182749425932		[learning rate: 0.000166]
		[batch 20/20] avg loss: 0.07189358276690286		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.07200270513058107 | validation: 0.06399756534816227]
	TIME [epoch: 8.78 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06943198748339241		[learning rate: 0.0001652]
		[batch 20/20] avg loss: 0.08204995057462858		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.07574096902901051 | validation: 0.07183273557187549]
	TIME [epoch: 8.77 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07834734637094432		[learning rate: 0.0001644]
		[batch 20/20] avg loss: 0.07456369784779392		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.0764555221093691 | validation: 0.08029055599608481]
	TIME [epoch: 8.76 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0725003480535476		[learning rate: 0.0001636]
		[batch 20/20] avg loss: 0.07881057928599161		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.07565546366976961 | validation: 0.07577470079045281]
	TIME [epoch: 8.76 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07803005487018297		[learning rate: 0.00016281]
		[batch 20/20] avg loss: 0.07493194372730382		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.07648099929874339 | validation: 0.08119790293383385]
	TIME [epoch: 8.76 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08150036739695209		[learning rate: 0.00016202]
		[batch 20/20] avg loss: 0.07197110395024212		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.0767357356735971 | validation: 0.06909299142689632]
	TIME [epoch: 8.78 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07500234488057306		[learning rate: 0.00016124]
		[batch 20/20] avg loss: 0.07733677556937096		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.076169560224972 | validation: 0.07794321746131025]
	TIME [epoch: 8.76 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07572110531787504		[learning rate: 0.00016046]
		[batch 20/20] avg loss: 0.07621241780158951		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.07596676155973228 | validation: 0.07108834806632244]
	TIME [epoch: 8.76 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07434861238561094		[learning rate: 0.00015968]
		[batch 20/20] avg loss: 0.07926693276031263		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.07680777257296177 | validation: 0.08032985010857176]
	TIME [epoch: 8.77 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0731910768646232		[learning rate: 0.00015891]
		[batch 20/20] avg loss: 0.08532148571204337		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.07925628128833329 | validation: 0.07892412400171588]
	TIME [epoch: 8.76 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07637729149491854		[learning rate: 0.00015814]
		[batch 20/20] avg loss: 0.0813185853949944		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.07884793844495648 | validation: 0.07808451286240224]
	TIME [epoch: 8.77 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08676050458369625		[learning rate: 0.00015738]
		[batch 20/20] avg loss: 0.0773603423489098		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.08206042346630302 | validation: 0.06669017986540579]
	TIME [epoch: 8.76 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06989134596957983		[learning rate: 0.00015662]
		[batch 20/20] avg loss: 0.07986380217212766		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.07487757407085374 | validation: 0.07873238269497931]
	TIME [epoch: 8.76 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06718844490347602		[learning rate: 0.00015586]
		[batch 20/20] avg loss: 0.07186217542375734		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.06952531016361667 | validation: 0.07576162973089001]
	TIME [epoch: 8.75 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07547947345428932		[learning rate: 0.00015511]
		[batch 20/20] avg loss: 0.07738475744052987		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.0764321154474096 | validation: 0.06628338763409347]
	TIME [epoch: 8.75 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07873465678543694		[learning rate: 0.00015436]
		[batch 20/20] avg loss: 0.07224974048512256		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.07549219863527976 | validation: 0.07621125658511496]
	TIME [epoch: 8.79 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07206453087001402		[learning rate: 0.00015361]
		[batch 20/20] avg loss: 0.07152271963281072		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.07179362525141239 | validation: 0.06996220751519994]
	TIME [epoch: 8.76 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07128360508214235		[learning rate: 0.00015287]
		[batch 20/20] avg loss: 0.0717031070249029		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.07149335605352262 | validation: 0.07994800043933381]
	TIME [epoch: 8.76 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0778965533727633		[learning rate: 0.00015213]
		[batch 20/20] avg loss: 0.0722612607767847		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.07507890707477399 | validation: 0.08043397229703333]
	TIME [epoch: 8.76 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08685234471984823		[learning rate: 0.00015139]
		[batch 20/20] avg loss: 0.07416272482966668		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.08050753477475746 | validation: 0.08577653792762727]
	TIME [epoch: 8.76 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07051229747377612		[learning rate: 0.00015066]
		[batch 20/20] avg loss: 0.07746064978971177		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.07398647363174393 | validation: 0.09045164539689338]
	TIME [epoch: 8.77 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07670368297104137		[learning rate: 0.00014993]
		[batch 20/20] avg loss: 0.07567915419453874		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.07619141858279006 | validation: 0.08514062376883401]
	TIME [epoch: 8.78 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07820792737438498		[learning rate: 0.00014921]
		[batch 20/20] avg loss: 0.08728776183662268		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.08274784460550384 | validation: 0.0826210641795059]
	TIME [epoch: 8.75 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07081871706842371		[learning rate: 0.00014849]
		[batch 20/20] avg loss: 0.07628206624798495		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.07355039165820434 | validation: 0.06491153358242371]
	TIME [epoch: 8.77 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07570628733488428		[learning rate: 0.00014777]
		[batch 20/20] avg loss: 0.0759527745930271		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.07582953096395569 | validation: 0.0743936561079906]
	TIME [epoch: 8.76 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06946667310272626		[learning rate: 0.00014705]
		[batch 20/20] avg loss: 0.07745629104915777		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.073461482075942 | validation: 0.07387631036154989]
	TIME [epoch: 8.76 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08496082125830146		[learning rate: 0.00014634]
		[batch 20/20] avg loss: 0.07632997677723728		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.08064539901776939 | validation: 0.07386621167178084]
	TIME [epoch: 8.77 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07465020876280275		[learning rate: 0.00014563]
		[batch 20/20] avg loss: 0.07186135864375413		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.07325578370327845 | validation: 0.0619544011579195]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_923.pth
	Model improved!!!
EPOCH 924/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07886477752826389		[learning rate: 0.00014493]
		[batch 20/20] avg loss: 0.0859582850966825		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.08241153131247321 | validation: 0.07061607470247161]
	TIME [epoch: 8.77 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08059724812638644		[learning rate: 0.00014423]
		[batch 20/20] avg loss: 0.07433920343132419		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.07746822577885529 | validation: 0.061418806250914046]
	TIME [epoch: 8.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_925.pth
	Model improved!!!
EPOCH 926/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07759424113789014		[learning rate: 0.00014353]
		[batch 20/20] avg loss: 0.07097644774403436		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.07428534444096226 | validation: 0.0737293688915205]
	TIME [epoch: 8.76 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07568881574479355		[learning rate: 0.00014284]
		[batch 20/20] avg loss: 0.07471142882302156		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.07520012228390756 | validation: 0.07155812001689736]
	TIME [epoch: 8.77 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07591525728745359		[learning rate: 0.00014215]
		[batch 20/20] avg loss: 0.0731870790565338		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.07455116817199368 | validation: 0.06595466640711632]
	TIME [epoch: 8.75 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07177564010514462		[learning rate: 0.00014146]
		[batch 20/20] avg loss: 0.08038805022175985		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.07608184516345226 | validation: 0.0742353784177971]
	TIME [epoch: 8.75 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07710942912942234		[learning rate: 0.00014078]
		[batch 20/20] avg loss: 0.07751642153152213		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.07731292533047224 | validation: 0.08504645011070659]
	TIME [epoch: 8.75 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0776113670676715		[learning rate: 0.00014009]
		[batch 20/20] avg loss: 0.0737034937370679		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.0756574304023697 | validation: 0.07337330721116489]
	TIME [epoch: 8.75 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0838422381127929		[learning rate: 0.00013942]
		[batch 20/20] avg loss: 0.07563297689929847		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.0797376075060457 | validation: 0.06815827580022592]
	TIME [epoch: 8.78 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07276386475152538		[learning rate: 0.00013874]
		[batch 20/20] avg loss: 0.07298035064512368		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.07287210769832456 | validation: 0.07033729265418288]
	TIME [epoch: 8.76 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0732769692368204		[learning rate: 0.00013807]
		[batch 20/20] avg loss: 0.07259792800724132		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.07293744862203086 | validation: 0.08654866336078804]
	TIME [epoch: 8.75 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07656688619614509		[learning rate: 0.0001374]
		[batch 20/20] avg loss: 0.0818468787145181		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.07920688245533158 | validation: 0.072595345398354]
	TIME [epoch: 8.76 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08035880655721842		[learning rate: 0.00013674]
		[batch 20/20] avg loss: 0.06979310456276593		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.07507595555999219 | validation: 0.07352326449946418]
	TIME [epoch: 8.76 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07031283649915286		[learning rate: 0.00013608]
		[batch 20/20] avg loss: 0.07497496741049581		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.07264390195482433 | validation: 0.08232572894452543]
	TIME [epoch: 8.77 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07301178399064015		[learning rate: 0.00013542]
		[batch 20/20] avg loss: 0.07703289458498838		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.07502233928781427 | validation: 0.07803945022616506]
	TIME [epoch: 8.77 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07893455647882083		[learning rate: 0.00013477]
		[batch 20/20] avg loss: 0.0718191426064029		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.07537684954261185 | validation: 0.07074200279238387]
	TIME [epoch: 8.75 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07315021660190657		[learning rate: 0.00013411]
		[batch 20/20] avg loss: 0.07240151720210995		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.07277586690200827 | validation: 0.0702629798933609]
	TIME [epoch: 8.76 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07185165483569894		[learning rate: 0.00013347]
		[batch 20/20] avg loss: 0.07350095653739719		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.07267630568654806 | validation: 0.07466612672413278]
	TIME [epoch: 8.75 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07578692917078338		[learning rate: 0.00013282]
		[batch 20/20] avg loss: 0.07262676610631111		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.07420684763854725 | validation: 0.0679560483145098]
	TIME [epoch: 8.78 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07141331386660717		[learning rate: 0.00013218]
		[batch 20/20] avg loss: 0.07163877489959017		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.07152604438309867 | validation: 0.08177955478021254]
	TIME [epoch: 8.76 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07786977042130043		[learning rate: 0.00013154]
		[batch 20/20] avg loss: 0.07808344404755918		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.07797660723442983 | validation: 0.08981416132505281]
	TIME [epoch: 8.77 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07629234472953277		[learning rate: 0.0001309]
		[batch 20/20] avg loss: 0.07992025252996499		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.07810629862974885 | validation: 0.08017368626073808]
	TIME [epoch: 8.77 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06339663087644597		[learning rate: 0.00013027]
		[batch 20/20] avg loss: 0.07808735893198514		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.07074199490421557 | validation: 0.06543653676266643]
	TIME [epoch: 8.75 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0689117273878832		[learning rate: 0.00012964]
		[batch 20/20] avg loss: 0.07706642426861234		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.07298907582824776 | validation: 0.06669170000875875]
	TIME [epoch: 8.77 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06812129012240939		[learning rate: 0.00012901]
		[batch 20/20] avg loss: 0.07443707646358294		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.07127918329299618 | validation: 0.07644997228627834]
	TIME [epoch: 8.76 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08042395978526876		[learning rate: 0.00012839]
		[batch 20/20] avg loss: 0.08167816674863429		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.08105106326695152 | validation: 0.08118251758714304]
	TIME [epoch: 8.77 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07391414784834648		[learning rate: 0.00012777]
		[batch 20/20] avg loss: 0.07767644014384968		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.07579529399609808 | validation: 0.06717882726326622]
	TIME [epoch: 8.76 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07664308247527471		[learning rate: 0.00012715]
		[batch 20/20] avg loss: 0.08141248894711302		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.07902778571119386 | validation: 0.08804081735795546]
	TIME [epoch: 8.75 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08632144244467607		[learning rate: 0.00012653]
		[batch 20/20] avg loss: 0.08179318878490667		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.08405731561479138 | validation: 0.07254069808734188]
	TIME [epoch: 8.77 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07682303474950988		[learning rate: 0.00012592]
		[batch 20/20] avg loss: 0.0717034407280277		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.07426323773876878 | validation: 0.07729625348581863]
	TIME [epoch: 8.77 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06968708525137038		[learning rate: 0.00012531]
		[batch 20/20] avg loss: 0.0816499895527076		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.075668537402039 | validation: 0.07333624100484709]
	TIME [epoch: 8.76 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07308704501638316		[learning rate: 0.00012471]
		[batch 20/20] avg loss: 0.07569569311557597		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.07439136906597957 | validation: 0.08082540094016019]
	TIME [epoch: 8.76 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07237585540079498		[learning rate: 0.00012411]
		[batch 20/20] avg loss: 0.07147709219757001		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.07192647379918247 | validation: 0.07034868858670243]
	TIME [epoch: 8.76 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06639286085843668		[learning rate: 0.0001235]
		[batch 20/20] avg loss: 0.07733678978473565		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.07186482532158615 | validation: 0.08129173431774386]
	TIME [epoch: 8.76 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07913202857053867		[learning rate: 0.00012291]
		[batch 20/20] avg loss: 0.07108797039855448		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.07510999948454657 | validation: 0.06657796625689906]
	TIME [epoch: 8.78 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07851324537302311		[learning rate: 0.00012231]
		[batch 20/20] avg loss: 0.07873930314701001		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.07862627426001656 | validation: 0.07238226383003606]
	TIME [epoch: 8.76 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07458389607583005		[learning rate: 0.00012172]
		[batch 20/20] avg loss: 0.07100699214764775		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.07279544411173888 | validation: 0.07007325918980215]
	TIME [epoch: 8.77 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06613976871388319		[learning rate: 0.00012113]
		[batch 20/20] avg loss: 0.07547313015336458		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.07080644943362387 | validation: 0.0636596523931163]
	TIME [epoch: 8.75 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07658549350400681		[learning rate: 0.00012055]
		[batch 20/20] avg loss: 0.06736004057323201		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.0719727670386194 | validation: 0.07290501127934351]
	TIME [epoch: 8.76 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07168825842666063		[learning rate: 0.00011996]
		[batch 20/20] avg loss: 0.07067993333166958		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.0711840958791651 | validation: 0.07687669265797276]
	TIME [epoch: 8.78 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0643078481752333		[learning rate: 0.00011938]
		[batch 20/20] avg loss: 0.07160444580219513		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.06795614698871422 | validation: 0.07118344916516542]
	TIME [epoch: 8.76 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07282291469776117		[learning rate: 0.00011881]
		[batch 20/20] avg loss: 0.06960199023967922		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.07121245246872021 | validation: 0.06549540393020634]
	TIME [epoch: 8.76 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07048502016005283		[learning rate: 0.00011823]
		[batch 20/20] avg loss: 0.07188736996642545		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.07118619506323913 | validation: 0.07576825872660725]
	TIME [epoch: 8.76 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.08274146989462094		[learning rate: 0.00011766]
		[batch 20/20] avg loss: 0.06987837887827639		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.07630992438644865 | validation: 0.07627508336475335]
	TIME [epoch: 8.76 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07640360435193765		[learning rate: 0.00011709]
		[batch 20/20] avg loss: 0.06539344867231736		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.07089852651212751 | validation: 0.06660091031403145]
	TIME [epoch: 8.78 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07178526328636925		[learning rate: 0.00011653]
		[batch 20/20] avg loss: 0.0674985026643696		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.06964188297536941 | validation: 0.0748706200079387]
	TIME [epoch: 8.76 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07810515913625074		[learning rate: 0.00011596]
		[batch 20/20] avg loss: 0.07512735056844488		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.07661625485234778 | validation: 0.06813712362237276]
	TIME [epoch: 8.76 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07303686669627507		[learning rate: 0.0001154]
		[batch 20/20] avg loss: 0.06320648742003965		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.06812167705815736 | validation: 0.0641789541323663]
	TIME [epoch: 8.76 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06316643382136296		[learning rate: 0.00011484]
		[batch 20/20] avg loss: 0.07390958169476665		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.06853800775806479 | validation: 0.06982835044603397]
	TIME [epoch: 8.76 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07312257313516207		[learning rate: 0.00011429]
		[batch 20/20] avg loss: 0.06955873422028681		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.07134065367772444 | validation: 0.07014528442015383]
	TIME [epoch: 8.77 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07317331441184226		[learning rate: 0.00011374]
		[batch 20/20] avg loss: 0.06657400094681962		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.06987365767933093 | validation: 0.0691490015879801]
	TIME [epoch: 8.76 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07049968145325017		[learning rate: 0.00011319]
		[batch 20/20] avg loss: 0.07111857839827038		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.07080912992576024 | validation: 0.0793198292523203]
	TIME [epoch: 8.75 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0730735274715004		[learning rate: 0.00011264]
		[batch 20/20] avg loss: 0.07835667613954651		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.07571510180552346 | validation: 0.0728384942955558]
	TIME [epoch: 8.74 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07507556935468039		[learning rate: 0.00011209]
		[batch 20/20] avg loss: 0.06886198111522449		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.07196877523495242 | validation: 0.06639104417906963]
	TIME [epoch: 8.75 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07179400868032292		[learning rate: 0.00011155]
		[batch 20/20] avg loss: 0.07018063761375906		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.070987323147041 | validation: 0.06522607781386204]
	TIME [epoch: 8.76 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06882015385004125		[learning rate: 0.00011101]
		[batch 20/20] avg loss: 0.07370843604156319		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.07126429494580222 | validation: 0.06743817550380199]
	TIME [epoch: 8.78 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07447275557309997		[learning rate: 0.00011047]
		[batch 20/20] avg loss: 0.07760090644352167		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.07603683100831082 | validation: 0.07423694655601401]
	TIME [epoch: 8.76 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06904149015490271		[learning rate: 0.00010994]
		[batch 20/20] avg loss: 0.07735868872177312		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.07320008943833792 | validation: 0.07675037570030806]
	TIME [epoch: 8.74 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.0781473668752965		[learning rate: 0.00010941]
		[batch 20/20] avg loss: 0.07371222178274237		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.07592979432901942 | validation: 0.07619602607126033]
	TIME [epoch: 8.75 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07230973043684069		[learning rate: 0.00010888]
		[batch 20/20] avg loss: 0.07004599150421814		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.0711778609705294 | validation: 0.06630848961168231]
	TIME [epoch: 8.76 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07035949865730576		[learning rate: 0.00010835]
		[batch 20/20] avg loss: 0.07656995564649158		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.07346472715189867 | validation: 0.06835765092851169]
	TIME [epoch: 8.78 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07871182343334218		[learning rate: 0.00010783]
		[batch 20/20] avg loss: 0.07108929534944058		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.07490055939139137 | validation: 0.08424168926493547]
	TIME [epoch: 8.75 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06940137971855105		[learning rate: 0.00010731]
		[batch 20/20] avg loss: 0.07626683267844744		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.07283410619849923 | validation: 0.07608564963074409]
	TIME [epoch: 8.76 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07447181683703136		[learning rate: 0.00010679]
		[batch 20/20] avg loss: 0.07482803604174557		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.07464992643938846 | validation: 0.06264445876851582]
	TIME [epoch: 8.75 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06784377620290168		[learning rate: 0.00010627]
		[batch 20/20] avg loss: 0.07356551540389153		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.07070464580339661 | validation: 0.07079085435796144]
	TIME [epoch: 8.75 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07057420231916417		[learning rate: 0.00010576]
		[batch 20/20] avg loss: 0.07158482227960425		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.07107951229938418 | validation: 0.060582733096812655]
	TIME [epoch: 8.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study1/model_tr_study1_r3_20240218_115024/states/model_tr_study1_989.pth
	Model improved!!!
EPOCH 990/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06797384385574656		[learning rate: 0.00010525]
		[batch 20/20] avg loss: 0.07699595328057		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.07248489856815828 | validation: 0.06815004935983232]
	TIME [epoch: 8.74 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07436886351575055		[learning rate: 0.00010474]
		[batch 20/20] avg loss: 0.0685627897377232		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.07146582662673687 | validation: 0.07022701630776296]
	TIME [epoch: 8.75 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07443324011246437		[learning rate: 0.00010423]
		[batch 20/20] avg loss: 0.06868886328581814		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.07156105169914125 | validation: 0.06650783106209349]
	TIME [epoch: 8.75 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07104131448305077		[learning rate: 0.00010373]
		[batch 20/20] avg loss: 0.07094763386197107		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.07099447417251092 | validation: 0.071282634847409]
	TIME [epoch: 8.75 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07525678125794659		[learning rate: 0.00010323]
		[batch 20/20] avg loss: 0.06984434677442129		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.07255056401618393 | validation: 0.07048745679265232]
	TIME [epoch: 8.77 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.06957846531201205		[learning rate: 0.00010273]
		[batch 20/20] avg loss: 0.06869688372523093		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.06913767451862148 | validation: 0.07027806112541156]
	TIME [epoch: 8.76 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07283528908933254		[learning rate: 0.00010223]
		[batch 20/20] avg loss: 0.06464371870051797		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.06873950389492525 | validation: 0.06903520258226398]
	TIME [epoch: 8.75 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07248383586882277		[learning rate: 0.00010174]
		[batch 20/20] avg loss: 0.07387577024698336		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.07317980305790307 | validation: 0.06444578931627859]
	TIME [epoch: 8.75 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07071341473446327		[learning rate: 0.00010124]
		[batch 20/20] avg loss: 0.06909445977999731		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.06990393725723029 | validation: 0.06793864819754175]
	TIME [epoch: 8.76 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07620723684939988		[learning rate: 0.00010075]
		[batch 20/20] avg loss: 0.06966272947754903		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.07293498316347446 | validation: 0.07800590738390639]
	TIME [epoch: 8.79 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/20] avg loss: 0.07172554839906181		[learning rate: 0.00010027]
		[batch 20/20] avg loss: 0.07168560441252593		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.07170557640579386 | validation: 0.08568952378102593]
	TIME [epoch: 8.77 sec]
Finished training in 8842.379 seconds.
