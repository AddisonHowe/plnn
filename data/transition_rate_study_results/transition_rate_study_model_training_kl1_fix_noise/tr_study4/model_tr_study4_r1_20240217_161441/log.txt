Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3741865521

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.78230125655936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.78230125655936 | validation: 9.340821328237883]
	TIME [epoch: 71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.411658091524604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.411658091524604 | validation: 6.409699303796696]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.569402827957911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.569402827957911 | validation: 5.878877437899264]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.502283349406783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.502283349406783 | validation: 4.478054310816822]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.132511560600828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.132511560600828 | validation: 4.304158912888861]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.985720187921321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.985720187921321 | validation: 5.1950808115842255]
	TIME [epoch: 9.07 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.789338786472587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.789338786472587 | validation: 5.134649226763316]
	TIME [epoch: 9.07 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.000079408991594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.000079408991594 | validation: 4.0841599351872295]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.365839812803953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.365839812803953 | validation: 3.961186281722136]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.33418389428353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.33418389428353 | validation: 3.837766364467997]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.315647117684087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.315647117684087 | validation: 3.8371989238316475]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9039050272350573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9039050272350573 | validation: 3.4483008254355187]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.728449648685379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.728449648685379 | validation: 3.5125958016414995]
	TIME [epoch: 9.1 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.108591564749419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.108591564749419 | validation: 5.389460700784695]
	TIME [epoch: 9.06 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.821271719255383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.821271719255383 | validation: 2.4360925871286034]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.177005181474865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.177005181474865 | validation: 1.6152452326931326]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8372720343218014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8372720343218014 | validation: 1.9780348212245658]
	TIME [epoch: 9.07 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7378495896527455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7378495896527455 | validation: 2.692778512569511]
	TIME [epoch: 9.09 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8667947112806327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8667947112806327 | validation: 2.718663211078988]
	TIME [epoch: 9.06 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0022793739213602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0022793739213602 | validation: 2.272825513040422]
	TIME [epoch: 9.06 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3561676530767097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3561676530767097 | validation: 1.0341993769912008]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9135736960737901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9135736960737901 | validation: 0.6540457541619515]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7854665518488251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7854665518488251 | validation: 0.7949150202692448]
	TIME [epoch: 9.09 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1155977826453116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1155977826453116 | validation: 0.67759438599935]
	TIME [epoch: 9.06 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6734290525630522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6734290525630522 | validation: 0.8088383141856001]
	TIME [epoch: 9.06 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5114693532636028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5114693532636028 | validation: 0.5313375454469343]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7271446108935935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7271446108935935 | validation: 0.805324892804975]
	TIME [epoch: 9.07 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.474345737428379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.474345737428379 | validation: 3.2212074207419255]
	TIME [epoch: 9.09 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2812112795767476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2812112795767476 | validation: 0.8443524495674595]
	TIME [epoch: 9.07 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7822557224215683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7822557224215683 | validation: 0.47164916249733657]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5991649035651724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5991649035651724 | validation: 0.5539381783130686]
	TIME [epoch: 9.07 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7262620534128412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7262620534128412 | validation: 1.3706877205596704]
	TIME [epoch: 9.06 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1693556233660685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1693556233660685 | validation: 0.519920971991652]
	TIME [epoch: 9.09 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7205717813921049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7205717813921049 | validation: 0.5232933769770349]
	TIME [epoch: 9.07 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5959663808362636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5959663808362636 | validation: 2.900904611902754]
	TIME [epoch: 9.07 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3135831114670395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3135831114670395 | validation: 2.7513739334241425]
	TIME [epoch: 9.08 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2957930754333775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2957930754333775 | validation: 2.7427304211280505]
	TIME [epoch: 9.06 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6036698467839183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6036698467839183 | validation: 0.5878676882378501]
	TIME [epoch: 9.1 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8297103493925684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8297103493925684 | validation: 0.5705307457635849]
	TIME [epoch: 9.06 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7479307663430261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7479307663430261 | validation: 1.011406888391835]
	TIME [epoch: 9.06 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1351001866647843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1351001866647843 | validation: 0.6305764459779074]
	TIME [epoch: 9.07 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9479204191010335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9479204191010335 | validation: 0.8837446394784141]
	TIME [epoch: 9.07 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6618524926574162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6618524926574162 | validation: 0.6150355895713087]
	TIME [epoch: 9.09 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6152572423743732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6152572423743732 | validation: 0.517714914436365]
	TIME [epoch: 9.06 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6702120647234974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6702120647234974 | validation: 0.7163176734122252]
	TIME [epoch: 9.06 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6989350266753924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6989350266753924 | validation: 0.5520498715717579]
	TIME [epoch: 9.06 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7558702116940248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7558702116940248 | validation: 0.8633060841155531]
	TIME [epoch: 9.08 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7176261795075959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7176261795075959 | validation: 0.4841984284677459]
	TIME [epoch: 9.06 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6410699252996019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6410699252996019 | validation: 0.7675863502003512]
	TIME [epoch: 9.06 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8235242345960337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8235242345960337 | validation: 0.6096157899095125]
	TIME [epoch: 9.06 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8453898050733292		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 0.8453898050733292 | validation: 0.8194224562921609]
	TIME [epoch: 9.06 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.711950624370531		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 0.711950624370531 | validation: 0.8905941467716187]
	TIME [epoch: 9.09 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7845188926579769		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.7845188926579769 | validation: 0.76531159699794]
	TIME [epoch: 9.06 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6544132684954177		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 0.6544132684954177 | validation: 0.637314440173269]
	TIME [epoch: 9.07 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7656988686634988		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 0.7656988686634988 | validation: 0.5106866168525759]
	TIME [epoch: 9.06 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7238304120414749		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.7238304120414749 | validation: 0.6245466887190734]
	TIME [epoch: 9.08 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6522198722091543		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 0.6522198722091543 | validation: 0.4797388781176837]
	TIME [epoch: 9.08 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.816838246061641		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 0.816838246061641 | validation: 0.5724910451368859]
	TIME [epoch: 9.05 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7047475283628822		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.7047475283628822 | validation: 0.91984091478247]
	TIME [epoch: 9.06 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9030284502563403		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.9030284502563403 | validation: 0.756439330370988]
	TIME [epoch: 9.06 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.610105382938846		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 0.610105382938846 | validation: 0.7263048324626289]
	TIME [epoch: 9.09 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6798564623392999		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 0.6798564623392999 | validation: 0.9361687051032983]
	TIME [epoch: 9.06 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6320675375169791		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.6320675375169791 | validation: 0.6106762560833632]
	TIME [epoch: 9.06 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7182119182921419		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 0.7182119182921419 | validation: 0.9631232067449073]
	TIME [epoch: 9.06 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7695967740621592		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.7695967740621592 | validation: 0.5836990442154532]
	TIME [epoch: 9.06 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.647775125243434		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.647775125243434 | validation: 0.5985512777936499]
	TIME [epoch: 9.08 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7460779972022646		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 0.7460779972022646 | validation: 0.7071084789661999]
	TIME [epoch: 9.06 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7298241457097707		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 0.7298241457097707 | validation: 0.5485607858131367]
	TIME [epoch: 9.06 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6083944783088524		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.6083944783088524 | validation: 0.5541306000746028]
	TIME [epoch: 9.06 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6096627008021056		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.6096627008021056 | validation: 0.5733251457187014]
	TIME [epoch: 9.08 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6327254226704264		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.6327254226704264 | validation: 0.5109477228726375]
	TIME [epoch: 9.06 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6852412623282863		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.6852412623282863 | validation: 0.7209519554099034]
	TIME [epoch: 9.06 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7575499083494454		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.7575499083494454 | validation: 0.7239689235213586]
	TIME [epoch: 9.06 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6030515795391116		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.6030515795391116 | validation: 1.4323950019819462]
	TIME [epoch: 9.07 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6773912872682042		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.6773912872682042 | validation: 0.5697555434306207]
	TIME [epoch: 9.09 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6171923443656226		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.6171923443656226 | validation: 0.4820677324170998]
	TIME [epoch: 9.07 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6785484509156907		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.6785484509156907 | validation: 0.6622209214214558]
	TIME [epoch: 9.06 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7206797703238018		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.7206797703238018 | validation: 0.8065897182158822]
	TIME [epoch: 9.05 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.61001492842702		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.61001492842702 | validation: 0.5695287979900143]
	TIME [epoch: 9.07 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6343439862211074		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.6343439862211074 | validation: 0.5546833225760082]
	TIME [epoch: 9.07 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7071122574255163		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.7071122574255163 | validation: 0.5688513493634746]
	TIME [epoch: 9.06 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1338827748040963		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.1338827748040963 | validation: 0.7559642614206483]
	TIME [epoch: 9.06 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.607791312593829		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.607791312593829 | validation: 0.4717669324835743]
	TIME [epoch: 9.05 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6398665977885047		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.6398665977885047 | validation: 0.6199699818872874]
	TIME [epoch: 9.08 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7732993230679064		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.7732993230679064 | validation: 0.44252390091997457]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5393460317641755		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.5393460317641755 | validation: 0.5965726942068021]
	TIME [epoch: 9.05 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6605889258468602		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.6605889258468602 | validation: 0.6653406054230051]
	TIME [epoch: 9.05 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6630487720979958		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.6630487720979958 | validation: 0.572315690739766]
	TIME [epoch: 9.06 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6310206998069522		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.6310206998069522 | validation: 0.5160506928672353]
	TIME [epoch: 9.07 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5082513604238099		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.5082513604238099 | validation: 0.5105505759669912]
	TIME [epoch: 9.05 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7419245586919082		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.7419245586919082 | validation: 1.166198526690766]
	TIME [epoch: 9.06 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6108506316491048		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.6108506316491048 | validation: 0.6521356349807581]
	TIME [epoch: 9.05 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5399390183061336		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.5399390183061336 | validation: 0.6634203396553587]
	TIME [epoch: 9.08 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7698400319827934		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.7698400319827934 | validation: 0.488913410317759]
	TIME [epoch: 9.09 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5706555650343591		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.5706555650343591 | validation: 0.5812846157787447]
	TIME [epoch: 9.07 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7469265967903399		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.7469265967903399 | validation: 0.590951251648975]
	TIME [epoch: 9.06 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6156173796788866		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.6156173796788866 | validation: 0.4874139505557638]
	TIME [epoch: 9.06 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6383417768937428		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.6383417768937428 | validation: 0.7091704110279817]
	TIME [epoch: 9.08 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8198534194288933		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.8198534194288933 | validation: 0.957140734847888]
	TIME [epoch: 9.07 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.747553103402532		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.747553103402532 | validation: 0.5558125743607901]
	TIME [epoch: 9.06 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5604976233485948		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.5604976233485948 | validation: 0.6199070177151291]
	TIME [epoch: 9.06 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6000715492098989		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.6000715492098989 | validation: 0.7396974009386348]
	TIME [epoch: 9.07 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5757285362690102		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.5757285362690102 | validation: 0.47701677474100335]
	TIME [epoch: 9.08 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.607876005585706		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.607876005585706 | validation: 1.0405482654051417]
	TIME [epoch: 9.06 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6380984319077843		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.6380984319077843 | validation: 0.5422179245026207]
	TIME [epoch: 9.06 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6122796698975513		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.6122796698975513 | validation: 0.6810777641524768]
	TIME [epoch: 9.06 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6004648424207737		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.6004648424207737 | validation: 0.779965083719167]
	TIME [epoch: 9.09 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5742223596903469		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.5742223596903469 | validation: 0.5417062173591478]
	TIME [epoch: 9.07 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0824358278390447		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.0824358278390447 | validation: 0.6723520364759632]
	TIME [epoch: 9.07 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5945063111278663		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.5945063111278663 | validation: 0.5245618424299049]
	TIME [epoch: 9.06 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.520435354010515		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.520435354010515 | validation: 0.6775127621086297]
	TIME [epoch: 9.05 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7741393764498137		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.7741393764498137 | validation: 0.6545362812092275]
	TIME [epoch: 9.15 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6670793619781599		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.6670793619781599 | validation: 0.658723512838825]
	TIME [epoch: 9.05 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6612741060086298		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.6612741060086298 | validation: 0.7345545608516473]
	TIME [epoch: 9.05 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5348233975978239		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.5348233975978239 | validation: 0.7052448963322449]
	TIME [epoch: 9.06 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6367779762960865		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.6367779762960865 | validation: 0.45051571101269794]
	TIME [epoch: 9.06 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5197759980324663		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.5197759980324663 | validation: 0.8079022873126258]
	TIME [epoch: 9.07 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6201389869060799		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.6201389869060799 | validation: 0.45654907897887]
	TIME [epoch: 9.05 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6272561377629542		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.6272561377629542 | validation: 0.7125497133855246]
	TIME [epoch: 9.07 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5669522738534857		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.5669522738534857 | validation: 0.5684024899810654]
	TIME [epoch: 9.06 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6152096329146015		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.6152096329146015 | validation: 0.9137672037738487]
	TIME [epoch: 9.09 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6875993188399481		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.6875993188399481 | validation: 0.5623578588393436]
	TIME [epoch: 9.07 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5258131847155443		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.5258131847155443 | validation: 0.45794155772989276]
	TIME [epoch: 9.06 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5965423033766979		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.5965423033766979 | validation: 0.5337211417543964]
	TIME [epoch: 9.05 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7240744096449738		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.7240744096449738 | validation: 0.5023121897318505]
	TIME [epoch: 9.06 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554301755879554		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.5554301755879554 | validation: 0.543711920660895]
	TIME [epoch: 9.08 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6169002945233345		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.6169002945233345 | validation: 0.3503700842237896]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6192723527535728		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.6192723527535728 | validation: 0.4559054948716914]
	TIME [epoch: 9.07 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6242689433481446		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.6242689433481446 | validation: 0.6149893664739334]
	TIME [epoch: 9.05 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48236716843197297		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.48236716843197297 | validation: 0.6120267227878561]
	TIME [epoch: 9.07 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6253293750918931		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.6253293750918931 | validation: 1.1042484889115094]
	TIME [epoch: 9.06 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.547912220360774		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.547912220360774 | validation: 0.6256049135905444]
	TIME [epoch: 9.06 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.546431244253761		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.546431244253761 | validation: 0.7793893055313372]
	TIME [epoch: 9.06 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6182709079076655		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.6182709079076655 | validation: 0.6760038137084261]
	TIME [epoch: 9.06 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4984856523837039		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.4984856523837039 | validation: 0.5625839469363461]
	TIME [epoch: 9.08 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.568435908944891		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.568435908944891 | validation: 0.5413482702117067]
	TIME [epoch: 9.06 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4600823909680144		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.4600823909680144 | validation: 0.3968786046158214]
	TIME [epoch: 9.05 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5479356953926491		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.5479356953926491 | validation: 0.6061865651918078]
	TIME [epoch: 9.05 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5764920797796395		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.5764920797796395 | validation: 0.4971740067956955]
	TIME [epoch: 9.04 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4824514346335291		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.4824514346335291 | validation: 0.41190943885099196]
	TIME [epoch: 9.08 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48060466841423627		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.48060466841423627 | validation: 0.4131945147557865]
	TIME [epoch: 9.05 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4327027222426974		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.4327027222426974 | validation: 0.4092111572628597]
	TIME [epoch: 9.06 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5029131706247499		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.5029131706247499 | validation: 0.4465345835016554]
	TIME [epoch: 9.05 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48258872366152605		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.48258872366152605 | validation: 0.41623558199683264]
	TIME [epoch: 9.06 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5464227206597813		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.5464227206597813 | validation: 0.3527547014165366]
	TIME [epoch: 9.07 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46501906486311767		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.46501906486311767 | validation: 0.3538140296167057]
	TIME [epoch: 9.07 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46613795846311384		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.46613795846311384 | validation: 0.4092040979393522]
	TIME [epoch: 9.07 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49846704794583535		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.49846704794583535 | validation: 0.48886891849548686]
	TIME [epoch: 9.07 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5384108601727822		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.5384108601727822 | validation: 0.48380949015818986]
	TIME [epoch: 9.07 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5209391561985866		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.5209391561985866 | validation: 0.6908206031112438]
	TIME [epoch: 9.06 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5467278084467642		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.5467278084467642 | validation: 0.36673526111383725]
	TIME [epoch: 9.04 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.503512954519856		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.503512954519856 | validation: 0.37833557242590543]
	TIME [epoch: 9.05 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.484008335263157		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.484008335263157 | validation: 0.45676726676141294]
	TIME [epoch: 9.06 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.534369592553255		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.534369592553255 | validation: 0.46716513726840314]
	TIME [epoch: 9.07 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5062620837163977		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.5062620837163977 | validation: 0.3563347958008635]
	TIME [epoch: 9.07 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.509807219628535		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.509807219628535 | validation: 0.6703770753348746]
	TIME [epoch: 9.05 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.618232392223412		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.618232392223412 | validation: 0.42479151754569416]
	TIME [epoch: 9.05 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.535007441811743		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.535007441811743 | validation: 0.395242041694125]
	TIME [epoch: 9.07 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5372105001286054		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.5372105001286054 | validation: 0.4065785775766998]
	TIME [epoch: 9.07 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5319002134952808		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.5319002134952808 | validation: 0.35734490537293895]
	TIME [epoch: 9.07 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5014796800484644		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.5014796800484644 | validation: 0.5444081435958253]
	TIME [epoch: 9.06 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46110263381991173		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.46110263381991173 | validation: 0.43583862278288443]
	TIME [epoch: 9.07 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6352803611195855		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.6352803611195855 | validation: 1.2119579622402377]
	TIME [epoch: 9.09 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6682425090260181		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.6682425090260181 | validation: 0.40474049660312417]
	TIME [epoch: 9.05 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45658228360269176		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.45658228360269176 | validation: 0.5841857381452873]
	TIME [epoch: 9.05 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4417486052793696		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.4417486052793696 | validation: 0.38557864871585745]
	TIME [epoch: 9.05 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5655968139983563		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.5655968139983563 | validation: 0.43849439024170256]
	TIME [epoch: 9.07 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45630563963270043		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.45630563963270043 | validation: 0.5081549030915452]
	TIME [epoch: 9.06 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43078799310551		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.43078799310551 | validation: 0.42210826939937995]
	TIME [epoch: 9.06 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.503850021884343		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.503850021884343 | validation: 0.8339570673169042]
	TIME [epoch: 9.05 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47842948014992903		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.47842948014992903 | validation: 0.3703626712462659]
	TIME [epoch: 9.05 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39780464721267805		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.39780464721267805 | validation: 0.3278942234614486]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_172.pth
	Model improved!!!
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38656861718888885		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.38656861718888885 | validation: 0.4251980517266545]
	TIME [epoch: 9.06 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47687970537626895		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.47687970537626895 | validation: 0.6292840689149369]
	TIME [epoch: 9.05 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4448515311643317		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.4448515311643317 | validation: 0.431291749438366]
	TIME [epoch: 9.05 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42252227695767186		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.42252227695767186 | validation: 0.36473652833128545]
	TIME [epoch: 9.04 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35725171657853205		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.35725171657853205 | validation: 0.33939979464312586]
	TIME [epoch: 9.08 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40361756692139716		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.40361756692139716 | validation: 0.28096897225760864]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4149634963238188		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.4149634963238188 | validation: 0.43731875197817116]
	TIME [epoch: 9.06 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4012485042471251		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.4012485042471251 | validation: 0.363478947767342]
	TIME [epoch: 9.06 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4108440323959745		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.4108440323959745 | validation: 0.36278194566778943]
	TIME [epoch: 9.07 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3777758034081079		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.3777758034081079 | validation: 0.4464799036840749]
	TIME [epoch: 9.07 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34186584882804516		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.34186584882804516 | validation: 0.33677783204390965]
	TIME [epoch: 9.06 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4305446180651861		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.4305446180651861 | validation: 0.34023240184114634]
	TIME [epoch: 9.05 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3845420421715907		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.3845420421715907 | validation: 0.2712914020020933]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_185.pth
	Model improved!!!
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4051587194686892		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.4051587194686892 | validation: 0.334116135849014]
	TIME [epoch: 9.08 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3623964447209044		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.3623964447209044 | validation: 0.24389822400960992]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_187.pth
	Model improved!!!
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4231047751192206		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.4231047751192206 | validation: 0.395107271154746]
	TIME [epoch: 9.08 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3420759690486865		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.3420759690486865 | validation: 0.5668523381414732]
	TIME [epoch: 9.05 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3891773967066393		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.3891773967066393 | validation: 0.49362580658138855]
	TIME [epoch: 9.05 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38491387718727815		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.38491387718727815 | validation: 0.4276412102288988]
	TIME [epoch: 9.06 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38150419855839035		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.38150419855839035 | validation: 0.4564947524253424]
	TIME [epoch: 9.07 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3656259276061803		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.3656259276061803 | validation: 0.444719577638108]
	TIME [epoch: 9.06 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3636046796262527		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.3636046796262527 | validation: 0.289141695461562]
	TIME [epoch: 9.06 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33785543820026337		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.33785543820026337 | validation: 0.8152377213275268]
	TIME [epoch: 9.05 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3746981074919046		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.3746981074919046 | validation: 0.26543883574720506]
	TIME [epoch: 9.06 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3247267630877678		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.3247267630877678 | validation: 0.25127705643935133]
	TIME [epoch: 9.07 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077415351025454		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.3077415351025454 | validation: 0.6401593077670208]
	TIME [epoch: 9.06 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44148687148568166		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.44148687148568166 | validation: 0.24904086066089437]
	TIME [epoch: 9.06 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3279861553503568		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.3279861553503568 | validation: 0.47918545185067163]
	TIME [epoch: 9.06 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4096842930528032		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.4096842930528032 | validation: 0.3614803819563872]
	TIME [epoch: 9.09 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34753166097067467		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.34753166097067467 | validation: 0.33213809847789855]
	TIME [epoch: 9.06 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29033323050190996		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.29033323050190996 | validation: 0.5080401578487624]
	TIME [epoch: 9.05 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29911331903899224		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.29911331903899224 | validation: 0.24517963512424545]
	TIME [epoch: 9.05 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38208791746153065		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.38208791746153065 | validation: 0.47144615863847883]
	TIME [epoch: 9.06 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2593787741869622		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.2593787741869622 | validation: 0.22523725569984127]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_206.pth
	Model improved!!!
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29897549175747606		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.29897549175747606 | validation: 0.3295003206595053]
	TIME [epoch: 9.04 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3345946775225602		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.3345946775225602 | validation: 0.19976876614618866]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_208.pth
	Model improved!!!
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5188925816564613		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.5188925816564613 | validation: 0.47675043118499916]
	TIME [epoch: 9.05 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5394981432064715		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.5394981432064715 | validation: 0.2968893026423003]
	TIME [epoch: 9.07 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48851625351553774		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.48851625351553774 | validation: 0.42238048712704634]
	TIME [epoch: 9.05 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3494436609629532		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.3494436609629532 | validation: 0.45451793072656943]
	TIME [epoch: 9.05 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32505586300004397		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.32505586300004397 | validation: 0.28920980845949656]
	TIME [epoch: 9.05 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25475392166875854		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.25475392166875854 | validation: 0.17588191710803716]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_214.pth
	Model improved!!!
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27549906296176563		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.27549906296176563 | validation: 0.17564447851282777]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_215.pth
	Model improved!!!
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3417174695924425		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.3417174695924425 | validation: 0.25565628712125643]
	TIME [epoch: 9.06 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3003675953345314		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.3003675953345314 | validation: 0.29427571700821964]
	TIME [epoch: 9.05 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3152546923210253		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.3152546923210253 | validation: 0.33205218405373926]
	TIME [epoch: 9.06 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32170949023017914		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.32170949023017914 | validation: 0.30190008631871107]
	TIME [epoch: 9.06 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33989965067032685		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.33989965067032685 | validation: 0.3104959049503426]
	TIME [epoch: 9.08 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31852131283340734		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.31852131283340734 | validation: 0.38492231039691427]
	TIME [epoch: 9.07 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30506185013555975		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.30506185013555975 | validation: 0.29074104453422556]
	TIME [epoch: 9.05 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29958575195134324		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.29958575195134324 | validation: 0.21222499422379235]
	TIME [epoch: 9.06 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3552440061208547		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.3552440061208547 | validation: 0.3673974785281986]
	TIME [epoch: 9.06 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.323013765266988		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.323013765266988 | validation: 0.24411018505907636]
	TIME [epoch: 9.09 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24052001822272526		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.24052001822272526 | validation: 0.2485545115796108]
	TIME [epoch: 9.07 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32421181862819576		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.32421181862819576 | validation: 0.6396896109995718]
	TIME [epoch: 9.07 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31930219964493667		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.31930219964493667 | validation: 0.2772575952487524]
	TIME [epoch: 9.07 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976704258460816		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.2976704258460816 | validation: 0.2581350047689333]
	TIME [epoch: 9.08 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601760436400495		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.2601760436400495 | validation: 0.4085436944206416]
	TIME [epoch: 9.07 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954570587099187		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.2954570587099187 | validation: 0.18436772096635445]
	TIME [epoch: 9.07 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2924874980623784		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.2924874980623784 | validation: 0.88609560330974]
	TIME [epoch: 9.06 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31621474528164095		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.31621474528164095 | validation: 0.2994525407959665]
	TIME [epoch: 9.06 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3763914356826733		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.3763914356826733 | validation: 0.3957484838388111]
	TIME [epoch: 9.09 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26241455453329454		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.26241455453329454 | validation: 0.2244234911421788]
	TIME [epoch: 9.07 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2736684490079506		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.2736684490079506 | validation: 0.33926079124412867]
	TIME [epoch: 9.06 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26429980668567277		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.26429980668567277 | validation: 0.2510510216504157]
	TIME [epoch: 9.06 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2824516477530853		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.2824516477530853 | validation: 0.2644085377036994]
	TIME [epoch: 9.07 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28038374827552837		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.28038374827552837 | validation: 0.3341374476596944]
	TIME [epoch: 9.09 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2878716553608328		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.2878716553608328 | validation: 0.2298237652982485]
	TIME [epoch: 9.07 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24549346806194916		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.24549346806194916 | validation: 0.31938165441943345]
	TIME [epoch: 9.07 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29599718359041194		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.29599718359041194 | validation: 0.20866350104263173]
	TIME [epoch: 9.06 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2891841120456634		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.2891841120456634 | validation: 0.16234542165406995]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_243.pth
	Model improved!!!
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26420424063772374		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.26420424063772374 | validation: 0.2295858751027655]
	TIME [epoch: 9.07 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3210450333735915		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.3210450333735915 | validation: 0.4783066102716089]
	TIME [epoch: 9.06 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2787696246745691		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.2787696246745691 | validation: 0.1967650797906475]
	TIME [epoch: 9.07 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2406083018717259		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.2406083018717259 | validation: 0.18757762440053657]
	TIME [epoch: 9.06 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23802060443202464		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.23802060443202464 | validation: 0.18787140570019237]
	TIME [epoch: 9.08 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23176683573515935		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.23176683573515935 | validation: 0.2697031905760733]
	TIME [epoch: 9.05 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23526306886291676		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.23526306886291676 | validation: 0.2527030743472304]
	TIME [epoch: 9.04 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28435450057153344		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.28435450057153344 | validation: 0.23600243157788675]
	TIME [epoch: 9.06 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33272817054798987		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.33272817054798987 | validation: 0.3156021164854457]
	TIME [epoch: 9.07 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2559763208872806		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.2559763208872806 | validation: 0.19898151093045047]
	TIME [epoch: 9.09 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608393011439606		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.2608393011439606 | validation: 0.20498965765783017]
	TIME [epoch: 9.07 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496049658805061		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.2496049658805061 | validation: 0.19125877194285557]
	TIME [epoch: 9.07 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6433330050127345		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.6433330050127345 | validation: 0.2009354804009565]
	TIME [epoch: 9.05 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23028271612572077		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.23028271612572077 | validation: 0.10456037554151347]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_257.pth
	Model improved!!!
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3122547385975776		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.3122547385975776 | validation: 0.2407818744848194]
	TIME [epoch: 9.08 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2517882591800378		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.2517882591800378 | validation: 0.2894814597729565]
	TIME [epoch: 9.06 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2243187463755203		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.2243187463755203 | validation: 0.23438196519721374]
	TIME [epoch: 9.05 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24733441705051748		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.24733441705051748 | validation: 0.19003102493215374]
	TIME [epoch: 9.06 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19667744816627156		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.19667744816627156 | validation: 0.17037632447856876]
	TIME [epoch: 9.07 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2165121846223677		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.2165121846223677 | validation: 0.19494948992720448]
	TIME [epoch: 9.07 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21205254189138917		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.21205254189138917 | validation: 0.6046632317691569]
	TIME [epoch: 9.07 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2487263389455975		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.2487263389455975 | validation: 0.12926103067934694]
	TIME [epoch: 9.07 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24630632457965723		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.24630632457965723 | validation: 0.22455017474506384]
	TIME [epoch: 9.06 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2686437315265403		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.2686437315265403 | validation: 0.1805526479146129]
	TIME [epoch: 9.1 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22674023952822214		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.22674023952822214 | validation: 0.24752677272494333]
	TIME [epoch: 9.07 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21922337448007223		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.21922337448007223 | validation: 0.178042742361953]
	TIME [epoch: 9.05 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529585872125464		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.2529585872125464 | validation: 0.2112866383167213]
	TIME [epoch: 9.06 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27356115296658395		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.27356115296658395 | validation: 0.38198942987037504]
	TIME [epoch: 9.07 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21480053520051431		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.21480053520051431 | validation: 0.21518570727654876]
	TIME [epoch: 9.08 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28216420693214095		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.28216420693214095 | validation: 0.3767531778566757]
	TIME [epoch: 9.06 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769273721439903		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.2769273721439903 | validation: 0.20001056782526835]
	TIME [epoch: 9.07 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24990328079354698		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.24990328079354698 | validation: 0.13269084611847362]
	TIME [epoch: 9.06 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2222238874248025		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.2222238874248025 | validation: 0.1287958098505685]
	TIME [epoch: 9.08 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.262568949262568		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.262568949262568 | validation: 0.17462530254612518]
	TIME [epoch: 9.06 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1997871866495202		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.1997871866495202 | validation: 0.12704349528300102]
	TIME [epoch: 9.06 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21007833516998398		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.21007833516998398 | validation: 0.3212489557593857]
	TIME [epoch: 9.06 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20751754186520568		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.20751754186520568 | validation: 0.12796706209816297]
	TIME [epoch: 9.07 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2024489755252444		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.2024489755252444 | validation: 0.22941687849818446]
	TIME [epoch: 9.09 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2626688357641629		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.2626688357641629 | validation: 0.20878446769481673]
	TIME [epoch: 9.06 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2390428915933037		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.2390428915933037 | validation: 0.27088103668888186]
	TIME [epoch: 9.06 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23065963694383607		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.23065963694383607 | validation: 0.1971343777135326]
	TIME [epoch: 9.06 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19314374130751522		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.19314374130751522 | validation: 0.1886565614149751]
	TIME [epoch: 9.08 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20958679727785748		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.20958679727785748 | validation: 0.1772441569100183]
	TIME [epoch: 9.06 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16330258350137505		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.16330258350137505 | validation: 0.2344569284596235]
	TIME [epoch: 9.07 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26298102096792375		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.26298102096792375 | validation: 0.3401938678413563]
	TIME [epoch: 9.06 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19265291894493966		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.19265291894493966 | validation: 0.2860962565196468]
	TIME [epoch: 9.06 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24531721894142086		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.24531721894142086 | validation: 0.1907027954356447]
	TIME [epoch: 9.09 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21409245461491336		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.21409245461491336 | validation: 0.1862703772187909]
	TIME [epoch: 9.07 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15708259377124642		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.15708259377124642 | validation: 0.2346744264975522]
	TIME [epoch: 9.07 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20862688393484094		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.20862688393484094 | validation: 0.13978387654296393]
	TIME [epoch: 9.07 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1941463486446678		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.1941463486446678 | validation: 0.2690944841781004]
	TIME [epoch: 9.08 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1809798750275462		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.1809798750275462 | validation: 0.17622524193598793]
	TIME [epoch: 9.08 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2405599993581143		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.2405599993581143 | validation: 0.41164456360987245]
	TIME [epoch: 9.05 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21658957893605774		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.21658957893605774 | validation: 0.2209822994828973]
	TIME [epoch: 9.07 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18340941740823233		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.18340941740823233 | validation: 0.21050765513795322]
	TIME [epoch: 9.07 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21011232320585777		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.21011232320585777 | validation: 0.11775990259171609]
	TIME [epoch: 9.1 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18611357451683122		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.18611357451683122 | validation: 0.1858807925116199]
	TIME [epoch: 9.06 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23528575165453208		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.23528575165453208 | validation: 0.33319182992594215]
	TIME [epoch: 9.06 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18627978678978574		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.18627978678978574 | validation: 0.16256951609531034]
	TIME [epoch: 9.06 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24805277001227796		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.24805277001227796 | validation: 0.1915969669868141]
	TIME [epoch: 9.05 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20063219479828617		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.20063219479828617 | validation: 0.13386841916204356]
	TIME [epoch: 9.09 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19347425213728153		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.19347425213728153 | validation: 0.12726586365053194]
	TIME [epoch: 9.08 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21339660509003236		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.21339660509003236 | validation: 0.23143632310294823]
	TIME [epoch: 9.06 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20554997325097962		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.20554997325097962 | validation: 0.11592076960750274]
	TIME [epoch: 9.08 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35563891483941495		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.35563891483941495 | validation: 0.33329123414369816]
	TIME [epoch: 9.09 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26501323666190185		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.26501323666190185 | validation: 0.4586826780228044]
	TIME [epoch: 9.07 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22198487147208987		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.22198487147208987 | validation: 0.16252710988721403]
	TIME [epoch: 9.07 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22969692632440938		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.22969692632440938 | validation: 0.1749510958579636]
	TIME [epoch: 9.06 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1826247823506093		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.1826247823506093 | validation: 0.14226387963845072]
	TIME [epoch: 9.06 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1619599904552162		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.1619599904552162 | validation: 0.21378255630618564]
	TIME [epoch: 9.09 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21717767240385735		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.21717767240385735 | validation: 0.13512586558270187]
	TIME [epoch: 9.06 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2045613633006375		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.2045613633006375 | validation: 0.09639661218741691]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_315.pth
	Model improved!!!
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22564792438418646		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.22564792438418646 | validation: 0.25575249951358503]
	TIME [epoch: 9.04 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2222400680281626		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.2222400680281626 | validation: 0.13620222158347822]
	TIME [epoch: 9.07 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18723964270582183		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.18723964270582183 | validation: 0.2512703587315371]
	TIME [epoch: 9.07 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2616109772926474		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.2616109772926474 | validation: 0.2631855208271512]
	TIME [epoch: 9.05 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20087555150058156		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.20087555150058156 | validation: 0.3541152841984405]
	TIME [epoch: 9.06 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2172176869594708		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.2172176869594708 | validation: 0.1692012332712411]
	TIME [epoch: 9.05 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2610540627974204		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.2610540627974204 | validation: 0.1569999855036967]
	TIME [epoch: 9.06 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23596646608323604		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.23596646608323604 | validation: 0.14180654033582385]
	TIME [epoch: 9.07 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.262275462774171		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.262275462774171 | validation: 0.21237415402119456]
	TIME [epoch: 9.05 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1938213582111087		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.1938213582111087 | validation: 0.16313396349003972]
	TIME [epoch: 9.06 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22121935735289008		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.22121935735289008 | validation: 0.23266669845072827]
	TIME [epoch: 9.05 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18779551122004476		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.18779551122004476 | validation: 0.13527691134013867]
	TIME [epoch: 9.08 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13955475681114368		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.13955475681114368 | validation: 0.11276457638243384]
	TIME [epoch: 9.06 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20787252955750685		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.20787252955750685 | validation: 0.21034806311060983]
	TIME [epoch: 9.05 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1691474198549212		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.1691474198549212 | validation: 0.12034596795823164]
	TIME [epoch: 9.06 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18685556115261465		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.18685556115261465 | validation: 0.2033055041349367]
	TIME [epoch: 9.06 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1524986392282514		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.1524986392282514 | validation: 0.13430912933174732]
	TIME [epoch: 9.06 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1912138439014734		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.1912138439014734 | validation: 0.14312406518254275]
	TIME [epoch: 9.06 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1814246554694734		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.1814246554694734 | validation: 0.181313313172432]
	TIME [epoch: 9.05 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1662670208226398		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.1662670208226398 | validation: 0.19626393919038182]
	TIME [epoch: 9.05 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2643080161185615		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.2643080161185615 | validation: 0.1325149590483887]
	TIME [epoch: 9.07 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22707724165104146		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.22707724165104146 | validation: 0.31856435512283565]
	TIME [epoch: 9.05 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895467179061377		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.1895467179061377 | validation: 0.14580878990873705]
	TIME [epoch: 9.06 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17115672273423357		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.17115672273423357 | validation: 0.12287829278001429]
	TIME [epoch: 9.05 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1700154113472658		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.1700154113472658 | validation: 0.17332311134217782]
	TIME [epoch: 9.06 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25220897152444793		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.25220897152444793 | validation: 0.2031012122273257]
	TIME [epoch: 9.07 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21298884779382066		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.21298884779382066 | validation: 0.38716486187348986]
	TIME [epoch: 9.05 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22836147810153543		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.22836147810153543 | validation: 0.223039614804118]
	TIME [epoch: 9.05 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16739341358610027		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.16739341358610027 | validation: 0.20893608592403984]
	TIME [epoch: 9.05 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16782542736134237		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.16782542736134237 | validation: 0.15199517539529606]
	TIME [epoch: 9.07 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19650950621246419		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.19650950621246419 | validation: 0.226992372143414]
	TIME [epoch: 9.07 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17213031979815013		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.17213031979815013 | validation: 0.12045325784601418]
	TIME [epoch: 9.04 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13556230482656695		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.13556230482656695 | validation: 0.17732796473241305]
	TIME [epoch: 9.05 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15448423280092632		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.15448423280092632 | validation: 0.14324045424656806]
	TIME [epoch: 9.04 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16890286454394873		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.16890286454394873 | validation: 0.19410955638941546]
	TIME [epoch: 9.07 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17353121975703206		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.17353121975703206 | validation: 0.15757932323247914]
	TIME [epoch: 9.04 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1842873800869104		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.1842873800869104 | validation: 0.16337001023359302]
	TIME [epoch: 9.05 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437385576295029		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.1437385576295029 | validation: 0.11343167092434042]
	TIME [epoch: 9.06 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17307974729895223		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.17307974729895223 | validation: 0.19896909015469227]
	TIME [epoch: 9.05 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20568589910514942		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.20568589910514942 | validation: 0.1719064820518593]
	TIME [epoch: 9.07 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20050137926639394		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.20050137926639394 | validation: 0.18480700402549624]
	TIME [epoch: 9.06 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16300118177745757		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.16300118177745757 | validation: 0.21200326644682338]
	TIME [epoch: 9.06 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1333582980371332		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.1333582980371332 | validation: 0.10542842204807132]
	TIME [epoch: 9.06 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12403389228471837		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.12403389228471837 | validation: 0.17940675085275204]
	TIME [epoch: 9.09 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22487100144993216		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.22487100144993216 | validation: 0.6557868079687514]
	TIME [epoch: 9.07 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2317094974829211		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.2317094974829211 | validation: 0.5431757593909083]
	TIME [epoch: 9.05 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23699050615129513		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.23699050615129513 | validation: 0.1215963510277116]
	TIME [epoch: 9.05 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484715135210265		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.1484715135210265 | validation: 0.2806379015624736]
	TIME [epoch: 9.07 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19540583812062645		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.19540583812062645 | validation: 0.13473688956240196]
	TIME [epoch: 9.09 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17798442193733321		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.17798442193733321 | validation: 0.20872259801393706]
	TIME [epoch: 9.07 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1948603093265954		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.1948603093265954 | validation: 0.18865042302649876]
	TIME [epoch: 9.06 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2014334951509365		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.2014334951509365 | validation: 0.16565397040167462]
	TIME [epoch: 9.05 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1924521466014227		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.1924521466014227 | validation: 0.13615891072631892]
	TIME [epoch: 9.06 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16961029803645059		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.16961029803645059 | validation: 0.12303701678514704]
	TIME [epoch: 9.06 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13734097506751985		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.13734097506751985 | validation: 0.11570954724567128]
	TIME [epoch: 9.07 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18535243165187823		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.18535243165187823 | validation: 0.25369039082993133]
	TIME [epoch: 9.06 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26536955564997655		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.26536955564997655 | validation: 0.13255177215530062]
	TIME [epoch: 9.07 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16003975040061347		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.16003975040061347 | validation: 0.2549296779833866]
	TIME [epoch: 9.09 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1518284184133329		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.1518284184133329 | validation: 0.15548492850867035]
	TIME [epoch: 9.07 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13182582426047382		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.13182582426047382 | validation: 0.08104425666048386]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_375.pth
	Model improved!!!
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14915460092758853		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.14915460092758853 | validation: 0.23409819938056972]
	TIME [epoch: 9.07 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15406215045861776		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.15406215045861776 | validation: 0.1892442454478301]
	TIME [epoch: 9.06 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12591310598262073		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.12591310598262073 | validation: 0.14128523565129153]
	TIME [epoch: 9.07 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18927544306669453		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.18927544306669453 | validation: 0.15972265795985635]
	TIME [epoch: 9.05 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17366986433703407		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.17366986433703407 | validation: 0.16504431439331918]
	TIME [epoch: 9.06 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750039319436249		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.18750039319436249 | validation: 0.35498619490906264]
	TIME [epoch: 9.06 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17824313156011268		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.17824313156011268 | validation: 0.09447020649584686]
	TIME [epoch: 9.05 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1517624384580643		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.1517624384580643 | validation: 0.15816799100657053]
	TIME [epoch: 9.06 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1606355902424068		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.1606355902424068 | validation: 0.12717363634939588]
	TIME [epoch: 9.06 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1603402404967895		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.1603402404967895 | validation: 0.10405044760496068]
	TIME [epoch: 9.06 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12197690743454011		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.12197690743454011 | validation: 0.16698747046564355]
	TIME [epoch: 9.06 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24877285221721107		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.24877285221721107 | validation: 0.20223953125696287]
	TIME [epoch: 9.08 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12510696483161218		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.12510696483161218 | validation: 0.11508269903051456]
	TIME [epoch: 9.05 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13043980490499923		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.13043980490499923 | validation: 0.19591639055989268]
	TIME [epoch: 9.05 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1396992809685977		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.1396992809685977 | validation: 0.254330850766547]
	TIME [epoch: 9.05 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1702752829705028		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.1702752829705028 | validation: 0.14072337428046347]
	TIME [epoch: 9.06 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12831390703180562		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.12831390703180562 | validation: 0.09787701450362568]
	TIME [epoch: 9.08 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14811744980206304		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.14811744980206304 | validation: 0.14152890587713168]
	TIME [epoch: 9.05 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14166631213227937		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.14166631213227937 | validation: 0.12841232182245724]
	TIME [epoch: 9.05 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335529109691201		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.1335529109691201 | validation: 0.10873577749241235]
	TIME [epoch: 9.04 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18347471653026254		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.18347471653026254 | validation: 0.20361282890581228]
	TIME [epoch: 9.07 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302053881757155		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.1302053881757155 | validation: 0.10401100646278548]
	TIME [epoch: 9.06 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16945647012908446		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.16945647012908446 | validation: 0.15641043493209367]
	TIME [epoch: 9.07 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13128018083038445		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.13128018083038445 | validation: 0.14943916678357175]
	TIME [epoch: 9.05 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14099301655003366		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.14099301655003366 | validation: 0.07761771224860495]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_400.pth
	Model improved!!!
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18061073894327834		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.18061073894327834 | validation: 0.22056964991699485]
	TIME [epoch: 9.09 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1261732453731361		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.1261732453731361 | validation: 0.10782623627450509]
	TIME [epoch: 9.04 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14054635281778466		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.14054635281778466 | validation: 0.17810763639950697]
	TIME [epoch: 9.05 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16567670752515695		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.16567670752515695 | validation: 0.07826673639302753]
	TIME [epoch: 9.05 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10080398125525376		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.10080398125525376 | validation: 0.15299582174908757]
	TIME [epoch: 9.05 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1459620764939775		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.1459620764939775 | validation: 0.11675361465478393]
	TIME [epoch: 9.07 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13536497962599128		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.13536497962599128 | validation: 0.08688892990782357]
	TIME [epoch: 9.05 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10791709424795662		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.10791709424795662 | validation: 0.09874785074396751]
	TIME [epoch: 9.05 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12597367295677178		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.12597367295677178 | validation: 0.10454947376075092]
	TIME [epoch: 9.04 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16400662992604315		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.16400662992604315 | validation: 0.15610415149374376]
	TIME [epoch: 9.05 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12901897490507935		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.12901897490507935 | validation: 0.19305831069358378]
	TIME [epoch: 9.07 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17410452066567653		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.17410452066567653 | validation: 0.13307548661288288]
	TIME [epoch: 9.05 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17258254586798624		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.17258254586798624 | validation: 0.1565960595508583]
	TIME [epoch: 9.05 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1324889307600995		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.1324889307600995 | validation: 0.22883334486918527]
	TIME [epoch: 9.04 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10539874814236108		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.10539874814236108 | validation: 0.12257408917981003]
	TIME [epoch: 9.06 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12009384764618156		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.12009384764618156 | validation: 0.15226990981365293]
	TIME [epoch: 9.05 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09851695564157882		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.09851695564157882 | validation: 0.12515492980577253]
	TIME [epoch: 9.03 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11457350291562866		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.11457350291562866 | validation: 0.09495786868158451]
	TIME [epoch: 9.04 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14780232997410933		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.14780232997410933 | validation: 0.11619753894916539]
	TIME [epoch: 9.05 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09469469205747852		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.09469469205747852 | validation: 0.07608823008391799]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_420.pth
	Model improved!!!
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13902518684747894		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.13902518684747894 | validation: 0.09231806253761113]
	TIME [epoch: 9.06 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09723727064451264		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.09723727064451264 | validation: 0.1253875078467282]
	TIME [epoch: 9.06 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14525324530932499		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.14525324530932499 | validation: 0.10689731183445872]
	TIME [epoch: 9.06 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18365647944102315		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.18365647944102315 | validation: 0.09149976457566647]
	TIME [epoch: 9.08 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14110243832321828		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.14110243832321828 | validation: 0.11245020237802089]
	TIME [epoch: 9.05 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15232834893048458		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.15232834893048458 | validation: 0.21443098816988326]
	TIME [epoch: 9.06 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12175893427013476		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.12175893427013476 | validation: 0.11915732185678216]
	TIME [epoch: 9.04 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11222723388479176		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.11222723388479176 | validation: 0.10738490315246713]
	TIME [epoch: 9.05 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13527426024140027		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.13527426024140027 | validation: 0.14677617425779418]
	TIME [epoch: 9.07 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1664628690295791		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.1664628690295791 | validation: 0.07631051900238658]
	TIME [epoch: 9.06 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10680437655780103		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.10680437655780103 | validation: 0.07396506541116121]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_431.pth
	Model improved!!!
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.127476358729033		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.127476358729033 | validation: 0.12612654770294865]
	TIME [epoch: 9.05 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14371373003857738		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.14371373003857738 | validation: 0.08981925648044999]
	TIME [epoch: 9.04 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0913394596480011		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.0913394596480011 | validation: 0.09120043952124143]
	TIME [epoch: 9.07 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12391754845538092		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.12391754845538092 | validation: 0.1475448880488215]
	TIME [epoch: 9.03 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14462422668950986		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.14462422668950986 | validation: 0.1262611678342645]
	TIME [epoch: 9.04 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09016585704791819		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.09016585704791819 | validation: 0.08385973988729115]
	TIME [epoch: 9.04 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0926664038922834		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.0926664038922834 | validation: 0.07805573694495146]
	TIME [epoch: 9.05 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11128320586821865		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.11128320586821865 | validation: 0.2828213574394878]
	TIME [epoch: 9.07 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15096704734807043		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.15096704734807043 | validation: 0.11219300777533991]
	TIME [epoch: 9.04 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.148699812391888		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.148699812391888 | validation: 0.1634849427382899]
	TIME [epoch: 9.05 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1505741001747329		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.1505741001747329 | validation: 0.1834721903989746]
	TIME [epoch: 9.04 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1295782836480937		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.1295782836480937 | validation: 0.09804172279324787]
	TIME [epoch: 9.04 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15765349268042828		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.15765349268042828 | validation: 0.10753436104315918]
	TIME [epoch: 9.07 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09992767360152514		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.09992767360152514 | validation: 0.06948039928024832]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_445.pth
	Model improved!!!
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1125336726404053		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.1125336726404053 | validation: 0.20149251841733928]
	TIME [epoch: 9.05 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13585563655014105		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.13585563655014105 | validation: 0.08033517203484183]
	TIME [epoch: 9.04 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10255255319660088		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.10255255319660088 | validation: 0.14369378257550192]
	TIME [epoch: 9.05 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.161956800668543		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.161956800668543 | validation: 0.14546346556471476]
	TIME [epoch: 9.06 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10977797285390949		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.10977797285390949 | validation: 0.0963934463991139]
	TIME [epoch: 9.05 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09834433465582096		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.09834433465582096 | validation: 0.0930421170567294]
	TIME [epoch: 9.06 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12736965015522972		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.12736965015522972 | validation: 0.09400219669269128]
	TIME [epoch: 9.05 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10793454035684313		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.10793454035684313 | validation: 0.08470093290946888]
	TIME [epoch: 9.05 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11506574828740386		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.11506574828740386 | validation: 0.12855578424000097]
	TIME [epoch: 9.06 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.102259709489456		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.102259709489456 | validation: 0.16504920238669812]
	TIME [epoch: 9.03 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12780468039988402		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.12780468039988402 | validation: 0.13575682540246092]
	TIME [epoch: 9.04 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16972618345396545		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.16972618345396545 | validation: 0.19921379158054428]
	TIME [epoch: 9.06 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1500825042884767		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.1500825042884767 | validation: 0.1802635570214774]
	TIME [epoch: 9.04 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1024455366478988		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.1024455366478988 | validation: 0.14649394851566322]
	TIME [epoch: 9.07 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14580930774388018		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.14580930774388018 | validation: 0.10985814028440508]
	TIME [epoch: 9.04 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11073250189632884		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.11073250189632884 | validation: 0.07318800923475348]
	TIME [epoch: 9.03 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10167840256216669		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.10167840256216669 | validation: 0.18499347151468948]
	TIME [epoch: 9.04 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11497958689320376		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.11497958689320376 | validation: 0.0835897794270873]
	TIME [epoch: 9.06 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10176232517664985		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.10176232517664985 | validation: 0.10400264166032488]
	TIME [epoch: 9.04 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10535827510433922		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.10535827510433922 | validation: 0.10119595277569651]
	TIME [epoch: 9.04 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10404009762675193		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.10404009762675193 | validation: 0.08445573687161917]
	TIME [epoch: 9.05 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09062018373649125		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.09062018373649125 | validation: 0.10869655951633365]
	TIME [epoch: 9.06 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11169493191721654		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.11169493191721654 | validation: 0.10716209503785339]
	TIME [epoch: 9.06 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10470454622566772		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.10470454622566772 | validation: 0.08923284061872083]
	TIME [epoch: 9.05 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14402485476019838		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.14402485476019838 | validation: 0.15286630643984883]
	TIME [epoch: 9.06 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1579036211683776		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.1579036211683776 | validation: 0.06887053776492849]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_471.pth
	Model improved!!!
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09092773291682894		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.09092773291682894 | validation: 0.14664976043907585]
	TIME [epoch: 9.08 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1145597905120019		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.1145597905120019 | validation: 0.13876966500957766]
	TIME [epoch: 9.06 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136433845590896		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.1136433845590896 | validation: 0.16557813973635632]
	TIME [epoch: 9.05 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10280334661747345		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.10280334661747345 | validation: 0.10003104044546526]
	TIME [epoch: 9.05 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12460882191060663		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.12460882191060663 | validation: 0.12407868075169382]
	TIME [epoch: 9.08 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12321461695554015		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.12321461695554015 | validation: 0.1312557658153826]
	TIME [epoch: 9.08 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09681128290170099		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.09681128290170099 | validation: 0.1230611156046664]
	TIME [epoch: 9.05 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08867290950870302		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.08867290950870302 | validation: 0.09159179929290799]
	TIME [epoch: 9.05 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08272434275427988		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.08272434275427988 | validation: 0.10607387787629483]
	TIME [epoch: 9.04 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11131099194755131		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.11131099194755131 | validation: 0.08648847878265695]
	TIME [epoch: 9.03 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11353822708195578		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.11353822708195578 | validation: 0.08386161636487349]
	TIME [epoch: 9.07 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11182477794113854		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.11182477794113854 | validation: 0.09906309435805583]
	TIME [epoch: 9.06 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10402774584684997		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.10402774584684997 | validation: 0.08832667302965513]
	TIME [epoch: 9.04 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10137444813325514		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.10137444813325514 | validation: 0.15363002678606583]
	TIME [epoch: 9.05 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13544927920778876		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.13544927920778876 | validation: 0.06521690641076258]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_486.pth
	Model improved!!!
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0993793820895121		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.0993793820895121 | validation: 0.08357235821945094]
	TIME [epoch: 9.07 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10760934551791808		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.10760934551791808 | validation: 0.07006394325157171]
	TIME [epoch: 9.05 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1258034028238308		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.1258034028238308 | validation: 0.13292486793573643]
	TIME [epoch: 9.04 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0960281441602988		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.0960281441602988 | validation: 0.09365926038560443]
	TIME [epoch: 9.05 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11404470594794472		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.11404470594794472 | validation: 0.10822326615073007]
	TIME [epoch: 9.04 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09656428408426855		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.09656428408426855 | validation: 0.13844959602041446]
	TIME [epoch: 9.05 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12903471905555677		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.12903471905555677 | validation: 0.14968645015234985]
	TIME [epoch: 9.06 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12419564161663424		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.12419564161663424 | validation: 0.08345023212916611]
	TIME [epoch: 9.04 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07806819658369746		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.07806819658369746 | validation: 0.10011632917513928]
	TIME [epoch: 9.04 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1804528814564761		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.1804528814564761 | validation: 0.17373066452560754]
	TIME [epoch: 9.03 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09661542807691668		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.09661542807691668 | validation: 0.07551355873593114]
	TIME [epoch: 9.04 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09953550521066976		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.09953550521066976 | validation: 0.12111180105940314]
	TIME [epoch: 9.06 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10297102392184801		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.10297102392184801 | validation: 0.07570614361137341]
	TIME [epoch: 9.04 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11286896877231019		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.11286896877231019 | validation: 0.0779492746216078]
	TIME [epoch: 9.05 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11306109318664759		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.11306109318664759 | validation: 0.11379397415583206]
	TIME [epoch: 9.03 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08933530090661805		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.08933530090661805 | validation: 0.07259496814713862]
	TIME [epoch: 9.04 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07594964700213197		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.07594964700213197 | validation: 0.1427675185110817]
	TIME [epoch: 9.06 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1430290239021266		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.1430290239021266 | validation: 0.21232369970595077]
	TIME [epoch: 9.04 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11442732257603871		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.11442732257603871 | validation: 0.07158438766429424]
	TIME [epoch: 9.05 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10378133375745577		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.10378133375745577 | validation: 0.08781117555837721]
	TIME [epoch: 9.04 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08190156228316611		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.08190156228316611 | validation: 0.1186291149158176]
	TIME [epoch: 9.04 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08669404909934134		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.08669404909934134 | validation: 0.10796813841306205]
	TIME [epoch: 9.06 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875696488586702		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.07875696488586702 | validation: 0.07903361601431527]
	TIME [epoch: 9.04 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07975878384455358		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.07975878384455358 | validation: 0.06393248250269883]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_510.pth
	Model improved!!!
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10735951796427379		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.10735951796427379 | validation: 0.24745820243062272]
	TIME [epoch: 9.06 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12813005046278858		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.12813005046278858 | validation: 0.06663435354655195]
	TIME [epoch: 9.07 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10564617413051491		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.10564617413051491 | validation: 0.11129055135091745]
	TIME [epoch: 9.08 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09168643362483513		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.09168643362483513 | validation: 0.1345675675950643]
	TIME [epoch: 9.05 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09687186024960039		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.09687186024960039 | validation: 0.08440220154186182]
	TIME [epoch: 9.06 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09296193530587189		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.09296193530587189 | validation: 0.15946623276980434]
	TIME [epoch: 9.06 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10556011087200708		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.10556011087200708 | validation: 0.09538827961764626]
	TIME [epoch: 9.07 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09644356036160381		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.09644356036160381 | validation: 0.07379896865837567]
	TIME [epoch: 9.09 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0804536742023482		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.0804536742023482 | validation: 0.07687726688930588]
	TIME [epoch: 9.06 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0922917399680819		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.0922917399680819 | validation: 0.12449388052787244]
	TIME [epoch: 9.05 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09583289660220135		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.09583289660220135 | validation: 0.06721851775332247]
	TIME [epoch: 9.04 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06688410330960333		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.06688410330960333 | validation: 0.06573855313851275]
	TIME [epoch: 9.06 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0784212184035521		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.0784212184035521 | validation: 0.10821015928602018]
	TIME [epoch: 9.09 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940252173307278		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.0940252173307278 | validation: 0.07338223107991274]
	TIME [epoch: 9.06 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0907794707438497		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.0907794707438497 | validation: 0.08775170291906537]
	TIME [epoch: 9.06 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08302952008029828		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.08302952008029828 | validation: 0.16336932824345557]
	TIME [epoch: 9.06 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15419701855633908		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.15419701855633908 | validation: 0.17446948211592334]
	TIME [epoch: 9.05 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13436573331191687		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.13436573331191687 | validation: 0.09643922328054111]
	TIME [epoch: 9.08 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09521958352607818		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.09521958352607818 | validation: 0.08496169291248602]
	TIME [epoch: 9.06 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0999762862455138		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.0999762862455138 | validation: 0.11396850307467829]
	TIME [epoch: 9.06 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07897681970310497		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.07897681970310497 | validation: 0.09437807094809947]
	TIME [epoch: 9.06 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07061555059551682		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.07061555059551682 | validation: 0.07322022333153985]
	TIME [epoch: 9.06 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07887056039364301		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.07887056039364301 | validation: 0.09240232516610841]
	TIME [epoch: 9.07 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07400361702489713		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.07400361702489713 | validation: 0.07961406228069806]
	TIME [epoch: 9.05 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06318958743772192		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.06318958743772192 | validation: 0.07234255978933267]
	TIME [epoch: 9.05 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08460197509126746		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.08460197509126746 | validation: 0.11559412656046239]
	TIME [epoch: 9.05 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10148298012455981		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.10148298012455981 | validation: 0.15737507044554802]
	TIME [epoch: 9.05 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08205525429219475		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.08205525429219475 | validation: 0.10887339666120638]
	TIME [epoch: 9.08 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07783481306094127		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.07783481306094127 | validation: 0.06409728825825861]
	TIME [epoch: 9.05 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07061507604763387		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.07061507604763387 | validation: 0.10971696237982753]
	TIME [epoch: 9.05 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08069614473930796		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.08069614473930796 | validation: 0.10634084523247254]
	TIME [epoch: 9.05 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09599462847647622		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.09599462847647622 | validation: 0.0721588695376643]
	TIME [epoch: 9.05 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08070963027250597		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.08070963027250597 | validation: 0.08281296337174002]
	TIME [epoch: 9.08 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10346901777225777		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.10346901777225777 | validation: 0.07051028099979449]
	TIME [epoch: 9.06 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09283677263332799		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.09283677263332799 | validation: 0.08652772815524398]
	TIME [epoch: 9.07 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09167284976625086		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.09167284976625086 | validation: 0.08658218391105292]
	TIME [epoch: 9.06 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12359302361711304		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.12359302361711304 | validation: 0.19719349565584549]
	TIME [epoch: 9.05 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08817133871161131		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.08817133871161131 | validation: 0.06708051914926745]
	TIME [epoch: 9.08 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08514858243833053		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.08514858243833053 | validation: 0.06958439656093056]
	TIME [epoch: 9.06 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0814965231804197		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.0814965231804197 | validation: 0.11304728254017705]
	TIME [epoch: 9.06 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09835129709498246		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.09835129709498246 | validation: 0.07517195948070293]
	TIME [epoch: 9.06 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07917837215040938		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.07917837215040938 | validation: 0.07045840604023375]
	TIME [epoch: 9.06 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11159149274720995		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.11159149274720995 | validation: 0.05517095229845568]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_553.pth
	Model improved!!!
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08476987503696043		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.08476987503696043 | validation: 0.05184091207084284]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_554.pth
	Model improved!!!
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09185693724852924		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.09185693724852924 | validation: 0.09592139508032538]
	TIME [epoch: 9.07 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10454928133984054		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.10454928133984054 | validation: 0.10398207151605082]
	TIME [epoch: 9.07 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08330730462754868		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.08330730462754868 | validation: 0.0856951039945367]
	TIME [epoch: 9.06 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07257851099993907		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.07257851099993907 | validation: 0.11767565034949329]
	TIME [epoch: 9.07 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09741377841385437		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.09741377841385437 | validation: 0.14713052792937642]
	TIME [epoch: 9.08 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1062514487578878		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.1062514487578878 | validation: 0.12801957123769545]
	TIME [epoch: 9.05 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09659148236930995		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.09659148236930995 | validation: 0.07396502701818417]
	TIME [epoch: 9.06 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06867792183026264		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.06867792183026264 | validation: 0.12474704325525773]
	TIME [epoch: 9.06 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0698989026584059		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.0698989026584059 | validation: 0.07612705259614308]
	TIME [epoch: 9.06 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695155393239612		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.0695155393239612 | validation: 0.07487660517106956]
	TIME [epoch: 9.08 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09389984127518633		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.09389984127518633 | validation: 0.10011570840482373]
	TIME [epoch: 9.06 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07179198502933996		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.07179198502933996 | validation: 0.09049606560924453]
	TIME [epoch: 9.05 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0796500695711141		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.0796500695711141 | validation: 0.08212929166480455]
	TIME [epoch: 9.05 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10100111790956405		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.10100111790956405 | validation: 0.11390981823941876]
	TIME [epoch: 9.05 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08413835342349935		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.08413835342349935 | validation: 0.0837461628286175]
	TIME [epoch: 9.08 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10033394458666059		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.10033394458666059 | validation: 0.07738948765137345]
	TIME [epoch: 9.06 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0917008325638484		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.0917008325638484 | validation: 0.06504394768302714]
	TIME [epoch: 9.07 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10452814905533236		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.10452814905533236 | validation: 0.12447778198551479]
	TIME [epoch: 9.05 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08315245369827495		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.08315245369827495 | validation: 0.1153350896743025]
	TIME [epoch: 9.05 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0848877532498026		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.0848877532498026 | validation: 0.07933181903771228]
	TIME [epoch: 9.07 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10284235990990429		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.10284235990990429 | validation: 0.1569862106730755]
	TIME [epoch: 9.05 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08799086160131056		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.08799086160131056 | validation: 0.099779099735614]
	TIME [epoch: 9.05 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08570509781409591		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.08570509781409591 | validation: 0.07410395702993146]
	TIME [epoch: 9.05 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0939144972652025		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.0939144972652025 | validation: 0.15407034781420287]
	TIME [epoch: 9.05 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10705576718918883		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.10705576718918883 | validation: 0.08733293680047716]
	TIME [epoch: 9.08 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06469236032628606		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.06469236032628606 | validation: 0.05517787766151094]
	TIME [epoch: 9.05 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07461340957114052		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.07461340957114052 | validation: 0.07484875073233155]
	TIME [epoch: 9.05 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07390362994029794		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.07390362994029794 | validation: 0.09067890802731599]
	TIME [epoch: 9.06 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14745841725344278		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.14745841725344278 | validation: 0.05739967936180517]
	TIME [epoch: 9.06 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07513341572589019		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.07513341572589019 | validation: 0.06091254125021173]
	TIME [epoch: 9.09 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07952796972362994		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.07952796972362994 | validation: 0.06280118758745673]
	TIME [epoch: 9.07 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10502755634125867		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.10502755634125867 | validation: 0.13032912295237875]
	TIME [epoch: 9.05 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225704564896448		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.11225704564896448 | validation: 0.06125036521504679]
	TIME [epoch: 9.05 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0753708850344018		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.0753708850344018 | validation: 0.07337103341745763]
	TIME [epoch: 9.05 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0610757235625463		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.0610757235625463 | validation: 0.07653267628538282]
	TIME [epoch: 9.08 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08377978701455306		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.08377978701455306 | validation: 0.07199644602784101]
	TIME [epoch: 9.06 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07630232576126558		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.07630232576126558 | validation: 0.07510577105190724]
	TIME [epoch: 9.05 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0636479038070918		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.0636479038070918 | validation: 0.06946071350813046]
	TIME [epoch: 9.05 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0690716070312503		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.0690716070312503 | validation: 0.10283890836235693]
	TIME [epoch: 9.04 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08022602298016578		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.08022602298016578 | validation: 0.05794959161486692]
	TIME [epoch: 9.06 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06981982523114419		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.06981982523114419 | validation: 0.07965602101380584]
	TIME [epoch: 9.06 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06802668421340688		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.06802668421340688 | validation: 0.06888464470360556]
	TIME [epoch: 9.07 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07934908436699256		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.07934908436699256 | validation: 0.08122769403601751]
	TIME [epoch: 9.07 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0793577518315373		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.0793577518315373 | validation: 0.06974081069668554]
	TIME [epoch: 9.08 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11505458074451802		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.11505458074451802 | validation: 0.06459928607186104]
	TIME [epoch: 9.09 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054143101716018		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.07054143101716018 | validation: 0.10372169641439952]
	TIME [epoch: 9.06 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08984297253614558		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.08984297253614558 | validation: 0.06996813753559362]
	TIME [epoch: 9.06 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10515300009563015		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.10515300009563015 | validation: 0.11536196192047696]
	TIME [epoch: 9.06 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0795605938812278		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.0795605938812278 | validation: 0.08095908581944211]
	TIME [epoch: 9.06 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08713154473698234		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.08713154473698234 | validation: 0.06400435168385904]
	TIME [epoch: 9.09 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07695581043963232		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.07695581043963232 | validation: 0.08203049956319197]
	TIME [epoch: 9.06 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09668972590095282		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.09668972590095282 | validation: 0.0603810454334874]
	TIME [epoch: 9.07 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07737267642561013		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.07737267642561013 | validation: 0.0801301967391301]
	TIME [epoch: 9.06 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08939471194376827		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.08939471194376827 | validation: 0.11623538413013132]
	TIME [epoch: 9.06 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07953104411254527		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.07953104411254527 | validation: 0.06429518276951188]
	TIME [epoch: 9.1 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07348722103890284		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.07348722103890284 | validation: 0.06071899681308112]
	TIME [epoch: 9.07 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05591943355030928		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.05591943355030928 | validation: 0.06774077635542507]
	TIME [epoch: 9.06 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358102246893874		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.06358102246893874 | validation: 0.0682636764005729]
	TIME [epoch: 9.06 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06618189252507009		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.06618189252507009 | validation: 0.05953308178128733]
	TIME [epoch: 9.05 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06620964742126054		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.06620964742126054 | validation: 0.06974562950408822]
	TIME [epoch: 9.08 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07505085789808212		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.07505085789808212 | validation: 0.07626584113397902]
	TIME [epoch: 9.05 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07620961132771017		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.07620961132771017 | validation: 0.07304941800939876]
	TIME [epoch: 9.05 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08372418391332972		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.08372418391332972 | validation: 0.07460569437774653]
	TIME [epoch: 9.05 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705717327945846		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.0705717327945846 | validation: 0.06969717109844595]
	TIME [epoch: 9.05 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07148896151008721		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.07148896151008721 | validation: 0.08972115132042516]
	TIME [epoch: 9.07 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07403107134619305		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.07403107134619305 | validation: 0.08660762325757827]
	TIME [epoch: 9.04 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1066925603816403		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.1066925603816403 | validation: 0.16775328825577682]
	TIME [epoch: 9.05 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09569985880505853		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.09569985880505853 | validation: 0.0794116409262962]
	TIME [epoch: 9.06 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08712959652105778		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.08712959652105778 | validation: 0.08532503812786077]
	TIME [epoch: 9.06 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06812077542337319		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.06812077542337319 | validation: 0.06341930767397944]
	TIME [epoch: 9.09 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05907625487531013		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.05907625487531013 | validation: 0.051568074273357904]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_625.pth
	Model improved!!!
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06721309660959149		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.06721309660959149 | validation: 0.08942345524841637]
	TIME [epoch: 9.05 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07756767332737044		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.07756767332737044 | validation: 0.07967720752995855]
	TIME [epoch: 9.06 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06403810617173786		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.06403810617173786 | validation: 0.05331763081753707]
	TIME [epoch: 9.04 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07299498555321002		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.07299498555321002 | validation: 0.07771519235240334]
	TIME [epoch: 9.08 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10764290909493619		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.10764290909493619 | validation: 0.10854691181668866]
	TIME [epoch: 9.06 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10214423684380125		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.10214423684380125 | validation: 0.08459005604974877]
	TIME [epoch: 9.06 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0677036390650501		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.0677036390650501 | validation: 0.09929539779887028]
	TIME [epoch: 9.05 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10668687865903578		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.10668687865903578 | validation: 0.13262249320954098]
	TIME [epoch: 9.04 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08550960475810614		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.08550960475810614 | validation: 0.15370120983425878]
	TIME [epoch: 9.06 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08873547040435505		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.08873547040435505 | validation: 0.05704796929725682]
	TIME [epoch: 9.07 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07022687133732199		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.07022687133732199 | validation: 0.05873013414870219]
	TIME [epoch: 9.06 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06320318233768628		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.06320318233768628 | validation: 0.0758011767583733]
	TIME [epoch: 9.06 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05526497109106937		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.05526497109106937 | validation: 0.07492611268259734]
	TIME [epoch: 9.05 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056244268761938034		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.056244268761938034 | validation: 0.05118459681277905]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_639.pth
	Model improved!!!
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844775131664838		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.06844775131664838 | validation: 0.08391784885604668]
	TIME [epoch: 9.06 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05884224191652977		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.05884224191652977 | validation: 0.0659295985576064]
	TIME [epoch: 9.04 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08457041740763183		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.08457041740763183 | validation: 0.13262200849904343]
	TIME [epoch: 9.04 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07988846266950492		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.07988846266950492 | validation: 0.05966623927602603]
	TIME [epoch: 9.04 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053593789460101494		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.053593789460101494 | validation: 0.07884760428550536]
	TIME [epoch: 9.05 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06369472618549235		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.06369472618549235 | validation: 0.08351501021485006]
	TIME [epoch: 9.07 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07825438145554439		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.07825438145554439 | validation: 0.07179063845547218]
	TIME [epoch: 9.04 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07744118811773101		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.07744118811773101 | validation: 0.06957463747034587]
	TIME [epoch: 9.04 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05979035503807626		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.05979035503807626 | validation: 0.05849008094950473]
	TIME [epoch: 9.05 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.055640604489880806		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.055640604489880806 | validation: 0.06002670808388046]
	TIME [epoch: 9.05 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643568197831172		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.06643568197831172 | validation: 0.0859100584381833]
	TIME [epoch: 9.07 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07410318683178782		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.07410318683178782 | validation: 0.06521208186956484]
	TIME [epoch: 9.05 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07302501174802586		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.07302501174802586 | validation: 0.05153547409456979]
	TIME [epoch: 9.04 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541638950425804		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.0541638950425804 | validation: 0.06646200513819345]
	TIME [epoch: 9.05 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06795079038993845		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.06795079038993845 | validation: 0.08036551521488224]
	TIME [epoch: 9.05 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07332347735695713		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.07332347735695713 | validation: 0.06621274879775411]
	TIME [epoch: 9.08 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07617550766647219		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.07617550766647219 | validation: 0.07571287868046941]
	TIME [epoch: 9.05 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07445886508770506		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.07445886508770506 | validation: 0.07892277384088]
	TIME [epoch: 9.05 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05263567732938097		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.05263567732938097 | validation: 0.058887284604686355]
	TIME [epoch: 9.04 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05954623848419931		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.05954623848419931 | validation: 0.07015702152897177]
	TIME [epoch: 9.04 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060479504207943804		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.060479504207943804 | validation: 0.05098701140911317]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_660.pth
	Model improved!!!
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06151266365038614		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.06151266365038614 | validation: 0.07946771958753208]
	TIME [epoch: 9.05 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.071664035240555		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.071664035240555 | validation: 0.07969263116467412]
	TIME [epoch: 9.05 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07783396661137336		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.07783396661137336 | validation: 0.07633038242767251]
	TIME [epoch: 9.05 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06007490670100655		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.06007490670100655 | validation: 0.05734909376118779]
	TIME [epoch: 9.04 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0514036443677504		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.0514036443677504 | validation: 0.06526386120874172]
	TIME [epoch: 9.06 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05075958551573946		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.05075958551573946 | validation: 0.06365239422694516]
	TIME [epoch: 9.05 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05780297316272537		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.05780297316272537 | validation: 0.07921794998505141]
	TIME [epoch: 9.04 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615015622127843		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.06615015622127843 | validation: 0.07277308305658796]
	TIME [epoch: 9.05 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05846513376082293		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.05846513376082293 | validation: 0.07995563545846468]
	TIME [epoch: 9.05 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07306025607556824		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.07306025607556824 | validation: 0.05509045926088732]
	TIME [epoch: 9.06 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05275443838987661		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.05275443838987661 | validation: 0.07132606009404577]
	TIME [epoch: 9.05 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06154270810379259		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.06154270810379259 | validation: 0.06660268616675452]
	TIME [epoch: 9.04 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052982753912023485		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.052982753912023485 | validation: 0.08160916751705902]
	TIME [epoch: 9.04 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07957907624309385		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.07957907624309385 | validation: 0.0895107279313545]
	TIME [epoch: 9.04 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08233444250575919		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.08233444250575919 | validation: 0.051678715098666096]
	TIME [epoch: 9.06 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07254937516087108		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.07254937516087108 | validation: 0.08937471530347897]
	TIME [epoch: 9.06 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060563181955530475		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.060563181955530475 | validation: 0.07389012203714311]
	TIME [epoch: 9.05 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0677987910664841		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.0677987910664841 | validation: 0.06442551262140365]
	TIME [epoch: 9.04 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0527940339262037		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.0527940339262037 | validation: 0.06588526143825252]
	TIME [epoch: 9.04 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0601490584854235		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.0601490584854235 | validation: 0.058784040280468464]
	TIME [epoch: 9.05 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053951974277818546		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.053951974277818546 | validation: 0.11225467549967308]
	TIME [epoch: 9.06 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06465719964110331		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.06465719964110331 | validation: 0.055013636929954965]
	TIME [epoch: 9.05 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0493513699456217		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.0493513699456217 | validation: 0.06473047246467808]
	TIME [epoch: 9.04 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061076669944658504		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.061076669944658504 | validation: 0.05474723158582315]
	TIME [epoch: 9.05 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467849911790613		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.06467849911790613 | validation: 0.05171809408789904]
	TIME [epoch: 9.05 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07356477987667366		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.07356477987667366 | validation: 0.1425013815885124]
	TIME [epoch: 9.06 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07670691166696741		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.07670691166696741 | validation: 0.06496176266203196]
	TIME [epoch: 9.05 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07370298629837607		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.07370298629837607 | validation: 0.09222230417234176]
	TIME [epoch: 9.06 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08087231809565938		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.08087231809565938 | validation: 0.0691434668612953]
	TIME [epoch: 9.05 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05568115063284958		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.05568115063284958 | validation: 0.0967407694566488]
	TIME [epoch: 9.06 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07019771525178782		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.07019771525178782 | validation: 0.09626312753103725]
	TIME [epoch: 9.07 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06484658025792348		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.06484658025792348 | validation: 0.04865378447498098]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_692.pth
	Model improved!!!
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061244073666929064		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.061244073666929064 | validation: 0.05868346551132396]
	TIME [epoch: 9.04 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05854130742915453		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.05854130742915453 | validation: 0.08505183453318507]
	TIME [epoch: 9.03 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06158109465386853		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.06158109465386853 | validation: 0.10294147769875377]
	TIME [epoch: 9.04 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06748873882616499		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.06748873882616499 | validation: 0.06543389802739596]
	TIME [epoch: 9.05 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05856623925006792		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.05856623925006792 | validation: 0.08081948444296973]
	TIME [epoch: 9.03 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05433088821500374		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.05433088821500374 | validation: 0.05363051531927492]
	TIME [epoch: 9.04 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0633058348888397		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.0633058348888397 | validation: 0.07293447365449017]
	TIME [epoch: 9.04 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05695375916083824		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.05695375916083824 | validation: 0.07550234731388746]
	TIME [epoch: 9.04 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05598451192746494		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.05598451192746494 | validation: 0.07489801299370923]
	TIME [epoch: 9.08 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06774442772425933		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.06774442772425933 | validation: 0.05668970886685148]
	TIME [epoch: 9.05 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05656751875757841		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.05656751875757841 | validation: 0.055857040482395814]
	TIME [epoch: 9.04 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04850567548854399		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.04850567548854399 | validation: 0.07301761232106867]
	TIME [epoch: 9.04 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05321058311958817		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.05321058311958817 | validation: 0.05535290865826621]
	TIME [epoch: 9.04 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05904783186274008		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.05904783186274008 | validation: 0.04809269783467442]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_706.pth
	Model improved!!!
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06561784585720998		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.06561784585720998 | validation: 0.08195786400583982]
	TIME [epoch: 9.04 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.057614658948717576		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.057614658948717576 | validation: 0.05473882445760807]
	TIME [epoch: 9.04 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06922481241173681		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.06922481241173681 | validation: 0.05894459102785278]
	TIME [epoch: 9.03 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05113646249095334		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.05113646249095334 | validation: 0.055786043939469024]
	TIME [epoch: 9.04 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05990248666743734		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.05990248666743734 | validation: 0.061714783760491665]
	TIME [epoch: 9.06 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05709477176019388		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.05709477176019388 | validation: 0.05148077843871649]
	TIME [epoch: 9.04 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533948615164556		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.06533948615164556 | validation: 0.06212486244268402]
	TIME [epoch: 9.04 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051376078151898895		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.051376078151898895 | validation: 0.0668988953903357]
	TIME [epoch: 9.05 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056973665193948794		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.056973665193948794 | validation: 0.05835175514884923]
	TIME [epoch: 9.06 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05683728657189313		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.05683728657189313 | validation: 0.07471568255082119]
	TIME [epoch: 9.07 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105222055913153		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.06105222055913153 | validation: 0.06591855249413747]
	TIME [epoch: 9.05 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043986637926371974		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.043986637926371974 | validation: 0.05936323035352772]
	TIME [epoch: 9.04 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05919710713968561		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.05919710713968561 | validation: 0.06246263224621082]
	TIME [epoch: 9.04 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056870724618791876		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.056870724618791876 | validation: 0.04090799754541405]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_720.pth
	Model improved!!!
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04545128751957194		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.04545128751957194 | validation: 0.062222064053586254]
	TIME [epoch: 9.06 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0588723487058602		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.0588723487058602 | validation: 0.055407497868167635]
	TIME [epoch: 9.03 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04732220044949673		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.04732220044949673 | validation: 0.06461941400018878]
	TIME [epoch: 9.04 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06559120851095876		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.06559120851095876 | validation: 0.0678151492964449]
	TIME [epoch: 9.03 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060176013439922606		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.060176013439922606 | validation: 0.047978493950994405]
	TIME [epoch: 9.03 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043419588545958274		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.043419588545958274 | validation: 0.04065120696565747]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_726.pth
	Model improved!!!
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04892017807139974		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.04892017807139974 | validation: 0.04948463394342964]
	TIME [epoch: 9.06 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04372749210474611		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.04372749210474611 | validation: 0.049108129702304125]
	TIME [epoch: 9.05 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05146977140391566		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.05146977140391566 | validation: 0.047139546369081305]
	TIME [epoch: 9.04 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06520126351876196		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.06520126351876196 | validation: 0.04496314867923487]
	TIME [epoch: 9.03 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05979962681315909		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.05979962681315909 | validation: 0.062309930053436435]
	TIME [epoch: 9.04 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05749530924450234		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.05749530924450234 | validation: 0.0666252294880485]
	TIME [epoch: 9.06 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05432456445605889		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.05432456445605889 | validation: 0.04280853060184667]
	TIME [epoch: 9.06 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047619601782962456		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.047619601782962456 | validation: 0.07279500451372933]
	TIME [epoch: 9.04 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052206820783908335		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.052206820783908335 | validation: 0.04611084051491829]
	TIME [epoch: 9.03 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06004108820293634		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.06004108820293634 | validation: 0.06298759815582938]
	TIME [epoch: 9.04 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04445430652269622		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.04445430652269622 | validation: 0.04871919137469263]
	TIME [epoch: 9.07 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05020094960575855		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.05020094960575855 | validation: 0.05557378001925546]
	TIME [epoch: 9.03 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05090760916788638		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.05090760916788638 | validation: 0.04678148995598656]
	TIME [epoch: 9.04 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052306515103203076		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.052306515103203076 | validation: 0.04821995816402169]
	TIME [epoch: 9.03 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05887075090093167		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.05887075090093167 | validation: 0.057635227351108494]
	TIME [epoch: 9.05 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05148052194364163		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.05148052194364163 | validation: 0.06624434725453202]
	TIME [epoch: 9.07 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06178142584991658		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.06178142584991658 | validation: 0.04495637466826996]
	TIME [epoch: 9.04 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048543065207297266		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.048543065207297266 | validation: 0.05039630832763499]
	TIME [epoch: 9.03 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045243433929717344		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.045243433929717344 | validation: 0.06956697827531945]
	TIME [epoch: 9.04 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05886538404097889		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.05886538404097889 | validation: 0.04950740749174018]
	TIME [epoch: 9.03 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058116069338193965		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.058116069338193965 | validation: 0.04826657130915882]
	TIME [epoch: 9.06 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04161766893743386		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.04161766893743386 | validation: 0.06131977744432907]
	TIME [epoch: 9.04 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05113380916491683		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.05113380916491683 | validation: 0.07723493004646377]
	TIME [epoch: 9.04 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.057649185254580904		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.057649185254580904 | validation: 0.06149732243064172]
	TIME [epoch: 9.03 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052787408634364964		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.052787408634364964 | validation: 0.04892455879572841]
	TIME [epoch: 9.03 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038128311855602816		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.038128311855602816 | validation: 0.05286389048804947]
	TIME [epoch: 9.05 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04686599858180265		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.04686599858180265 | validation: 0.04715616935863906]
	TIME [epoch: 9.04 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053092444384920646		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.053092444384920646 | validation: 0.05406570684127904]
	TIME [epoch: 9.04 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05545089861036813		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.05545089861036813 | validation: 0.0356749172150129]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_755.pth
	Model improved!!!
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05515182213021365		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.05515182213021365 | validation: 0.056687622827892505]
	TIME [epoch: 9.04 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04635938904822619		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.04635938904822619 | validation: 0.05541833713689605]
	TIME [epoch: 9.05 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04533000792997023		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.04533000792997023 | validation: 0.047146551670575076]
	TIME [epoch: 9.03 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05339888218498721		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.05339888218498721 | validation: 0.055083994386076876]
	TIME [epoch: 9.03 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04486765595215797		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.04486765595215797 | validation: 0.05218988370872302]
	TIME [epoch: 9.03 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04338469292824553		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.04338469292824553 | validation: 0.05174669262592799]
	TIME [epoch: 9.03 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04999039103600494		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.04999039103600494 | validation: 0.05514949055648502]
	TIME [epoch: 9.04 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05752805960015171		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.05752805960015171 | validation: 0.047240852903413996]
	TIME [epoch: 9.05 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04274703256197275		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.04274703256197275 | validation: 0.04787884400660178]
	TIME [epoch: 9.04 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04799641499378017		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.04799641499378017 | validation: 0.05485155060260105]
	TIME [epoch: 9.03 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045127590964174416		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.045127590964174416 | validation: 0.052517098300906895]
	TIME [epoch: 9.03 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05703748351503429		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.05703748351503429 | validation: 0.04573410277586264]
	TIME [epoch: 9.05 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04684025047184215		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.04684025047184215 | validation: 0.055129265298474076]
	TIME [epoch: 9.05 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05589367142664242		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.05589367142664242 | validation: 0.049174783024179845]
	TIME [epoch: 9.04 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045210138171325374		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.045210138171325374 | validation: 0.06524423794419752]
	TIME [epoch: 9.03 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056595453047764276		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.056595453047764276 | validation: 0.053843441089609076]
	TIME [epoch: 9.03 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05845395038709096		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.05845395038709096 | validation: 0.08588425932952451]
	TIME [epoch: 9.05 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.062264329234586815		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.062264329234586815 | validation: 0.056220304479094194]
	TIME [epoch: 9.05 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0594164162921786		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.0594164162921786 | validation: 0.0677580090991699]
	TIME [epoch: 9.04 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04922105462194422		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.04922105462194422 | validation: 0.04612022837204201]
	TIME [epoch: 9.03 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04478869849826777		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.04478869849826777 | validation: 0.043616417588819]
	TIME [epoch: 9.03 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04294221912923595		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.04294221912923595 | validation: 0.05559463197502745]
	TIME [epoch: 9.04 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05058304178638741		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.05058304178638741 | validation: 0.05566856349335547]
	TIME [epoch: 9.05 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04472713471777882		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.04472713471777882 | validation: 0.047077217125019916]
	TIME [epoch: 9.04 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04476312058774671		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.04476312058774671 | validation: 0.06868504887192607]
	TIME [epoch: 9.04 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04672975581785185		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.04672975581785185 | validation: 0.053962893373668566]
	TIME [epoch: 9.05 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049028828811140165		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.049028828811140165 | validation: 0.08068916138238527]
	TIME [epoch: 9.06 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06200936552617835		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.06200936552617835 | validation: 0.05816175199597]
	TIME [epoch: 9.06 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04910231301328435		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.04910231301328435 | validation: 0.03727435596644117]
	TIME [epoch: 9.04 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04473534018839638		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.04473534018839638 | validation: 0.049722186370469615]
	TIME [epoch: 9.03 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04379215293898624		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.04379215293898624 | validation: 0.0640594617984183]
	TIME [epoch: 9.04 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043242970610053576		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.043242970610053576 | validation: 0.053254989741772285]
	TIME [epoch: 9.05 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04636372445928761		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.04636372445928761 | validation: 0.044466227669000685]
	TIME [epoch: 9.06 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044863486718749575		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.044863486718749575 | validation: 0.047449740270034776]
	TIME [epoch: 9.04 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04743896701010217		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.04743896701010217 | validation: 0.060467006022256006]
	TIME [epoch: 9.04 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.041641418731474436		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.041641418731474436 | validation: 0.04178970594285581]
	TIME [epoch: 9.04 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04264009157403477		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.04264009157403477 | validation: 0.05225614476840398]
	TIME [epoch: 9.04 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0533988201060138		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.0533988201060138 | validation: 0.056008251065465135]
	TIME [epoch: 9.06 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04986942019908237		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.04986942019908237 | validation: 0.05000378820586864]
	TIME [epoch: 9.05 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04927259289203213		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.04927259289203213 | validation: 0.07246543129145522]
	TIME [epoch: 9.05 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050280894728103945		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.050280894728103945 | validation: 0.05318631676478407]
	TIME [epoch: 9.05 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04429771830876894		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.04429771830876894 | validation: 0.0854914536433481]
	TIME [epoch: 9.04 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05213073744765338		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.05213073744765338 | validation: 0.05521895926232323]
	TIME [epoch: 9.05 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04256269829885971		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.04256269829885971 | validation: 0.052239100001912314]
	TIME [epoch: 9.03 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05737647202170494		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.05737647202170494 | validation: 0.10012143419069777]
	TIME [epoch: 9.03 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05259951045778616		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.05259951045778616 | validation: 0.0692263680743866]
	TIME [epoch: 9.03 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06283011286568559		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.06283011286568559 | validation: 0.05090293078292801]
	TIME [epoch: 9.04 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053390539237660115		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.053390539237660115 | validation: 0.06899702571433211]
	TIME [epoch: 9.05 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04565176443120849		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.04565176443120849 | validation: 0.05554218060805414]
	TIME [epoch: 9.05 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044612508254540204		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.044612508254540204 | validation: 0.049535027156147604]
	TIME [epoch: 9.03 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05641525519803681		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.05641525519803681 | validation: 0.05414483687532694]
	TIME [epoch: 9.04 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04153969956303549		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.04153969956303549 | validation: 0.048937485497685604]
	TIME [epoch: 9.05 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037619828900923		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.037619828900923 | validation: 0.04191302086616847]
	TIME [epoch: 9.06 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035998623286506874		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.035998623286506874 | validation: 0.06384886466313527]
	TIME [epoch: 9.04 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04568328622591341		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.04568328622591341 | validation: 0.0476592563908092]
	TIME [epoch: 9.03 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04634220587269577		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.04634220587269577 | validation: 0.06411063807605072]
	TIME [epoch: 9.02 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05369792773268276		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.05369792773268276 | validation: 0.04861620942935931]
	TIME [epoch: 9.03 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04656280198655131		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.04656280198655131 | validation: 0.060031374538442324]
	TIME [epoch: 9.05 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052662919094176495		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.052662919094176495 | validation: 0.0486398314536408]
	TIME [epoch: 9.04 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0442614254135469		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.0442614254135469 | validation: 0.06172687326586812]
	TIME [epoch: 9.03 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0444554221943912		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.0444554221943912 | validation: 0.06015016005339322]
	TIME [epoch: 9.03 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04928070501884809		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.04928070501884809 | validation: 0.052628090673871766]
	TIME [epoch: 9.04 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0611769355741378		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.0611769355741378 | validation: 0.06934454024178704]
	TIME [epoch: 9.06 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05724469326597872		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.05724469326597872 | validation: 0.050189972464261844]
	TIME [epoch: 9.03 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037104651796977375		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.037104651796977375 | validation: 0.0566261909962683]
	TIME [epoch: 9.04 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04468218581008883		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.04468218581008883 | validation: 0.039226041326485994]
	TIME [epoch: 9.04 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043573551573468615		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.043573551573468615 | validation: 0.058174294031145525]
	TIME [epoch: 9.04 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045331352317250356		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.045331352317250356 | validation: 0.0546830784223719]
	TIME [epoch: 9.05 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04560573485535662		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.04560573485535662 | validation: 0.05544838703870683]
	TIME [epoch: 9.03 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050494731891373636		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.050494731891373636 | validation: 0.06977026555792225]
	TIME [epoch: 9.03 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04608025124274835		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.04608025124274835 | validation: 0.03826110390398743]
	TIME [epoch: 9.02 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04605281349995572		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.04605281349995572 | validation: 0.046732490792144504]
	TIME [epoch: 9.04 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04255256851340539		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.04255256851340539 | validation: 0.04563969773918364]
	TIME [epoch: 9.05 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04173577809736151		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.04173577809736151 | validation: 0.06545037913476578]
	TIME [epoch: 9.04 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0523268525485826		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.0523268525485826 | validation: 0.04723088348018663]
	TIME [epoch: 9.04 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04058918494592024		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.04058918494592024 | validation: 0.06871236170146572]
	TIME [epoch: 9.02 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06121071877482278		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.06121071877482278 | validation: 0.05097519372997883]
	TIME [epoch: 9.02 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04902655289493501		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.04902655289493501 | validation: 0.05429685152311845]
	TIME [epoch: 9.06 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04974687062540546		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.04974687062540546 | validation: 0.046971052780641266]
	TIME [epoch: 9.04 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045977919955587455		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.045977919955587455 | validation: 0.04793660558934623]
	TIME [epoch: 9.04 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053204197712318976		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.053204197712318976 | validation: 0.05150142148054216]
	TIME [epoch: 9.03 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04302633005649939		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.04302633005649939 | validation: 0.055391529041391385]
	TIME [epoch: 9.03 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047871917615659156		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.047871917615659156 | validation: 0.05912162109852092]
	TIME [epoch: 9.04 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04569469835007009		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.04569469835007009 | validation: 0.039657335356587844]
	TIME [epoch: 9.04 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04652260006676784		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.04652260006676784 | validation: 0.06690135738042685]
	TIME [epoch: 9.03 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05027136486797181		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.05027136486797181 | validation: 0.049811677811515465]
	TIME [epoch: 9.02 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04437226692153294		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.04437226692153294 | validation: 0.058395304813095114]
	TIME [epoch: 9.02 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05198030339487823		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.05198030339487823 | validation: 0.057926468459732525]
	TIME [epoch: 9.04 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048076796570450414		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.048076796570450414 | validation: 0.06956962331381848]
	TIME [epoch: 9.02 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04765604460144985		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.04765604460144985 | validation: 0.05898174851719235]
	TIME [epoch: 9.02 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044407962162531525		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.044407962162531525 | validation: 0.05058626430508419]
	TIME [epoch: 9.03 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05133231984936574		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.05133231984936574 | validation: 0.04166299726041563]
	TIME [epoch: 9.05 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04606027589066878		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.04606027589066878 | validation: 0.068434085421997]
	TIME [epoch: 9.06 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05108406437458366		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.05108406437458366 | validation: 0.053662835569811704]
	TIME [epoch: 9.04 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04314095990972569		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.04314095990972569 | validation: 0.044056572423212606]
	TIME [epoch: 9.02 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03884207445857802		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.03884207445857802 | validation: 0.046182115069455285]
	TIME [epoch: 9.03 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06170357635767224		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.06170357635767224 | validation: 0.06306976942544737]
	TIME [epoch: 9.03 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039713427968977234		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.039713427968977234 | validation: 0.0421398026736375]
	TIME [epoch: 9.06 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04382927630635215		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.04382927630635215 | validation: 0.06844625245365102]
	TIME [epoch: 9.03 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06303839312832708		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.06303839312832708 | validation: 0.053797867829269874]
	TIME [epoch: 9.03 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043339568070213684		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.043339568070213684 | validation: 0.05104391190851204]
	TIME [epoch: 9.03 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03995629527173734		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.03995629527173734 | validation: 0.055007718548928074]
	TIME [epoch: 9.03 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038608715033635346		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.038608715033635346 | validation: 0.045358342038069106]
	TIME [epoch: 9.05 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03933216775843534		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.03933216775843534 | validation: 0.047713302261407915]
	TIME [epoch: 9.03 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04666032378159382		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.04666032378159382 | validation: 0.042832430882742474]
	TIME [epoch: 9.04 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037947242444070876		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.037947242444070876 | validation: 0.04510946759740239]
	TIME [epoch: 9.03 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04099050985391356		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.04099050985391356 | validation: 0.048471617179042026]
	TIME [epoch: 9.04 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053204252757669025		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.053204252757669025 | validation: 0.06823679686495543]
	TIME [epoch: 9.05 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052556672856618525		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.052556672856618525 | validation: 0.08223319799844478]
	TIME [epoch: 9.03 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061301781344586546		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.061301781344586546 | validation: 0.053476006889331004]
	TIME [epoch: 9.02 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04443525114525289		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.04443525114525289 | validation: 0.049383724390346176]
	TIME [epoch: 9.02 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04748113801161141		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.04748113801161141 | validation: 0.052600155660062015]
	TIME [epoch: 9.03 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04017874330780367		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.04017874330780367 | validation: 0.05823705374328921]
	TIME [epoch: 9.05 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03879694750967867		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.03879694750967867 | validation: 0.05481348807018183]
	TIME [epoch: 9.03 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04644637853507705		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.04644637853507705 | validation: 0.05832021944056515]
	TIME [epoch: 9.02 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05831864469437124		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.05831864469437124 | validation: 0.06791516160856964]
	TIME [epoch: 9.02 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05234160200072816		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.05234160200072816 | validation: 0.05634177343120881]
	TIME [epoch: 9.03 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04107520454147856		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.04107520454147856 | validation: 0.060258632848298715]
	TIME [epoch: 9.05 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052508325009271516		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.052508325009271516 | validation: 0.06621235354969521]
	TIME [epoch: 9.03 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04849341955667876		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.04849341955667876 | validation: 0.057903768300972165]
	TIME [epoch: 9.03 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04543828946464894		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.04543828946464894 | validation: 0.0697405663009626]
	TIME [epoch: 9.03 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049290616635861054		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.049290616635861054 | validation: 0.04790405831432205]
	TIME [epoch: 9.03 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049988850717785735		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.049988850717785735 | validation: 0.04820624207466316]
	TIME [epoch: 9.05 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03694585509125864		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.03694585509125864 | validation: 0.056238971823887575]
	TIME [epoch: 9.03 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04269714383107461		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.04269714383107461 | validation: 0.05447417252965152]
	TIME [epoch: 9.03 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048417610436137945		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.048417610436137945 | validation: 0.05251251946050557]
	TIME [epoch: 9.02 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03730610786312298		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.03730610786312298 | validation: 0.038419130209992755]
	TIME [epoch: 9.03 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03781406127585306		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.03781406127585306 | validation: 0.04606872292408337]
	TIME [epoch: 9.05 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05019926500571029		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.05019926500571029 | validation: 0.06182538075849728]
	TIME [epoch: 9.03 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04919642012818937		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.04919642012818937 | validation: 0.04147505180499532]
	TIME [epoch: 9.03 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03913139266091935		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.03913139266091935 | validation: 0.04519348945992248]
	TIME [epoch: 9.03 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050923822404636276		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.050923822404636276 | validation: 0.05389402644384589]
	TIME [epoch: 9.04 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03831360768325639		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.03831360768325639 | validation: 0.05390609760610135]
	TIME [epoch: 9.06 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05227802722475296		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.05227802722475296 | validation: 0.04123667823665383]
	TIME [epoch: 9.04 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04525410293455528		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.04525410293455528 | validation: 0.055755177501651904]
	TIME [epoch: 9.03 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05516445233336663		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.05516445233336663 | validation: 0.041844562199021565]
	TIME [epoch: 9.03 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03949363316539591		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.03949363316539591 | validation: 0.036398267020256836]
	TIME [epoch: 9.03 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03754841701874736		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.03754841701874736 | validation: 0.03973476305032599]
	TIME [epoch: 9.06 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039564286895996614		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.039564286895996614 | validation: 0.050691099997433896]
	TIME [epoch: 9.03 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04110947877557018		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.04110947877557018 | validation: 0.040726934364251816]
	TIME [epoch: 9.03 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04704686916063226		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.04704686916063226 | validation: 0.0578489876601007]
	TIME [epoch: 9.02 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04814282818281798		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.04814282818281798 | validation: 0.04556654872166835]
	TIME [epoch: 9.04 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044007157219188825		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.044007157219188825 | validation: 0.06899463214013822]
	TIME [epoch: 9.05 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.046627044465862535		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.046627044465862535 | validation: 0.03890338819674468]
	TIME [epoch: 9.03 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04680882533750996		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.04680882533750996 | validation: 0.06091603361670604]
	TIME [epoch: 9.04 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04414117552141729		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.04414117552141729 | validation: 0.045766990746547234]
	TIME [epoch: 9.03 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03411725013830878		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.03411725013830878 | validation: 0.04869024676043544]
	TIME [epoch: 9.03 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049769296500508445		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.049769296500508445 | validation: 0.052342428354823396]
	TIME [epoch: 9.05 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04602982422856197		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.04602982422856197 | validation: 0.05083451602103407]
	TIME [epoch: 9.03 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052455253308580585		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.052455253308580585 | validation: 0.05239022513969509]
	TIME [epoch: 9.03 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04477466926767855		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.04477466926767855 | validation: 0.047698494963272435]
	TIME [epoch: 9.03 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042903357668292744		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.042903357668292744 | validation: 0.05428980813911807]
	TIME [epoch: 9.03 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04694203048484115		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.04694203048484115 | validation: 0.05730966948180405]
	TIME [epoch: 9.06 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04345703369838612		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.04345703369838612 | validation: 0.053235427460748934]
	TIME [epoch: 9.03 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04671944420688749		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.04671944420688749 | validation: 0.06917677263346116]
	TIME [epoch: 9.03 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04626986972036652		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.04626986972036652 | validation: 0.04288822220589392]
	TIME [epoch: 9.03 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04334104216139202		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.04334104216139202 | validation: 0.04833985879246008]
	TIME [epoch: 9.04 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05228942939578959		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.05228942939578959 | validation: 0.0525158148978454]
	TIME [epoch: 9.07 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03644412675477682		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.03644412675477682 | validation: 0.05122142246161025]
	TIME [epoch: 9.04 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03862837485287283		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.03862837485287283 | validation: 0.04381893871346962]
	TIME [epoch: 9.04 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045524757997652286		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.045524757997652286 | validation: 0.05714294478640538]
	TIME [epoch: 9.03 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04014417152758705		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.04014417152758705 | validation: 0.05283585325404586]
	TIME [epoch: 9.02 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045379426513485484		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.045379426513485484 | validation: 0.06575035496738307]
	TIME [epoch: 9.05 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04513662337293903		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.04513662337293903 | validation: 0.03981124329540729]
	TIME [epoch: 9.03 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03596073145755686		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.03596073145755686 | validation: 0.05934407736155277]
	TIME [epoch: 9.04 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04897071107542443		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.04897071107542443 | validation: 0.045059844015350486]
	TIME [epoch: 9.03 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038698704129901354		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.038698704129901354 | validation: 0.03960522485786659]
	TIME [epoch: 9.03 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03886514720446754		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.03886514720446754 | validation: 0.051019557192961855]
	TIME [epoch: 9.05 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.046119513437354216		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.046119513437354216 | validation: 0.05129777058503468]
	TIME [epoch: 9.03 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03645813511137726		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.03645813511137726 | validation: 0.04069320851365933]
	TIME [epoch: 9.03 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042592588965912635		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.042592588965912635 | validation: 0.04666823254158011]
	TIME [epoch: 9.03 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038444045772692656		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.038444045772692656 | validation: 0.049090758548811016]
	TIME [epoch: 9.03 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04044544927242289		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.04044544927242289 | validation: 0.043271128424623495]
	TIME [epoch: 9.05 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043129677733049945		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.043129677733049945 | validation: 0.040949706734848684]
	TIME [epoch: 9.03 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042692880630195905		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.042692880630195905 | validation: 0.047695546326904883]
	TIME [epoch: 9.03 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044253404731807604		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.044253404731807604 | validation: 0.054159161845429335]
	TIME [epoch: 9.03 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043186610635568945		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.043186610635568945 | validation: 0.044511750856959985]
	TIME [epoch: 9.01 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039417263413315744		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.039417263413315744 | validation: 0.045840851921060854]
	TIME [epoch: 9.05 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03842984336423938		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.03842984336423938 | validation: 0.0432022858567328]
	TIME [epoch: 9.03 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04627366050193532		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.04627366050193532 | validation: 0.041491305522028454]
	TIME [epoch: 9.04 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04251919372721348		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.04251919372721348 | validation: 0.037193057357172356]
	TIME [epoch: 9.02 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04057263541488727		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.04057263541488727 | validation: 0.05273197988007278]
	TIME [epoch: 9.02 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04621646911822515		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.04621646911822515 | validation: 0.050222953451399314]
	TIME [epoch: 9.04 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.041044241843906024		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.041044241843906024 | validation: 0.04256949514671303]
	TIME [epoch: 9.03 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0419534944690396		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.0419534944690396 | validation: 0.049572238648577224]
	TIME [epoch: 9.03 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03530940641157605		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.03530940641157605 | validation: 0.037014326020825446]
	TIME [epoch: 9.02 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03997344116653928		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.03997344116653928 | validation: 0.034417532140534265]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240217_161441/states/model_tr_study4_942.pth
	Model improved!!!
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03432812350483484		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.03432812350483484 | validation: 0.046814716463203385]
	TIME [epoch: 9.04 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045967914517678884		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.045967914517678884 | validation: 0.0422649929167221]
	TIME [epoch: 9.03 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03733472632145517		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.03733472632145517 | validation: 0.04184545999746765]
	TIME [epoch: 9.02 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037203091874945915		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.037203091874945915 | validation: 0.04949640138992806]
	TIME [epoch: 9.03 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04009140793330575		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.04009140793330575 | validation: 0.041589611272424554]
	TIME [epoch: 9.03 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036590863557974		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.036590863557974 | validation: 0.04253251854803005]
	TIME [epoch: 9.03 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04296012751276909		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.04296012751276909 | validation: 0.04730137057748984]
	TIME [epoch: 9.04 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04526923617691077		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.04526923617691077 | validation: 0.056088816249439254]
	TIME [epoch: 9.02 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0484570263335001		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.0484570263335001 | validation: 0.05116527763319253]
	TIME [epoch: 9.03 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04269984072374228		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.04269984072374228 | validation: 0.043208170762586005]
	TIME [epoch: 9.03 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036586913871942406		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.036586913871942406 | validation: 0.046954152919774506]
	TIME [epoch: 9.04 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03833637623626186		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.03833637623626186 | validation: 0.04419000429750376]
	TIME [epoch: 9.05 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039487978035547454		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.039487978035547454 | validation: 0.0396375146143606]
	TIME [epoch: 9.04 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03697756750291743		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.03697756750291743 | validation: 0.06158490404146709]
	TIME [epoch: 9.03 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.046036757521098565		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.046036757521098565 | validation: 0.046953505337965884]
	TIME [epoch: 9.02 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037705440395128895		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.037705440395128895 | validation: 0.04614116496040321]
	TIME [epoch: 9.03 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03300709526013916		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.03300709526013916 | validation: 0.04900388784487475]
	TIME [epoch: 9.05 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043167160589659664		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.043167160589659664 | validation: 0.03899829059512781]
	TIME [epoch: 9.03 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03662494031120145		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.03662494031120145 | validation: 0.036834985422501895]
	TIME [epoch: 9.03 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043941193751943206		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.043941193751943206 | validation: 0.05057188590492262]
	TIME [epoch: 9.03 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03721121092436725		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.03721121092436725 | validation: 0.05044181473543846]
	TIME [epoch: 9.03 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03881316923834523		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.03881316923834523 | validation: 0.03555802671719555]
	TIME [epoch: 9.06 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04084177014579393		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.04084177014579393 | validation: 0.05131497958834046]
	TIME [epoch: 9.03 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04265514852616033		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.04265514852616033 | validation: 0.03568852990626254]
	TIME [epoch: 9.04 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03381816664059306		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.03381816664059306 | validation: 0.04075217541001311]
	TIME [epoch: 9.03 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03514232538979351		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.03514232538979351 | validation: 0.04031981132836955]
	TIME [epoch: 9.03 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035914487063966966		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.035914487063966966 | validation: 0.039578111037677444]
	TIME [epoch: 9.05 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03510180102836746		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.03510180102836746 | validation: 0.04089332264048516]
	TIME [epoch: 9.02 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03229926274292873		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.03229926274292873 | validation: 0.044152067498935285]
	TIME [epoch: 9.03 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03336302413360768		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.03336302413360768 | validation: 0.04722320351255753]
	TIME [epoch: 9.02 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034611607010939405		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.034611607010939405 | validation: 0.04849333685008349]
	TIME [epoch: 9.03 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037181650396638		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.037181650396638 | validation: 0.04264232226674397]
	TIME [epoch: 9.05 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03876460869482095		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.03876460869482095 | validation: 0.041757340582650876]
	TIME [epoch: 9.03 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03922867649088917		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.03922867649088917 | validation: 0.045915278279798896]
	TIME [epoch: 9.03 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03829079486725771		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.03829079486725771 | validation: 0.047968752398970804]
	TIME [epoch: 9.02 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03915080062234209		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.03915080062234209 | validation: 0.04800304626136116]
	TIME [epoch: 9.03 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04358317100525949		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.04358317100525949 | validation: 0.03504307080241752]
	TIME [epoch: 9.06 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03755567416378407		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.03755567416378407 | validation: 0.03886553046451339]
	TIME [epoch: 9.04 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03624658803946788		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.03624658803946788 | validation: 0.04657429329915776]
	TIME [epoch: 9.04 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04094269008287159		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.04094269008287159 | validation: 0.03999811458794765]
	TIME [epoch: 9.04 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04075184915283862		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.04075184915283862 | validation: 0.042423694920236156]
	TIME [epoch: 9.02 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047860751130700034		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.047860751130700034 | validation: 0.041565147011619626]
	TIME [epoch: 9.05 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03741281410805466		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.03741281410805466 | validation: 0.05080851788046599]
	TIME [epoch: 9.03 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036828918146284334		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.036828918146284334 | validation: 0.04924297622282113]
	TIME [epoch: 9.03 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03707690811443455		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.03707690811443455 | validation: 0.03978034955822318]
	TIME [epoch: 9.03 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04051627288972605		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.04051627288972605 | validation: 0.044090724788995804]
	TIME [epoch: 9.03 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03758165151184469		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.03758165151184469 | validation: 0.042968657256029094]
	TIME [epoch: 9.05 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034277761025471		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.034277761025471 | validation: 0.037066508147286174]
	TIME [epoch: 9.02 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03858891255218084		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.03858891255218084 | validation: 0.04970719875697317]
	TIME [epoch: 9.02 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036159751389322106		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.036159751389322106 | validation: 0.04263593782270644]
	TIME [epoch: 9.03 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03959895689383645		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.03959895689383645 | validation: 0.04861419558372021]
	TIME [epoch: 9.04 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037732780956299464		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.037732780956299464 | validation: 0.040057883507146924]
	TIME [epoch: 9.06 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040725216385177135		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.040725216385177135 | validation: 0.044147394671824325]
	TIME [epoch: 9.03 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040183518355892865		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.040183518355892865 | validation: 0.05526187808430279]
	TIME [epoch: 9.03 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05184775365736214		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.05184775365736214 | validation: 0.05055902914805363]
	TIME [epoch: 9.02 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04425896006483254		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.04425896006483254 | validation: 0.04770765818601713]
	TIME [epoch: 9.03 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038995085687270545		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.038995085687270545 | validation: 0.04246032352743148]
	TIME [epoch: 9.06 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037309013003251894		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.037309013003251894 | validation: 0.04220986149730312]
	TIME [epoch: 9.03 sec]
Finished training in 9148.272 seconds.
