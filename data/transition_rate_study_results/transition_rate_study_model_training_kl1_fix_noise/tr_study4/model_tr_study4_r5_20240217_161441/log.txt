Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 203580723

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.631772245439489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.631772245439489 | validation: 7.98249141280583]
	TIME [epoch: 70.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.649342251541796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.649342251541796 | validation: 6.607651340264002]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.339439876388873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.339439876388873 | validation: 6.385006987132878]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.580568213297994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.580568213297994 | validation: 4.244943465042602]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.476487817791439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.476487817791439 | validation: 4.08203661626818]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.916419834750458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.916419834750458 | validation: 4.968769236999989]
	TIME [epoch: 9.04 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.488723630631698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.488723630631698 | validation: 4.109157915453581]
	TIME [epoch: 9.06 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.9434813746802435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9434813746802435 | validation: 3.9168277648354186]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.042976103427551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.042976103427551 | validation: 4.991028620704274]
	TIME [epoch: 9.05 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.816786631276605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.816786631276605 | validation: 4.137102766593585]
	TIME [epoch: 9.05 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.957583695462712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.957583695462712 | validation: 4.058404003152069]
	TIME [epoch: 9.05 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.0406147618598025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0406147618598025 | validation: 3.6742004638673853]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.791753416099385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.791753416099385 | validation: 3.91096028944881]
	TIME [epoch: 9.06 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.905554481528059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.905554481528059 | validation: 4.380414590638127]
	TIME [epoch: 9.06 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.624414301271917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.624414301271917 | validation: 4.394683936999436]
	TIME [epoch: 9.06 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.3716559785786036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3716559785786036 | validation: 4.334257358650336]
	TIME [epoch: 9.05 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.569011556897307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.569011556897307 | validation: 4.139525579559643]
	TIME [epoch: 9.08 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.231519371671517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.231519371671517 | validation: 4.777270248728522]
	TIME [epoch: 9.05 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.479985802999204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.479985802999204 | validation: 4.914225458480882]
	TIME [epoch: 9.05 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.567969412292074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.567969412292074 | validation: 3.5103573833381856]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.070711663307412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.070711663307412 | validation: 3.594165848513951]
	TIME [epoch: 9.04 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9774748038102055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9774748038102055 | validation: 5.282140999594715]
	TIME [epoch: 9.07 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.193749467076214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193749467076214 | validation: 3.3675333656200346]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.005941158353522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.005941158353522 | validation: 2.074336202553303]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.182834312238892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.182834312238892 | validation: 2.1560452551500955]
	TIME [epoch: 9.03 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0783474260556334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0783474260556334 | validation: 1.667859306822537]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.084334947127453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.084334947127453 | validation: 1.7025431946164504]
	TIME [epoch: 9.07 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9229644863429107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9229644863429107 | validation: 1.5131332888673867]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6402782949984585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6402782949984585 | validation: 1.8886629157892303]
	TIME [epoch: 9.05 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5989153144452692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5989153144452692 | validation: 1.3695643526568286]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.436737820628468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.436737820628468 | validation: 1.9543320315287964]
	TIME [epoch: 9.05 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.674044151192821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.674044151192821 | validation: 1.2853312916868451]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5536412058124172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5536412058124172 | validation: 1.30709482849484]
	TIME [epoch: 9.04 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3604138647318824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3604138647318824 | validation: 1.0790147227464757]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3111658121131629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3111658121131629 | validation: 1.747246887975999]
	TIME [epoch: 9.05 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3390547750179735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3390547750179735 | validation: 1.0216353526842574]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3775888043239413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3775888043239413 | validation: 0.983902761338741]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2568303516760193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2568303516760193 | validation: 1.093502936070589]
	TIME [epoch: 9.05 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9893290565869632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9893290565869632 | validation: 1.159535259254378]
	TIME [epoch: 9.04 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0799881442030368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0799881442030368 | validation: 1.273523884937997]
	TIME [epoch: 9.05 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9792329086186526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9792329086186526 | validation: 1.2353470249069032]
	TIME [epoch: 9.05 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0642181760373417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0642181760373417 | validation: 0.7208524730960932]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0326369857842415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0326369857842415 | validation: 1.0663355855718222]
	TIME [epoch: 9.05 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9634641929383028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9634641929383028 | validation: 0.8100819080617434]
	TIME [epoch: 9.03 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9299483749570234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9299483749570234 | validation: 1.2362251101798467]
	TIME [epoch: 9.04 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1487525732539279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1487525732539279 | validation: 1.2706066038144446]
	TIME [epoch: 9.04 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0859326587466578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0859326587466578 | validation: 0.846200289263084]
	TIME [epoch: 9.06 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0692891332193375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0692891332193375 | validation: 1.1778520343309649]
	TIME [epoch: 9.04 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0528688325541669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0528688325541669 | validation: 1.2309224855436403]
	TIME [epoch: 9.03 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1081075853180327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1081075853180327 | validation: 0.8264083452943598]
	TIME [epoch: 9.05 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1938709023399425		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 1.1938709023399425 | validation: 1.424726428738008]
	TIME [epoch: 9.04 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4294338422587252		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.4294338422587252 | validation: 1.2008759142785226]
	TIME [epoch: 9.06 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2481411706480052		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 1.2481411706480052 | validation: 0.9155351974371603]
	TIME [epoch: 9.06 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9242398630709019		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 0.9242398630709019 | validation: 0.8480265969421847]
	TIME [epoch: 9.04 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.891503875547866		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 0.891503875547866 | validation: 0.9857089037665197]
	TIME [epoch: 9.05 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9261887324905047		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.9261887324905047 | validation: 0.6060352123203694]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.398927678256699		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.398927678256699 | validation: 1.2601963177650732]
	TIME [epoch: 9.06 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1380348331668633		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.1380348331668633 | validation: 0.7998842161548836]
	TIME [epoch: 9.04 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7941479075796899		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.7941479075796899 | validation: 0.746249782896004]
	TIME [epoch: 9.03 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8834727974001659		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.8834727974001659 | validation: 0.7200354818493229]
	TIME [epoch: 9.05 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8989552845920972		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 0.8989552845920972 | validation: 0.9154874422619851]
	TIME [epoch: 9.04 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.208224185231591		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.208224185231591 | validation: 1.2200842002116494]
	TIME [epoch: 9.06 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0694941150073602		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.0694941150073602 | validation: 0.8393954017577854]
	TIME [epoch: 9.04 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1108072238683828		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.1108072238683828 | validation: 1.2888802061498192]
	TIME [epoch: 9.04 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9945007011573583		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.9945007011573583 | validation: 0.7728116634230355]
	TIME [epoch: 9.04 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9293322140585124		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.9293322140585124 | validation: 0.8519236202080077]
	TIME [epoch: 9.05 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8441815617859266		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 0.8441815617859266 | validation: 0.8274030171379272]
	TIME [epoch: 9.07 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6930400504828367		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 0.6930400504828367 | validation: 0.931932460746147]
	TIME [epoch: 9.06 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4772662206547404		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.4772662206547404 | validation: 1.2181118167660547]
	TIME [epoch: 9.05 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.876735657480501		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.876735657480501 | validation: 0.7499271543058684]
	TIME [epoch: 9.04 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7450480431078699		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.7450480431078699 | validation: 0.901063761665744]
	TIME [epoch: 9.04 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8573860450126023		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.8573860450126023 | validation: 1.161768825966992]
	TIME [epoch: 9.06 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8389416222996736		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.8389416222996736 | validation: 0.7818104485772008]
	TIME [epoch: 9.04 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8451083877467436		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.8451083877467436 | validation: 1.216262093788022]
	TIME [epoch: 9.03 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6969322038413013		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.6969322038413013 | validation: 0.559451697861232]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_75.pth
	Model improved!!!
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8230578019998813		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.8230578019998813 | validation: 0.8310112715600093]
	TIME [epoch: 9.04 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7114529907465533		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.7114529907465533 | validation: 0.6347637242062731]
	TIME [epoch: 9.06 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.739276569530362		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.739276569530362 | validation: 0.6197011067586446]
	TIME [epoch: 9.05 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6319416562613526		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.6319416562613526 | validation: 0.5253556171548618]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6582582768571377		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.6582582768571377 | validation: 0.548867806694197]
	TIME [epoch: 9.04 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6375594965625494		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.6375594965625494 | validation: 1.2025623659577829]
	TIME [epoch: 9.05 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8045213718246964		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.8045213718246964 | validation: 0.7325256719461447]
	TIME [epoch: 9.06 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7723784995064646		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.7723784995064646 | validation: 0.6417409989280474]
	TIME [epoch: 9.05 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.715488414913757		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.715488414913757 | validation: 1.0855982149091434]
	TIME [epoch: 9.04 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6999281268651355		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.6999281268651355 | validation: 0.6746145681085441]
	TIME [epoch: 9.03 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6914383349754847		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.6914383349754847 | validation: 0.6246478166175538]
	TIME [epoch: 9.03 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7724698691433931		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.7724698691433931 | validation: 0.6172378771132677]
	TIME [epoch: 9.06 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6557130909657712		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.6557130909657712 | validation: 1.697982851014269]
	TIME [epoch: 9.04 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8362867639338001		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.8362867639338001 | validation: 0.6609070510940078]
	TIME [epoch: 9.04 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6435402593547723		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.6435402593547723 | validation: 0.8628449266780807]
	TIME [epoch: 9.03 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8487046652751327		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.8487046652751327 | validation: 0.7942973435770083]
	TIME [epoch: 9.04 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8142124885600873		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.8142124885600873 | validation: 0.7337986379146018]
	TIME [epoch: 9.05 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6799956928003807		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.6799956928003807 | validation: 0.684562371673843]
	TIME [epoch: 9.05 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6608599844092933		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.6608599844092933 | validation: 0.7302826356348646]
	TIME [epoch: 9.04 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7230764253535974		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.7230764253535974 | validation: 0.9021384725903945]
	TIME [epoch: 9.04 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9177299839726544		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.9177299839726544 | validation: 0.7406096634821144]
	TIME [epoch: 9.04 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6413412610098702		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.6413412610098702 | validation: 0.8087790860917767]
	TIME [epoch: 9.06 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6676150097543259		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.6676150097543259 | validation: 0.6140449422522603]
	TIME [epoch: 9.04 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6463556405969024		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.6463556405969024 | validation: 0.7181025440712046]
	TIME [epoch: 9.04 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.690774620772186		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.690774620772186 | validation: 0.8994928792242662]
	TIME [epoch: 9.03 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7330426029651428		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.7330426029651428 | validation: 0.7576946261665765]
	TIME [epoch: 9.04 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7005247122687057		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.7005247122687057 | validation: 0.5936481971877137]
	TIME [epoch: 9.06 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.718102759286007		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.718102759286007 | validation: 0.7268639233306913]
	TIME [epoch: 9.04 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6749486129714717		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.6749486129714717 | validation: 0.5334109959275917]
	TIME [epoch: 9.03 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116388499555756		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.6116388499555756 | validation: 0.7888374964115281]
	TIME [epoch: 9.03 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7732577977063992		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.7732577977063992 | validation: 0.5667511395537244]
	TIME [epoch: 9.04 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7053755484558606		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.7053755484558606 | validation: 0.5519799704536478]
	TIME [epoch: 9.06 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5962767545123907		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.5962767545123907 | validation: 0.5707667663908187]
	TIME [epoch: 9.04 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5684418410675515		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5684418410675515 | validation: 0.8691822896016759]
	TIME [epoch: 9.05 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6402671602732476		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.6402671602732476 | validation: 0.45872921769729724]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5009874090230736		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.5009874090230736 | validation: 0.4709469598528485]
	TIME [epoch: 9.04 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6376979612512967		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.6376979612512967 | validation: 0.4697816688567815]
	TIME [epoch: 9.06 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6247480496702085		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.6247480496702085 | validation: 0.4988113919266137]
	TIME [epoch: 9.04 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6482832876338567		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.6482832876338567 | validation: 0.7619045953610437]
	TIME [epoch: 9.04 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.529207311434897		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.529207311434897 | validation: 0.44652689330771245]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5028399831851557		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5028399831851557 | validation: 0.6952202683872907]
	TIME [epoch: 9.04 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.574975041437699		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.574975041437699 | validation: 0.6817008918274301]
	TIME [epoch: 9.06 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5845673171158611		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.5845673171158611 | validation: 0.6844706852804945]
	TIME [epoch: 9.04 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7047187073937129		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.7047187073937129 | validation: 0.737220169696011]
	TIME [epoch: 9.05 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5785283850895808		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.5785283850895808 | validation: 0.4355036261846943]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_120.pth
	Model improved!!!
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.536193896400116		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.536193896400116 | validation: 0.49649785033960836]
	TIME [epoch: 9.05 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7524617259232851		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.7524617259232851 | validation: 0.7191282171792828]
	TIME [epoch: 9.06 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6228417685916738		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.6228417685916738 | validation: 0.42407510941612836]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_123.pth
	Model improved!!!
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5729438564599565		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.5729438564599565 | validation: 0.5393756337464514]
	TIME [epoch: 9.04 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5555209615728897		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.5555209615728897 | validation: 0.46688720922588545]
	TIME [epoch: 9.03 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6255312898422193		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.6255312898422193 | validation: 0.8118538854164352]
	TIME [epoch: 9.04 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6492265726059739		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.6492265726059739 | validation: 0.5169888061647575]
	TIME [epoch: 9.06 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5462572349247623		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5462572349247623 | validation: 0.7667274248003049]
	TIME [epoch: 9.04 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6117061018999763		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.6117061018999763 | validation: 0.4178793793763588]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_129.pth
	Model improved!!!
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.649497794595859		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.649497794595859 | validation: 0.5138874019553602]
	TIME [epoch: 9.02 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4961371269614814		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.4961371269614814 | validation: 0.7983767447507841]
	TIME [epoch: 9.04 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6280376249953006		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.6280376249953006 | validation: 0.5547493093829683]
	TIME [epoch: 9.05 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5508201511705798		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.5508201511705798 | validation: 0.5069373794292154]
	TIME [epoch: 9.04 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6691576092766504		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.6691576092766504 | validation: 0.8980436851667534]
	TIME [epoch: 9.03 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5917055573108805		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.5917055573108805 | validation: 0.897526724029176]
	TIME [epoch: 9.03 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5102598569849486		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.5102598569849486 | validation: 0.4123210193269873]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_136.pth
	Model improved!!!
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.50385901635252		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.50385901635252 | validation: 0.622429460821199]
	TIME [epoch: 9.06 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824724485240057		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.5824724485240057 | validation: 1.1928696758167332]
	TIME [epoch: 9.04 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5566911391106008		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.5566911391106008 | validation: 0.5668459632936682]
	TIME [epoch: 9.05 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4613202711166756		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.4613202711166756 | validation: 0.43268517238140897]
	TIME [epoch: 9.04 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4689301051670512		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.4689301051670512 | validation: 0.4351319140219334]
	TIME [epoch: 9.03 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5950507911317264		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.5950507911317264 | validation: 0.7102673406028779]
	TIME [epoch: 9.07 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5046263332967773		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.5046263332967773 | validation: 0.43096545303064215]
	TIME [epoch: 9.04 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6248678735039461		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.6248678735039461 | validation: 0.5442814110350849]
	TIME [epoch: 9.04 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.500648840884748		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.500648840884748 | validation: 0.43966995244081497]
	TIME [epoch: 9.04 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5070944333862262		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.5070944333862262 | validation: 0.3497210688101754]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_146.pth
	Model improved!!!
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4096256167911213		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.4096256167911213 | validation: 0.6983762665058404]
	TIME [epoch: 9.07 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5061009895234532		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.5061009895234532 | validation: 0.5056758979884304]
	TIME [epoch: 9.04 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5067339006852001		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.5067339006852001 | validation: 0.6461966220070279]
	TIME [epoch: 9.04 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4909222560240624		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.4909222560240624 | validation: 0.45973298417465236]
	TIME [epoch: 9.03 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4935148537824007		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.4935148537824007 | validation: 0.4058534394966684]
	TIME [epoch: 9.02 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48385522701749367		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.48385522701749367 | validation: 0.5049609790515841]
	TIME [epoch: 9.05 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4702788463518166		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.4702788463518166 | validation: 0.4667508762949018]
	TIME [epoch: 9.02 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43378345197429535		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.43378345197429535 | validation: 0.5703843193792959]
	TIME [epoch: 9.03 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.444031346902553		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.444031346902553 | validation: 0.5928076364190294]
	TIME [epoch: 9.03 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4410110317660763		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.4410110317660763 | validation: 0.5581205655659124]
	TIME [epoch: 9.02 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4466328578217322		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.4466328578217322 | validation: 0.3758922751643376]
	TIME [epoch: 9.06 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5370337786113126		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.5370337786113126 | validation: 0.6935517169005582]
	TIME [epoch: 9.02 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46533845964119214		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.46533845964119214 | validation: 0.6296646152625474]
	TIME [epoch: 9.04 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5258194756555508		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.5258194756555508 | validation: 0.4443351238598585]
	TIME [epoch: 9.03 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40736472448890026		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.40736472448890026 | validation: 0.39597036781315276]
	TIME [epoch: 9.03 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4066735052634005		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.4066735052634005 | validation: 0.5751644059894148]
	TIME [epoch: 9.06 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43400524907384314		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.43400524907384314 | validation: 0.47109005715870783]
	TIME [epoch: 9.02 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5078603159497146		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.5078603159497146 | validation: 0.3801587237888686]
	TIME [epoch: 9.03 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48328374634182547		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.48328374634182547 | validation: 0.3538668327550794]
	TIME [epoch: 9.03 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.417802249584454		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.417802249584454 | validation: 0.4334468076845452]
	TIME [epoch: 9.03 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41997950720107624		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.41997950720107624 | validation: 0.6754857069343774]
	TIME [epoch: 9.06 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4473467007033453		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.4473467007033453 | validation: 0.41359190525536876]
	TIME [epoch: 9.02 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5246116166308588		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.5246116166308588 | validation: 0.4037271392220917]
	TIME [epoch: 9.03 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.649601067293818		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.649601067293818 | validation: 0.7667033346744806]
	TIME [epoch: 9.03 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4869398742350054		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.4869398742350054 | validation: 0.5193676991707505]
	TIME [epoch: 9.03 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4038106477254474		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.4038106477254474 | validation: 0.4170886944444907]
	TIME [epoch: 9.05 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5339551432854087		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.5339551432854087 | validation: 0.3322652187279774]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_173.pth
	Model improved!!!
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40258620049416527		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.40258620049416527 | validation: 0.6249066493196176]
	TIME [epoch: 9.03 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4070962788214921		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.4070962788214921 | validation: 0.39481468569676265]
	TIME [epoch: 9.02 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39958116269611016		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.39958116269611016 | validation: 0.3441981786045395]
	TIME [epoch: 9.02 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4386898471899404		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.4386898471899404 | validation: 0.437472424264312]
	TIME [epoch: 9.05 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4324205257335854		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.4324205257335854 | validation: 0.3099044433800673]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43713056053936955		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.43713056053936955 | validation: 0.39280392666987307]
	TIME [epoch: 9.03 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36753803053606193		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.36753803053606193 | validation: 0.3324356679490692]
	TIME [epoch: 9.03 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4525073515139469		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.4525073515139469 | validation: 0.5655766736330168]
	TIME [epoch: 9.02 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5195099463390738		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.5195099463390738 | validation: 0.31649548874484057]
	TIME [epoch: 9.05 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4618207964654742		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.4618207964654742 | validation: 0.2545077329670352]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.374711913984597		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.374711913984597 | validation: 0.3499405037837445]
	TIME [epoch: 9.04 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47204410748753434		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.47204410748753434 | validation: 0.3970033107494929]
	TIME [epoch: 9.03 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44376525815312695		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.44376525815312695 | validation: 0.44285864976885014]
	TIME [epoch: 9.03 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.379268053081176		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.379268053081176 | validation: 0.3767438971185664]
	TIME [epoch: 9.06 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3452309229093877		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.3452309229093877 | validation: 0.234980744354215]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39341069304453236		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.39341069304453236 | validation: 0.5419285258303592]
	TIME [epoch: 9.04 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4438118499108		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.4438118499108 | validation: 0.3097780761594321]
	TIME [epoch: 9.04 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.499784177353639		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.499784177353639 | validation: 0.3108564814784609]
	TIME [epoch: 9.02 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4033873474866237		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.4033873474866237 | validation: 0.2918967370907601]
	TIME [epoch: 9.05 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4006249337186218		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.4006249337186218 | validation: 0.28071306153115316]
	TIME [epoch: 9.02 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3695973392014878		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.3695973392014878 | validation: 0.320692541293579]
	TIME [epoch: 9.03 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3666167479643415		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.3666167479643415 | validation: 0.27248860345639636]
	TIME [epoch: 9.03 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3146058768599124		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.3146058768599124 | validation: 0.498320714981085]
	TIME [epoch: 9.02 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3656778019967647		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.3656778019967647 | validation: 0.3749444657313262]
	TIME [epoch: 9.05 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6073886848834922		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.6073886848834922 | validation: 0.3878319705543026]
	TIME [epoch: 9.03 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3490796298231055		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.3490796298231055 | validation: 0.345426387419091]
	TIME [epoch: 9.03 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3420977947542483		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.3420977947542483 | validation: 0.2564641130203932]
	TIME [epoch: 9.03 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3990427370158584		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.3990427370158584 | validation: 0.5165030494161804]
	TIME [epoch: 9.02 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4218988711283139		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.4218988711283139 | validation: 0.3476590697409449]
	TIME [epoch: 9.05 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30693158228438217		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.30693158228438217 | validation: 0.23608754807417415]
	TIME [epoch: 9.03 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4683922383211264		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.4683922383211264 | validation: 0.42819578656391655]
	TIME [epoch: 9.01 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30711826163607925		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.30711826163607925 | validation: 0.49037175989786297]
	TIME [epoch: 9.03 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135361802431827		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.3135361802431827 | validation: 0.35628179930999904]
	TIME [epoch: 9.02 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3603228788323484		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.3603228788323484 | validation: 0.4963855901650469]
	TIME [epoch: 9.04 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31370644283028454		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.31370644283028454 | validation: 0.2640677686625045]
	TIME [epoch: 9.03 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208419241049659		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.3208419241049659 | validation: 0.2925253536173402]
	TIME [epoch: 9.01 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4013660189804522		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.4013660189804522 | validation: 0.20633331353623496]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_210.pth
	Model improved!!!
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4189435877645554		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.4189435877645554 | validation: 0.45298656461389697]
	TIME [epoch: 9.02 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40529934508917853		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.40529934508917853 | validation: 0.2915943197324643]
	TIME [epoch: 9.04 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32496879973277154		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.32496879973277154 | validation: 0.25336122865865135]
	TIME [epoch: 9.02 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3660773418110794		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.3660773418110794 | validation: 0.6185232979108254]
	TIME [epoch: 9.02 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4810002299858135		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.4810002299858135 | validation: 0.43051843919147104]
	TIME [epoch: 9.02 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3303139164215163		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.3303139164215163 | validation: 0.3646515133455749]
	TIME [epoch: 9.01 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3562210144254288		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.3562210144254288 | validation: 0.3077822115779829]
	TIME [epoch: 9.03 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3010195011569322		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.3010195011569322 | validation: 0.3607939536142599]
	TIME [epoch: 9.02 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43175978662528236		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.43175978662528236 | validation: 0.3156933154780111]
	TIME [epoch: 9.01 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37375638912403497		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.37375638912403497 | validation: 0.3871261160559447]
	TIME [epoch: 9.02 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3403073767470485		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.3403073767470485 | validation: 0.3507186083344883]
	TIME [epoch: 9.01 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3201815451765144		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.3201815451765144 | validation: 0.8347912723911595]
	TIME [epoch: 9.03 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3507275225341019		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.3507275225341019 | validation: 0.44162691465470194]
	TIME [epoch: 9.03 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36446298107499875		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.36446298107499875 | validation: 0.3723227618150514]
	TIME [epoch: 9.01 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35842478549167767		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.35842478549167767 | validation: 0.25315064732107206]
	TIME [epoch: 9.02 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3350159836915415		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.3350159836915415 | validation: 0.43258462793455643]
	TIME [epoch: 9.01 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3660870189282416		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.3660870189282416 | validation: 0.45970838791221574]
	TIME [epoch: 9.03 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36180679417314043		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.36180679417314043 | validation: 0.3151794614810277]
	TIME [epoch: 9.03 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3525031794297933		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.3525031794297933 | validation: 0.24014658904152292]
	TIME [epoch: 9.01 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35918876989802623		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.35918876989802623 | validation: 0.48096974078775073]
	TIME [epoch: 9.02 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40133406178628694		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.40133406178628694 | validation: 0.5364751201140424]
	TIME [epoch: 9.02 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3683529910848097		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.3683529910848097 | validation: 0.7011662268456555]
	TIME [epoch: 9.02 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32730031562016926		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.32730031562016926 | validation: 0.28923347362628904]
	TIME [epoch: 9.03 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37955566179461137		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.37955566179461137 | validation: 0.23928066325622738]
	TIME [epoch: 9.02 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33789939265305935		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.33789939265305935 | validation: 0.7234854965495459]
	TIME [epoch: 9.03 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30910397261665185		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.30910397261665185 | validation: 0.17839037479708317]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36067256944771114		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.36067256944771114 | validation: 0.21842925465273805]
	TIME [epoch: 9.04 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34209804397556703		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.34209804397556703 | validation: 0.4038834525435681]
	TIME [epoch: 9.04 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30763866793544486		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.30763866793544486 | validation: 0.5697240628410186]
	TIME [epoch: 9.02 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3362087838838077		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.3362087838838077 | validation: 0.9089390432631022]
	TIME [epoch: 9.02 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3409691359931348		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.3409691359931348 | validation: 0.20231813622934947]
	TIME [epoch: 9.02 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36783931271047565		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.36783931271047565 | validation: 0.26180173687631114]
	TIME [epoch: 9.02 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2794595825087897		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.2794595825087897 | validation: 0.6963074175634572]
	TIME [epoch: 9.04 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2904826116852834		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.2904826116852834 | validation: 0.3658240171789592]
	TIME [epoch: 9.02 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.306528210446281		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.306528210446281 | validation: 0.30468705169076804]
	TIME [epoch: 9.03 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31889908087073915		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.31889908087073915 | validation: 0.4266913570626256]
	TIME [epoch: 9.02 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.304615192833901		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.304615192833901 | validation: 0.3347688534046702]
	TIME [epoch: 9.04 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29822837761547627		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.29822837761547627 | validation: 0.27427933472917637]
	TIME [epoch: 9.04 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2798888032919853		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.2798888032919853 | validation: 0.29761286081726934]
	TIME [epoch: 9.02 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29473665577233976		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.29473665577233976 | validation: 0.28610390569621397]
	TIME [epoch: 9.03 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2779936550076639		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.2779936550076639 | validation: 0.6880085711235234]
	TIME [epoch: 9.03 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33909384899592265		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.33909384899592265 | validation: 0.2001802531152399]
	TIME [epoch: 9.05 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728253248435605		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.2728253248435605 | validation: 0.36018411489807534]
	TIME [epoch: 9.05 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38001838970652313		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.38001838970652313 | validation: 0.48285477275950367]
	TIME [epoch: 9.03 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44052075579497413		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.44052075579497413 | validation: 0.5475295883999493]
	TIME [epoch: 9.04 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30618639987895585		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.30618639987895585 | validation: 0.5007024804946991]
	TIME [epoch: 9.03 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37811814320917		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.37811814320917 | validation: 0.35625098337057676]
	TIME [epoch: 9.04 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3282529856348722		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.3282529856348722 | validation: 0.30296080392377595]
	TIME [epoch: 9.05 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35118213762864536		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.35118213762864536 | validation: 0.6045389451190067]
	TIME [epoch: 9.04 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3036323419202902		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.3036323419202902 | validation: 0.3149764880044982]
	TIME [epoch: 9.04 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3308988577956444		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.3308988577956444 | validation: 0.3004905664474371]
	TIME [epoch: 9.03 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.253716600991519		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.253716600991519 | validation: 0.27027318435052433]
	TIME [epoch: 9.03 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296585601295947		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.2296585601295947 | validation: 0.8304717503543644]
	TIME [epoch: 9.03 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3444906354637804		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.3444906354637804 | validation: 0.2502293887049124]
	TIME [epoch: 9.03 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4094464376846004		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.4094464376846004 | validation: 0.2172907981086568]
	TIME [epoch: 9.03 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22252530124394349		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.22252530124394349 | validation: 0.3985286980745744]
	TIME [epoch: 9.04 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2835012163294016		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.2835012163294016 | validation: 0.3071766478660304]
	TIME [epoch: 9.05 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30846021206754637		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.30846021206754637 | validation: 0.2741976507048655]
	TIME [epoch: 9.05 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32083840998150415		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.32083840998150415 | validation: 0.19811703465143873]
	TIME [epoch: 9.02 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2949581843874577		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.2949581843874577 | validation: 0.21750028020190698]
	TIME [epoch: 9.03 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3058807035879714		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.3058807035879714 | validation: 0.3500776533940456]
	TIME [epoch: 9.02 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31497276696176757		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.31497276696176757 | validation: 0.23881345107772584]
	TIME [epoch: 9.05 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2826868933928692		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.2826868933928692 | validation: 0.4072727917788868]
	TIME [epoch: 9.05 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24380347539623165		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.24380347539623165 | validation: 0.49484145017763426]
	TIME [epoch: 9.02 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29109964901854457		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.29109964901854457 | validation: 0.23245716584128037]
	TIME [epoch: 9.03 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32480502387219035		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.32480502387219035 | validation: 0.32887038091110754]
	TIME [epoch: 9.02 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31330492089026		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.31330492089026 | validation: 0.21852775544408076]
	TIME [epoch: 9.03 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3204690410617683		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.3204690410617683 | validation: 0.24445760268869757]
	TIME [epoch: 9.05 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34046186046144417		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.34046186046144417 | validation: 0.194886321856003]
	TIME [epoch: 9.03 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32525921272407904		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.32525921272407904 | validation: 0.41131273458861994]
	TIME [epoch: 9.03 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4831114338962356		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.4831114338962356 | validation: 0.28201373140132113]
	TIME [epoch: 9.03 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2484245109838899		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.2484245109838899 | validation: 0.261207946065838]
	TIME [epoch: 9.03 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25673766960292643		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.25673766960292643 | validation: 0.2873440165770592]
	TIME [epoch: 9.05 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29446004959775884		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.29446004959775884 | validation: 0.2722433260167161]
	TIME [epoch: 9.02 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29722762873428665		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.29722762873428665 | validation: 0.26757917891954835]
	TIME [epoch: 9.03 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2479026056228933		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.2479026056228933 | validation: 0.4099681638422995]
	TIME [epoch: 9.02 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29978063323812226		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.29978063323812226 | validation: 0.23632598210555356]
	TIME [epoch: 9.02 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2962653222065039		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.2962653222065039 | validation: 0.3437490417183965]
	TIME [epoch: 9.05 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47657998275904295		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.47657998275904295 | validation: 0.22054050732866476]
	TIME [epoch: 9.01 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2572416966338963		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.2572416966338963 | validation: 0.20016876007576323]
	TIME [epoch: 9.03 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27029369823235505		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.27029369823235505 | validation: 0.5429359976771367]
	TIME [epoch: 9.02 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27742241316854377		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.27742241316854377 | validation: 0.26197626588674466]
	TIME [epoch: 9.04 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27545889357402237		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.27545889357402237 | validation: 0.24610057672862556]
	TIME [epoch: 9.05 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.331291236785816		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.331291236785816 | validation: 0.7267335454456226]
	TIME [epoch: 9.03 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34362746221828505		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.34362746221828505 | validation: 0.22538071729359727]
	TIME [epoch: 9.03 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24836744168293595		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.24836744168293595 | validation: 0.24358867735551812]
	TIME [epoch: 9.02 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24778767397411233		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.24778767397411233 | validation: 0.23600339329931264]
	TIME [epoch: 9.02 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2481146170440857		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.2481146170440857 | validation: 0.25302669873665495]
	TIME [epoch: 9.05 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797538128203895		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.2797538128203895 | validation: 0.23156275332642853]
	TIME [epoch: 9.01 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2590614600293496		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.2590614600293496 | validation: 0.47296332998201257]
	TIME [epoch: 9.02 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2957881769746518		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.2957881769746518 | validation: 0.21595168650220603]
	TIME [epoch: 9.04 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29711605074266717		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.29711605074266717 | validation: 0.17991197789711427]
	TIME [epoch: 9.01 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2374736076785839		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.2374736076785839 | validation: 0.20694996852495023]
	TIME [epoch: 9.05 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22003455960552185		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.22003455960552185 | validation: 0.29254684530580977]
	TIME [epoch: 9.02 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21012930741455288		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.21012930741455288 | validation: 0.17700695131815652]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19831705249644102		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.19831705249644102 | validation: 0.1851641169024284]
	TIME [epoch: 9.03 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23339409943025405		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.23339409943025405 | validation: 0.18767171986675754]
	TIME [epoch: 9.02 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31644514836580384		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.31644514836580384 | validation: 0.32572277639615005]
	TIME [epoch: 9.06 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30740076003413985		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.30740076003413985 | validation: 0.2815302683406273]
	TIME [epoch: 9.01 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23707322796545097		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.23707322796545097 | validation: 0.2405505083863131]
	TIME [epoch: 9.02 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2300049384496659		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.2300049384496659 | validation: 0.44609234723721997]
	TIME [epoch: 9.02 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3230637287896688		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.3230637287896688 | validation: 0.20524416150296015]
	TIME [epoch: 9.01 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23978198539879675		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.23978198539879675 | validation: 0.3184496432014774]
	TIME [epoch: 9.05 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26051562806173834		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.26051562806173834 | validation: 0.24080859356015658]
	TIME [epoch: 9.01 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2547991333038751		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.2547991333038751 | validation: 0.2556249649670553]
	TIME [epoch: 9.02 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2703671705979319		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.2703671705979319 | validation: 0.2892635199758805]
	TIME [epoch: 9.02 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2301820294042511		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.2301820294042511 | validation: 0.16193814080644914]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_317.pth
	Model improved!!!
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2465057509800725		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.2465057509800725 | validation: 0.2709476561781888]
	TIME [epoch: 9.07 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2570661460341598		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.2570661460341598 | validation: 0.34301218034571423]
	TIME [epoch: 9.03 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27939364989321797		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.27939364989321797 | validation: 0.18887123258561234]
	TIME [epoch: 9.04 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2548305529831444		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.2548305529831444 | validation: 0.22481664957259917]
	TIME [epoch: 9.02 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21643924553979152		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.21643924553979152 | validation: 0.2743862284815186]
	TIME [epoch: 9.02 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24644260265054418		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.24644260265054418 | validation: 0.17853055300340626]
	TIME [epoch: 9.05 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25884600476289144		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.25884600476289144 | validation: 0.24895888867486798]
	TIME [epoch: 9.02 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23685785122443268		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.23685785122443268 | validation: 0.20106400579596007]
	TIME [epoch: 9.03 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.274848967751289		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.274848967751289 | validation: 0.35516428699633595]
	TIME [epoch: 9.03 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3045298222413324		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.3045298222413324 | validation: 0.238083532318056]
	TIME [epoch: 9.03 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2512511053025267		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.2512511053025267 | validation: 0.4874658901919555]
	TIME [epoch: 9.05 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2725542943441389		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.2725542943441389 | validation: 0.1755845333487735]
	TIME [epoch: 9.03 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28470299687890965		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.28470299687890965 | validation: 0.3009824014983035]
	TIME [epoch: 9.02 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2688663394613311		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.2688663394613311 | validation: 0.2510829058724562]
	TIME [epoch: 9.02 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2602419059726161		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.2602419059726161 | validation: 0.24516563339317127]
	TIME [epoch: 9.02 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3272219074655509		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.3272219074655509 | validation: 0.372830478772016]
	TIME [epoch: 9.06 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2263243475548719		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.2263243475548719 | validation: 0.21288064712925986]
	TIME [epoch: 9.03 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30049169425133826		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.30049169425133826 | validation: 0.23148251890779284]
	TIME [epoch: 9.02 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27830956024852915		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.27830956024852915 | validation: 0.23306605413492604]
	TIME [epoch: 9.02 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.233331639405893		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.233331639405893 | validation: 0.2951283079492869]
	TIME [epoch: 9.01 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30452628769163614		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.30452628769163614 | validation: 0.25377940045300496]
	TIME [epoch: 9.04 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3235567775141902		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.3235567775141902 | validation: 0.9149491375766811]
	TIME [epoch: 9.02 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29799997049763427		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.29799997049763427 | validation: 0.25051380270723717]
	TIME [epoch: 9.01 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.256580064948327		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.256580064948327 | validation: 0.28934041478095546]
	TIME [epoch: 9.03 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22527806943821244		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.22527806943821244 | validation: 0.1571302521264908]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_342.pth
	Model improved!!!
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2130139496902487		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.2130139496902487 | validation: 0.2749775609760368]
	TIME [epoch: 9.07 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2594252511550329		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.2594252511550329 | validation: 0.6723437747288724]
	TIME [epoch: 9.05 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811525331465777		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.2811525331465777 | validation: 0.20567564623731194]
	TIME [epoch: 9.04 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19010565666009208		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.19010565666009208 | validation: 0.22471944525100707]
	TIME [epoch: 9.05 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1889155086754324		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.1889155086754324 | validation: 0.18304855598371905]
	TIME [epoch: 9.04 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25359149659363417		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.25359149659363417 | validation: 0.2811932362186942]
	TIME [epoch: 9.07 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23032699242967594		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.23032699242967594 | validation: 0.2203854223863358]
	TIME [epoch: 9.04 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2827085409547477		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.2827085409547477 | validation: 0.2486520166870872]
	TIME [epoch: 9.04 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788625716078999		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.2788625716078999 | validation: 0.29535116454453025]
	TIME [epoch: 9.04 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35746141995419245		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.35746141995419245 | validation: 0.46505215017204576]
	TIME [epoch: 9.03 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23881793335541374		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.23881793335541374 | validation: 0.16930520261864812]
	TIME [epoch: 9.04 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2773770349169316		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.2773770349169316 | validation: 0.22198341802687985]
	TIME [epoch: 9.06 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2774369127132345		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.2774369127132345 | validation: 0.21162076491265375]
	TIME [epoch: 9.03 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.208998152073422		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.208998152073422 | validation: 0.19528106884186383]
	TIME [epoch: 9.04 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23597331773456148		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.23597331773456148 | validation: 0.2212261180744175]
	TIME [epoch: 9.03 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25243881606486795		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.25243881606486795 | validation: 0.19657260016181546]
	TIME [epoch: 9.04 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21431604440629387		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.21431604440629387 | validation: 0.2112005225649222]
	TIME [epoch: 9.07 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17745554714956002		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.17745554714956002 | validation: 0.1678067361263409]
	TIME [epoch: 9.04 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1976456106324311		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.1976456106324311 | validation: 0.21691048280810823]
	TIME [epoch: 9.04 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21183628816021266		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.21183628816021266 | validation: 0.2146840965281605]
	TIME [epoch: 9.03 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2549493888402542		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.2549493888402542 | validation: 0.15634095947628535]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_363.pth
	Model improved!!!
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1977302826857225		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.1977302826857225 | validation: 0.16933034769604627]
	TIME [epoch: 9.07 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26457888536729846		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.26457888536729846 | validation: 0.33055335749667736]
	TIME [epoch: 9.04 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24697939621008316		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.24697939621008316 | validation: 0.16230466814473327]
	TIME [epoch: 9.05 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20349497311693776		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.20349497311693776 | validation: 0.2642942030454671]
	TIME [epoch: 9.04 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2016215961065412		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.2016215961065412 | validation: 0.25859796072079433]
	TIME [epoch: 9.03 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20097553572427299		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.20097553572427299 | validation: 0.18672003508714824]
	TIME [epoch: 9.06 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2831331552578396		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.2831331552578396 | validation: 0.4056188778525329]
	TIME [epoch: 9.03 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2564311784953727		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.2564311784953727 | validation: 0.2356177793181004]
	TIME [epoch: 9.04 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2636169138422839		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.2636169138422839 | validation: 0.1707878557323022]
	TIME [epoch: 9.04 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24760968790516852		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.24760968790516852 | validation: 0.2151664420657473]
	TIME [epoch: 9.05 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20957782462805113		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.20957782462805113 | validation: 0.23518314316076222]
	TIME [epoch: 9.07 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24827473428812405		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.24827473428812405 | validation: 0.231727354401686]
	TIME [epoch: 9.03 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19279089737693147		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.19279089737693147 | validation: 0.19664889613393294]
	TIME [epoch: 9.04 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18631871997351973		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.18631871997351973 | validation: 0.3027273145948286]
	TIME [epoch: 9.04 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2717646403332235		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.2717646403332235 | validation: 0.16437847198733807]
	TIME [epoch: 9.04 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20981248209704612		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.20981248209704612 | validation: 0.18072949054241133]
	TIME [epoch: 9.06 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18164119857007843		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.18164119857007843 | validation: 0.22467212722091895]
	TIME [epoch: 9.05 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2098347620535931		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.2098347620535931 | validation: 0.16578008801680366]
	TIME [epoch: 9.05 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28316503587405706		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.28316503587405706 | validation: 0.27737353883225113]
	TIME [epoch: 9.04 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27121015732964043		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.27121015732964043 | validation: 0.19398054027902611]
	TIME [epoch: 9.04 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21596906629544246		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.21596906629544246 | validation: 0.179194903042308]
	TIME [epoch: 9.07 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20891627241432684		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.20891627241432684 | validation: 0.20544727768149423]
	TIME [epoch: 9.06 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1710695116550956		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.1710695116550956 | validation: 0.18993021709190092]
	TIME [epoch: 9.05 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1919870396724875		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.1919870396724875 | validation: 0.17492380520249895]
	TIME [epoch: 9.05 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17715721861278377		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.17715721861278377 | validation: 0.17827181657214483]
	TIME [epoch: 9.04 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20513986449528368		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.20513986449528368 | validation: 0.1941228981143249]
	TIME [epoch: 9.06 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2262698339211378		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.2262698339211378 | validation: 0.24814927944926224]
	TIME [epoch: 9.04 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.203872073812475		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.203872073812475 | validation: 0.17638663989381145]
	TIME [epoch: 9.04 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17233308308530942		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.17233308308530942 | validation: 0.14551702500207048]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_392.pth
	Model improved!!!
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2297829561212786		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.2297829561212786 | validation: 0.24551738142644197]
	TIME [epoch: 9.04 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18172186217371783		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.18172186217371783 | validation: 0.15656441095212706]
	TIME [epoch: 9.06 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18837265024665217		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.18837265024665217 | validation: 0.2412521503669955]
	TIME [epoch: 9.04 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1886987345298798		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.1886987345298798 | validation: 0.23754063323185526]
	TIME [epoch: 9.04 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2214236826562693		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.2214236826562693 | validation: 0.17794891249924033]
	TIME [epoch: 9.04 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23018878890986344		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.23018878890986344 | validation: 0.17650719161998518]
	TIME [epoch: 9.04 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2099383811782966		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.2099383811782966 | validation: 0.16668566327639062]
	TIME [epoch: 9.07 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18730712634654534		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.18730712634654534 | validation: 0.2586137618640968]
	TIME [epoch: 9.05 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040052237235666		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.2040052237235666 | validation: 0.18409973050879114]
	TIME [epoch: 9.04 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18731006057759567		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.18731006057759567 | validation: 0.25041930539261464]
	TIME [epoch: 9.04 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25837281208375745		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.25837281208375745 | validation: 0.23955649217299826]
	TIME [epoch: 9.03 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1897581376640022		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.1897581376640022 | validation: 0.16898762780571008]
	TIME [epoch: 9.04 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2111462898389791		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.2111462898389791 | validation: 0.149724718876291]
	TIME [epoch: 9.06 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21604373336298624		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.21604373336298624 | validation: 0.15578706697707517]
	TIME [epoch: 9.04 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18484391375308956		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.18484391375308956 | validation: 0.27785088496335575]
	TIME [epoch: 9.04 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20772016031022905		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.20772016031022905 | validation: 0.22410518500216345]
	TIME [epoch: 9.03 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21331279896613659		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.21331279896613659 | validation: 0.19672941774776104]
	TIME [epoch: 9.04 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20193046703439763		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.20193046703439763 | validation: 0.15572606233395805]
	TIME [epoch: 9.06 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18373742826776313		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.18373742826776313 | validation: 0.22453623566625486]
	TIME [epoch: 9.03 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21334997165435152		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.21334997165435152 | validation: 0.16112486744721344]
	TIME [epoch: 9.04 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915614980890649		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.1915614980890649 | validation: 0.24414493481954605]
	TIME [epoch: 9.04 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23330406126751074		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.23330406126751074 | validation: 0.19493074699081347]
	TIME [epoch: 9.04 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25412142573621366		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.25412142573621366 | validation: 0.1754202568725411]
	TIME [epoch: 9.05 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21849956097482717		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.21849956097482717 | validation: 0.2230328001649308]
	TIME [epoch: 9.02 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20941119318865886		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.20941119318865886 | validation: 0.21827357048789023]
	TIME [epoch: 9.03 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23356081585582916		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.23356081585582916 | validation: 0.13724396925179724]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_418.pth
	Model improved!!!
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20193057746717566		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.20193057746717566 | validation: 0.20901376216146833]
	TIME [epoch: 9.04 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1649531738215029		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.1649531738215029 | validation: 0.15888430573358925]
	TIME [epoch: 9.06 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.163705048289029		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.163705048289029 | validation: 0.17891910640285058]
	TIME [epoch: 9.03 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16550273974217372		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.16550273974217372 | validation: 0.35580209804273755]
	TIME [epoch: 9.04 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29076767379573726		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.29076767379573726 | validation: 0.2753525942042292]
	TIME [epoch: 9.03 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2000143702251263		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.2000143702251263 | validation: 0.1406544657953852]
	TIME [epoch: 9.04 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18103325541064152		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.18103325541064152 | validation: 0.14932087093649943]
	TIME [epoch: 9.06 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18862005800004558		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.18862005800004558 | validation: 0.14591064698752318]
	TIME [epoch: 9.04 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18135815394687357		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.18135815394687357 | validation: 0.14401158114234408]
	TIME [epoch: 9.04 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2251199437564339		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.2251199437564339 | validation: 0.33683771503353516]
	TIME [epoch: 9.03 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20893658747992894		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.20893658747992894 | validation: 0.17892600003877485]
	TIME [epoch: 9.04 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18066636172977457		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.18066636172977457 | validation: 0.1512524941270909]
	TIME [epoch: 9.07 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063586984756459		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.2063586984756459 | validation: 0.21112441702500334]
	TIME [epoch: 9.04 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22430326126216632		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.22430326126216632 | validation: 0.17464385695638213]
	TIME [epoch: 9.04 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18868446700805258		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.18868446700805258 | validation: 0.222465353231929]
	TIME [epoch: 9.04 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20876152182382463		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.20876152182382463 | validation: 0.21241878503204054]
	TIME [epoch: 9.05 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19322848590294645		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.19322848590294645 | validation: 0.2482716198263822]
	TIME [epoch: 9.07 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16195075442588208		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.16195075442588208 | validation: 0.20407095718977936]
	TIME [epoch: 9.05 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18442374302251457		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.18442374302251457 | validation: 0.15967311166480055]
	TIME [epoch: 9.06 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2212467185576509		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.2212467185576509 | validation: 0.1811879338427505]
	TIME [epoch: 9.04 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17581635358897357		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.17581635358897357 | validation: 0.23425275815273888]
	TIME [epoch: 9.04 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20501749400592661		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.20501749400592661 | validation: 0.24264799084217392]
	TIME [epoch: 9.07 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1953630154823467		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.1953630154823467 | validation: 0.15018416280859057]
	TIME [epoch: 9.04 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2051864610404853		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.2051864610404853 | validation: 0.15097352663059227]
	TIME [epoch: 9.05 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17669258663913542		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.17669258663913542 | validation: 0.16254391237010848]
	TIME [epoch: 9.04 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17623670554002538		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.17623670554002538 | validation: 0.17542903121484893]
	TIME [epoch: 9.04 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23905638949532512		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.23905638949532512 | validation: 0.344073584148024]
	TIME [epoch: 9.06 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2287659057427128		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.2287659057427128 | validation: 0.2287692537986478]
	TIME [epoch: 9.04 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16500197321607155		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.16500197321607155 | validation: 0.1814271797364089]
	TIME [epoch: 9.03 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20572988451051785		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.20572988451051785 | validation: 0.1649133448487316]
	TIME [epoch: 9.03 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16840480710471864		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.16840480710471864 | validation: 0.2410120215558561]
	TIME [epoch: 9.05 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1942694913724087		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.1942694913724087 | validation: 0.2093469784014937]
	TIME [epoch: 9.06 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19276972273277845		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.19276972273277845 | validation: 0.16179308315926372]
	TIME [epoch: 9.04 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1850141015020222		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.1850141015020222 | validation: 0.19443844840063063]
	TIME [epoch: 9.05 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17211801376535288		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.17211801376535288 | validation: 0.21787746017228005]
	TIME [epoch: 9.04 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20052787707927872		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.20052787707927872 | validation: 0.14774448938372609]
	TIME [epoch: 9.04 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14618216294956535		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.14618216294956535 | validation: 0.16320561701826222]
	TIME [epoch: 9.05 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15977044791697087		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.15977044791697087 | validation: 0.237618657023072]
	TIME [epoch: 9.03 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22504189995844545		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.22504189995844545 | validation: 0.16611498285509763]
	TIME [epoch: 9.03 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20389468986022705		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.20389468986022705 | validation: 0.30789603105218943]
	TIME [epoch: 9.03 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16840227739261499		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.16840227739261499 | validation: 0.23082960913799305]
	TIME [epoch: 9.02 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19264867486989906		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.19264867486989906 | validation: 0.2156209310158031]
	TIME [epoch: 9.05 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1735377897046881		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.1735377897046881 | validation: 0.14411983875310774]
	TIME [epoch: 9.02 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.185856415769317		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.185856415769317 | validation: 0.16745157126558685]
	TIME [epoch: 9.03 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.170171147293545		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.170171147293545 | validation: 0.23219509210173106]
	TIME [epoch: 9.02 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1587705237856541		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.1587705237856541 | validation: 0.17830767079935936]
	TIME [epoch: 9.03 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18662456259723265		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.18662456259723265 | validation: 0.25158903098699636]
	TIME [epoch: 9.05 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18048750728472057		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.18048750728472057 | validation: 0.1868077798759307]
	TIME [epoch: 9.04 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.164574085550798		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.164574085550798 | validation: 0.22242002392966415]
	TIME [epoch: 9.03 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18577807737144084		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.18577807737144084 | validation: 0.24553240389721726]
	TIME [epoch: 9.02 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1740605836584048		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.1740605836584048 | validation: 0.1903636735214964]
	TIME [epoch: 9.02 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1684442175646069		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.1684442175646069 | validation: 0.20859886103484448]
	TIME [epoch: 9.03 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16515230250802673		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.16515230250802673 | validation: 0.18766088975152007]
	TIME [epoch: 9.03 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22382902393480633		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.22382902393480633 | validation: 0.22920884123716023]
	TIME [epoch: 9.03 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19789571237688247		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.19789571237688247 | validation: 0.16867336403555072]
	TIME [epoch: 9.02 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15325478949554946		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.15325478949554946 | validation: 0.24611418583955208]
	TIME [epoch: 9.02 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2012621377192449		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.2012621377192449 | validation: 0.16889506648910932]
	TIME [epoch: 9.04 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15415620393101864		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.15415620393101864 | validation: 0.15582481971198478]
	TIME [epoch: 9.04 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18432192271578135		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.18432192271578135 | validation: 0.1297771976000185]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_477.pth
	Model improved!!!
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14413599120617257		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.14413599120617257 | validation: 0.25016533134786034]
	TIME [epoch: 9.04 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17115899909434681		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.17115899909434681 | validation: 0.1651345283743135]
	TIME [epoch: 9.03 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.181091880295966		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.181091880295966 | validation: 0.19536917367773776]
	TIME [epoch: 9.04 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1650354608592275		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.1650354608592275 | validation: 0.23954543039765253]
	TIME [epoch: 9.03 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20170156137426093		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.20170156137426093 | validation: 0.12138232091749242]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_482.pth
	Model improved!!!
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17363975114053976		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.17363975114053976 | validation: 0.1986585820447996]
	TIME [epoch: 9.02 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19557522892959173		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.19557522892959173 | validation: 0.1571288004907045]
	TIME [epoch: 9.02 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13952960190738473		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.13952960190738473 | validation: 0.12307369162620573]
	TIME [epoch: 9.03 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513300934424572		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.1513300934424572 | validation: 0.1143999784487448]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_486.pth
	Model improved!!!
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1557286939134444		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.1557286939134444 | validation: 0.20361449523623204]
	TIME [epoch: 9.02 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1449111352482833		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.1449111352482833 | validation: 0.1580581011295764]
	TIME [epoch: 9.02 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18298586519961182		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.18298586519961182 | validation: 0.12727341499133282]
	TIME [epoch: 9.02 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17104802407361114		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.17104802407361114 | validation: 0.17925063178303052]
	TIME [epoch: 9.02 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1526647842397666		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.1526647842397666 | validation: 0.24910105616517098]
	TIME [epoch: 9.05 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18176605435419088		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.18176605435419088 | validation: 0.20950267078573062]
	TIME [epoch: 9.03 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14479940169232072		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.14479940169232072 | validation: 0.15650377857355724]
	TIME [epoch: 9.03 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1858690247679465		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.1858690247679465 | validation: 0.16466243331306918]
	TIME [epoch: 9.01 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14323372029697123		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.14323372029697123 | validation: 0.17868676923139795]
	TIME [epoch: 9.02 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1596742149829838		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.1596742149829838 | validation: 0.13698536928473465]
	TIME [epoch: 9.03 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1351402546605935		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.1351402546605935 | validation: 0.21987968322165385]
	TIME [epoch: 9.02 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16344367802358478		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.16344367802358478 | validation: 0.19815173865557817]
	TIME [epoch: 9.02 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14810885790683673		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.14810885790683673 | validation: 0.14717114727455924]
	TIME [epoch: 9.01 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15688161755801952		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.15688161755801952 | validation: 0.15361396002656313]
	TIME [epoch: 9.01 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14123315038659973		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.14123315038659973 | validation: 0.1448589092387592]
	TIME [epoch: 9.01 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541560942221409		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.1541560942221409 | validation: 0.181443959932242]
	TIME [epoch: 9.04 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14595346237732068		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.14595346237732068 | validation: 0.16606937276938433]
	TIME [epoch: 9.02 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.139362857024222		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.139362857024222 | validation: 0.15624965619597436]
	TIME [epoch: 9.02 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14874878124852492		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.14874878124852492 | validation: 0.19430267507267046]
	TIME [epoch: 9.03 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1462332926807217		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.1462332926807217 | validation: 0.15923091244518583]
	TIME [epoch: 9.02 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18044101600439638		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.18044101600439638 | validation: 0.15890019194351385]
	TIME [epoch: 9.04 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17868478099834786		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.17868478099834786 | validation: 0.1509314004410538]
	TIME [epoch: 9.02 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14620035934703718		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.14620035934703718 | validation: 0.2730784831117229]
	TIME [epoch: 9.02 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13931803209245386		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.13931803209245386 | validation: 0.12934862036027772]
	TIME [epoch: 9.02 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18226798511152292		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.18226798511152292 | validation: 0.16828163633208534]
	TIME [epoch: 9.02 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17143984597522838		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.17143984597522838 | validation: 0.1702797635232053]
	TIME [epoch: 9.04 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14372614553962423		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.14372614553962423 | validation: 0.1647220256073448]
	TIME [epoch: 9.02 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16700243268159623		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.16700243268159623 | validation: 0.19240298546716839]
	TIME [epoch: 9.01 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14421298801570784		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.14421298801570784 | validation: 0.13098320865361793]
	TIME [epoch: 9.01 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12989195496102474		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.12989195496102474 | validation: 0.13411884265909346]
	TIME [epoch: 9.01 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1277407613920865		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.1277407613920865 | validation: 0.1877876030477308]
	TIME [epoch: 9.05 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15086541370700843		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.15086541370700843 | validation: 0.18035861922791188]
	TIME [epoch: 9.03 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16757796423811983		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.16757796423811983 | validation: 0.2562057925766169]
	TIME [epoch: 9.03 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14859781955535187		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.14859781955535187 | validation: 0.15859721121997855]
	TIME [epoch: 9.03 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13402848335477974		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.13402848335477974 | validation: 0.13966027244887083]
	TIME [epoch: 9.02 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11869902806044166		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.11869902806044166 | validation: 0.2369017977723369]
	TIME [epoch: 9.04 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14419944230069315		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.14419944230069315 | validation: 0.1616471090273111]
	TIME [epoch: 9.02 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14817448755064275		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.14817448755064275 | validation: 0.17168503970868876]
	TIME [epoch: 9.02 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265414720494779		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.1265414720494779 | validation: 0.16096020541971617]
	TIME [epoch: 9.02 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16025042892321975		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.16025042892321975 | validation: 0.15464539187133322]
	TIME [epoch: 9.02 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15502949446677033		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.15502949446677033 | validation: 0.15616275753147152]
	TIME [epoch: 9.04 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1525497477690932		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.1525497477690932 | validation: 0.13721267438815493]
	TIME [epoch: 9.02 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1518366550154488		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.1518366550154488 | validation: 0.17590416884979174]
	TIME [epoch: 9.01 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11701888194359375		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.11701888194359375 | validation: 0.10823984002486953]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_530.pth
	Model improved!!!
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11927857911805126		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.11927857911805126 | validation: 0.252871003703279]
	TIME [epoch: 9.02 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1546701586846552		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.1546701586846552 | validation: 0.1360757619380437]
	TIME [epoch: 9.05 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1283902585561211		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.1283902585561211 | validation: 0.13572911989347936]
	TIME [epoch: 9.01 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11662808375987728		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.11662808375987728 | validation: 0.10568711900604322]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_534.pth
	Model improved!!!
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13319640996994703		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.13319640996994703 | validation: 0.12910139432658832]
	TIME [epoch: 9.02 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13252144965152596		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.13252144965152596 | validation: 0.1515910676821958]
	TIME [epoch: 9.01 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14515061980007526		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.14515061980007526 | validation: 0.1431114007002171]
	TIME [epoch: 9.03 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11244016054500486		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.11244016054500486 | validation: 0.15841023050815395]
	TIME [epoch: 9.02 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12272911557251823		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.12272911557251823 | validation: 0.13119361351915526]
	TIME [epoch: 9.01 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1508437616039045		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.1508437616039045 | validation: 0.15111824944655175]
	TIME [epoch: 9.02 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1330733664739456		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.1330733664739456 | validation: 0.12800419484498582]
	TIME [epoch: 9.01 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13422006781623755		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.13422006781623755 | validation: 0.14654493857594447]
	TIME [epoch: 9.03 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16113563874747877		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.16113563874747877 | validation: 0.1494417744660515]
	TIME [epoch: 9.03 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14023677851836033		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.14023677851836033 | validation: 0.12392379356499407]
	TIME [epoch: 9.02 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12394917853189832		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.12394917853189832 | validation: 0.15749221561442237]
	TIME [epoch: 9.02 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18023414181888303		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.18023414181888303 | validation: 0.1368905562224121]
	TIME [epoch: 9.02 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12652536262778302		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.12652536262778302 | validation: 0.15993949842712626]
	TIME [epoch: 9.02 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1419634936020484		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.1419634936020484 | validation: 0.1642595218474885]
	TIME [epoch: 9.04 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1448024808624323		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.1448024808624323 | validation: 0.13273396002797958]
	TIME [epoch: 9.01 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15002151348924464		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.15002151348924464 | validation: 0.13413669924622018]
	TIME [epoch: 9.02 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11901423097960606		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.11901423097960606 | validation: 0.1190190885689015]
	TIME [epoch: 9.02 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13073034753260315		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.13073034753260315 | validation: 0.13162904622904678]
	TIME [epoch: 9.02 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13467233696445666		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.13467233696445666 | validation: 0.13201778248937818]
	TIME [epoch: 9.04 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14046577473793875		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.14046577473793875 | validation: 0.11110108458852673]
	TIME [epoch: 9.01 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12655808279654499		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.12655808279654499 | validation: 0.17976552023922782]
	TIME [epoch: 9.02 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.168070315793873		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.168070315793873 | validation: 0.2357468496456478]
	TIME [epoch: 9.01 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19812389862634716		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.19812389862634716 | validation: 0.13170712779923743]
	TIME [epoch: 9.02 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289963836762697		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.1289963836762697 | validation: 0.13444684287917097]
	TIME [epoch: 9.05 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11819817017951521		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.11819817017951521 | validation: 0.12575032800632782]
	TIME [epoch: 9.02 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11975624654383314		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.11975624654383314 | validation: 0.13051094363852014]
	TIME [epoch: 9.02 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1238623099144464		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.1238623099144464 | validation: 0.12586747018926142]
	TIME [epoch: 9.01 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12813611717434245		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.12813611717434245 | validation: 0.15692573724282577]
	TIME [epoch: 9.01 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562515736004629		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.1562515736004629 | validation: 0.17217731302435169]
	TIME [epoch: 9.04 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13551192895231523		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.13551192895231523 | validation: 0.14006513525342662]
	TIME [epoch: 9.01 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12298445049009019		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.12298445049009019 | validation: 0.13511347678537777]
	TIME [epoch: 9.02 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13352387876728597		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.13352387876728597 | validation: 0.14458568695873275]
	TIME [epoch: 9.02 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13942266444858023		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.13942266444858023 | validation: 0.12358818706313549]
	TIME [epoch: 9.01 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11132065122835351		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.11132065122835351 | validation: 0.12104967839271959]
	TIME [epoch: 9.04 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12427792531866533		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.12427792531866533 | validation: 0.11390007423730539]
	TIME [epoch: 9.01 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11430654700809224		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.11430654700809224 | validation: 0.2141261738443143]
	TIME [epoch: 9.02 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335108748560049		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.1335108748560049 | validation: 0.1396745947296271]
	TIME [epoch: 9.03 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12486490476724892		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.12486490476724892 | validation: 0.11391491144721219]
	TIME [epoch: 9.02 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1677658149050999		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.1677658149050999 | validation: 0.12486371657238254]
	TIME [epoch: 9.05 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10502555790230961		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.10502555790230961 | validation: 0.12053749527167429]
	TIME [epoch: 9.01 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13337257102309447		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.13337257102309447 | validation: 0.16291149218324705]
	TIME [epoch: 9.02 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15647355743633046		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.15647355743633046 | validation: 0.19772133262555902]
	TIME [epoch: 9.02 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13873083207421516		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.13873083207421516 | validation: 0.14745791630630367]
	TIME [epoch: 9.01 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14543209872871338		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.14543209872871338 | validation: 0.17696836995105425]
	TIME [epoch: 9.04 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1431055636443715		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.1431055636443715 | validation: 0.1166883713875497]
	TIME [epoch: 9.02 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14119132911726068		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.14119132911726068 | validation: 0.14925446585940763]
	TIME [epoch: 9.02 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12875862413967798		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.12875862413967798 | validation: 0.1331148869368902]
	TIME [epoch: 9.01 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11949492420816903		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.11949492420816903 | validation: 0.15140068991284084]
	TIME [epoch: 9.02 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255844172742165		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.1255844172742165 | validation: 0.1298108162267851]
	TIME [epoch: 9.05 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14978801565781108		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.14978801565781108 | validation: 0.14570670964366605]
	TIME [epoch: 9.02 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13874757014994216		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.13874757014994216 | validation: 0.12497256913481153]
	TIME [epoch: 9.03 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11704042082920693		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.11704042082920693 | validation: 0.11289343024187812]
	TIME [epoch: 9.03 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13765542032897254		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.13765542032897254 | validation: 0.18697470665713245]
	TIME [epoch: 9.02 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13442510307802652		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.13442510307802652 | validation: 0.13357131954933704]
	TIME [epoch: 9.04 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16228708021238109		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.16228708021238109 | validation: 0.139160765558738]
	TIME [epoch: 9.02 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12125646325159915		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.12125646325159915 | validation: 0.1447207766981332]
	TIME [epoch: 9.02 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15172110264929195		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.15172110264929195 | validation: 0.12718908406225624]
	TIME [epoch: 9.02 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13208412362105992		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.13208412362105992 | validation: 0.11277469527489939]
	TIME [epoch: 9.02 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13776096425836476		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.13776096425836476 | validation: 0.13393969114964582]
	TIME [epoch: 9.04 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1346551375672235		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.1346551375672235 | validation: 0.14119148033425016]
	TIME [epoch: 9.01 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12186671974570826		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.12186671974570826 | validation: 0.1336383850865052]
	TIME [epoch: 9.01 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11824671807388484		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.11824671807388484 | validation: 0.14930502151966374]
	TIME [epoch: 9.02 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14323316052303015		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.14323316052303015 | validation: 0.14393110370198123]
	TIME [epoch: 9.02 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12793645100422463		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.12793645100422463 | validation: 0.1694387069242455]
	TIME [epoch: 9.05 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12914806348209426		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.12914806348209426 | validation: 0.14477071650890264]
	TIME [epoch: 9.03 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14285506204561707		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.14285506204561707 | validation: 0.10161720946899709]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_600.pth
	Model improved!!!
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12090666420580254		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.12090666420580254 | validation: 0.11811910604066586]
	TIME [epoch: 9.02 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10971673891222103		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.10971673891222103 | validation: 0.12160384280103306]
	TIME [epoch: 9.01 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11300720458217413		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.11300720458217413 | validation: 0.13669935889153745]
	TIME [epoch: 9.04 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12596098327555977		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.12596098327555977 | validation: 0.11795432114014125]
	TIME [epoch: 9.02 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12977391780735179		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.12977391780735179 | validation: 0.1527007401574872]
	TIME [epoch: 9.02 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11187981384187436		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.11187981384187436 | validation: 0.11972963499613858]
	TIME [epoch: 9.02 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1115354852986706		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.1115354852986706 | validation: 0.11470308580254081]
	TIME [epoch: 9.01 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11639731241153066		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.11639731241153066 | validation: 0.13787153130929103]
	TIME [epoch: 9.04 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.198050098322338		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.198050098322338 | validation: 0.22722227317819596]
	TIME [epoch: 9.02 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16674150664154785		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.16674150664154785 | validation: 0.13463799951993127]
	TIME [epoch: 9.02 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1571311538620639		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.1571311538620639 | validation: 0.12130741585729932]
	TIME [epoch: 9.03 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11834658223184424		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.11834658223184424 | validation: 0.10827245200129598]
	TIME [epoch: 9.02 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316425332955694		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.1316425332955694 | validation: 0.11433599927894492]
	TIME [epoch: 9.03 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11317483437749572		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.11317483437749572 | validation: 0.1275578783011268]
	TIME [epoch: 9.03 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11488520896115659		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.11488520896115659 | validation: 0.11465679000986864]
	TIME [epoch: 9.01 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10557327199766275		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.10557327199766275 | validation: 0.15394289178062143]
	TIME [epoch: 9.02 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334578757373086		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.1334578757373086 | validation: 0.16522149411602122]
	TIME [epoch: 9.01 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14880228516261657		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.14880228516261657 | validation: 0.10523595569645469]
	TIME [epoch: 9.03 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11453744694997052		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.11453744694997052 | validation: 0.12400497755243942]
	TIME [epoch: 9.03 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11928325493702643		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.11928325493702643 | validation: 0.14372456985341603]
	TIME [epoch: 9.01 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13376907725618045		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.13376907725618045 | validation: 0.12233836315735677]
	TIME [epoch: 9.02 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12020562170502698		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.12020562170502698 | validation: 0.11791504320626965]
	TIME [epoch: 9.01 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12488928667214942		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.12488928667214942 | validation: 0.14611268340065844]
	TIME [epoch: 9.03 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11891406000699452		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.11891406000699452 | validation: 0.1187947508800195]
	TIME [epoch: 9.04 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10339378056776291		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.10339378056776291 | validation: 0.11573848769452302]
	TIME [epoch: 9.02 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11281352712887519		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.11281352712887519 | validation: 0.14969384427676813]
	TIME [epoch: 9.03 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12583501445547796		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.12583501445547796 | validation: 0.11881625679730115]
	TIME [epoch: 9.01 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12175970844144013		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.12175970844144013 | validation: 0.13219215637244738]
	TIME [epoch: 9.03 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13600098253270343		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.13600098253270343 | validation: 0.12856791665573464]
	TIME [epoch: 9.04 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1232196667882282		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.1232196667882282 | validation: 0.13618513305048568]
	TIME [epoch: 9.01 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11460099789410541		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.11460099789410541 | validation: 0.12260162579294492]
	TIME [epoch: 9.02 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1191029261760568		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.1191029261760568 | validation: 0.1266021449699416]
	TIME [epoch: 9.02 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12257227236619542		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.12257227236619542 | validation: 0.1464769531524085]
	TIME [epoch: 9.02 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11151936796853264		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.11151936796853264 | validation: 0.11297063413984879]
	TIME [epoch: 9.03 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11734882017471222		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.11734882017471222 | validation: 0.13056934010669127]
	TIME [epoch: 9.01 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12742905614276093		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.12742905614276093 | validation: 0.11902209406980627]
	TIME [epoch: 9.02 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1256806746886372		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.1256806746886372 | validation: 0.2260826528652336]
	TIME [epoch: 9.02 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12828892853501808		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.12828892853501808 | validation: 0.11908610747441874]
	TIME [epoch: 9.03 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1195274379933893		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.1195274379933893 | validation: 0.1274103406782352]
	TIME [epoch: 9.04 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11498974579727979		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.11498974579727979 | validation: 0.12294226024401118]
	TIME [epoch: 9.01 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11662221178822893		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.11662221178822893 | validation: 0.17076397444035327]
	TIME [epoch: 9.01 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1263085743022388		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.1263085743022388 | validation: 0.12629036445585323]
	TIME [epoch: 9.01 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11515123542609644		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.11515123542609644 | validation: 0.117209692475559]
	TIME [epoch: 9.02 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12026490364518731		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.12026490364518731 | validation: 0.11389081134843523]
	TIME [epoch: 9.04 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11339500484526166		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.11339500484526166 | validation: 0.1058467531652856]
	TIME [epoch: 9.01 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09904841670951696		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.09904841670951696 | validation: 0.12918177701497888]
	TIME [epoch: 9.03 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1157672105162125		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.1157672105162125 | validation: 0.10748869153553041]
	TIME [epoch: 9.02 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1205119757452983		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.1205119757452983 | validation: 0.17836256600121386]
	TIME [epoch: 9.03 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12279059030859041		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.12279059030859041 | validation: 0.1148190490371461]
	TIME [epoch: 9.04 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12358437986074129		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.12358437986074129 | validation: 0.16366616901428882]
	TIME [epoch: 9.02 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13469681022034366		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.13469681022034366 | validation: 0.14146707284121607]
	TIME [epoch: 9.03 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1126462733781054		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.1126462733781054 | validation: 0.11059374686905094]
	TIME [epoch: 9.03 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11938452181884614		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.11938452181884614 | validation: 0.12334526789632805]
	TIME [epoch: 9.03 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11256092890813552		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.11256092890813552 | validation: 0.13475756599002323]
	TIME [epoch: 9.03 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1246733577221341		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.1246733577221341 | validation: 0.1309950763273487]
	TIME [epoch: 9.01 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10979645330694257		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.10979645330694257 | validation: 0.11467036370560114]
	TIME [epoch: 9.02 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1069482123848908		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.1069482123848908 | validation: 0.11781041086849847]
	TIME [epoch: 9.02 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10337168495417708		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.10337168495417708 | validation: 0.10830340944675165]
	TIME [epoch: 9.03 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11893827078279325		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.11893827078279325 | validation: 0.12578451198197468]
	TIME [epoch: 9.04 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1071239470282018		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.1071239470282018 | validation: 0.1418349823502032]
	TIME [epoch: 9.01 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1660796231547905		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.1660796231547905 | validation: 0.13401787127817263]
	TIME [epoch: 9.01 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12406877406501512		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.12406877406501512 | validation: 0.11947529822494549]
	TIME [epoch: 9.02 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10858745498024328		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.10858745498024328 | validation: 0.11087292647630351]
	TIME [epoch: 9.02 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11027988521069165		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.11027988521069165 | validation: 0.11436380595485537]
	TIME [epoch: 9.05 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14706583649482813		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.14706583649482813 | validation: 0.1205577684073407]
	TIME [epoch: 9.02 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10220767386023426		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.10220767386023426 | validation: 0.12885126839990513]
	TIME [epoch: 9.03 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10595188607329316		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.10595188607329316 | validation: 0.12225246748464297]
	TIME [epoch: 9.02 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10866642953598564		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.10866642953598564 | validation: 0.14079517730883973]
	TIME [epoch: 9.02 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12282672667942926		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.12282672667942926 | validation: 0.1367578118491381]
	TIME [epoch: 9.04 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11458822130842228		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.11458822130842228 | validation: 0.13494158666851414]
	TIME [epoch: 9.01 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10243104229269998		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.10243104229269998 | validation: 0.11717770745944855]
	TIME [epoch: 9.02 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10875783278904794		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.10875783278904794 | validation: 0.12174641206740948]
	TIME [epoch: 9.02 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11728932471141862		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.11728932471141862 | validation: 0.11089778042768134]
	TIME [epoch: 9.02 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10232539743391575		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.10232539743391575 | validation: 0.1158002778522883]
	TIME [epoch: 9.04 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10771206205057748		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.10771206205057748 | validation: 0.12571837441985664]
	TIME [epoch: 9.01 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10881523629231937		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.10881523629231937 | validation: 0.10856253008773611]
	TIME [epoch: 9.02 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09908187929547682		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.09908187929547682 | validation: 0.1105103146132177]
	TIME [epoch: 9.02 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11146459572584903		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.11146459572584903 | validation: 0.1377649905456565]
	TIME [epoch: 9.02 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11592217919599554		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.11592217919599554 | validation: 0.11787990187861683]
	TIME [epoch: 9.04 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11237915994098849		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.11237915994098849 | validation: 0.16613178293101774]
	TIME [epoch: 9.01 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12143534066429607		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.12143534066429607 | validation: 0.0997560476573025]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_681.pth
	Model improved!!!
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10116486848485037		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.10116486848485037 | validation: 0.1236208820130015]
	TIME [epoch: 9.01 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10534693556896005		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.10534693556896005 | validation: 0.1332844342071318]
	TIME [epoch: 9.01 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11170001156831137		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.11170001156831137 | validation: 0.09202014916493076]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_684.pth
	Model improved!!!
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11460900353712825		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.11460900353712825 | validation: 0.16133832034892523]
	TIME [epoch: 9 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12427005876480524		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.12427005876480524 | validation: 0.1080900314162881]
	TIME [epoch: 9.01 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10710401904750792		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.10710401904750792 | validation: 0.10613817989568614]
	TIME [epoch: 9.01 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10283910249434562		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.10283910249434562 | validation: 0.13729411762690324]
	TIME [epoch: 9.01 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11498841022143355		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.11498841022143355 | validation: 0.10639662919957638]
	TIME [epoch: 9.03 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10434457810826421		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.10434457810826421 | validation: 0.11389702178942987]
	TIME [epoch: 9.01 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09952498559203235		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.09952498559203235 | validation: 0.11252424335568176]
	TIME [epoch: 9.02 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14627198532538596		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.14627198532538596 | validation: 0.1067084844633838]
	TIME [epoch: 9.01 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10799192523327324		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.10799192523327324 | validation: 0.14807785976178067]
	TIME [epoch: 9 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10743038744241859		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.10743038744241859 | validation: 0.12080634569470142]
	TIME [epoch: 9.02 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11812970226575055		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.11812970226575055 | validation: 0.11069408032351977]
	TIME [epoch: 9.01 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1318406795232825		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.1318406795232825 | validation: 0.15091687555290906]
	TIME [epoch: 9.01 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11877176184076851		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.11877176184076851 | validation: 0.11768750854591448]
	TIME [epoch: 9.01 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1017509841597167		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.1017509841597167 | validation: 0.12168185635114104]
	TIME [epoch: 9.01 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12429216390873352		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.12429216390873352 | validation: 0.11927614500855233]
	TIME [epoch: 9.02 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10098738889545586		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.10098738889545586 | validation: 0.09933267447843203]
	TIME [epoch: 9.02 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09546785323325485		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.09546785323325485 | validation: 0.13990463436958914]
	TIME [epoch: 9 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13204444728093137		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.13204444728093137 | validation: 0.09683018376092993]
	TIME [epoch: 9 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185758491202149		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.10185758491202149 | validation: 0.11508395341420183]
	TIME [epoch: 9.01 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10051757199778662		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.10051757199778662 | validation: 0.09512768573331706]
	TIME [epoch: 9.02 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11607047562529064		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.11607047562529064 | validation: 0.14957965461898678]
	TIME [epoch: 9.03 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1105688244118875		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.1105688244118875 | validation: 0.1135860128268564]
	TIME [epoch: 9.01 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10104536252064904		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.10104536252064904 | validation: 0.11915316490286137]
	TIME [epoch: 9.01 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10232518523416108		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.10232518523416108 | validation: 0.1475961184110539]
	TIME [epoch: 9 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10567751036426579		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.10567751036426579 | validation: 0.12045109874505278]
	TIME [epoch: 9.01 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09822720620019407		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.09822720620019407 | validation: 0.13317255724389604]
	TIME [epoch: 9.03 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11626304674227983		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.11626304674227983 | validation: 0.16450850428473984]
	TIME [epoch: 9.01 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11693176057432227		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.11693176057432227 | validation: 0.14810356033863392]
	TIME [epoch: 9.01 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11408200595911566		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.11408200595911566 | validation: 0.1081000952717614]
	TIME [epoch: 9 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10015207841582532		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.10015207841582532 | validation: 0.10499684114414135]
	TIME [epoch: 9.01 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09699185592118395		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.09699185592118395 | validation: 0.11626277719870781]
	TIME [epoch: 9.02 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11785236312460583		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.11785236312460583 | validation: 0.11886582715710212]
	TIME [epoch: 9.01 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1064400444264261		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.1064400444264261 | validation: 0.09917412813297857]
	TIME [epoch: 9.02 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10534755552590473		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.10534755552590473 | validation: 0.11372977838781323]
	TIME [epoch: 9.01 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10663379708849016		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.10663379708849016 | validation: 0.13352117592550694]
	TIME [epoch: 9.02 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11814780794173226		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.11814780794173226 | validation: 0.1319545823809548]
	TIME [epoch: 9.03 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10454312117839001		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.10454312117839001 | validation: 0.10849086211178999]
	TIME [epoch: 9 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10391856104175054		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.10391856104175054 | validation: 0.11052231167159415]
	TIME [epoch: 9 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10430123568063884		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.10430123568063884 | validation: 0.13739747610709394]
	TIME [epoch: 9.01 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1246437121492063		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.1246437121492063 | validation: 0.13792006777756655]
	TIME [epoch: 9.01 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12206255407658398		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.12206255407658398 | validation: 0.11082714080340461]
	TIME [epoch: 9.03 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10760432041764409		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.10760432041764409 | validation: 0.1044770161874537]
	TIME [epoch: 9 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09889535017706257		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.09889535017706257 | validation: 0.11230446291887383]
	TIME [epoch: 9.01 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10367086369679987		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.10367086369679987 | validation: 0.12854533662585568]
	TIME [epoch: 9 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10108573810004166		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.10108573810004166 | validation: 0.11225622428116352]
	TIME [epoch: 9.01 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11375192320559054		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.11375192320559054 | validation: 0.124120068322332]
	TIME [epoch: 9.04 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10960349454086649		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.10960349454086649 | validation: 0.11834061990423726]
	TIME [epoch: 9.01 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09531433502815331		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.09531433502815331 | validation: 0.12153283143463535]
	TIME [epoch: 9.02 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15013812898212553		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.15013812898212553 | validation: 0.15448863188572276]
	TIME [epoch: 9 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1878801085708462		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.1878801085708462 | validation: 0.17764323432921905]
	TIME [epoch: 9.01 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16003744187297558		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.16003744187297558 | validation: 0.17199713523392546]
	TIME [epoch: 9.03 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16114250285143733		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.16114250285143733 | validation: 0.1903068407919257]
	TIME [epoch: 9.01 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17721319659184126		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.17721319659184126 | validation: 0.15098929975501463]
	TIME [epoch: 9.01 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12631770768825773		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.12631770768825773 | validation: 0.12506310085844927]
	TIME [epoch: 9.04 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11490156111100018		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.11490156111100018 | validation: 0.11637349062740784]
	TIME [epoch: 9.01 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11626162289394755		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.11626162289394755 | validation: 0.13103893010417864]
	TIME [epoch: 9.02 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12464207947199564		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.12464207947199564 | validation: 0.12677537917260184]
	TIME [epoch: 9.01 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666813247672933		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.11666813247672933 | validation: 0.12217726190398003]
	TIME [epoch: 9.01 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11698919315724024		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.11698919315724024 | validation: 0.1250445409378749]
	TIME [epoch: 9.01 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251820337923399		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.1251820337923399 | validation: 0.13413578255685493]
	TIME [epoch: 9.02 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11285470488986574		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.11285470488986574 | validation: 0.1144121009367019]
	TIME [epoch: 9.04 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10471760488879552		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.10471760488879552 | validation: 0.12898627876834806]
	TIME [epoch: 9.01 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10723397959008366		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.10723397959008366 | validation: 0.10975681250883565]
	TIME [epoch: 9.01 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09915500811962938		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.09915500811962938 | validation: 0.12478526699687886]
	TIME [epoch: 9.02 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10016377884269718		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.10016377884269718 | validation: 0.10346869479656931]
	TIME [epoch: 9.02 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10417768321766425		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.10417768321766425 | validation: 0.10906616870893858]
	TIME [epoch: 9.04 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10412713298657857		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.10412713298657857 | validation: 0.12476917499675352]
	TIME [epoch: 9.01 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11345132130724042		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.11345132130724042 | validation: 0.12240571004340746]
	TIME [epoch: 9.02 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10797566214433989		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.10797566214433989 | validation: 0.11106093157138763]
	TIME [epoch: 9.01 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09177587712807503		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.09177587712807503 | validation: 0.09204048725434852]
	TIME [epoch: 9.01 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09875459242673945		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.09875459242673945 | validation: 0.12655982202262356]
	TIME [epoch: 9.04 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10496944390536622		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.10496944390536622 | validation: 0.11435710958254505]
	TIME [epoch: 9.02 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10387709873896116		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.10387709873896116 | validation: 0.11017843871774338]
	TIME [epoch: 9.02 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1011175129862539		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.1011175129862539 | validation: 0.12726171934450756]
	TIME [epoch: 9.02 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10627895717792739		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.10627895717792739 | validation: 0.1237414291571024]
	TIME [epoch: 9.02 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09918261451374805		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.09918261451374805 | validation: 0.10894771829819]
	TIME [epoch: 9.04 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09220121253043778		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.09220121253043778 | validation: 0.1189120960254046]
	TIME [epoch: 9.02 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09712810827278293		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.09712810827278293 | validation: 0.14206941650554844]
	TIME [epoch: 9.01 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11053570804721198		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.11053570804721198 | validation: 0.09277245092626854]
	TIME [epoch: 9.01 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08878143716471518		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.08878143716471518 | validation: 0.10519787524667129]
	TIME [epoch: 9.01 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0943842818364701		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.0943842818364701 | validation: 0.1016264711509187]
	TIME [epoch: 9.04 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10670432297488142		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.10670432297488142 | validation: 0.10811978610326246]
	TIME [epoch: 9.02 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1026331385390881		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.1026331385390881 | validation: 0.10621464368246486]
	TIME [epoch: 9.01 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940973811268763		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.0940973811268763 | validation: 0.10860268847456096]
	TIME [epoch: 9.02 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10051519623368492		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.10051519623368492 | validation: 0.10755720218076582]
	TIME [epoch: 9.02 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10517811520659356		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.10517811520659356 | validation: 0.12246338630420131]
	TIME [epoch: 9.04 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10464569533955828		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.10464569533955828 | validation: 0.10678133121311567]
	TIME [epoch: 9.02 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0929739586809474		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.0929739586809474 | validation: 0.10269435801449742]
	TIME [epoch: 9.02 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09095917617764951		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.09095917617764951 | validation: 0.1206688221416497]
	TIME [epoch: 9 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11096914808866758		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.11096914808866758 | validation: 0.10610260898402897]
	TIME [epoch: 9.01 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10050442207199925		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.10050442207199925 | validation: 0.09522766746898714]
	TIME [epoch: 9.04 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09702082672468541		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.09702082672468541 | validation: 0.09579356898634814]
	TIME [epoch: 9.01 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10986132390688175		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.10986132390688175 | validation: 0.10288086227397927]
	TIME [epoch: 9.01 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09693766709271467		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.09693766709271467 | validation: 0.09971587290764372]
	TIME [epoch: 9.01 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09202090673750586		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.09202090673750586 | validation: 0.10154803679890663]
	TIME [epoch: 9.01 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10424935307268315		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.10424935307268315 | validation: 0.10000418672530656]
	TIME [epoch: 9.04 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10165293867071787		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.10165293867071787 | validation: 0.09545595435296474]
	TIME [epoch: 9.01 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10721622830224245		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.10721622830224245 | validation: 0.10922264375892152]
	TIME [epoch: 9.02 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11268436476513125		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.11268436476513125 | validation: 0.10044672241081]
	TIME [epoch: 9.02 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09975547707668775		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.09975547707668775 | validation: 0.10384406382889216]
	TIME [epoch: 9.03 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09321240378772956		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.09321240378772956 | validation: 0.1221722243247171]
	TIME [epoch: 9.04 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10170761753807636		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.10170761753807636 | validation: 0.1172636436368774]
	TIME [epoch: 9.01 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11249413122722648		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.11249413122722648 | validation: 0.10364502724059545]
	TIME [epoch: 9.01 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09684896987342223		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.09684896987342223 | validation: 0.10780650737958115]
	TIME [epoch: 9.01 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09561272988032946		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.09561272988032946 | validation: 0.10216921386725947]
	TIME [epoch: 9.01 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09872959701044168		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.09872959701044168 | validation: 0.10390882222805975]
	TIME [epoch: 9.03 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09628996230579895		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.09628996230579895 | validation: 0.10205465953753454]
	TIME [epoch: 9.01 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09431271470681905		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.09431271470681905 | validation: 0.10199040784971841]
	TIME [epoch: 9.01 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1033593506871648		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.1033593506871648 | validation: 0.1419532299631197]
	TIME [epoch: 9.01 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10319399582039024		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.10319399582039024 | validation: 0.09398257137084834]
	TIME [epoch: 9.01 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09413814571344067		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.09413814571344067 | validation: 0.10663798569708174]
	TIME [epoch: 9.04 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0927427685709577		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.0927427685709577 | validation: 0.10311891067494092]
	TIME [epoch: 9.02 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09600691397538139		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.09600691397538139 | validation: 0.14336236353194465]
	TIME [epoch: 9.02 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1018666119081844		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.1018666119081844 | validation: 0.0970247218868221]
	TIME [epoch: 9.01 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09198307422546351		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.09198307422546351 | validation: 0.12151224731782152]
	TIME [epoch: 9.01 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09341335824466268		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.09341335824466268 | validation: 0.08886652790773136]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_800.pth
	Model improved!!!
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09758851984127877		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.09758851984127877 | validation: 0.11896639415332705]
	TIME [epoch: 9.01 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09533334168019435		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.09533334168019435 | validation: 0.10772212644418204]
	TIME [epoch: 9.01 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10585511968352974		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.10585511968352974 | validation: 0.12099925450012719]
	TIME [epoch: 9.01 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1130500074398271		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.1130500074398271 | validation: 0.10425644675544182]
	TIME [epoch: 9.01 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1108991760265287		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.1108991760265287 | validation: 0.11814099139726797]
	TIME [epoch: 9.03 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11408205143502967		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.11408205143502967 | validation: 0.11736047434974134]
	TIME [epoch: 9.01 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09653381699591604		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.09653381699591604 | validation: 0.10565134849754484]
	TIME [epoch: 9.01 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10075405212364934		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.10075405212364934 | validation: 0.09804519780101521]
	TIME [epoch: 9.01 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09234364097588879		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.09234364097588879 | validation: 0.09200541163711858]
	TIME [epoch: 9.01 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09894408357772681		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.09894408357772681 | validation: 0.1486106807854131]
	TIME [epoch: 9.03 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1187097490223072		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.1187097490223072 | validation: 0.1207151004425352]
	TIME [epoch: 9.03 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09932650997941006		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.09932650997941006 | validation: 0.10552688780650765]
	TIME [epoch: 9.01 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11125131329428768		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.11125131329428768 | validation: 0.12345481324163571]
	TIME [epoch: 9 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11039325525592554		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.11039325525592554 | validation: 0.12173451264783003]
	TIME [epoch: 9 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08820202535011305		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.08820202535011305 | validation: 0.10920641345685034]
	TIME [epoch: 9.01 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921491014251717		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.0921491014251717 | validation: 0.1238299702339675]
	TIME [epoch: 9.03 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09856939727436374		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.09856939727436374 | validation: 0.09108024449936747]
	TIME [epoch: 9.02 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08875170627412306		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.08875170627412306 | validation: 0.10274002683422538]
	TIME [epoch: 9 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10489882809859608		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.10489882809859608 | validation: 0.13264975519490657]
	TIME [epoch: 9 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11178418813147391		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.11178418813147391 | validation: 0.09985414183156335]
	TIME [epoch: 9.01 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08997975911809153		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.08997975911809153 | validation: 0.10218912327085747]
	TIME [epoch: 9.02 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10440428204129255		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.10440428204129255 | validation: 0.11841082035052092]
	TIME [epoch: 9.01 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10064876084773751		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.10064876084773751 | validation: 0.12021057656810194]
	TIME [epoch: 9.01 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09750759571172528		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.09750759571172528 | validation: 0.12415899420781867]
	TIME [epoch: 9.01 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09485122333742786		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.09485122333742786 | validation: 0.1133144028236702]
	TIME [epoch: 9.02 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10821413302605942		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.10821413302605942 | validation: 0.11966669818473935]
	TIME [epoch: 9.03 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10075347971549227		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.10075347971549227 | validation: 0.13858027977099738]
	TIME [epoch: 9 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1183216360130049		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.1183216360130049 | validation: 0.11246569633849321]
	TIME [epoch: 9.01 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10621011064199581		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.10621011064199581 | validation: 0.1096467688550154]
	TIME [epoch: 9 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10533815703022595		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.10533815703022595 | validation: 0.11330940284119204]
	TIME [epoch: 9.01 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10111254753017493		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.10111254753017493 | validation: 0.10193825996828075]
	TIME [epoch: 9.02 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09963710324716721		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.09963710324716721 | validation: 0.12475148662615174]
	TIME [epoch: 9.01 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10049924959535328		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.10049924959535328 | validation: 0.10345521364864113]
	TIME [epoch: 9.01 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09117440828044891		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.09117440828044891 | validation: 0.09760531427274674]
	TIME [epoch: 9 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09409047266912562		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.09409047266912562 | validation: 0.12039635833953466]
	TIME [epoch: 9.01 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10592067225910824		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.10592067225910824 | validation: 0.11309491794875096]
	TIME [epoch: 9.03 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09667021686378556		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.09667021686378556 | validation: 0.11645572494680934]
	TIME [epoch: 9.01 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09523737846008103		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.09523737846008103 | validation: 0.10399996319370752]
	TIME [epoch: 9.01 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.104319060235606		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.104319060235606 | validation: 0.12899667020506594]
	TIME [epoch: 9 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1114462645193871		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.1114462645193871 | validation: 0.1241356053825705]
	TIME [epoch: 9.01 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10059548193441714		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.10059548193441714 | validation: 0.11154163501357389]
	TIME [epoch: 9.03 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0994780067783809		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.0994780067783809 | validation: 0.0984497735773171]
	TIME [epoch: 9.01 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0910828818378378		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.0910828818378378 | validation: 0.10562571736007034]
	TIME [epoch: 9 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09087702191844296		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.09087702191844296 | validation: 0.09801999503827508]
	TIME [epoch: 9 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09193188884821037		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.09193188884821037 | validation: 0.0883985965935406]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_845.pth
	Model improved!!!
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09664628504943298		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.09664628504943298 | validation: 0.12115925895228856]
	TIME [epoch: 9.04 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10501958216284239		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.10501958216284239 | validation: 0.10788772047591845]
	TIME [epoch: 9.01 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0954730634298411		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.0954730634298411 | validation: 0.11105663708784747]
	TIME [epoch: 9.01 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09191523995155021		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.09191523995155021 | validation: 0.10039003724862143]
	TIME [epoch: 9.02 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09950789371980413		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.09950789371980413 | validation: 0.11059404194063721]
	TIME [epoch: 9.02 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09103842968056455		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.09103842968056455 | validation: 0.13032723824169148]
	TIME [epoch: 9.04 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09753120532861417		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.09753120532861417 | validation: 0.10922563817568094]
	TIME [epoch: 9.02 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09953359531420802		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.09953359531420802 | validation: 0.10948216626401591]
	TIME [epoch: 9.01 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10334111284682765		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.10334111284682765 | validation: 0.12759832445297103]
	TIME [epoch: 9 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09877760996327045		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.09877760996327045 | validation: 0.10625734368821581]
	TIME [epoch: 9.02 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09554250903302414		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.09554250903302414 | validation: 0.10820176313272628]
	TIME [epoch: 9.04 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08976527376540269		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.08976527376540269 | validation: 0.10481595524256868]
	TIME [epoch: 9.02 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09973035690549252		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.09973035690549252 | validation: 0.10469106089636764]
	TIME [epoch: 9.02 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0925731688876493		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.0925731688876493 | validation: 0.09943087750074645]
	TIME [epoch: 9.01 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08962809314960837		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.08962809314960837 | validation: 0.09354209860786228]
	TIME [epoch: 9.01 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08986086238520137		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.08986086238520137 | validation: 0.09447509740563079]
	TIME [epoch: 9.03 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09097119125473416		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.09097119125473416 | validation: 0.1056275807725934]
	TIME [epoch: 9.02 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08778611731168072		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.08778611731168072 | validation: 0.10416722032083035]
	TIME [epoch: 9.02 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09562419300981126		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.09562419300981126 | validation: 0.10805952659082803]
	TIME [epoch: 9.02 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09702476284388561		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.09702476284388561 | validation: 0.10552212280158794]
	TIME [epoch: 9.01 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09812560770947612		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.09812560770947612 | validation: 0.11436100711050551]
	TIME [epoch: 9.03 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09524102273598632		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.09524102273598632 | validation: 0.10254460997677116]
	TIME [epoch: 9.01 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09574670579204624		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.09574670579204624 | validation: 0.109897622063233]
	TIME [epoch: 9.01 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09580158002655817		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.09580158002655817 | validation: 0.1029538966813425]
	TIME [epoch: 9 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09286657651858052		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.09286657651858052 | validation: 0.11282321659911343]
	TIME [epoch: 9.01 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09440721302568855		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.09440721302568855 | validation: 0.11325736222194938]
	TIME [epoch: 9.02 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0927889739715999		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.0927889739715999 | validation: 0.11262638554640866]
	TIME [epoch: 9.02 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10024778110335367		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.10024778110335367 | validation: 0.09825497242672623]
	TIME [epoch: 9.01 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10098734400179248		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.10098734400179248 | validation: 0.11639554841835027]
	TIME [epoch: 9 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09116215190501631		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.09116215190501631 | validation: 0.11607519411788345]
	TIME [epoch: 9.02 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09380811717308182		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.09380811717308182 | validation: 0.1284510002267029]
	TIME [epoch: 9.01 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09958892835938304		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.09958892835938304 | validation: 0.10048535977836094]
	TIME [epoch: 9.02 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09089710277141363		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.09089710277141363 | validation: 0.10038376758119474]
	TIME [epoch: 9.01 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09056257991431685		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.09056257991431685 | validation: 0.10852624266012845]
	TIME [epoch: 9.01 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09153435518962508		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.09153435518962508 | validation: 0.10553108684751]
	TIME [epoch: 9.01 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09753248770454845		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.09753248770454845 | validation: 0.1032414164964863]
	TIME [epoch: 9.02 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09810875884166406		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.09810875884166406 | validation: 0.10165622758896013]
	TIME [epoch: 9.02 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09036792603339938		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.09036792603339938 | validation: 0.10368694935494355]
	TIME [epoch: 9.02 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09041674501603787		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.09041674501603787 | validation: 0.11356594407784706]
	TIME [epoch: 9 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09064737776989874		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.09064737776989874 | validation: 0.11233104264466086]
	TIME [epoch: 9.01 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08683986919734356		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.08683986919734356 | validation: 0.1137329450091685]
	TIME [epoch: 9.02 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08816805930972005		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.08816805930972005 | validation: 0.11169467128826814]
	TIME [epoch: 9.03 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09447774011329327		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.09447774011329327 | validation: 0.11875730773562154]
	TIME [epoch: 9.02 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09405312476701282		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.09405312476701282 | validation: 0.12605532137348766]
	TIME [epoch: 9.01 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10222431586357705		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.10222431586357705 | validation: 0.11136864445929201]
	TIME [epoch: 9.02 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09318678993407513		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.09318678993407513 | validation: 0.10347391496739675]
	TIME [epoch: 9.03 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0924648173335038		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.0924648173335038 | validation: 0.10647992974861807]
	TIME [epoch: 9.02 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08785794491298564		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.08785794491298564 | validation: 0.09574047329802546]
	TIME [epoch: 9.01 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0861020194377466		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.0861020194377466 | validation: 0.09888191134670446]
	TIME [epoch: 9.01 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08644944464343661		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.08644944464343661 | validation: 0.10645864834919698]
	TIME [epoch: 9.02 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08840394077646922		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.08840394077646922 | validation: 0.10147801211588539]
	TIME [epoch: 9.02 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09163096459597654		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.09163096459597654 | validation: 0.09783801944579786]
	TIME [epoch: 9.03 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08915744432750262		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.08915744432750262 | validation: 0.09373127690110089]
	TIME [epoch: 9.01 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08948626899312692		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.08948626899312692 | validation: 0.09483903702091455]
	TIME [epoch: 9.01 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09530126703005332		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.09530126703005332 | validation: 0.10196320000651588]
	TIME [epoch: 9.01 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08629095788522831		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.08629095788522831 | validation: 0.09899592532616801]
	TIME [epoch: 9.02 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08643428928209469		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.08643428928209469 | validation: 0.10498074908949638]
	TIME [epoch: 9.02 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09472569775978681		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.09472569775978681 | validation: 0.10052752131077303]
	TIME [epoch: 9.02 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08940400411949209		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.08940400411949209 | validation: 0.09459086018870783]
	TIME [epoch: 9.01 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08994997433118687		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.08994997433118687 | validation: 0.1087209240237715]
	TIME [epoch: 9.01 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09372643644064657		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.09372643644064657 | validation: 0.11102478782490136]
	TIME [epoch: 9.03 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09194239436339324		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.09194239436339324 | validation: 0.13159256745288153]
	TIME [epoch: 9.02 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09569964038951047		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.09569964038951047 | validation: 0.09599609991943422]
	TIME [epoch: 9.01 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08987873887021924		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.08987873887021924 | validation: 0.10145341516221815]
	TIME [epoch: 9.01 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09187428323961679		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.09187428323961679 | validation: 0.09357179952881683]
	TIME [epoch: 9.02 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08593541242251058		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.08593541242251058 | validation: 0.09663467061589825]
	TIME [epoch: 9.03 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914184924243376		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.08914184924243376 | validation: 0.1013064290292423]
	TIME [epoch: 9.03 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09168103043638254		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.09168103043638254 | validation: 0.09499435250543016]
	TIME [epoch: 9.01 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08878176620014591		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.08878176620014591 | validation: 0.09453202756843311]
	TIME [epoch: 9.01 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0838922056560485		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.0838922056560485 | validation: 0.09775741371373581]
	TIME [epoch: 9.02 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09565016576822163		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.09565016576822163 | validation: 0.11093266303875111]
	TIME [epoch: 9.03 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10470637204860558		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.10470637204860558 | validation: 0.09963505081178403]
	TIME [epoch: 9.03 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09255782162687463		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.09255782162687463 | validation: 0.10203816305619395]
	TIME [epoch: 9.02 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09653160309382051		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.09653160309382051 | validation: 0.11869584990416368]
	TIME [epoch: 9.01 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09835510801740413		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.09835510801740413 | validation: 0.11836696952329735]
	TIME [epoch: 9.02 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981325635117929		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.08981325635117929 | validation: 0.10651398876930772]
	TIME [epoch: 9.02 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08544464828155127		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.08544464828155127 | validation: 0.10355010432993815]
	TIME [epoch: 9.02 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09127267200741676		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.09127267200741676 | validation: 0.09518088147790613]
	TIME [epoch: 9.02 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09709356299972463		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.09709356299972463 | validation: 0.09940859767954119]
	TIME [epoch: 9.01 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09455689001173276		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.09455689001173276 | validation: 0.11849463435006445]
	TIME [epoch: 9.01 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09599744707760069		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.09599744707760069 | validation: 0.10646069317328502]
	TIME [epoch: 9.02 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09091234495906027		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.09091234495906027 | validation: 0.11371245070439032]
	TIME [epoch: 9.03 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09976831035825974		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.09976831035825974 | validation: 0.10657143021069243]
	TIME [epoch: 9.01 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09031714984273109		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.09031714984273109 | validation: 0.12894782242557043]
	TIME [epoch: 9.02 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10375923750131189		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.10375923750131189 | validation: 0.116547873181687]
	TIME [epoch: 9.02 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0926878392136892		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.0926878392136892 | validation: 0.09349656594874231]
	TIME [epoch: 9.02 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09019774637405525		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.09019774637405525 | validation: 0.11016300293266851]
	TIME [epoch: 9.02 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09673251759075344		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.09673251759075344 | validation: 0.10220459083212538]
	TIME [epoch: 9.01 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09082491446406635		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.09082491446406635 | validation: 0.09293870961149028]
	TIME [epoch: 9.03 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08951354097173612		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.08951354097173612 | validation: 0.1091420449616344]
	TIME [epoch: 9.01 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08497894229949503		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.08497894229949503 | validation: 0.11056238130309523]
	TIME [epoch: 9.01 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10135161531291743		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.10135161531291743 | validation: 0.09340279286183312]
	TIME [epoch: 9.02 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08999701893272509		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.08999701893272509 | validation: 0.10345826277562828]
	TIME [epoch: 9.01 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08620405101690837		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.08620405101690837 | validation: 0.09552148022447693]
	TIME [epoch: 9.01 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08197870965338272		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.08197870965338272 | validation: 0.08720756411756553]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_940.pth
	Model improved!!!
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08697482622703637		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.08697482622703637 | validation: 0.10449450653610684]
	TIME [epoch: 9.02 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10392488610749265		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.10392488610749265 | validation: 0.10640017788289888]
	TIME [epoch: 9.02 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08599622176552588		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.08599622176552588 | validation: 0.09498962094800757]
	TIME [epoch: 9.01 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0901213415604962		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.0901213415604962 | validation: 0.09560579365772227]
	TIME [epoch: 9.01 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0844375048175521		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.0844375048175521 | validation: 0.0979485621161004]
	TIME [epoch: 9 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08528823756943855		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.08528823756943855 | validation: 0.0986638459847129]
	TIME [epoch: 9.01 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0941760386687108		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.0941760386687108 | validation: 0.10727693749912634]
	TIME [epoch: 9.02 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0983603558112192		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.0983603558112192 | validation: 0.10574633554664964]
	TIME [epoch: 9.01 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10406253225002389		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.10406253225002389 | validation: 0.13049527699748537]
	TIME [epoch: 9.01 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11256023665861987		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.11256023665861987 | validation: 0.10257732356465951]
	TIME [epoch: 9.01 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10446167657239944		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.10446167657239944 | validation: 0.09821904956780916]
	TIME [epoch: 9.01 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08468456179102504		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.08468456179102504 | validation: 0.10909307341154023]
	TIME [epoch: 9.02 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08637394460037293		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.08637394460037293 | validation: 0.1068473128769195]
	TIME [epoch: 9.01 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11230752008524436		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.11230752008524436 | validation: 0.10367688626359245]
	TIME [epoch: 9.02 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09108768432093892		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.09108768432093892 | validation: 0.11027385294965039]
	TIME [epoch: 9.01 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0927879061067525		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.0927879061067525 | validation: 0.11154431054445177]
	TIME [epoch: 9.02 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0931907113095039		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.0931907113095039 | validation: 0.10569109971108953]
	TIME [epoch: 9.04 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09481276910935442		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.09481276910935442 | validation: 0.11814946647747548]
	TIME [epoch: 9.02 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08893320580264433		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.08893320580264433 | validation: 0.10498365318116545]
	TIME [epoch: 9.02 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09196706289504263		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.09196706289504263 | validation: 0.10477213540519204]
	TIME [epoch: 9.01 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08908025630510327		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.08908025630510327 | validation: 0.10559393796227394]
	TIME [epoch: 9.02 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09287814871975597		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.09287814871975597 | validation: 0.1031455170246635]
	TIME [epoch: 9.04 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900769259602822		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.0900769259602822 | validation: 0.09352585179257375]
	TIME [epoch: 9.01 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09197315825845404		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.09197315825845404 | validation: 0.112382584076861]
	TIME [epoch: 9.02 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09960552071382231		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.09960552071382231 | validation: 0.10815291159444107]
	TIME [epoch: 9.01 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09154909537535452		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.09154909537535452 | validation: 0.09427302956425557]
	TIME [epoch: 9.01 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08286015736109228		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.08286015736109228 | validation: 0.09179558146740917]
	TIME [epoch: 9.03 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08848214884869839		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.08848214884869839 | validation: 0.09110292951985363]
	TIME [epoch: 9.02 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08552598357856758		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.08552598357856758 | validation: 0.10225205288624303]
	TIME [epoch: 9.02 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08890222646236631		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.08890222646236631 | validation: 0.11358512561341005]
	TIME [epoch: 9.02 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08793460169666209		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.08793460169666209 | validation: 0.09480073541857244]
	TIME [epoch: 9.03 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0837805162835373		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.0837805162835373 | validation: 0.0976778910887349]
	TIME [epoch: 9.02 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08810555150547691		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.08810555150547691 | validation: 0.10678605637676677]
	TIME [epoch: 9.02 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08783726989461878		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.08783726989461878 | validation: 0.10749306512630062]
	TIME [epoch: 9.01 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08712623857589365		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.08712623857589365 | validation: 0.10839014429815386]
	TIME [epoch: 9.01 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08943265702893834		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.08943265702893834 | validation: 0.10179422682900358]
	TIME [epoch: 9.03 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09141588201032325		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.09141588201032325 | validation: 0.08323268741651496]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240217_161441/states/model_tr_study4_977.pth
	Model improved!!!
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09261171856253657		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.09261171856253657 | validation: 0.10444745495678628]
	TIME [epoch: 9.02 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09346967805855168		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.09346967805855168 | validation: 0.1090157388002561]
	TIME [epoch: 9.02 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09713655613698072		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.09713655613698072 | validation: 0.12920334763154742]
	TIME [epoch: 9.01 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.111950155773116		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.111950155773116 | validation: 0.12298324077953057]
	TIME [epoch: 9.01 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09455516891741464		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.09455516891741464 | validation: 0.11840080862207818]
	TIME [epoch: 9.05 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09245427634845002		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.09245427634845002 | validation: 0.10119883964595147]
	TIME [epoch: 9.03 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739061939101267		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.08739061939101267 | validation: 0.09852304592170477]
	TIME [epoch: 9.02 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08503119872183659		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.08503119872183659 | validation: 0.10138951461991058]
	TIME [epoch: 9.02 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08748315513664813		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.08748315513664813 | validation: 0.1009836345206164]
	TIME [epoch: 9.02 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08818119699429154		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.08818119699429154 | validation: 0.11415523588383118]
	TIME [epoch: 9.02 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10016782461127731		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.10016782461127731 | validation: 0.11290798586157799]
	TIME [epoch: 9.04 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08980362705297631		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.08980362705297631 | validation: 0.0988389428766337]
	TIME [epoch: 9.02 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08867390965877274		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.08867390965877274 | validation: 0.1154819444035515]
	TIME [epoch: 9.02 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09710982966282243		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.09710982966282243 | validation: 0.10583272412975275]
	TIME [epoch: 9.02 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08687315707091112		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.08687315707091112 | validation: 0.10093755203646518]
	TIME [epoch: 9.03 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09141120976794767		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.09141120976794767 | validation: 0.11190045457083175]
	TIME [epoch: 9.03 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10257677772182865		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.10257677772182865 | validation: 0.11126818002066872]
	TIME [epoch: 9.01 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08890356459347706		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.08890356459347706 | validation: 0.1083143490936746]
	TIME [epoch: 9.15 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09232720756750323		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.09232720756750323 | validation: 0.105063618639657]
	TIME [epoch: 9.02 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0949139386348491		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.0949139386348491 | validation: 0.1070513022940232]
	TIME [epoch: 9.02 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09123776267054182		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.09123776267054182 | validation: 0.0943952400766229]
	TIME [epoch: 9.03 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08549870016300881		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.08549870016300881 | validation: 0.09517967986540139]
	TIME [epoch: 9.02 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09105860761736598		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.09105860761736598 | validation: 0.10168275977393859]
	TIME [epoch: 9.02 sec]
Finished training in 9126.238 seconds.
