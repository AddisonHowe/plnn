Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2350767

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.802849758331124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.802849758331124 | validation: 8.490543646147984]
	TIME [epoch: 70.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.143912437583165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.143912437583165 | validation: 7.238017346755291]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.717766124585599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.717766124585599 | validation: 6.111088887021978]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.055965354086189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.055965354086189 | validation: 5.815325203827941]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.138815793814166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.138815793814166 | validation: 6.218051131091245]
	TIME [epoch: 9.09 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.260786223172526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.260786223172526 | validation: 6.2245585985947445]
	TIME [epoch: 9.08 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.9171484722481935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9171484722481935 | validation: 6.3778136628184585]
	TIME [epoch: 9.1 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.952467667475725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.952467667475725 | validation: 5.682477817029984]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.918034144723295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.918034144723295 | validation: 7.1018899606057655]
	TIME [epoch: 9.1 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.14590888963599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.14590888963599 | validation: 5.259485007224317]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.849765745759917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.849765745759917 | validation: 4.6504010498250565]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.604857799945081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.604857799945081 | validation: 4.586036608862859]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.4949471495673405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4949471495673405 | validation: 4.231004078187601]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.330589547637868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.330589547637868 | validation: 3.935408609564385]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.594822848647813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.594822848647813 | validation: 3.9590390929309764]
	TIME [epoch: 9.08 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.269809251320913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.269809251320913 | validation: 4.355175784170797]
	TIME [epoch: 9.08 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.384640894993394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.384640894993394 | validation: 3.9472456351066656]
	TIME [epoch: 9.07 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.7621463006203784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7621463006203784 | validation: 4.068147812952226]
	TIME [epoch: 9.11 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8008753155534016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8008753155534016 | validation: 3.7172504203922623]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.4412735995701222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4412735995701222 | validation: 2.0933740350934467]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.781151833232464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.781151833232464 | validation: 4.298836817968576]
	TIME [epoch: 9.07 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.572190815067155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.572190815067155 | validation: 2.6213744796651124]
	TIME [epoch: 9.07 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9950411250099216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9950411250099216 | validation: 1.2613679965266684]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8855488464426573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8855488464426573 | validation: 3.619924201043545]
	TIME [epoch: 9.1 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.047616241593894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.047616241593894 | validation: 2.4501245356105086]
	TIME [epoch: 9.09 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5557630821281072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5557630821281072 | validation: 1.7418712955808975]
	TIME [epoch: 9.1 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.649491193993608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.649491193993608 | validation: 1.7319603767797633]
	TIME [epoch: 9.09 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3489460838397922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3489460838397922 | validation: 1.7810194195726037]
	TIME [epoch: 9.12 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5199927233374388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5199927233374388 | validation: 1.4601912272110722]
	TIME [epoch: 9.1 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4453296769871273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4453296769871273 | validation: 1.1936193423340438]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1989674172489448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1989674172489448 | validation: 2.0647963781328826]
	TIME [epoch: 9.09 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.331690913773842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.331690913773842 | validation: 0.8489264413105546]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2868440936485253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2868440936485253 | validation: 2.296200490012517]
	TIME [epoch: 9.11 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3640970179116887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3640970179116887 | validation: 1.0061474406312088]
	TIME [epoch: 9.08 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2564904551338505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2564904551338505 | validation: 0.8805901708698616]
	TIME [epoch: 9.08 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9075739704952366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9075739704952366 | validation: 0.8186883547760402]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0396449017886196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0396449017886196 | validation: 1.7232390110688938]
	TIME [epoch: 9.08 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2964993828952311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2964993828952311 | validation: 0.6520203678827878]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7715635257183682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7715635257183682 | validation: 1.054289099657336]
	TIME [epoch: 9.09 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9060282191392368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9060282191392368 | validation: 0.7418622162909905]
	TIME [epoch: 9.09 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8703024364827741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8703024364827741 | validation: 0.794922162357268]
	TIME [epoch: 9.1 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8989322966587284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8989322966587284 | validation: 0.829793841671094]
	TIME [epoch: 9.1 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8744737291015886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8744737291015886 | validation: 0.7761073344365783]
	TIME [epoch: 9.12 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8457646762851339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8457646762851339 | validation: 0.6104833029543286]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.786936176884925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.786936176884925 | validation: 0.49734880486536365]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0526072169918212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0526072169918212 | validation: 1.0222052082181974]
	TIME [epoch: 9.09 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7893024753705382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7893024753705382 | validation: 0.649170849010231]
	TIME [epoch: 9.07 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8924692204819445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8924692204819445 | validation: 0.5117991657862108]
	TIME [epoch: 9.11 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7464717868407662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7464717868407662 | validation: 1.012305167387538]
	TIME [epoch: 9.09 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9711754014589659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9711754014589659 | validation: 1.220235674281847]
	TIME [epoch: 9.08 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8425188431482387		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 0.8425188431482387 | validation: 0.683446286953725]
	TIME [epoch: 9.11 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7647278718596799		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 0.7647278718596799 | validation: 0.7652802479323297]
	TIME [epoch: 9.1 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7742785111407543		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.7742785111407543 | validation: 0.6241504294176318]
	TIME [epoch: 9.11 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7894249968894076		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 0.7894249968894076 | validation: 0.5190363653655904]
	TIME [epoch: 9.08 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7319416943954662		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 0.7319416943954662 | validation: 0.500553860776646]
	TIME [epoch: 9.09 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7323086721918324		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.7323086721918324 | validation: 0.7815211246776226]
	TIME [epoch: 9.09 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6697725415918085		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 0.6697725415918085 | validation: 0.6472939049299137]
	TIME [epoch: 9.08 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7018580288496354		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 0.7018580288496354 | validation: 0.8196451629707533]
	TIME [epoch: 9.11 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7119218359993014		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.7119218359993014 | validation: 0.5685953492490905]
	TIME [epoch: 9.09 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7464470651749545		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.7464470651749545 | validation: 1.0178508988254071]
	TIME [epoch: 9.09 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8057488722577499		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 0.8057488722577499 | validation: 0.9926110541095092]
	TIME [epoch: 9.09 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7730808854215037		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 0.7730808854215037 | validation: 0.5444315627746148]
	TIME [epoch: 9.08 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7052456267651956		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.7052456267651956 | validation: 0.7151027166591286]
	TIME [epoch: 9.11 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6489300634130815		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 0.6489300634130815 | validation: 0.4747145239725598]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7956124425435476		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.7956124425435476 | validation: 0.6835730142664136]
	TIME [epoch: 9.08 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9377376814979325		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.9377376814979325 | validation: 0.5601783920059328]
	TIME [epoch: 9.08 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6870094052914825		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 0.6870094052914825 | validation: 1.294584899241714]
	TIME [epoch: 9.07 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7111293216432454		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 0.7111293216432454 | validation: 0.6475725995979469]
	TIME [epoch: 9.1 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.809711014183802		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.809711014183802 | validation: 0.985548506133477]
	TIME [epoch: 9.06 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6828672655293893		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.6828672655293893 | validation: 0.5874445761198351]
	TIME [epoch: 9.06 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6270129663845097		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.6270129663845097 | validation: 0.8110952148151556]
	TIME [epoch: 9.07 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6890438727814521		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.6890438727814521 | validation: 0.6070050496878017]
	TIME [epoch: 9.07 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7778871507767858		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.7778871507767858 | validation: 0.577208962829906]
	TIME [epoch: 9.08 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7074024686727004		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.7074024686727004 | validation: 0.5499357703916223]
	TIME [epoch: 9.07 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7345279974648712		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.7345279974648712 | validation: 0.7249913225286806]
	TIME [epoch: 9.06 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7825337273989227		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.7825337273989227 | validation: 0.5874628423524639]
	TIME [epoch: 9.06 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8017936285716752		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.8017936285716752 | validation: 0.5665593541364107]
	TIME [epoch: 9.07 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6388479376115435		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.6388479376115435 | validation: 0.5586850499309052]
	TIME [epoch: 9.09 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5901374217220667		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.5901374217220667 | validation: 0.7243918865983251]
	TIME [epoch: 9.07 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6155829981996097		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.6155829981996097 | validation: 0.6326903269079416]
	TIME [epoch: 9.07 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7381268416681909		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.7381268416681909 | validation: 0.577312931268525]
	TIME [epoch: 9.07 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6988995191173398		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.6988995191173398 | validation: 0.661779390378151]
	TIME [epoch: 9.07 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7455936717671803		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.7455936717671803 | validation: 0.5265788346659295]
	TIME [epoch: 9.1 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7052925894218605		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.7052925894218605 | validation: 0.5570122634796988]
	TIME [epoch: 9.08 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7389331951953532		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.7389331951953532 | validation: 0.5275133856017622]
	TIME [epoch: 9.07 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6160304138901014		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.6160304138901014 | validation: 0.5520669083480567]
	TIME [epoch: 9.07 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6854298669134347		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.6854298669134347 | validation: 1.6179887243861013]
	TIME [epoch: 9.07 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7571959623767925		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.7571959623767925 | validation: 0.4820468096768912]
	TIME [epoch: 9.09 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5357781601754042		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.5357781601754042 | validation: 0.8128762339226161]
	TIME [epoch: 9.08 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6918811528523676		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.6918811528523676 | validation: 0.6166841470285933]
	TIME [epoch: 9.06 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.651201134365891		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.651201134365891 | validation: 0.8885371334739052]
	TIME [epoch: 9.07 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6162634172471647		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.6162634172471647 | validation: 0.48045753542426595]
	TIME [epoch: 9.07 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6906240698024285		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.6906240698024285 | validation: 0.7379737640471786]
	TIME [epoch: 9.1 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6002068130162066		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.6002068130162066 | validation: 0.5412515533275919]
	TIME [epoch: 9.07 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5394106218105554		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.5394106218105554 | validation: 0.6649417559595199]
	TIME [epoch: 9.08 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6311235014163635		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.6311235014163635 | validation: 0.6338162377332093]
	TIME [epoch: 9.07 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.671809112465449		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.671809112465449 | validation: 0.5136507340282732]
	TIME [epoch: 9.08 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6361782281003443		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.6361782281003443 | validation: 0.40453922824567157]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6966435343347139		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.6966435343347139 | validation: 0.540462564448951]
	TIME [epoch: 9.07 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6354205024870871		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.6354205024870871 | validation: 0.6551351528183336]
	TIME [epoch: 9.07 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6967666890602471		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.6967666890602471 | validation: 0.715608555371323]
	TIME [epoch: 9.07 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6174082520182956		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.6174082520182956 | validation: 0.5088129849356569]
	TIME [epoch: 9.08 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6163784608296241		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.6163784608296241 | validation: 0.42718088118006553]
	TIME [epoch: 9.1 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4905316835458528		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.4905316835458528 | validation: 0.7127850245938814]
	TIME [epoch: 9.07 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5634026949593219		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.5634026949593219 | validation: 0.4279722093365789]
	TIME [epoch: 9.08 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5531476315467105		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.5531476315467105 | validation: 0.3753953972177839]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5612988612785574		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.5612988612785574 | validation: 1.4878929940975274]
	TIME [epoch: 9.09 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6874662897329484		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.6874662897329484 | validation: 0.42164949105518545]
	TIME [epoch: 9.11 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5252487772309554		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5252487772309554 | validation: 0.47194812482378123]
	TIME [epoch: 9.08 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46135369690462646		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.46135369690462646 | validation: 0.50808873163192]
	TIME [epoch: 9.08 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6932233040431041		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.6932233040431041 | validation: 0.7053165911183901]
	TIME [epoch: 9.07 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5422397334991688		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.5422397334991688 | validation: 0.3610201305839972]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7088393158099359		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.7088393158099359 | validation: 0.3892015275591738]
	TIME [epoch: 9.11 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5608427378833813		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.5608427378833813 | validation: 0.3926959168267289]
	TIME [epoch: 9.08 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5719351881274549		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.5719351881274549 | validation: 0.5126218172032235]
	TIME [epoch: 9.09 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5477321931289348		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5477321931289348 | validation: 0.4081590455171806]
	TIME [epoch: 9.08 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5023978287698856		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.5023978287698856 | validation: 0.5673188310309327]
	TIME [epoch: 9.1 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.574144526860859		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.574144526860859 | validation: 0.479958351199568]
	TIME [epoch: 9.11 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6366597771486522		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.6366597771486522 | validation: 0.5609462600832307]
	TIME [epoch: 9.1 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5911286990751116		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.5911286990751116 | validation: 0.5262226111291903]
	TIME [epoch: 9.09 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5223416362946367		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.5223416362946367 | validation: 1.1336775781066537]
	TIME [epoch: 9.09 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5783163275394394		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.5783163275394394 | validation: 0.6942696745805665]
	TIME [epoch: 9.09 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6203723763500977		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.6203723763500977 | validation: 0.4587449275029615]
	TIME [epoch: 9.11 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4972028149233618		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.4972028149233618 | validation: 0.5176097212954743]
	TIME [epoch: 9.08 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5795011373209208		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.5795011373209208 | validation: 0.5598064645080965]
	TIME [epoch: 9.09 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4546693710217994		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.4546693710217994 | validation: 0.6439478815609527]
	TIME [epoch: 9.08 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5026440488368589		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.5026440488368589 | validation: 0.45613612204026144]
	TIME [epoch: 9.1 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4974855972797566		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.4974855972797566 | validation: 0.592981704783692]
	TIME [epoch: 9.11 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.510216225500274		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.510216225500274 | validation: 0.5703041925424666]
	TIME [epoch: 9.09 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.571892210413444		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.571892210413444 | validation: 0.33845690685141216]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4629700878936222		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.4629700878936222 | validation: 0.3492167546305881]
	TIME [epoch: 9.08 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42446197983172523		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.42446197983172523 | validation: 0.8132122529800236]
	TIME [epoch: 9.09 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4842018921521641		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.4842018921521641 | validation: 0.5259365048637898]
	TIME [epoch: 9.11 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.504332608696666		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.504332608696666 | validation: 0.464287792075635]
	TIME [epoch: 9.09 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.53697526365756		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.53697526365756 | validation: 0.5196697502773849]
	TIME [epoch: 9.08 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5367829626642264		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.5367829626642264 | validation: 0.627073426755407]
	TIME [epoch: 9.08 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5736470544060781		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.5736470544060781 | validation: 0.5694293194927795]
	TIME [epoch: 9.08 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.470880399785848		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.470880399785848 | validation: 0.419074400512342]
	TIME [epoch: 9.1 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4960649506241837		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.4960649506241837 | validation: 0.5000967274299352]
	TIME [epoch: 9.08 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46306439271845257		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.46306439271845257 | validation: 0.9839006868039797]
	TIME [epoch: 9.08 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6447603662104765		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.6447603662104765 | validation: 0.996195509275839]
	TIME [epoch: 9.07 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.511431228303143		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.511431228303143 | validation: 0.5303530070509173]
	TIME [epoch: 9.08 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5309087812146824		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.5309087812146824 | validation: 0.378573571796402]
	TIME [epoch: 9.1 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48836993751448327		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.48836993751448327 | validation: 0.5696800116949837]
	TIME [epoch: 9.08 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6132887125425117		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.6132887125425117 | validation: 0.6143061003189996]
	TIME [epoch: 9.07 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48353793251332444		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.48353793251332444 | validation: 1.2492899820119998]
	TIME [epoch: 9.09 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6266964512197173		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.6266964512197173 | validation: 0.5452003693623566]
	TIME [epoch: 9.09 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7677121612761546		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.7677121612761546 | validation: 0.5372721056451094]
	TIME [epoch: 9.11 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48589625094145805		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.48589625094145805 | validation: 0.5807631334192418]
	TIME [epoch: 9.08 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5156797682479889		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.5156797682479889 | validation: 0.7992535396617231]
	TIME [epoch: 9.08 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6007274657825511		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.6007274657825511 | validation: 0.6415512932045829]
	TIME [epoch: 9.08 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6247679486770799		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.6247679486770799 | validation: 0.4238187904153351]
	TIME [epoch: 9.09 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49629644271219214		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.49629644271219214 | validation: 0.6767892776997158]
	TIME [epoch: 9.1 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5424591098901894		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.5424591098901894 | validation: 0.48432789871470816]
	TIME [epoch: 9.08 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42061596752547253		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.42061596752547253 | validation: 0.7546422986394128]
	TIME [epoch: 9.08 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5435205923905141		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.5435205923905141 | validation: 0.9161778363386494]
	TIME [epoch: 9.07 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5760605785665329		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.5760605785665329 | validation: 0.5881479312390687]
	TIME [epoch: 9.09 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5095428867435535		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.5095428867435535 | validation: 0.3700188888251114]
	TIME [epoch: 9.11 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4161257929951671		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.4161257929951671 | validation: 0.7325924593398865]
	TIME [epoch: 9.09 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5502516854471161		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.5502516854471161 | validation: 0.5359684639173752]
	TIME [epoch: 9.1 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5133538609557908		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.5133538609557908 | validation: 0.5655020373645389]
	TIME [epoch: 9.08 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4707219192583218		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.4707219192583218 | validation: 0.5470026397274619]
	TIME [epoch: 9.09 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4906534741368887		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.4906534741368887 | validation: 0.36724687697180625]
	TIME [epoch: 9.09 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4267064233571509		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.4267064233571509 | validation: 0.3409866681927588]
	TIME [epoch: 9.09 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4561926838955045		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.4561926838955045 | validation: 0.5598078162611957]
	TIME [epoch: 9.08 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.481401761507137		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.481401761507137 | validation: 0.3861927541602991]
	TIME [epoch: 9.09 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4802663251534073		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.4802663251534073 | validation: 0.34420000442993326]
	TIME [epoch: 9.1 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4061443799989034		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.4061443799989034 | validation: 0.4034086914765384]
	TIME [epoch: 9.1 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.53185940721149		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.53185940721149 | validation: 0.29437579723702095]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_169.pth
	Model improved!!!
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6335013798016542		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.6335013798016542 | validation: 0.6742255442448133]
	TIME [epoch: 9.07 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4116018828679048		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.4116018828679048 | validation: 0.3525244006718411]
	TIME [epoch: 9.07 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44824788530949566		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.44824788530949566 | validation: 0.525258426739374]
	TIME [epoch: 9.09 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4556457008117894		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.4556457008117894 | validation: 0.458830173900951]
	TIME [epoch: 9.09 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.518805282043276		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.518805282043276 | validation: 0.6840708408186374]
	TIME [epoch: 9.07 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4528224742959293		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.4528224742959293 | validation: 0.2947109013847998]
	TIME [epoch: 9.06 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37542746872918564		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.37542746872918564 | validation: 0.3614302464809088]
	TIME [epoch: 9.08 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29750497922368024		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.29750497922368024 | validation: 0.32309609316408755]
	TIME [epoch: 9.08 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44106588086322757		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.44106588086322757 | validation: 0.48814837253631926]
	TIME [epoch: 9.09 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109650084286594		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.3109650084286594 | validation: 0.3398620267691903]
	TIME [epoch: 9.07 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34954498538693396		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.34954498538693396 | validation: 0.30604236544790897]
	TIME [epoch: 9.07 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4080211444461022		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.4080211444461022 | validation: 0.37208241678772425]
	TIME [epoch: 9.07 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35788636911601807		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.35788636911601807 | validation: 0.29210233789201157]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_182.pth
	Model improved!!!
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46848009530533063		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.46848009530533063 | validation: 0.37782815875640213]
	TIME [epoch: 9.09 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3906301177927738		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.3906301177927738 | validation: 0.2592196791895027]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_184.pth
	Model improved!!!
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29677597561040414		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.29677597561040414 | validation: 0.25670188048799303]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_185.pth
	Model improved!!!
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3559796632346939		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.3559796632346939 | validation: 0.2969068687594101]
	TIME [epoch: 9.1 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31965960693862633		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.31965960693862633 | validation: 0.2847362969206515]
	TIME [epoch: 9.09 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37873791161589193		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.37873791161589193 | validation: 0.22701999013779744]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36917414366370876		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.36917414366370876 | validation: 0.531363042524342]
	TIME [epoch: 9.07 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.304174140850846		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.304174140850846 | validation: 0.3153686124674472]
	TIME [epoch: 9.07 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32036370057024877		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.32036370057024877 | validation: 0.21112660504057343]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_191.pth
	Model improved!!!
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.304263924941324		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.304263924941324 | validation: 0.26602952605101793]
	TIME [epoch: 9.09 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.400094374078396		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.400094374078396 | validation: 0.22936744917956436]
	TIME [epoch: 9.08 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29240027822927345		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.29240027822927345 | validation: 0.341284207816428]
	TIME [epoch: 9.07 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28523938789081005		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.28523938789081005 | validation: 0.28024404373105705]
	TIME [epoch: 9.06 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28869145311469274		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.28869145311469274 | validation: 0.2121828647943505]
	TIME [epoch: 9.06 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37697752381911953		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.37697752381911953 | validation: 0.5233086467324511]
	TIME [epoch: 9.09 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40836335968142257		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.40836335968142257 | validation: 0.4778511290698853]
	TIME [epoch: 9.08 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982501323866928		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.2982501323866928 | validation: 0.18969605154920174]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30803313375161656		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.30803313375161656 | validation: 0.2755760762249726]
	TIME [epoch: 9.08 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3027885141734721		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.3027885141734721 | validation: 0.6396727762526009]
	TIME [epoch: 9.07 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4306164112934733		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.4306164112934733 | validation: 0.2583281210790558]
	TIME [epoch: 9.08 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3649681036047659		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.3649681036047659 | validation: 0.4104115554082677]
	TIME [epoch: 9.08 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34917139441096745		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.34917139441096745 | validation: 0.16043003556890384]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_204.pth
	Model improved!!!
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24504682194298835		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.24504682194298835 | validation: 0.18520283180658537]
	TIME [epoch: 9.07 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3929937259910172		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.3929937259910172 | validation: 0.2617587044958578]
	TIME [epoch: 9.06 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25774622124408697		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.25774622124408697 | validation: 0.22254383030164365]
	TIME [epoch: 9.08 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35667246701162314		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.35667246701162314 | validation: 0.4091674876954889]
	TIME [epoch: 9.08 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2989502211221168		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.2989502211221168 | validation: 0.2588402378510742]
	TIME [epoch: 9.06 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728383284116364		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.2728383284116364 | validation: 0.27999235238192743]
	TIME [epoch: 9.06 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621936448900659		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.3621936448900659 | validation: 0.5379406231640094]
	TIME [epoch: 9.06 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38618121090671637		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.38618121090671637 | validation: 0.38925174407636065]
	TIME [epoch: 9.09 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2900454679093854		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.2900454679093854 | validation: 0.39100266517864607]
	TIME [epoch: 9.08 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006904972657614		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.3006904972657614 | validation: 0.18900996105112347]
	TIME [epoch: 9.07 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30512092862977336		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.30512092862977336 | validation: 0.23983502393025374]
	TIME [epoch: 9.07 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2846421868996937		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.2846421868996937 | validation: 0.23231250111733814]
	TIME [epoch: 9.06 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3218304273846778		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.3218304273846778 | validation: 0.4444525996330675]
	TIME [epoch: 9.09 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31752088995561967		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.31752088995561967 | validation: 0.22414464189021616]
	TIME [epoch: 9.08 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.334302456499361		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.334302456499361 | validation: 0.5896611650300461]
	TIME [epoch: 9.08 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3984688186837508		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.3984688186837508 | validation: 0.21828623011256926]
	TIME [epoch: 9.06 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30967294836308534		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.30967294836308534 | validation: 0.32941721282642156]
	TIME [epoch: 9.06 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31807947361618993		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.31807947361618993 | validation: 0.42052341269952187]
	TIME [epoch: 9.08 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3430644894662564		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.3430644894662564 | validation: 0.19781626988078627]
	TIME [epoch: 9.08 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33294728362078296		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.33294728362078296 | validation: 0.2356031383303071]
	TIME [epoch: 9.08 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135454390680745		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.3135454390680745 | validation: 0.300836449433516]
	TIME [epoch: 9.07 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24887462723875128		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.24887462723875128 | validation: 0.21052475936899995]
	TIME [epoch: 9.08 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2928413621930555		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.2928413621930555 | validation: 0.19305115917199306]
	TIME [epoch: 9.08 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797092050608401		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.2797092050608401 | validation: 0.1969775921400001]
	TIME [epoch: 9.07 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711020340778407		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.2711020340778407 | validation: 0.2714078937713815]
	TIME [epoch: 9.07 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3332452354827895		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.3332452354827895 | validation: 0.6906055132211135]
	TIME [epoch: 9.07 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3645534731603038		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.3645534731603038 | validation: 0.27253756406299695]
	TIME [epoch: 9.06 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3381571566434382		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.3381571566434382 | validation: 0.2298030207495357]
	TIME [epoch: 9.08 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29373726123512384		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.29373726123512384 | validation: 0.22468400203016503]
	TIME [epoch: 9.08 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2926590262486845		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.2926590262486845 | validation: 0.17034098324463154]
	TIME [epoch: 9.06 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3447014974379234		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.3447014974379234 | validation: 0.21668343808436863]
	TIME [epoch: 9.05 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25943919152691974		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.25943919152691974 | validation: 0.5888804127151472]
	TIME [epoch: 9.06 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3394844160453029		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.3394844160453029 | validation: 0.20441399838122934]
	TIME [epoch: 9.08 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285131102023514		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.3285131102023514 | validation: 0.44205703375049094]
	TIME [epoch: 9.1 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31149918767919205		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.31149918767919205 | validation: 0.2116342132017059]
	TIME [epoch: 9.07 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23311532372275412		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.23311532372275412 | validation: 0.21862648926171327]
	TIME [epoch: 9.07 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.313801204586537		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.313801204586537 | validation: 0.23538827378349678]
	TIME [epoch: 9.08 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2573752613257124		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.2573752613257124 | validation: 0.30517196902590427]
	TIME [epoch: 9.09 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28611924035583747		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.28611924035583747 | validation: 0.3459625022538677]
	TIME [epoch: 9.09 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2526034554057517		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.2526034554057517 | validation: 0.4187715630225871]
	TIME [epoch: 9.08 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26146897061275354		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.26146897061275354 | validation: 0.17532224173296854]
	TIME [epoch: 9.08 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26609894516188043		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.26609894516188043 | validation: 0.2719245618059048]
	TIME [epoch: 9.08 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2585493022687715		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.2585493022687715 | validation: 0.20196229176673436]
	TIME [epoch: 9.1 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3243884950814594		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.3243884950814594 | validation: 0.34775341114884467]
	TIME [epoch: 9.1 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2303622653835072		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.2303622653835072 | validation: 0.3331302430123456]
	TIME [epoch: 9.08 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3978184763493308		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.3978184763493308 | validation: 0.19625526642592325]
	TIME [epoch: 9.1 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258968859806613		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.258968859806613 | validation: 0.18827356167598464]
	TIME [epoch: 9.09 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2606396300489795		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.2606396300489795 | validation: 0.3824250131393504]
	TIME [epoch: 9.1 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3161029545745878		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.3161029545745878 | validation: 0.2983590188002998]
	TIME [epoch: 9.11 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874518150153701		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.2874518150153701 | validation: 0.29767399242561043]
	TIME [epoch: 9.08 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30162806940902814		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.30162806940902814 | validation: 0.330188377263565]
	TIME [epoch: 9.08 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27494921564735286		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.27494921564735286 | validation: 0.21869912561403893]
	TIME [epoch: 9.08 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30098159541946223		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.30098159541946223 | validation: 0.1714602977742295]
	TIME [epoch: 9.11 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25854224486825955		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.25854224486825955 | validation: 0.2885690030200042]
	TIME [epoch: 9.1 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22962046454188498		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.22962046454188498 | validation: 0.29903092657475916]
	TIME [epoch: 9.08 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665068532311573		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.2665068532311573 | validation: 0.31297586553371126]
	TIME [epoch: 9.09 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2817756004339382		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.2817756004339382 | validation: 0.18038407330131276]
	TIME [epoch: 9.09 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23986443522142165		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.23986443522142165 | validation: 0.3142562983929936]
	TIME [epoch: 9.1 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33812914220676427		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.33812914220676427 | validation: 0.15664477629368811]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_263.pth
	Model improved!!!
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3552761791216357		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.3552761791216357 | validation: 0.2621464205156283]
	TIME [epoch: 9.08 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26737219147081515		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.26737219147081515 | validation: 0.28681223489547863]
	TIME [epoch: 9.09 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3141711222571998		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.3141711222571998 | validation: 0.2177884792716755]
	TIME [epoch: 9.07 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23564280355604256		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.23564280355604256 | validation: 0.30944607166680216]
	TIME [epoch: 9.09 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25868915300526724		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.25868915300526724 | validation: 0.18695574091687261]
	TIME [epoch: 9.08 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23123927292994165		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.23123927292994165 | validation: 0.26598666001592347]
	TIME [epoch: 9.08 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2914635689433454		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.2914635689433454 | validation: 0.16813004455442626]
	TIME [epoch: 9.06 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2624232676472518		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.2624232676472518 | validation: 0.17384872419644126]
	TIME [epoch: 9.06 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698195729286295		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.2698195729286295 | validation: 0.236666011593599]
	TIME [epoch: 9.08 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23232931687134553		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.23232931687134553 | validation: 0.2335204223837705]
	TIME [epoch: 9.07 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2837432077810508		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.2837432077810508 | validation: 0.16308457430114778]
	TIME [epoch: 9.05 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31253358527627967		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.31253358527627967 | validation: 0.36247491826133715]
	TIME [epoch: 9.06 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2857102598838682		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.2857102598838682 | validation: 0.612617611221591]
	TIME [epoch: 9.06 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34229207538439976		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.34229207538439976 | validation: 0.1734650339568885]
	TIME [epoch: 9.08 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25528557568848254		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.25528557568848254 | validation: 0.16210723798404492]
	TIME [epoch: 9.08 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2637339484897012		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.2637339484897012 | validation: 0.14795348726833088]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2772534891734331		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.2772534891734331 | validation: 0.5560266027373879]
	TIME [epoch: 9.07 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23384759140354325		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.23384759140354325 | validation: 0.17958495796636487]
	TIME [epoch: 9.06 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23981471473476343		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.23981471473476343 | validation: 0.2465704969420849]
	TIME [epoch: 9.08 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2205678556812308		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.2205678556812308 | validation: 0.14927215113696812]
	TIME [epoch: 9.07 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43668298201356315		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.43668298201356315 | validation: 0.4090928858360223]
	TIME [epoch: 9.06 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25263683742857423		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.25263683742857423 | validation: 0.1280784031552672]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_285.pth
	Model improved!!!
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2377791467192547		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.2377791467192547 | validation: 0.3945801517953159]
	TIME [epoch: 9.06 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2008887834638954		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.2008887834638954 | validation: 0.13441495718158109]
	TIME [epoch: 9.08 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29789111238876587		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.29789111238876587 | validation: 0.2755785750256743]
	TIME [epoch: 9.06 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23539327420987294		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.23539327420987294 | validation: 0.19322782484931425]
	TIME [epoch: 9.05 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24919747536820047		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.24919747536820047 | validation: 0.22044787113008876]
	TIME [epoch: 9.07 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20462310775755016		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.20462310775755016 | validation: 0.3051386256510349]
	TIME [epoch: 9.06 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22788919293914828		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.22788919293914828 | validation: 0.28651915721335974]
	TIME [epoch: 9.08 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22734348468894625		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.22734348468894625 | validation: 0.3420253621068798]
	TIME [epoch: 9.07 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2384369846114999		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.2384369846114999 | validation: 0.21036589489677335]
	TIME [epoch: 9.05 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2307583726520413		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.2307583726520413 | validation: 0.1432043987899665]
	TIME [epoch: 9.06 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23395391364833876		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.23395391364833876 | validation: 0.3588236828042472]
	TIME [epoch: 9.05 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24862057773934643		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.24862057773934643 | validation: 0.2981349035276192]
	TIME [epoch: 9.07 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20294592892213048		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.20294592892213048 | validation: 0.13793327092851088]
	TIME [epoch: 9.07 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22674635992374964		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.22674635992374964 | validation: 0.2947784320880394]
	TIME [epoch: 9.05 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22727116224773872		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.22727116224773872 | validation: 0.28426477103063175]
	TIME [epoch: 9.05 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19937286452641642		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.19937286452641642 | validation: 0.1727490990321297]
	TIME [epoch: 9.05 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2730711022796008		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.2730711022796008 | validation: 0.13484353579738395]
	TIME [epoch: 9.07 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2441974797431624		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.2441974797431624 | validation: 0.3390138664654694]
	TIME [epoch: 9.06 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24285686893761685		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.24285686893761685 | validation: 0.2139916621112587]
	TIME [epoch: 9.06 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2384312254882664		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.2384312254882664 | validation: 0.11907581937049919]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277738662671996		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.2277738662671996 | validation: 0.1384051725977237]
	TIME [epoch: 9.07 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19787079062682228		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.19787079062682228 | validation: 0.11907308890618841]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_307.pth
	Model improved!!!
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20294057290905715		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.20294057290905715 | validation: 0.1011968818469231]
	TIME [epoch: 9.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_308.pth
	Model improved!!!
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2486985930220782		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.2486985930220782 | validation: 0.1905988659629075]
	TIME [epoch: 9.09 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22406578889691686		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.22406578889691686 | validation: 0.1803537564705176]
	TIME [epoch: 9.09 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23189473801023483		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.23189473801023483 | validation: 0.18675992800862629]
	TIME [epoch: 9.09 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32642717442508795		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.32642717442508795 | validation: 0.2284739279950414]
	TIME [epoch: 9.1 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2380719624270733		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.2380719624270733 | validation: 0.12755826602151438]
	TIME [epoch: 9.1 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21915226504354018		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.21915226504354018 | validation: 0.16545493590896088]
	TIME [epoch: 9.09 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20529698228226975		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.20529698228226975 | validation: 0.13204922372862501]
	TIME [epoch: 9.09 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18643131959532042		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.18643131959532042 | validation: 0.17570473761655947]
	TIME [epoch: 9.1 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23065774808149775		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.23065774808149775 | validation: 0.14770817241081913]
	TIME [epoch: 9.11 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2430150608083294		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.2430150608083294 | validation: 0.23984380293793844]
	TIME [epoch: 9.12 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1891254677227562		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.1891254677227562 | validation: 0.24283386460488748]
	TIME [epoch: 9.1 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837593144935492		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.1837593144935492 | validation: 0.12187091287313906]
	TIME [epoch: 9.09 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22061144638702332		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.22061144638702332 | validation: 0.14400717166550064]
	TIME [epoch: 9.09 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19593648362610472		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.19593648362610472 | validation: 0.1573123431826351]
	TIME [epoch: 9.1 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22314690758322842		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.22314690758322842 | validation: 0.1922253350530726]
	TIME [epoch: 9.11 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1825865353017712		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.1825865353017712 | validation: 0.15462742542548663]
	TIME [epoch: 9.1 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22042326226002698		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.22042326226002698 | validation: 0.3656807129199549]
	TIME [epoch: 9.09 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22848036648061926		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.22848036648061926 | validation: 0.15936724716231254]
	TIME [epoch: 9.1 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15243681319548466		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.15243681319548466 | validation: 0.11042084918443276]
	TIME [epoch: 9.08 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20804403798778948		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.20804403798778948 | validation: 0.17488003028023888]
	TIME [epoch: 9.19 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16785259945119735		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.16785259945119735 | validation: 0.16589194337072452]
	TIME [epoch: 9.09 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16710548862125654		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.16710548862125654 | validation: 0.1345659728023001]
	TIME [epoch: 9.09 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19319474286496224		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.19319474286496224 | validation: 0.10509205873579011]
	TIME [epoch: 9.1 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1963128412671383		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.1963128412671383 | validation: 0.15814216713864804]
	TIME [epoch: 9.1 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1808455205999755		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.1808455205999755 | validation: 0.4060102465067974]
	TIME [epoch: 9.1 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27472594530879374		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.27472594530879374 | validation: 0.13395527442677488]
	TIME [epoch: 9.11 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17435755013987592		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.17435755013987592 | validation: 0.09097234761375225]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_335.pth
	Model improved!!!
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.288382746046705		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.288382746046705 | validation: 0.47339768782531544]
	TIME [epoch: 9.1 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24745624655939658		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.24745624655939658 | validation: 0.20504739602961167]
	TIME [epoch: 9.09 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.156541661294552		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.156541661294552 | validation: 0.1252759634760268]
	TIME [epoch: 9.1 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21254878983575418		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.21254878983575418 | validation: 0.2162798475295432]
	TIME [epoch: 9.11 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1951230419317544		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.1951230419317544 | validation: 0.15967777339986539]
	TIME [epoch: 9.08 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20194421057951506		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.20194421057951506 | validation: 0.10067762524713675]
	TIME [epoch: 9.09 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17412315798220068		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.17412315798220068 | validation: 0.1762052497416025]
	TIME [epoch: 9.1 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.178520803528271		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.178520803528271 | validation: 0.12461801534461839]
	TIME [epoch: 9.09 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18751438606593857		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.18751438606593857 | validation: 0.11982524989489451]
	TIME [epoch: 9.12 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18877893555980463		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.18877893555980463 | validation: 0.152363985945204]
	TIME [epoch: 9.09 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19725838787252967		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.19725838787252967 | validation: 0.14699250309390086]
	TIME [epoch: 9.09 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18428855966676877		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.18428855966676877 | validation: 0.13678668961201135]
	TIME [epoch: 9.09 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1645607390999224		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.1645607390999224 | validation: 0.15589249948037415]
	TIME [epoch: 9.09 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1448922033637275		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.1448922033637275 | validation: 0.22763478815379107]
	TIME [epoch: 9.11 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20636140329011704		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.20636140329011704 | validation: 0.10625991136268884]
	TIME [epoch: 9.09 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21754134202609815		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.21754134202609815 | validation: 0.3942853513304232]
	TIME [epoch: 9.09 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18917043580286635		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.18917043580286635 | validation: 0.12464129526189421]
	TIME [epoch: 9.09 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16550753268619484		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.16550753268619484 | validation: 0.1494269437420726]
	TIME [epoch: 9.09 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15679793409521103		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.15679793409521103 | validation: 0.2075304326723158]
	TIME [epoch: 9.11 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22823629058354475		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.22823629058354475 | validation: 0.10579728536572741]
	TIME [epoch: 9.11 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14714392242680474		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.14714392242680474 | validation: 0.1567205812350448]
	TIME [epoch: 9.1 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24651876841771583		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.24651876841771583 | validation: 0.23371571881445347]
	TIME [epoch: 9.1 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16511303211208705		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.16511303211208705 | validation: 0.09823661146263524]
	TIME [epoch: 9.1 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17114010094146676		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.17114010094146676 | validation: 0.097912212681558]
	TIME [epoch: 9.1 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15248263981693308		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.15248263981693308 | validation: 0.403469611833043]
	TIME [epoch: 9.11 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20003413434565132		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.20003413434565132 | validation: 0.11159834544003903]
	TIME [epoch: 9.09 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13985916417812727		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.13985916417812727 | validation: 0.12554691740975293]
	TIME [epoch: 9.1 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15551980559707929		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.15551980559707929 | validation: 0.16209071723426727]
	TIME [epoch: 9.1 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17644440485408794		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.17644440485408794 | validation: 0.13331855854313904]
	TIME [epoch: 9.12 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17150797105672122		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.17150797105672122 | validation: 0.15989018629258184]
	TIME [epoch: 9.09 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18987584233444343		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.18987584233444343 | validation: 0.16295163992802303]
	TIME [epoch: 9.1 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25785580392282903		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.25785580392282903 | validation: 0.19084384773726393]
	TIME [epoch: 9.08 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1687778682344394		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.1687778682344394 | validation: 0.1350057158165393]
	TIME [epoch: 9.08 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20934044361369802		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.20934044361369802 | validation: 0.2400162129522331]
	TIME [epoch: 9.1 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.207933317327932		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.207933317327932 | validation: 0.13336612167686787]
	TIME [epoch: 9.1 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13444157762383607		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.13444157762383607 | validation: 0.316297701281645]
	TIME [epoch: 9.11 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20817978763763398		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.20817978763763398 | validation: 0.24845677996426588]
	TIME [epoch: 9.1 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16286991391302372		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.16286991391302372 | validation: 0.13333344939686534]
	TIME [epoch: 9.09 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14718009055039333		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.14718009055039333 | validation: 0.16271112822030076]
	TIME [epoch: 9.09 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18610785770237456		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.18610785770237456 | validation: 0.13320444304510465]
	TIME [epoch: 9.09 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18777828691698586		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.18777828691698586 | validation: 0.18961843396814446]
	TIME [epoch: 9.11 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14077061525791598		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.14077061525791598 | validation: 0.111448961211138]
	TIME [epoch: 9.09 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1420436674322528		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.1420436674322528 | validation: 0.14598255639812857]
	TIME [epoch: 9.09 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17935525767825028		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.17935525767825028 | validation: 0.18423405806796295]
	TIME [epoch: 9.09 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15426870629381237		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.15426870629381237 | validation: 0.11478712794930834]
	TIME [epoch: 9.09 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16135700001997538		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.16135700001997538 | validation: 0.10016319112892741]
	TIME [epoch: 9.09 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16302821907833218		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.16302821907833218 | validation: 0.129549913774819]
	TIME [epoch: 9.11 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13974736141126903		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.13974736141126903 | validation: 0.1259509954024802]
	TIME [epoch: 9.1 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1405723625517247		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.1405723625517247 | validation: 0.21326050448426143]
	TIME [epoch: 9.09 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16487061338877135		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.16487061338877135 | validation: 0.3586495490532302]
	TIME [epoch: 9.09 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2172931297758708		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.2172931297758708 | validation: 0.10929030042524407]
	TIME [epoch: 9.09 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15288150448321433		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.15288150448321433 | validation: 0.09876158065539675]
	TIME [epoch: 9.11 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15369236191079794		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.15369236191079794 | validation: 0.23155542638087034]
	TIME [epoch: 9.09 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17270761486007993		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.17270761486007993 | validation: 0.14880959763489443]
	TIME [epoch: 9.08 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18481974723268912		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.18481974723268912 | validation: 0.1252951191027159]
	TIME [epoch: 9.09 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1288000628115286		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.1288000628115286 | validation: 0.20961963420857688]
	TIME [epoch: 9.08 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14112316131567598		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.14112316131567598 | validation: 0.14098135026487355]
	TIME [epoch: 9.1 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15282976183311417		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.15282976183311417 | validation: 0.12006516069955042]
	TIME [epoch: 9.1 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14538871947701865		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.14538871947701865 | validation: 0.11908699029890335]
	TIME [epoch: 9.08 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13772591848628346		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.13772591848628346 | validation: 0.11634257625390981]
	TIME [epoch: 9.09 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13678043680312385		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.13678043680312385 | validation: 0.07396583977365093]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_396.pth
	Model improved!!!
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15393741434526595		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.15393741434526595 | validation: 0.08906949668900792]
	TIME [epoch: 9.09 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17188790983626057		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.17188790983626057 | validation: 0.08088295356737402]
	TIME [epoch: 9.1 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1662861757360793		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.1662861757360793 | validation: 0.13861500127927628]
	TIME [epoch: 9.07 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13970423707580404		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.13970423707580404 | validation: 0.10596324953269057]
	TIME [epoch: 9.07 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13911912331052473		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.13911912331052473 | validation: 0.1281774772811772]
	TIME [epoch: 9.07 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14179855827859564		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.14179855827859564 | validation: 0.14920631326225786]
	TIME [epoch: 9.08 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14659561899227452		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.14659561899227452 | validation: 0.09470562275853217]
	TIME [epoch: 9.1 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1592662039144342		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.1592662039144342 | validation: 0.162318672740335]
	TIME [epoch: 9.07 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1450374878590197		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.1450374878590197 | validation: 0.17279514427203096]
	TIME [epoch: 9.08 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14444455270209963		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.14444455270209963 | validation: 0.09068761637715847]
	TIME [epoch: 9.07 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14139960323838635		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.14139960323838635 | validation: 0.08456869151792692]
	TIME [epoch: 9.07 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15478621098610107		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.15478621098610107 | validation: 0.0768761020941762]
	TIME [epoch: 9.1 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16858016957296743		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.16858016957296743 | validation: 0.08808050005383394]
	TIME [epoch: 9.08 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1237970433566959		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.1237970433566959 | validation: 0.1971858220398855]
	TIME [epoch: 9.08 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1396352972194149		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.1396352972194149 | validation: 0.1283971157482672]
	TIME [epoch: 9.09 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490602955261272		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.1490602955261272 | validation: 0.18338438854959907]
	TIME [epoch: 9.09 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1352615118638413		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.1352615118638413 | validation: 0.12466027754538778]
	TIME [epoch: 9.1 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15081424654337855		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.15081424654337855 | validation: 0.11411506327537799]
	TIME [epoch: 9.1 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13795185624775752		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.13795185624775752 | validation: 0.12978893590609883]
	TIME [epoch: 9.09 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13579564925192028		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.13579564925192028 | validation: 0.09138898876526089]
	TIME [epoch: 9.09 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.196269494052747		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.196269494052747 | validation: 0.09774816247175325]
	TIME [epoch: 9.08 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14453351538234568		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.14453351538234568 | validation: 0.16525879100514496]
	TIME [epoch: 9.09 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13073313595154096		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.13073313595154096 | validation: 0.14604379116520683]
	TIME [epoch: 9.1 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14004780346271273		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.14004780346271273 | validation: 0.10003991095146245]
	TIME [epoch: 9.09 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14150337893935167		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.14150337893935167 | validation: 0.2574839277487654]
	TIME [epoch: 9.08 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1841572139522448		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.1841572139522448 | validation: 0.09338750678761465]
	TIME [epoch: 9.08 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14363748036353177		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.14363748036353177 | validation: 0.09904127311802316]
	TIME [epoch: 9.08 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13427576776038716		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.13427576776038716 | validation: 0.19792900939434077]
	TIME [epoch: 9.08 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1423578031354216		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.1423578031354216 | validation: 0.06974894707178271]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_425.pth
	Model improved!!!
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11862591275961783		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.11862591275961783 | validation: 0.08826845201663858]
	TIME [epoch: 9.07 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291538406595655		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.1291538406595655 | validation: 0.13542985318172282]
	TIME [epoch: 9.07 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18534729391422042		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.18534729391422042 | validation: 0.12861101547500206]
	TIME [epoch: 9.07 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13251268137428857		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.13251268137428857 | validation: 0.076113574450346]
	TIME [epoch: 9.08 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13291632262583392		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.13291632262583392 | validation: 0.10506539446177138]
	TIME [epoch: 9.1 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16272550392267746		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.16272550392267746 | validation: 0.2558625459119963]
	TIME [epoch: 9.08 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15663622480432804		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.15663622480432804 | validation: 0.16885774140677506]
	TIME [epoch: 9.07 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14676695726902317		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.14676695726902317 | validation: 0.11004288378124312]
	TIME [epoch: 9.07 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13993263240620543		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.13993263240620543 | validation: 0.0959277658144658]
	TIME [epoch: 9.07 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12579564972819818		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.12579564972819818 | validation: 0.0967149478439973]
	TIME [epoch: 9.11 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12641880844255102		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.12641880844255102 | validation: 0.08348180883803188]
	TIME [epoch: 9.09 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12952318821548178		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.12952318821548178 | validation: 0.11091018792076375]
	TIME [epoch: 9.08 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12239711572074012		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.12239711572074012 | validation: 0.07927556675080746]
	TIME [epoch: 9.09 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14568885177241234		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.14568885177241234 | validation: 0.3016454591886284]
	TIME [epoch: 9.08 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15630910020802632		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.15630910020802632 | validation: 0.2633669260009046]
	TIME [epoch: 9.1 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1510169583806073		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.1510169583806073 | validation: 0.09314798210783704]
	TIME [epoch: 9.08 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12934015925745132		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.12934015925745132 | validation: 0.16234649095311637]
	TIME [epoch: 9.07 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13655194148970007		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.13655194148970007 | validation: 0.07556386759392418]
	TIME [epoch: 9.08 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10472573496695095		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.10472573496695095 | validation: 0.0980647848066179]
	TIME [epoch: 9.07 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11195878444397844		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.11195878444397844 | validation: 0.10807416889523337]
	TIME [epoch: 9.08 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11438583828284299		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.11438583828284299 | validation: 0.12140193850869119]
	TIME [epoch: 9.09 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15096389389175002		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.15096389389175002 | validation: 0.11454116784376386]
	TIME [epoch: 9.07 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11828851132417324		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.11828851132417324 | validation: 0.13527933534171083]
	TIME [epoch: 9.08 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13520354225563616		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.13520354225563616 | validation: 0.10201933018452788]
	TIME [epoch: 9.08 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1464764755781136		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.1464764755781136 | validation: 0.19061913066516933]
	TIME [epoch: 9.09 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15738191042167743		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.15738191042167743 | validation: 0.10193175700901297]
	TIME [epoch: 9.1 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13573378528005214		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.13573378528005214 | validation: 0.09708120888516697]
	TIME [epoch: 9.07 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12822962012935585		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.12822962012935585 | validation: 0.15135418877018988]
	TIME [epoch: 9.07 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16733424059805374		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.16733424059805374 | validation: 0.0912067877141553]
	TIME [epoch: 9.08 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10378778321528667		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.10378778321528667 | validation: 0.1535615938914282]
	TIME [epoch: 9.08 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.135472781457114		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.135472781457114 | validation: 0.10394762243861094]
	TIME [epoch: 9.08 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1410420004747756		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.1410420004747756 | validation: 0.0952675202796929]
	TIME [epoch: 9.08 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1276427087537137		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.1276427087537137 | validation: 0.12903936366970453]
	TIME [epoch: 9.07 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11426904556923718		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.11426904556923718 | validation: 0.1207255552963104]
	TIME [epoch: 9.07 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12767615731829776		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.12767615731829776 | validation: 0.09223153568101058]
	TIME [epoch: 9.07 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10885151726660207		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.10885151726660207 | validation: 0.06330655136235701]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_461.pth
	Model improved!!!
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1015240288242536		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.1015240288242536 | validation: 0.1041314488494553]
	TIME [epoch: 9.09 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12314839173960365		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.12314839173960365 | validation: 0.11316982029642471]
	TIME [epoch: 9.07 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13826719364575152		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.13826719364575152 | validation: 0.075352526064216]
	TIME [epoch: 9.07 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997751967234671		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.0997751967234671 | validation: 0.07698128687725891]
	TIME [epoch: 9.06 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10952398681408286		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.10952398681408286 | validation: 0.06010766529146694]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_466.pth
	Model improved!!!
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10592518425446582		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.10592518425446582 | validation: 0.07974569664841565]
	TIME [epoch: 9.09 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14067018558040217		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.14067018558040217 | validation: 0.08630815559346322]
	TIME [epoch: 9.07 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11681301147167156		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.11681301147167156 | validation: 0.0822948060189656]
	TIME [epoch: 9.07 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10394598646652456		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.10394598646652456 | validation: 0.08306270308162358]
	TIME [epoch: 9.06 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08826822430695733		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.08826822430695733 | validation: 0.1395165567677058]
	TIME [epoch: 9.06 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11955163479936189		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.11955163479936189 | validation: 0.0758205496916079]
	TIME [epoch: 9.09 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11573409651809781		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.11573409651809781 | validation: 0.1565213584972357]
	TIME [epoch: 9.06 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12659191340354684		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.12659191340354684 | validation: 0.09179718998768283]
	TIME [epoch: 9.07 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14199243469189907		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.14199243469189907 | validation: 0.16373108596140665]
	TIME [epoch: 9.07 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11951036072978924		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.11951036072978924 | validation: 0.07704620654628916]
	TIME [epoch: 9.07 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11100296892390082		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.11100296892390082 | validation: 0.0830563173273886]
	TIME [epoch: 9.09 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09361174550525865		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.09361174550525865 | validation: 0.06888330741943692]
	TIME [epoch: 9.06 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0967280436322247		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.0967280436322247 | validation: 0.11555744118450742]
	TIME [epoch: 9.07 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17224674660762723		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.17224674660762723 | validation: 0.12495017002481049]
	TIME [epoch: 9.06 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10852672765792801		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.10852672765792801 | validation: 0.0673427060742405]
	TIME [epoch: 9.07 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11843913928281362		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.11843913928281362 | validation: 0.119498852424628]
	TIME [epoch: 9.07 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11839880518044085		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.11839880518044085 | validation: 0.13495682236019302]
	TIME [epoch: 9.08 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10798677884193282		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.10798677884193282 | validation: 0.1540418473801771]
	TIME [epoch: 9.07 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12146541899578112		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.12146541899578112 | validation: 0.08539538624650522]
	TIME [epoch: 9.06 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0962663766960261		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.0962663766960261 | validation: 0.07195289297714447]
	TIME [epoch: 9.07 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11478380315819565		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.11478380315819565 | validation: 0.08485966992428023]
	TIME [epoch: 9.07 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1287128727884874		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.1287128727884874 | validation: 0.09562917728670316]
	TIME [epoch: 9.09 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10881993706649104		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.10881993706649104 | validation: 0.09911117924278906]
	TIME [epoch: 9.08 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11414938838350872		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.11414938838350872 | validation: 0.1051916248059441]
	TIME [epoch: 9.07 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1304847639766336		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.1304847639766336 | validation: 0.12866979424793232]
	TIME [epoch: 9.07 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10729485590391008		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.10729485590391008 | validation: 0.09185452757332074]
	TIME [epoch: 9.07 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12543631589808668		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.12543631589808668 | validation: 0.07679620131592754]
	TIME [epoch: 9.07 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10558001023146728		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.10558001023146728 | validation: 0.07130671786069229]
	TIME [epoch: 9.09 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12166746193580433		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.12166746193580433 | validation: 0.07992906086812833]
	TIME [epoch: 9.06 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11270215177473777		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.11270215177473777 | validation: 0.06318465517556449]
	TIME [epoch: 9.07 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1124216630951135		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.1124216630951135 | validation: 0.0916325452904515]
	TIME [epoch: 9.07 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1269490116526601		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.1269490116526601 | validation: 0.13410713846645467]
	TIME [epoch: 9.06 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12167267446057557		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.12167267446057557 | validation: 0.07468426364256861]
	TIME [epoch: 9.09 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09629519734266523		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.09629519734266523 | validation: 0.12186489471855752]
	TIME [epoch: 9.07 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10859392780085923		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.10859392780085923 | validation: 0.11086375689909347]
	TIME [epoch: 9.08 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.120035544067046		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.120035544067046 | validation: 0.1280799717686182]
	TIME [epoch: 9.07 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11281416757349391		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.11281416757349391 | validation: 0.1908945114967092]
	TIME [epoch: 9.07 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15477018833391193		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.15477018833391193 | validation: 0.10896005144614948]
	TIME [epoch: 9.09 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09573297257631322		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.09573297257631322 | validation: 0.14342857871798953]
	TIME [epoch: 9.08 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12003214439848264		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.12003214439848264 | validation: 0.15365684691413603]
	TIME [epoch: 9.07 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10943882800495937		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.10943882800495937 | validation: 0.08106056692745658]
	TIME [epoch: 9.07 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12045082939532381		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.12045082939532381 | validation: 0.10124396554727766]
	TIME [epoch: 9.07 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10609484202433941		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.10609484202433941 | validation: 0.09319810967920536]
	TIME [epoch: 9.07 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09240322943140396		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.09240322943140396 | validation: 0.09354015615008734]
	TIME [epoch: 9.1 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11280452469378117		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.11280452469378117 | validation: 0.09715200272815856]
	TIME [epoch: 9.07 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10465088785247847		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.10465088785247847 | validation: 0.036723550597438065]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_512.pth
	Model improved!!!
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09624308560354877		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.09624308560354877 | validation: 0.09066913205771679]
	TIME [epoch: 9.06 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08997442997933548		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.08997442997933548 | validation: 0.1313387128758039]
	TIME [epoch: 9.08 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1661518228440448		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.1661518228440448 | validation: 0.1289707914039111]
	TIME [epoch: 9.1 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14478709593774716		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.14478709593774716 | validation: 0.08096580451070226]
	TIME [epoch: 9.08 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.103486988780395		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.103486988780395 | validation: 0.10967127884481555]
	TIME [epoch: 9.07 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09996017745791552		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.09996017745791552 | validation: 0.0871535240075745]
	TIME [epoch: 9.07 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08869399378702914		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.08869399378702914 | validation: 0.05232170123407702]
	TIME [epoch: 9.06 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09030334295458217		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.09030334295458217 | validation: 0.12177633311494354]
	TIME [epoch: 9.08 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09268875225791363		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.09268875225791363 | validation: 0.054487802672705504]
	TIME [epoch: 9.08 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09903577614570899		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.09903577614570899 | validation: 0.10203165140804026]
	TIME [epoch: 9.08 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08364755927268237		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.08364755927268237 | validation: 0.07679767368302685]
	TIME [epoch: 9.07 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10273796316711355		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.10273796316711355 | validation: 0.10836716680419872]
	TIME [epoch: 9.07 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16069702989212736		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.16069702989212736 | validation: 0.1140263021824253]
	TIME [epoch: 9.07 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11972820076845898		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.11972820076845898 | validation: 0.09966500843905486]
	TIME [epoch: 9.08 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09933234927375997		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.09933234927375997 | validation: 0.08930581119677636]
	TIME [epoch: 9.07 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09752936560385478		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.09752936560385478 | validation: 0.06683312218913007]
	TIME [epoch: 9.08 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11733594206771261		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.11733594206771261 | validation: 0.05740834380880228]
	TIME [epoch: 9.07 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10969116341954702		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.10969116341954702 | validation: 0.06852234489948847]
	TIME [epoch: 9.07 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08704078455743498		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.08704078455743498 | validation: 0.11892230328788692]
	TIME [epoch: 9.09 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10065640285412931		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.10065640285412931 | validation: 0.04912801592565176]
	TIME [epoch: 9.07 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09524048511471292		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.09524048511471292 | validation: 0.05834311192584228]
	TIME [epoch: 9.06 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10205349116223258		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.10205349116223258 | validation: 0.0596310232003905]
	TIME [epoch: 9.07 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08463410628116436		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.08463410628116436 | validation: 0.07988463283742485]
	TIME [epoch: 9.07 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878760957548056		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.0878760957548056 | validation: 0.0826087438084697]
	TIME [epoch: 9.08 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11421151595493795		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.11421151595493795 | validation: 0.13874267329833628]
	TIME [epoch: 9.08 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10185557136354777		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.10185557136354777 | validation: 0.050033381682044326]
	TIME [epoch: 9.06 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1044829622237621		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.1044829622237621 | validation: 0.07892604504886386]
	TIME [epoch: 9.06 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08029257857936789		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.08029257857936789 | validation: 0.055899719698338]
	TIME [epoch: 9.08 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0897080092195284		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.0897080092195284 | validation: 0.11305253394980436]
	TIME [epoch: 9.09 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1221988303367048		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.1221988303367048 | validation: 0.05163766448318047]
	TIME [epoch: 9.1 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09834455090597272		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.09834455090597272 | validation: 0.041952499114514964]
	TIME [epoch: 9.08 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08545689525134102		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.08545689525134102 | validation: 0.1974351849177949]
	TIME [epoch: 9.06 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11908526534300837		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.11908526534300837 | validation: 0.07947516774607796]
	TIME [epoch: 9.07 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10262020264065552		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.10262020264065552 | validation: 0.0638761590517444]
	TIME [epoch: 9.06 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09433846231891865		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.09433846231891865 | validation: 0.053469061553743265]
	TIME [epoch: 9.1 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0805456623572943		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.0805456623572943 | validation: 0.05870257087761113]
	TIME [epoch: 9.07 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10030220505502865		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.10030220505502865 | validation: 0.09918102424477382]
	TIME [epoch: 9.07 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09371969026923081		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.09371969026923081 | validation: 0.06662560221582953]
	TIME [epoch: 9.07 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09065977660782183		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.09065977660782183 | validation: 0.10924366912098349]
	TIME [epoch: 9.06 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09102807162831494		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.09102807162831494 | validation: 0.05607144596797413]
	TIME [epoch: 9.07 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08775073950492453		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.08775073950492453 | validation: 0.09211468312242299]
	TIME [epoch: 9.09 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0865337995333008		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.0865337995333008 | validation: 0.05788835126169836]
	TIME [epoch: 9.08 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09919401862514302		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.09919401862514302 | validation: 0.051358299828867915]
	TIME [epoch: 9.08 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08390354441047583		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.08390354441047583 | validation: 0.10412852686098634]
	TIME [epoch: 9.07 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10065709455182958		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.10065709455182958 | validation: 0.06553628596474964]
	TIME [epoch: 9.06 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08107108922308706		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.08107108922308706 | validation: 0.21239667754717448]
	TIME [epoch: 9.08 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16365978876423054		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.16365978876423054 | validation: 0.0748322119276651]
	TIME [epoch: 9.06 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1560500220672525		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.1560500220672525 | validation: 0.159439251064601]
	TIME [epoch: 9.06 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1128506137957616		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.1128506137957616 | validation: 0.10500956609253809]
	TIME [epoch: 9.07 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09937934400543189		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.09937934400543189 | validation: 0.058551485667859525]
	TIME [epoch: 9.06 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08390210940002875		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.08390210940002875 | validation: 0.053914716304163404]
	TIME [epoch: 9.09 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09000795084288542		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.09000795084288542 | validation: 0.06390767327348146]
	TIME [epoch: 9.07 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08512841994768729		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.08512841994768729 | validation: 0.10791061746736673]
	TIME [epoch: 9.06 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09857263027858977		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.09857263027858977 | validation: 0.15935807146487901]
	TIME [epoch: 9.06 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314718304956047		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.11314718304956047 | validation: 0.07854788425097803]
	TIME [epoch: 9.07 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08594633118737871		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.08594633118737871 | validation: 0.08528491991743176]
	TIME [epoch: 9.08 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10067924097461836		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.10067924097461836 | validation: 0.24994141921625493]
	TIME [epoch: 9.09 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12126059023326563		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.12126059023326563 | validation: 0.06302211219808766]
	TIME [epoch: 9.07 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981977909871718		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.08981977909871718 | validation: 0.04612896021875622]
	TIME [epoch: 9.06 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08264791899976451		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.08264791899976451 | validation: 0.08360877257524467]
	TIME [epoch: 9.06 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09578545932856368		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.09578545932856368 | validation: 0.07130440972206915]
	TIME [epoch: 9.06 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678637312804096		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.07678637312804096 | validation: 0.10760894196853102]
	TIME [epoch: 9.09 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10230417531088101		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.10230417531088101 | validation: 0.09981899000507467]
	TIME [epoch: 9.07 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13041784746965882		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.13041784746965882 | validation: 0.08085582363401614]
	TIME [epoch: 9.06 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08454409483353682		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.08454409483353682 | validation: 0.05026120594812625]
	TIME [epoch: 9.06 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07769999876451968		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.07769999876451968 | validation: 0.0999290211786027]
	TIME [epoch: 9.06 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08712710138917736		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.08712710138917736 | validation: 0.03653353012966487]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_579.pth
	Model improved!!!
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09771383002733193		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.09771383002733193 | validation: 0.11822911006166203]
	TIME [epoch: 9.09 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09151941053307959		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.09151941053307959 | validation: 0.07804084919188299]
	TIME [epoch: 9.07 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0827191928690347		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.0827191928690347 | validation: 0.08503636911728472]
	TIME [epoch: 9.07 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09234712365387954		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.09234712365387954 | validation: 0.05118623067263388]
	TIME [epoch: 9.07 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.076819985159185		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.076819985159185 | validation: 0.10419959281650024]
	TIME [epoch: 9.05 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10078258113921564		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.10078258113921564 | validation: 0.07414305275335648]
	TIME [epoch: 9.08 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08811960187286261		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.08811960187286261 | validation: 0.0631245369610767]
	TIME [epoch: 9.06 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816431454025863		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.07816431454025863 | validation: 0.06837365108633645]
	TIME [epoch: 9.06 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10087239547785429		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.10087239547785429 | validation: 0.06614917504649545]
	TIME [epoch: 9.07 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08115153700613617		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.08115153700613617 | validation: 0.08882542144312494]
	TIME [epoch: 9.06 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09559994842711791		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.09559994842711791 | validation: 0.11971612563927789]
	TIME [epoch: 9.08 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09046115242349387		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.09046115242349387 | validation: 0.13882781743122785]
	TIME [epoch: 9.06 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09883112281783182		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.09883112281783182 | validation: 0.07860211527722422]
	TIME [epoch: 9.05 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07381798131002013		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.07381798131002013 | validation: 0.04086546562655695]
	TIME [epoch: 9.07 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10006495477365944		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.10006495477365944 | validation: 0.05835273883839533]
	TIME [epoch: 9.06 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07476318451351549		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.07476318451351549 | validation: 0.04464051421668619]
	TIME [epoch: 9.08 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0781431416784822		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.0781431416784822 | validation: 0.06442066007960157]
	TIME [epoch: 9.08 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07367154456352046		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.07367154456352046 | validation: 0.179337819150542]
	TIME [epoch: 9.06 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10400757354238273		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.10400757354238273 | validation: 0.044591653510429305]
	TIME [epoch: 9.06 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07556494905750046		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.07556494905750046 | validation: 0.06028384801329001]
	TIME [epoch: 9.05 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07573403319520884		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.07573403319520884 | validation: 0.07336257049075505]
	TIME [epoch: 9.06 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08143464278660568		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.08143464278660568 | validation: 0.053741043697768824]
	TIME [epoch: 9.08 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0774383083764982		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.0774383083764982 | validation: 0.0568816884788078]
	TIME [epoch: 9.06 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07550512982613974		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.07550512982613974 | validation: 0.11408437100825619]
	TIME [epoch: 9.07 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08482148784771333		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.08482148784771333 | validation: 0.06262190926717412]
	TIME [epoch: 9.06 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07677880001229323		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.07677880001229323 | validation: 0.07153662007102247]
	TIME [epoch: 9.06 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07847042237535576		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.07847042237535576 | validation: 0.048066579293095574]
	TIME [epoch: 9.09 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06768338292385272		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.06768338292385272 | validation: 0.0576998685371202]
	TIME [epoch: 9.07 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0896766133539519		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.0896766133539519 | validation: 0.05508881210495781]
	TIME [epoch: 9.07 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10512160063268791		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.10512160063268791 | validation: 0.06352032350219049]
	TIME [epoch: 9.07 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08959605537602115		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.08959605537602115 | validation: 0.04022506033786952]
	TIME [epoch: 9.06 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0813333460107785		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.0813333460107785 | validation: 0.049159197649216516]
	TIME [epoch: 9.07 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.062100028002148644		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.062100028002148644 | validation: 0.06182345173629297]
	TIME [epoch: 9.07 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06503867138993397		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.06503867138993397 | validation: 0.06325637806152967]
	TIME [epoch: 9.07 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08376521666898874		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.08376521666898874 | validation: 0.0849082600509148]
	TIME [epoch: 9.06 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0947245370471183		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.0947245370471183 | validation: 0.14217722379267295]
	TIME [epoch: 9.06 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08036803073630869		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.08036803073630869 | validation: 0.05279029486456602]
	TIME [epoch: 9.06 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09359532177194246		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.09359532177194246 | validation: 0.07033738466013581]
	TIME [epoch: 9.08 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07892104845154826		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.07892104845154826 | validation: 0.06633625854906164]
	TIME [epoch: 9.06 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07723876204849427		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.07723876204849427 | validation: 0.0946750572841856]
	TIME [epoch: 9.06 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08707838642546065		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.08707838642546065 | validation: 0.06867609687001139]
	TIME [epoch: 9.07 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06636278361285518		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.06636278361285518 | validation: 0.053092438658715824]
	TIME [epoch: 9.07 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739087988713539		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.0739087988713539 | validation: 0.043569203925534004]
	TIME [epoch: 9.08 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07544926297894741		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.07544926297894741 | validation: 0.05684242687577506]
	TIME [epoch: 9.08 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07379206562407971		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.07379206562407971 | validation: 0.05579454885442506]
	TIME [epoch: 9.06 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07068098789499558		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.07068098789499558 | validation: 0.03739815588232541]
	TIME [epoch: 9.07 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08263388400658114		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.08263388400658114 | validation: 0.06066313324200151]
	TIME [epoch: 9.06 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09735786488635505		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.09735786488635505 | validation: 0.07472703209847745]
	TIME [epoch: 9.06 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09008734524946962		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.09008734524946962 | validation: 0.07547797912966286]
	TIME [epoch: 9.09 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07171850930756807		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.07171850930756807 | validation: 0.05194768775714624]
	TIME [epoch: 9.07 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06864723731745628		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.06864723731745628 | validation: 0.1273758404339213]
	TIME [epoch: 9.06 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08770263999128583		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.08770263999128583 | validation: 0.07164052132199927]
	TIME [epoch: 9.06 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07627079937879602		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.07627079937879602 | validation: 0.0658675267617596]
	TIME [epoch: 9.06 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06762085733629909		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.06762085733629909 | validation: 0.05904562619229472]
	TIME [epoch: 9.09 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08010715833675518		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.08010715833675518 | validation: 0.03971092720584915]
	TIME [epoch: 9.08 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06483177975705227		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.06483177975705227 | validation: 0.043852333873581055]
	TIME [epoch: 9.07 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382936410378708		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.08382936410378708 | validation: 0.08567998805248228]
	TIME [epoch: 9.06 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09058374396961488		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.09058374396961488 | validation: 0.056284713943848826]
	TIME [epoch: 9.06 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06618106705909532		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.06618106705909532 | validation: 0.056017239505476955]
	TIME [epoch: 9.06 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06437751515260118		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.06437751515260118 | validation: 0.057056516937141394]
	TIME [epoch: 9.08 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08846474146715354		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.08846474146715354 | validation: 0.0855039173534675]
	TIME [epoch: 9.07 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08974442368569374		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.08974442368569374 | validation: 0.06801082615510354]
	TIME [epoch: 9.07 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10067631605633318		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.10067631605633318 | validation: 0.0526021560966858]
	TIME [epoch: 9.05 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08544711002178969		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.08544711002178969 | validation: 0.08161952449533338]
	TIME [epoch: 9.05 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08173188318519202		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.08173188318519202 | validation: 0.13747685016173516]
	TIME [epoch: 9.08 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0890527502225383		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.0890527502225383 | validation: 0.044974507076005255]
	TIME [epoch: 9.07 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671434363189774		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.06671434363189774 | validation: 0.04188272886485798]
	TIME [epoch: 9.08 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07231905409157723		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.07231905409157723 | validation: 0.035311022638531336]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_647.pth
	Model improved!!!
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07133829579321524		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.07133829579321524 | validation: 0.05500834140978973]
	TIME [epoch: 9.07 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405757171206287		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.07405757171206287 | validation: 0.0519097306932094]
	TIME [epoch: 9.08 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08998836203203965		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.08998836203203965 | validation: 0.05510491314996961]
	TIME [epoch: 9.07 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07728401979762695		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.07728401979762695 | validation: 0.06011463613697]
	TIME [epoch: 9.05 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07292718444091244		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.07292718444091244 | validation: 0.047650841250804835]
	TIME [epoch: 9.06 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0789359575502874		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.0789359575502874 | validation: 0.034999575047166866]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_653.pth
	Model improved!!!
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766405188729075		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.0766405188729075 | validation: 0.04742754949474426]
	TIME [epoch: 9.06 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08370075714615474		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.08370075714615474 | validation: 0.055874064062764045]
	TIME [epoch: 9.09 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.087490497549319		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.087490497549319 | validation: 0.05761910426321158]
	TIME [epoch: 9.05 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10855266873103311		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.10855266873103311 | validation: 0.05640343100993246]
	TIME [epoch: 9.06 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09534379192191442		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.09534379192191442 | validation: 0.04017345011294428]
	TIME [epoch: 9.05 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07734929436144207		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.07734929436144207 | validation: 0.04284783643487666]
	TIME [epoch: 9.06 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0680374174924996		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.0680374174924996 | validation: 0.0492657712879227]
	TIME [epoch: 9.08 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631113369516374		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.0631113369516374 | validation: 0.06688871027610871]
	TIME [epoch: 9.06 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09255290932660637		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.09255290932660637 | validation: 0.04242572688150731]
	TIME [epoch: 9.06 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936627640963964		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.05936627640963964 | validation: 0.04830458527714514]
	TIME [epoch: 9.05 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07052831603426532		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.07052831603426532 | validation: 0.06067590112593149]
	TIME [epoch: 9.06 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09842545531225258		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.09842545531225258 | validation: 0.0435299877292212]
	TIME [epoch: 9.08 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08705742766164663		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.08705742766164663 | validation: 0.05788801634773953]
	TIME [epoch: 9.06 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889590325171513		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.06889590325171513 | validation: 0.07924682662281661]
	TIME [epoch: 9.06 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07515280383082358		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.07515280383082358 | validation: 0.036820291236616384]
	TIME [epoch: 9.05 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.059320301264793374		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.059320301264793374 | validation: 0.05065277635813574]
	TIME [epoch: 9.06 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08561391392052636		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.08561391392052636 | validation: 0.05910567142789175]
	TIME [epoch: 9.07 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812424164968412		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.07812424164968412 | validation: 0.049282115281576395]
	TIME [epoch: 9.06 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07724061615684684		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.07724061615684684 | validation: 0.03994990352189484]
	TIME [epoch: 9.06 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06879738071488031		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.06879738071488031 | validation: 0.06649144184091749]
	TIME [epoch: 9.06 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07132390375388666		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.07132390375388666 | validation: 0.07810793401831101]
	TIME [epoch: 9.06 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07179031084232089		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.07179031084232089 | validation: 0.0586595692340383]
	TIME [epoch: 9.06 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08332984585795752		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.08332984585795752 | validation: 0.06466534063203075]
	TIME [epoch: 9.08 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0839016645088091		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.0839016645088091 | validation: 0.07291961992027114]
	TIME [epoch: 9.06 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09071080444420399		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.09071080444420399 | validation: 0.0641729034365982]
	TIME [epoch: 9.05 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06354825859981203		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.06354825859981203 | validation: 0.05163595931542245]
	TIME [epoch: 9.06 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06387464911710883		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.06387464911710883 | validation: 0.03988396524650294]
	TIME [epoch: 9.06 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0706684900482761		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.0706684900482761 | validation: 0.04060730917294017]
	TIME [epoch: 9.08 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08563717296604893		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.08563717296604893 | validation: 0.054143411091270466]
	TIME [epoch: 9.06 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783370241915197		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.06783370241915197 | validation: 0.048419799304338845]
	TIME [epoch: 9.05 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06829975079127394		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.06829975079127394 | validation: 0.07904846231506366]
	TIME [epoch: 9.06 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06739202615316903		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.06739202615316903 | validation: 0.11006209589060145]
	TIME [epoch: 9.07 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816340415019432		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.07816340415019432 | validation: 0.04277640052629494]
	TIME [epoch: 9.08 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245148057459782		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.06245148057459782 | validation: 0.050237475335213326]
	TIME [epoch: 9.08 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0711190711651338		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.0711190711651338 | validation: 0.058820734163491234]
	TIME [epoch: 9.06 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06743227925565767		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.06743227925565767 | validation: 0.05124363855218289]
	TIME [epoch: 9.06 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392003601317071		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.07392003601317071 | validation: 0.04054851194377364]
	TIME [epoch: 9.06 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09451798860075217		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.09451798860075217 | validation: 0.04692138271413336]
	TIME [epoch: 9.06 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06541730646493837		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.06541730646493837 | validation: 0.04798006543939991]
	TIME [epoch: 9.08 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07152267768056199		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.07152267768056199 | validation: 0.05519169294275121]
	TIME [epoch: 9.06 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07158587026140391		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.07158587026140391 | validation: 0.056438284361903776]
	TIME [epoch: 9.06 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06598505210855773		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.06598505210855773 | validation: 0.04196821360624693]
	TIME [epoch: 9.06 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05662662701495748		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.05662662701495748 | validation: 0.05990188425695391]
	TIME [epoch: 9.06 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06534854812547738		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.06534854812547738 | validation: 0.05515461291422621]
	TIME [epoch: 9.07 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06786421891243916		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.06786421891243916 | validation: 0.07435988310464567]
	TIME [epoch: 9.07 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06305416505417666		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.06305416505417666 | validation: 0.05083215024763362]
	TIME [epoch: 9.07 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10613551010325259		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.10613551010325259 | validation: 0.04308215970745223]
	TIME [epoch: 9.07 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06067981208161849		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.06067981208161849 | validation: 0.03524618589303632]
	TIME [epoch: 9.06 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914444397346618		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.06914444397346618 | validation: 0.051077710520863975]
	TIME [epoch: 9.07 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06064505410354033		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.06064505410354033 | validation: 0.05032590838253491]
	TIME [epoch: 9.07 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06948530843854231		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.06948530843854231 | validation: 0.045132422540501635]
	TIME [epoch: 9.05 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06155213948543078		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.06155213948543078 | validation: 0.05632493629747805]
	TIME [epoch: 9.06 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0670046702103202		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.0670046702103202 | validation: 0.06499625882073247]
	TIME [epoch: 9.06 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07242848743765026		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.07242848743765026 | validation: 0.05970917571644906]
	TIME [epoch: 9.06 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07177996151786949		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.07177996151786949 | validation: 0.05019119939957126]
	TIME [epoch: 9.08 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467411039202568		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.06467411039202568 | validation: 0.047536687625921024]
	TIME [epoch: 9.06 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07660776305824138		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.07660776305824138 | validation: 0.038095387017724414]
	TIME [epoch: 9.06 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07594781182264544		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.07594781182264544 | validation: 0.0390777399968697]
	TIME [epoch: 9.05 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629208102379788		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.06629208102379788 | validation: 0.07998719706782681]
	TIME [epoch: 9.07 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0610101416244905		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.0610101416244905 | validation: 0.048565344323219795]
	TIME [epoch: 9.08 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06265373473993516		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.06265373473993516 | validation: 0.09202611076791092]
	TIME [epoch: 9.08 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08682987336570719		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.08682987336570719 | validation: 0.057964648465892346]
	TIME [epoch: 9.07 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06198427579226495		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.06198427579226495 | validation: 0.04764639453214212]
	TIME [epoch: 9.06 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319897864563538		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.06319897864563538 | validation: 0.053737416430586354]
	TIME [epoch: 9.06 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539454074075506		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.06539454074075506 | validation: 0.044675653722492326]
	TIME [epoch: 9.06 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058927202484945006		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.058927202484945006 | validation: 0.03922473947247525]
	TIME [epoch: 9.08 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1011444068268321		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.1011444068268321 | validation: 0.09308974203016782]
	TIME [epoch: 9.06 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629967336199189		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.0629967336199189 | validation: 0.04355545812340436]
	TIME [epoch: 9.08 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07449432993461982		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.07449432993461982 | validation: 0.04406400096594981]
	TIME [epoch: 9.06 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06518099213691227		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.06518099213691227 | validation: 0.0448097156215646]
	TIME [epoch: 9.05 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06514819649650497		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.06514819649650497 | validation: 0.049471819509802825]
	TIME [epoch: 9.06 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06639195469538892		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.06639195469538892 | validation: 0.03958785773968625]
	TIME [epoch: 9.08 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06650952176586937		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.06650952176586937 | validation: 0.02652652355759426]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_726.pth
	Model improved!!!
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060664937819442086		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.060664937819442086 | validation: 0.08532216370114662]
	TIME [epoch: 9.07 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07496735238765435		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.07496735238765435 | validation: 0.058900601088612614]
	TIME [epoch: 9.06 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06175800094807282		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.06175800094807282 | validation: 0.053209703279247705]
	TIME [epoch: 9.05 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06339023004479884		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.06339023004479884 | validation: 0.03798405303259047]
	TIME [epoch: 9.08 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06159229758216317		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.06159229758216317 | validation: 0.039256697897758014]
	TIME [epoch: 9.05 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05944430038411367		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.05944430038411367 | validation: 0.042805948804414504]
	TIME [epoch: 9.06 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06318676656523523		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.06318676656523523 | validation: 0.04885820403091142]
	TIME [epoch: 9.05 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06044076512002652		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.06044076512002652 | validation: 0.035148988169316824]
	TIME [epoch: 9.05 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056476429660655136		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.056476429660655136 | validation: 0.046113340362190565]
	TIME [epoch: 9.07 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058731066628300785		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.058731066628300785 | validation: 0.05614969005187402]
	TIME [epoch: 9.05 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885125384700255		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.06885125384700255 | validation: 0.06526977198305087]
	TIME [epoch: 9.05 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07664842274566146		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.07664842274566146 | validation: 0.0775978336933513]
	TIME [epoch: 9.06 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06386607986229881		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.06386607986229881 | validation: 0.0626351473355906]
	TIME [epoch: 9.05 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05860695941750007		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.05860695941750007 | validation: 0.09232167175768052]
	TIME [epoch: 9.09 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450848660604699		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.07450848660604699 | validation: 0.05606983036320094]
	TIME [epoch: 9.06 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07854786866421015		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.07854786866421015 | validation: 0.04739891169713294]
	TIME [epoch: 9.05 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05907061179846358		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.05907061179846358 | validation: 0.05185707945280551]
	TIME [epoch: 9.06 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05821379933338764		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.05821379933338764 | validation: 0.031337553035655955]
	TIME [epoch: 9.05 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05977822249539551		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.05977822249539551 | validation: 0.04793741218501054]
	TIME [epoch: 9.06 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07781282505329806		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.07781282505329806 | validation: 0.05447561360554158]
	TIME [epoch: 9.06 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06817307238403678		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.06817307238403678 | validation: 0.04692034984540678]
	TIME [epoch: 9.05 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.062403418252627116		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.062403418252627116 | validation: 0.04000358713144936]
	TIME [epoch: 9.05 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06681152615506078		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.06681152615506078 | validation: 0.062290906106180155]
	TIME [epoch: 9.05 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05867312450149416		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.05867312450149416 | validation: 0.0396157088161988]
	TIME [epoch: 9.05 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06251866169119573		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.06251866169119573 | validation: 0.041844203887766246]
	TIME [epoch: 9.08 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06210297931575591		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.06210297931575591 | validation: 0.07211026140631493]
	TIME [epoch: 9.06 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06225332681816988		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.06225332681816988 | validation: 0.04948491961914926]
	TIME [epoch: 9.06 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06938656037118049		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.06938656037118049 | validation: 0.049474788110068994]
	TIME [epoch: 9.06 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07184450862683035		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.07184450862683035 | validation: 0.05146557731140217]
	TIME [epoch: 9.05 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0580058432073192		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.0580058432073192 | validation: 0.030659056335732994]
	TIME [epoch: 9.07 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04905819777175039		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.04905819777175039 | validation: 0.033446851639312755]
	TIME [epoch: 9.06 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06549579358481929		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.06549579358481929 | validation: 0.03935126636371069]
	TIME [epoch: 9.06 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06233482886159365		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.06233482886159365 | validation: 0.05438571158394789]
	TIME [epoch: 9.06 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0600026802745395		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.0600026802745395 | validation: 0.031146446344524053]
	TIME [epoch: 9.06 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051958278828392046		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.051958278828392046 | validation: 0.03863697561476937]
	TIME [epoch: 9.07 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07166901963518887		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.07166901963518887 | validation: 0.041367836888337235]
	TIME [epoch: 9.08 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05618745497919793		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.05618745497919793 | validation: 0.0359228492280059]
	TIME [epoch: 9.07 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06124856747347589		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.06124856747347589 | validation: 0.06930618279780046]
	TIME [epoch: 9.06 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07107003798667366		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.07107003798667366 | validation: 0.062192923896988495]
	TIME [epoch: 9.07 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06525909189265137		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.06525909189265137 | validation: 0.03521859896514469]
	TIME [epoch: 9.06 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05883979309436012		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.05883979309436012 | validation: 0.060384363311299476]
	TIME [epoch: 9.07 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0696924865781201		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.0696924865781201 | validation: 0.033063568377305626]
	TIME [epoch: 9.07 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06537722471822263		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.06537722471822263 | validation: 0.04411200104836209]
	TIME [epoch: 9.05 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05279643487054202		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.05279643487054202 | validation: 0.03160283535427129]
	TIME [epoch: 9.05 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06412172112916255		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.06412172112916255 | validation: 0.048532092932073514]
	TIME [epoch: 9.05 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07675985994934212		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.07675985994934212 | validation: 0.041647481927082244]
	TIME [epoch: 9.06 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0655963468661532		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.0655963468661532 | validation: 0.03984174733052221]
	TIME [epoch: 9.07 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058183016024551525		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.058183016024551525 | validation: 0.05598317143064943]
	TIME [epoch: 9.06 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06263594055178419		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.06263594055178419 | validation: 0.08575998891554801]
	TIME [epoch: 9.05 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662622612361526		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.0662622612361526 | validation: 0.05097547333327397]
	TIME [epoch: 9.05 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060147051687599096		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.060147051687599096 | validation: 0.059530041162919614]
	TIME [epoch: 9.05 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060030309362557835		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.060030309362557835 | validation: 0.03992542868282187]
	TIME [epoch: 9.09 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05244410202047928		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.05244410202047928 | validation: 0.04806494647466558]
	TIME [epoch: 9.06 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0593263087885702		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.0593263087885702 | validation: 0.04329906913785789]
	TIME [epoch: 9.06 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05409515452326291		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.05409515452326291 | validation: 0.03928120361036554]
	TIME [epoch: 9.06 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05879021610422656		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.05879021610422656 | validation: 0.07278425239560418]
	TIME [epoch: 9.05 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07057952850573854		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.07057952850573854 | validation: 0.05253806765354094]
	TIME [epoch: 9.06 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08173380781384545		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.08173380781384545 | validation: 0.057733909656542196]
	TIME [epoch: 9.07 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632834974435892		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.06632834974435892 | validation: 0.0507581401623386]
	TIME [epoch: 9.06 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06300342142059745		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.06300342142059745 | validation: 0.04940617949327915]
	TIME [epoch: 9.05 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05277004201486453		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.05277004201486453 | validation: 0.034357872238777405]
	TIME [epoch: 9.05 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05817249692145421		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.05817249692145421 | validation: 0.06622969112684593]
	TIME [epoch: 9.04 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06685561959673536		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.06685561959673536 | validation: 0.04353035471027381]
	TIME [epoch: 9.07 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.059888206033109445		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.059888206033109445 | validation: 0.048060645807132915]
	TIME [epoch: 9.04 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06646710656378522		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.06646710656378522 | validation: 0.05206763277707172]
	TIME [epoch: 9.06 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06080836849103179		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.06080836849103179 | validation: 0.06215442447890236]
	TIME [epoch: 9.06 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054877298980438804		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.054877298980438804 | validation: 0.04811407085122761]
	TIME [epoch: 9.06 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07341770812774592		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.07341770812774592 | validation: 0.03105403264132446]
	TIME [epoch: 9.07 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07269014488480412		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.07269014488480412 | validation: 0.05945451542004178]
	TIME [epoch: 9.06 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05622800602327653		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.05622800602327653 | validation: 0.040395134371706984]
	TIME [epoch: 9.05 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05551848885993227		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.05551848885993227 | validation: 0.035547176680008875]
	TIME [epoch: 9.05 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05342768923451206		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.05342768923451206 | validation: 0.04585578760346712]
	TIME [epoch: 9.05 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.059542598728179075		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.059542598728179075 | validation: 0.07489355536515135]
	TIME [epoch: 9.06 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08433214439823704		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.08433214439823704 | validation: 0.05067436366775137]
	TIME [epoch: 9.07 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06526973773942238		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.06526973773942238 | validation: 0.048888687995095985]
	TIME [epoch: 9.06 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05732518746143458		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.05732518746143458 | validation: 0.03779188809435103]
	TIME [epoch: 9.05 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06356847903381846		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.06356847903381846 | validation: 0.03799809484274594]
	TIME [epoch: 9.05 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0517754710020055		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.0517754710020055 | validation: 0.08215273046389468]
	TIME [epoch: 9.05 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05944811642305856		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.05944811642305856 | validation: 0.03599384304130675]
	TIME [epoch: 9.08 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0576334149836879		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.0576334149836879 | validation: 0.02317852244129942]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240217_161441/states/model_tr_study4_806.pth
	Model improved!!!
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0499914689681719		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.0499914689681719 | validation: 0.03517600787238899]
	TIME [epoch: 9.05 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05199582312326727		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.05199582312326727 | validation: 0.056535376213050534]
	TIME [epoch: 9.05 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06840265889588668		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.06840265889588668 | validation: 0.04669378375579737]
	TIME [epoch: 9.05 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05327462136934179		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.05327462136934179 | validation: 0.042082551988861586]
	TIME [epoch: 9.05 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052037847391764404		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.052037847391764404 | validation: 0.03845235382128055]
	TIME [epoch: 9.06 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06293029836931266		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.06293029836931266 | validation: 0.03630028557394785]
	TIME [epoch: 9.05 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0618591821559207		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.0618591821559207 | validation: 0.03302013052746651]
	TIME [epoch: 9.04 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05636689382111028		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.05636689382111028 | validation: 0.04277977913835672]
	TIME [epoch: 9.05 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07096197087612197		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.07096197087612197 | validation: 0.03962756054912888]
	TIME [epoch: 9.04 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05818405202496783		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.05818405202496783 | validation: 0.039805670948757005]
	TIME [epoch: 9.07 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05512138792483902		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.05512138792483902 | validation: 0.03875072447146645]
	TIME [epoch: 9.06 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054611046940746144		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.054611046940746144 | validation: 0.038416065584025674]
	TIME [epoch: 9.07 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05080016857674581		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.05080016857674581 | validation: 0.036159082158061365]
	TIME [epoch: 9.07 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051273563037292025		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.051273563037292025 | validation: 0.03579403433766138]
	TIME [epoch: 9.06 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06704520608727556		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.06704520608727556 | validation: 0.06977732096127917]
	TIME [epoch: 9.08 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06355141971841331		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.06355141971841331 | validation: 0.035608958906321694]
	TIME [epoch: 9.05 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049911843993404564		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.049911843993404564 | validation: 0.04302735762047086]
	TIME [epoch: 9.05 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06148392376166874		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.06148392376166874 | validation: 0.0528789584137507]
	TIME [epoch: 9.05 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07672232832681505		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.07672232832681505 | validation: 0.06426308786437789]
	TIME [epoch: 9.05 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07611906297314311		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.07611906297314311 | validation: 0.05198989582503678]
	TIME [epoch: 9.06 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05764067227213099		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.05764067227213099 | validation: 0.039105090004233664]
	TIME [epoch: 9.07 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05143257797379451		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.05143257797379451 | validation: 0.04820970804401707]
	TIME [epoch: 9.04 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058529287221879944		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.058529287221879944 | validation: 0.02958621512169884]
	TIME [epoch: 9.05 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04767953803554168		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.04767953803554168 | validation: 0.03208536762518492]
	TIME [epoch: 9.05 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05219931103744183		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.05219931103744183 | validation: 0.04573600046081701]
	TIME [epoch: 9.06 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05434170918831045		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.05434170918831045 | validation: 0.047536429797743904]
	TIME [epoch: 9.08 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05626564214332469		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.05626564214332469 | validation: 0.04738209133218835]
	TIME [epoch: 9.06 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05291480573514884		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.05291480573514884 | validation: 0.03821383817130247]
	TIME [epoch: 9.06 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056394963452500925		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.056394963452500925 | validation: 0.035361671559945775]
	TIME [epoch: 9.05 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05464448823238357		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.05464448823238357 | validation: 0.03983726804592715]
	TIME [epoch: 9.04 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06572073218906724		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.06572073218906724 | validation: 0.056274224255232874]
	TIME [epoch: 9.07 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06390079216803696		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.06390079216803696 | validation: 0.029237835663412606]
	TIME [epoch: 9.06 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054849428954681125		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.054849428954681125 | validation: 0.04591176212232094]
	TIME [epoch: 9.06 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05577860068769873		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.05577860068769873 | validation: 0.03510158405330408]
	TIME [epoch: 9.05 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053872025077978114		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.053872025077978114 | validation: 0.04447624924472541]
	TIME [epoch: 9.06 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05499690471938706		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.05499690471938706 | validation: 0.03088201665911716]
	TIME [epoch: 9.05 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05752101001422607		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.05752101001422607 | validation: 0.04360224539202266]
	TIME [epoch: 9.06 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05308341272310677		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.05308341272310677 | validation: 0.034769815539953196]
	TIME [epoch: 9.07 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05659506173756804		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.05659506173756804 | validation: 0.02664325703603655]
	TIME [epoch: 9.06 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0532554862286744		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.0532554862286744 | validation: 0.05806218533094884]
	TIME [epoch: 9.06 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05803061773621356		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.05803061773621356 | validation: 0.030868013985549343]
	TIME [epoch: 9.06 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04944136765082737		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.04944136765082737 | validation: 0.05918566682171157]
	TIME [epoch: 9.07 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358088990071409		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.06358088990071409 | validation: 0.05753993896414377]
	TIME [epoch: 9.06 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061483321425793325		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.061483321425793325 | validation: 0.029346265266705848]
	TIME [epoch: 9.05 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06028384734679613		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.06028384734679613 | validation: 0.040538183612186224]
	TIME [epoch: 9.06 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054734170239418525		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.054734170239418525 | validation: 0.05901046798056405]
	TIME [epoch: 9.05 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06149416847685761		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.06149416847685761 | validation: 0.05153805651284228]
	TIME [epoch: 9.06 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058477079041323154		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.058477079041323154 | validation: 0.029636442948185363]
	TIME [epoch: 9.08 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053131079697611314		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.053131079697611314 | validation: 0.03869009568177957]
	TIME [epoch: 9.05 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05441661497958972		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.05441661497958972 | validation: 0.03588909133055312]
	TIME [epoch: 9.05 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05219371706664153		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.05219371706664153 | validation: 0.03302658079184912]
	TIME [epoch: 9.06 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05743452839634944		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.05743452839634944 | validation: 0.05018693715907373]
	TIME [epoch: 9.06 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0599110193024225		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.0599110193024225 | validation: 0.048152953810688376]
	TIME [epoch: 9.09 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0563542129121968		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.0563542129121968 | validation: 0.028009855652930946]
	TIME [epoch: 9.05 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05153648288914005		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.05153648288914005 | validation: 0.03528697982383326]
	TIME [epoch: 9.05 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06332033881104163		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.06332033881104163 | validation: 0.05688185966846433]
	TIME [epoch: 9.05 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05808519979096758		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.05808519979096758 | validation: 0.03606615924439966]
	TIME [epoch: 9.04 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051435881622832615		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.051435881622832615 | validation: 0.047629918925262554]
	TIME [epoch: 9.07 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06446681879798713		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.06446681879798713 | validation: 0.034960501976826895]
	TIME [epoch: 9.06 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05800593120660567		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.05800593120660567 | validation: 0.048615479422238955]
	TIME [epoch: 9.04 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0550895357737458		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.0550895357737458 | validation: 0.05698000570386227]
	TIME [epoch: 9.05 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885423688294853		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.06885423688294853 | validation: 0.037064553575966316]
	TIME [epoch: 9.05 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04967335675678099		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.04967335675678099 | validation: 0.037711138627589263]
	TIME [epoch: 9.05 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056749411227685585		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.056749411227685585 | validation: 0.03926739373724111]
	TIME [epoch: 9.07 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0566815657463021		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.0566815657463021 | validation: 0.04419964136844971]
	TIME [epoch: 9.06 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05245438245262324		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.05245438245262324 | validation: 0.038638296754093686]
	TIME [epoch: 9.06 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051844611325390755		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.051844611325390755 | validation: 0.03840320631524259]
	TIME [epoch: 9.05 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05280379044760088		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.05280379044760088 | validation: 0.0314202254953954]
	TIME [epoch: 9.05 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04882833945673465		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.04882833945673465 | validation: 0.03450380769193967]
	TIME [epoch: 9.07 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058191926037745215		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.058191926037745215 | validation: 0.050373552554121015]
	TIME [epoch: 9.06 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060875268218801994		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.060875268218801994 | validation: 0.03872031812629883]
	TIME [epoch: 9.06 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05438632828609448		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.05438632828609448 | validation: 0.04475303093366853]
	TIME [epoch: 9.06 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.059215013726690656		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.059215013726690656 | validation: 0.04756325228291565]
	TIME [epoch: 9.06 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05080540398158908		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.05080540398158908 | validation: 0.029733697949514755]
	TIME [epoch: 9.06 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047748427574942125		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.047748427574942125 | validation: 0.04657338128635779]
	TIME [epoch: 9.06 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056709145839944984		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.056709145839944984 | validation: 0.042207171442490476]
	TIME [epoch: 9.06 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05651592122385972		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.05651592122385972 | validation: 0.045435783754929626]
	TIME [epoch: 9.05 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050015577973931066		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.050015577973931066 | validation: 0.03281961743575765]
	TIME [epoch: 9.05 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06004625654936881		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.06004625654936881 | validation: 0.039677814618348406]
	TIME [epoch: 9.06 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05362628157041632		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.05362628157041632 | validation: 0.03578409795368565]
	TIME [epoch: 9.08 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050817392270401066		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.050817392270401066 | validation: 0.035559318019610014]
	TIME [epoch: 9.06 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05694007694354038		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.05694007694354038 | validation: 0.04617929840603063]
	TIME [epoch: 9.05 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05830501205021401		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.05830501205021401 | validation: 0.04214511439838345]
	TIME [epoch: 9.04 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05127298841170506		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.05127298841170506 | validation: 0.03356127737789897]
	TIME [epoch: 9.05 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05240258690388646		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.05240258690388646 | validation: 0.03608232052360805]
	TIME [epoch: 9.06 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053228638717312225		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.053228638717312225 | validation: 0.03862896653227295]
	TIME [epoch: 9.07 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0501207469353356		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.0501207469353356 | validation: 0.03893889831295122]
	TIME [epoch: 9.06 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06147079121591805		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.06147079121591805 | validation: 0.04008470342059889]
	TIME [epoch: 9.05 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048025257390403496		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.048025257390403496 | validation: 0.03877794886948029]
	TIME [epoch: 9.05 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06314311453733137		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.06314311453733137 | validation: 0.06106716293840017]
	TIME [epoch: 9.05 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05820629144751523		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.05820629144751523 | validation: 0.039468012435274584]
	TIME [epoch: 9.08 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05010669157090003		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.05010669157090003 | validation: 0.04425403049883714]
	TIME [epoch: 9.05 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05591968977112486		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.05591968977112486 | validation: 0.050193222216115906]
	TIME [epoch: 9.05 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049740625291434346		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.049740625291434346 | validation: 0.02919194456035411]
	TIME [epoch: 9.06 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05686972304762995		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.05686972304762995 | validation: 0.04516956663088789]
	TIME [epoch: 9.05 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05816706840864065		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.05816706840864065 | validation: 0.04954515124189314]
	TIME [epoch: 9.07 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0517853337291451		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.0517853337291451 | validation: 0.04330250482074515]
	TIME [epoch: 9.06 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060977228786392314		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.060977228786392314 | validation: 0.03555790288034481]
	TIME [epoch: 9.06 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04884254077896304		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.04884254077896304 | validation: 0.03663562615637203]
	TIME [epoch: 9.06 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048408131135570576		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.048408131135570576 | validation: 0.05428377697651237]
	TIME [epoch: 9.05 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05929645462273292		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.05929645462273292 | validation: 0.0391804420965847]
	TIME [epoch: 9.06 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053704611705030394		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.053704611705030394 | validation: 0.04326426297521196]
	TIME [epoch: 9.07 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05684169267795101		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.05684169267795101 | validation: 0.04492458933767508]
	TIME [epoch: 9.05 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06385856027564527		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.06385856027564527 | validation: 0.04040245597538807]
	TIME [epoch: 9.06 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050314354568625486		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.050314354568625486 | validation: 0.04591738288478509]
	TIME [epoch: 9.06 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05263211326042252		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.05263211326042252 | validation: 0.05454026490624092]
	TIME [epoch: 9.06 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05819227715576856		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.05819227715576856 | validation: 0.03925259586290407]
	TIME [epoch: 9.08 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05180249029687328		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.05180249029687328 | validation: 0.04376157754915824]
	TIME [epoch: 9.05 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056081588559071624		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.056081588559071624 | validation: 0.03631413950374074]
	TIME [epoch: 9.05 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015280782593093		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.06015280782593093 | validation: 0.045019516130362924]
	TIME [epoch: 9.05 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053126854231085555		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.053126854231085555 | validation: 0.02712034002042609]
	TIME [epoch: 9.05 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04773695208898723		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.04773695208898723 | validation: 0.0350886842260362]
	TIME [epoch: 9.06 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05254482975308396		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.05254482975308396 | validation: 0.026356187414984737]
	TIME [epoch: 9.06 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0562888458280917		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.0562888458280917 | validation: 0.029873879188296044]
	TIME [epoch: 9.05 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050530198674765645		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.050530198674765645 | validation: 0.04133261393253536]
	TIME [epoch: 9.05 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05232537126806458		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.05232537126806458 | validation: 0.04702620096441226]
	TIME [epoch: 9.05 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05491151863347997		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.05491151863347997 | validation: 0.043820416589018335]
	TIME [epoch: 9.06 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05504952774185899		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.05504952774185899 | validation: 0.036964715221914454]
	TIME [epoch: 9.08 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056094343286372514		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.056094343286372514 | validation: 0.04757424015715191]
	TIME [epoch: 9.06 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050750250682762586		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.050750250682762586 | validation: 0.03749864702297447]
	TIME [epoch: 9.05 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052720273168195185		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.052720273168195185 | validation: 0.030262034297479534]
	TIME [epoch: 9.05 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049786354304981476		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.049786354304981476 | validation: 0.04198625741413692]
	TIME [epoch: 9.05 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.057767708652292714		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.057767708652292714 | validation: 0.03944405217340499]
	TIME [epoch: 9.06 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05568383846753988		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.05568383846753988 | validation: 0.03165576530137925]
	TIME [epoch: 9.06 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0589701000143056		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.0589701000143056 | validation: 0.04450268722041367]
	TIME [epoch: 9.05 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05571337507842462		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.05571337507842462 | validation: 0.052029641003893366]
	TIME [epoch: 9.05 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642973068809122		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.0642973068809122 | validation: 0.0380142644113538]
	TIME [epoch: 9.06 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056860190151890276		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.056860190151890276 | validation: 0.0511185203996335]
	TIME [epoch: 9.06 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061565807130900395		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.061565807130900395 | validation: 0.029448029867122714]
	TIME [epoch: 9.08 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052786468992655586		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.052786468992655586 | validation: 0.0436023844278699]
	TIME [epoch: 9.06 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05858627374444954		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.05858627374444954 | validation: 0.03510696092469293]
	TIME [epoch: 9.06 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05721181819275789		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.05721181819275789 | validation: 0.04118563127959507]
	TIME [epoch: 9.06 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06117584286520137		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.06117584286520137 | validation: 0.03480130759003015]
	TIME [epoch: 9.05 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05182223895242344		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.05182223895242344 | validation: 0.04223196003159528]
	TIME [epoch: 9.07 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05103891852379131		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.05103891852379131 | validation: 0.040697283568063417]
	TIME [epoch: 9.06 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06445062431000574		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.06445062431000574 | validation: 0.0475844008602187]
	TIME [epoch: 9.05 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05068762332833262		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.05068762332833262 | validation: 0.041106445110641626]
	TIME [epoch: 9.05 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05235250679620442		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.05235250679620442 | validation: 0.05038066305310712]
	TIME [epoch: 9.14 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05254247654445153		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.05254247654445153 | validation: 0.02859099043995856]
	TIME [epoch: 9.06 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050827436394311344		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.050827436394311344 | validation: 0.0358586282624158]
	TIME [epoch: 9.07 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048799514562614846		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.048799514562614846 | validation: 0.03385948437550541]
	TIME [epoch: 9.04 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053991330265133086		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.053991330265133086 | validation: 0.0388861169478005]
	TIME [epoch: 9.05 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047744082853642275		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.047744082853642275 | validation: 0.039130459014684336]
	TIME [epoch: 9.06 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04925212989815274		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.04925212989815274 | validation: 0.0363978361970677]
	TIME [epoch: 9.06 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05429281438794244		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.05429281438794244 | validation: 0.04407140062374955]
	TIME [epoch: 9.08 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053080148244208904		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.053080148244208904 | validation: 0.034595408858342]
	TIME [epoch: 9.06 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05318932260231386		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.05318932260231386 | validation: 0.04506596839537183]
	TIME [epoch: 9.05 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045593043873649555		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.045593043873649555 | validation: 0.03054836739712101]
	TIME [epoch: 9.05 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04843632238049066		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.04843632238049066 | validation: 0.04164078117388795]
	TIME [epoch: 9.04 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05020635274421882		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.05020635274421882 | validation: 0.033283086655463257]
	TIME [epoch: 9.06 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049376746212209985		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.049376746212209985 | validation: 0.030278881086445043]
	TIME [epoch: 9.06 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05156601160318105		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.05156601160318105 | validation: 0.056920478798156274]
	TIME [epoch: 9.04 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304867256579608		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.06304867256579608 | validation: 0.04191223166761207]
	TIME [epoch: 9.06 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05052494618657729		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.05052494618657729 | validation: 0.03579660331584385]
	TIME [epoch: 9.04 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053825669897019736		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.053825669897019736 | validation: 0.03402074472164396]
	TIME [epoch: 9.05 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05453625465468835		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.05453625465468835 | validation: 0.03678768514919268]
	TIME [epoch: 9.07 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051972563428395235		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.051972563428395235 | validation: 0.052371094871579246]
	TIME [epoch: 9.06 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05140424185589261		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.05140424185589261 | validation: 0.04541069642207392]
	TIME [epoch: 9.06 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05600137976183126		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.05600137976183126 | validation: 0.045268169188694515]
	TIME [epoch: 9.05 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05398555185726507		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.05398555185726507 | validation: 0.03246418534712256]
	TIME [epoch: 9.05 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05069969765178124		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.05069969765178124 | validation: 0.03661901429072924]
	TIME [epoch: 9.07 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05174899289347669		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.05174899289347669 | validation: 0.0329137367222323]
	TIME [epoch: 9.05 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05507510298415276		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.05507510298415276 | validation: 0.04534529526352949]
	TIME [epoch: 9.05 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05308596992918918		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.05308596992918918 | validation: 0.040026630884980485]
	TIME [epoch: 9.05 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061831300694681804		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.061831300694681804 | validation: 0.029945071072561516]
	TIME [epoch: 9.05 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054789892686938166		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.054789892686938166 | validation: 0.03970264720675258]
	TIME [epoch: 9.06 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06142736995334892		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.06142736995334892 | validation: 0.03483609951513339]
	TIME [epoch: 9.06 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05058187491000073		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.05058187491000073 | validation: 0.0408938605242953]
	TIME [epoch: 9.05 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.055239217573923735		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.055239217573923735 | validation: 0.035058080621945306]
	TIME [epoch: 9.05 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047193470474084245		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.047193470474084245 | validation: 0.03589492544430805]
	TIME [epoch: 9.05 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050267946331661706		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.050267946331661706 | validation: 0.03257787043102878]
	TIME [epoch: 9.06 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05171587807204643		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.05171587807204643 | validation: 0.03982419685023186]
	TIME [epoch: 9.08 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05161756178735326		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.05161756178735326 | validation: 0.041155372582065475]
	TIME [epoch: 9.07 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05190252867531906		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.05190252867531906 | validation: 0.0453777734938743]
	TIME [epoch: 9.05 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050348097919024795		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.050348097919024795 | validation: 0.024577306042985875]
	TIME [epoch: 9.05 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05216431063030408		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.05216431063030408 | validation: 0.03364577149809539]
	TIME [epoch: 9.05 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05354943840875065		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.05354943840875065 | validation: 0.04157470716313191]
	TIME [epoch: 9.06 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05244557690525149		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.05244557690525149 | validation: 0.029064521516359798]
	TIME [epoch: 9.07 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04725750075448944		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.04725750075448944 | validation: 0.032702379434791796]
	TIME [epoch: 9.05 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04619778053150884		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.04619778053150884 | validation: 0.031050450160034302]
	TIME [epoch: 9.05 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04799827092534939		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.04799827092534939 | validation: 0.038641607621211715]
	TIME [epoch: 9.05 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05356133640458081		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.05356133640458081 | validation: 0.03713276027081974]
	TIME [epoch: 9.04 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05139007621368837		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.05139007621368837 | validation: 0.04948407968352578]
	TIME [epoch: 9.09 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.061599895911018776		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.061599895911018776 | validation: 0.052060740487209156]
	TIME [epoch: 9.07 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05071119688958002		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.05071119688958002 | validation: 0.03186863456157707]
	TIME [epoch: 9.06 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05349836989126392		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.05349836989126392 | validation: 0.046271182820284376]
	TIME [epoch: 9.06 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06271432709871866		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.06271432709871866 | validation: 0.037901006670782555]
	TIME [epoch: 9.04 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05200024418678832		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.05200024418678832 | validation: 0.04584940524171573]
	TIME [epoch: 9.08 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05962455423065347		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.05962455423065347 | validation: 0.03781763855815275]
	TIME [epoch: 9.07 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04896915083137865		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.04896915083137865 | validation: 0.032383626571044224]
	TIME [epoch: 9.05 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05149119920723335		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.05149119920723335 | validation: 0.03906091472498904]
	TIME [epoch: 9.05 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052065551173962964		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.052065551173962964 | validation: 0.03711468008768035]
	TIME [epoch: 9.05 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05152624396697271		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.05152624396697271 | validation: 0.0384675791234233]
	TIME [epoch: 9.06 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054696391111251554		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.054696391111251554 | validation: 0.030435736700868403]
	TIME [epoch: 9.04 sec]
Finished training in 9170.763 seconds.
