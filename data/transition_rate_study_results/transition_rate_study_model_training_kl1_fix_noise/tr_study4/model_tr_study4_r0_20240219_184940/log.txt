Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2350899406

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.667896039043551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.667896039043551 | validation: 9.45422417820031]
	TIME [epoch: 79.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.271805375428242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.271805375428242 | validation: 7.95219123088367]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.310339930396962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.310339930396962 | validation: 7.693314016848651]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.932376355265072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.932376355265072 | validation: 9.073368648676793]
	TIME [epoch: 8.34 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.540859727810687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.540859727810687 | validation: 7.3273283567710354]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.631336426148264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.631336426148264 | validation: 7.0467251067855265]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.568311250845946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.568311250845946 | validation: 7.1313034721846265]
	TIME [epoch: 8.36 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.581285503122674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.581285503122674 | validation: 6.998738300726349]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.229530723708109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.229530723708109 | validation: 5.653336887596055]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.253975925731539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.253975925731539 | validation: 4.407987947463777]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9647442292722928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9647442292722928 | validation: 4.270355201747664]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.083514937941262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.083514937941262 | validation: 5.0214908381646]
	TIME [epoch: 8.61 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.897325109181787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.897325109181787 | validation: 5.288635730953005]
	TIME [epoch: 8.33 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.169200982408752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.169200982408752 | validation: 4.504528528785296]
	TIME [epoch: 8.32 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.571650334078794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.571650334078794 | validation: 4.847894738027113]
	TIME [epoch: 8.36 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.108116457568731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.108116457568731 | validation: 4.037491001720837]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.547585315867547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.547585315867547 | validation: 6.212177996184215]
	TIME [epoch: 8.33 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.221291786661534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.221291786661534 | validation: 4.07335029897231]
	TIME [epoch: 8.33 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9266747983740147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9266747983740147 | validation: 5.690577765425213]
	TIME [epoch: 8.35 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.769052586633447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.769052586633447 | validation: 3.866045536588409]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.427516978410979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.427516978410979 | validation: 4.233325746034808]
	TIME [epoch: 8.33 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.571266297784093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.571266297784093 | validation: 3.9763110014050183]
	TIME [epoch: 8.33 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.429089885358734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.429089885358734 | validation: 4.395085634141575]
	TIME [epoch: 8.36 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.271057049070394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.271057049070394 | validation: 4.162120906088726]
	TIME [epoch: 8.33 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3527253796426195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3527253796426195 | validation: 3.508683095202926]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8254048964779854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8254048964779854 | validation: 4.86219537098327]
	TIME [epoch: 8.32 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.829913207892929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.829913207892929 | validation: 4.122282320234963]
	TIME [epoch: 8.34 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.776257185148137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.776257185148137 | validation: 3.8667179142780412]
	TIME [epoch: 8.32 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.1152645705184545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1152645705184545 | validation: 3.6362796704966476]
	TIME [epoch: 8.31 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2307717928546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2307717928546 | validation: 4.716045969798324]
	TIME [epoch: 8.32 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.93913207484294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.93913207484294 | validation: 4.938349520903626]
	TIME [epoch: 8.33 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.361731882940289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.361731882940289 | validation: 4.341483782031881]
	TIME [epoch: 8.32 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.437560451380515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.437560451380515 | validation: 3.575557642612181]
	TIME [epoch: 8.32 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.807420084243213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.807420084243213 | validation: 4.133371429576711]
	TIME [epoch: 8.33 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.090086747358732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.090086747358732 | validation: 3.824205041268341]
	TIME [epoch: 8.33 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.930607124448466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.930607124448466 | validation: 3.470580661971649]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.060809173091603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.060809173091603 | validation: 3.7043961766769584]
	TIME [epoch: 8.33 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8482669399144256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8482669399144256 | validation: 3.525599771281829]
	TIME [epoch: 8.34 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9034862183795425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9034862183795425 | validation: 3.4282876228993127]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8224983070415854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8224983070415854 | validation: 3.5799625091894343]
	TIME [epoch: 8.32 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.991327533594758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.991327533594758 | validation: 3.536380962413297]
	TIME [epoch: 8.31 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1693555315397726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1693555315397726 | validation: 3.42409812012011]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7683768160599063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7683768160599063 | validation: 3.8300351735998657]
	TIME [epoch: 8.33 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5888595086771353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5888595086771353 | validation: 3.5746122000112184]
	TIME [epoch: 8.32 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1702503279509555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1702503279509555 | validation: 3.5826188800128183]
	TIME [epoch: 8.31 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0475471439002852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0475471439002852 | validation: 3.7566517642326502]
	TIME [epoch: 8.33 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9801619601200215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9801619601200215 | validation: 3.6741622806386705]
	TIME [epoch: 8.32 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.991662784677144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.991662784677144 | validation: 3.4526013890181035]
	TIME [epoch: 8.31 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.394873344707316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.394873344707316 | validation: 4.914059041416177]
	TIME [epoch: 8.31 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.942131293037986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.942131293037986 | validation: 3.9763914796467965]
	TIME [epoch: 8.33 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.4305327045375344		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 4.4305327045375344 | validation: 3.940678254223309]
	TIME [epoch: 8.32 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.352024598764207		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 3.352024598764207 | validation: 5.431586326749814]
	TIME [epoch: 8.31 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2845421930280265		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 3.2845421930280265 | validation: 3.4338122720179447]
	TIME [epoch: 8.31 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.814723411663129		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.814723411663129 | validation: 3.5130690401234403]
	TIME [epoch: 8.33 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9189946241277775		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 2.9189946241277775 | validation: 3.7639377604015625]
	TIME [epoch: 8.32 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9064038780594146		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 2.9064038780594146 | validation: 3.4156623008224845]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8149428794612126		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 2.8149428794612126 | validation: 3.5107805280852675]
	TIME [epoch: 8.31 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.873328250331003		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 2.873328250331003 | validation: 6.058763469592835]
	TIME [epoch: 8.34 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.869555121510904		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 3.869555121510904 | validation: 3.319543588175094]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9333143871926213		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 2.9333143871926213 | validation: 3.3295040226643793]
	TIME [epoch: 8.31 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7808220121035125		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 2.7808220121035125 | validation: 3.2741160479552294]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.138464343813214		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 3.138464343813214 | validation: 3.212636232690425]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.18066863420828		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 3.18066863420828 | validation: 4.44346380705654]
	TIME [epoch: 8.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.511162537958648		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 3.511162537958648 | validation: 4.023913124952543]
	TIME [epoch: 8.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6919286538106606		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 3.6919286538106606 | validation: 5.15760413887267]
	TIME [epoch: 8.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3064257041382454		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 3.3064257041382454 | validation: 3.30766398678406]
	TIME [epoch: 8.34 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.002653540523479		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 3.002653540523479 | validation: 5.292466472378461]
	TIME [epoch: 8.31 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.071982748270411		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 3.071982748270411 | validation: 4.079153268429058]
	TIME [epoch: 8.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2137665078325184		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 3.2137665078325184 | validation: 3.4283453308228458]
	TIME [epoch: 8.31 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0499755607726433		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 3.0499755607726433 | validation: 5.655420497662715]
	TIME [epoch: 8.33 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.798912797239671		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 3.798912797239671 | validation: 3.4666781387971213]
	TIME [epoch: 8.31 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.808314030072208		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 2.808314030072208 | validation: 3.419694268647372]
	TIME [epoch: 8.31 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.758782388953257		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 2.758782388953257 | validation: 3.8188089425071094]
	TIME [epoch: 8.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8352908295228945		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 2.8352908295228945 | validation: 3.0715475801845202]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8026346380513396		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 2.8026346380513396 | validation: 3.545770012091777]
	TIME [epoch: 8.31 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.847186181854627		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 2.847186181854627 | validation: 3.299231260594908]
	TIME [epoch: 8.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.65787475932827		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 2.65787475932827 | validation: 3.2508458683144323]
	TIME [epoch: 8.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.710314668798615		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 2.710314668798615 | validation: 3.040076184947763]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.649267056756769		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 2.649267056756769 | validation: 3.278635540290505]
	TIME [epoch: 8.31 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.586354487556446		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 2.586354487556446 | validation: 2.804895145125771]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8407779842303524		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 2.8407779842303524 | validation: 3.696577400033981]
	TIME [epoch: 8.32 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7922230428001447		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 2.7922230428001447 | validation: 3.419641120141962]
	TIME [epoch: 8.36 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5499838181131436		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 2.5499838181131436 | validation: 2.7716239034915438]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.187262176701625		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 2.187262176701625 | validation: 2.4853336512533355]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3560610657803664		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 2.3560610657803664 | validation: 2.47832103848201]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9319537042912227		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 1.9319537042912227 | validation: 1.9918610237797458]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7570729707374717		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 1.7570729707374717 | validation: 1.8015075305515813]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4669452468488189		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 1.4669452468488189 | validation: 1.6783976807792609]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.431218828616133		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 1.431218828616133 | validation: 1.2868608079532464]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1591751057238358		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 1.1591751057238358 | validation: 1.4524913602729241]
	TIME [epoch: 8.34 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1961811499671262		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 1.1961811499671262 | validation: 1.4360496347697236]
	TIME [epoch: 8.32 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3736942514426915		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 1.3736942514426915 | validation: 1.940482965741904]
	TIME [epoch: 8.33 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1600984746083312		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.1600984746083312 | validation: 1.6436462604785977]
	TIME [epoch: 8.34 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9618412540257578		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 0.9618412540257578 | validation: 1.0899815374833897]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1228304453012148		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 1.1228304453012148 | validation: 1.4938854038981482]
	TIME [epoch: 8.33 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9354761952171498		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 0.9354761952171498 | validation: 0.948025183928239]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9806344453558493		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 0.9806344453558493 | validation: 0.6267530389385543]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9658842888249832		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 0.9658842888249832 | validation: 1.1268800865299946]
	TIME [epoch: 8.33 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8379236729835495		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 0.8379236729835495 | validation: 0.547848694971974]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8379173672867939		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 0.8379173672867939 | validation: 0.6163372119584798]
	TIME [epoch: 8.29 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7269573666081517		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 0.7269573666081517 | validation: 0.7811415133592088]
	TIME [epoch: 8.32 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1088579357528103		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 1.1088579357528103 | validation: 0.8016432902405404]
	TIME [epoch: 8.31 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7439262564297846		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 0.7439262564297846 | validation: 0.8115562967645947]
	TIME [epoch: 8.31 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6677800848347565		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 0.6677800848347565 | validation: 0.73846952933377]
	TIME [epoch: 8.31 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8037167786293427		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 0.8037167786293427 | validation: 0.5502506332165802]
	TIME [epoch: 8.33 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5929546486214802		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 0.5929546486214802 | validation: 0.7276536943745517]
	TIME [epoch: 8.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0563603457196544		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 1.0563603457196544 | validation: 1.4495868359360362]
	TIME [epoch: 8.31 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7190289749378073		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 0.7190289749378073 | validation: 0.9895801854363903]
	TIME [epoch: 8.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6690426781528072		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 0.6690426781528072 | validation: 0.5839984653535334]
	TIME [epoch: 8.32 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.671862619433468		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 0.671862619433468 | validation: 1.120792887635308]
	TIME [epoch: 8.31 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6355986823512589		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 0.6355986823512589 | validation: 0.6257304603988051]
	TIME [epoch: 8.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.614105904932615		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 0.614105904932615 | validation: 1.470796792012972]
	TIME [epoch: 8.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6741757990249038		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 0.6741757990249038 | validation: 0.467255656890501]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7265207358532615		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 0.7265207358532615 | validation: 0.4676425957374504]
	TIME [epoch: 8.31 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5900306609066274		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 0.5900306609066274 | validation: 0.5603026255587655]
	TIME [epoch: 8.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7204219787061596		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 0.7204219787061596 | validation: 0.41222127842822065]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5708102852730903		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.5708102852730903 | validation: 0.5663904974680354]
	TIME [epoch: 8.36 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6411771160760392		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 0.6411771160760392 | validation: 0.5157770236560195]
	TIME [epoch: 8.33 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5085689561022267		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 0.5085689561022267 | validation: 0.9461846686899453]
	TIME [epoch: 8.32 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6654782536413283		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 0.6654782536413283 | validation: 2.329615351137643]
	TIME [epoch: 8.33 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9628533454419343		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 0.9628533454419343 | validation: 1.0910526150162343]
	TIME [epoch: 8.36 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6341259505572647		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 0.6341259505572647 | validation: 0.4980509883513498]
	TIME [epoch: 8.33 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714664154128928		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 0.6714664154128928 | validation: 0.410498106245416]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5099764277994623		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.5099764277994623 | validation: 0.4632223407057142]
	TIME [epoch: 8.32 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6809818809578149		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.6809818809578149 | validation: 0.5034855038348085]
	TIME [epoch: 8.36 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5373478292692315		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 0.5373478292692315 | validation: 0.6041748243508169]
	TIME [epoch: 8.32 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5924788830113505		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 0.5924788830113505 | validation: 0.42308426155490597]
	TIME [epoch: 8.33 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5897321030590483		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.5897321030590483 | validation: 0.6180190223943639]
	TIME [epoch: 8.32 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.899607965004874		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 0.899607965004874 | validation: 0.4633683466743334]
	TIME [epoch: 8.36 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5175527545249412		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 0.5175527545249412 | validation: 0.5867350011410968]
	TIME [epoch: 8.32 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5139833629374542		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.5139833629374542 | validation: 0.413020835334574]
	TIME [epoch: 8.32 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824475356801802		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.5824475356801802 | validation: 0.8952440268133162]
	TIME [epoch: 8.32 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6424522215513466		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.6424522215513466 | validation: 0.4148787456534162]
	TIME [epoch: 8.35 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5330043496930716		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.5330043496930716 | validation: 0.4888115221860243]
	TIME [epoch: 8.32 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.700545032669807		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.700545032669807 | validation: 0.8448341828423078]
	TIME [epoch: 8.33 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6397605391530333		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.6397605391530333 | validation: 1.225429278595747]
	TIME [epoch: 8.33 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6713838916057746		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 0.6713838916057746 | validation: 0.598361996686819]
	TIME [epoch: 8.36 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6115087123246841		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 0.6115087123246841 | validation: 0.9518217148278159]
	TIME [epoch: 8.32 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6854689743181019		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 0.6854689743181019 | validation: 0.621086646684219]
	TIME [epoch: 8.32 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5636372792004717		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.5636372792004717 | validation: 0.43239223252933545]
	TIME [epoch: 8.32 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5513979961628692		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.5513979961628692 | validation: 0.453078156221983]
	TIME [epoch: 8.35 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5292942697170663		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 0.5292942697170663 | validation: 0.4416292893088222]
	TIME [epoch: 8.32 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282724663254458		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.5282724663254458 | validation: 0.6163926058413813]
	TIME [epoch: 8.32 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5443197203272235		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.5443197203272235 | validation: 0.9006269347990006]
	TIME [epoch: 8.32 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6409983217726387		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.6409983217726387 | validation: 0.4041493554736121]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.561585516264459		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.561585516264459 | validation: 0.5095035359858779]
	TIME [epoch: 8.33 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5896133600213769		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.5896133600213769 | validation: 0.5801460774720476]
	TIME [epoch: 8.32 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.474150377953228		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.474150377953228 | validation: 0.80754993610457]
	TIME [epoch: 8.32 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6661379370644592		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.6661379370644592 | validation: 0.4425859175530831]
	TIME [epoch: 8.35 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7358586918765778		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.7358586918765778 | validation: 0.5848863843779218]
	TIME [epoch: 8.32 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.519855319567992		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.519855319567992 | validation: 0.618380638889251]
	TIME [epoch: 8.33 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5514589147459801		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.5514589147459801 | validation: 0.5074450982074099]
	TIME [epoch: 8.32 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6878457270513072		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.6878457270513072 | validation: 0.650954683680915]
	TIME [epoch: 8.36 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5503026440439207		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.5503026440439207 | validation: 0.5630572979331671]
	TIME [epoch: 8.32 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5996529746990003		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.5996529746990003 | validation: 0.9743816894882313]
	TIME [epoch: 8.32 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6465722436994698		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.6465722436994698 | validation: 0.4078556803538693]
	TIME [epoch: 8.33 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4896413099871236		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.4896413099871236 | validation: 0.4026723647314925]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5557851250141408		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.5557851250141408 | validation: 0.664032158212299]
	TIME [epoch: 8.33 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5314856263556409		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.5314856263556409 | validation: 0.6655116985910167]
	TIME [epoch: 8.32 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5447095813712053		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.5447095813712053 | validation: 0.534930994957097]
	TIME [epoch: 8.32 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5623456943868477		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.5623456943868477 | validation: 0.8245006497562113]
	TIME [epoch: 8.34 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.603349974587484		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.603349974587484 | validation: 0.6363086190857031]
	TIME [epoch: 8.32 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45729357838779644		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.45729357838779644 | validation: 0.42681251887606597]
	TIME [epoch: 8.32 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0450387761677868		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 1.0450387761677868 | validation: 0.495220454855374]
	TIME [epoch: 8.33 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4816546680637268		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.4816546680637268 | validation: 0.710772293142642]
	TIME [epoch: 8.34 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7352242957507692		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.7352242957507692 | validation: 0.9242826983818162]
	TIME [epoch: 8.32 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6527629370064846		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.6527629370064846 | validation: 0.7470470899233783]
	TIME [epoch: 8.32 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5641703881710196		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.5641703881710196 | validation: 0.6009473704442629]
	TIME [epoch: 8.32 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6375357117937325		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.6375357117937325 | validation: 0.7466121788342698]
	TIME [epoch: 8.34 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5650634944708124		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.5650634944708124 | validation: 0.8717772098027465]
	TIME [epoch: 8.31 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5597505028795912		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5597505028795912 | validation: 0.5680295020860553]
	TIME [epoch: 8.32 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5409316871578019		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.5409316871578019 | validation: 0.54516216133409]
	TIME [epoch: 8.33 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6356294556817617		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.6356294556817617 | validation: 0.4445401478161967]
	TIME [epoch: 8.34 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5692861953035824		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.5692861953035824 | validation: 0.5065776392768786]
	TIME [epoch: 8.32 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0098986802906604		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 1.0098986802906604 | validation: 0.5768204135021178]
	TIME [epoch: 8.31 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660937536046899		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.4660937536046899 | validation: 0.5124121559017809]
	TIME [epoch: 8.32 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6630513203603569		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 0.6630513203603569 | validation: 0.5114153234099612]
	TIME [epoch: 8.34 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5351035594705053		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.5351035594705053 | validation: 0.3986047940905476]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4795682796106007		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.4795682796106007 | validation: 0.6485920576572248]
	TIME [epoch: 8.32 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4822634919994642		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.4822634919994642 | validation: 0.3527130254288774]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5248145029865118		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.5248145029865118 | validation: 0.4929836537508492]
	TIME [epoch: 8.34 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856044941530736		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.5856044941530736 | validation: 0.3912424722223985]
	TIME [epoch: 8.31 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5054332240461447		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.5054332240461447 | validation: 0.4281317732781097]
	TIME [epoch: 8.32 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6585796577424883		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.6585796577424883 | validation: 0.4402249118008227]
	TIME [epoch: 8.33 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5353968641986725		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.5353968641986725 | validation: 0.4741771401476901]
	TIME [epoch: 8.33 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43804676575134616		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.43804676575134616 | validation: 0.3895555497477219]
	TIME [epoch: 8.31 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49168839611362153		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.49168839611362153 | validation: 0.5369192691603095]
	TIME [epoch: 8.31 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44072836264185195		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.44072836264185195 | validation: 0.5468832907045142]
	TIME [epoch: 8.33 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5417985062842507		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.5417985062842507 | validation: 0.46474172811521003]
	TIME [epoch: 8.33 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6173476510685254		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.6173476510685254 | validation: 0.40302469412035574]
	TIME [epoch: 8.31 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41429126764652036		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.41429126764652036 | validation: 0.39041255171249833]
	TIME [epoch: 8.31 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.449385214045685		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.449385214045685 | validation: 1.0908359758609]
	TIME [epoch: 8.33 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5504850271001385		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.5504850271001385 | validation: 0.47206872732716776]
	TIME [epoch: 8.33 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4704182903143813		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.4704182903143813 | validation: 0.592694601644563]
	TIME [epoch: 8.32 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4695444928200224		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.4695444928200224 | validation: 0.5211814439274692]
	TIME [epoch: 8.31 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45133752351148343		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.45133752351148343 | validation: 0.4141191927945983]
	TIME [epoch: 8.33 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6087420045303011		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.6087420045303011 | validation: 0.3736097758395191]
	TIME [epoch: 8.33 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5765505520708489		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.5765505520708489 | validation: 0.39304644633036584]
	TIME [epoch: 8.31 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4454243965046933		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.4454243965046933 | validation: 0.44168115743693526]
	TIME [epoch: 8.31 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4714799237377855		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.4714799237377855 | validation: 0.35289766191724137]
	TIME [epoch: 8.33 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.560920635145328		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.560920635145328 | validation: 0.41854484533999625]
	TIME [epoch: 8.33 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4744864254971753		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.4744864254971753 | validation: 0.672428339589017]
	TIME [epoch: 8.31 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5637818044026075		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.5637818044026075 | validation: 0.4394581921867711]
	TIME [epoch: 8.31 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.457216594928858		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.457216594928858 | validation: 0.7259844137421136]
	TIME [epoch: 8.33 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5310373869249242		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.5310373869249242 | validation: 0.438841413489516]
	TIME [epoch: 8.33 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49758007179885827		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.49758007179885827 | validation: 0.43126297735792696]
	TIME [epoch: 8.31 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.473247839833758		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.473247839833758 | validation: 0.3868338233835635]
	TIME [epoch: 8.31 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5009265787342129		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.5009265787342129 | validation: 0.46143930597041316]
	TIME [epoch: 8.33 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5588573574104195		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.5588573574104195 | validation: 0.3571763869741515]
	TIME [epoch: 8.33 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4148487613856394		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.4148487613856394 | validation: 0.6488868666800385]
	TIME [epoch: 8.32 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5549059952251618		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.5549059952251618 | validation: 0.6033463521051774]
	TIME [epoch: 8.32 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4491966271325444		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.4491966271325444 | validation: 0.4743818549721251]
	TIME [epoch: 8.33 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5727573137946798		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.5727573137946798 | validation: 0.36209005558296053]
	TIME [epoch: 8.33 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48347684930463697		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.48347684930463697 | validation: 0.6987747966008443]
	TIME [epoch: 8.32 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5953813358662543		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.5953813358662543 | validation: 0.37072718772500013]
	TIME [epoch: 8.31 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4009075570288371		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.4009075570288371 | validation: 0.6483848886815221]
	TIME [epoch: 8.33 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4749187144735255		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.4749187144735255 | validation: 0.38196039781756164]
	TIME [epoch: 8.33 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4232476479696031		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.4232476479696031 | validation: 0.42823257909287293]
	TIME [epoch: 8.31 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43468073619789543		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.43468073619789543 | validation: 0.4659496672328688]
	TIME [epoch: 8.32 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43611283116989086		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.43611283116989086 | validation: 0.5955876374009874]
	TIME [epoch: 8.33 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.572805477778269		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.572805477778269 | validation: 0.4187728341672292]
	TIME [epoch: 8.33 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4445491910056929		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.4445491910056929 | validation: 0.4246740576971938]
	TIME [epoch: 8.31 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4514835148928384		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.4514835148928384 | validation: 0.5899935814540449]
	TIME [epoch: 8.31 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5138724702021442		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.5138724702021442 | validation: 0.4459212137691465]
	TIME [epoch: 8.33 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45331967471455015		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.45331967471455015 | validation: 0.4884691309687973]
	TIME [epoch: 8.33 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48924086893252355		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.48924086893252355 | validation: 0.4122109574456566]
	TIME [epoch: 8.31 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.400839069482951		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.400839069482951 | validation: 0.486467283866746]
	TIME [epoch: 8.31 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4169591804370594		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.4169591804370594 | validation: 0.32681285839663515]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49653853085219846		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.49653853085219846 | validation: 0.31466726476211343]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5395646577396958		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.5395646577396958 | validation: 0.3553851194990342]
	TIME [epoch: 8.31 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48814916952292126		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.48814916952292126 | validation: 0.32339056761615614]
	TIME [epoch: 8.31 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4018456833897669		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.4018456833897669 | validation: 0.3953369460943786]
	TIME [epoch: 8.33 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5674020994177698		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.5674020994177698 | validation: 0.33099734467330166]
	TIME [epoch: 8.31 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3635442082077348		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.3635442082077348 | validation: 0.37874035762719305]
	TIME [epoch: 8.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.469868034784141		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.469868034784141 | validation: 0.38770141173923145]
	TIME [epoch: 8.31 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4117549905037648		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.4117549905037648 | validation: 0.3511139553939575]
	TIME [epoch: 8.33 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4732020037754542		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.4732020037754542 | validation: 0.4358096921021039]
	TIME [epoch: 8.32 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47024049653565153		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.47024049653565153 | validation: 0.3222331884411549]
	TIME [epoch: 8.31 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45173979281135235		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.45173979281135235 | validation: 0.3739229783388742]
	TIME [epoch: 8.31 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.353227827974557		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.353227827974557 | validation: 0.4227141761144797]
	TIME [epoch: 8.33 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41181407905438333		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.41181407905438333 | validation: 0.29618541392370723]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40583213976183935		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.40583213976183935 | validation: 0.7146939221066713]
	TIME [epoch: 8.31 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49426603328115537		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.49426603328115537 | validation: 0.30805070615120445]
	TIME [epoch: 8.31 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42694099710299377		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.42694099710299377 | validation: 0.7322898628903425]
	TIME [epoch: 8.34 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42831758229708666		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.42831758229708666 | validation: 0.4558086282039309]
	TIME [epoch: 8.31 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36342777626531947		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.36342777626531947 | validation: 0.26580405154285985]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3576874310846536		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.3576874310846536 | validation: 0.3051335153658157]
	TIME [epoch: 8.31 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40368044592247426		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.40368044592247426 | validation: 0.31287617499851905]
	TIME [epoch: 8.33 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42532642487810596		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.42532642487810596 | validation: 0.29744353423431824]
	TIME [epoch: 8.31 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37849994939758486		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.37849994939758486 | validation: 0.2725894570324211]
	TIME [epoch: 8.31 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36863964781873426		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.36863964781873426 | validation: 0.25085954305520103]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4269554189869666		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.4269554189869666 | validation: 0.5229182769925431]
	TIME [epoch: 8.34 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4298879316404197		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.4298879316404197 | validation: 0.2933753826405672]
	TIME [epoch: 8.31 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49894911782973705		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.49894911782973705 | validation: 0.44462385301409324]
	TIME [epoch: 8.31 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3567948227378977		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.3567948227378977 | validation: 0.28025008611094104]
	TIME [epoch: 8.32 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35571044426541676		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.35571044426541676 | validation: 0.3009186271653816]
	TIME [epoch: 8.34 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47341461798034656		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.47341461798034656 | validation: 0.28946982142462413]
	TIME [epoch: 8.31 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3890181943353609		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.3890181943353609 | validation: 0.3569543071693799]
	TIME [epoch: 8.31 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34859983080086165		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.34859983080086165 | validation: 0.39193765822792925]
	TIME [epoch: 8.32 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39845052345904386		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.39845052345904386 | validation: 0.3644956563083558]
	TIME [epoch: 8.34 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43068393637787966		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.43068393637787966 | validation: 0.38689164888599425]
	TIME [epoch: 8.32 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.394699668891643		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.394699668891643 | validation: 0.5301031738993254]
	TIME [epoch: 8.32 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42145101236222227		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.42145101236222227 | validation: 0.4343315470016751]
	TIME [epoch: 8.32 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37173234445032705		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.37173234445032705 | validation: 0.3622815696742507]
	TIME [epoch: 8.34 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39753364452972983		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.39753364452972983 | validation: 0.28042272121103645]
	TIME [epoch: 8.32 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40208732269281333		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.40208732269281333 | validation: 0.4707331610138689]
	TIME [epoch: 8.31 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37266688178548923		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.37266688178548923 | validation: 0.3129823919153826]
	TIME [epoch: 8.31 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32429493359047035		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.32429493359047035 | validation: 0.5158712877875926]
	TIME [epoch: 8.33 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43711047967942174		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.43711047967942174 | validation: 0.6407137077547262]
	TIME [epoch: 8.31 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3871543609570599		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.3871543609570599 | validation: 0.29204364115358294]
	TIME [epoch: 8.31 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30876549794235514		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.30876549794235514 | validation: 0.9472664392249666]
	TIME [epoch: 8.31 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4439195848528983		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.4439195848528983 | validation: 0.35601844889448475]
	TIME [epoch: 8.33 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39933574783447884		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.39933574783447884 | validation: 0.43059484029371686]
	TIME [epoch: 8.31 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40909644382544147		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.40909644382544147 | validation: 0.22831719283556995]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.381026843717141		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.381026843717141 | validation: 0.20280660133143125]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34303077614230365		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.34303077614230365 | validation: 0.5664751902074648]
	TIME [epoch: 8.34 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4391941672331394		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.4391941672331394 | validation: 0.36661316867937765]
	TIME [epoch: 8.33 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3671544172801923		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.3671544172801923 | validation: 0.9724511873211167]
	TIME [epoch: 8.32 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3953764914909274		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.3953764914909274 | validation: 0.26996366693122353]
	TIME [epoch: 8.32 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4649847523568734		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.4649847523568734 | validation: 0.42710139033617656]
	TIME [epoch: 8.35 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3494512665553433		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.3494512665553433 | validation: 0.446607472589034]
	TIME [epoch: 8.32 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40086572522460084		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.40086572522460084 | validation: 0.28765743351098094]
	TIME [epoch: 8.32 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.312711628942666		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.312711628942666 | validation: 0.43695300593816067]
	TIME [epoch: 8.32 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45723981157382354		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.45723981157382354 | validation: 0.22458136958889058]
	TIME [epoch: 8.35 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39835000682000715		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.39835000682000715 | validation: 0.24112103904034493]
	TIME [epoch: 8.32 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3480723348133024		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.3480723348133024 | validation: 0.26194101825972765]
	TIME [epoch: 8.33 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3988375833290001		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.3988375833290001 | validation: 0.537593789349369]
	TIME [epoch: 8.33 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35584777128950645		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.35584777128950645 | validation: 0.4438622009073853]
	TIME [epoch: 8.35 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38451541299631653		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.38451541299631653 | validation: 0.23049724294639423]
	TIME [epoch: 8.33 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3118237321646811		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.3118237321646811 | validation: 0.23881249579592878]
	TIME [epoch: 8.32 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38565755113367484		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.38565755113367484 | validation: 0.3706350655333098]
	TIME [epoch: 8.33 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.346574637907451		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.346574637907451 | validation: 0.29238546401854065]
	TIME [epoch: 8.35 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2945566572091277		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.2945566572091277 | validation: 0.49128545222893744]
	TIME [epoch: 8.33 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4150381409147563		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.4150381409147563 | validation: 0.29272342184193956]
	TIME [epoch: 8.33 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36812902469618447		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.36812902469618447 | validation: 0.5055557572028764]
	TIME [epoch: 8.33 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44470887389711217		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.44470887389711217 | validation: 0.2782734033435439]
	TIME [epoch: 8.36 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32282771667477406		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.32282771667477406 | validation: 0.2920535322810095]
	TIME [epoch: 8.32 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3316836631312166		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.3316836631312166 | validation: 0.20378618383120106]
	TIME [epoch: 8.32 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3259272584422389		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.3259272584422389 | validation: 0.5064124391450868]
	TIME [epoch: 8.33 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4197993192151978		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.4197993192151978 | validation: 0.33542787622302944]
	TIME [epoch: 8.35 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42935155421163246		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.42935155421163246 | validation: 0.35036168611271046]
	TIME [epoch: 8.33 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3275757129714153		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.3275757129714153 | validation: 0.3762454118560861]
	TIME [epoch: 8.33 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3591368726718318		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.3591368726718318 | validation: 0.28028333023675267]
	TIME [epoch: 8.34 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2799388668878244		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.2799388668878244 | validation: 0.5368942279620518]
	TIME [epoch: 8.34 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34042474033891174		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.34042474033891174 | validation: 0.37646843145634723]
	TIME [epoch: 8.32 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3278973209596716		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.3278973209596716 | validation: 0.5759686937865712]
	TIME [epoch: 8.33 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3257980446769156		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.3257980446769156 | validation: 0.3057139980053176]
	TIME [epoch: 8.33 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33012906825132193		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.33012906825132193 | validation: 0.23581063904199254]
	TIME [epoch: 8.34 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2783454989121113		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.2783454989121113 | validation: 0.7491506422934194]
	TIME [epoch: 8.33 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3582923299613915		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.3582923299613915 | validation: 0.3304386041615187]
	TIME [epoch: 8.32 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3670858749198619		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.3670858749198619 | validation: 0.23476251939636822]
	TIME [epoch: 8.33 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37043269852628746		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.37043269852628746 | validation: 0.40776073549008607]
	TIME [epoch: 8.34 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36085582769356916		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.36085582769356916 | validation: 0.30594641671984213]
	TIME [epoch: 8.32 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4071301974494321		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.4071301974494321 | validation: 0.5381643176784007]
	TIME [epoch: 8.33 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39576227256742275		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.39576227256742275 | validation: 0.3793439641389059]
	TIME [epoch: 8.33 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3835704925800826		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.3835704925800826 | validation: 0.2645071051341517]
	TIME [epoch: 8.34 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35451494644236026		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.35451494644236026 | validation: 0.334489082619314]
	TIME [epoch: 8.32 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26210672280160013		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.26210672280160013 | validation: 0.49744280124288504]
	TIME [epoch: 8.32 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2936702641816656		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.2936702641816656 | validation: 0.28618042082717604]
	TIME [epoch: 8.32 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28204263316106826		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.28204263316106826 | validation: 0.3038645153699932]
	TIME [epoch: 8.34 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126979632729202		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.3126979632729202 | validation: 0.24582100932938572]
	TIME [epoch: 8.32 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3724506520869407		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.3724506520869407 | validation: 0.5190923008826319]
	TIME [epoch: 8.32 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30951249947554793		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.30951249947554793 | validation: 0.2082845588700127]
	TIME [epoch: 8.32 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21914122118391083		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.21914122118391083 | validation: 0.25821234873835325]
	TIME [epoch: 8.33 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25190700501480867		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.25190700501480867 | validation: 0.2355551661703601]
	TIME [epoch: 8.32 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4969932671783025		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.4969932671783025 | validation: 0.5518594799769538]
	TIME [epoch: 8.32 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36938665978779617		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.36938665978779617 | validation: 0.2171042145688415]
	TIME [epoch: 8.33 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27596826519478446		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.27596826519478446 | validation: 0.2420217306442915]
	TIME [epoch: 8.33 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3341003679218931		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.3341003679218931 | validation: 0.3251391909343308]
	TIME [epoch: 8.32 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2937113045886368		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.2937113045886368 | validation: 0.29937988374772495]
	TIME [epoch: 8.32 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3268679319408611		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.3268679319408611 | validation: 0.2799725193646745]
	TIME [epoch: 8.32 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.260083978368099		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.260083978368099 | validation: 0.2638523072772673]
	TIME [epoch: 8.34 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24654216734129736		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.24654216734129736 | validation: 0.2035296778123834]
	TIME [epoch: 8.32 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.224808448624586		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.224808448624586 | validation: 0.22150889484348957]
	TIME [epoch: 8.32 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496964813798145		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.2496964813798145 | validation: 0.33335386996844774]
	TIME [epoch: 8.33 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2664996649674585		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.2664996649674585 | validation: 0.17189680167508553]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21040744345461776		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.21040744345461776 | validation: 0.4452089997900756]
	TIME [epoch: 8.31 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33614712358597754		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.33614712358597754 | validation: 0.3516385536600159]
	TIME [epoch: 8.32 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2890544352115559		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.2890544352115559 | validation: 0.25029988737457937]
	TIME [epoch: 8.33 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25146784568876385		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.25146784568876385 | validation: 0.1602226975280013]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28499724407988136		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.28499724407988136 | validation: 0.18943340776340856]
	TIME [epoch: 8.32 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28754944857850456		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.28754944857850456 | validation: 0.2825794043225246]
	TIME [epoch: 8.32 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26917271434554524		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.26917271434554524 | validation: 0.3990009605043461]
	TIME [epoch: 8.33 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2432549989535105		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.2432549989535105 | validation: 0.2746549587098712]
	TIME [epoch: 8.33 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2515103265154756		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.2515103265154756 | validation: 0.3131794423358828]
	TIME [epoch: 8.32 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4088703007914688		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.4088703007914688 | validation: 0.5679865026676597]
	TIME [epoch: 8.32 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34653315958587216		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.34653315958587216 | validation: 0.24829862699130725]
	TIME [epoch: 8.33 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2776489179893257		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.2776489179893257 | validation: 0.3211895637754415]
	TIME [epoch: 8.34 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25746836517160426		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.25746836517160426 | validation: 0.3192616822866441]
	TIME [epoch: 8.32 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33327947719326845		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.33327947719326845 | validation: 0.24135148539882867]
	TIME [epoch: 8.32 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27006163157491897		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.27006163157491897 | validation: 0.226351127185328]
	TIME [epoch: 8.34 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3426240348809751		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.3426240348809751 | validation: 0.27017254166114935]
	TIME [epoch: 8.33 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3324437933403517		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.3324437933403517 | validation: 0.3093234051735956]
	TIME [epoch: 8.32 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22565354957430026		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.22565354957430026 | validation: 0.2661739988482244]
	TIME [epoch: 8.32 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2351478845622616		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.2351478845622616 | validation: 0.14953486776771235]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28337906667116414		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.28337906667116414 | validation: 0.20343796266111908]
	TIME [epoch: 8.33 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.244499033157115		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.244499033157115 | validation: 0.19703301808440432]
	TIME [epoch: 8.31 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24354833209619514		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.24354833209619514 | validation: 0.7480471270010745]
	TIME [epoch: 8.31 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662793163121031		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.3662793163121031 | validation: 0.20974895841941382]
	TIME [epoch: 8.34 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27725744121212786		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.27725744121212786 | validation: 0.17439892852764333]
	TIME [epoch: 8.32 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23403411637920662		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.23403411637920662 | validation: 0.28708440770747196]
	TIME [epoch: 8.31 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.381221643587498		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.381221643587498 | validation: 0.23240477824157116]
	TIME [epoch: 8.31 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24323721858327044		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.24323721858327044 | validation: 0.34996300786349993]
	TIME [epoch: 8.34 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23617165957166747		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.23617165957166747 | validation: 0.301188785552622]
	TIME [epoch: 8.32 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23963047425291134		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.23963047425291134 | validation: 0.20057457782064297]
	TIME [epoch: 8.31 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2672739468536373		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.2672739468536373 | validation: 0.5356198435446233]
	TIME [epoch: 8.31 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31294598364310094		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.31294598364310094 | validation: 0.26974774410077046]
	TIME [epoch: 8.33 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3508727695870204		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.3508727695870204 | validation: 0.24967018496945564]
	TIME [epoch: 8.32 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2653934178649225		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.2653934178649225 | validation: 0.20039583562071234]
	TIME [epoch: 8.31 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2989559061851822		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.2989559061851822 | validation: 0.35859188750580645]
	TIME [epoch: 8.31 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25838442289229174		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.25838442289229174 | validation: 0.18097454615486866]
	TIME [epoch: 8.33 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2436491341125057		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.2436491341125057 | validation: 0.216444395771174]
	TIME [epoch: 8.32 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24885757203874528		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.24885757203874528 | validation: 0.33255547565973564]
	TIME [epoch: 8.31 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40048876910322573		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.40048876910322573 | validation: 0.154145100523161]
	TIME [epoch: 8.31 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641465266436242		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.2641465266436242 | validation: 0.23211838622908662]
	TIME [epoch: 8.33 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22694832787267244		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.22694832787267244 | validation: 0.3688669439252431]
	TIME [epoch: 8.32 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23592698737743314		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.23592698737743314 | validation: 0.24043990668191062]
	TIME [epoch: 8.31 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30351101223707966		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.30351101223707966 | validation: 0.28943932903837993]
	TIME [epoch: 8.31 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2512091776643278		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.2512091776643278 | validation: 0.204195027769693]
	TIME [epoch: 8.33 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2792927405673352		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.2792927405673352 | validation: 0.15517830721074444]
	TIME [epoch: 8.32 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2191064718468995		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.2191064718468995 | validation: 0.4012504102649789]
	TIME [epoch: 8.31 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35003128830612396		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.35003128830612396 | validation: 0.490505334833951]
	TIME [epoch: 8.31 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24609678772775326		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.24609678772775326 | validation: 0.15677163703115476]
	TIME [epoch: 8.33 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2634007595541373		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.2634007595541373 | validation: 0.24891298060960038]
	TIME [epoch: 8.32 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24749447627471702		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.24749447627471702 | validation: 0.24433021574780767]
	TIME [epoch: 8.31 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2034424220415188		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.2034424220415188 | validation: 0.3131598931263457]
	TIME [epoch: 8.31 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29356916970270663		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.29356916970270663 | validation: 0.18814409166872936]
	TIME [epoch: 8.33 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23071681379134015		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.23071681379134015 | validation: 0.2315284930301929]
	TIME [epoch: 8.31 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26061660630075656		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.26061660630075656 | validation: 0.21064919464358228]
	TIME [epoch: 8.31 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2567097082725019		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.2567097082725019 | validation: 0.38024132367347074]
	TIME [epoch: 8.31 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23235894093656095		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.23235894093656095 | validation: 0.17287060552490763]
	TIME [epoch: 8.33 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25148900326770196		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.25148900326770196 | validation: 0.23311446366289404]
	TIME [epoch: 8.32 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21628162590739825		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.21628162590739825 | validation: 0.2057454601447913]
	TIME [epoch: 8.31 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19779213090725556		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.19779213090725556 | validation: 0.28167220931812076]
	TIME [epoch: 8.31 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2730339935520097		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.2730339935520097 | validation: 0.3681719266753641]
	TIME [epoch: 8.33 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.279164654873506		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.279164654873506 | validation: 0.16227699937059886]
	TIME [epoch: 8.32 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2091532909352683		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.2091532909352683 | validation: 0.1454361929856111]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19781136194671775		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.19781136194671775 | validation: 0.12853232354964628]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1991998836089915		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.1991998836089915 | validation: 0.2455360920237037]
	TIME [epoch: 8.33 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23021567085778352		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.23021567085778352 | validation: 0.20917001786210865]
	TIME [epoch: 8.31 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17822744623692888		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.17822744623692888 | validation: 0.20025953536433383]
	TIME [epoch: 8.31 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2218557341101069		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.2218557341101069 | validation: 0.22263731482744087]
	TIME [epoch: 8.31 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24638910502646877		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.24638910502646877 | validation: 0.28193422653985073]
	TIME [epoch: 8.33 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21939572264947227		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.21939572264947227 | validation: 0.23901840415533704]
	TIME [epoch: 8.32 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2028873179030523		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.2028873179030523 | validation: 0.2791040476798728]
	TIME [epoch: 8.31 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765591322882951		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.2765591322882951 | validation: 0.18650268874227063]
	TIME [epoch: 8.31 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20089998548311438		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.20089998548311438 | validation: 0.2841487758942739]
	TIME [epoch: 8.34 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18183112136243484		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.18183112136243484 | validation: 0.228391997665302]
	TIME [epoch: 8.32 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22873232888982525		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.22873232888982525 | validation: 0.1603343829418804]
	TIME [epoch: 8.31 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17533031165933757		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.17533031165933757 | validation: 0.2408612623352698]
	TIME [epoch: 8.31 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20670710415254753		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.20670710415254753 | validation: 0.2348744276624741]
	TIME [epoch: 8.33 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2451211771066792		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.2451211771066792 | validation: 0.1795588271004841]
	TIME [epoch: 8.32 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2179121966338839		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.2179121966338839 | validation: 0.2621994979021228]
	TIME [epoch: 8.32 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1749652545273346		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.1749652545273346 | validation: 0.18865664989544834]
	TIME [epoch: 8.31 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1942707337004616		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.1942707337004616 | validation: 0.21174165156562394]
	TIME [epoch: 8.33 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18805798730491968		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.18805798730491968 | validation: 0.20497404494762944]
	TIME [epoch: 8.32 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15455618082189454		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.15455618082189454 | validation: 0.13269530883436906]
	TIME [epoch: 8.32 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2432775114091223		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.2432775114091223 | validation: 0.11710554142379859]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17424077694197843		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.17424077694197843 | validation: 0.1072000878364879]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14859504440704738		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.14859504440704738 | validation: 0.12544446817929816]
	TIME [epoch: 8.32 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1532357819506884		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.1532357819506884 | validation: 0.18812081912221545]
	TIME [epoch: 8.32 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15366838671374242		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.15366838671374242 | validation: 0.16544197406903288]
	TIME [epoch: 8.32 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2646231887771251		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.2646231887771251 | validation: 0.12177580690208908]
	TIME [epoch: 8.34 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2315576622557126		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.2315576622557126 | validation: 0.1730680495464495]
	TIME [epoch: 8.32 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17146705340690058		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.17146705340690058 | validation: 0.18069345769971928]
	TIME [epoch: 8.31 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1541085412206485		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.1541085412206485 | validation: 0.1517125496219309]
	TIME [epoch: 8.32 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18736073321358007		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.18736073321358007 | validation: 0.260111084638446]
	TIME [epoch: 8.34 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39083757738267966		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.39083757738267966 | validation: 0.12907265667485276]
	TIME [epoch: 8.31 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19940885144457227		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.19940885144457227 | validation: 0.4221143067387064]
	TIME [epoch: 8.31 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2006953270328044		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.2006953270328044 | validation: 0.15644748571219744]
	TIME [epoch: 8.31 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19528106057892908		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.19528106057892908 | validation: 0.14219725154338056]
	TIME [epoch: 8.33 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16702399071020324		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.16702399071020324 | validation: 0.09157403439507088]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1758137662200855		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.1758137662200855 | validation: 0.20330954149851688]
	TIME [epoch: 8.32 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1602325298046051		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.1602325298046051 | validation: 0.1587566692232145]
	TIME [epoch: 8.31 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063481452765239		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.2063481452765239 | validation: 0.16139255149168713]
	TIME [epoch: 8.33 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18488646860956312		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.18488646860956312 | validation: 0.19242857043654615]
	TIME [epoch: 8.31 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179704692363716		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.179704692363716 | validation: 0.10195311556222833]
	TIME [epoch: 8.31 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13914038636439585		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.13914038636439585 | validation: 0.10183949673011927]
	TIME [epoch: 8.31 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2132267922360893		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.2132267922360893 | validation: 0.08753509150210737]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1459681336627239		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.1459681336627239 | validation: 0.14828361010746094]
	TIME [epoch: 8.31 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16118863300588634		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.16118863300588634 | validation: 0.3495806044265248]
	TIME [epoch: 8.31 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1818162197675282		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.1818162197675282 | validation: 0.2657340343458666]
	TIME [epoch: 8.32 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24826342846007635		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.24826342846007635 | validation: 0.1167430791320497]
	TIME [epoch: 8.33 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18516894561237646		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.18516894561237646 | validation: 0.25715592110845237]
	TIME [epoch: 8.31 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1619551961217087		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.1619551961217087 | validation: 0.10001171361697403]
	TIME [epoch: 8.31 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1379802545298409		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.1379802545298409 | validation: 0.11132071467596136]
	TIME [epoch: 8.32 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16320787710029322		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.16320787710029322 | validation: 0.15978695850391333]
	TIME [epoch: 8.33 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19308935880761674		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.19308935880761674 | validation: 0.1858570756426265]
	TIME [epoch: 8.31 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2227482602023542		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.2227482602023542 | validation: 0.26265162253449864]
	TIME [epoch: 8.31 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1695870529965275		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.1695870529965275 | validation: 0.09185992856529832]
	TIME [epoch: 8.32 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17282805547185706		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.17282805547185706 | validation: 0.13971903895498733]
	TIME [epoch: 8.34 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19746469191582589		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.19746469191582589 | validation: 0.10384852715561256]
	TIME [epoch: 8.32 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20625270430385276		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.20625270430385276 | validation: 0.08037221593578031]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19176783499830904		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.19176783499830904 | validation: 0.17789167557534316]
	TIME [epoch: 8.32 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14239324098488965		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.14239324098488965 | validation: 0.1340662933003744]
	TIME [epoch: 8.32 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20924401584257427		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.20924401584257427 | validation: 0.5137891393638978]
	TIME [epoch: 8.31 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2669625909446958		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.2669625909446958 | validation: 0.23874443589757827]
	TIME [epoch: 8.31 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21295775581326967		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.21295775581326967 | validation: 0.2643268909845976]
	TIME [epoch: 8.33 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17283567526179067		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.17283567526179067 | validation: 0.1445220151840087]
	TIME [epoch: 8.32 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17178970465128024		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.17178970465128024 | validation: 0.16024286994023124]
	TIME [epoch: 8.31 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16340724870553186		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.16340724870553186 | validation: 0.14742784198681702]
	TIME [epoch: 8.31 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806587294732185		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.1806587294732185 | validation: 0.16847115923925848]
	TIME [epoch: 8.32 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1600073994250763		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.1600073994250763 | validation: 0.1395819964725325]
	TIME [epoch: 8.32 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17444270457395422		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.17444270457395422 | validation: 0.10010070360111138]
	TIME [epoch: 8.31 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1455527768906249		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.1455527768906249 | validation: 0.1468451733681105]
	TIME [epoch: 8.31 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17987847266820003		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.17987847266820003 | validation: 0.13703835962879635]
	TIME [epoch: 8.33 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14143115213082674		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.14143115213082674 | validation: 0.17150793567662342]
	TIME [epoch: 8.32 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14679398410709293		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.14679398410709293 | validation: 0.12756051657919076]
	TIME [epoch: 8.31 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1611774643766779		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.1611774643766779 | validation: 0.13823581824635478]
	TIME [epoch: 8.31 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1672931144156764		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.1672931144156764 | validation: 0.21759350182366577]
	TIME [epoch: 8.33 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13226329303344425		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.13226329303344425 | validation: 0.13882043349038234]
	TIME [epoch: 8.32 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1137808188129493		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.1137808188129493 | validation: 0.12482131907620533]
	TIME [epoch: 8.31 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.156940337450733		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.156940337450733 | validation: 0.17166673371216778]
	TIME [epoch: 8.31 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2342669486133425		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.2342669486133425 | validation: 0.24586743167485067]
	TIME [epoch: 8.33 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17868114428792883		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.17868114428792883 | validation: 0.23870910052435146]
	TIME [epoch: 8.32 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27167980501290556		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.27167980501290556 | validation: 0.23679929520299647]
	TIME [epoch: 8.31 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20122540827745472		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.20122540827745472 | validation: 0.2972927515666356]
	TIME [epoch: 8.31 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20828185811786265		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.20828185811786265 | validation: 0.4345258559428927]
	TIME [epoch: 8.32 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2279877378748377		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.2279877378748377 | validation: 0.14652803297878197]
	TIME [epoch: 8.32 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16905017476957923		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.16905017476957923 | validation: 0.3584564448203598]
	TIME [epoch: 8.31 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15367804010511826		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.15367804010511826 | validation: 0.140304629595666]
	TIME [epoch: 8.31 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15257208394296567		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.15257208394296567 | validation: 0.4174357182126721]
	TIME [epoch: 8.32 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19681933101655125		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.19681933101655125 | validation: 0.20113497168394373]
	TIME [epoch: 8.32 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14769731073989742		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.14769731073989742 | validation: 0.3178675287179695]
	TIME [epoch: 8.31 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17708617799256357		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.17708617799256357 | validation: 0.12029555191008069]
	TIME [epoch: 8.31 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13679778603860265		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.13679778603860265 | validation: 0.22170504947154882]
	TIME [epoch: 8.33 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17632371443228823		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.17632371443228823 | validation: 0.26130256463771334]
	TIME [epoch: 8.32 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16758045492233675		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.16758045492233675 | validation: 0.13554196352958642]
	TIME [epoch: 8.31 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13778167185510448		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.13778167185510448 | validation: 0.13059893157246152]
	TIME [epoch: 8.31 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18885804412150023		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.18885804412150023 | validation: 0.20658441656055399]
	TIME [epoch: 8.33 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16182607929187298		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.16182607929187298 | validation: 0.39097665657242586]
	TIME [epoch: 8.32 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3096433165022738		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.3096433165022738 | validation: 0.21323787241084363]
	TIME [epoch: 8.31 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179499630910994		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.179499630910994 | validation: 0.11751693830756527]
	TIME [epoch: 8.31 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17637885964865413		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.17637885964865413 | validation: 0.10623173536215122]
	TIME [epoch: 8.33 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13792795482892697		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.13792795482892697 | validation: 0.09991938432561062]
	TIME [epoch: 8.32 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13227650302255473		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.13227650302255473 | validation: 0.2651612503333713]
	TIME [epoch: 8.31 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17479419504429475		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.17479419504429475 | validation: 0.08196910872537166]
	TIME [epoch: 8.31 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19544956669790267		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.19544956669790267 | validation: 0.11122198475317116]
	TIME [epoch: 8.32 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15585429335119216		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.15585429335119216 | validation: 0.08156333447434116]
	TIME [epoch: 8.32 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11880555965380653		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.11880555965380653 | validation: 0.3248355867507495]
	TIME [epoch: 8.32 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16535841445785976		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.16535841445785976 | validation: 0.09165040113839369]
	TIME [epoch: 8.31 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18442680759267177		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.18442680759267177 | validation: 0.08594296356102134]
	TIME [epoch: 8.33 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11694550622029798		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.11694550622029798 | validation: 0.1001574354947094]
	TIME [epoch: 8.32 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2396804799683006		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.2396804799683006 | validation: 0.12330916240573166]
	TIME [epoch: 8.31 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15059369655314053		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.15059369655314053 | validation: 0.13155854157106522]
	TIME [epoch: 8.31 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16565713317661482		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.16565713317661482 | validation: 0.18162814739500932]
	TIME [epoch: 8.32 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16702521653197233		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.16702521653197233 | validation: 0.14338395906616652]
	TIME [epoch: 8.32 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15507622402423565		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.15507622402423565 | validation: 0.23254662761386036]
	TIME [epoch: 8.31 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24565516042981575		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.24565516042981575 | validation: 0.21211584782258036]
	TIME [epoch: 8.32 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1700496639066204		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.1700496639066204 | validation: 0.11838452889913226]
	TIME [epoch: 8.33 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2079385729004452		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.2079385729004452 | validation: 0.2876166375433865]
	TIME [epoch: 8.32 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19952249106246095		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.19952249106246095 | validation: 0.1494788223285925]
	TIME [epoch: 8.31 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16606924129266903		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.16606924129266903 | validation: 0.15279527082256164]
	TIME [epoch: 8.31 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14960003901515903		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.14960003901515903 | validation: 0.1094203148094968]
	TIME [epoch: 8.33 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12473282663481915		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.12473282663481915 | validation: 0.09881934594398706]
	TIME [epoch: 8.33 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20042645122633052		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.20042645122633052 | validation: 0.219321648410768]
	TIME [epoch: 8.31 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19782756000941132		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.19782756000941132 | validation: 0.243385988404677]
	TIME [epoch: 8.31 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1858547070837316		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.1858547070837316 | validation: 0.15134661378932315]
	TIME [epoch: 8.33 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806050572333814		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.1806050572333814 | validation: 0.16064666257718815]
	TIME [epoch: 8.32 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23899563105014474		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.23899563105014474 | validation: 0.2866333795449888]
	TIME [epoch: 8.32 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1402985804123102		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.1402985804123102 | validation: 0.1322177933748028]
	TIME [epoch: 8.31 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17122412353037225		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.17122412353037225 | validation: 0.20835469044653698]
	TIME [epoch: 8.33 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2061918389030602		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.2061918389030602 | validation: 0.12188685047262632]
	TIME [epoch: 8.33 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16241400666939337		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.16241400666939337 | validation: 0.09678877381629922]
	TIME [epoch: 8.32 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16056455902110373		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.16056455902110373 | validation: 0.11779052686609859]
	TIME [epoch: 8.32 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17203773873370315		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.17203773873370315 | validation: 0.42961416025331584]
	TIME [epoch: 8.33 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1986642123815268		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.1986642123815268 | validation: 0.16222643898484634]
	TIME [epoch: 8.33 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492837305961549		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.1492837305961549 | validation: 0.19062400196592405]
	TIME [epoch: 8.32 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14499284894271267		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.14499284894271267 | validation: 0.09254946212744397]
	TIME [epoch: 8.31 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19587069212524488		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.19587069212524488 | validation: 0.1161629348562046]
	TIME [epoch: 8.34 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1026298014602776		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.1026298014602776 | validation: 0.18509816255746148]
	TIME [epoch: 8.32 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15394855630464002		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.15394855630464002 | validation: 0.12567200434159168]
	TIME [epoch: 8.32 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1493223886366522		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.1493223886366522 | validation: 0.11983869214999303]
	TIME [epoch: 8.31 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13174248107437872		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.13174248107437872 | validation: 0.10357842058674331]
	TIME [epoch: 8.34 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14602128932533165		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.14602128932533165 | validation: 0.12624641813849558]
	TIME [epoch: 8.32 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14626701058610664		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.14626701058610664 | validation: 0.17267483264861805]
	TIME [epoch: 8.32 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12786541644649038		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.12786541644649038 | validation: 0.08202792885239596]
	TIME [epoch: 8.31 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13971755033916353		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.13971755033916353 | validation: 0.14499808457818664]
	TIME [epoch: 8.34 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1673225137559619		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.1673225137559619 | validation: 0.10118384768558872]
	TIME [epoch: 8.32 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15200284825564442		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.15200284825564442 | validation: 0.14146310247826377]
	TIME [epoch: 8.32 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15700521276157037		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.15700521276157037 | validation: 0.10047475655127988]
	TIME [epoch: 8.32 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18654518398459577		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.18654518398459577 | validation: 0.10258020585491187]
	TIME [epoch: 8.34 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13967861064201115		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.13967861064201115 | validation: 0.1616117532146173]
	TIME [epoch: 8.31 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1386300096404677		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.1386300096404677 | validation: 0.2249708258826137]
	TIME [epoch: 8.32 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15065639820031243		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.15065639820031243 | validation: 0.09226215258595358]
	TIME [epoch: 8.32 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15276031202845805		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.15276031202845805 | validation: 0.1295065635425106]
	TIME [epoch: 8.34 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12510464482180833		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.12510464482180833 | validation: 0.12751480787522013]
	TIME [epoch: 8.33 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13224376807620272		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.13224376807620272 | validation: 0.16305620294098447]
	TIME [epoch: 8.31 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17611220612065448		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.17611220612065448 | validation: 0.18201493424434273]
	TIME [epoch: 8.32 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607161388464519		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.1607161388464519 | validation: 0.6083476063334983]
	TIME [epoch: 8.34 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2212242768865042		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.2212242768865042 | validation: 0.15532304071223668]
	TIME [epoch: 8.32 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13958085200251424		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.13958085200251424 | validation: 0.1559042338537161]
	TIME [epoch: 8.31 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1511677762042275		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.1511677762042275 | validation: 0.20008228182751753]
	TIME [epoch: 8.31 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15127274006189434		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.15127274006189434 | validation: 0.2126079906351798]
	TIME [epoch: 8.33 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14258239567085967		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.14258239567085967 | validation: 0.13697812802964432]
	TIME [epoch: 8.31 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1629033440446696		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.1629033440446696 | validation: 0.08327839273501898]
	TIME [epoch: 8.32 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12573981665473352		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.12573981665473352 | validation: 0.09246948499935242]
	TIME [epoch: 8.32 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09591866465803243		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.09591866465803243 | validation: 0.11754186661637267]
	TIME [epoch: 8.33 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12625895926635736		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.12625895926635736 | validation: 0.07982499507164897]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22730369915957455		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.22730369915957455 | validation: 0.1830507572854202]
	TIME [epoch: 8.31 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1391083175494103		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.1391083175494103 | validation: 0.1523171679686926]
	TIME [epoch: 8.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16365014790208718		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.16365014790208718 | validation: 0.2912310336587167]
	TIME [epoch: 8.32 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15582868104615205		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.15582868104615205 | validation: 0.18213499160051727]
	TIME [epoch: 8.31 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16956827793731094		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.16956827793731094 | validation: 0.0962969503996901]
	TIME [epoch: 8.31 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13625173870230642		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.13625173870230642 | validation: 0.27314934784841366]
	TIME [epoch: 8.31 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16430094151501273		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.16430094151501273 | validation: 0.09646312211200567]
	TIME [epoch: 8.33 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11030682046848701		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.11030682046848701 | validation: 0.08869593794651837]
	TIME [epoch: 8.32 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12100325113383645		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.12100325113383645 | validation: 0.08925895705646039]
	TIME [epoch: 8.31 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12906777753560897		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.12906777753560897 | validation: 0.1766340082965171]
	TIME [epoch: 8.31 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10693063272962486		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.10693063272962486 | validation: 0.10692245022609131]
	TIME [epoch: 8.33 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19786609299062885		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.19786609299062885 | validation: 0.09333850125228468]
	TIME [epoch: 8.31 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18090077854930592		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.18090077854930592 | validation: 0.07768286031648146]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3377115189270616		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.3377115189270616 | validation: 0.0911202102443638]
	TIME [epoch: 8.33 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09437768514935582		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.09437768514935582 | validation: 0.13530426784384153]
	TIME [epoch: 8.34 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18006979133022094		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.18006979133022094 | validation: 0.1323060356305738]
	TIME [epoch: 8.32 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14602315983969616		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.14602315983969616 | validation: 0.13557016804489047]
	TIME [epoch: 8.32 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12507552869961364		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.12507552869961364 | validation: 0.10942076367681625]
	TIME [epoch: 8.32 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17939217659270673		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.17939217659270673 | validation: 0.4065106224298352]
	TIME [epoch: 8.34 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1729448780955687		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.1729448780955687 | validation: 0.13069107643080788]
	TIME [epoch: 8.33 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11727654233532281		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.11727654233532281 | validation: 0.1367835547574399]
	TIME [epoch: 8.33 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12533008600809303		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.12533008600809303 | validation: 0.1271467001557883]
	TIME [epoch: 8.33 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11067923013845364		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.11067923013845364 | validation: 0.09166236597862702]
	TIME [epoch: 8.35 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19885081304363542		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.19885081304363542 | validation: 0.22242312836258304]
	TIME [epoch: 8.32 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11829320449060368		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.11829320449060368 | validation: 0.36469319669585776]
	TIME [epoch: 8.32 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1503199798554791		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.1503199798554791 | validation: 0.10388988469634854]
	TIME [epoch: 8.32 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.137375002956696		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.137375002956696 | validation: 0.2292799910674201]
	TIME [epoch: 8.35 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17580683204046624		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.17580683204046624 | validation: 0.08733969208773901]
	TIME [epoch: 8.32 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12276455448044092		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.12276455448044092 | validation: 0.18628736752551706]
	TIME [epoch: 8.32 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10866654114561429		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.10866654114561429 | validation: 0.2283607398363477]
	TIME [epoch: 8.32 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17161603689951183		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.17161603689951183 | validation: 0.19209854823600583]
	TIME [epoch: 8.35 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16383818282223667		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.16383818282223667 | validation: 0.20418725298795276]
	TIME [epoch: 8.32 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13774161544721353		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.13774161544721353 | validation: 0.07144771521428375]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_592.pth
	Model improved!!!
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399398229251194		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.1399398229251194 | validation: 0.23343177692415468]
	TIME [epoch: 8.32 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13983800988037687		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.13983800988037687 | validation: 0.14448773762508754]
	TIME [epoch: 8.35 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19534419581762766		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.19534419581762766 | validation: 0.2514411553521782]
	TIME [epoch: 8.32 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14938745494244393		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.14938745494244393 | validation: 0.23615795582886184]
	TIME [epoch: 8.32 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1311017623617494		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.1311017623617494 | validation: 0.11439705163257242]
	TIME [epoch: 8.33 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14434170862779172		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.14434170862779172 | validation: 0.09195772921886017]
	TIME [epoch: 8.34 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12598559833645645		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.12598559833645645 | validation: 0.15500308226965126]
	TIME [epoch: 8.32 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14047098702949995		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.14047098702949995 | validation: 0.06653690123797182]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10425301083900151		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.10425301083900151 | validation: 0.13789645063135927]
	TIME [epoch: 8.32 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15929296425344364		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.15929296425344364 | validation: 0.09699772120959144]
	TIME [epoch: 8.35 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1312092866889889		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.1312092866889889 | validation: 0.09364328474864753]
	TIME [epoch: 8.33 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12292762850560365		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.12292762850560365 | validation: 0.10117860483240795]
	TIME [epoch: 8.32 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11068085426498886		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.11068085426498886 | validation: 0.17228195867680127]
	TIME [epoch: 8.33 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338302106748529		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.1338302106748529 | validation: 0.20368510091818376]
	TIME [epoch: 8.35 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1555096494195845		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.1555096494195845 | validation: 0.10536383497589194]
	TIME [epoch: 8.32 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13645494819862397		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.13645494819862397 | validation: 0.20763045298575852]
	TIME [epoch: 8.32 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13470923940402885		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.13470923940402885 | validation: 0.11671673657459417]
	TIME [epoch: 8.32 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1390541662574341		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.1390541662574341 | validation: 0.22306808074583176]
	TIME [epoch: 8.34 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13447320149058734		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.13447320149058734 | validation: 0.06279291778759895]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1647884572170207		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.1647884572170207 | validation: 0.1432907928667734]
	TIME [epoch: 8.31 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0904944256413306		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.0904944256413306 | validation: 0.10415660119788281]
	TIME [epoch: 8.32 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1940768827356387		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.1940768827356387 | validation: 0.07729713021158433]
	TIME [epoch: 8.33 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13139687878770764		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.13139687878770764 | validation: 0.11169033148157721]
	TIME [epoch: 8.31 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13702049713301617		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.13702049713301617 | validation: 0.3107537169694501]
	TIME [epoch: 8.32 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16297658628881856		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.16297658628881856 | validation: 0.09165411668554799]
	TIME [epoch: 8.32 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11276350424333188		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.11276350424333188 | validation: 0.17033949814436117]
	TIME [epoch: 8.33 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17053492255997044		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.17053492255997044 | validation: 0.19579286752879593]
	TIME [epoch: 8.31 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13148887437817883		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.13148887437817883 | validation: 0.1595049514295404]
	TIME [epoch: 8.31 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11811421491388754		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.11811421491388754 | validation: 0.18058165648004962]
	TIME [epoch: 8.32 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13340188143544546		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.13340188143544546 | validation: 0.10760923324293856]
	TIME [epoch: 8.33 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10496633146788766		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.10496633146788766 | validation: 0.16052987464678076]
	TIME [epoch: 8.31 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18111082156090152		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.18111082156090152 | validation: 0.0769965911350445]
	TIME [epoch: 8.31 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1766468637665088		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.1766468637665088 | validation: 0.14008185220693495]
	TIME [epoch: 8.32 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11371836965694362		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.11371836965694362 | validation: 0.1707090096386115]
	TIME [epoch: 8.33 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13109473862389698		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.13109473862389698 | validation: 0.06670653589330608]
	TIME [epoch: 8.31 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12041135538638255		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.12041135538638255 | validation: 0.09004390422989564]
	TIME [epoch: 8.32 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1143465035526811		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.1143465035526811 | validation: 0.0923803017299396]
	TIME [epoch: 8.32 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1123001222243039		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.1123001222243039 | validation: 0.1147529098426083]
	TIME [epoch: 8.33 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1345097389946268		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.1345097389946268 | validation: 0.16042454906429685]
	TIME [epoch: 8.31 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11243390243049738		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.11243390243049738 | validation: 0.08030426200097428]
	TIME [epoch: 8.31 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12304242462988255		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.12304242462988255 | validation: 0.1249693983770804]
	TIME [epoch: 8.33 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12971361489925937		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.12971361489925937 | validation: 0.11943498338811326]
	TIME [epoch: 8.32 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17743950279662069		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.17743950279662069 | validation: 0.1384217609017822]
	TIME [epoch: 8.31 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1171965443461354		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.1171965443461354 | validation: 0.15818869290256732]
	TIME [epoch: 8.31 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10136418539240977		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.10136418539240977 | validation: 0.2908936880547802]
	TIME [epoch: 8.32 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11850628145224415		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.11850628145224415 | validation: 0.0903257507490553]
	TIME [epoch: 8.33 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17842922486697946		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.17842922486697946 | validation: 0.1257709388062976]
	TIME [epoch: 8.31 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09343968397442046		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.09343968397442046 | validation: 0.06008490637506689]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13108931124557752		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.13108931124557752 | validation: 0.09696888329190856]
	TIME [epoch: 8.33 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11913120906634686		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.11913120906634686 | validation: 0.12727341266630776]
	TIME [epoch: 8.33 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09616617983904091		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.09616617983904091 | validation: 0.204775020680236]
	TIME [epoch: 8.32 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11933399627147394		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.11933399627147394 | validation: 0.1407253797106321]
	TIME [epoch: 8.31 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20927436557455734		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.20927436557455734 | validation: 0.28710977459221304]
	TIME [epoch: 8.33 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12313537651137622		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.12313537651137622 | validation: 0.14105108048072057]
	TIME [epoch: 8.33 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11085833219676826		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.11085833219676826 | validation: 0.08510735874441062]
	TIME [epoch: 8.32 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11507479858152576		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.11507479858152576 | validation: 0.09389347692445149]
	TIME [epoch: 8.32 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14628154864167706		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.14628154864167706 | validation: 0.15953958400086432]
	TIME [epoch: 8.34 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10129047548407273		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.10129047548407273 | validation: 0.08270507699522113]
	TIME [epoch: 8.32 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08428146271797628		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.08428146271797628 | validation: 0.16306075568352735]
	TIME [epoch: 8.32 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10333950308620146		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.10333950308620146 | validation: 0.1928288433671047]
	TIME [epoch: 8.32 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12853986272755907		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.12853986272755907 | validation: 0.2104284239186383]
	TIME [epoch: 8.33 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11191558648077822		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.11191558648077822 | validation: 0.08022334624669442]
	TIME [epoch: 8.33 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09872611635214462		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.09872611635214462 | validation: 0.07873138653433687]
	TIME [epoch: 8.32 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09511195147413919		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.09511195147413919 | validation: 0.08735523702889152]
	TIME [epoch: 8.32 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08572541720407581		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.08572541720407581 | validation: 0.12727537990718388]
	TIME [epoch: 8.33 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10175246233433433		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.10175246233433433 | validation: 0.08656331731769168]
	TIME [epoch: 8.32 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286901061452588		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.1286901061452588 | validation: 0.16177471072173366]
	TIME [epoch: 8.32 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11756834513331171		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.11756834513331171 | validation: 0.13067868797469512]
	TIME [epoch: 8.31 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10168425973542058		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.10168425973542058 | validation: 0.06750341103267136]
	TIME [epoch: 8.33 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.145181517940197		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.145181517940197 | validation: 0.19049146720085203]
	TIME [epoch: 8.33 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14195387859487024		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.14195387859487024 | validation: 0.10692229224988783]
	TIME [epoch: 8.31 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11328874593230234		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.11328874593230234 | validation: 0.06779400310392891]
	TIME [epoch: 8.32 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10761661154487312		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.10761661154487312 | validation: 0.1530278316357545]
	TIME [epoch: 8.33 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13855004867575046		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.13855004867575046 | validation: 0.1332299353464531]
	TIME [epoch: 8.32 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09533697567006369		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.09533697567006369 | validation: 0.15649597222508083]
	TIME [epoch: 8.32 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13317661763538816		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.13317661763538816 | validation: 0.21338255207573975]
	TIME [epoch: 8.32 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11498158036555181		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.11498158036555181 | validation: 0.1221686826465557]
	TIME [epoch: 8.33 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08865348255164329		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.08865348255164329 | validation: 0.06813163715316131]
	TIME [epoch: 8.32 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10598416973645283		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.10598416973645283 | validation: 0.20087470718377126]
	TIME [epoch: 8.31 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14182939030821098		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.14182939030821098 | validation: 0.10177525952559519]
	TIME [epoch: 8.31 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09819225222832224		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.09819225222832224 | validation: 0.1437355974175368]
	TIME [epoch: 8.33 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11868835816335403		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.11868835816335403 | validation: 0.1481495591656969]
	TIME [epoch: 8.32 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17261139003095802		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.17261139003095802 | validation: 0.1800978230663804]
	TIME [epoch: 8.32 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10371443814619737		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.10371443814619737 | validation: 0.09537750131841555]
	TIME [epoch: 8.31 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10349356230673448		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.10349356230673448 | validation: 0.06635226051153645]
	TIME [epoch: 8.33 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09176054242445819		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.09176054242445819 | validation: 0.07025761651543722]
	TIME [epoch: 8.32 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10325306175836253		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.10325306175836253 | validation: 0.10571803126197213]
	TIME [epoch: 8.32 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10571321420498281		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.10571321420498281 | validation: 0.08365395446732857]
	TIME [epoch: 8.31 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11155730569604845		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.11155730569604845 | validation: 0.08683790611542815]
	TIME [epoch: 8.33 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09996252203351631		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.09996252203351631 | validation: 0.23459305766721422]
	TIME [epoch: 8.32 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11350264466887734		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.11350264466887734 | validation: 0.0987980565998797]
	TIME [epoch: 8.32 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1248127402737895		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.1248127402737895 | validation: 0.4583308425491184]
	TIME [epoch: 8.31 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1908574201954753		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.1908574201954753 | validation: 0.0788668396771321]
	TIME [epoch: 8.33 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18471526060476776		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.18471526060476776 | validation: 0.1678182562483222]
	TIME [epoch: 8.32 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16394480310674053		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.16394480310674053 | validation: 0.18326283179495817]
	TIME [epoch: 8.32 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1280053943687735		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.1280053943687735 | validation: 0.10505884705695942]
	TIME [epoch: 8.32 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11255916620089348		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.11255916620089348 | validation: 0.07584216212420249]
	TIME [epoch: 8.33 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09846951468811813		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.09846951468811813 | validation: 0.09540496272635655]
	TIME [epoch: 8.32 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08891027684959489		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.08891027684959489 | validation: 0.10589936906115566]
	TIME [epoch: 8.31 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1272692351330976		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.1272692351330976 | validation: 0.31519908518240797]
	TIME [epoch: 8.31 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13518570208364547		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.13518570208364547 | validation: 0.07914881871144905]
	TIME [epoch: 8.33 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09999830120230216		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.09999830120230216 | validation: 0.0898621689018374]
	TIME [epoch: 8.32 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09101408083509854		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.09101408083509854 | validation: 0.12477348147348405]
	TIME [epoch: 8.31 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13740939985101214		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.13740939985101214 | validation: 0.08450878412724686]
	TIME [epoch: 8.31 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08030439880437865		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.08030439880437865 | validation: 0.108738201031189]
	TIME [epoch: 8.33 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1014597822426456		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.1014597822426456 | validation: 0.2312146825096869]
	TIME [epoch: 8.32 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09650082783427391		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.09650082783427391 | validation: 0.0708678427340701]
	TIME [epoch: 8.31 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08804738217408159		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.08804738217408159 | validation: 0.0952350235389648]
	TIME [epoch: 8.32 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09633331124949937		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.09633331124949937 | validation: 0.10301574503448982]
	TIME [epoch: 8.33 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10214401303630989		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.10214401303630989 | validation: 0.06337654812936142]
	TIME [epoch: 8.32 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0749362550810195		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.0749362550810195 | validation: 0.09065564847805055]
	TIME [epoch: 8.31 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452921811767887		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.1452921811767887 | validation: 0.0784259804735669]
	TIME [epoch: 8.31 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10474411987199095		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.10474411987199095 | validation: 0.06951979434525374]
	TIME [epoch: 8.33 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10214826940461894		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.10214826940461894 | validation: 0.10077125489874973]
	TIME [epoch: 8.32 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08792121856776636		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.08792121856776636 | validation: 0.07799044339798235]
	TIME [epoch: 8.32 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09147251571588443		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.09147251571588443 | validation: 0.09099664749225558]
	TIME [epoch: 8.31 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764583194917017		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.0764583194917017 | validation: 0.0892466987550358]
	TIME [epoch: 8.34 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10235769129162797		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.10235769129162797 | validation: 0.07631171340509678]
	TIME [epoch: 8.31 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11375667290742833		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.11375667290742833 | validation: 0.06697340046082899]
	TIME [epoch: 8.32 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09372408347199951		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.09372408347199951 | validation: 0.11245927355350296]
	TIME [epoch: 8.31 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10371782510914737		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.10371782510914737 | validation: 0.09639366023513216]
	TIME [epoch: 8.34 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12074835817926888		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.12074835817926888 | validation: 0.07465814259411735]
	TIME [epoch: 8.31 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09914091243622088		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.09914091243622088 | validation: 0.11054771019742061]
	TIME [epoch: 8.31 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15413365366840975		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.15413365366840975 | validation: 0.13131465684261784]
	TIME [epoch: 8.31 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09548533582028432		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.09548533582028432 | validation: 0.09405248956521893]
	TIME [epoch: 8.33 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13198769546742156		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.13198769546742156 | validation: 0.09218505195873702]
	TIME [epoch: 8.32 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10218148105678264		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.10218148105678264 | validation: 0.05981068923400393]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09105551277049653		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.09105551277049653 | validation: 0.06336944307230734]
	TIME [epoch: 8.31 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08968893701719556		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.08968893701719556 | validation: 0.07706451469895509]
	TIME [epoch: 8.33 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09979597431641699		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.09979597431641699 | validation: 0.19291524549125139]
	TIME [epoch: 8.32 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12288744419818731		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.12288744419818731 | validation: 0.2419474369944996]
	TIME [epoch: 8.31 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14226852016330352		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.14226852016330352 | validation: 0.11422565159769724]
	TIME [epoch: 8.31 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07782379307953277		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.07782379307953277 | validation: 0.10950686655423275]
	TIME [epoch: 8.33 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08936259791115378		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.08936259791115378 | validation: 0.0810302382010969]
	TIME [epoch: 8.32 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12448383539111307		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.12448383539111307 | validation: 0.09690672256619134]
	TIME [epoch: 8.31 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08847193187448416		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.08847193187448416 | validation: 0.11273959664712464]
	TIME [epoch: 8.32 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07968952466640966		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.07968952466640966 | validation: 0.08732245109025191]
	TIME [epoch: 8.33 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08173172088307629		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.08173172088307629 | validation: 0.10224977248801356]
	TIME [epoch: 8.31 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12036223464564336		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.12036223464564336 | validation: 0.14517929466416762]
	TIME [epoch: 8.31 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10639095160019665		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.10639095160019665 | validation: 0.06906553429355718]
	TIME [epoch: 8.31 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0924242942700135		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.0924242942700135 | validation: 0.13795506334707497]
	TIME [epoch: 8.33 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09349830687787353		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.09349830687787353 | validation: 0.0722997255775581]
	TIME [epoch: 8.32 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10299530585370283		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.10299530585370283 | validation: 0.06268487224757086]
	TIME [epoch: 8.31 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09075890440181389		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.09075890440181389 | validation: 0.09530830336678464]
	TIME [epoch: 8.31 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07748184656205312		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.07748184656205312 | validation: 0.18623466547580647]
	TIME [epoch: 8.33 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08100114088214638		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.08100114088214638 | validation: 0.05180470668598797]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10495010192835616		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.10495010192835616 | validation: 0.055827437089649046]
	TIME [epoch: 8.31 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11110310791230946		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.11110310791230946 | validation: 0.05390248633403806]
	TIME [epoch: 8.31 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08222808191768506		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.08222808191768506 | validation: 0.09655163144399327]
	TIME [epoch: 8.33 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10419899308348235		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.10419899308348235 | validation: 0.14492200714785275]
	TIME [epoch: 8.32 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10724566618713616		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.10724566618713616 | validation: 0.13607047893764046]
	TIME [epoch: 8.31 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10419412458982262		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.10419412458982262 | validation: 0.15365007095682626]
	TIME [epoch: 8.31 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1098571691244435		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.1098571691244435 | validation: 0.06591891398813475]
	TIME [epoch: 8.33 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09010676178483026		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.09010676178483026 | validation: 0.05455769965978216]
	TIME [epoch: 8.31 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0755828877371093		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.0755828877371093 | validation: 0.06119924784715338]
	TIME [epoch: 8.31 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10110177564496807		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.10110177564496807 | validation: 0.16670967141087173]
	TIME [epoch: 8.31 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08889951524413525		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.08889951524413525 | validation: 0.07497290434037344]
	TIME [epoch: 8.33 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06697092061966806		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.06697092061966806 | validation: 0.07129561822359583]
	TIME [epoch: 8.31 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0727888796223975		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.0727888796223975 | validation: 0.10474283089039978]
	TIME [epoch: 8.31 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09001911294108363		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.09001911294108363 | validation: 0.13861027226851116]
	TIME [epoch: 8.31 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11151718854005913		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.11151718854005913 | validation: 0.2583198449175435]
	TIME [epoch: 8.33 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562317450095465		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.1562317450095465 | validation: 0.20652959655692754]
	TIME [epoch: 8.31 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09933112050635509		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.09933112050635509 | validation: 0.12284123587558661]
	TIME [epoch: 8.32 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08564698261560762		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.08564698261560762 | validation: 0.06282440977152468]
	TIME [epoch: 8.31 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11334853860131107		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.11334853860131107 | validation: 0.08256966771762927]
	TIME [epoch: 8.34 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08339136159109103		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.08339136159109103 | validation: 0.17030161224928897]
	TIME [epoch: 8.31 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09659623656201091		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.09659623656201091 | validation: 0.13556216826229056]
	TIME [epoch: 8.31 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1063522249484599		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.1063522249484599 | validation: 0.08272144945050593]
	TIME [epoch: 8.31 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07449954332170487		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.07449954332170487 | validation: 0.057077598091462164]
	TIME [epoch: 8.33 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1111660888776157		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.1111660888776157 | validation: 0.08207309186806874]
	TIME [epoch: 8.31 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08543844948505223		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.08543844948505223 | validation: 0.10655037451184285]
	TIME [epoch: 8.31 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10542229161370517		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.10542229161370517 | validation: 0.1230338512615169]
	TIME [epoch: 8.31 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14898674671106948		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.14898674671106948 | validation: 0.12203103112910377]
	TIME [epoch: 8.33 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11797946372450238		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.11797946372450238 | validation: 0.0601644714380188]
	TIME [epoch: 8.31 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07567794221545474		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.07567794221545474 | validation: 0.05235538221815196]
	TIME [epoch: 8.31 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08835608075270002		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.08835608075270002 | validation: 0.2866246645754271]
	TIME [epoch: 8.31 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12202314246447994		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.12202314246447994 | validation: 0.09478362081241049]
	TIME [epoch: 8.33 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.065989126938171		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.065989126938171 | validation: 0.12112853619679469]
	TIME [epoch: 8.31 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10719748912610763		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.10719748912610763 | validation: 0.15833003963872944]
	TIME [epoch: 8.31 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09445629748084143		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.09445629748084143 | validation: 0.08364184132459287]
	TIME [epoch: 8.31 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07649689385381002		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.07649689385381002 | validation: 0.05140820666141442]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_773.pth
	Model improved!!!
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08982125608993258		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.08982125608993258 | validation: 0.07908935902287595]
	TIME [epoch: 8.31 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08399565687103486		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.08399565687103486 | validation: 0.13967269239705077]
	TIME [epoch: 8.31 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09858646439273486		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.09858646439273486 | validation: 0.07447946202548124]
	TIME [epoch: 8.31 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06664700693308798		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.06664700693308798 | validation: 0.07271925025822473]
	TIME [epoch: 8.33 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07175558296740972		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.07175558296740972 | validation: 0.05342358565199707]
	TIME [epoch: 8.31 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12149996248300718		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.12149996248300718 | validation: 0.12496517321143041]
	TIME [epoch: 8.31 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10400501828188435		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.10400501828188435 | validation: 0.09982640736905998]
	TIME [epoch: 8.31 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08070461253813419		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.08070461253813419 | validation: 0.2561461907763719]
	TIME [epoch: 8.34 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13125491228139147		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.13125491228139147 | validation: 0.04614330947652797]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_782.pth
	Model improved!!!
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08151197050267209		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.08151197050267209 | validation: 0.08737387184090756]
	TIME [epoch: 8.32 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10549285602422735		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.10549285602422735 | validation: 0.050817511377101734]
	TIME [epoch: 8.31 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0938868617017505		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.0938868617017505 | validation: 0.0868032495749089]
	TIME [epoch: 8.32 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1038846879761485		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.1038846879761485 | validation: 0.07742756163230219]
	TIME [epoch: 8.32 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060033688929125126		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.060033688929125126 | validation: 0.045478093555145385]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066562413774505		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.07066562413774505 | validation: 0.11893249953554097]
	TIME [epoch: 8.31 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09059377749992743		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.09059377749992743 | validation: 0.1351165662230957]
	TIME [epoch: 8.32 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08752641443075337		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.08752641443075337 | validation: 0.06012857414410437]
	TIME [epoch: 8.31 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07445300382953157		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.07445300382953157 | validation: 0.06523933578555519]
	TIME [epoch: 8.33 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06963161436363477		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.06963161436363477 | validation: 0.0838840295976701]
	TIME [epoch: 8.31 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10040797656723197		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.10040797656723197 | validation: 0.12666216892714097]
	TIME [epoch: 8.32 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09819938127789266		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.09819938127789266 | validation: 0.061938232674379035]
	TIME [epoch: 8.31 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10933890019620307		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.10933890019620307 | validation: 0.11285023533421801]
	TIME [epoch: 8.31 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06958102978004234		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.06958102978004234 | validation: 0.04504334113793408]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06625925946987035		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.06625925946987035 | validation: 0.0738751177630306]
	TIME [epoch: 8.33 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0987268771286593		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.0987268771286593 | validation: 0.07462295659831417]
	TIME [epoch: 8.31 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07311481332378307		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.07311481332378307 | validation: 0.13701771657496853]
	TIME [epoch: 8.31 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07156618555110389		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.07156618555110389 | validation: 0.08347487556935207]
	TIME [epoch: 8.32 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.077039799898963		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.077039799898963 | validation: 0.11963066207029205]
	TIME [epoch: 8.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07428738113953472		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.07428738113953472 | validation: 0.05110612385795331]
	TIME [epoch: 8.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06458215637368134		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.06458215637368134 | validation: 0.0931633812283052]
	TIME [epoch: 8.31 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07920259483987488		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.07920259483987488 | validation: 0.09589101578962436]
	TIME [epoch: 8.32 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09294960636442966		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.09294960636442966 | validation: 0.08344478826525462]
	TIME [epoch: 8.32 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07447356294183645		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.07447356294183645 | validation: 0.08257222530856187]
	TIME [epoch: 8.31 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08109232197993085		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.08109232197993085 | validation: 0.059664648767924613]
	TIME [epoch: 8.31 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06725166571745764		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.06725166571745764 | validation: 0.0945167931600249]
	TIME [epoch: 8.32 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11259161809516822		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.11259161809516822 | validation: 0.1377542261534854]
	TIME [epoch: 8.32 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09915560623056288		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.09915560623056288 | validation: 0.07922659055853921]
	TIME [epoch: 8.31 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0998943076225747		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.0998943076225747 | validation: 0.05566478058008131]
	TIME [epoch: 8.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885479191075794		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.06885479191075794 | validation: 0.07661738375131137]
	TIME [epoch: 8.32 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07497016658514286		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.07497016658514286 | validation: 0.12067747580430799]
	TIME [epoch: 8.32 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1053265091860647		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.1053265091860647 | validation: 0.08917654659342891]
	TIME [epoch: 8.31 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08770936294411666		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.08770936294411666 | validation: 0.3687822245135923]
	TIME [epoch: 8.31 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467027961114112		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.1467027961114112 | validation: 0.08326784487296113]
	TIME [epoch: 8.32 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16222691628692196		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.16222691628692196 | validation: 0.14074083805376075]
	TIME [epoch: 8.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08174863224074823		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.08174863224074823 | validation: 0.13597411361271122]
	TIME [epoch: 8.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10473694136641729		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.10473694136641729 | validation: 0.11387845950295963]
	TIME [epoch: 8.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07380447514103171		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.07380447514103171 | validation: 0.05647908306076049]
	TIME [epoch: 8.32 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06684646657497462		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.06684646657497462 | validation: 0.11578536241508453]
	TIME [epoch: 8.31 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407012435272085		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.07407012435272085 | validation: 0.07049323851618806]
	TIME [epoch: 8.31 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08012189263428945		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.08012189263428945 | validation: 0.0551627297303746]
	TIME [epoch: 8.31 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0882580961663604		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.0882580961663604 | validation: 0.08807860370418245]
	TIME [epoch: 8.32 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08583368302437289		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.08583368302437289 | validation: 0.09539315310888147]
	TIME [epoch: 8.31 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09954832896593853		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.09954832896593853 | validation: 0.06155512371954096]
	TIME [epoch: 8.31 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.129762580397684		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.129762580397684 | validation: 0.09127487455114389]
	TIME [epoch: 8.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494230984668722		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.06494230984668722 | validation: 0.0841705569191085]
	TIME [epoch: 8.32 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07958332416378097		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.07958332416378097 | validation: 0.03421940064125398]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_829.pth
	Model improved!!!
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07566275096640146		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.07566275096640146 | validation: 0.0878082054113849]
	TIME [epoch: 8.32 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08494337428436992		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.08494337428436992 | validation: 0.08189337802168786]
	TIME [epoch: 8.33 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355072333783966		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.1355072333783966 | validation: 0.06910464934820798]
	TIME [epoch: 8.34 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382830083569286		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.08382830083569286 | validation: 0.08076452253758773]
	TIME [epoch: 8.32 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09077621771861659		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.09077621771861659 | validation: 0.07772407903040801]
	TIME [epoch: 8.32 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0736244319757586		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.0736244319757586 | validation: 0.08344314087068261]
	TIME [epoch: 8.32 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08628155680185944		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.08628155680185944 | validation: 0.12973441146864767]
	TIME [epoch: 8.35 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08330680829789186		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.08330680829789186 | validation: 0.05183831878773979]
	TIME [epoch: 8.32 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08694923841578486		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.08694923841578486 | validation: 0.041612097960575065]
	TIME [epoch: 8.32 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09035180905495269		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.09035180905495269 | validation: 0.08817417224399586]
	TIME [epoch: 8.32 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07193781348557604		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.07193781348557604 | validation: 0.09228084412247581]
	TIME [epoch: 8.34 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09950376562671566		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.09950376562671566 | validation: 0.04792021653183644]
	TIME [epoch: 8.33 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0635605291212765		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.0635605291212765 | validation: 0.12491032333374107]
	TIME [epoch: 8.32 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09427366346209147		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.09427366346209147 | validation: 0.07844604511362899]
	TIME [epoch: 8.32 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0765509894378233		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.0765509894378233 | validation: 0.0792409642183617]
	TIME [epoch: 8.35 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08289486498731605		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.08289486498731605 | validation: 0.15011109753564242]
	TIME [epoch: 8.32 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07344091865491378		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.07344091865491378 | validation: 0.039365242907266645]
	TIME [epoch: 8.32 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08388841095931389		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.08388841095931389 | validation: 0.12073830841993434]
	TIME [epoch: 8.32 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06984073265619173		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.06984073265619173 | validation: 0.07717401715307891]
	TIME [epoch: 8.34 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0808182558603315		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.0808182558603315 | validation: 0.0958144123465374]
	TIME [epoch: 8.32 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07588273866643884		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.07588273866643884 | validation: 0.080247200039844]
	TIME [epoch: 8.32 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10068510702924369		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.10068510702924369 | validation: 0.10008735245575424]
	TIME [epoch: 8.32 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017864005705533		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.07017864005705533 | validation: 0.07478035932033289]
	TIME [epoch: 8.34 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08156262386576293		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.08156262386576293 | validation: 0.08570514509559501]
	TIME [epoch: 8.33 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07688598404556567		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.07688598404556567 | validation: 0.08279114001878324]
	TIME [epoch: 8.32 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10130695914539505		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.10130695914539505 | validation: 0.09523162287045181]
	TIME [epoch: 8.32 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0837560070384225		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.0837560070384225 | validation: 0.08392899672106083]
	TIME [epoch: 8.34 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07573291040224543		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.07573291040224543 | validation: 0.19833143741362302]
	TIME [epoch: 8.33 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09404963017856854		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.09404963017856854 | validation: 0.20980655846921795]
	TIME [epoch: 8.32 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14057139299812713		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.14057139299812713 | validation: 0.07382739012966635]
	TIME [epoch: 8.32 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059162940630506575		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.059162940630506575 | validation: 0.05159741252803697]
	TIME [epoch: 8.35 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08399815838885552		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.08399815838885552 | validation: 0.07421766442750194]
	TIME [epoch: 8.33 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10273117111819138		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.10273117111819138 | validation: 0.05601500682261791]
	TIME [epoch: 8.32 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05601624592852705		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.05601624592852705 | validation: 0.039879271759388574]
	TIME [epoch: 8.32 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07490062534956293		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.07490062534956293 | validation: 0.1650534526058338]
	TIME [epoch: 8.35 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10472744160505951		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.10472744160505951 | validation: 0.07508452449064543]
	TIME [epoch: 8.33 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08266022457617435		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.08266022457617435 | validation: 0.11341626130956448]
	TIME [epoch: 8.32 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12120203180617288		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.12120203180617288 | validation: 0.05873302896991227]
	TIME [epoch: 8.33 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07691181643385765		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.07691181643385765 | validation: 0.1691313934473483]
	TIME [epoch: 8.34 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08695449944368014		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.08695449944368014 | validation: 0.04413001212542378]
	TIME [epoch: 8.33 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739395255610363		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.0739395255610363 | validation: 0.07466325852268303]
	TIME [epoch: 8.32 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09604014292709087		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.09604014292709087 | validation: 0.0987273757384386]
	TIME [epoch: 8.32 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10834503473381907		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.10834503473381907 | validation: 0.07909397529706017]
	TIME [epoch: 8.34 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08374451644000769		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.08374451644000769 | validation: 0.06917041156114201]
	TIME [epoch: 8.33 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11236677442701007		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.11236677442701007 | validation: 0.05988774236709228]
	TIME [epoch: 8.32 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07136356417628156		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.07136356417628156 | validation: 0.08490255645578301]
	TIME [epoch: 8.32 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07699760748503896		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.07699760748503896 | validation: 0.07854901348935606]
	TIME [epoch: 8.34 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14421525774357347		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.14421525774357347 | validation: 0.13473369301768134]
	TIME [epoch: 8.32 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11297635769286143		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.11297635769286143 | validation: 0.10889179609636568]
	TIME [epoch: 8.32 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09287241688988361		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.09287241688988361 | validation: 0.16845680851846956]
	TIME [epoch: 8.33 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878206394643627		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.0878206394643627 | validation: 0.08349539378016488]
	TIME [epoch: 8.35 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07069109162851439		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.07069109162851439 | validation: 0.06172362235152552]
	TIME [epoch: 8.33 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09020537259822733		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.09020537259822733 | validation: 0.13399365746388417]
	TIME [epoch: 8.32 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11201667635271631		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.11201667635271631 | validation: 0.07482855877628816]
	TIME [epoch: 8.33 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05454919727871702		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.05454919727871702 | validation: 0.07402823355848466]
	TIME [epoch: 8.34 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10229623499007276		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.10229623499007276 | validation: 0.04337309017428145]
	TIME [epoch: 8.33 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07136137578112264		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.07136137578112264 | validation: 0.08668435371985568]
	TIME [epoch: 8.32 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12829074907075827		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.12829074907075827 | validation: 0.12919009087041772]
	TIME [epoch: 8.32 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08869787107710635		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.08869787107710635 | validation: 0.05834022044501472]
	TIME [epoch: 8.34 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0959447557141248		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.0959447557141248 | validation: 0.08306528909420227]
	TIME [epoch: 8.33 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09481578805155214		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.09481578805155214 | validation: 0.06949938213026412]
	TIME [epoch: 8.32 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516991301033896		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.06516991301033896 | validation: 0.06037111086486498]
	TIME [epoch: 8.32 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06944489280739545		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.06944489280739545 | validation: 0.08549856235637734]
	TIME [epoch: 8.34 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05078441572213964		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.05078441572213964 | validation: 0.12465470399889293]
	TIME [epoch: 8.32 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08000885752939225		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.08000885752939225 | validation: 0.10031215864747492]
	TIME [epoch: 8.32 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10623893440322547		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.10623893440322547 | validation: 0.09205974367192174]
	TIME [epoch: 8.32 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07885466997859758		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.07885466997859758 | validation: 0.05699425929992796]
	TIME [epoch: 8.34 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08330874987373775		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.08330874987373775 | validation: 0.08219935649247426]
	TIME [epoch: 8.32 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05588889656345182		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.05588889656345182 | validation: 0.047608061409551816]
	TIME [epoch: 8.33 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07974427360353431		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.07974427360353431 | validation: 0.04963740226021942]
	TIME [epoch: 8.32 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10864795331753004		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.10864795331753004 | validation: 0.06633327522024471]
	TIME [epoch: 8.34 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1052786026627063		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.1052786026627063 | validation: 0.0908554214006775]
	TIME [epoch: 8.33 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08765864852390395		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.08765864852390395 | validation: 0.0919313011254366]
	TIME [epoch: 8.33 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08915799013501617		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.08915799013501617 | validation: 0.07326340180771782]
	TIME [epoch: 8.33 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07226095661673881		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.07226095661673881 | validation: 0.06731773986373013]
	TIME [epoch: 8.34 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0636032990597942		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.0636032990597942 | validation: 0.051296300077761696]
	TIME [epoch: 8.32 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086684285340115		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.07086684285340115 | validation: 0.07991661503353123]
	TIME [epoch: 8.32 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08004894358267406		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.08004894358267406 | validation: 0.08661507641379551]
	TIME [epoch: 8.33 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10121475268956596		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.10121475268956596 | validation: 0.06568663311391404]
	TIME [epoch: 8.35 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057546283530870934		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.057546283530870934 | validation: 0.06576496359439937]
	TIME [epoch: 8.32 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07784774454832884		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.07784774454832884 | validation: 0.08076276842806906]
	TIME [epoch: 8.33 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06920862849722104		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.06920862849722104 | validation: 0.09787536909782905]
	TIME [epoch: 8.32 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08093369515683183		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.08093369515683183 | validation: 0.08253035339533418]
	TIME [epoch: 8.35 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08299211154399337		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.08299211154399337 | validation: 0.07776340664509909]
	TIME [epoch: 8.33 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07661604172948651		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.07661604172948651 | validation: 0.096515977716091]
	TIME [epoch: 8.32 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07430094306981955		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.07430094306981955 | validation: 0.04205280753598731]
	TIME [epoch: 8.32 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407921722936277		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.06407921722936277 | validation: 0.087580722948423]
	TIME [epoch: 8.35 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06170058068328928		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.06170058068328928 | validation: 0.09346374403112509]
	TIME [epoch: 8.32 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06670680720073326		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.06670680720073326 | validation: 0.08442122250951845]
	TIME [epoch: 8.33 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056927238364159506		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.056927238364159506 | validation: 0.0610792404795443]
	TIME [epoch: 8.32 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07353347565481912		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.07353347565481912 | validation: 0.06166398172258164]
	TIME [epoch: 8.35 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07014785858265422		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.07014785858265422 | validation: 0.06289368223826382]
	TIME [epoch: 8.32 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05090017594970514		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.05090017594970514 | validation: 0.05975771415821267]
	TIME [epoch: 8.32 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06887556282428083		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.06887556282428083 | validation: 0.10599925387868353]
	TIME [epoch: 8.32 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08069548164971238		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.08069548164971238 | validation: 0.06295512731157851]
	TIME [epoch: 8.35 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06096255939437313		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.06096255939437313 | validation: 0.16897335398521057]
	TIME [epoch: 8.33 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08276255027964133		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.08276255027964133 | validation: 0.07907856125798635]
	TIME [epoch: 8.32 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961503400422116		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.06961503400422116 | validation: 0.1558903498203899]
	TIME [epoch: 8.32 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08575526040052024		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.08575526040052024 | validation: 0.12105691521279097]
	TIME [epoch: 8.34 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07157550671178967		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.07157550671178967 | validation: 0.12960628874996707]
	TIME [epoch: 8.32 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07345194170090556		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.07345194170090556 | validation: 0.05543205149927456]
	TIME [epoch: 8.32 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06580244531766619		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.06580244531766619 | validation: 0.04470545173714268]
	TIME [epoch: 8.32 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04429409811788965		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.04429409811788965 | validation: 0.0746636923999745]
	TIME [epoch: 8.34 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06788769282633753		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.06788769282633753 | validation: 0.05679665444255064]
	TIME [epoch: 8.32 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06808639484255427		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.06808639484255427 | validation: 0.13255469451536608]
	TIME [epoch: 8.33 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06867348931901737		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.06867348931901737 | validation: 0.05738987877611179]
	TIME [epoch: 8.32 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09358891989563889		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.09358891989563889 | validation: 0.12032857212711678]
	TIME [epoch: 8.34 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1056994776488672		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.1056994776488672 | validation: 0.08944437255740853]
	TIME [epoch: 8.32 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08690630805833517		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.08690630805833517 | validation: 0.06717412501066057]
	TIME [epoch: 8.32 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05424028701782637		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.05424028701782637 | validation: 0.10577879744339855]
	TIME [epoch: 8.32 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058051615873884264		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.058051615873884264 | validation: 0.08405701397077547]
	TIME [epoch: 8.34 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08182368345140754		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.08182368345140754 | validation: 0.07445650196712035]
	TIME [epoch: 8.32 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07177209926086577		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.07177209926086577 | validation: 0.050445625160128446]
	TIME [epoch: 8.32 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0537908179604928		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.0537908179604928 | validation: 0.051343015463006465]
	TIME [epoch: 8.32 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06645981549946978		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.06645981549946978 | validation: 0.07311160858148474]
	TIME [epoch: 8.34 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06754346672075513		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.06754346672075513 | validation: 0.09000695548383772]
	TIME [epoch: 8.32 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07109423386629649		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.07109423386629649 | validation: 0.09317368488516162]
	TIME [epoch: 8.32 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07027266162325503		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.07027266162325503 | validation: 0.07472156046809875]
	TIME [epoch: 8.33 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060035874560995926		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.060035874560995926 | validation: 0.06544595936303144]
	TIME [epoch: 8.33 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0619782615662058		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.0619782615662058 | validation: 0.07576196721145391]
	TIME [epoch: 8.32 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06921045311002642		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.06921045311002642 | validation: 0.06135055698707573]
	TIME [epoch: 8.32 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284762772857854		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.07284762772857854 | validation: 0.06385539501712757]
	TIME [epoch: 8.33 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07915774743325754		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.07915774743325754 | validation: 0.03545630631497593]
	TIME [epoch: 8.34 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05825341552324903		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.05825341552324903 | validation: 0.03459716204051386]
	TIME [epoch: 8.33 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05609558785632329		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.05609558785632329 | validation: 0.03573533932278339]
	TIME [epoch: 8.33 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052988674071034636		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.052988674071034636 | validation: 0.05244516276304674]
	TIME [epoch: 8.33 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05870295097551469		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.05870295097551469 | validation: 0.09085710395162115]
	TIME [epoch: 8.34 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05956658106827088		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.05956658106827088 | validation: 0.101462324645389]
	TIME [epoch: 8.32 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07775814590329758		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.07775814590329758 | validation: 0.04161078902657975]
	TIME [epoch: 8.32 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04817970694494989		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.04817970694494989 | validation: 0.0593348372352783]
	TIME [epoch: 8.32 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0613415866582264		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.0613415866582264 | validation: 0.24047934224363882]
	TIME [epoch: 8.34 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11603951637725338		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.11603951637725338 | validation: 0.13831430476798018]
	TIME [epoch: 8.32 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08364710798516804		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.08364710798516804 | validation: 0.10931477155652676]
	TIME [epoch: 8.33 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05703239625200217		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.05703239625200217 | validation: 0.044204613875644366]
	TIME [epoch: 8.32 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049906745159815566		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.049906745159815566 | validation: 0.06705525384157882]
	TIME [epoch: 8.34 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10622898675250869		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.10622898675250869 | validation: 0.055355865867793744]
	TIME [epoch: 8.32 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07178424036762968		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.07178424036762968 | validation: 0.09473062686423829]
	TIME [epoch: 8.32 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467072002292594		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.06467072002292594 | validation: 0.09129723046858662]
	TIME [epoch: 8.33 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061090699848622		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.061090699848622 | validation: 0.07794627311270086]
	TIME [epoch: 8.33 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07164061659613885		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.07164061659613885 | validation: 0.15546619346804297]
	TIME [epoch: 8.32 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06219526211570904		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.06219526211570904 | validation: 0.05407655652469783]
	TIME [epoch: 8.32 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08130094115249624		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.08130094115249624 | validation: 0.06731503710478973]
	TIME [epoch: 8.33 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08246997019815185		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.08246997019815185 | validation: 0.050626996403545725]
	TIME [epoch: 8.33 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06538637568414979		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.06538637568414979 | validation: 0.046071722799055345]
	TIME [epoch: 8.32 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056677754038824746		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.056677754038824746 | validation: 0.0787286615128858]
	TIME [epoch: 8.32 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06980037476126845		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.06980037476126845 | validation: 0.045843092552321954]
	TIME [epoch: 8.33 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045188773193261804		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.045188773193261804 | validation: 0.14521995851794786]
	TIME [epoch: 8.33 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08822390549841552		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.08822390549841552 | validation: 0.05812063075978255]
	TIME [epoch: 8.32 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661954819960116		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.0661954819960116 | validation: 0.09829958738963022]
	TIME [epoch: 8.32 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06807066315856317		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.06807066315856317 | validation: 0.054087739139852986]
	TIME [epoch: 8.33 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08796298973118775		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.08796298973118775 | validation: 0.07129557387454291]
	TIME [epoch: 8.33 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055433301265202316		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.055433301265202316 | validation: 0.0863620173767067]
	TIME [epoch: 8.32 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08710976338765695		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.08710976338765695 | validation: 0.05621696207374161]
	TIME [epoch: 8.32 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05172866321702024		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.05172866321702024 | validation: 0.0713969860821241]
	TIME [epoch: 8.33 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061462792248351814		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.061462792248351814 | validation: 0.12377600151992313]
	TIME [epoch: 8.34 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06735293976340977		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.06735293976340977 | validation: 0.09060786473685387]
	TIME [epoch: 8.33 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060784608498152634		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.060784608498152634 | validation: 0.07574348544409042]
	TIME [epoch: 8.32 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671285894592724		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.06671285894592724 | validation: 0.05182425220455182]
	TIME [epoch: 8.34 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07022075645055967		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.07022075645055967 | validation: 0.04609650877010439]
	TIME [epoch: 8.32 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07157716243842398		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.07157716243842398 | validation: 0.05424785887315429]
	TIME [epoch: 8.32 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06492332987861951		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.06492332987861951 | validation: 0.06833776277157377]
	TIME [epoch: 8.32 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06254667852558485		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.06254667852558485 | validation: 0.07460299432671659]
	TIME [epoch: 8.34 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09496108686379334		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.09496108686379334 | validation: 0.12250546015037844]
	TIME [epoch: 8.33 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09810298901411305		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.09810298901411305 | validation: 0.06165102333952997]
	TIME [epoch: 8.32 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06972242134033488		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.06972242134033488 | validation: 0.05896420878717258]
	TIME [epoch: 8.32 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06084852819220937		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.06084852819220937 | validation: 0.04213184429281207]
	TIME [epoch: 8.34 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05749776044934005		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.05749776044934005 | validation: 0.059912931916184055]
	TIME [epoch: 8.33 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06312175912595781		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.06312175912595781 | validation: 0.058479399059951566]
	TIME [epoch: 8.32 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07015162156071539		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.07015162156071539 | validation: 0.059039050265300236]
	TIME [epoch: 8.32 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628085635324134		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.0628085635324134 | validation: 0.059737515431267735]
	TIME [epoch: 8.33 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06040664275360086		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.06040664275360086 | validation: 0.06491406288891971]
	TIME [epoch: 8.33 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06295840329042232		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.06295840329042232 | validation: 0.06840607152748737]
	TIME [epoch: 8.32 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07689054296733526		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.07689054296733526 | validation: 0.11378158198760638]
	TIME [epoch: 8.32 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06933081599438803		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.06933081599438803 | validation: 0.12783605277852372]
	TIME [epoch: 8.33 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08661412394881869		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.08661412394881869 | validation: 0.1962178912940804]
	TIME [epoch: 8.33 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671309775996296		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.07671309775996296 | validation: 0.08845590571782802]
	TIME [epoch: 8.32 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0722497107324488		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.0722497107324488 | validation: 0.057258566431459615]
	TIME [epoch: 8.31 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05520507907892501		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.05520507907892501 | validation: 0.048090546204070654]
	TIME [epoch: 8.33 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04809342001579042		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.04809342001579042 | validation: 0.08477859640043552]
	TIME [epoch: 8.33 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07101771086136156		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.07101771086136156 | validation: 0.05677639969932339]
	TIME [epoch: 8.32 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0646609758073858		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.0646609758073858 | validation: 0.07259565254722747]
	TIME [epoch: 8.32 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06669251247326968		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.06669251247326968 | validation: 0.06924408346190883]
	TIME [epoch: 8.33 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06189032046511287		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.06189032046511287 | validation: 0.053404986605077004]
	TIME [epoch: 8.32 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0544961158196726		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.0544961158196726 | validation: 0.06966447894870371]
	TIME [epoch: 8.31 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524876687938434		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.06524876687938434 | validation: 0.05895322574146096]
	TIME [epoch: 8.31 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04486816890844718		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.04486816890844718 | validation: 0.06399173838042237]
	TIME [epoch: 8.33 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0851077528418396		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.0851077528418396 | validation: 0.05478125885956332]
	TIME [epoch: 8.32 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648247698742362		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.0648247698742362 | validation: 0.06843442768766311]
	TIME [epoch: 8.31 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06530869179683751		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.06530869179683751 | validation: 0.05059019114726427]
	TIME [epoch: 8.31 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04977595631074472		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.04977595631074472 | validation: 0.05521436732916799]
	TIME [epoch: 8.33 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041245260364226884		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.041245260364226884 | validation: 0.040446264540876395]
	TIME [epoch: 8.32 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051742121141396966		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.051742121141396966 | validation: 0.08982274700483417]
	TIME [epoch: 8.31 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08477511796409157		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.08477511796409157 | validation: 0.09556399149957974]
	TIME [epoch: 8.31 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676189972358808		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.0676189972358808 | validation: 0.053460106503888674]
	TIME [epoch: 8.34 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060515106462743794		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.060515106462743794 | validation: 0.07029377247835869]
	TIME [epoch: 8.32 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04323561750792032		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.04323561750792032 | validation: 0.053264534026819646]
	TIME [epoch: 8.32 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05464280227781768		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.05464280227781768 | validation: 0.055633522985232366]
	TIME [epoch: 8.32 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04753340357610908		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.04753340357610908 | validation: 0.07056800447900369]
	TIME [epoch: 8.34 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07790106640312447		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.07790106640312447 | validation: 0.054161300423730664]
	TIME [epoch: 8.32 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049160850551032906		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.049160850551032906 | validation: 0.0886872505136129]
	TIME [epoch: 8.32 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528509249684995		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.06528509249684995 | validation: 0.06390370082662779]
	TIME [epoch: 8.31 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06478959238020063		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.06478959238020063 | validation: 0.043524516768934415]
	TIME [epoch: 8.34 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07502653018315691		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.07502653018315691 | validation: 0.06715081706331182]
	TIME [epoch: 8.32 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09683386058279989		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.09683386058279989 | validation: 0.09900589618246797]
	TIME [epoch: 8.32 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643324065832898		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.0643324065832898 | validation: 0.05067221537138967]
	TIME [epoch: 8.32 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05948428667607604		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.05948428667607604 | validation: 0.04128411603167085]
	TIME [epoch: 8.33 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056192538877642376		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.056192538877642376 | validation: 0.08693936846137801]
	TIME [epoch: 8.32 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07707070269159018		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.07707070269159018 | validation: 0.057510651539752045]
	TIME [epoch: 8.31 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047463463684716566		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.047463463684716566 | validation: 0.044194296249410694]
	TIME [epoch: 8.32 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04137035449475456		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.04137035449475456 | validation: 0.04165510280675517]
	TIME [epoch: 8.34 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06534940538658632		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.06534940538658632 | validation: 0.060836522517371414]
	TIME [epoch: 8.32 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06223661017878379		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.06223661017878379 | validation: 0.08609619225957399]
	TIME [epoch: 8.32 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07095786233879428		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.07095786233879428 | validation: 0.04458362755592357]
	TIME [epoch: 8.32 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0602733668717925		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.0602733668717925 | validation: 0.043318626971373016]
	TIME [epoch: 8.34 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0443078090852671		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.0443078090852671 | validation: 0.05408192102035178]
	TIME [epoch: 8.32 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0868964471270246		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.0868964471270246 | validation: 0.13089391170055903]
	TIME [epoch: 8.32 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06586239558639137		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.06586239558639137 | validation: 0.06625746364072534]
	TIME [epoch: 8.31 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0704678483525242		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.0704678483525242 | validation: 0.07248490522421647]
	TIME [epoch: 8.34 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07274023742617045		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.07274023742617045 | validation: 0.14079438401052707]
	TIME [epoch: 8.32 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089549130176878		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.07089549130176878 | validation: 0.07174140417586915]
	TIME [epoch: 8.32 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09090380583653383		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.09090380583653383 | validation: 0.05763701358028939]
	TIME [epoch: 8.32 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05005649385152505		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.05005649385152505 | validation: 0.09197522607261754]
	TIME [epoch: 8.34 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055040294848632855		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.055040294848632855 | validation: 0.04436470842604241]
	TIME [epoch: 8.32 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05518785282182278		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.05518785282182278 | validation: 0.12500132680347642]
	TIME [epoch: 8.32 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06213895782612553		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.06213895782612553 | validation: 0.052589937356221736]
	TIME [epoch: 8.32 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04768837897068902		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.04768837897068902 | validation: 0.043191014996476824]
	TIME [epoch: 8.34 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040965772280684536		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.040965772280684536 | validation: 0.05765037694736587]
	TIME [epoch: 8.32 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06973263632230059		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.06973263632230059 | validation: 0.05562010767144913]
	TIME [epoch: 8.32 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04913149178242909		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.04913149178242909 | validation: 0.04938205835647458]
	TIME [epoch: 8.32 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07673005695747674		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.07673005695747674 | validation: 0.08507673034996789]
	TIME [epoch: 8.34 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05150520565065112		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.05150520565065112 | validation: 0.053099793367915565]
	TIME [epoch: 8.32 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05169229207631211		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.05169229207631211 | validation: 0.05886768272770489]
	TIME [epoch: 8.32 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08201095714085556		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.08201095714085556 | validation: 0.07846457139432919]
	TIME [epoch: 8.32 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06918152611411506		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.06918152611411506 | validation: 0.044570633879717846]
	TIME [epoch: 8.34 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050378504768291275		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.050378504768291275 | validation: 0.0432593890349081]
	TIME [epoch: 8.32 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05380566618604156		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.05380566618604156 | validation: 0.11708008145871307]
	TIME [epoch: 8.31 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07489307180216721		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.07489307180216721 | validation: 0.08362016398155989]
	TIME [epoch: 8.32 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06180313023094246		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.06180313023094246 | validation: 0.043184187355982645]
	TIME [epoch: 8.34 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07944653830077877		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.07944653830077877 | validation: 0.07805649648503507]
	TIME [epoch: 8.32 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04472992892960419		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.04472992892960419 | validation: 0.07862081477844549]
	TIME [epoch: 8.31 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05996446267516704		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.05996446267516704 | validation: 0.06003374165819183]
	TIME [epoch: 8.32 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048722329050165124		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.048722329050165124 | validation: 0.04154019462641135]
	TIME [epoch: 8.34 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0440456345946368		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.0440456345946368 | validation: 0.10662261418523206]
	TIME [epoch: 8.32 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086760486326282		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.07086760486326282 | validation: 0.051030955786045315]
	TIME [epoch: 8.32 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06663661718853878		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.06663661718853878 | validation: 0.04400111621025123]
	TIME [epoch: 8.32 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05675886824873807		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.05675886824873807 | validation: 0.05522955067998828]
	TIME [epoch: 8.34 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04617235919150053		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.04617235919150053 | validation: 0.0680428735937848]
	TIME [epoch: 8.32 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05487349416495346		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.05487349416495346 | validation: 0.064770932962578]
	TIME [epoch: 8.32 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05932881822881333		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.05932881822881333 | validation: 0.05503672597306292]
	TIME [epoch: 8.32 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058817286091330814		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.058817286091330814 | validation: 0.03364698835218567]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1079.pth
	Model improved!!!
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03736566191807108		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.03736566191807108 | validation: 0.05858833711753888]
	TIME [epoch: 8.32 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06255698627201153		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.06255698627201153 | validation: 0.02980291427317739]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06304929421079197		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.06304929421079197 | validation: 0.04216795823004035]
	TIME [epoch: 8.32 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04753997865196405		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.04753997865196405 | validation: 0.06405666705959398]
	TIME [epoch: 8.34 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07363104262978425		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.07363104262978425 | validation: 0.08949332988335179]
	TIME [epoch: 8.31 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06630834507576193		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.06630834507576193 | validation: 0.05273336294071264]
	TIME [epoch: 8.32 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042149228642041195		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.042149228642041195 | validation: 0.045512995691591826]
	TIME [epoch: 8.32 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04941746208266996		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.04941746208266996 | validation: 0.04997597503360852]
	TIME [epoch: 8.34 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0509533081397889		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.0509533081397889 | validation: 0.036423755660573154]
	TIME [epoch: 8.31 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053885251617251606		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.053885251617251606 | validation: 0.03512732560082718]
	TIME [epoch: 8.32 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052992201057560216		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.052992201057560216 | validation: 0.09578545759840462]
	TIME [epoch: 8.32 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05500643839543416		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.05500643839543416 | validation: 0.040812258881648966]
	TIME [epoch: 8.34 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033846858128042424		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.033846858128042424 | validation: 0.034288056509441264]
	TIME [epoch: 8.32 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04072948340557896		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.04072948340557896 | validation: 0.06760586336554544]
	TIME [epoch: 8.31 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05549717537565242		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.05549717537565242 | validation: 0.18515895792254133]
	TIME [epoch: 8.32 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08700551053076123		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.08700551053076123 | validation: 0.11853889458887866]
	TIME [epoch: 8.34 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05797716773433779		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.05797716773433779 | validation: 0.05771071312062894]
	TIME [epoch: 8.32 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05442760474625359		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.05442760474625359 | validation: 0.0458008501610947]
	TIME [epoch: 8.32 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056385081921438526		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.056385081921438526 | validation: 0.06620327574017547]
	TIME [epoch: 8.32 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04480806698789315		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.04480806698789315 | validation: 0.04443243264278279]
	TIME [epoch: 8.34 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05137878559141331		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.05137878559141331 | validation: 0.047043365305449475]
	TIME [epoch: 8.32 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054450555457734306		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.054450555457734306 | validation: 0.05298796119184328]
	TIME [epoch: 8.32 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04923315265974262		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.04923315265974262 | validation: 0.08966114754486018]
	TIME [epoch: 8.32 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04729324494548577		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.04729324494548577 | validation: 0.046032581342467765]
	TIME [epoch: 8.35 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05797980525625089		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.05797980525625089 | validation: 0.044532500186545386]
	TIME [epoch: 8.33 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044317733122879		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.044317733122879 | validation: 0.04561859459985221]
	TIME [epoch: 8.32 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07993687685376051		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.07993687685376051 | validation: 0.06717695302354408]
	TIME [epoch: 8.33 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06513497336809387		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.06513497336809387 | validation: 0.05118259724573624]
	TIME [epoch: 8.35 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366860324943274		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.06366860324943274 | validation: 0.06434961898920177]
	TIME [epoch: 8.32 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06909067197701321		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.06909067197701321 | validation: 0.0522010795452032]
	TIME [epoch: 8.32 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057835524864454736		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.057835524864454736 | validation: 0.0694257425205486]
	TIME [epoch: 8.32 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860296513389577		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.06860296513389577 | validation: 0.06521210565152856]
	TIME [epoch: 8.34 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04367392911023578		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.04367392911023578 | validation: 0.051570192861743455]
	TIME [epoch: 8.32 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06403413581535117		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.06403413581535117 | validation: 0.04563454357281388]
	TIME [epoch: 8.32 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05771916704637246		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.05771916704637246 | validation: 0.07030142286026558]
	TIME [epoch: 8.33 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0544938692236129		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.0544938692236129 | validation: 0.06880446132409106]
	TIME [epoch: 8.34 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07950887665596039		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.07950887665596039 | validation: 0.058677239458940024]
	TIME [epoch: 8.32 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04029376049730756		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.04029376049730756 | validation: 0.04668323560310684]
	TIME [epoch: 8.32 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047668868562556505		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.047668868562556505 | validation: 0.04719441746324761]
	TIME [epoch: 8.33 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04042129043724058		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.04042129043724058 | validation: 0.04777533757447714]
	TIME [epoch: 8.34 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08676448904927386		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.08676448904927386 | validation: 0.035220116091176576]
	TIME [epoch: 8.32 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0462840735076007		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.0462840735076007 | validation: 0.04469472360685865]
	TIME [epoch: 8.31 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06842826300487297		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.06842826300487297 | validation: 0.08754346487616553]
	TIME [epoch: 8.33 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04102576456248191		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.04102576456248191 | validation: 0.041011020779000894]
	TIME [epoch: 8.33 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0568021068371505		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.0568021068371505 | validation: 0.12173932493637096]
	TIME [epoch: 8.32 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061413795815702776		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.061413795815702776 | validation: 0.044917668090704216]
	TIME [epoch: 8.31 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05098947298833748		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.05098947298833748 | validation: 0.10612862306734273]
	TIME [epoch: 8.32 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06054141675133744		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.06054141675133744 | validation: 0.05858633332517213]
	TIME [epoch: 8.33 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03983303049108977		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.03983303049108977 | validation: 0.06639818002089758]
	TIME [epoch: 8.31 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06002539002481326		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.06002539002481326 | validation: 0.05195631093442301]
	TIME [epoch: 8.32 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040250642546208644		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.040250642546208644 | validation: 0.05519695151190783]
	TIME [epoch: 8.33 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05285113266802133		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.05285113266802133 | validation: 0.028330390410509443]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1131.pth
	Model improved!!!
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0803015997565721		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.0803015997565721 | validation: 0.08981811786493654]
	TIME [epoch: 8.32 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05024044951030369		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.05024044951030369 | validation: 0.062468726919409585]
	TIME [epoch: 8.31 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664085921177216		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.05664085921177216 | validation: 0.04781789465387967]
	TIME [epoch: 8.33 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03878532852836201		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.03878532852836201 | validation: 0.03890800815688346]
	TIME [epoch: 8.33 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035483665396456185		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.035483665396456185 | validation: 0.0786097946542807]
	TIME [epoch: 8.31 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050082267000778405		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.050082267000778405 | validation: 0.079893126260088]
	TIME [epoch: 8.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0529979990379709		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.0529979990379709 | validation: 0.053387625363564145]
	TIME [epoch: 8.33 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04268289871918044		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.04268289871918044 | validation: 0.04292136039718526]
	TIME [epoch: 8.32 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04668915307782032		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.04668915307782032 | validation: 0.061341337512332283]
	TIME [epoch: 8.32 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07616739169866993		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.07616739169866993 | validation: 0.04570626230547051]
	TIME [epoch: 8.31 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039319533391296936		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.039319533391296936 | validation: 0.05123636948929773]
	TIME [epoch: 8.33 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049281100430980766		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.049281100430980766 | validation: 0.05611311111182418]
	TIME [epoch: 8.32 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060671899920682684		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.060671899920682684 | validation: 0.04787359156518434]
	TIME [epoch: 8.32 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040233598804641287		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.040233598804641287 | validation: 0.06668479753581787]
	TIME [epoch: 8.31 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0493395408081295		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.0493395408081295 | validation: 0.04881986411189417]
	TIME [epoch: 8.33 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038040182393656266		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.038040182393656266 | validation: 0.03800094543802504]
	TIME [epoch: 8.32 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045480278394791594		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.045480278394791594 | validation: 0.03596681566042372]
	TIME [epoch: 8.31 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539963509741643		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.06539963509741643 | validation: 0.04874455448600415]
	TIME [epoch: 8.32 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04190084192156277		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.04190084192156277 | validation: 0.03533927979534128]
	TIME [epoch: 8.33 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03722009946505382		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.03722009946505382 | validation: 0.047253038672918385]
	TIME [epoch: 8.32 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04354567656742415		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.04354567656742415 | validation: 0.04166798521914727]
	TIME [epoch: 8.31 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04815814978374087		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.04815814978374087 | validation: 0.04172098991014328]
	TIME [epoch: 8.31 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043827982284185205		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.043827982284185205 | validation: 0.05439749154477303]
	TIME [epoch: 8.33 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0483632472135918		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.0483632472135918 | validation: 0.03767152421747487]
	TIME [epoch: 8.32 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043455584742870854		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.043455584742870854 | validation: 0.04892742205871821]
	TIME [epoch: 8.32 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05011643917717397		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.05011643917717397 | validation: 0.07078734594299144]
	TIME [epoch: 8.31 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04877418171573125		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.04877418171573125 | validation: 0.04520369258078123]
	TIME [epoch: 8.34 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0557349315027328		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.0557349315027328 | validation: 0.043410590732268994]
	TIME [epoch: 8.32 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044774460883862714		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.044774460883862714 | validation: 0.05748664654131981]
	TIME [epoch: 8.32 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05778203013985571		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.05778203013985571 | validation: 0.06840490911264105]
	TIME [epoch: 8.31 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043489054666596604		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.043489054666596604 | validation: 0.0342045023402208]
	TIME [epoch: 8.33 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05077572779174937		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.05077572779174937 | validation: 0.050585498764137975]
	TIME [epoch: 8.32 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04585078229764763		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.04585078229764763 | validation: 0.06785829798066786]
	TIME [epoch: 8.32 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04633806893204485		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.04633806893204485 | validation: 0.07698337620467753]
	TIME [epoch: 8.31 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05954488528901648		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.05954488528901648 | validation: 0.06142517313346424]
	TIME [epoch: 8.33 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044210144565404674		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.044210144565404674 | validation: 0.04869432082079727]
	TIME [epoch: 8.31 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04774511773559361		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.04774511773559361 | validation: 0.043885102069896036]
	TIME [epoch: 8.31 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050807123900767734		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.050807123900767734 | validation: 0.0555225884083959]
	TIME [epoch: 8.31 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03511410576723872		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.03511410576723872 | validation: 0.04332306763848025]
	TIME [epoch: 8.32 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04419442030971312		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.04419442030971312 | validation: 0.059085423262259185]
	TIME [epoch: 8.32 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040121859160885884		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.040121859160885884 | validation: 0.06777050950250806]
	TIME [epoch: 8.32 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042870495077188576		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.042870495077188576 | validation: 0.029316755859251913]
	TIME [epoch: 8.31 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04837536597369665		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.04837536597369665 | validation: 0.05570063912042244]
	TIME [epoch: 8.34 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07199322700896435		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.07199322700896435 | validation: 0.13094895998867265]
	TIME [epoch: 8.31 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07635529936746398		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.07635529936746398 | validation: 0.04771771049894519]
	TIME [epoch: 8.32 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07262177204613404		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.07262177204613404 | validation: 0.05130123234235542]
	TIME [epoch: 8.31 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051666827569715676		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.051666827569715676 | validation: 0.04635381129254407]
	TIME [epoch: 8.33 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0638071774414311		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.0638071774414311 | validation: 0.07487197010114624]
	TIME [epoch: 8.32 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047559115545885405		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.047559115545885405 | validation: 0.03305374195967613]
	TIME [epoch: 8.31 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04821438531918344		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.04821438531918344 | validation: 0.09026649108322041]
	TIME [epoch: 8.3 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05715966920436868		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.05715966920436868 | validation: 0.04045687189295277]
	TIME [epoch: 8.32 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04168765169884609		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.04168765169884609 | validation: 0.05203414971632657]
	TIME [epoch: 8.31 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05064560814495106		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.05064560814495106 | validation: 0.04220621718438166]
	TIME [epoch: 8.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05300852221104466		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.05300852221104466 | validation: 0.04773536135408914]
	TIME [epoch: 8.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05051433286827407		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.05051433286827407 | validation: 0.03742666958773386]
	TIME [epoch: 8.33 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040740044902436254		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.040740044902436254 | validation: 0.05323615401359408]
	TIME [epoch: 8.31 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04125961249606553		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.04125961249606553 | validation: 0.07070252551500365]
	TIME [epoch: 8.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04679802243683981		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.04679802243683981 | validation: 0.03732149747207912]
	TIME [epoch: 8.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050092242261600604		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.050092242261600604 | validation: 0.07203643490077227]
	TIME [epoch: 8.32 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05123468292029011		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.05123468292029011 | validation: 0.04315603040963405]
	TIME [epoch: 8.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040500370486010746		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.040500370486010746 | validation: 0.0595060782151416]
	TIME [epoch: 8.31 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04955931035106127		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.04955931035106127 | validation: 0.030961874903192556]
	TIME [epoch: 8.31 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03896586252160473		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.03896586252160473 | validation: 0.04867439793108734]
	TIME [epoch: 8.34 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050989440063161084		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.050989440063161084 | validation: 0.0773958669758594]
	TIME [epoch: 8.31 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04718013959968863		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.04718013959968863 | validation: 0.0847776837380636]
	TIME [epoch: 8.31 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048513066919067725		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.048513066919067725 | validation: 0.051942184696119276]
	TIME [epoch: 8.31 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03863547641679363		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.03863547641679363 | validation: 0.07099615117132879]
	TIME [epoch: 8.33 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047428791563605896		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.047428791563605896 | validation: 0.03774517602931623]
	TIME [epoch: 8.32 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04342820955534713		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.04342820955534713 | validation: 0.045035792617278754]
	TIME [epoch: 8.31 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04315629091994754		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.04315629091994754 | validation: 0.051923411352121335]
	TIME [epoch: 8.31 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04899890431089649		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.04899890431089649 | validation: 0.0673880970388681]
	TIME [epoch: 8.33 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044128435109986236		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.044128435109986236 | validation: 0.034526247617299125]
	TIME [epoch: 8.31 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05429475679787645		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.05429475679787645 | validation: 0.09950947738772262]
	TIME [epoch: 8.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05054932950981933		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.05054932950981933 | validation: 0.039616239483083515]
	TIME [epoch: 8.31 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03866249569478746		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.03866249569478746 | validation: 0.03264083937513175]
	TIME [epoch: 8.33 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042825901818921604		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.042825901818921604 | validation: 0.0459383416965748]
	TIME [epoch: 8.31 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04813591889024514		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.04813591889024514 | validation: 0.06997332313116805]
	TIME [epoch: 8.31 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07518785747650944		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.07518785747650944 | validation: 0.04118480954621674]
	TIME [epoch: 8.31 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040332144247673375		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.040332144247673375 | validation: 0.052771621402218215]
	TIME [epoch: 8.33 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06107203812257891		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.06107203812257891 | validation: 0.05963540286071754]
	TIME [epoch: 8.31 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05926728513649582		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.05926728513649582 | validation: 0.050790666396777706]
	TIME [epoch: 8.31 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053600481195910224		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.053600481195910224 | validation: 0.07612397769242228]
	TIME [epoch: 8.31 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05841102027082483		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.05841102027082483 | validation: 0.06651982577408712]
	TIME [epoch: 8.33 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040662523710704127		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.040662523710704127 | validation: 0.050105035450311135]
	TIME [epoch: 8.32 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05253212642447304		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.05253212642447304 | validation: 0.04903301296412757]
	TIME [epoch: 8.31 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048700754555504794		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.048700754555504794 | validation: 0.05882499599374867]
	TIME [epoch: 8.31 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03332565103717088		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.03332565103717088 | validation: 0.03825980811765256]
	TIME [epoch: 8.34 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04884857812449167		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.04884857812449167 | validation: 0.05497750855578467]
	TIME [epoch: 8.32 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034956415918922276		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.034956415918922276 | validation: 0.0361139750147529]
	TIME [epoch: 8.31 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04005429966993495		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.04005429966993495 | validation: 0.036156561943601694]
	TIME [epoch: 8.32 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04349949341424397		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.04349949341424397 | validation: 0.08045381643041369]
	TIME [epoch: 8.34 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049822749544691854		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.049822749544691854 | validation: 0.036454690496806455]
	TIME [epoch: 8.32 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04187132378920861		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.04187132378920861 | validation: 0.040725604431727735]
	TIME [epoch: 8.31 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07473939188022048		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.07473939188022048 | validation: 0.05738209892063416]
	TIME [epoch: 8.31 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04249749255739974		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.04249749255739974 | validation: 0.04180539317794277]
	TIME [epoch: 8.33 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046770524570467195		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.046770524570467195 | validation: 0.04394950536491697]
	TIME [epoch: 8.31 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04372972844384543		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.04372972844384543 | validation: 0.04081706376824029]
	TIME [epoch: 8.31 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032180923332299036		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.032180923332299036 | validation: 0.0485449852902243]
	TIME [epoch: 8.31 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04867122892004088		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.04867122892004088 | validation: 0.03796115817221789]
	TIME [epoch: 8.33 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050902416386815696		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.050902416386815696 | validation: 0.054516834530280917]
	TIME [epoch: 8.31 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05134185620331257		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.05134185620331257 | validation: 0.06246463249027799]
	TIME [epoch: 8.31 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050831127193159555		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.050831127193159555 | validation: 0.08948794967414407]
	TIME [epoch: 8.31 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06258625878495114		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.06258625878495114 | validation: 0.04725728821959345]
	TIME [epoch: 8.33 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03452222780405882		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.03452222780405882 | validation: 0.04216578502017897]
	TIME [epoch: 8.31 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06824697648237452		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.06824697648237452 | validation: 0.037629086200318546]
	TIME [epoch: 8.31 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04802241527627695		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.04802241527627695 | validation: 0.0587595429615667]
	TIME [epoch: 8.31 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05594552786444891		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.05594552786444891 | validation: 0.06030250298125306]
	TIME [epoch: 8.33 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05355539972886436		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.05355539972886436 | validation: 0.053362512512738165]
	TIME [epoch: 8.31 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03949978967491345		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.03949978967491345 | validation: 0.06467842031524709]
	TIME [epoch: 8.31 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04553287681125022		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.04553287681125022 | validation: 0.028279618591886234]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1241.pth
	Model improved!!!
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04198511877731588		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.04198511877731588 | validation: 0.06129009170978658]
	TIME [epoch: 8.33 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04183332933111008		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.04183332933111008 | validation: 0.04403609664941754]
	TIME [epoch: 8.31 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0552685885265084		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.0552685885265084 | validation: 0.05423690602053538]
	TIME [epoch: 8.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04142009104871192		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.04142009104871192 | validation: 0.06757630611106842]
	TIME [epoch: 8.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05109997128345539		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.05109997128345539 | validation: 0.06522218480012434]
	TIME [epoch: 8.34 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04900741276430609		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.04900741276430609 | validation: 0.05809859350668191]
	TIME [epoch: 8.32 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04568440005168041		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.04568440005168041 | validation: 0.09386301842743924]
	TIME [epoch: 8.31 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06454162690370327		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.06454162690370327 | validation: 0.055303528582467336]
	TIME [epoch: 8.31 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04770871866822242		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.04770871866822242 | validation: 0.04473607765345872]
	TIME [epoch: 8.33 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05782277824559027		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.05782277824559027 | validation: 0.042501344513713485]
	TIME [epoch: 8.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042585660119114736		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.042585660119114736 | validation: 0.052643158101007725]
	TIME [epoch: 8.31 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04120613599497227		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.04120613599497227 | validation: 0.04302775135521002]
	TIME [epoch: 8.31 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053528044004705774		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.053528044004705774 | validation: 0.03954088430028914]
	TIME [epoch: 8.34 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05493269687713916		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.05493269687713916 | validation: 0.04826469154561605]
	TIME [epoch: 8.31 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04768355769720856		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.04768355769720856 | validation: 0.039446115552822646]
	TIME [epoch: 8.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03672129871585806		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.03672129871585806 | validation: 0.05170712638952296]
	TIME [epoch: 8.31 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042624940329050995		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.042624940329050995 | validation: 0.03569833900998011]
	TIME [epoch: 8.33 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037345281278287706		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.037345281278287706 | validation: 0.05440545394959852]
	TIME [epoch: 8.31 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04535208073434031		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.04535208073434031 | validation: 0.043354319568393515]
	TIME [epoch: 8.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040801949983707134		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.040801949983707134 | validation: 0.06192634160709401]
	TIME [epoch: 8.31 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03554124795287855		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.03554124795287855 | validation: 0.04161963107402247]
	TIME [epoch: 8.34 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043998011581622316		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.043998011581622316 | validation: 0.04187026188633054]
	TIME [epoch: 8.3 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042328050106210297		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.042328050106210297 | validation: 0.05438333109720998]
	TIME [epoch: 8.31 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03753037677192439		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.03753037677192439 | validation: 0.06391066933038031]
	TIME [epoch: 8.31 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0531169321103628		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.0531169321103628 | validation: 0.05032093752895485]
	TIME [epoch: 8.33 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03783663571030909		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.03783663571030909 | validation: 0.04525531021370721]
	TIME [epoch: 8.31 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03612390520251555		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.03612390520251555 | validation: 0.03241164011935013]
	TIME [epoch: 8.31 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03385750409595355		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.03385750409595355 | validation: 0.05233984342587823]
	TIME [epoch: 8.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046230737275198115		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.046230737275198115 | validation: 0.04071212228767353]
	TIME [epoch: 8.33 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04984921467277081		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.04984921467277081 | validation: 0.03155773282906837]
	TIME [epoch: 8.31 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032576455194282664		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.032576455194282664 | validation: 0.044468766427232354]
	TIME [epoch: 8.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04056102324079947		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.04056102324079947 | validation: 0.05104293614316888]
	TIME [epoch: 8.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05212760099764828		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.05212760099764828 | validation: 0.051913713314122215]
	TIME [epoch: 8.33 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0807340142678888		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.0807340142678888 | validation: 0.044126634037768744]
	TIME [epoch: 8.31 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047845905171093744		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.047845905171093744 | validation: 0.04567688671858021]
	TIME [epoch: 8.31 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03760030866838576		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.03760030866838576 | validation: 0.05989708937630476]
	TIME [epoch: 8.31 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042202007755989625		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.042202007755989625 | validation: 0.06234768612799326]
	TIME [epoch: 8.34 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0542089392485642		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.0542089392485642 | validation: 0.03937338507242384]
	TIME [epoch: 8.31 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03991837551841068		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.03991837551841068 | validation: 0.04691037795606694]
	TIME [epoch: 8.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0399383075497148		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.0399383075497148 | validation: 0.06482616051129446]
	TIME [epoch: 8.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05642223119047422		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.05642223119047422 | validation: 0.06517840814730877]
	TIME [epoch: 8.32 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05075849084389593		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.05075849084389593 | validation: 0.05823730795653663]
	TIME [epoch: 8.31 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04554932120707932		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.04554932120707932 | validation: 0.05227969383152207]
	TIME [epoch: 8.31 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04075172457900121		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.04075172457900121 | validation: 0.03381115005260041]
	TIME [epoch: 8.31 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04180733152190377		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.04180733152190377 | validation: 0.0576705085091012]
	TIME [epoch: 8.33 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030284367392178546		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.030284367392178546 | validation: 0.034263735374289096]
	TIME [epoch: 8.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03257601934184859		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.03257601934184859 | validation: 0.05965117448811581]
	TIME [epoch: 8.29 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03274679823010626		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.03274679823010626 | validation: 0.03606967683238466]
	TIME [epoch: 8.3 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03960427060316696		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.03960427060316696 | validation: 0.04731278658508521]
	TIME [epoch: 8.32 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03991918533138368		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.03991918533138368 | validation: 0.05106575720319202]
	TIME [epoch: 8.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04976713116996915		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.04976713116996915 | validation: 0.04664932923867364]
	TIME [epoch: 8.31 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04436527844218679		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.04436527844218679 | validation: 0.028512697866052497]
	TIME [epoch: 8.31 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04982726968717317		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.04982726968717317 | validation: 0.04500285153382063]
	TIME [epoch: 8.33 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041338320459789295		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.041338320459789295 | validation: 0.04331467310746154]
	TIME [epoch: 8.31 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04313014509009031		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.04313014509009031 | validation: 0.09058377716370165]
	TIME [epoch: 8.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053913183019585996		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.053913183019585996 | validation: 0.03718044358479526]
	TIME [epoch: 8.31 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027632876813246887		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.027632876813246887 | validation: 0.05682194149769801]
	TIME [epoch: 8.33 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04875991232127784		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.04875991232127784 | validation: 0.03596493493133173]
	TIME [epoch: 8.31 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05104904353384976		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.05104904353384976 | validation: 0.035165321452229746]
	TIME [epoch: 8.31 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0362922176787389		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.0362922176787389 | validation: 0.04484273813710997]
	TIME [epoch: 8.32 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03279371328657669		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.03279371328657669 | validation: 0.07441315750509245]
	TIME [epoch: 8.33 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059153610350496946		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.059153610350496946 | validation: 0.04352823220573654]
	TIME [epoch: 8.32 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03920563518838409		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.03920563518838409 | validation: 0.030590500125718782]
	TIME [epoch: 8.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04670857209617969		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.04670857209617969 | validation: 0.06015728372714757]
	TIME [epoch: 8.31 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03454642864646696		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.03454642864646696 | validation: 0.03637486825751909]
	TIME [epoch: 8.33 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05721940352080279		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.05721940352080279 | validation: 0.04965293370633245]
	TIME [epoch: 8.31 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0414794199019091		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.0414794199019091 | validation: 0.03408939328612087]
	TIME [epoch: 8.31 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03281491948049795		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.03281491948049795 | validation: 0.033593529311798424]
	TIME [epoch: 8.31 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04153177721456329		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.04153177721456329 | validation: 0.04022075066110984]
	TIME [epoch: 8.32 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034645361793259125		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.034645361793259125 | validation: 0.028899838024392863]
	TIME [epoch: 8.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03284511014584657		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.03284511014584657 | validation: 0.04439088871031115]
	TIME [epoch: 8.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03543950662235609		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.03543950662235609 | validation: 0.04099441267918286]
	TIME [epoch: 8.3 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04108803874841423		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.04108803874841423 | validation: 0.029769693772761494]
	TIME [epoch: 8.32 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03843242188551877		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.03843242188551877 | validation: 0.03304521866340901]
	TIME [epoch: 8.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03187671874983621		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.03187671874983621 | validation: 0.05517795564844398]
	TIME [epoch: 8.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035550236961855185		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.035550236961855185 | validation: 0.04766152301120809]
	TIME [epoch: 8.32 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03962062646975011		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.03962062646975011 | validation: 0.05339949337319594]
	TIME [epoch: 8.33 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03251835150404334		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.03251835150404334 | validation: 0.050690305347617495]
	TIME [epoch: 8.31 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04663387893674412		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.04663387893674412 | validation: 0.03675203494107094]
	TIME [epoch: 8.32 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04790335249098787		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.04790335249098787 | validation: 0.07076506166008574]
	TIME [epoch: 8.31 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0453463819024743		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.0453463819024743 | validation: 0.032063949407241665]
	TIME [epoch: 8.33 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036835791242897785		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.036835791242897785 | validation: 0.03467982867523632]
	TIME [epoch: 8.31 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03654487267395029		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.03654487267395029 | validation: 0.038859873678314866]
	TIME [epoch: 8.31 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03326268904726622		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.03326268904726622 | validation: 0.036362019007907226]
	TIME [epoch: 8.32 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0351747660237788		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.0351747660237788 | validation: 0.06679041929923316]
	TIME [epoch: 8.33 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052974946510705334		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.052974946510705334 | validation: 0.03912602080664988]
	TIME [epoch: 8.31 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034613110289942815		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.034613110289942815 | validation: 0.043049241046870926]
	TIME [epoch: 8.31 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041896622343810135		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.041896622343810135 | validation: 0.038441064145285725]
	TIME [epoch: 8.32 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0329143777275943		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.0329143777275943 | validation: 0.03916546462734015]
	TIME [epoch: 8.32 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032192534806642026		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.032192534806642026 | validation: 0.039808356841716845]
	TIME [epoch: 8.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052211615558042865		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.052211615558042865 | validation: 0.040977143001376726]
	TIME [epoch: 8.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03161985198769397		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.03161985198769397 | validation: 0.042519963141651185]
	TIME [epoch: 8.32 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03608752119371058		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.03608752119371058 | validation: 0.05346786785450694]
	TIME [epoch: 8.31 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04341673650150902		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.04341673650150902 | validation: 0.059419081516838765]
	TIME [epoch: 8.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043808094219669844		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.043808094219669844 | validation: 0.04903568071980126]
	TIME [epoch: 8.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036919858652649594		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.036919858652649594 | validation: 0.03927583482381834]
	TIME [epoch: 8.31 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03506188310518227		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.03506188310518227 | validation: 0.028420229818394798]
	TIME [epoch: 8.31 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034665533683848074		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.034665533683848074 | validation: 0.05345598954756034]
	TIME [epoch: 8.3 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044332055163500604		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.044332055163500604 | validation: 0.04463682950465319]
	TIME [epoch: 8.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035911594181952264		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.035911594181952264 | validation: 0.0381259805895794]
	TIME [epoch: 8.31 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03732457613308169		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.03732457613308169 | validation: 0.056847909715864516]
	TIME [epoch: 8.31 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03717041989093228		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.03717041989093228 | validation: 0.038128528892467435]
	TIME [epoch: 8.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03210728574133151		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.03210728574133151 | validation: 0.027638246729852052]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1344.pth
	Model improved!!!
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03635367488802134		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.03635367488802134 | validation: 0.03498195778511341]
	TIME [epoch: 8.32 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04781213959517948		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.04781213959517948 | validation: 0.03520264965951608]
	TIME [epoch: 8.31 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04026539186386623		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.04026539186386623 | validation: 0.050308551309078006]
	TIME [epoch: 8.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04577671189894789		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.04577671189894789 | validation: 0.057272460168598896]
	TIME [epoch: 8.3 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03169776691448678		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.03169776691448678 | validation: 0.049379482391025506]
	TIME [epoch: 8.31 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0508193457783195		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.0508193457783195 | validation: 0.0727993508400942]
	TIME [epoch: 8.31 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04912128305672329		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.04912128305672329 | validation: 0.050879745688339244]
	TIME [epoch: 8.3 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03712391524549442		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.03712391524549442 | validation: 0.040781515208803895]
	TIME [epoch: 8.31 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02666459230355948		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.02666459230355948 | validation: 0.049902196238103554]
	TIME [epoch: 8.31 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0570163733957884		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.0570163733957884 | validation: 0.04092869166607409]
	TIME [epoch: 8.31 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033906376933470185		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.033906376933470185 | validation: 0.04825914508431795]
	TIME [epoch: 8.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04287468135001902		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.04287468135001902 | validation: 0.06593302170659461]
	TIME [epoch: 8.31 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05407587076213568		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.05407587076213568 | validation: 0.05858177031915748]
	TIME [epoch: 8.32 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037508903775820286		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.037508903775820286 | validation: 0.05914030503313118]
	TIME [epoch: 8.31 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04817228367186238		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.04817228367186238 | validation: 0.05085766841205243]
	TIME [epoch: 8.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05243836869518137		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.05243836869518137 | validation: 0.046287029329179774]
	TIME [epoch: 8.3 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04850442023856509		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.04850442023856509 | validation: 0.057989729834123496]
	TIME [epoch: 8.32 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0382177057708748		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.0382177057708748 | validation: 0.04133463062934915]
	TIME [epoch: 8.31 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03508518114620998		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.03508518114620998 | validation: 0.05423074427656959]
	TIME [epoch: 8.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031412884413312234		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.031412884413312234 | validation: 0.043725521824981246]
	TIME [epoch: 8.31 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040902028761873044		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.040902028761873044 | validation: 0.03951626943846733]
	TIME [epoch: 8.32 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03878164042493322		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.03878164042493322 | validation: 0.03315588200636888]
	TIME [epoch: 8.31 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02749776885673021		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.02749776885673021 | validation: 0.03612095524073075]
	TIME [epoch: 8.31 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03301474615165068		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.03301474615165068 | validation: 0.06376066001865142]
	TIME [epoch: 8.3 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03802833136683528		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.03802833136683528 | validation: 0.035782178063606576]
	TIME [epoch: 8.32 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02946480417336551		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.02946480417336551 | validation: 0.04794945401430611]
	TIME [epoch: 8.31 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04577212948970112		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.04577212948970112 | validation: 0.055873932417500285]
	TIME [epoch: 8.3 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03970482275297489		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.03970482275297489 | validation: 0.03158810037795301]
	TIME [epoch: 8.31 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025314633475100472		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.025314633475100472 | validation: 0.044931044304464894]
	TIME [epoch: 8.32 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03004258154529969		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.03004258154529969 | validation: 0.035732651378906646]
	TIME [epoch: 8.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03428594009340971		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.03428594009340971 | validation: 0.04586653904034914]
	TIME [epoch: 8.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031418869686300505		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.031418869686300505 | validation: 0.03254893196274433]
	TIME [epoch: 8.3 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027127998548619796		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.027127998548619796 | validation: 0.052837727228482206]
	TIME [epoch: 8.32 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038614160754204555		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.038614160754204555 | validation: 0.0377246368645707]
	TIME [epoch: 8.31 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047034439222536674		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.047034439222536674 | validation: 0.05068617102382736]
	TIME [epoch: 8.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043214974249168925		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.043214974249168925 | validation: 0.04505845776006129]
	TIME [epoch: 8.31 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02798004704736241		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.02798004704736241 | validation: 0.026648928235523856]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1381.pth
	Model improved!!!
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032911029535389755		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.032911029535389755 | validation: 0.04696476951679471]
	TIME [epoch: 8.32 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043502457473573446		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.043502457473573446 | validation: 0.04777889801324353]
	TIME [epoch: 8.31 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04313143086305076		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.04313143086305076 | validation: 0.05966066904103373]
	TIME [epoch: 8.3 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03269019017626303		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.03269019017626303 | validation: 0.03390434952362681]
	TIME [epoch: 8.32 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030497734416880373		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.030497734416880373 | validation: 0.033870277696057244]
	TIME [epoch: 8.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03317414545700411		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.03317414545700411 | validation: 0.035522212691726306]
	TIME [epoch: 8.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030478818838468407		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.030478818838468407 | validation: 0.02511541841709986]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1388.pth
	Model improved!!!
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03095324943298245		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.03095324943298245 | validation: 0.03488145681859592]
	TIME [epoch: 8.32 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0821833114070659		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.0821833114070659 | validation: 0.043875688660403575]
	TIME [epoch: 8.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04508826060136355		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.04508826060136355 | validation: 0.04850717176591023]
	TIME [epoch: 8.29 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03510044785768632		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.03510044785768632 | validation: 0.03544997182056109]
	TIME [epoch: 8.29 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03276897545247769		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.03276897545247769 | validation: 0.042197216214923096]
	TIME [epoch: 8.32 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0275082981419221		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.0275082981419221 | validation: 0.04222862303670685]
	TIME [epoch: 8.31 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03282748620288056		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.03282748620288056 | validation: 0.03986194467171254]
	TIME [epoch: 8.31 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02631262539595624		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.02631262539595624 | validation: 0.04402529483292547]
	TIME [epoch: 8.3 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034117067777639114		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.034117067777639114 | validation: 0.04247238381922628]
	TIME [epoch: 8.33 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035795285696901255		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.035795285696901255 | validation: 0.048781423731716754]
	TIME [epoch: 8.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03888368486915987		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.03888368486915987 | validation: 0.05437226628984656]
	TIME [epoch: 8.29 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037602999259821655		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.037602999259821655 | validation: 0.03268740986347282]
	TIME [epoch: 8.29 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03447751618742515		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.03447751618742515 | validation: 0.03946915163356772]
	TIME [epoch: 8.32 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03433437118173073		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.03433437118173073 | validation: 0.04295660273851787]
	TIME [epoch: 8.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0368079786503356		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.0368079786503356 | validation: 0.03748289843143572]
	TIME [epoch: 8.29 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03686520599255911		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.03686520599255911 | validation: 0.04661178378335072]
	TIME [epoch: 8.29 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050372135579300995		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.050372135579300995 | validation: 0.06074746659310107]
	TIME [epoch: 8.32 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03578031542993403		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.03578031542993403 | validation: 0.049523441790215325]
	TIME [epoch: 8.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037505317805126434		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.037505317805126434 | validation: 0.045916287753172906]
	TIME [epoch: 8.29 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03542481499809086		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.03542481499809086 | validation: 0.034883366194103524]
	TIME [epoch: 8.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036581253053249836		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.036581253053249836 | validation: 0.05123492394077196]
	TIME [epoch: 8.32 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034441720738883894		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.034441720738883894 | validation: 0.03740480750827077]
	TIME [epoch: 8.3 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04001282350453141		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.04001282350453141 | validation: 0.04941246157053959]
	TIME [epoch: 8.3 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03993436670636119		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.03993436670636119 | validation: 0.03914424798225982]
	TIME [epoch: 8.29 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03768151505019858		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.03768151505019858 | validation: 0.059510902503787856]
	TIME [epoch: 8.32 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03584496643139203		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.03584496643139203 | validation: 0.05783997109201554]
	TIME [epoch: 8.31 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05029899092339555		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.05029899092339555 | validation: 0.030305481239848834]
	TIME [epoch: 8.29 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035725830665341136		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.035725830665341136 | validation: 0.03503478509334326]
	TIME [epoch: 8.3 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024767538861056544		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.024767538861056544 | validation: 0.03462891641775675]
	TIME [epoch: 8.31 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033252147836063894		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.033252147836063894 | validation: 0.029702929613295043]
	TIME [epoch: 8.29 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03422683562382856		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.03422683562382856 | validation: 0.04725914436721086]
	TIME [epoch: 8.29 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03586981433655497		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.03586981433655497 | validation: 0.047729759941964815]
	TIME [epoch: 8.31 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03643911060338129		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.03643911060338129 | validation: 0.051863999551815365]
	TIME [epoch: 8.33 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03928934723916234		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.03928934723916234 | validation: 0.03941588376776488]
	TIME [epoch: 8.31 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031107227347952803		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.031107227347952803 | validation: 0.03376154409825154]
	TIME [epoch: 8.3 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026829948048993496		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.026829948048993496 | validation: 0.04272864962608541]
	TIME [epoch: 8.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035699250780811674		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.035699250780811674 | validation: 0.04252126619757677]
	TIME [epoch: 8.33 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037021099134868826		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.037021099134868826 | validation: 0.05304686194455158]
	TIME [epoch: 8.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04177905739103674		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.04177905739103674 | validation: 0.03221811483160372]
	TIME [epoch: 8.31 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02746590297959294		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.02746590297959294 | validation: 0.036013627638509405]
	TIME [epoch: 8.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04113320969521455		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.04113320969521455 | validation: 0.04659269297642826]
	TIME [epoch: 8.32 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03891987767236491		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.03891987767236491 | validation: 0.038904787017361935]
	TIME [epoch: 8.29 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038586079551615235		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.038586079551615235 | validation: 0.03386252107880026]
	TIME [epoch: 8.3 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032401845658755084		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.032401845658755084 | validation: 0.028326952353008895]
	TIME [epoch: 8.31 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031520156154403914		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.031520156154403914 | validation: 0.03438225188665405]
	TIME [epoch: 8.33 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029366206959346653		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.029366206959346653 | validation: 0.0366833422290359]
	TIME [epoch: 8.3 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03129907547184925		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.03129907547184925 | validation: 0.03830667442777673]
	TIME [epoch: 8.3 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034997495836311565		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.034997495836311565 | validation: 0.0359236716022643]
	TIME [epoch: 8.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03211377193030403		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.03211377193030403 | validation: 0.048893335614065794]
	TIME [epoch: 8.32 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03747921246644216		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.03747921246644216 | validation: 0.04588656621842567]
	TIME [epoch: 8.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03238806592323154		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.03238806592323154 | validation: 0.037456447373409044]
	TIME [epoch: 8.29 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032694973431852604		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.032694973431852604 | validation: 0.044564882701406884]
	TIME [epoch: 8.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036379577061157846		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.036379577061157846 | validation: 0.031421665626742805]
	TIME [epoch: 8.31 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022862899429000202		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.022862899429000202 | validation: 0.03317424529054962]
	TIME [epoch: 8.29 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04215672981550623		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.04215672981550623 | validation: 0.05439599172898567]
	TIME [epoch: 8.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03466667478150876		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.03466667478150876 | validation: 0.047102731714683745]
	TIME [epoch: 8.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03600991842850215		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.03600991842850215 | validation: 0.0506307236967191]
	TIME [epoch: 8.33 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03934960201289547		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.03934960201289547 | validation: 0.03280976522454174]
	TIME [epoch: 8.31 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02684523933641384		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.02684523933641384 | validation: 0.04002021518406043]
	TIME [epoch: 8.31 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024433095990400215		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.024433095990400215 | validation: 0.029739873730043893]
	TIME [epoch: 8.31 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028023384772019		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.028023384772019 | validation: 0.03609026820254628]
	TIME [epoch: 8.33 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04232650976948486		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.04232650976948486 | validation: 0.04333574335334393]
	TIME [epoch: 8.31 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04498814328099306		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.04498814328099306 | validation: 0.03467870076573993]
	TIME [epoch: 8.31 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04066387233272721		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.04066387233272721 | validation: 0.034956734108113445]
	TIME [epoch: 8.31 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0323150629417775		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.0323150629417775 | validation: 0.027152717979838176]
	TIME [epoch: 8.32 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030750759510552318		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.030750759510552318 | validation: 0.03845373033179547]
	TIME [epoch: 8.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03721952073679034		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.03721952073679034 | validation: 0.05916000369593062]
	TIME [epoch: 8.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042952110235452895		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.042952110235452895 | validation: 0.06817147785653475]
	TIME [epoch: 8.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04704931768309406		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.04704931768309406 | validation: 0.03126220445994037]
	TIME [epoch: 8.32 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03543996352907111		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.03543996352907111 | validation: 0.03528280595521203]
	TIME [epoch: 8.31 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030136754445589053		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.030136754445589053 | validation: 0.03453686772507124]
	TIME [epoch: 8.29 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03184190339703287		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.03184190339703287 | validation: 0.04634013603260426]
	TIME [epoch: 8.3 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03522791555108985		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.03522791555108985 | validation: 0.0464385398306588]
	TIME [epoch: 8.32 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03692284661226826		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.03692284661226826 | validation: 0.054269952723282666]
	TIME [epoch: 8.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04652272551945964		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.04652272551945964 | validation: 0.06545405017648094]
	TIME [epoch: 8.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046047624094616234		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.046047624094616234 | validation: 0.035781789408754455]
	TIME [epoch: 8.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040474623591882225		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.040474623591882225 | validation: 0.03699705199417466]
	TIME [epoch: 8.33 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05789911622418684		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.05789911622418684 | validation: 0.0706538520506845]
	TIME [epoch: 8.3 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04069296492143448		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.04069296492143448 | validation: 0.04174953573441714]
	TIME [epoch: 8.3 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03800401930490751		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.03800401930490751 | validation: 0.03939877796509253]
	TIME [epoch: 8.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03639906242858339		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.03639906242858339 | validation: 0.03962734408428312]
	TIME [epoch: 8.31 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020676649953881156		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.020676649953881156 | validation: 0.02929291979074674]
	TIME [epoch: 8.29 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02815961682771669		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.02815961682771669 | validation: 0.03081568688018328]
	TIME [epoch: 8.31 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0351167666660247		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.0351167666660247 | validation: 0.04488996130538688]
	TIME [epoch: 8.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03644344413954118		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.03644344413954118 | validation: 0.04752786039856443]
	TIME [epoch: 8.33 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024486988510674292		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.024486988510674292 | validation: 0.029623930355115267]
	TIME [epoch: 8.31 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04144135216524565		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.04144135216524565 | validation: 0.04166477874896626]
	TIME [epoch: 8.3 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03556352296156179		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.03556352296156179 | validation: 0.04510106975340904]
	TIME [epoch: 8.31 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032279142754238245		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.032279142754238245 | validation: 0.03852306874901508]
	TIME [epoch: 8.32 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030654993702348466		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.030654993702348466 | validation: 0.037243190773949095]
	TIME [epoch: 8.3 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02939663260266432		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.02939663260266432 | validation: 0.03400334969408912]
	TIME [epoch: 8.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036805639548357805		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.036805639548357805 | validation: 0.024580550284466682]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1480.pth
	Model improved!!!
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0313381444306692		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.0313381444306692 | validation: 0.0386127731662609]
	TIME [epoch: 8.32 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03333331213170966		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.03333331213170966 | validation: 0.030111322985298006]
	TIME [epoch: 8.3 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027269300698298526		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.027269300698298526 | validation: 0.037969490005500164]
	TIME [epoch: 8.29 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029265558466105752		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.029265558466105752 | validation: 0.04538668323449586]
	TIME [epoch: 8.3 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02827648693320418		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.02827648693320418 | validation: 0.037445421904191985]
	TIME [epoch: 8.31 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03157218741005212		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.03157218741005212 | validation: 0.03164816898686664]
	TIME [epoch: 8.29 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03190123634666384		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.03190123634666384 | validation: 0.030529888702692166]
	TIME [epoch: 8.3 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031444737680280055		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.031444737680280055 | validation: 0.039748125774206125]
	TIME [epoch: 8.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03301700058034081		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.03301700058034081 | validation: 0.04559583056643347]
	TIME [epoch: 8.31 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02967733656915253		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.02967733656915253 | validation: 0.028962350529428582]
	TIME [epoch: 8.3 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033549736527138094		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.033549736527138094 | validation: 0.043084840070557476]
	TIME [epoch: 8.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03715290364000466		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.03715290364000466 | validation: 0.025920241168338833]
	TIME [epoch: 8.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021931497253063537		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.021931497253063537 | validation: 0.03228432221253652]
	TIME [epoch: 8.31 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03035822384958145		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.03035822384958145 | validation: 0.04818870825900591]
	TIME [epoch: 8.3 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02839768724330876		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.02839768724330876 | validation: 0.03591949616309379]
	TIME [epoch: 8.29 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036533128188729044		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.036533128188729044 | validation: 0.03304364590410058]
	TIME [epoch: 8.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031568879195831005		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.031568879195831005 | validation: 0.03324181532451451]
	TIME [epoch: 8.32 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02804659763097684		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.02804659763097684 | validation: 0.06800384122844838]
	TIME [epoch: 8.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04735251590370776		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.04735251590370776 | validation: 0.07086074768635034]
	TIME [epoch: 8.29 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031918433061973714		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.031918433061973714 | validation: 0.032520798297761486]
	TIME [epoch: 8.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033794589513984494		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.033794589513984494 | validation: 0.032585815074877914]
	TIME [epoch: 8.31 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023232898722933937		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.023232898722933937 | validation: 0.034325038503763325]
	TIME [epoch: 8.29 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024472851088797182		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.024472851088797182 | validation: 0.036883019111302165]
	TIME [epoch: 8.29 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027948364695852056		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.027948364695852056 | validation: 0.029536220542342534]
	TIME [epoch: 8.3 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03531889484866201		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.03531889484866201 | validation: 0.041093639176677396]
	TIME [epoch: 8.31 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03705870344570138		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.03705870344570138 | validation: 0.041253818939027194]
	TIME [epoch: 8.3 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02874584084698577		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.02874584084698577 | validation: 0.02834807536183883]
	TIME [epoch: 8.29 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02903939067204716		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.02903939067204716 | validation: 0.04236060433159293]
	TIME [epoch: 8.31 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033318793102636		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.033318793102636 | validation: 0.049504069145808155]
	TIME [epoch: 8.32 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041656918180195346		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.041656918180195346 | validation: 0.023925716213501272]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1510.pth
	Model improved!!!
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032600429981615435		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.032600429981615435 | validation: 0.046436653918828764]
	TIME [epoch: 8.3 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058558566530593784		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.058558566530593784 | validation: 0.04992258803847415]
	TIME [epoch: 8.31 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0509694173513338		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.0509694173513338 | validation: 0.05279306672481621]
	TIME [epoch: 8.31 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04207144660304111		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.04207144660304111 | validation: 0.03833093994041445]
	TIME [epoch: 8.3 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03250487519661717		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.03250487519661717 | validation: 0.04211600540724122]
	TIME [epoch: 8.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033120457567702453		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.033120457567702453 | validation: 0.05157996571467201]
	TIME [epoch: 8.31 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038763120288757565		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.038763120288757565 | validation: 0.03825513606148824]
	TIME [epoch: 8.31 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049531210321348794		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.049531210321348794 | validation: 0.038993446489238845]
	TIME [epoch: 8.3 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028513325911920313		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.028513325911920313 | validation: 0.029627949647544713]
	TIME [epoch: 8.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024781051494797708		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.024781051494797708 | validation: 0.025638520600439422]
	TIME [epoch: 8.31 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026039169417996284		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.026039169417996284 | validation: 0.03295688718985871]
	TIME [epoch: 8.32 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04263257175171755		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.04263257175171755 | validation: 0.038825809335948175]
	TIME [epoch: 8.3 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030528351090444876		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.030528351090444876 | validation: 0.03778480050204937]
	TIME [epoch: 8.29 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04174398589242337		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.04174398589242337 | validation: 0.06564747660668378]
	TIME [epoch: 8.32 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046397470836341034		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.046397470836341034 | validation: 0.02880307453207931]
	TIME [epoch: 8.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028622897557192727		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.028622897557192727 | validation: 0.03957704505891303]
	TIME [epoch: 8.29 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028811922801176438		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.028811922801176438 | validation: 0.042182971149436886]
	TIME [epoch: 8.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033448173999997194		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.033448173999997194 | validation: 0.053590939612012244]
	TIME [epoch: 8.32 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03785582797621048		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.03785582797621048 | validation: 0.029636094534009453]
	TIME [epoch: 8.31 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030455457694369015		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.030455457694369015 | validation: 0.03415116021947709]
	TIME [epoch: 8.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03141082950558007		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.03141082950558007 | validation: 0.040793231327469565]
	TIME [epoch: 8.3 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03555936763403057		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.03555936763403057 | validation: 0.050535045886144214]
	TIME [epoch: 8.32 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03445574294102155		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.03445574294102155 | validation: 0.03489952054843164]
	TIME [epoch: 8.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03072931043858797		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.03072931043858797 | validation: 0.030376975373106734]
	TIME [epoch: 8.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0363195720639137		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.0363195720639137 | validation: 0.041131938610669425]
	TIME [epoch: 8.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02889756636676452		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.02889756636676452 | validation: 0.026513339369231392]
	TIME [epoch: 8.31 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02488722744788636		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.02488722744788636 | validation: 0.02957514516081951]
	TIME [epoch: 8.31 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04025132392444545		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.04025132392444545 | validation: 0.048195040430470105]
	TIME [epoch: 8.29 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02714922908575506		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.02714922908575506 | validation: 0.03109257694776001]
	TIME [epoch: 8.3 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031135713419071436		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.031135713419071436 | validation: 0.04205778612605257]
	TIME [epoch: 8.31 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030163309386536784		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.030163309386536784 | validation: 0.026205791491281515]
	TIME [epoch: 8.31 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024588730114852533		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.024588730114852533 | validation: 0.03546606017032785]
	TIME [epoch: 8.3 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048731858943732685		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.048731858943732685 | validation: 0.029577574426207186]
	TIME [epoch: 8.29 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027758068951869847		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.027758068951869847 | validation: 0.05296697695247433]
	TIME [epoch: 8.31 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029223760167185697		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.029223760167185697 | validation: 0.03801959136688946]
	TIME [epoch: 8.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0279994855328225		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.0279994855328225 | validation: 0.05169718407509169]
	TIME [epoch: 8.29 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03478879271714762		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.03478879271714762 | validation: 0.03384229727332931]
	TIME [epoch: 8.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027154763241603125		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.027154763241603125 | validation: 0.034526350318357754]
	TIME [epoch: 8.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024438319838111986		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.024438319838111986 | validation: 0.03283708377572322]
	TIME [epoch: 8.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030761910533602776		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.030761910533602776 | validation: 0.047971506570188546]
	TIME [epoch: 8.3 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02697656775964411		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.02697656775964411 | validation: 0.05838790375520529]
	TIME [epoch: 8.29 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03567575425096708		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.03567575425096708 | validation: 0.046273446499876]
	TIME [epoch: 8.32 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03358142953059216		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.03358142953059216 | validation: 0.04160781384489121]
	TIME [epoch: 8.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0414610957723336		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.0414610957723336 | validation: 0.03239238245917633]
	TIME [epoch: 8.29 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02774759096065496		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.02774759096065496 | validation: 0.04593301328308551]
	TIME [epoch: 8.29 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029063747002743816		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.029063747002743816 | validation: 0.026824223772472913]
	TIME [epoch: 8.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028199982201394497		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.028199982201394497 | validation: 0.052629695741742144]
	TIME [epoch: 8.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027726990319158446		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.027726990319158446 | validation: 0.025941585041081388]
	TIME [epoch: 8.29 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030436210071135793		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.030436210071135793 | validation: 0.051890982299629976]
	TIME [epoch: 8.29 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05714400976802382		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.05714400976802382 | validation: 0.03828239125109573]
	TIME [epoch: 8.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028889079828476032		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.028889079828476032 | validation: 0.03641523385352552]
	TIME [epoch: 8.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03095611446309767		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.03095611446309767 | validation: 0.03585537524738785]
	TIME [epoch: 8.3 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029873116577011943		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.029873116577011943 | validation: 0.0375874436147869]
	TIME [epoch: 8.29 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029365464366033694		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.029365464366033694 | validation: 0.04064262074072679]
	TIME [epoch: 8.31 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029785278362843903		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.029785278362843903 | validation: 0.03858373415581533]
	TIME [epoch: 8.31 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026330584842215232		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.026330584842215232 | validation: 0.040935657395510694]
	TIME [epoch: 8.29 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029753328160416658		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.029753328160416658 | validation: 0.03565076921168546]
	TIME [epoch: 8.29 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04312202552512786		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.04312202552512786 | validation: 0.027824421062419474]
	TIME [epoch: 8.32 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021984948782907757		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.021984948782907757 | validation: 0.033056117607661986]
	TIME [epoch: 8.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034113813091199915		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.034113813091199915 | validation: 0.03453805726779098]
	TIME [epoch: 8.29 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026989186777454804		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.026989186777454804 | validation: 0.0465291356328649]
	TIME [epoch: 8.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02981332993983029		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.02981332993983029 | validation: 0.03070331367580261]
	TIME [epoch: 8.31 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02004439792717915		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.02004439792717915 | validation: 0.0232528743314337]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1573.pth
	Model improved!!!
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02768684214166021		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.02768684214166021 | validation: 0.04926284850360585]
	TIME [epoch: 8.31 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02421358809906083		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.02421358809906083 | validation: 0.03955480558806682]
	TIME [epoch: 8.31 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02402811025545555		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.02402811025545555 | validation: 0.0292613338705974]
	TIME [epoch: 8.33 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027966054060564693		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.027966054060564693 | validation: 0.050652257179522236]
	TIME [epoch: 8.31 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026121054187032654		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.026121054187032654 | validation: 0.022317543656663427]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1578.pth
	Model improved!!!
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021842606640197975		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.021842606640197975 | validation: 0.035711706165316805]
	TIME [epoch: 8.31 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024883675295365004		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.024883675295365004 | validation: 0.03765151285533914]
	TIME [epoch: 8.33 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033779663056418836		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.033779663056418836 | validation: 0.06287195226785822]
	TIME [epoch: 8.31 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04521340092122679		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.04521340092122679 | validation: 0.03687467293621159]
	TIME [epoch: 8.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03038570740862797		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.03038570740862797 | validation: 0.03692356013169804]
	TIME [epoch: 8.31 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035189346776308944		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.035189346776308944 | validation: 0.051794711758563816]
	TIME [epoch: 8.33 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038536515307682775		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.038536515307682775 | validation: 0.06025413392680097]
	TIME [epoch: 8.31 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03163094218872719		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.03163094218872719 | validation: 0.03166682726627355]
	TIME [epoch: 8.31 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02570597287935238		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.02570597287935238 | validation: 0.03709154633260986]
	TIME [epoch: 8.31 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027605018026209384		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.027605018026209384 | validation: 0.033666509161708935]
	TIME [epoch: 8.33 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031642033917422006		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.031642033917422006 | validation: 0.03608447627661994]
	TIME [epoch: 8.31 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03260343355322701		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.03260343355322701 | validation: 0.03267691038494367]
	TIME [epoch: 8.31 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02875561375115786		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.02875561375115786 | validation: 0.03911056021601468]
	TIME [epoch: 8.31 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04726167138373844		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.04726167138373844 | validation: 0.05633901638249791]
	TIME [epoch: 8.33 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04129259304779338		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.04129259304779338 | validation: 0.03369653006053113]
	TIME [epoch: 8.31 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027970461806280895		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.027970461806280895 | validation: 0.03748009362571218]
	TIME [epoch: 8.31 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02318505528150826		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.02318505528150826 | validation: 0.043434283315877883]
	TIME [epoch: 8.3 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027646910892193705		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.027646910892193705 | validation: 0.03140002381633007]
	TIME [epoch: 8.33 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026906561365109716		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.026906561365109716 | validation: 0.042475750785153366]
	TIME [epoch: 8.31 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03458269656001031		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.03458269656001031 | validation: 0.029293306931078074]
	TIME [epoch: 8.32 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02334556964765284		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.02334556964765284 | validation: 0.02896654419008393]
	TIME [epoch: 8.31 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02850494989463797		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.02850494989463797 | validation: 0.035300190335586734]
	TIME [epoch: 8.33 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032329946718459346		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.032329946718459346 | validation: 0.04941063670217573]
	TIME [epoch: 8.31 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023544360504101036		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.023544360504101036 | validation: 0.02605779898896609]
	TIME [epoch: 8.31 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02610599799306772		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.02610599799306772 | validation: 0.03857464049507507]
	TIME [epoch: 8.31 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025360980636612525		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.025360980636612525 | validation: 0.028585762733193104]
	TIME [epoch: 8.33 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04172353798090186		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.04172353798090186 | validation: 0.03335480480160356]
	TIME [epoch: 8.31 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022463881599820244		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.022463881599820244 | validation: 0.033318914618076075]
	TIME [epoch: 8.31 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024464445965595022		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.024464445965595022 | validation: 0.04701601604405453]
	TIME [epoch: 8.31 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03255789752545836		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.03255789752545836 | validation: 0.03411915584082513]
	TIME [epoch: 8.33 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03779222707883392		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.03779222707883392 | validation: 0.028916462085241585]
	TIME [epoch: 8.31 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02287471045004056		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.02287471045004056 | validation: 0.03557983392018557]
	TIME [epoch: 8.31 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02644781763248808		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.02644781763248808 | validation: 0.044555955955955864]
	TIME [epoch: 8.31 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026782617451410327		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.026782617451410327 | validation: 0.031074946042653324]
	TIME [epoch: 8.33 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04066821479906921		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.04066821479906921 | validation: 0.056935262005859494]
	TIME [epoch: 8.31 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03676638193699612		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.03676638193699612 | validation: 0.03221315168921364]
	TIME [epoch: 8.31 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03719339516245816		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.03719339516245816 | validation: 0.039657332490310504]
	TIME [epoch: 8.31 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02756453299190102		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.02756453299190102 | validation: 0.02672827003586528]
	TIME [epoch: 8.33 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0250224994853932		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.0250224994853932 | validation: 0.03256937217755373]
	TIME [epoch: 8.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019207878017272764		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.019207878017272764 | validation: 0.039843924779550816]
	TIME [epoch: 8.31 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029405313643173697		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.029405313643173697 | validation: 0.0362109609182405]
	TIME [epoch: 8.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027626119709430803		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.027626119709430803 | validation: 0.04043144835872007]
	TIME [epoch: 8.33 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026121287563122403		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.026121287563122403 | validation: 0.03804048121051398]
	TIME [epoch: 8.31 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03430234098536579		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.03430234098536579 | validation: 0.05902968054244073]
	TIME [epoch: 8.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024153517373110573		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.024153517373110573 | validation: 0.02837293239390218]
	TIME [epoch: 8.31 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023503832634303203		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.023503832634303203 | validation: 0.02341439112296287]
	TIME [epoch: 8.33 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0360117232711644		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.0360117232711644 | validation: 0.06825213759897253]
	TIME [epoch: 8.31 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027004739569754334		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.027004739569754334 | validation: 0.03450680969412078]
	TIME [epoch: 8.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025758260765506708		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.025758260765506708 | validation: 0.039379486150471446]
	TIME [epoch: 8.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02702751754540229		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.02702751754540229 | validation: 0.041601822692268114]
	TIME [epoch: 8.33 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02847392484867804		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.02847392484867804 | validation: 0.03464229435793756]
	TIME [epoch: 8.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023739512029408414		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.023739512029408414 | validation: 0.0335765361386115]
	TIME [epoch: 8.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025736218687619633		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.025736218687619633 | validation: 0.04689252521180391]
	TIME [epoch: 8.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03686641766911901		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.03686641766911901 | validation: 0.04702708168194743]
	TIME [epoch: 8.33 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035608928952140614		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.035608928952140614 | validation: 0.03672758141445464]
	TIME [epoch: 8.3 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031745285472858834		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.031745285472858834 | validation: 0.041139421078850366]
	TIME [epoch: 8.3 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033931266944202364		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.033931266944202364 | validation: 0.0372759069661768]
	TIME [epoch: 8.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03144215101909607		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.03144215101909607 | validation: 0.048669457562238894]
	TIME [epoch: 8.33 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03568996303267322		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.03568996303267322 | validation: 0.03552281223012076]
	TIME [epoch: 8.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02799582086019674		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.02799582086019674 | validation: 0.026329462175951224]
	TIME [epoch: 8.3 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02846130644080097		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.02846130644080097 | validation: 0.031004150719327307]
	TIME [epoch: 8.3 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029756379229651454		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.029756379229651454 | validation: 0.046302537560221506]
	TIME [epoch: 8.33 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03524123609678061		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.03524123609678061 | validation: 0.0348855694077424]
	TIME [epoch: 8.31 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021237724316672386		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.021237724316672386 | validation: 0.027879648559609848]
	TIME [epoch: 8.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031819841667953534		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.031819841667953534 | validation: 0.04046168958702622]
	TIME [epoch: 8.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0386548252288112		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.0386548252288112 | validation: 0.04182863234860894]
	TIME [epoch: 8.33 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03039840322252011		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.03039840322252011 | validation: 0.042113398028841474]
	TIME [epoch: 8.3 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026145638511387022		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.026145638511387022 | validation: 0.026842142638650642]
	TIME [epoch: 8.3 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027701298134621695		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.027701298134621695 | validation: 0.03916794769122463]
	TIME [epoch: 8.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031554796512868744		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.031554796512868744 | validation: 0.03393403369493599]
	TIME [epoch: 8.33 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0323810886993403		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.0323810886993403 | validation: 0.03137981861222432]
	TIME [epoch: 8.3 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0270107535130934		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.0270107535130934 | validation: 0.040995811872212386]
	TIME [epoch: 8.3 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02469399020212606		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.02469399020212606 | validation: 0.03337108791067135]
	TIME [epoch: 8.3 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025528425292421546		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.025528425292421546 | validation: 0.020741594802480334]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1652.pth
	Model improved!!!
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02651863094899428		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.02651863094899428 | validation: 0.0281116333412125]
	TIME [epoch: 8.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026042400066163846		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.026042400066163846 | validation: 0.03362642208956303]
	TIME [epoch: 8.3 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03837866238000442		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.03837866238000442 | validation: 0.03472053237753326]
	TIME [epoch: 8.31 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025468450676177264		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.025468450676177264 | validation: 0.0336666939711736]
	TIME [epoch: 8.32 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038832174156120884		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.038832174156120884 | validation: 0.032238938332631556]
	TIME [epoch: 8.31 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020258207001536292		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.020258207001536292 | validation: 0.03184305638375577]
	TIME [epoch: 8.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03252116489956191		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.03252116489956191 | validation: 0.048723384464742184]
	TIME [epoch: 8.31 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03398550803210178		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.03398550803210178 | validation: 0.03793355583447781]
	TIME [epoch: 8.32 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02862660516336533		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.02862660516336533 | validation: 0.03756904983232322]
	TIME [epoch: 8.31 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02598283658249454		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.02598283658249454 | validation: 0.04161613206135438]
	TIME [epoch: 8.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03087424020967733		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.03087424020967733 | validation: 0.027909325728838627]
	TIME [epoch: 8.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03942340672474902		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.03942340672474902 | validation: 0.038436449853308824]
	TIME [epoch: 8.32 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03384761421690067		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.03384761421690067 | validation: 0.03236773124101787]
	TIME [epoch: 8.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030232799993454396		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.030232799993454396 | validation: 0.032790072962422694]
	TIME [epoch: 8.31 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02678068096936647		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.02678068096936647 | validation: 0.03743683621246551]
	TIME [epoch: 8.3 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02174614657398104		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.02174614657398104 | validation: 0.037739182857613]
	TIME [epoch: 8.32 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030745862741374003		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.030745862741374003 | validation: 0.032813174816447674]
	TIME [epoch: 8.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032551999386940235		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.032551999386940235 | validation: 0.039070988977196436]
	TIME [epoch: 8.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030249324672717515		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.030249324672717515 | validation: 0.032717892362297]
	TIME [epoch: 8.31 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019020438151049767		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.019020438151049767 | validation: 0.03330500995992749]
	TIME [epoch: 8.33 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022524488594013136		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.022524488594013136 | validation: 0.03141805091369024]
	TIME [epoch: 8.3 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02632928109464961		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.02632928109464961 | validation: 0.025288501793984727]
	TIME [epoch: 8.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025512656208144285		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.025512656208144285 | validation: 0.024186877519711825]
	TIME [epoch: 8.31 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03076147444141427		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.03076147444141427 | validation: 0.031040320761941638]
	TIME [epoch: 8.31 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019520535670069596		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.019520535670069596 | validation: 0.033799840590909985]
	TIME [epoch: 8.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02704950799786312		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.02704950799786312 | validation: 0.025948013177193537]
	TIME [epoch: 8.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021169901797175445		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.021169901797175445 | validation: 0.03174212465821498]
	TIME [epoch: 8.32 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030975530742732682		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.030975530742732682 | validation: 0.03575463076531311]
	TIME [epoch: 8.31 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028114247379270273		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.028114247379270273 | validation: 0.018392821511316364]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1681.pth
	Model improved!!!
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021739659997459887		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.021739659997459887 | validation: 0.03149744729398656]
	TIME [epoch: 8.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027004076714277164		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.027004076714277164 | validation: 0.027343872299197873]
	TIME [epoch: 8.31 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0249869242975019		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.0249869242975019 | validation: 0.03174347281339755]
	TIME [epoch: 8.31 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02465197149408264		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.02465197149408264 | validation: 0.03645145555158184]
	TIME [epoch: 8.3 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032306004476030686		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.032306004476030686 | validation: 0.037242551766373706]
	TIME [epoch: 8.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026262128557228964		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.026262128557228964 | validation: 0.036935659508691945]
	TIME [epoch: 8.31 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03100569172010057		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.03100569172010057 | validation: 0.026631599630438027]
	TIME [epoch: 8.31 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02542505153591303		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.02542505153591303 | validation: 0.04698778528216534]
	TIME [epoch: 8.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027556074027391873		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.027556074027391873 | validation: 0.02492928250089773]
	TIME [epoch: 8.3 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03363541857886513		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.03363541857886513 | validation: 0.030962232550978717]
	TIME [epoch: 8.31 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041560317152323875		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.041560317152323875 | validation: 0.04341377237175128]
	TIME [epoch: 8.31 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024554941236301513		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.024554941236301513 | validation: 0.03508263143642887]
	TIME [epoch: 8.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029897189813099127		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.029897189813099127 | validation: 0.02411969469362503]
	TIME [epoch: 8.3 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02701220728735836		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.02701220728735836 | validation: 0.03062562010540629]
	TIME [epoch: 8.31 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0210332062122188		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.0210332062122188 | validation: 0.04045472452474236]
	TIME [epoch: 8.31 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02921869721779599		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.02921869721779599 | validation: 0.0411796756777591]
	TIME [epoch: 8.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025748576231554365		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.025748576231554365 | validation: 0.02275870119249194]
	TIME [epoch: 8.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03225959293969807		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.03225959293969807 | validation: 0.04031648233002141]
	TIME [epoch: 8.31 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02643011777810207		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.02643011777810207 | validation: 0.0392339397167598]
	TIME [epoch: 8.31 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02632569880105685		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.02632569880105685 | validation: 0.02697395848528131]
	TIME [epoch: 8.29 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028986091426166122		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.028986091426166122 | validation: 0.04019562666540229]
	TIME [epoch: 8.29 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022969848922292792		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.022969848922292792 | validation: 0.0365679835796529]
	TIME [epoch: 8.31 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023504777541681624		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.023504777541681624 | validation: 0.03405549711764291]
	TIME [epoch: 8.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03345653457322621		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.03345653457322621 | validation: 0.038924933784398597]
	TIME [epoch: 8.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025140343049245444		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.025140343049245444 | validation: 0.03944176486204011]
	TIME [epoch: 8.3 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03247672952101014		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.03247672952101014 | validation: 0.022938071285770724]
	TIME [epoch: 8.31 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029138890091593577		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.029138890091593577 | validation: 0.02697937322799412]
	TIME [epoch: 8.3 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02290232891062659		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.02290232891062659 | validation: 0.02696647291815642]
	TIME [epoch: 8.3 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02010792368957324		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.02010792368957324 | validation: 0.027445289958059522]
	TIME [epoch: 8.29 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02904500607485235		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.02904500607485235 | validation: 0.027215385400107518]
	TIME [epoch: 8.31 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027866270538931086		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.027866270538931086 | validation: 0.023040282169192496]
	TIME [epoch: 8.3 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02787008467786114		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.02787008467786114 | validation: 0.04073480300602183]
	TIME [epoch: 8.29 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026057411307732294		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.026057411307732294 | validation: 0.03593307754031641]
	TIME [epoch: 8.29 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028472241113337134		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.028472241113337134 | validation: 0.03086447732165868]
	TIME [epoch: 8.31 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026951876154422204		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.026951876154422204 | validation: 0.03537595594428621]
	TIME [epoch: 8.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028968188620549017		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.028968188620549017 | validation: 0.027753891269596154]
	TIME [epoch: 8.29 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027955646617606144		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.027955646617606144 | validation: 0.03838321618883658]
	TIME [epoch: 8.29 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027664397219782793		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.027664397219782793 | validation: 0.02705860100928049]
	TIME [epoch: 8.31 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024079448794671793		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.024079448794671793 | validation: 0.03124627087065008]
	TIME [epoch: 8.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023784970247665287		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.023784970247665287 | validation: 0.029620934641347844]
	TIME [epoch: 8.29 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026133647347432537		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.026133647347432537 | validation: 0.03302106874724257]
	TIME [epoch: 8.29 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021087320564376132		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.021087320564376132 | validation: 0.03177777568347752]
	TIME [epoch: 8.32 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03019697256398971		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.03019697256398971 | validation: 0.03554133946359395]
	TIME [epoch: 8.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024967021461249492		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.024967021461249492 | validation: 0.035240104781096154]
	TIME [epoch: 8.29 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03775774748486928		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.03775774748486928 | validation: 0.05210118315170775]
	TIME [epoch: 8.29 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041247795054867704		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.041247795054867704 | validation: 0.028010521311643312]
	TIME [epoch: 8.31 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0294119034199296		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.0294119034199296 | validation: 0.02170014130525138]
	TIME [epoch: 8.29 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021894776316031265		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.021894776316031265 | validation: 0.023911983514652]
	TIME [epoch: 8.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02857528232208121		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.02857528232208121 | validation: 0.04697599581319187]
	TIME [epoch: 8.29 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028191796705199425		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.028191796705199425 | validation: 0.025970083122716932]
	TIME [epoch: 8.31 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022194635688400154		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.022194635688400154 | validation: 0.03563633403815141]
	TIME [epoch: 8.3 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04199949553877768		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.04199949553877768 | validation: 0.026438113278164192]
	TIME [epoch: 8.29 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026176819791351207		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.026176819791351207 | validation: 0.020172220893218403]
	TIME [epoch: 8.29 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023574465376015746		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.023574465376015746 | validation: 0.0215208219090854]
	TIME [epoch: 8.31 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023614013456416318		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.023614013456416318 | validation: 0.04320435391151374]
	TIME [epoch: 8.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02911612081007602		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.02911612081007602 | validation: 0.03743313693226623]
	TIME [epoch: 8.29 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023115045323316083		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.023115045323316083 | validation: 0.03631804867270709]
	TIME [epoch: 8.29 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0310593036050337		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.0310593036050337 | validation: 0.023842353381961598]
	TIME [epoch: 8.31 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024223783751938812		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.024223783751938812 | validation: 0.032120765485754904]
	TIME [epoch: 8.3 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0246820562015555		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.0246820562015555 | validation: 0.033048490204106384]
	TIME [epoch: 8.29 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021206488513256433		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.021206488513256433 | validation: 0.03580158428760825]
	TIME [epoch: 8.3 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03306826090633902		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.03306826090633902 | validation: 0.03080023750942945]
	TIME [epoch: 8.32 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022757899395434832		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.022757899395434832 | validation: 0.024841248813484842]
	TIME [epoch: 8.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027645157179432257		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.027645157179432257 | validation: 0.033163069218904766]
	TIME [epoch: 8.29 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03723906664370581		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.03723906664370581 | validation: 0.029338373126196825]
	TIME [epoch: 8.29 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02329366489998221		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.02329366489998221 | validation: 0.024134070452566228]
	TIME [epoch: 8.32 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033482296358828864		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.033482296358828864 | validation: 0.05151455504032601]
	TIME [epoch: 8.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03488061440349029		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.03488061440349029 | validation: 0.043562167687627634]
	TIME [epoch: 8.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030688717183021498		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.030688717183021498 | validation: 0.040997322992439196]
	TIME [epoch: 8.29 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023266599986531505		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.023266599986531505 | validation: 0.029533826884224817]
	TIME [epoch: 8.32 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026649886806132582		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.026649886806132582 | validation: 0.029207117093573376]
	TIME [epoch: 8.3 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027238360564899634		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.027238360564899634 | validation: 0.043913977535064874]
	TIME [epoch: 8.29 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026118197637538275		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.026118197637538275 | validation: 0.03653433724315601]
	TIME [epoch: 8.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021928293496424126		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.021928293496424126 | validation: 0.041250483735085705]
	TIME [epoch: 8.32 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022057946501191656		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.022057946501191656 | validation: 0.02615705512974802]
	TIME [epoch: 8.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023695483456581505		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.023695483456581505 | validation: 0.03596840685623261]
	TIME [epoch: 8.29 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0247659325181827		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.0247659325181827 | validation: 0.034913546008454185]
	TIME [epoch: 8.29 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030511204338544755		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.030511204338544755 | validation: 0.03779581860728232]
	TIME [epoch: 8.31 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029273589026502844		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.029273589026502844 | validation: 0.04315422088289056]
	TIME [epoch: 8.29 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02470510243961806		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.02470510243961806 | validation: 0.03189292055878258]
	TIME [epoch: 8.29 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024934953427865437		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.024934953427865437 | validation: 0.02156396290168222]
	TIME [epoch: 8.29 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018430121662779388		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.018430121662779388 | validation: 0.024099193564031618]
	TIME [epoch: 8.31 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021642254562732173		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.021642254562732173 | validation: 0.03169276334031218]
	TIME [epoch: 8.29 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02604099474382563		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.02604099474382563 | validation: 0.02869544387242668]
	TIME [epoch: 8.29 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02227661994508292		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.02227661994508292 | validation: 0.01704995081870921]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1766.pth
	Model improved!!!
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02598069656254568		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.02598069656254568 | validation: 0.03476907715793161]
	TIME [epoch: 8.32 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03848711826725862		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.03848711826725862 | validation: 0.035405462618058346]
	TIME [epoch: 8.29 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02207125675476847		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.02207125675476847 | validation: 0.02759980660976784]
	TIME [epoch: 8.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021340524185724605		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.021340524185724605 | validation: 0.025983109034240757]
	TIME [epoch: 8.29 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022921055806558403		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.022921055806558403 | validation: 0.02950445984252065]
	TIME [epoch: 8.31 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02464350235889256		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.02464350235889256 | validation: 0.02740184284488908]
	TIME [epoch: 8.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024738909452628226		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.024738909452628226 | validation: 0.028710516739014806]
	TIME [epoch: 8.3 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022065200975181633		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.022065200975181633 | validation: 0.02485472554454523]
	TIME [epoch: 8.29 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019964325496747856		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.019964325496747856 | validation: 0.03449935954183661]
	TIME [epoch: 8.32 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022008721595824992		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.022008721595824992 | validation: 0.02992236737000127]
	TIME [epoch: 8.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02801927763796915		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.02801927763796915 | validation: 0.04484413438560937]
	TIME [epoch: 8.29 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025910550447949838		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.025910550447949838 | validation: 0.03552815025904738]
	TIME [epoch: 8.29 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023478398252351866		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.023478398252351866 | validation: 0.030936768354744695]
	TIME [epoch: 8.32 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024034746463248886		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.024034746463248886 | validation: 0.025919286700491307]
	TIME [epoch: 8.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020535930171358706		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.020535930171358706 | validation: 0.027737025423552143]
	TIME [epoch: 8.29 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02456485983786933		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.02456485983786933 | validation: 0.026958679650342023]
	TIME [epoch: 8.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024787161547445678		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.024787161547445678 | validation: 0.025453217626731486]
	TIME [epoch: 8.32 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026180167679846593		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.026180167679846593 | validation: 0.031879767171410736]
	TIME [epoch: 8.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027111633283465754		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.027111633283465754 | validation: 0.021372176070225866]
	TIME [epoch: 8.31 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02361141354640769		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.02361141354640769 | validation: 0.04112211831606645]
	TIME [epoch: 8.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02190981573386862		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.02190981573386862 | validation: 0.03167040648297439]
	TIME [epoch: 8.31 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026777183341172767		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.026777183341172767 | validation: 0.030699498926682486]
	TIME [epoch: 8.29 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022811480013416204		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.022811480013416204 | validation: 0.02046074912179375]
	TIME [epoch: 8.29 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028240243521041285		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.028240243521041285 | validation: 0.0305000248013162]
	TIME [epoch: 8.3 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022850499263815084		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.022850499263815084 | validation: 0.030625644040627176]
	TIME [epoch: 8.32 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021763597378097417		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.021763597378097417 | validation: 0.0349096426891436]
	TIME [epoch: 8.29 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026421276680363686		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.026421276680363686 | validation: 0.032134101269982]
	TIME [epoch: 8.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03438973470855604		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.03438973470855604 | validation: 0.04197119722166531]
	TIME [epoch: 8.29 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035892872476789656		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.035892872476789656 | validation: 0.032340665463712906]
	TIME [epoch: 8.32 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01836616254788446		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.01836616254788446 | validation: 0.030484741929071846]
	TIME [epoch: 8.3 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029466831934065508		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.029466831934065508 | validation: 0.024170553693569487]
	TIME [epoch: 8.29 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020285735618256816		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.020285735618256816 | validation: 0.03241903914070941]
	TIME [epoch: 8.29 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022572946727742		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.022572946727742 | validation: 0.03391659839641148]
	TIME [epoch: 8.32 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027274923060286317		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.027274923060286317 | validation: 0.03445072553966881]
	TIME [epoch: 8.29 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028152992512647596		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.028152992512647596 | validation: 0.030987307791221892]
	TIME [epoch: 8.29 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018808801065840892		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.018808801065840892 | validation: 0.027142223321401773]
	TIME [epoch: 8.3 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021969164198114653		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.021969164198114653 | validation: 0.02584726930832614]
	TIME [epoch: 8.32 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021964126333350976		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.021964126333350976 | validation: 0.03235499692974857]
	TIME [epoch: 8.29 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02170663504184353		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.02170663504184353 | validation: 0.023121354933218652]
	TIME [epoch: 8.29 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024169929569638714		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.024169929569638714 | validation: 0.036741838397674906]
	TIME [epoch: 8.3 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024854874439641458		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.024854874439641458 | validation: 0.028523024947680973]
	TIME [epoch: 8.33 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020548814813256204		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.020548814813256204 | validation: 0.03804934618176108]
	TIME [epoch: 8.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02229369288826259		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.02229369288826259 | validation: 0.03271828260692403]
	TIME [epoch: 8.29 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024489381851839614		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.024489381851839614 | validation: 0.02191797452205798]
	TIME [epoch: 8.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019212146987910673		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.019212146987910673 | validation: 0.023482134852290084]
	TIME [epoch: 8.32 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02369750123848772		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.02369750123848772 | validation: 0.03210706721891171]
	TIME [epoch: 8.29 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022250916070025897		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.022250916070025897 | validation: 0.029570594083953183]
	TIME [epoch: 8.29 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024673203919050375		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.024673203919050375 | validation: 0.03376509563976679]
	TIME [epoch: 8.29 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025688147349555324		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.025688147349555324 | validation: 0.03729176381347636]
	TIME [epoch: 8.32 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03513066114584004		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.03513066114584004 | validation: 0.03114907124375201]
	TIME [epoch: 8.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031503222826643126		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.031503222826643126 | validation: 0.034793134404400544]
	TIME [epoch: 8.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025288629478792374		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.025288629478792374 | validation: 0.040422531271207054]
	TIME [epoch: 8.3 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023080161614801867		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.023080161614801867 | validation: 0.035702025234140844]
	TIME [epoch: 8.33 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022247930680086278		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.022247930680086278 | validation: 0.032160997953710496]
	TIME [epoch: 8.31 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03105528253810346		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.03105528253810346 | validation: 0.03514779272520309]
	TIME [epoch: 8.31 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02693226026377001		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.02693226026377001 | validation: 0.034506995234325086]
	TIME [epoch: 8.29 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026490589450345704		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.026490589450345704 | validation: 0.03432116357389806]
	TIME [epoch: 8.32 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020873424552271515		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.020873424552271515 | validation: 0.035720590806523296]
	TIME [epoch: 8.3 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029855654622531275		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.029855654622531275 | validation: 0.042254853869098837]
	TIME [epoch: 8.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02298487143675097		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.02298487143675097 | validation: 0.04656707690942767]
	TIME [epoch: 8.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028319669550367355		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.028319669550367355 | validation: 0.03283680207282782]
	TIME [epoch: 8.33 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022965115857523588		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.022965115857523588 | validation: 0.025138100232280344]
	TIME [epoch: 8.29 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02681512511658864		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.02681512511658864 | validation: 0.039684319315941144]
	TIME [epoch: 8.29 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02652700352760114		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.02652700352760114 | validation: 0.04487499136925338]
	TIME [epoch: 8.31 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025564921894337005		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.025564921894337005 | validation: 0.03958512314670719]
	TIME [epoch: 8.31 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026728627076725665		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.026728627076725665 | validation: 0.04217176603482169]
	TIME [epoch: 8.29 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024041680629192173		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.024041680629192173 | validation: 0.03741354152722121]
	TIME [epoch: 8.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022121479839014725		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.022121479839014725 | validation: 0.030858599060618812]
	TIME [epoch: 8.3 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022742527573182316		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.022742527573182316 | validation: 0.025590349667683775]
	TIME [epoch: 8.34 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024727704036304227		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.024727704036304227 | validation: 0.0314896461814881]
	TIME [epoch: 8.31 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028618426344132773		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.028618426344132773 | validation: 0.03238866359064596]
	TIME [epoch: 8.29 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022438198644618528		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.022438198644618528 | validation: 0.03360921676580138]
	TIME [epoch: 8.3 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024478109076744636		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.024478109076744636 | validation: 0.03629032002819892]
	TIME [epoch: 8.32 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02446308778239107		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.02446308778239107 | validation: 0.035917973224172214]
	TIME [epoch: 8.3 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031244468893228027		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.031244468893228027 | validation: 0.0336062902414846]
	TIME [epoch: 8.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026588468345827933		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.026588468345827933 | validation: 0.01996568129316703]
	TIME [epoch: 8.29 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018931877393098477		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.018931877393098477 | validation: 0.027236900384060556]
	TIME [epoch: 8.32 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019510768678699424		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.019510768678699424 | validation: 0.03720153095438013]
	TIME [epoch: 8.31 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02510652690615727		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.02510652690615727 | validation: 0.026966262147010374]
	TIME [epoch: 8.32 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02447475975805886		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.02447475975805886 | validation: 0.04048626168601152]
	TIME [epoch: 8.32 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02238013580320628		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.02238013580320628 | validation: 0.02043784579814547]
	TIME [epoch: 8.33 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02492260839269271		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.02492260839269271 | validation: 0.0191609361402631]
	TIME [epoch: 8.32 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02563624708019146		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.02563624708019146 | validation: 0.02436189142831799]
	TIME [epoch: 8.32 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022739746927864173		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.022739746927864173 | validation: 0.03079778697714571]
	TIME [epoch: 8.32 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026345106745539748		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.026345106745539748 | validation: 0.03977899646836695]
	TIME [epoch: 8.34 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03355461753491273		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.03355461753491273 | validation: 0.032845706716196785]
	TIME [epoch: 8.31 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02746070563886216		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.02746070563886216 | validation: 0.03939918837727638]
	TIME [epoch: 8.31 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02513083744492602		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.02513083744492602 | validation: 0.02799617634251208]
	TIME [epoch: 8.32 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024243601345070778		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.024243601345070778 | validation: 0.03734691363361101]
	TIME [epoch: 8.33 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02502550946683671		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.02502550946683671 | validation: 0.03469739837706193]
	TIME [epoch: 8.3 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021638251844181403		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.021638251844181403 | validation: 0.03576149933193114]
	TIME [epoch: 8.32 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027746315993672378		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.027746315993672378 | validation: 0.03922310529392885]
	TIME [epoch: 8.33 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027780430781316347		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.027780430781316347 | validation: 0.025748034437428628]
	TIME [epoch: 8.33 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018680883785570746		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.018680883785570746 | validation: 0.02215785235060929]
	TIME [epoch: 8.31 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022343688750268674		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.022343688750268674 | validation: 0.02801913342088074]
	TIME [epoch: 8.31 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02515034870531065		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.02515034870531065 | validation: 0.018460595699130805]
	TIME [epoch: 8.32 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02481133012724722		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.02481133012724722 | validation: 0.03493390237714977]
	TIME [epoch: 8.33 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021829484249675197		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.021829484249675197 | validation: 0.034309499553863365]
	TIME [epoch: 8.32 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023445394796384536		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.023445394796384536 | validation: 0.02845770074584477]
	TIME [epoch: 8.31 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02855909248665976		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.02855909248665976 | validation: 0.034413810220275454]
	TIME [epoch: 8.32 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023834233283709087		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.023834233283709087 | validation: 0.021164250434259874]
	TIME [epoch: 8.33 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02642768234170298		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.02642768234170298 | validation: 0.030314537921050107]
	TIME [epoch: 8.31 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022870405077453478		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.022870405077453478 | validation: 0.03522907659700339]
	TIME [epoch: 8.31 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022269533965876415		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.022269533965876415 | validation: 0.02544923010193042]
	TIME [epoch: 8.32 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0220676167331882		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.0220676167331882 | validation: 0.030042413843639745]
	TIME [epoch: 8.32 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023540225095693975		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.023540225095693975 | validation: 0.023251322623446327]
	TIME [epoch: 8.31 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022574126936737052		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.022574126936737052 | validation: 0.032884847423429744]
	TIME [epoch: 8.31 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022618279393053515		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.022618279393053515 | validation: 0.04039591571763042]
	TIME [epoch: 8.33 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02530807443968499		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.02530807443968499 | validation: 0.020130365061485023]
	TIME [epoch: 8.31 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019509560306891868		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.019509560306891868 | validation: 0.03313931555646317]
	TIME [epoch: 8.31 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021803704316939326		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.021803704316939326 | validation: 0.03345717035690178]
	TIME [epoch: 8.31 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025231185758496456		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.025231185758496456 | validation: 0.03555953552320323]
	TIME [epoch: 8.32 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021875012370698464		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.021875012370698464 | validation: 0.03864933145433825]
	TIME [epoch: 8.33 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022935482162366894		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.022935482162366894 | validation: 0.0351147357262148]
	TIME [epoch: 8.32 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025978858371976398		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.025978858371976398 | validation: 0.03834470318359917]
	TIME [epoch: 8.31 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017399542351072196		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.017399542351072196 | validation: 0.027510639567306625]
	TIME [epoch: 8.32 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020801046195555		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.020801046195555 | validation: 0.03305289131874904]
	TIME [epoch: 8.32 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02041142246310222		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.02041142246310222 | validation: 0.04491167327996942]
	TIME [epoch: 8.31 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027745769260335888		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.027745769260335888 | validation: 0.026948263875340987]
	TIME [epoch: 8.31 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021322963567928687		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.021322963567928687 | validation: 0.027622660923613138]
	TIME [epoch: 8.33 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02105585424062199		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.02105585424062199 | validation: 0.035258987477477306]
	TIME [epoch: 8.32 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02506496460408004		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.02506496460408004 | validation: 0.02931465484791904]
	TIME [epoch: 8.31 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02207923899812956		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.02207923899812956 | validation: 0.03320222899416267]
	TIME [epoch: 8.31 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031971198539945386		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.031971198539945386 | validation: 0.031931424256066696]
	TIME [epoch: 8.32 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02326456550260971		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.02326456550260971 | validation: 0.03423612605515276]
	TIME [epoch: 8.32 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024256782816784672		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.024256782816784672 | validation: 0.027679267842157053]
	TIME [epoch: 8.31 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023787012129552396		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.023787012129552396 | validation: 0.03935292322097553]
	TIME [epoch: 8.31 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02000018593059267		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.02000018593059267 | validation: 0.028487059378492934]
	TIME [epoch: 8.32 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01647847956100808		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.01647847956100808 | validation: 0.02657068798906098]
	TIME [epoch: 8.32 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028460327656433138		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.028460327656433138 | validation: 0.031052832330668342]
	TIME [epoch: 8.31 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02041885264549862		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.02041885264549862 | validation: 0.019604281030513884]
	TIME [epoch: 8.31 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01964454913268577		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.01964454913268577 | validation: 0.023814162516186507]
	TIME [epoch: 8.32 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022029706967506817		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.022029706967506817 | validation: 0.03178620647219397]
	TIME [epoch: 8.32 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02693736325375245		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.02693736325375245 | validation: 0.034745259057401424]
	TIME [epoch: 8.31 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02023503987037258		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.02023503987037258 | validation: 0.03629441537407212]
	TIME [epoch: 8.31 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02503618449996458		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.02503618449996458 | validation: 0.046748316288267935]
	TIME [epoch: 8.32 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02891121636060722		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.02891121636060722 | validation: 0.0317450891398251]
	TIME [epoch: 8.32 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020545884446515006		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.020545884446515006 | validation: 0.03229805463793864]
	TIME [epoch: 8.32 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023782282465848837		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.023782282465848837 | validation: 0.02536822402977561]
	TIME [epoch: 8.31 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026329423186176454		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.026329423186176454 | validation: 0.031185007259287197]
	TIME [epoch: 8.33 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025347793642982903		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.025347793642982903 | validation: 0.023635089642256895]
	TIME [epoch: 8.31 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02647167192149562		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.02647167192149562 | validation: 0.02584962556666899]
	TIME [epoch: 8.31 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020454261083214128		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.020454261083214128 | validation: 0.03341418056879929]
	TIME [epoch: 8.31 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02212198091171671		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.02212198091171671 | validation: 0.018220662896035585]
	TIME [epoch: 8.32 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021849136633197097		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.021849136633197097 | validation: 0.02735634831278292]
	TIME [epoch: 8.31 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023731871890474654		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.023731871890474654 | validation: 0.027657775266426102]
	TIME [epoch: 8.3 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02055865104665596		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.02055865104665596 | validation: 0.033271090650079035]
	TIME [epoch: 8.31 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024751935281364205		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.024751935281364205 | validation: 0.028071505407177958]
	TIME [epoch: 8.31 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02283407764576876		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.02283407764576876 | validation: 0.025064566359051473]
	TIME [epoch: 8.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02192194850568053		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.02192194850568053 | validation: 0.01663051291669021]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240219_184940/states/model_tr_study4_1916.pth
	Model improved!!!
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01918597394365239		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.01918597394365239 | validation: 0.026412291493442104]
	TIME [epoch: 8.3 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02190187504784516		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.02190187504784516 | validation: 0.023290284660104767]
	TIME [epoch: 8.32 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02424554113084914		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.02424554113084914 | validation: 0.032222419100348315]
	TIME [epoch: 8.31 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019886129453064373		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.019886129453064373 | validation: 0.02253923282130955]
	TIME [epoch: 8.3 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024501093716405166		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.024501093716405166 | validation: 0.022153703759710063]
	TIME [epoch: 8.31 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023816760838075712		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.023816760838075712 | validation: 0.039135919072518933]
	TIME [epoch: 8.33 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030902745595348946		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.030902745595348946 | validation: 0.031559157719568895]
	TIME [epoch: 8.31 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02578104944131555		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.02578104944131555 | validation: 0.024506864593783595]
	TIME [epoch: 8.3 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01982254552302607		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.01982254552302607 | validation: 0.023279067188249694]
	TIME [epoch: 8.31 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02426320627703942		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.02426320627703942 | validation: 0.023623674791803294]
	TIME [epoch: 8.33 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01829671186637451		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.01829671186637451 | validation: 0.02343202465034347]
	TIME [epoch: 8.31 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03146622235653601		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.03146622235653601 | validation: 0.03572752674257599]
	TIME [epoch: 8.31 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026706969504515992		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.026706969504515992 | validation: 0.03658214438358419]
	TIME [epoch: 8.31 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02714063270120771		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.02714063270120771 | validation: 0.03966831021404418]
	TIME [epoch: 8.34 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0287020480148245		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.0287020480148245 | validation: 0.03774920970779769]
	TIME [epoch: 8.32 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026834366474856396		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.026834366474856396 | validation: 0.03530787165034713]
	TIME [epoch: 8.32 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024701117257452092		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.024701117257452092 | validation: 0.029120851138111796]
	TIME [epoch: 8.31 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017984998448613128		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.017984998448613128 | validation: 0.027038664260193062]
	TIME [epoch: 8.34 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02645636118085267		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.02645636118085267 | validation: 0.03634863579204216]
	TIME [epoch: 8.31 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02473367546434522		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.02473367546434522 | validation: 0.03199291905297034]
	TIME [epoch: 8.3 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018825090869195798		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.018825090869195798 | validation: 0.026842414416079194]
	TIME [epoch: 8.31 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019949963891012272		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.019949963891012272 | validation: 0.03192963293229868]
	TIME [epoch: 8.33 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02760469279770996		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.02760469279770996 | validation: 0.028127896215627644]
	TIME [epoch: 8.32 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021136008397643753		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.021136008397643753 | validation: 0.027262236158527412]
	TIME [epoch: 8.31 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023479531536786395		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.023479531536786395 | validation: 0.026537209796520272]
	TIME [epoch: 8.31 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020981137186625632		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.020981137186625632 | validation: 0.02652361097997708]
	TIME [epoch: 8.33 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019682410159515603		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.019682410159515603 | validation: 0.029405591207597125]
	TIME [epoch: 8.32 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022876578751709738		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.022876578751709738 | validation: 0.03616365606233811]
	TIME [epoch: 8.31 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020649015165766556		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.020649015165766556 | validation: 0.029101948929854585]
	TIME [epoch: 8.31 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020947240776397216		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.020947240776397216 | validation: 0.03635049646540406]
	TIME [epoch: 8.33 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030278276440967443		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.030278276440967443 | validation: 0.030382855599718803]
	TIME [epoch: 8.31 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02400165406325527		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.02400165406325527 | validation: 0.027734113620248788]
	TIME [epoch: 8.3 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023465603889521618		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.023465603889521618 | validation: 0.029411992122529637]
	TIME [epoch: 8.31 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021257033799718883		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.021257033799718883 | validation: 0.03609766381111482]
	TIME [epoch: 8.32 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025946731751356235		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.025946731751356235 | validation: 0.02705992745341441]
	TIME [epoch: 8.31 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03708025625061905		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.03708025625061905 | validation: 0.03054552923163937]
	TIME [epoch: 8.31 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02010193665771184		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.02010193665771184 | validation: 0.022692474687769422]
	TIME [epoch: 8.31 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025214308605260048		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.025214308605260048 | validation: 0.033114825837635246]
	TIME [epoch: 8.32 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025330835529252242		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.025330835529252242 | validation: 0.031841312997355466]
	TIME [epoch: 8.32 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0211059559749836		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.0211059559749836 | validation: 0.02766208474958888]
	TIME [epoch: 8.31 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020452751642823154		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.020452751642823154 | validation: 0.022806289806319713]
	TIME [epoch: 8.32 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02313338065070554		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.02313338065070554 | validation: 0.03161626038258465]
	TIME [epoch: 8.33 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018326755212920563		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.018326755212920563 | validation: 0.030757708285190997]
	TIME [epoch: 8.32 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021681082892524163		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.021681082892524163 | validation: 0.02424441757042429]
	TIME [epoch: 8.31 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02164111901780949		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.02164111901780949 | validation: 0.027513405732438136]
	TIME [epoch: 8.32 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018907674260650435		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.018907674260650435 | validation: 0.03210837816415138]
	TIME [epoch: 8.34 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024368496008834874		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.024368496008834874 | validation: 0.027023798087647405]
	TIME [epoch: 8.31 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02411603722342424		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.02411603722342424 | validation: 0.03141480655169792]
	TIME [epoch: 8.31 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019852013164245702		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.019852013164245702 | validation: 0.028426549705887892]
	TIME [epoch: 8.31 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02004137186158944		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.02004137186158944 | validation: 0.027320392206805516]
	TIME [epoch: 8.33 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02265623347112136		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.02265623347112136 | validation: 0.034117346111453915]
	TIME [epoch: 8.31 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022489620538957374		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.022489620538957374 | validation: 0.039216508637949524]
	TIME [epoch: 8.31 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025141991369746413		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.025141991369746413 | validation: 0.027913088446854764]
	TIME [epoch: 8.31 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02778914878465441		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.02778914878465441 | validation: 0.03499637844891815]
	TIME [epoch: 8.34 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023370049985478508		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.023370049985478508 | validation: 0.02393480958472206]
	TIME [epoch: 8.31 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01900148287539705		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.01900148287539705 | validation: 0.03129738277768703]
	TIME [epoch: 8.31 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01934287413432119		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.01934287413432119 | validation: 0.021516877781206516]
	TIME [epoch: 8.3 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02154530747006452		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.02154530747006452 | validation: 0.022288614493887336]
	TIME [epoch: 8.33 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020136941487743427		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.020136941487743427 | validation: 0.027237184221280596]
	TIME [epoch: 8.31 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018737562852032583		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.018737562852032583 | validation: 0.02743849079391302]
	TIME [epoch: 8.31 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022140363431386294		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.022140363431386294 | validation: 0.02492206095016735]
	TIME [epoch: 8.31 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02329449197478283		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.02329449197478283 | validation: 0.024222568431758573]
	TIME [epoch: 8.32 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03418518045382155		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.03418518045382155 | validation: 0.03830327426938049]
	TIME [epoch: 8.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024920832340916535		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.024920832340916535 | validation: 0.03213229605045079]
	TIME [epoch: 8.31 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02459478763625241		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.02459478763625241 | validation: 0.02598740332806543]
	TIME [epoch: 8.32 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023497435724113325		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.023497435724113325 | validation: 0.02868453027943267]
	TIME [epoch: 8.34 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022961169728021372		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.022961169728021372 | validation: 0.0332736938752972]
	TIME [epoch: 8.32 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017779566383956086		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.017779566383956086 | validation: 0.03329970559223369]
	TIME [epoch: 8.31 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02055895183224741		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.02055895183224741 | validation: 0.029485531710705573]
	TIME [epoch: 8.32 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024325737940651092		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.024325737940651092 | validation: 0.033967391180384277]
	TIME [epoch: 8.34 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022924454458207615		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.022924454458207615 | validation: 0.029315322689297808]
	TIME [epoch: 8.32 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026740546343209687		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.026740546343209687 | validation: 0.023347382949931106]
	TIME [epoch: 8.32 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01972053341757899		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.01972053341757899 | validation: 0.02869793054921916]
	TIME [epoch: 8.32 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02467019986979891		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.02467019986979891 | validation: 0.03157265352945101]
	TIME [epoch: 8.34 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023666239697943132		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.023666239697943132 | validation: 0.026788159012967105]
	TIME [epoch: 8.32 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02022867819378902		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.02022867819378902 | validation: 0.030675907665189774]
	TIME [epoch: 8.32 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01895777143824812		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.01895777143824812 | validation: 0.03716591037170212]
	TIME [epoch: 8.32 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02205051941359465		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.02205051941359465 | validation: 0.03826290524642781]
	TIME [epoch: 8.33 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02971888268842806		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.02971888268842806 | validation: 0.033094630686168185]
	TIME [epoch: 8.32 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02530069801737116		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.02530069801737116 | validation: 0.02740420332188931]
	TIME [epoch: 8.32 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01563757072198439		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.01563757072198439 | validation: 0.02939363430859785]
	TIME [epoch: 8.31 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021609696386510478		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.021609696386510478 | validation: 0.030557468003048024]
	TIME [epoch: 8.35 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02366015293739949		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.02366015293739949 | validation: 0.04276899956967178]
	TIME [epoch: 8.34 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02881503357521285		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.02881503357521285 | validation: 0.02421470236623835]
	TIME [epoch: 8.34 sec]
Finished training in 16801.416 seconds.
