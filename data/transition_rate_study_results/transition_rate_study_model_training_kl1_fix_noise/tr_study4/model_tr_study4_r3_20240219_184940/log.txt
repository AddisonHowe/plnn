Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2085727246

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.001642682618867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.001642682618867 | validation: 7.780749871118699]
	TIME [epoch: 78.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.966358176701459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.966358176701459 | validation: 7.531852672264783]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.684449218884209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.684449218884209 | validation: 7.038538751110508]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.266019871634903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.266019871634903 | validation: 6.716464637671274]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.033907544831254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.033907544831254 | validation: 6.449155562281998]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.785048051550945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.785048051550945 | validation: 6.245891694532857]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.621795351501618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.621795351501618 | validation: 6.2220873175123925]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.466244276099533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.466244276099533 | validation: 6.211260442033908]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.392304039889057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.392304039889057 | validation: 7.099460923021441]
	TIME [epoch: 8.53 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.661870100001098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.661870100001098 | validation: 5.0156967644786565]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.1653210409803965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1653210409803965 | validation: 5.024244709030891]
	TIME [epoch: 8.51 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.0960455181790545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0960455181790545 | validation: 4.715421314857712]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.398641088279325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.398641088279325 | validation: 5.0301447872561855]
	TIME [epoch: 8.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.077356246682185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.077356246682185 | validation: 5.0948694874216915]
	TIME [epoch: 8.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.915422015247719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.915422015247719 | validation: 4.024960624634879]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.042806129501609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.042806129501609 | validation: 4.596783145576459]
	TIME [epoch: 8.53 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.60100934620596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.60100934620596 | validation: 3.8015047991395905]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.180337758103856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.180337758103856 | validation: 3.650239175682139]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.954234944930097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.954234944930097 | validation: 4.235945412322653]
	TIME [epoch: 8.52 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.146178472164995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.146178472164995 | validation: 3.4158547596188313]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.695161946154811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.695161946154811 | validation: 3.304532640814851]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.060311360353126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.060311360353126 | validation: 3.064950364067811]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3036506782105373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3036506782105373 | validation: 2.6791066868533218]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4298760572090616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4298760572090616 | validation: 2.5871118456176987]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0999406610559563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0999406610559563 | validation: 2.4998158847878234]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.92278008396135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.92278008396135 | validation: 1.9147279974453015]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4875683734568992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4875683734568992 | validation: 2.0612071637715044]
	TIME [epoch: 8.52 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5760517232927467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5760517232927467 | validation: 1.8417456969642347]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.627013282830252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.627013282830252 | validation: 1.236789862400129]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.489536039713688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.489536039713688 | validation: 2.239602734221396]
	TIME [epoch: 8.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8951495410378043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8951495410378043 | validation: 1.1818684377557889]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4187234802822037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4187234802822037 | validation: 1.8143747552216118]
	TIME [epoch: 8.52 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2792577405216776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2792577405216776 | validation: 0.8645048232878063]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0341885150085717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0341885150085717 | validation: 1.5676841813533597]
	TIME [epoch: 8.53 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0665433638182351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0665433638182351 | validation: 1.308017867602231]
	TIME [epoch: 8.52 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3477068668434373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3477068668434373 | validation: 0.9004631348696022]
	TIME [epoch: 8.51 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8511635466618926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8511635466618926 | validation: 1.5740325448757813]
	TIME [epoch: 8.52 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1849610329996283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1849610329996283 | validation: 0.8708812102241364]
	TIME [epoch: 8.54 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9553664765528417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9553664765528417 | validation: 0.8487909850766747]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9079125207154437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9079125207154437 | validation: 0.789383557480914]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7982605482451621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7982605482451621 | validation: 0.9920758842520686]
	TIME [epoch: 8.52 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6859695848148402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6859695848148402 | validation: 0.8618247663607399]
	TIME [epoch: 8.54 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2578559333773582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2578559333773582 | validation: 1.0267845960475583]
	TIME [epoch: 8.52 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8194052759662019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8194052759662019 | validation: 1.0787014434755346]
	TIME [epoch: 8.51 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.786699690137521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.786699690137521 | validation: 0.889815974584728]
	TIME [epoch: 8.51 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9224554290614193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9224554290614193 | validation: 0.7373397406648341]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8334242945213399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8334242945213399 | validation: 0.864044481992206]
	TIME [epoch: 8.51 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8268674456784458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8268674456784458 | validation: 0.873784285228962]
	TIME [epoch: 8.52 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7147983638882456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7147983638882456 | validation: 0.8467871818496138]
	TIME [epoch: 8.51 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7098001702123857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7098001702123857 | validation: 0.6321497526432645]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7577856086676176		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 0.7577856086676176 | validation: 0.8400135368274517]
	TIME [epoch: 8.51 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0167833202205552		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 1.0167833202205552 | validation: 0.8440772239767045]
	TIME [epoch: 8.51 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7431962361920543		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 0.7431962361920543 | validation: 0.7278168584052476]
	TIME [epoch: 8.51 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9036256818397523		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 0.9036256818397523 | validation: 0.7135951264476985]
	TIME [epoch: 8.53 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7484836775439645		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 0.7484836775439645 | validation: 1.1725721868706414]
	TIME [epoch: 8.51 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7795693722028016		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 0.7795693722028016 | validation: 0.8791736163589752]
	TIME [epoch: 8.51 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8631981146445986		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 0.8631981146445986 | validation: 0.6888879615896256]
	TIME [epoch: 8.52 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6897913522482069		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 0.6897913522482069 | validation: 0.6453681567072638]
	TIME [epoch: 8.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7023657689824454		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 0.7023657689824454 | validation: 0.6116015635351694]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6579983440366679		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 0.6579983440366679 | validation: 2.1040266743506746]
	TIME [epoch: 8.51 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9844878149135428		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 0.9844878149135428 | validation: 0.5638346049873211]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8366180897987847		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 0.8366180897987847 | validation: 0.7679166166364061]
	TIME [epoch: 8.52 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7291629563301683		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 0.7291629563301683 | validation: 0.6638208537816683]
	TIME [epoch: 8.51 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7538441013692626		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 0.7538441013692626 | validation: 0.9806732593480567]
	TIME [epoch: 8.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8727993296348823		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 0.8727993296348823 | validation: 0.798819356683748]
	TIME [epoch: 8.53 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6408462496630639		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 0.6408462496630639 | validation: 0.9804465028323044]
	TIME [epoch: 8.53 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7433265262813722		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 0.7433265262813722 | validation: 0.9029041068264637]
	TIME [epoch: 8.52 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7149358597674731		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 0.7149358597674731 | validation: 0.7840776682689287]
	TIME [epoch: 8.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9457087726299672		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 0.9457087726299672 | validation: 0.8078606962302743]
	TIME [epoch: 8.54 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.796185895880942		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 0.796185895880942 | validation: 0.7050537843098186]
	TIME [epoch: 8.52 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7730647590794659		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 0.7730647590794659 | validation: 0.68418357775425]
	TIME [epoch: 8.51 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6787112746978059		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 0.6787112746978059 | validation: 0.7613051123983311]
	TIME [epoch: 8.51 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7854194020297984		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 0.7854194020297984 | validation: 1.2654751381024891]
	TIME [epoch: 8.54 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.69993786790323		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 0.69993786790323 | validation: 0.7068356871290964]
	TIME [epoch: 8.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.852579899314627		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 0.852579899314627 | validation: 0.9486364734324186]
	TIME [epoch: 8.51 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7116220032408452		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 0.7116220032408452 | validation: 0.5900150607591006]
	TIME [epoch: 8.51 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.72207659565866		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 0.72207659565866 | validation: 0.6914670443311126]
	TIME [epoch: 8.54 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7050633877908798		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 0.7050633877908798 | validation: 0.7557935265002624]
	TIME [epoch: 8.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.685812583798685		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 0.685812583798685 | validation: 0.6837415275682792]
	TIME [epoch: 8.51 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6145926409781348		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 0.6145926409781348 | validation: 0.6570769294732621]
	TIME [epoch: 8.51 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6556298357347998		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 0.6556298357347998 | validation: 0.8137391737584012]
	TIME [epoch: 8.54 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6523944157070641		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 0.6523944157070641 | validation: 0.6578843638276278]
	TIME [epoch: 8.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6922984465446572		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 0.6922984465446572 | validation: 0.59521501829954]
	TIME [epoch: 8.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8337266089590034		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 0.8337266089590034 | validation: 0.887732875084527]
	TIME [epoch: 8.52 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6754327147031796		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 0.6754327147031796 | validation: 0.7381014537134973]
	TIME [epoch: 8.54 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7909470849343265		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 0.7909470849343265 | validation: 0.541096908242019]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.584360073110459		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 0.584360073110459 | validation: 0.7099765905744777]
	TIME [epoch: 8.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5839130848906989		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 0.5839130848906989 | validation: 0.6722641480430434]
	TIME [epoch: 8.51 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7319613210723765		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 0.7319613210723765 | validation: 0.6272481094536413]
	TIME [epoch: 8.53 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5631882961841674		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 0.5631882961841674 | validation: 0.6574018144775353]
	TIME [epoch: 8.51 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6746967610074559		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 0.6746967610074559 | validation: 0.6359164891819763]
	TIME [epoch: 8.51 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7711624631904322		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 0.7711624631904322 | validation: 0.5488107397385296]
	TIME [epoch: 8.51 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6312472673366079		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.6312472673366079 | validation: 0.4475828123749107]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7415122684789338		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 0.7415122684789338 | validation: 1.0804767017873336]
	TIME [epoch: 8.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6380348756296842		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 0.6380348756296842 | validation: 0.7372762086178806]
	TIME [epoch: 8.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9017364721761549		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 0.9017364721761549 | validation: 0.4584257028141781]
	TIME [epoch: 8.52 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8241619628547419		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 0.8241619628547419 | validation: 0.6639789492476775]
	TIME [epoch: 8.51 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7255693874508735		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 0.7255693874508735 | validation: 1.0343878297156952]
	TIME [epoch: 8.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6370523288191504		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 0.6370523288191504 | validation: 0.48254036990938]
	TIME [epoch: 8.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6948927662087656		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 0.6948927662087656 | validation: 0.7479148089185306]
	TIME [epoch: 8.52 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6558250644155728		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 0.6558250644155728 | validation: 0.5662743789298907]
	TIME [epoch: 8.51 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5199158571276754		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 0.5199158571276754 | validation: 0.6669634669875177]
	TIME [epoch: 8.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6038659114471285		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 0.6038659114471285 | validation: 0.532599196572727]
	TIME [epoch: 8.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6163174377462441		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 0.6163174377462441 | validation: 0.6901260620343863]
	TIME [epoch: 8.53 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6180726486099124		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 0.6180726486099124 | validation: 0.7570883714878288]
	TIME [epoch: 8.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5849750626716395		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 0.5849750626716395 | validation: 0.4956354906495499]
	TIME [epoch: 8.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7361147391707223		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 0.7361147391707223 | validation: 0.5889998894862029]
	TIME [epoch: 8.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6263780588611644		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 0.6263780588611644 | validation: 0.9213936792746723]
	TIME [epoch: 8.52 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7188932540137662		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 0.7188932540137662 | validation: 0.7115913785861475]
	TIME [epoch: 8.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6036771146923762		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 0.6036771146923762 | validation: 0.6980875468342482]
	TIME [epoch: 8.49 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.70520140988435		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 0.70520140988435 | validation: 0.5650895917627736]
	TIME [epoch: 8.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.61443843726521		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 0.61443843726521 | validation: 0.6156622748444418]
	TIME [epoch: 8.52 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.611641326911494		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 0.611641326911494 | validation: 0.5701956483866584]
	TIME [epoch: 8.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5952642682061059		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 0.5952642682061059 | validation: 0.5701613725148055]
	TIME [epoch: 8.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5927372780789564		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 0.5927372780789564 | validation: 0.4880276887757882]
	TIME [epoch: 8.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5581493102877774		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 0.5581493102877774 | validation: 0.8311028656703406]
	TIME [epoch: 8.52 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5614561862097148		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.5614561862097148 | validation: 0.40753993786453735]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6562993518935639		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 0.6562993518935639 | validation: 0.6304390476744406]
	TIME [epoch: 8.51 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.575399999071807		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 0.575399999071807 | validation: 0.7046591654427714]
	TIME [epoch: 8.51 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5920067588520114		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 0.5920067588520114 | validation: 1.1874347462171357]
	TIME [epoch: 8.53 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6166499591597043		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 0.6166499591597043 | validation: 0.7794162310198323]
	TIME [epoch: 8.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6506519035578693		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 0.6506519035578693 | validation: 0.5459189746333134]
	TIME [epoch: 8.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5798403343327342		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 0.5798403343327342 | validation: 0.40706926662228415]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5600794023233351		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.5600794023233351 | validation: 1.0800979984956873]
	TIME [epoch: 8.53 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5944559893030057		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.5944559893030057 | validation: 0.936498943763966]
	TIME [epoch: 8.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5495642655825873		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 0.5495642655825873 | validation: 0.4032663430425876]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6704370975802895		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 0.6704370975802895 | validation: 0.401120345592565]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5553815570220226		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.5553815570220226 | validation: 0.7428324165400287]
	TIME [epoch: 8.53 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5903720895585587		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 0.5903720895585587 | validation: 0.35654177659105346]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5017099023509924		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 0.5017099023509924 | validation: 0.5943931985907676]
	TIME [epoch: 8.51 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.594146953759263		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.594146953759263 | validation: 0.4557837661475286]
	TIME [epoch: 8.53 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5003184191601093		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.5003184191601093 | validation: 0.6216667517794359]
	TIME [epoch: 8.51 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47576635787791793		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.47576635787791793 | validation: 0.5716984580329656]
	TIME [epoch: 8.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5167279231310803		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.5167279231310803 | validation: 0.4503879192764824]
	TIME [epoch: 8.51 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5193201792688742		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.5193201792688742 | validation: 0.4927113799760209]
	TIME [epoch: 8.53 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4235876068198824		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.4235876068198824 | validation: 0.42809063062958685]
	TIME [epoch: 8.51 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5024237578359736		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 0.5024237578359736 | validation: 0.5387344266749196]
	TIME [epoch: 8.51 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4747811480251434		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 0.4747811480251434 | validation: 0.3438806884905954]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48456015359513643		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 0.48456015359513643 | validation: 0.5489693699352955]
	TIME [epoch: 8.54 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5232214896307599		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.5232214896307599 | validation: 1.1948216550312039]
	TIME [epoch: 8.51 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6473720010191159		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.6473720010191159 | validation: 0.35903729340897456]
	TIME [epoch: 8.51 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4496039448068491		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 0.4496039448068491 | validation: 0.5464394077180037]
	TIME [epoch: 8.51 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4391762724091244		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.4391762724091244 | validation: 0.32418808778637154]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5485667696297459		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.5485667696297459 | validation: 0.4821849517381028]
	TIME [epoch: 8.52 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42991205182658376		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.42991205182658376 | validation: 0.3299259144157725]
	TIME [epoch: 8.51 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4226842197995123		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.4226842197995123 | validation: 0.391886929956867]
	TIME [epoch: 8.52 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49804183876264163		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.49804183876264163 | validation: 0.3416381569161863]
	TIME [epoch: 8.54 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7375772766119447		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.7375772766119447 | validation: 0.5088143892066288]
	TIME [epoch: 8.52 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5347506942913642		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.5347506942913642 | validation: 0.4863559525827593]
	TIME [epoch: 8.52 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8704953595413529		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.8704953595413529 | validation: 0.3751021005013609]
	TIME [epoch: 8.52 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4276065513226527		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.4276065513226527 | validation: 0.33421108820758816]
	TIME [epoch: 8.53 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4091048357843313		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.4091048357843313 | validation: 0.3771257259124523]
	TIME [epoch: 8.51 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41510523090562534		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.41510523090562534 | validation: 0.41039994082321174]
	TIME [epoch: 8.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5697814092497719		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.5697814092497719 | validation: 0.40765280896975087]
	TIME [epoch: 8.52 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4851636846589586		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.4851636846589586 | validation: 0.47546744155799037]
	TIME [epoch: 8.52 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4883416226315661		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.4883416226315661 | validation: 0.45086662858806237]
	TIME [epoch: 8.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4480865951999986		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.4480865951999986 | validation: 1.0738288346784572]
	TIME [epoch: 8.51 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6451251984599453		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.6451251984599453 | validation: 0.3743879205546028]
	TIME [epoch: 8.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5224698844286579		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.5224698844286579 | validation: 0.5116176046015388]
	TIME [epoch: 8.52 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.495447179760677		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.495447179760677 | validation: 0.534359996265248]
	TIME [epoch: 8.51 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42058469388931324		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.42058469388931324 | validation: 0.7228600108596113]
	TIME [epoch: 8.51 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5400384219204102		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.5400384219204102 | validation: 0.5680092967349832]
	TIME [epoch: 8.53 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5154208469330627		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.5154208469330627 | validation: 0.5032152096092997]
	TIME [epoch: 8.52 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.56226990951178		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.56226990951178 | validation: 0.5944575795975044]
	TIME [epoch: 8.51 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4638370456183978		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.4638370456183978 | validation: 0.6324586213686407]
	TIME [epoch: 8.51 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38606676043407395		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.38606676043407395 | validation: 0.45198871276904384]
	TIME [epoch: 8.54 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5308875925883627		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.5308875925883627 | validation: 0.7423881074328567]
	TIME [epoch: 8.52 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45825008981588367		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.45825008981588367 | validation: 0.3223471692533565]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.503901708261494		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.503901708261494 | validation: 0.3484346467261543]
	TIME [epoch: 8.51 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5460944380563502		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.5460944380563502 | validation: 0.7196419332793563]
	TIME [epoch: 8.52 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7857348362208368		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.7857348362208368 | validation: 0.5190420826669803]
	TIME [epoch: 8.51 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5465343927719056		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.5465343927719056 | validation: 0.4022856271918577]
	TIME [epoch: 8.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3950474153256739		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.3950474153256739 | validation: 0.8788495901292646]
	TIME [epoch: 8.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46365377821922527		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.46365377821922527 | validation: 0.3135669232579644]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3340151756163376		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.3340151756163376 | validation: 0.3246267078872448]
	TIME [epoch: 8.51 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3560886010392207		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.3560886010392207 | validation: 0.24603242246536]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4147087878535792		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 0.4147087878535792 | validation: 0.4568420805196667]
	TIME [epoch: 8.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46238859330574195		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.46238859330574195 | validation: 0.6101812458101095]
	TIME [epoch: 8.52 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39863069360185344		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.39863069360185344 | validation: 0.6350603286387428]
	TIME [epoch: 8.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45769229293017977		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.45769229293017977 | validation: 0.46021402323288585]
	TIME [epoch: 8.49 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4778717588443827		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.4778717588443827 | validation: 0.7805778568307726]
	TIME [epoch: 8.51 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4822234776703433		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.4822234776703433 | validation: 0.8186606958003572]
	TIME [epoch: 8.51 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5203473301172667		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.5203473301172667 | validation: 0.27764726734910444]
	TIME [epoch: 8.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3522393635911976		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.3522393635911976 | validation: 0.48354257861721295]
	TIME [epoch: 8.49 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5371374120736221		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.5371374120736221 | validation: 0.45806478364853276]
	TIME [epoch: 8.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.454642425117899		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.454642425117899 | validation: 0.36470191342686187]
	TIME [epoch: 8.51 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4744097606958947		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.4744097606958947 | validation: 1.120578838998263]
	TIME [epoch: 8.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6181768057209784		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.6181768057209784 | validation: 0.33300879154494967]
	TIME [epoch: 8.51 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5931084200244268		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.5931084200244268 | validation: 0.8600855057099565]
	TIME [epoch: 8.52 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5356005239451369		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.5356005239451369 | validation: 0.35358707547499124]
	TIME [epoch: 8.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39538334299952144		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.39538334299952144 | validation: 0.46834855515458107]
	TIME [epoch: 8.51 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.557257171003154		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.557257171003154 | validation: 0.8770573977599216]
	TIME [epoch: 8.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5194748694163451		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.5194748694163451 | validation: 0.43130688736155653]
	TIME [epoch: 8.52 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42572987809033763		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.42572987809033763 | validation: 0.404086731130788]
	TIME [epoch: 8.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4211078786176688		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.4211078786176688 | validation: 0.9682474634065491]
	TIME [epoch: 8.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40990804188443947		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.40990804188443947 | validation: 0.5874115342277116]
	TIME [epoch: 8.49 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4132004939472334		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.4132004939472334 | validation: 1.072092573289325]
	TIME [epoch: 8.52 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6212477037665187		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.6212477037665187 | validation: 0.26902083353869666]
	TIME [epoch: 8.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4228114717969008		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.4228114717969008 | validation: 0.874621794718464]
	TIME [epoch: 8.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7054881180088919		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.7054881180088919 | validation: 0.21851405226229714]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5063942312929094		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.5063942312929094 | validation: 0.32301017572612845]
	TIME [epoch: 8.53 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3976950291770887		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.3976950291770887 | validation: 0.6521430565176333]
	TIME [epoch: 8.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7250707754601925		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.7250707754601925 | validation: 0.5724475187411786]
	TIME [epoch: 8.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5274873727742646		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.5274873727742646 | validation: 0.808182901958437]
	TIME [epoch: 8.51 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7285660213914681		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.7285660213914681 | validation: 0.3739072334833374]
	TIME [epoch: 8.53 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5878879036715225		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.5878879036715225 | validation: 0.6104830979155158]
	TIME [epoch: 8.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4715054514291531		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.4715054514291531 | validation: 0.9124453031214794]
	TIME [epoch: 8.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7081068956423839		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.7081068956423839 | validation: 0.38876289054888513]
	TIME [epoch: 8.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6043295108101774		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.6043295108101774 | validation: 1.0261720275715358]
	TIME [epoch: 8.53 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5481681708515148		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5481681708515148 | validation: 0.5012267304653042]
	TIME [epoch: 8.49 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6593951157145621		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.6593951157145621 | validation: 0.6748430764738883]
	TIME [epoch: 8.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4892942516306048		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.4892942516306048 | validation: 0.7145520003801017]
	TIME [epoch: 8.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7037424901888538		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.7037424901888538 | validation: 0.42029250829168474]
	TIME [epoch: 8.53 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6388077506371872		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.6388077506371872 | validation: 0.9714026058622525]
	TIME [epoch: 8.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8061990300675251		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.8061990300675251 | validation: 0.302122104496069]
	TIME [epoch: 8.49 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7016445675524926		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.7016445675524926 | validation: 0.6169350744094193]
	TIME [epoch: 8.51 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1013697733018504		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 1.1013697733018504 | validation: 1.0332844362679723]
	TIME [epoch: 8.51 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7644789356698534		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.7644789356698534 | validation: 0.9521675243209634]
	TIME [epoch: 8.49 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7286672104383737		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.7286672104383737 | validation: 0.4725141895400053]
	TIME [epoch: 8.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5890138305076882		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.5890138305076882 | validation: 0.43141625156493524]
	TIME [epoch: 8.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6861064423918672		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.6861064423918672 | validation: 0.47253982265007044]
	TIME [epoch: 8.53 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5643552604541793		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.5643552604541793 | validation: 0.38078400331284123]
	TIME [epoch: 8.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48439291106695387		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.48439291106695387 | validation: 0.7678496501559573]
	TIME [epoch: 8.52 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5634509994713119		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.5634509994713119 | validation: 0.38869017073990386]
	TIME [epoch: 8.51 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4252495077290117		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.4252495077290117 | validation: 0.47706516099402074]
	TIME [epoch: 8.51 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4281918943515601		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.4281918943515601 | validation: 0.3697121284916341]
	TIME [epoch: 8.49 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5888877742254656		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.5888877742254656 | validation: 0.513389759281498]
	TIME [epoch: 8.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5640634546359979		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.5640634546359979 | validation: 0.6184897398139368]
	TIME [epoch: 8.51 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42454884943542837		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.42454884943542837 | validation: 0.21552282633279943]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5201781384575641		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.5201781384575641 | validation: 0.30151265677186856]
	TIME [epoch: 8.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6591494830469491		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.6591494830469491 | validation: 0.5679769713632783]
	TIME [epoch: 8.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4830816594159607		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.4830816594159607 | validation: 0.33400717994889095]
	TIME [epoch: 8.51 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5379514921910042		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.5379514921910042 | validation: 0.2681007542729469]
	TIME [epoch: 8.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4659433033567234		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.4659433033567234 | validation: 1.2547989605828067]
	TIME [epoch: 8.49 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.571515790423442		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.571515790423442 | validation: 0.6205066219695261]
	TIME [epoch: 8.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6216846962507133		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.6216846962507133 | validation: 0.8729900501216882]
	TIME [epoch: 8.52 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49504896717260716		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.49504896717260716 | validation: 0.5436807320921716]
	TIME [epoch: 8.51 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5001539864240917		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.5001539864240917 | validation: 0.32367365640148815]
	TIME [epoch: 8.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42443755995485655		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.42443755995485655 | validation: 0.5810686706608046]
	TIME [epoch: 8.49 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4450569077137271		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.4450569077137271 | validation: 0.5356218583031835]
	TIME [epoch: 8.51 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4126716985096703		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.4126716985096703 | validation: 0.35405812900402617]
	TIME [epoch: 8.49 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38217433865086153		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.38217433865086153 | validation: 0.7204789352339104]
	TIME [epoch: 8.49 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5058849358817324		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.5058849358817324 | validation: 0.89007395351379]
	TIME [epoch: 8.49 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4559704416655091		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.4559704416655091 | validation: 0.30891850008199917]
	TIME [epoch: 8.52 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5722438679614774		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.5722438679614774 | validation: 0.357275496372647]
	TIME [epoch: 8.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4406782684080969		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.4406782684080969 | validation: 0.42464235531665484]
	TIME [epoch: 8.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3861411681166572		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.3861411681166572 | validation: 1.3121660599999354]
	TIME [epoch: 8.49 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4802323780509181		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.4802323780509181 | validation: 0.48263883773598015]
	TIME [epoch: 8.53 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48950961778662405		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.48950961778662405 | validation: 0.36286640469069853]
	TIME [epoch: 8.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5814315262893733		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.5814315262893733 | validation: 2.639698529361067]
	TIME [epoch: 8.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7077734422496051		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.7077734422496051 | validation: 0.32003403370070116]
	TIME [epoch: 8.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4266760304925194		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.4266760304925194 | validation: 0.32352936967310175]
	TIME [epoch: 8.53 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41233820528651205		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.41233820528651205 | validation: 0.5649498257062133]
	TIME [epoch: 8.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1291518341618885		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 1.1291518341618885 | validation: 0.7829971045543399]
	TIME [epoch: 8.49 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6510792219470878		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.6510792219470878 | validation: 0.6932920220822367]
	TIME [epoch: 8.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5892213890424708		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.5892213890424708 | validation: 0.5274434084940991]
	TIME [epoch: 8.52 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662881995965347		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.3662881995965347 | validation: 0.7616498461574648]
	TIME [epoch: 8.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44125294916901564		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.44125294916901564 | validation: 0.3186918611557915]
	TIME [epoch: 8.49 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3991438061669818		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.3991438061669818 | validation: 0.3978038840956979]
	TIME [epoch: 8.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3783157211901743		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.3783157211901743 | validation: 0.37633517653832255]
	TIME [epoch: 8.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4047486724959808		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.4047486724959808 | validation: 0.25983277579772013]
	TIME [epoch: 8.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3063763198163366		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.3063763198163366 | validation: 0.41099357587494967]
	TIME [epoch: 8.49 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4159687861333029		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.4159687861333029 | validation: 0.26148535314873445]
	TIME [epoch: 8.51 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4531438564147557		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.4531438564147557 | validation: 0.4362942715199367]
	TIME [epoch: 8.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3652594047592384		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.3652594047592384 | validation: 0.3327000079138044]
	TIME [epoch: 8.51 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4351530641629844		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.4351530641629844 | validation: 0.29236887957169705]
	TIME [epoch: 8.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4243289777598063		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.4243289777598063 | validation: 0.9102102511134547]
	TIME [epoch: 8.51 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4786392466797945		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.4786392466797945 | validation: 0.37028058393534924]
	TIME [epoch: 8.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3307196722351907		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.3307196722351907 | validation: 0.48057826537860515]
	TIME [epoch: 8.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39742301551336906		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.39742301551336906 | validation: 0.3446053429923003]
	TIME [epoch: 8.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44984936479975807		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.44984936479975807 | validation: 0.2262912435725447]
	TIME [epoch: 8.52 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39464554661235507		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.39464554661235507 | validation: 0.430756440047264]
	TIME [epoch: 8.51 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4893558126098192		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.4893558126098192 | validation: 0.3108917566887573]
	TIME [epoch: 8.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39315719650724584		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.39315719650724584 | validation: 0.26142121103017535]
	TIME [epoch: 8.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35818941096191115		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.35818941096191115 | validation: 0.33057224380339456]
	TIME [epoch: 8.52 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37096583129989774		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.37096583129989774 | validation: 0.22355155837228327]
	TIME [epoch: 8.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3203615367072149		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.3203615367072149 | validation: 0.3741865198685871]
	TIME [epoch: 8.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5217160063379601		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.5217160063379601 | validation: 0.5987558668401372]
	TIME [epoch: 8.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3984415187513092		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.3984415187513092 | validation: 0.27559997820878723]
	TIME [epoch: 8.53 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3544358373176557		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.3544358373176557 | validation: 0.4975807115059171]
	TIME [epoch: 8.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3996579049331735		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.3996579049331735 | validation: 0.44826706597716925]
	TIME [epoch: 8.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32700368313477884		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.32700368313477884 | validation: 0.26143754998868196]
	TIME [epoch: 8.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36328565186641815		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.36328565186641815 | validation: 0.42977179739482874]
	TIME [epoch: 8.53 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4004757918183082		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.4004757918183082 | validation: 0.569746923186629]
	TIME [epoch: 8.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41631475138663204		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.41631475138663204 | validation: 0.39131079652193257]
	TIME [epoch: 8.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4112255633046732		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.4112255633046732 | validation: 0.34472756869498855]
	TIME [epoch: 8.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3211912383089507		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.3211912383089507 | validation: 0.35512477970444356]
	TIME [epoch: 8.53 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41277189291555355		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.41277189291555355 | validation: 0.32637920310328417]
	TIME [epoch: 8.49 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42595875796875937		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.42595875796875937 | validation: 0.3049294209996618]
	TIME [epoch: 8.49 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500256156937359		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.3500256156937359 | validation: 0.24489266302505605]
	TIME [epoch: 8.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3610514879336449		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.3610514879336449 | validation: 0.24487422825108296]
	TIME [epoch: 8.52 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3650669401794359		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.3650669401794359 | validation: 0.38639829132610826]
	TIME [epoch: 8.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33034384961700136		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.33034384961700136 | validation: 0.37209939612307696]
	TIME [epoch: 8.49 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.315619279645531		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.315619279645531 | validation: 0.822734019465394]
	TIME [epoch: 8.51 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3755180170435107		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.3755180170435107 | validation: 0.2730642118091192]
	TIME [epoch: 8.52 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4279551075058151		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.4279551075058151 | validation: 0.2117204482313626]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34683873836929613		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.34683873836929613 | validation: 0.5003589951299163]
	TIME [epoch: 8.51 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917063425380277		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.3917063425380277 | validation: 0.3036267770012891]
	TIME [epoch: 8.52 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33438811905524285		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.33438811905524285 | validation: 0.2228880951042572]
	TIME [epoch: 8.51 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3443151400520219		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.3443151400520219 | validation: 0.5483811662460294]
	TIME [epoch: 8.49 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40499286387478695		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.40499286387478695 | validation: 0.30271040340851485]
	TIME [epoch: 8.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3839254929924599		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.3839254929924599 | validation: 0.40083114119513297]
	TIME [epoch: 8.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4238247963709587		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.4238247963709587 | validation: 0.751893595112328]
	TIME [epoch: 8.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6433413474275352		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.6433413474275352 | validation: 0.6393505705083589]
	TIME [epoch: 8.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4400473853383766		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.4400473853383766 | validation: 0.5018817454122313]
	TIME [epoch: 8.49 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3866245027113046		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.3866245027113046 | validation: 0.4138446947698854]
	TIME [epoch: 8.52 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8886826350491068		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.8886826350491068 | validation: 0.3174948159690861]
	TIME [epoch: 8.49 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37724322946631517		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.37724322946631517 | validation: 0.3767296916308078]
	TIME [epoch: 8.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4755304501656616		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 1.4755304501656616 | validation: 0.4956246057229634]
	TIME [epoch: 8.49 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39377765628963757		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.39377765628963757 | validation: 0.26184267182604126]
	TIME [epoch: 8.51 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1263662665093968		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 1.1263662665093968 | validation: 2.1097454327979275]
	TIME [epoch: 8.51 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.509327543379196		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.509327543379196 | validation: 0.5779424056252064]
	TIME [epoch: 8.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3324901740780806		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.3324901740780806 | validation: 0.6194893849336927]
	TIME [epoch: 8.49 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4387390393969218		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.4387390393969218 | validation: 0.21881020688979647]
	TIME [epoch: 8.52 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4656275557230372		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.4656275557230372 | validation: 0.40441487948571586]
	TIME [epoch: 8.49 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3346436135065536		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.3346436135065536 | validation: 0.5701099084439049]
	TIME [epoch: 8.49 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40578572979892974		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.40578572979892974 | validation: 0.27120575724336354]
	TIME [epoch: 8.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29746379154837554		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.29746379154837554 | validation: 0.20585225448432154]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32764832173139424		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.32764832173139424 | validation: 0.3727810898925399]
	TIME [epoch: 8.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4820017563408229		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.4820017563408229 | validation: 0.23628772727915076]
	TIME [epoch: 8.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40847722050899293		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.40847722050899293 | validation: 0.3231154344306444]
	TIME [epoch: 8.49 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3732718276636059		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.3732718276636059 | validation: 0.32430307809823267]
	TIME [epoch: 8.51 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4101155619190471		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.4101155619190471 | validation: 0.41387239425394284]
	TIME [epoch: 8.49 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3075302334066097		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.3075302334066097 | validation: 0.4216320238535042]
	TIME [epoch: 8.48 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5085475952085325		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.5085475952085325 | validation: 0.6193608633508919]
	TIME [epoch: 8.49 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5486296917868545		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.5486296917868545 | validation: 0.6438658892223463]
	TIME [epoch: 8.51 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47264798782459116		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.47264798782459116 | validation: 0.28991084873027273]
	TIME [epoch: 8.48 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3618559796785764		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.3618559796785764 | validation: 0.37789167246390315]
	TIME [epoch: 8.48 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3485451867930831		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.3485451867930831 | validation: 0.29603549548159513]
	TIME [epoch: 8.49 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4772669130477934		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.4772669130477934 | validation: 0.41162225600707514]
	TIME [epoch: 8.51 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36238298792633844		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.36238298792633844 | validation: 0.4521212054713074]
	TIME [epoch: 8.49 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3287145622904078		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.3287145622904078 | validation: 0.26492180819248673]
	TIME [epoch: 8.49 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34874329102632456		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.34874329102632456 | validation: 0.2177395925059233]
	TIME [epoch: 8.49 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31690845475908075		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.31690845475908075 | validation: 0.3288833287561304]
	TIME [epoch: 8.51 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.385411408633053		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.385411408633053 | validation: 0.22518642823293833]
	TIME [epoch: 8.49 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702157495315475		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.2702157495315475 | validation: 0.3410103750526823]
	TIME [epoch: 8.48 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.370819447768591		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.370819447768591 | validation: 0.29044466966525007]
	TIME [epoch: 8.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3357546888046798		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.3357546888046798 | validation: 0.3317908182451187]
	TIME [epoch: 8.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3257500482048963		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.3257500482048963 | validation: 0.6521510786364683]
	TIME [epoch: 8.48 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3792711794669757		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.3792711794669757 | validation: 0.24923979532470286]
	TIME [epoch: 8.49 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40145971621333876		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.40145971621333876 | validation: 0.3623472876998154]
	TIME [epoch: 8.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31863009609539505		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.31863009609539505 | validation: 0.3248222207332685]
	TIME [epoch: 8.49 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3000279215110849		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.3000279215110849 | validation: 0.34907780676896905]
	TIME [epoch: 8.48 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4418318542449895		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.4418318542449895 | validation: 0.44240653927845597]
	TIME [epoch: 8.48 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.315856860626635		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.315856860626635 | validation: 0.30807895390590845]
	TIME [epoch: 8.51 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31377932737553343		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.31377932737553343 | validation: 0.3413870105813889]
	TIME [epoch: 8.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4174861978593169		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.4174861978593169 | validation: 0.42474637794742043]
	TIME [epoch: 8.49 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32978782588608024		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.32978782588608024 | validation: 0.3241726486177229]
	TIME [epoch: 8.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3254085688766691		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.3254085688766691 | validation: 0.2396595993753443]
	TIME [epoch: 8.51 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3197276508174104		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.3197276508174104 | validation: 0.3749669151673221]
	TIME [epoch: 8.49 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3180489495486191		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.3180489495486191 | validation: 0.3599913067955541]
	TIME [epoch: 8.49 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3703504911764267		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.3703504911764267 | validation: 0.6126823908629943]
	TIME [epoch: 8.48 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42085170993263255		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.42085170993263255 | validation: 0.33665663576905974]
	TIME [epoch: 8.52 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3029989142238635		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.3029989142238635 | validation: 0.6463532099696473]
	TIME [epoch: 8.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4052597771933183		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.4052597771933183 | validation: 0.32993601124300553]
	TIME [epoch: 8.49 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3508563015096203		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.3508563015096203 | validation: 0.36748807919776794]
	TIME [epoch: 8.49 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40413155382043675		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.40413155382043675 | validation: 0.3536959994496879]
	TIME [epoch: 8.52 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3859777688347691		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.3859777688347691 | validation: 0.4067412094261471]
	TIME [epoch: 8.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1675029290229575		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 2.1675029290229575 | validation: 0.8925791733013775]
	TIME [epoch: 8.49 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4500041039146606		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.4500041039146606 | validation: 0.5752433078273333]
	TIME [epoch: 8.49 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822568567456033		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.2822568567456033 | validation: 0.34472124921237224]
	TIME [epoch: 8.51 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3399405542672919		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.3399405542672919 | validation: 0.6192914585732161]
	TIME [epoch: 8.49 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2941863840246203		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.2941863840246203 | validation: 0.8553641512340726]
	TIME [epoch: 8.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36418663702439186		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.36418663702439186 | validation: 0.251110241584695]
	TIME [epoch: 8.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929090191199757		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.2929090191199757 | validation: 0.48440926263229733]
	TIME [epoch: 8.53 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4382369693304316		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.4382369693304316 | validation: 0.8161007452565796]
	TIME [epoch: 8.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3800796121815152		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.3800796121815152 | validation: 0.2779606342590222]
	TIME [epoch: 8.49 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40567149503190364		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.40567149503190364 | validation: 0.42821088060430246]
	TIME [epoch: 8.49 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30648576964193075		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.30648576964193075 | validation: 0.2986798435482743]
	TIME [epoch: 8.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28416045855457517		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.28416045855457517 | validation: 0.6015236223972827]
	TIME [epoch: 8.49 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30088339742767056		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.30088339742767056 | validation: 0.2309383897222459]
	TIME [epoch: 8.49 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3682623343843069		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.3682623343843069 | validation: 0.39515607256974566]
	TIME [epoch: 8.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5363451618025439		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.5363451618025439 | validation: 0.24499116071816096]
	TIME [epoch: 8.51 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126014595521536		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.3126014595521536 | validation: 0.3620105659707302]
	TIME [epoch: 8.49 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4332880055482555		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.4332880055482555 | validation: 0.47072397453065784]
	TIME [epoch: 8.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3508221525401048		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.3508221525401048 | validation: 0.35266664426508504]
	TIME [epoch: 8.51 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3539267722346235		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.3539267722346235 | validation: 0.35122988026156454]
	TIME [epoch: 8.51 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4023641211666106		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.4023641211666106 | validation: 0.4286546318800184]
	TIME [epoch: 8.49 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3972545675943711		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.3972545675943711 | validation: 0.4372821797878605]
	TIME [epoch: 8.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3219234073970537		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.3219234073970537 | validation: 0.27845906244757]
	TIME [epoch: 8.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31649964308377043		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.31649964308377043 | validation: 0.3670722530279248]
	TIME [epoch: 8.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30654670892605		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.30654670892605 | validation: 0.5306811389549375]
	TIME [epoch: 8.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36661597389966893		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.36661597389966893 | validation: 0.4387265038785957]
	TIME [epoch: 8.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3469670246357447		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.3469670246357447 | validation: 0.2609810597592196]
	TIME [epoch: 8.51 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4725523525185114		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.4725523525185114 | validation: 0.544094203419377]
	TIME [epoch: 8.51 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3541755209714518		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.3541755209714518 | validation: 0.3935066021149311]
	TIME [epoch: 8.49 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29639015491541554		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.29639015491541554 | validation: 0.2526910622517504]
	TIME [epoch: 8.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.274722062689478		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.274722062689478 | validation: 0.4702278256301046]
	TIME [epoch: 8.52 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.282598466329394		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.282598466329394 | validation: 0.2491284657804682]
	TIME [epoch: 8.51 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3166108076514465		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.3166108076514465 | validation: 0.6844502046353814]
	TIME [epoch: 8.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40500945415411377		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.40500945415411377 | validation: 0.4179467026723056]
	TIME [epoch: 8.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3447588208952875		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.3447588208952875 | validation: 0.31457234151607516]
	TIME [epoch: 8.53 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45190742007773094		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.45190742007773094 | validation: 0.3692393805636198]
	TIME [epoch: 8.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.424576815773262		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.424576815773262 | validation: 0.23633387177657608]
	TIME [epoch: 8.51 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33081796506162464		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.33081796506162464 | validation: 0.26979990207926097]
	TIME [epoch: 8.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36752275359862485		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.36752275359862485 | validation: 0.475480500051365]
	TIME [epoch: 8.53 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38301233690994		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.38301233690994 | validation: 0.25872842683809005]
	TIME [epoch: 8.51 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844774008251246		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.2844774008251246 | validation: 0.3626104151632696]
	TIME [epoch: 8.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32184353218649875		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.32184353218649875 | validation: 0.351693343557702]
	TIME [epoch: 8.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3196816608274314		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.3196816608274314 | validation: 0.23223243814811284]
	TIME [epoch: 8.52 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27811700477292944		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.27811700477292944 | validation: 0.5007190820269158]
	TIME [epoch: 8.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4432193786909265		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.4432193786909265 | validation: 0.2505431489613461]
	TIME [epoch: 8.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2753239337325101		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.2753239337325101 | validation: 0.4547893609619274]
	TIME [epoch: 8.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4502681256153826		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.4502681256153826 | validation: 0.6214829617320934]
	TIME [epoch: 8.53 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.342865787867242		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.342865787867242 | validation: 0.20819729299327522]
	TIME [epoch: 8.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3176725352026209		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.3176725352026209 | validation: 0.28019150036594687]
	TIME [epoch: 8.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27878917813611037		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.27878917813611037 | validation: 0.28733622083948884]
	TIME [epoch: 8.49 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33716350360921643		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.33716350360921643 | validation: 0.26406213121554967]
	TIME [epoch: 8.53 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3329353735217956		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.3329353735217956 | validation: 0.4018520076978318]
	TIME [epoch: 8.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3488420954322339		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.3488420954322339 | validation: 0.2302493465397316]
	TIME [epoch: 8.49 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711533639692864		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.2711533639692864 | validation: 0.40310849050124553]
	TIME [epoch: 8.49 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3253812120896934		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.3253812120896934 | validation: 0.23030751176788922]
	TIME [epoch: 8.51 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33785549908669454		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.33785549908669454 | validation: 0.3072302701130939]
	TIME [epoch: 8.49 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3346279727153814		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.3346279727153814 | validation: 0.23831947366903]
	TIME [epoch: 8.49 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37099393585769		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.37099393585769 | validation: 0.31576555941086404]
	TIME [epoch: 8.51 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4092478224300452		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.4092478224300452 | validation: 0.3305115146881755]
	TIME [epoch: 8.51 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3220797574274158		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.3220797574274158 | validation: 0.22006953365383072]
	TIME [epoch: 8.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.270036413049467		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.270036413049467 | validation: 0.1707179148787325]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046772348735854		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.3046772348735854 | validation: 0.26767525257903113]
	TIME [epoch: 8.53 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2568266410764685		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.2568266410764685 | validation: 0.1900404402431154]
	TIME [epoch: 8.53 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27131678516742025		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.27131678516742025 | validation: 0.2315800796339784]
	TIME [epoch: 8.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2765517870158796		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.2765517870158796 | validation: 0.21824489613828665]
	TIME [epoch: 8.51 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31660814407592636		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.31660814407592636 | validation: 0.3119374961121977]
	TIME [epoch: 8.54 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2949375708258254		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.2949375708258254 | validation: 0.24787727320763764]
	TIME [epoch: 8.52 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970615346999916		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.2970615346999916 | validation: 0.3490425783390411]
	TIME [epoch: 8.52 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2748268428924672		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.2748268428924672 | validation: 0.30274258232792994]
	TIME [epoch: 8.52 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4943744268160595		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.4943744268160595 | validation: 0.4294837691683145]
	TIME [epoch: 8.54 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2673777613055243		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.2673777613055243 | validation: 0.5743521488179234]
	TIME [epoch: 8.52 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3554176325408648		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.3554176325408648 | validation: 0.25013448712737574]
	TIME [epoch: 8.52 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2580309565430145		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.2580309565430145 | validation: 0.25781141457449697]
	TIME [epoch: 8.52 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29259551743033496		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.29259551743033496 | validation: 0.4694610810203844]
	TIME [epoch: 8.54 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3522343284836572		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.3522343284836572 | validation: 0.29290427754415876]
	TIME [epoch: 8.52 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3455275500475121		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.3455275500475121 | validation: 0.17088683337803012]
	TIME [epoch: 8.52 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28460157029081895		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.28460157029081895 | validation: 0.20468640234252322]
	TIME [epoch: 8.52 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2858936610896998		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.2858936610896998 | validation: 0.23445697524263942]
	TIME [epoch: 8.55 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456145767654076		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.2456145767654076 | validation: 0.2002050317030195]
	TIME [epoch: 8.52 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2865862270589242		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.2865862270589242 | validation: 0.2693878738856063]
	TIME [epoch: 8.52 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37458477367484366		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.37458477367484366 | validation: 0.29262831867942396]
	TIME [epoch: 8.52 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27222126769145355		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.27222126769145355 | validation: 0.20727110750759611]
	TIME [epoch: 8.54 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2627059305963544		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.2627059305963544 | validation: 0.4063384435614419]
	TIME [epoch: 8.52 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3054315697761039		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.3054315697761039 | validation: 0.5192023758407229]
	TIME [epoch: 8.52 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44995919799027745		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.44995919799027745 | validation: 3.4544665180204235]
	TIME [epoch: 8.52 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1517805047206204		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 2.1517805047206204 | validation: 0.5429844238840122]
	TIME [epoch: 8.54 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077009938899116		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.3077009938899116 | validation: 0.2598689255063352]
	TIME [epoch: 8.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3965021670880987		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.3965021670880987 | validation: 0.26593774991662733]
	TIME [epoch: 8.52 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2808960900468941		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.2808960900468941 | validation: 0.2240754935368714]
	TIME [epoch: 8.53 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3296919662681944		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.3296919662681944 | validation: 0.5773262878980066]
	TIME [epoch: 8.54 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7748335501798221		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.7748335501798221 | validation: 0.2363038833121403]
	TIME [epoch: 8.52 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.361143071180047		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.361143071180047 | validation: 0.36007789355713116]
	TIME [epoch: 8.52 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2848609765097086		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.2848609765097086 | validation: 0.28118509080119475]
	TIME [epoch: 8.53 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.309289121836007		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.309289121836007 | validation: 0.3153007358808121]
	TIME [epoch: 8.53 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737813899976168		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.2737813899976168 | validation: 0.23771431768228726]
	TIME [epoch: 8.52 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2826919259748334		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.2826919259748334 | validation: 0.5036443523673737]
	TIME [epoch: 8.51 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3906381955285746		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.3906381955285746 | validation: 0.4139232454336443]
	TIME [epoch: 8.53 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28636059253151847		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.28636059253151847 | validation: 0.15691066630949344]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2778106333636085		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.2778106333636085 | validation: 0.4795526538155839]
	TIME [epoch: 8.51 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28590683787241344		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.28590683787241344 | validation: 0.31104946824880964]
	TIME [epoch: 8.51 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27125311486613723		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.27125311486613723 | validation: 0.20970011338684585]
	TIME [epoch: 8.53 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22165963714739817		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.22165963714739817 | validation: 0.2636442153278856]
	TIME [epoch: 8.52 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2989592086816597		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.2989592086816597 | validation: 0.3030676532392321]
	TIME [epoch: 8.51 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24968673520890045		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.24968673520890045 | validation: 0.323779853963704]
	TIME [epoch: 8.51 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28078829643442355		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.28078829643442355 | validation: 0.2549931805366815]
	TIME [epoch: 8.54 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23555773093192958		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.23555773093192958 | validation: 0.5735160775879752]
	TIME [epoch: 8.52 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3622925988207314		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.3622925988207314 | validation: 0.3465969201789767]
	TIME [epoch: 8.51 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2776057906894102		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.2776057906894102 | validation: 0.4880044859712945]
	TIME [epoch: 8.51 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5266460482315202		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.5266460482315202 | validation: 3.3503158698043083]
	TIME [epoch: 8.53 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1234987284263545		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 1.1234987284263545 | validation: 0.265011649977582]
	TIME [epoch: 8.51 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23851240303580235		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.23851240303580235 | validation: 0.15666379141316272]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22373822366287185		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.22373822366287185 | validation: 0.2853059009107758]
	TIME [epoch: 8.51 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587483689044759		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.2587483689044759 | validation: 0.32712584365910025]
	TIME [epoch: 8.53 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31515849509508975		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.31515849509508975 | validation: 0.15727012002776505]
	TIME [epoch: 8.51 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.297106921968183		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.297106921968183 | validation: 0.23755123819197715]
	TIME [epoch: 8.51 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3129088141161213		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.3129088141161213 | validation: 0.5430235364778692]
	TIME [epoch: 8.51 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3043234009439912		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.3043234009439912 | validation: 0.18456714512813285]
	TIME [epoch: 8.53 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37146836929682375		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.37146836929682375 | validation: 0.323207030798234]
	TIME [epoch: 8.51 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29069549913860726		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.29069549913860726 | validation: 0.4171623878756445]
	TIME [epoch: 8.51 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3926224478658926		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.3926224478658926 | validation: 0.3068534610486031]
	TIME [epoch: 8.51 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29206065284101074		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.29206065284101074 | validation: 0.2628326254367337]
	TIME [epoch: 8.53 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23454187949749503		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.23454187949749503 | validation: 0.2845705159030998]
	TIME [epoch: 8.51 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24062941867268606		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.24062941867268606 | validation: 0.19328013113247772]
	TIME [epoch: 8.51 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37647345263525134		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.37647345263525134 | validation: 0.2775229860896503]
	TIME [epoch: 8.52 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24336854807915734		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.24336854807915734 | validation: 0.39980184006013275]
	TIME [epoch: 8.53 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3340711648413928		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.3340711648413928 | validation: 0.2169297055418894]
	TIME [epoch: 8.51 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2799056964806162		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.2799056964806162 | validation: 0.29046112653730194]
	TIME [epoch: 8.51 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26647484691344125		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.26647484691344125 | validation: 0.3848241372523818]
	TIME [epoch: 8.52 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31513698585305705		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.31513698585305705 | validation: 0.28583535705937035]
	TIME [epoch: 8.52 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24276215095950676		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.24276215095950676 | validation: 0.21225170502784738]
	TIME [epoch: 8.51 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24760323463299933		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.24760323463299933 | validation: 0.7305223795517225]
	TIME [epoch: 8.51 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3294602056274333		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.3294602056274333 | validation: 0.22320846737106093]
	TIME [epoch: 8.53 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28500750467514957		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.28500750467514957 | validation: 0.16775343487902794]
	TIME [epoch: 8.52 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25743049897932285		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.25743049897932285 | validation: 0.12495768926306766]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2697630278686642		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.2697630278686642 | validation: 0.2788306270223144]
	TIME [epoch: 8.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2147774519854328		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.2147774519854328 | validation: 0.5955961739181674]
	TIME [epoch: 8.52 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34552052116077236		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.34552052116077236 | validation: 0.48448252572767153]
	TIME [epoch: 8.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39072650740206955		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.39072650740206955 | validation: 0.36681481051682563]
	TIME [epoch: 8.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803958345856102		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.2803958345856102 | validation: 0.2842745866363501]
	TIME [epoch: 8.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34789198082777106		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.34789198082777106 | validation: 0.5998254426470343]
	TIME [epoch: 8.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6200319561676826		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.6200319561676826 | validation: 0.5223074938220442]
	TIME [epoch: 8.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.311235043595875		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.311235043595875 | validation: 0.632424513752522]
	TIME [epoch: 8.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30008969266470015		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.30008969266470015 | validation: 0.4579274199475448]
	TIME [epoch: 8.49 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2773632556574696		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.2773632556574696 | validation: 0.4596048868349286]
	TIME [epoch: 8.52 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2687293003769326		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.2687293003769326 | validation: 0.31552665939684543]
	TIME [epoch: 8.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29246885960378155		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.29246885960378155 | validation: 0.26621928678675405]
	TIME [epoch: 8.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3591194319175931		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.3591194319175931 | validation: 0.22857496746226455]
	TIME [epoch: 8.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30019525042239975		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.30019525042239975 | validation: 0.30018181497860974]
	TIME [epoch: 8.52 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32917451857657265		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.32917451857657265 | validation: 0.20351480369179634]
	TIME [epoch: 8.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22727415246611535		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.22727415246611535 | validation: 0.21275488413226099]
	TIME [epoch: 8.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22555664887257376		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.22555664887257376 | validation: 0.1797071248138059]
	TIME [epoch: 8.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2413961009034798		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.2413961009034798 | validation: 0.22205673315878582]
	TIME [epoch: 8.53 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23601099275916654		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.23601099275916654 | validation: 0.2711844780553122]
	TIME [epoch: 8.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6515516328443755		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.6515516328443755 | validation: 0.38009454926001834]
	TIME [epoch: 8.49 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26758460020148866		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.26758460020148866 | validation: 0.3272956563579098]
	TIME [epoch: 8.51 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2793710606787895		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.2793710606787895 | validation: 0.23040099813686463]
	TIME [epoch: 8.51 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.685167340520303		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 1.685167340520303 | validation: 3.0479149476526004]
	TIME [epoch: 8.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4511365365131983		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 1.4511365365131983 | validation: 0.2591990036030355]
	TIME [epoch: 8.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2519080318148321		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 1.2519080318148321 | validation: 2.985189888445408]
	TIME [epoch: 8.51 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.342025358414354		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 1.342025358414354 | validation: 1.5164668471925578]
	TIME [epoch: 8.51 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31263195304186275		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.31263195304186275 | validation: 0.1951413685636001]
	TIME [epoch: 8.49 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29079719316305486		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.29079719316305486 | validation: 0.31040715476902303]
	TIME [epoch: 8.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2713753719693412		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.2713753719693412 | validation: 0.5706277251278107]
	TIME [epoch: 8.51 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3136770292970259		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.3136770292970259 | validation: 0.23201449514230582]
	TIME [epoch: 8.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2610110912242426		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.2610110912242426 | validation: 0.2268964875292876]
	TIME [epoch: 8.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25592396010978047		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.25592396010978047 | validation: 0.2930419839787669]
	TIME [epoch: 8.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28351022238056584		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.28351022238056584 | validation: 0.24379355684580895]
	TIME [epoch: 8.51 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5372803189340272		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 1.5372803189340272 | validation: 0.19396533883767864]
	TIME [epoch: 8.51 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23580581889830757		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.23580581889830757 | validation: 0.24595803082409612]
	TIME [epoch: 8.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24858568242188211		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.24858568242188211 | validation: 0.1753529471375306]
	TIME [epoch: 8.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29390214148811716		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.29390214148811716 | validation: 0.28091544451281436]
	TIME [epoch: 8.51 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35359527466329316		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.35359527466329316 | validation: 0.48812228335343]
	TIME [epoch: 8.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29997634965257636		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.29997634965257636 | validation: 0.44243271237399323]
	TIME [epoch: 8.49 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.278112006187731		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.278112006187731 | validation: 0.29030951614400513]
	TIME [epoch: 8.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587470639364845		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.2587470639364845 | validation: 0.17522511191536372]
	TIME [epoch: 8.52 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22786578193922585		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.22786578193922585 | validation: 0.22006803636115224]
	TIME [epoch: 8.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3045859950776681		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.3045859950776681 | validation: 0.5521695779054527]
	TIME [epoch: 8.49 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2854935875250917		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.2854935875250917 | validation: 0.13805386984351264]
	TIME [epoch: 8.49 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24393146845983668		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.24393146845983668 | validation: 0.25219144267094495]
	TIME [epoch: 8.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26918927338126414		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.26918927338126414 | validation: 0.2152783194461054]
	TIME [epoch: 8.49 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22550395545936625		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.22550395545936625 | validation: 0.17533374076818792]
	TIME [epoch: 8.49 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22784889130225325		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.22784889130225325 | validation: 0.1834184600656763]
	TIME [epoch: 8.49 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3999645127078975		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.3999645127078975 | validation: 0.22318632909700248]
	TIME [epoch: 8.52 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28107046346370235		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.28107046346370235 | validation: 0.25466480152296533]
	TIME [epoch: 8.49 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23327725904342805		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.23327725904342805 | validation: 0.2531835063853804]
	TIME [epoch: 8.49 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25621332482506604		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.25621332482506604 | validation: 0.15728708524046198]
	TIME [epoch: 8.49 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30329137211769397		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.30329137211769397 | validation: 0.36679019142964386]
	TIME [epoch: 8.52 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861497906880125		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.2861497906880125 | validation: 0.3771289650851226]
	TIME [epoch: 8.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26035130207655777		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.26035130207655777 | validation: 0.15541223066533694]
	TIME [epoch: 8.49 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2295108458637412		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.2295108458637412 | validation: 0.268217655014967]
	TIME [epoch: 8.49 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25911591187685523		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.25911591187685523 | validation: 0.14705196338388798]
	TIME [epoch: 8.52 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26099282486279474		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.26099282486279474 | validation: 0.14079184049290838]
	TIME [epoch: 8.49 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25526226745274627		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.25526226745274627 | validation: 0.2121471024815535]
	TIME [epoch: 8.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22175283647559577		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.22175283647559577 | validation: 0.17716713764658498]
	TIME [epoch: 8.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29285871176026285		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.29285871176026285 | validation: 0.26651061433817985]
	TIME [epoch: 8.51 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30536367659260844		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.30536367659260844 | validation: 0.24073124434166523]
	TIME [epoch: 8.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2826751771954297		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.2826751771954297 | validation: 0.27894914666343706]
	TIME [epoch: 8.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2229870943847409		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.2229870943847409 | validation: 0.5011148883941232]
	TIME [epoch: 8.51 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2550639262429121		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.2550639262429121 | validation: 0.1936218908751981]
	TIME [epoch: 8.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22766906261990663		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.22766906261990663 | validation: 0.18984313562870336]
	TIME [epoch: 8.49 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2354227944130213		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.2354227944130213 | validation: 0.1680836556621736]
	TIME [epoch: 8.49 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23888646738447794		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.23888646738447794 | validation: 0.32829406040945497]
	TIME [epoch: 8.51 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23503487712367183		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.23503487712367183 | validation: 0.15267526141163745]
	TIME [epoch: 8.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2450200018862696		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.2450200018862696 | validation: 0.19548660752781477]
	TIME [epoch: 8.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23727154587883778		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.23727154587883778 | validation: 0.16265484616543988]
	TIME [epoch: 8.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24997602712855369		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.24997602712855369 | validation: 0.19236057894120623]
	TIME [epoch: 8.51 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18939171407595862		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.18939171407595862 | validation: 0.2804109039713677]
	TIME [epoch: 8.51 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33293072458215994		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.33293072458215994 | validation: 0.26656045937535244]
	TIME [epoch: 8.49 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22314648281187682		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.22314648281187682 | validation: 0.2612896244300752]
	TIME [epoch: 8.49 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3275261701963708		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.3275261701963708 | validation: 0.20953752043747073]
	TIME [epoch: 8.51 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23294020077428007		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.23294020077428007 | validation: 0.14738812654344718]
	TIME [epoch: 8.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4316491494376008		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.4316491494376008 | validation: 0.3105536969874878]
	TIME [epoch: 8.49 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4768682016033451		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.4768682016033451 | validation: 0.2877206350787075]
	TIME [epoch: 8.49 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26430615800904395		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.26430615800904395 | validation: 0.8020758669268064]
	TIME [epoch: 8.52 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5067704257830881		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.5067704257830881 | validation: 1.2339485398884584]
	TIME [epoch: 8.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105977945589267		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.3105977945589267 | validation: 0.24168411964531306]
	TIME [epoch: 8.49 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20815413730565138		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.20815413730565138 | validation: 0.24448194493951494]
	TIME [epoch: 8.49 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25983546757052306		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.25983546757052306 | validation: 0.248246898935642]
	TIME [epoch: 8.52 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20551219795649228		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.20551219795649228 | validation: 0.3729204863188482]
	TIME [epoch: 8.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25657425019751035		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.25657425019751035 | validation: 0.26360177436988896]
	TIME [epoch: 8.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28564356559848514		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.28564356559848514 | validation: 0.21954504437925149]
	TIME [epoch: 8.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19722630812375033		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.19722630812375033 | validation: 0.24741571074302324]
	TIME [epoch: 8.52 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23199819216828454		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.23199819216828454 | validation: 0.4346651990629778]
	TIME [epoch: 8.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2429623592157319		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.2429623592157319 | validation: 0.17523007112410974]
	TIME [epoch: 8.49 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19448577950546786		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.19448577950546786 | validation: 0.14007781829709212]
	TIME [epoch: 8.49 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2419132147478149		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.2419132147478149 | validation: 0.2367431252984068]
	TIME [epoch: 8.53 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1704017246933196		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.1704017246933196 | validation: 0.24653009090579514]
	TIME [epoch: 8.49 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2353386130903357		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.2353386130903357 | validation: 0.15122955382961356]
	TIME [epoch: 8.49 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16290152209114703		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.16290152209114703 | validation: 0.18147587475275204]
	TIME [epoch: 8.49 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700587929784625		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.2700587929784625 | validation: 0.4874254416530328]
	TIME [epoch: 8.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28959112407587756		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.28959112407587756 | validation: 0.217389593008086]
	TIME [epoch: 8.49 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2552799944282374		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.2552799944282374 | validation: 0.18670666851595288]
	TIME [epoch: 8.49 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25990159291092213		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.25990159291092213 | validation: 0.19524709692670478]
	TIME [epoch: 8.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20155919024991792		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.20155919024991792 | validation: 0.27006173687954776]
	TIME [epoch: 8.51 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24214547494197758		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.24214547494197758 | validation: 0.1608486980652985]
	TIME [epoch: 8.49 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26317071366135303		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.26317071366135303 | validation: 0.2700445405275437]
	TIME [epoch: 8.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2394802111982932		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.2394802111982932 | validation: 0.23712775043139717]
	TIME [epoch: 8.49 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28137362989694825		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.28137362989694825 | validation: 0.35637451440255774]
	TIME [epoch: 8.51 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734195025772127		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.2734195025772127 | validation: 0.16289938060167358]
	TIME [epoch: 8.49 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22554231639751587		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.22554231639751587 | validation: 0.20382127281983553]
	TIME [epoch: 8.49 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19561702823776597		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.19561702823776597 | validation: 0.22941230325429302]
	TIME [epoch: 8.51 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18897970526470642		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.18897970526470642 | validation: 0.20009867076220578]
	TIME [epoch: 8.51 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3417986467774788		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.3417986467774788 | validation: 0.2210141406759285]
	TIME [epoch: 8.49 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566734585704881		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.2566734585704881 | validation: 0.27928564718777116]
	TIME [epoch: 8.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2509719805700549		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.2509719805700549 | validation: 0.20110199029082643]
	TIME [epoch: 8.51 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18435638255696088		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.18435638255696088 | validation: 0.1812920639919373]
	TIME [epoch: 8.51 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.262489554585274		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.262489554585274 | validation: 0.14878329061747556]
	TIME [epoch: 8.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.218781027111182		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.218781027111182 | validation: 0.3459700024983798]
	TIME [epoch: 8.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2432761109416653		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.2432761109416653 | validation: 0.16347615765653944]
	TIME [epoch: 8.52 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22146200020025328		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.22146200020025328 | validation: 0.30575371005122626]
	TIME [epoch: 8.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2238436976124		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.2238436976124 | validation: 0.15510956078283974]
	TIME [epoch: 8.49 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18250097963022466		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.18250097963022466 | validation: 0.13415240698035968]
	TIME [epoch: 8.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20515854433883857		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.20515854433883857 | validation: 0.25751139803672896]
	TIME [epoch: 8.52 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2606195916902384		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.2606195916902384 | validation: 0.24733859919063328]
	TIME [epoch: 8.49 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20690613414087902		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.20690613414087902 | validation: 0.14380936410191203]
	TIME [epoch: 8.49 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20479046238967494		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.20479046238967494 | validation: 0.16019156066936432]
	TIME [epoch: 8.49 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30877006585939365		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.30877006585939365 | validation: 0.13373212498710368]
	TIME [epoch: 8.51 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34999262273220727		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.34999262273220727 | validation: 0.1354472619137767]
	TIME [epoch: 8.49 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2004387807464718		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.2004387807464718 | validation: 0.1323874970503151]
	TIME [epoch: 8.49 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18609868914247962		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.18609868914247962 | validation: 0.26662981654976375]
	TIME [epoch: 8.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20162796709843503		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.20162796709843503 | validation: 0.13121452774357134]
	TIME [epoch: 8.52 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19725263199089763		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.19725263199089763 | validation: 0.23607065827704793]
	TIME [epoch: 8.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2044042819659384		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.2044042819659384 | validation: 0.2163351469601223]
	TIME [epoch: 8.49 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029375786877218		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.2029375786877218 | validation: 0.12790709637456416]
	TIME [epoch: 8.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728341579170276		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.2728341579170276 | validation: 0.13636008957940032]
	TIME [epoch: 8.52 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20299860473505338		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.20299860473505338 | validation: 0.19259727588036651]
	TIME [epoch: 8.49 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.269737967298466		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.269737967298466 | validation: 0.4153054358455045]
	TIME [epoch: 8.49 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22686111889609376		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.22686111889609376 | validation: 0.16782756569959645]
	TIME [epoch: 8.49 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23163324978915031		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.23163324978915031 | validation: 0.19156191288232094]
	TIME [epoch: 8.52 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18612394057986137		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.18612394057986137 | validation: 0.1638682044585107]
	TIME [epoch: 8.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20544869181490782		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.20544869181490782 | validation: 0.29258878168045044]
	TIME [epoch: 8.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22970066351163493		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.22970066351163493 | validation: 0.25955960493727614]
	TIME [epoch: 8.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788974237133748		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.2788974237133748 | validation: 0.23021199791940583]
	TIME [epoch: 8.51 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2447019392532641		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.2447019392532641 | validation: 0.22867512321062866]
	TIME [epoch: 8.49 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22816020283757438		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.22816020283757438 | validation: 0.19553603633629024]
	TIME [epoch: 8.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17615405215881266		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.17615405215881266 | validation: 0.22355995866508374]
	TIME [epoch: 8.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2388426572493017		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.2388426572493017 | validation: 0.2622817182434183]
	TIME [epoch: 8.51 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18844333186091158		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.18844333186091158 | validation: 0.4950829418084717]
	TIME [epoch: 8.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3613836004116784		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.3613836004116784 | validation: 0.229423114828315]
	TIME [epoch: 8.49 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26211310271785176		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.26211310271785176 | validation: 0.23814831162088584]
	TIME [epoch: 8.51 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15766467798731126		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.15766467798731126 | validation: 0.1274181753158974]
	TIME [epoch: 8.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21799308032214942		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.21799308032214942 | validation: 0.1521275674234157]
	TIME [epoch: 8.49 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1618885039239924		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.1618885039239924 | validation: 0.24397836245612753]
	TIME [epoch: 8.49 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19043081841405793		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.19043081841405793 | validation: 0.16851997000094918]
	TIME [epoch: 8.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17837071521486061		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.17837071521486061 | validation: 0.2705534617846632]
	TIME [epoch: 8.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19500311593950317		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.19500311593950317 | validation: 0.27822315284193244]
	TIME [epoch: 8.49 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24340582607139605		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.24340582607139605 | validation: 0.12429099043677633]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16737125352600368		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.16737125352600368 | validation: 0.3643145130016534]
	TIME [epoch: 8.51 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26299093833925047		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.26299093833925047 | validation: 0.17285864298636894]
	TIME [epoch: 8.49 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19339186848282275		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.19339186848282275 | validation: 0.1918795506828345]
	TIME [epoch: 8.47 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23111571209066617		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.23111571209066617 | validation: 0.17260644851128074]
	TIME [epoch: 8.48 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26385505365256046		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.26385505365256046 | validation: 0.27948750685768975]
	TIME [epoch: 8.51 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24142023695253031		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.24142023695253031 | validation: 0.24709368545400967]
	TIME [epoch: 8.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2443776810724069		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.2443776810724069 | validation: 0.3102048942565897]
	TIME [epoch: 8.49 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18508900940866382		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.18508900940866382 | validation: 0.23950451992996905]
	TIME [epoch: 8.49 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22894363766036618		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.22894363766036618 | validation: 0.2121650353504098]
	TIME [epoch: 8.52 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1586016478906323		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.1586016478906323 | validation: 0.22531697876165063]
	TIME [epoch: 8.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17622661695324182		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.17622661695324182 | validation: 0.17350866149434005]
	TIME [epoch: 8.49 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4982600293420442		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.4982600293420442 | validation: 3.2293778599706138]
	TIME [epoch: 8.49 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.527433506940582		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.527433506940582 | validation: 0.22298236854373826]
	TIME [epoch: 8.52 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18885398857701494		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.18885398857701494 | validation: 0.33676340364479374]
	TIME [epoch: 8.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19957178580869273		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.19957178580869273 | validation: 0.32551871310594827]
	TIME [epoch: 8.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17646746954620426		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.17646746954620426 | validation: 0.19811593550604056]
	TIME [epoch: 8.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882363315197086		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.1882363315197086 | validation: 0.19340254134419904]
	TIME [epoch: 8.52 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19932260645253191		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.19932260645253191 | validation: 0.21597458502669342]
	TIME [epoch: 8.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1574534721720399		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.1574534721720399 | validation: 0.17027875146092286]
	TIME [epoch: 8.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18556601974006542		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.18556601974006542 | validation: 0.15814019131072904]
	TIME [epoch: 8.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283039287261045		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.283039287261045 | validation: 0.13303116188797115]
	TIME [epoch: 8.53 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17757000311279253		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.17757000311279253 | validation: 0.2723066737034179]
	TIME [epoch: 8.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16951575063896854		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.16951575063896854 | validation: 0.13032038223486608]
	TIME [epoch: 8.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.163187748691965		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.163187748691965 | validation: 0.14756972804129254]
	TIME [epoch: 8.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16299318308536176		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.16299318308536176 | validation: 0.1179428390899843]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20013192001693197		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.20013192001693197 | validation: 0.1559834414430083]
	TIME [epoch: 8.49 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18028436111909768		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.18028436111909768 | validation: 0.16808685778784976]
	TIME [epoch: 8.48 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23680409734411292		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.23680409734411292 | validation: 0.1261477866120226]
	TIME [epoch: 8.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43216412302924984		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.43216412302924984 | validation: 0.5397313391565263]
	TIME [epoch: 8.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926759326547574		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.1926759326547574 | validation: 0.1668832607737319]
	TIME [epoch: 8.49 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21261347831985863		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.21261347831985863 | validation: 0.16096464170105906]
	TIME [epoch: 8.49 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1741832819878967		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.1741832819878967 | validation: 0.16129018522703095]
	TIME [epoch: 8.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17204881591524684		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.17204881591524684 | validation: 0.16289564555015795]
	TIME [epoch: 8.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27198092154705134		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.27198092154705134 | validation: 0.22840006258304463]
	TIME [epoch: 8.49 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1621018052244531		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.1621018052244531 | validation: 0.12119174244524897]
	TIME [epoch: 8.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22789707234503814		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.22789707234503814 | validation: 0.23093864789894936]
	TIME [epoch: 8.52 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895018750344767		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.1895018750344767 | validation: 0.1871990773706066]
	TIME [epoch: 8.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1654489334173707		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.1654489334173707 | validation: 0.29510313632603213]
	TIME [epoch: 8.49 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24069975275761885		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.24069975275761885 | validation: 0.3392036283057859]
	TIME [epoch: 8.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17768785159279557		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.17768785159279557 | validation: 0.20612135754681027]
	TIME [epoch: 8.52 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19356278047893521		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.19356278047893521 | validation: 0.2331881183803895]
	TIME [epoch: 8.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23565315390436886		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.23565315390436886 | validation: 0.2277313096654458]
	TIME [epoch: 8.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16287514260000419		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.16287514260000419 | validation: 0.12780247460332309]
	TIME [epoch: 8.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16982319231441645		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.16982319231441645 | validation: 0.1093828642049448]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15369925824911845		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.15369925824911845 | validation: 0.15826911158582824]
	TIME [epoch: 8.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2208979836323191		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.2208979836323191 | validation: 0.15490887670278186]
	TIME [epoch: 8.49 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17017580794360235		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.17017580794360235 | validation: 0.08415256227579576]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_691.pth
	Model improved!!!
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27747155121378475		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.27747155121378475 | validation: 0.21899796324486256]
	TIME [epoch: 8.52 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40440688335307395		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.40440688335307395 | validation: 1.2331324201816827]
	TIME [epoch: 8.49 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4560339106577535		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.4560339106577535 | validation: 0.27893447233750057]
	TIME [epoch: 8.49 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27687337102731796		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.27687337102731796 | validation: 0.32522979029019383]
	TIME [epoch: 8.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5215137388992		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.5215137388992 | validation: 0.21103268740291092]
	TIME [epoch: 8.52 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5454855678769656		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.5454855678769656 | validation: 0.48794399579485703]
	TIME [epoch: 8.49 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3850445313378443		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.3850445313378443 | validation: 0.6514505932921211]
	TIME [epoch: 8.49 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8328194532123749		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.8328194532123749 | validation: 0.9913695795225279]
	TIME [epoch: 8.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.456711134326207		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.456711134326207 | validation: 0.4216518319691382]
	TIME [epoch: 8.51 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24916980856385101		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.24916980856385101 | validation: 0.21273972226903537]
	TIME [epoch: 8.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17109411947269432		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.17109411947269432 | validation: 0.2799805508766534]
	TIME [epoch: 8.49 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17203671921495628		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.17203671921495628 | validation: 0.25104653677991823]
	TIME [epoch: 8.52 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18055487226236394		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.18055487226236394 | validation: 0.19731668987560336]
	TIME [epoch: 8.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16866822618355978		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.16866822618355978 | validation: 0.13158900675688082]
	TIME [epoch: 8.49 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2060013772584018		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.2060013772584018 | validation: 0.29510652344763455]
	TIME [epoch: 8.49 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21923543022927597		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.21923543022927597 | validation: 0.100200721617412]
	TIME [epoch: 8.51 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22529515874973477		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.22529515874973477 | validation: 0.3028037421870907]
	TIME [epoch: 8.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20626871994726348		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.20626871994726348 | validation: 0.18612808597965336]
	TIME [epoch: 8.49 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16992420518431323		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.16992420518431323 | validation: 0.37436499750976904]
	TIME [epoch: 8.49 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2170185936882823		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.2170185936882823 | validation: 0.11727184323704215]
	TIME [epoch: 8.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17844079226352333		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.17844079226352333 | validation: 0.5978337181664167]
	TIME [epoch: 8.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3925019142107845		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.3925019142107845 | validation: 0.16721448848424136]
	TIME [epoch: 8.49 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16376814110051915		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.16376814110051915 | validation: 0.18475783913692415]
	TIME [epoch: 8.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21341282091342664		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.21341282091342664 | validation: 0.12656820354690312]
	TIME [epoch: 8.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1756867515407861		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.1756867515407861 | validation: 0.23979156564054072]
	TIME [epoch: 8.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1419071630265139		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.1419071630265139 | validation: 0.1172707411261904]
	TIME [epoch: 8.49 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1584881458736595		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.1584881458736595 | validation: 0.11354713545938816]
	TIME [epoch: 8.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1956658908417959		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.1956658908417959 | validation: 0.16591868564477688]
	TIME [epoch: 8.52 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17746531775395297		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.17746531775395297 | validation: 0.2580974750183084]
	TIME [epoch: 8.49 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2306819148922868		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.2306819148922868 | validation: 0.19256425245198922]
	TIME [epoch: 8.49 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15776495386739178		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.15776495386739178 | validation: 0.43569070129630894]
	TIME [epoch: 8.49 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20033713249272442		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.20033713249272442 | validation: 0.14747070613543092]
	TIME [epoch: 8.51 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1984144543997199		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.1984144543997199 | validation: 0.25126989193104643]
	TIME [epoch: 8.49 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33828989055221437		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.33828989055221437 | validation: 0.12310957724176082]
	TIME [epoch: 8.49 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1938141808545194		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.1938141808545194 | validation: 0.3493757358827958]
	TIME [epoch: 8.49 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20986959240739594		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.20986959240739594 | validation: 0.18125047924771132]
	TIME [epoch: 8.52 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1621642724964816		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.1621642724964816 | validation: 0.11707818897395166]
	TIME [epoch: 8.49 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12329760931075448		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.12329760931075448 | validation: 0.08876496756170944]
	TIME [epoch: 8.49 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14284648792229318		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.14284648792229318 | validation: 0.2419676177749697]
	TIME [epoch: 8.49 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18094627960814186		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.18094627960814186 | validation: 0.17559229979655405]
	TIME [epoch: 8.52 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1992035916287528		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.1992035916287528 | validation: 0.37072852138814905]
	TIME [epoch: 8.49 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23038893091788717		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.23038893091788717 | validation: 0.4330332108364658]
	TIME [epoch: 8.49 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21106269273849163		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.21106269273849163 | validation: 0.20030690498657228]
	TIME [epoch: 8.49 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20328185552322883		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.20328185552322883 | validation: 0.290526453404767]
	TIME [epoch: 8.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18489350299076585		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.18489350299076585 | validation: 0.24262323821254267]
	TIME [epoch: 8.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20008966371508152		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.20008966371508152 | validation: 0.19137446574615088]
	TIME [epoch: 8.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1885973590039651		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.1885973590039651 | validation: 0.22610248484930195]
	TIME [epoch: 8.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17790578527598225		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.17790578527598225 | validation: 0.22312827046329836]
	TIME [epoch: 8.51 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17942258815962409		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.17942258815962409 | validation: 0.268535422407403]
	TIME [epoch: 8.49 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16336250181341955		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.16336250181341955 | validation: 0.14340520763228654]
	TIME [epoch: 8.49 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18137838151483907		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.18137838151483907 | validation: 0.13067318280748777]
	TIME [epoch: 8.51 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14652448795130144		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.14652448795130144 | validation: 0.20267796978019437]
	TIME [epoch: 8.51 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20537439774616448		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.20537439774616448 | validation: 0.13670458170137217]
	TIME [epoch: 8.49 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15332727799478957		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.15332727799478957 | validation: 0.19759919219242067]
	TIME [epoch: 8.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882840562183285		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.1882840562183285 | validation: 0.14322694783150258]
	TIME [epoch: 8.51 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18145658272818593		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.18145658272818593 | validation: 0.2514373783457845]
	TIME [epoch: 8.51 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19824607061170443		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.19824607061170443 | validation: 0.18055023822418725]
	TIME [epoch: 8.49 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17004357815357413		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.17004357815357413 | validation: 0.1680174775381117]
	TIME [epoch: 8.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23027075954014703		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.23027075954014703 | validation: 0.15865659461844692]
	TIME [epoch: 8.51 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995134585176102		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.1995134585176102 | validation: 0.14458488574266626]
	TIME [epoch: 8.51 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16358536886551014		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.16358536886551014 | validation: 0.16838677238745242]
	TIME [epoch: 8.49 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18301440607610153		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.18301440607610153 | validation: 0.12624108391444439]
	TIME [epoch: 8.49 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1887611510608596		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.1887611510608596 | validation: 0.20259886765690832]
	TIME [epoch: 8.51 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17377784306112748		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.17377784306112748 | validation: 0.10177206815411456]
	TIME [epoch: 8.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13080316115472942		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.13080316115472942 | validation: 0.11542456388578595]
	TIME [epoch: 8.49 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14845919392411056		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.14845919392411056 | validation: 0.1397201751743682]
	TIME [epoch: 8.49 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19671461279762079		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.19671461279762079 | validation: 0.1967621679919329]
	TIME [epoch: 8.51 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623656228398104		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.1623656228398104 | validation: 0.1093672578332392]
	TIME [epoch: 8.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11788170343461069		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.11788170343461069 | validation: 0.19773496424763276]
	TIME [epoch: 8.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13949002490908696		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.13949002490908696 | validation: 0.2533551302467389]
	TIME [epoch: 8.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16564761692614838		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.16564761692614838 | validation: 0.0904770526903122]
	TIME [epoch: 8.52 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16439931879593592		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.16439931879593592 | validation: 0.1040275220694451]
	TIME [epoch: 8.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492208602998021		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.1492208602998021 | validation: 0.12380918510349456]
	TIME [epoch: 8.49 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1478324708458703		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.1478324708458703 | validation: 0.10749842067914811]
	TIME [epoch: 8.49 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14352571581933535		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.14352571581933535 | validation: 0.09911340732134147]
	TIME [epoch: 8.52 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1838274587069622		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.1838274587069622 | validation: 0.13429792183637718]
	TIME [epoch: 8.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13377281238599162		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.13377281238599162 | validation: 0.20135454861663232]
	TIME [epoch: 8.49 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16728675196904125		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.16728675196904125 | validation: 0.23534391508087305]
	TIME [epoch: 8.49 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15971116735949742		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.15971116735949742 | validation: 0.20797871639400667]
	TIME [epoch: 8.52 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19078262057873369		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.19078262057873369 | validation: 0.19440568296163666]
	TIME [epoch: 8.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16720412372556012		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.16720412372556012 | validation: 0.09884939168054821]
	TIME [epoch: 8.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16794386407976444		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.16794386407976444 | validation: 0.12811883498808183]
	TIME [epoch: 8.49 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12500249700365523		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.12500249700365523 | validation: 0.1425916781765063]
	TIME [epoch: 8.52 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17281447885011605		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.17281447885011605 | validation: 0.14576614667468835]
	TIME [epoch: 8.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18481129797287899		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.18481129797287899 | validation: 0.25362096751720054]
	TIME [epoch: 8.49 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1314242109549998		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.1314242109549998 | validation: 0.306568009649835]
	TIME [epoch: 8.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19672511167197798		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.19672511167197798 | validation: 0.26678501318174674]
	TIME [epoch: 8.51 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1628169025946431		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.1628169025946431 | validation: 0.14812281806608474]
	TIME [epoch: 8.49 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14647988175929075		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.14647988175929075 | validation: 0.1026354689396203]
	TIME [epoch: 8.49 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16175596598652517		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.16175596598652517 | validation: 0.12060829412684626]
	TIME [epoch: 8.51 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16163428911158848		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.16163428911158848 | validation: 0.15982848802377883]
	TIME [epoch: 8.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13878263514092323		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.13878263514092323 | validation: 0.14877761420560848]
	TIME [epoch: 8.49 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15631347758169695		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.15631347758169695 | validation: 0.18137650234123948]
	TIME [epoch: 8.49 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1842579477788951		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.1842579477788951 | validation: 0.2099420202616934]
	TIME [epoch: 8.51 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15728844329869407		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.15728844329869407 | validation: 0.1305368052942662]
	TIME [epoch: 8.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1573786190474182		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.1573786190474182 | validation: 0.19218485744849087]
	TIME [epoch: 8.49 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1460264798194087		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.1460264798194087 | validation: 0.1024884178863158]
	TIME [epoch: 8.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12205059094359778		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.12205059094359778 | validation: 0.11769670058155299]
	TIME [epoch: 8.51 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16943593259006123		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.16943593259006123 | validation: 0.35085262359787506]
	TIME [epoch: 8.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.141283502125897		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.141283502125897 | validation: 0.10799368835978174]
	TIME [epoch: 8.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16786559810100857		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.16786559810100857 | validation: 0.23167449184841682]
	TIME [epoch: 8.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1379195836596124		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.1379195836596124 | validation: 0.12083305922854033]
	TIME [epoch: 8.52 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12480477018436806		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.12480477018436806 | validation: 0.1659003163749334]
	TIME [epoch: 8.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14063680323891686		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.14063680323891686 | validation: 0.0989301049923794]
	TIME [epoch: 8.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14554408851442588		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.14554408851442588 | validation: 0.1732953451786636]
	TIME [epoch: 8.49 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15158834978471045		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.15158834978471045 | validation: 0.20087609011522733]
	TIME [epoch: 8.52 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14625131305444578		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.14625131305444578 | validation: 0.14355182764530502]
	TIME [epoch: 8.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16011820993011572		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.16011820993011572 | validation: 0.12238298450855853]
	TIME [epoch: 8.49 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.248693727825551		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.248693727825551 | validation: 0.18450322197556418]
	TIME [epoch: 8.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11448507670017638		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.11448507670017638 | validation: 0.1596546478975437]
	TIME [epoch: 8.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12862943982239078		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.12862943982239078 | validation: 0.23687384758604935]
	TIME [epoch: 8.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1928369520042263		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.1928369520042263 | validation: 0.29118209318005356]
	TIME [epoch: 8.49 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18141036006309755		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.18141036006309755 | validation: 0.22583759118736235]
	TIME [epoch: 8.49 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19513095786012338		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.19513095786012338 | validation: 0.23949139781526804]
	TIME [epoch: 8.52 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15239452332428424		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.15239452332428424 | validation: 0.18740019265279248]
	TIME [epoch: 8.49 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16323847064396854		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.16323847064396854 | validation: 0.1540342330600039]
	TIME [epoch: 8.49 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1667946102797389		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.1667946102797389 | validation: 0.15472689361790404]
	TIME [epoch: 8.49 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15222910052472635		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.15222910052472635 | validation: 0.09648832859679819]
	TIME [epoch: 8.52 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14060904841860053		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.14060904841860053 | validation: 0.11135785991268604]
	TIME [epoch: 8.49 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13776687723452205		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.13776687723452205 | validation: 0.11008676634047102]
	TIME [epoch: 8.49 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2310962387799062		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.2310962387799062 | validation: 0.09847912594642247]
	TIME [epoch: 8.49 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13797186721093851		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.13797186721093851 | validation: 0.14638755596549702]
	TIME [epoch: 8.52 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1241461494581237		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.1241461494581237 | validation: 0.15322089249589294]
	TIME [epoch: 8.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.153503541042766		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.153503541042766 | validation: 0.1265367026517479]
	TIME [epoch: 8.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12064794437730889		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.12064794437730889 | validation: 0.1327204333900863]
	TIME [epoch: 8.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14210580374892473		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.14210580374892473 | validation: 0.11903762249060554]
	TIME [epoch: 8.51 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1482822083069406		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.1482822083069406 | validation: 0.11488819646437468]
	TIME [epoch: 8.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1891578608236863		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.1891578608236863 | validation: 0.10323111634956506]
	TIME [epoch: 8.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1455956941341515		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.1455956941341515 | validation: 0.10733797343324275]
	TIME [epoch: 8.51 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18047886889089318		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.18047886889089318 | validation: 0.09611940977217859]
	TIME [epoch: 8.51 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17257508798967244		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.17257508798967244 | validation: 0.11327887249489879]
	TIME [epoch: 8.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25806395706072466		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.25806395706072466 | validation: 0.2689724254619034]
	TIME [epoch: 8.49 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1526467278423248		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.1526467278423248 | validation: 0.11821860940673286]
	TIME [epoch: 8.51 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15972214923370492		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.15972214923370492 | validation: 0.1547951313777704]
	TIME [epoch: 8.51 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12300109393381373		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.12300109393381373 | validation: 0.09604034293407573]
	TIME [epoch: 8.49 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13861655131882059		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.13861655131882059 | validation: 0.13192625174252715]
	TIME [epoch: 8.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11770134405001956		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.11770134405001956 | validation: 0.3721331494038122]
	TIME [epoch: 8.51 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921589079168823		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.1921589079168823 | validation: 0.11248208581370017]
	TIME [epoch: 8.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13546631850533963		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.13546631850533963 | validation: 0.11513096547355953]
	TIME [epoch: 8.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13933582894798024		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.13933582894798024 | validation: 0.10696869465538347]
	TIME [epoch: 8.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1256658479441617		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.1256658479441617 | validation: 0.20836687355035255]
	TIME [epoch: 8.52 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14580105726050932		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.14580105726050932 | validation: 0.12533253207344686]
	TIME [epoch: 8.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25889130745762606		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.25889130745762606 | validation: 0.16393217509540092]
	TIME [epoch: 8.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1343282326143807		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.1343282326143807 | validation: 0.09816055251906236]
	TIME [epoch: 8.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11977874981692967		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.11977874981692967 | validation: 0.10486014853983423]
	TIME [epoch: 8.52 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14646477789968732		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.14646477789968732 | validation: 0.12582299069229202]
	TIME [epoch: 8.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19467999588058865		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.19467999588058865 | validation: 0.2068692652801666]
	TIME [epoch: 8.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.123587253962369		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.123587253962369 | validation: 0.11091373941411091]
	TIME [epoch: 8.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1232656528758703		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.1232656528758703 | validation: 0.09677981393243071]
	TIME [epoch: 8.52 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11578285917241242		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.11578285917241242 | validation: 0.11588648201259746]
	TIME [epoch: 8.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17467046216557938		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.17467046216557938 | validation: 0.13816134809366828]
	TIME [epoch: 8.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17959978606842328		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.17959978606842328 | validation: 0.19430127123305918]
	TIME [epoch: 8.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1840873104737955		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.1840873104737955 | validation: 0.13280808514054235]
	TIME [epoch: 8.53 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342335089143522		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.1342335089143522 | validation: 0.08892587113680994]
	TIME [epoch: 8.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11449463014348196		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.11449463014348196 | validation: 0.11503480252707281]
	TIME [epoch: 8.49 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11684697602463741		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.11684697602463741 | validation: 0.17901902635084244]
	TIME [epoch: 8.49 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19768188687070168		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.19768188687070168 | validation: 0.2554561627822097]
	TIME [epoch: 8.52 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16005609250739355		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.16005609250739355 | validation: 0.14501066007105123]
	TIME [epoch: 8.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15568812068658527		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.15568812068658527 | validation: 0.14462048168975855]
	TIME [epoch: 8.49 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13784602082946756		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.13784602082946756 | validation: 0.13300346417954162]
	TIME [epoch: 8.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12576017877949017		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.12576017877949017 | validation: 0.09953722180799728]
	TIME [epoch: 8.52 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12527654682508021		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.12527654682508021 | validation: 0.2479519433829655]
	TIME [epoch: 8.49 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16543216518607937		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.16543216518607937 | validation: 0.10487752882110427]
	TIME [epoch: 8.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10858637149606967		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.10858637149606967 | validation: 0.17003224560183758]
	TIME [epoch: 8.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14258528373960386		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.14258528373960386 | validation: 0.18785870652647224]
	TIME [epoch: 8.51 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14520167247263271		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.14520167247263271 | validation: 0.07215138830046755]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_857.pth
	Model improved!!!
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250952316454694		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.1250952316454694 | validation: 0.11874862076189302]
	TIME [epoch: 8.51 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13512270718791874		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.13512270718791874 | validation: 0.1375353945009466]
	TIME [epoch: 8.51 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16742204102103886		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.16742204102103886 | validation: 0.11704440510690887]
	TIME [epoch: 8.51 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12681343440852955		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.12681343440852955 | validation: 0.28334940834633554]
	TIME [epoch: 8.49 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21575546974134277		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.21575546974134277 | validation: 0.16032593731994166]
	TIME [epoch: 8.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12544546817402832		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.12544546817402832 | validation: 0.1448197839055817]
	TIME [epoch: 8.51 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11238086675308401		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.11238086675308401 | validation: 0.10670985200204741]
	TIME [epoch: 8.51 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15381289831752928		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.15381289831752928 | validation: 0.12894276853396025]
	TIME [epoch: 8.49 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1618853551229379		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.1618853551229379 | validation: 0.09472027193085283]
	TIME [epoch: 8.49 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1642092499562559		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.1642092499562559 | validation: 0.15331142372132303]
	TIME [epoch: 8.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1691107352867474		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.1691107352867474 | validation: 0.13158514491240075]
	TIME [epoch: 8.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14051735827915093		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.14051735827915093 | validation: 0.1762376952092534]
	TIME [epoch: 8.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12715505223949403		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.12715505223949403 | validation: 0.20351795016103086]
	TIME [epoch: 8.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1455240138869667		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.1455240138869667 | validation: 0.10748226244840463]
	TIME [epoch: 8.52 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12722816517554264		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.12722816517554264 | validation: 0.10414095917109695]
	TIME [epoch: 8.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14554299672405685		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.14554299672405685 | validation: 0.128062398858239]
	TIME [epoch: 8.49 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1691203213744535		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.1691203213744535 | validation: 0.22451484859307058]
	TIME [epoch: 8.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1723767226076532		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.1723767226076532 | validation: 0.10419702201113586]
	TIME [epoch: 8.52 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1764685323413136		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.1764685323413136 | validation: 0.11627907931391246]
	TIME [epoch: 8.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12913397503395857		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.12913397503395857 | validation: 0.21388601431098642]
	TIME [epoch: 8.49 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15168303397009045		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.15168303397009045 | validation: 0.15265800139836472]
	TIME [epoch: 8.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17543598059198778		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.17543598059198778 | validation: 0.15622723308466557]
	TIME [epoch: 8.52 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12192794196505179		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.12192794196505179 | validation: 0.0844011767864962]
	TIME [epoch: 8.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11084217784081998		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.11084217784081998 | validation: 0.1246447454743616]
	TIME [epoch: 8.49 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1526527337755633		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.1526527337755633 | validation: 0.18859741484724193]
	TIME [epoch: 8.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14419377266747596		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.14419377266747596 | validation: 0.22241774042747703]
	TIME [epoch: 8.52 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12759767305614264		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.12759767305614264 | validation: 0.13193101322191775]
	TIME [epoch: 8.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1510454898815396		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.1510454898815396 | validation: 0.13998050484577612]
	TIME [epoch: 8.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11613395536457809		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.11613395536457809 | validation: 0.12019790002241754]
	TIME [epoch: 8.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1641185669558613		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.1641185669558613 | validation: 0.10743533065187812]
	TIME [epoch: 8.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14051898038508243		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.14051898038508243 | validation: 0.1261768843168694]
	TIME [epoch: 8.49 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22234688147112897		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.22234688147112897 | validation: 0.16755443688192034]
	TIME [epoch: 8.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1446971833493824		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.1446971833493824 | validation: 0.15908747763476114]
	TIME [epoch: 8.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14513730179254963		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.14513730179254963 | validation: 0.1239049841384039]
	TIME [epoch: 8.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12392113210761176		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.12392113210761176 | validation: 0.09737105291259665]
	TIME [epoch: 8.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12665020648987033		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.12665020648987033 | validation: 0.1588172864275464]
	TIME [epoch: 8.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1174130800757884		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.1174130800757884 | validation: 0.1185389507071803]
	TIME [epoch: 8.51 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15019437861136936		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.15019437861136936 | validation: 0.15125717115237522]
	TIME [epoch: 8.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14062569736583702		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.14062569736583702 | validation: 0.11491458646046224]
	TIME [epoch: 8.49 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14482495980152463		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.14482495980152463 | validation: 0.1556568372554174]
	TIME [epoch: 8.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14519690196928228		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.14519690196928228 | validation: 0.21322144140229296]
	TIME [epoch: 8.51 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14257483425265158		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.14257483425265158 | validation: 0.1129937677856736]
	TIME [epoch: 8.51 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1371651164966581		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.1371651164966581 | validation: 0.1875638390570339]
	TIME [epoch: 8.49 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14808330496925204		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.14808330496925204 | validation: 0.09469641610234929]
	TIME [epoch: 8.49 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14398423416505263		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.14398423416505263 | validation: 0.15536545021658194]
	TIME [epoch: 8.51 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17129546470512233		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.17129546470512233 | validation: 0.29192647383741654]
	TIME [epoch: 8.49 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1741741179991741		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.1741741179991741 | validation: 0.10566478222470166]
	TIME [epoch: 8.49 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1283957315586579		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.1283957315586579 | validation: 0.16800672432429423]
	TIME [epoch: 8.49 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14378897095087992		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.14378897095087992 | validation: 0.10386958758207324]
	TIME [epoch: 8.51 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1392577462113686		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.1392577462113686 | validation: 0.16109720162077124]
	TIME [epoch: 8.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12666997350497416		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.12666997350497416 | validation: 0.16941144945672285]
	TIME [epoch: 8.49 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11986908721253664		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.11986908721253664 | validation: 0.11329633934493094]
	TIME [epoch: 8.49 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316587938846637		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.1316587938846637 | validation: 0.234593143018684]
	TIME [epoch: 8.52 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17365767750130895		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.17365767750130895 | validation: 0.09934033384820369]
	TIME [epoch: 8.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13730036306422083		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.13730036306422083 | validation: 0.20238316839727616]
	TIME [epoch: 8.49 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13716086818534684		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.13716086818534684 | validation: 0.12615473897350804]
	TIME [epoch: 8.49 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13339224232819497		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.13339224232819497 | validation: 0.09657053735964]
	TIME [epoch: 8.52 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13510385534825303		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.13510385534825303 | validation: 0.1045937081726726]
	TIME [epoch: 8.49 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12916853077696439		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.12916853077696439 | validation: 0.2940238163669034]
	TIME [epoch: 8.49 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17008000231422638		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.17008000231422638 | validation: 0.13230697757004498]
	TIME [epoch: 8.49 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11246103158500798		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.11246103158500798 | validation: 0.10784267174032253]
	TIME [epoch: 8.52 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14954897051484378		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.14954897051484378 | validation: 0.06947111403618013]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_919.pth
	Model improved!!!
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14465105058308358		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.14465105058308358 | validation: 0.07771722207361534]
	TIME [epoch: 8.49 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11601973685801074		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.11601973685801074 | validation: 0.1342037288292856]
	TIME [epoch: 8.49 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11520421389436966		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.11520421389436966 | validation: 0.08361353706488936]
	TIME [epoch: 8.51 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12728758527755668		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.12728758527755668 | validation: 0.1205408178603791]
	TIME [epoch: 8.49 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11221508412798302		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.11221508412798302 | validation: 0.08846744775332607]
	TIME [epoch: 8.49 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10547827485233752		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.10547827485233752 | validation: 0.12654020283311398]
	TIME [epoch: 8.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1623414360802084		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.1623414360802084 | validation: 0.0878464399670463]
	TIME [epoch: 8.51 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17181445453005412		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.17181445453005412 | validation: 0.20214691808257595]
	TIME [epoch: 8.49 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10411001966656608		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.10411001966656608 | validation: 0.11390403594409738]
	TIME [epoch: 8.48 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11306182045728577		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.11306182045728577 | validation: 0.2092860581488753]
	TIME [epoch: 8.49 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255405073061528		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.1255405073061528 | validation: 0.2003771565761039]
	TIME [epoch: 8.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13204129873736659		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.13204129873736659 | validation: 0.1388444061189827]
	TIME [epoch: 8.48 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1438420459646242		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.1438420459646242 | validation: 0.11892435728473698]
	TIME [epoch: 8.48 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1691293865595742		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.1691293865595742 | validation: 0.2443407532547966]
	TIME [epoch: 8.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13419008885345954		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.13419008885345954 | validation: 0.11639882468318294]
	TIME [epoch: 8.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102765375733968		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.12102765375733968 | validation: 0.105081753111779]
	TIME [epoch: 8.49 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14088279489395866		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.14088279489395866 | validation: 0.08859174398560067]
	TIME [epoch: 8.49 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306066821976349		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.1306066821976349 | validation: 0.1458241780253211]
	TIME [epoch: 8.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11364803520914638		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.11364803520914638 | validation: 0.0945431920431403]
	TIME [epoch: 8.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1215023731921866		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.1215023731921866 | validation: 0.12108450817407695]
	TIME [epoch: 8.49 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1506240711785564		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.1506240711785564 | validation: 0.08266170012214763]
	TIME [epoch: 8.49 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11030878445642678		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.11030878445642678 | validation: 0.12409853550245512]
	TIME [epoch: 8.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11325834674340032		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.11325834674340032 | validation: 0.0920113050643567]
	TIME [epoch: 8.49 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14739587166424842		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.14739587166424842 | validation: 0.12325572719450634]
	TIME [epoch: 8.49 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13274190243143555		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.13274190243143555 | validation: 0.11876945142026178]
	TIME [epoch: 8.49 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1272331216389641		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.1272331216389641 | validation: 0.0962193756891529]
	TIME [epoch: 8.51 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11669637011993025		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.11669637011993025 | validation: 0.14763067228304008]
	TIME [epoch: 8.49 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13287464594465265		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.13287464594465265 | validation: 0.11972893470422857]
	TIME [epoch: 8.49 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13988331328411957		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.13988331328411957 | validation: 0.0786431200543156]
	TIME [epoch: 8.49 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11031174658864937		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.11031174658864937 | validation: 0.10293877547048781]
	TIME [epoch: 8.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09563568870348546		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.09563568870348546 | validation: 0.21971287232283232]
	TIME [epoch: 8.49 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1456429844561062		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.1456429844561062 | validation: 0.08013273050547191]
	TIME [epoch: 8.49 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11562026643239347		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.11562026643239347 | validation: 0.16000018688823234]
	TIME [epoch: 8.49 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10360715006196655		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.10360715006196655 | validation: 0.09743735155032877]
	TIME [epoch: 8.52 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09222632255577413		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.09222632255577413 | validation: 0.10378885340248006]
	TIME [epoch: 8.49 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638670131075209		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.10638670131075209 | validation: 0.09385449317313774]
	TIME [epoch: 8.49 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12360624251617555		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.12360624251617555 | validation: 0.13735224620354414]
	TIME [epoch: 8.49 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12648499381003508		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.12648499381003508 | validation: 0.20815927802408724]
	TIME [epoch: 8.52 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136320837464972		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.1136320837464972 | validation: 0.09895735835520111]
	TIME [epoch: 8.49 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11617701078922327		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.11617701078922327 | validation: 0.11662185493332458]
	TIME [epoch: 8.49 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12995145062253344		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.12995145062253344 | validation: 0.11465364342132461]
	TIME [epoch: 8.49 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09507539809931848		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.09507539809931848 | validation: 0.08772141414993363]
	TIME [epoch: 8.52 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13260734083953168		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.13260734083953168 | validation: 0.08611265578277366]
	TIME [epoch: 8.49 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11829469445295956		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.11829469445295956 | validation: 0.09216319030098188]
	TIME [epoch: 8.49 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.133835334720214		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.133835334720214 | validation: 0.22702583199627768]
	TIME [epoch: 8.49 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316664103973774		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.1316664103973774 | validation: 0.18943550795167763]
	TIME [epoch: 8.51 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10761613953336184		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.10761613953336184 | validation: 0.12728046166581966]
	TIME [epoch: 8.49 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15647185816888892		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.15647185816888892 | validation: 0.1526012895146096]
	TIME [epoch: 8.49 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.146305636463115		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.146305636463115 | validation: 0.12193368457837644]
	TIME [epoch: 8.49 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1229247710175311		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.1229247710175311 | validation: 0.13534611166970448]
	TIME [epoch: 8.51 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12439835690197179		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.12439835690197179 | validation: 0.13593830995243045]
	TIME [epoch: 8.49 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10295210215943713		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.10295210215943713 | validation: 0.12217600933197031]
	TIME [epoch: 8.49 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10108544310092163		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.10108544310092163 | validation: 0.07954075366885734]
	TIME [epoch: 8.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12802945912248082		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.12802945912248082 | validation: 0.12694254102231284]
	TIME [epoch: 8.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10527014609875913		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.10527014609875913 | validation: 0.16772244746687814]
	TIME [epoch: 8.49 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15220730154847248		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.15220730154847248 | validation: 0.08690184769693629]
	TIME [epoch: 8.49 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11914960571017778		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.11914960571017778 | validation: 0.16166381063344137]
	TIME [epoch: 8.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10549198261377742		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.10549198261377742 | validation: 0.10788672689568038]
	TIME [epoch: 8.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16530109072007976		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.16530109072007976 | validation: 0.4547141356653964]
	TIME [epoch: 8.49 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16148351995501048		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.16148351995501048 | validation: 0.12401940644412415]
	TIME [epoch: 8.49 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257062583908609		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.1257062583908609 | validation: 0.06382683673706127]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12189630893697623		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.12189630893697623 | validation: 0.11981986396800434]
	TIME [epoch: 8.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12318038649777416		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.12318038649777416 | validation: 0.1221701889380335]
	TIME [epoch: 8.49 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11583962111879145		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.11583962111879145 | validation: 0.08802215072257592]
	TIME [epoch: 8.49 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10281110384606931		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.10281110384606931 | validation: 0.09277075159720406]
	TIME [epoch: 8.51 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11260128859341563		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.11260128859341563 | validation: 0.1503131586992732]
	TIME [epoch: 8.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11327020750368473		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.11327020750368473 | validation: 0.08118579675925802]
	TIME [epoch: 8.49 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13236941085935836		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.13236941085935836 | validation: 0.1155384892789999]
	TIME [epoch: 8.49 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14423476994437995		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.14423476994437995 | validation: 0.10319386949755073]
	TIME [epoch: 8.51 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1087925652686613		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.1087925652686613 | validation: 0.09539301155569099]
	TIME [epoch: 8.49 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10835470846396211		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.10835470846396211 | validation: 0.1021623839068675]
	TIME [epoch: 8.49 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10948474986943113		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.10948474986943113 | validation: 0.08679946858143794]
	TIME [epoch: 8.49 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12314849408011334		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.12314849408011334 | validation: 0.08047353673069402]
	TIME [epoch: 8.51 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12062197070246532		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.12062197070246532 | validation: 0.2306333814217411]
	TIME [epoch: 8.49 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12353915311002901		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.12353915311002901 | validation: 0.11492240447462489]
	TIME [epoch: 8.49 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12266442712439592		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.12266442712439592 | validation: 0.16950898903630052]
	TIME [epoch: 8.49 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15238132203750876		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.15238132203750876 | validation: 0.22899622415805682]
	TIME [epoch: 8.52 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12596987387915845		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.12596987387915845 | validation: 0.2636196971954578]
	TIME [epoch: 8.49 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12280683953781138		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.12280683953781138 | validation: 0.11329455848277631]
	TIME [epoch: 8.49 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08213908417058388		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.08213908417058388 | validation: 0.10617378825591495]
	TIME [epoch: 8.49 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10310983449194025		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.10310983449194025 | validation: 0.20533190949483138]
	TIME [epoch: 8.51 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11617859718111445		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.11617859718111445 | validation: 0.12446327518177604]
	TIME [epoch: 8.49 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13133541098074938		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.13133541098074938 | validation: 0.19703159687182953]
	TIME [epoch: 8.49 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14093170664512927		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.14093170664512927 | validation: 0.07495157475711907]
	TIME [epoch: 8.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11264132132721356		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.11264132132721356 | validation: 0.1440359045802143]
	TIME [epoch: 8.51 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14706037434591918		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.14706037434591918 | validation: 0.14268235326038936]
	TIME [epoch: 8.49 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12330597529474704		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.12330597529474704 | validation: 0.09708050097939064]
	TIME [epoch: 8.49 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12539954990639274		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.12539954990639274 | validation: 0.1410542631153936]
	TIME [epoch: 8.51 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12835023339843893		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.12835023339843893 | validation: 0.12609121330970718]
	TIME [epoch: 8.51 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136959045451406		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.1136959045451406 | validation: 0.08903773344969035]
	TIME [epoch: 8.49 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11993893149003707		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.11993893149003707 | validation: 0.13180155442157576]
	TIME [epoch: 8.49 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16298736808678363		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.16298736808678363 | validation: 0.12991253138763248]
	TIME [epoch: 8.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15824972473113802		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.15824972473113802 | validation: 0.10817744620842656]
	TIME [epoch: 8.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14557511405872908		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.14557511405872908 | validation: 0.11274504361478291]
	TIME [epoch: 8.49 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1129477915881221		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.1129477915881221 | validation: 0.09643251588707216]
	TIME [epoch: 8.49 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12374385027043107		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.12374385027043107 | validation: 0.09378995134889018]
	TIME [epoch: 8.51 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10070452018937955		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.10070452018937955 | validation: 0.14106645100137755]
	TIME [epoch: 8.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14099364553114785		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.14099364553114785 | validation: 0.15237464993333763]
	TIME [epoch: 8.49 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1331606135418735		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.1331606135418735 | validation: 0.1127135614142103]
	TIME [epoch: 8.49 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16276355569324413		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.16276355569324413 | validation: 0.09700962401198279]
	TIME [epoch: 8.51 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10324749436355407		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.10324749436355407 | validation: 0.10319010083302066]
	TIME [epoch: 8.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11082637107697471		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.11082637107697471 | validation: 0.10387481677089375]
	TIME [epoch: 8.49 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17480185231864936		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.17480185231864936 | validation: 0.08711910929579522]
	TIME [epoch: 8.49 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13527744488566767		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.13527744488566767 | validation: 0.0769991728893823]
	TIME [epoch: 8.51 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1049872657672237		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.1049872657672237 | validation: 0.12032286156165041]
	TIME [epoch: 8.49 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17875759231228713		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.17875759231228713 | validation: 0.15738431857959934]
	TIME [epoch: 8.49 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16898466118303707		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.16898466118303707 | validation: 0.13429325455879568]
	TIME [epoch: 8.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13359792717675395		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.13359792717675395 | validation: 0.16454128837979198]
	TIME [epoch: 8.52 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12650616769384287		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.12650616769384287 | validation: 0.1388458066207799]
	TIME [epoch: 8.49 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11407753054255534		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.11407753054255534 | validation: 0.19306813282160357]
	TIME [epoch: 8.49 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20000099541581853		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.20000099541581853 | validation: 0.07087018406011661]
	TIME [epoch: 8.49 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09731637512618836		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.09731637512618836 | validation: 0.12599821574101874]
	TIME [epoch: 8.52 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14289599052171154		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.14289599052171154 | validation: 0.10280228396930433]
	TIME [epoch: 8.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12042393445639418		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.12042393445639418 | validation: 0.11875761942002105]
	TIME [epoch: 8.49 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1161812721498866		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.1161812721498866 | validation: 0.11191435350379711]
	TIME [epoch: 8.49 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10469482835600208		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.10469482835600208 | validation: 0.13040286647997876]
	TIME [epoch: 8.52 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10988775791184087		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.10988775791184087 | validation: 0.13893127699828106]
	TIME [epoch: 8.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10897428400505452		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.10897428400505452 | validation: 0.15401047784778754]
	TIME [epoch: 8.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14220574465335117		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.14220574465335117 | validation: 0.12225576909651903]
	TIME [epoch: 8.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10627298905412777		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.10627298905412777 | validation: 0.090195717452022]
	TIME [epoch: 8.51 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09362122202062215		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.09362122202062215 | validation: 0.09406646097134691]
	TIME [epoch: 8.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08489906617634911		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.08489906617634911 | validation: 0.09967320983164078]
	TIME [epoch: 8.49 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09246031022822372		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.09246031022822372 | validation: 0.09966254759889835]
	TIME [epoch: 8.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11284716163763764		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.11284716163763764 | validation: 0.08628752958005277]
	TIME [epoch: 8.51 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1091154841399509		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.1091154841399509 | validation: 0.12216518905670805]
	TIME [epoch: 8.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12311927905933229		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.12311927905933229 | validation: 0.1450328872664805]
	TIME [epoch: 8.49 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12691725321227038		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.12691725321227038 | validation: 0.11673650302760794]
	TIME [epoch: 8.51 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10829944743798625		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.10829944743798625 | validation: 0.15878503523583581]
	TIME [epoch: 8.51 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1248396948045355		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.1248396948045355 | validation: 0.08427525608187278]
	TIME [epoch: 8.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09108329340124129		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.09108329340124129 | validation: 0.2636542316121402]
	TIME [epoch: 8.49 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13448148217025704		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.13448148217025704 | validation: 0.18881527459736294]
	TIME [epoch: 8.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10850296986522283		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.10850296986522283 | validation: 0.11211258206314192]
	TIME [epoch: 8.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10345299766822443		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.10345299766822443 | validation: 0.09069256209309948]
	TIME [epoch: 8.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10688318046536693		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.10688318046536693 | validation: 0.10769784186092152]
	TIME [epoch: 8.49 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09661377385450101		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.09661377385450101 | validation: 0.15728293341821725]
	TIME [epoch: 8.52 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11413263340343101		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.11413263340343101 | validation: 0.13373081920239516]
	TIME [epoch: 8.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1091064409192943		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.1091064409192943 | validation: 0.15715236056149462]
	TIME [epoch: 8.49 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13227614471901653		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.13227614471901653 | validation: 0.11995737258121006]
	TIME [epoch: 8.49 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18731736295013818		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.18731736295013818 | validation: 0.09481854880664575]
	TIME [epoch: 8.52 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11206783706637222		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.11206783706637222 | validation: 0.12001270154694818]
	TIME [epoch: 8.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10067456163510533		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.10067456163510533 | validation: 0.07838499800669407]
	TIME [epoch: 8.49 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11553716065401284		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.11553716065401284 | validation: 0.10585872078362704]
	TIME [epoch: 8.49 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1249064159997892		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.1249064159997892 | validation: 0.18266512101946925]
	TIME [epoch: 8.52 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08836967463784293		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.08836967463784293 | validation: 0.09020851951779524]
	TIME [epoch: 8.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09160448602832488		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.09160448602832488 | validation: 0.07872687684120795]
	TIME [epoch: 8.49 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13058772870459606		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.13058772870459606 | validation: 0.09809583632833058]
	TIME [epoch: 8.49 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08881991379072254		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.08881991379072254 | validation: 0.06623808777750435]
	TIME [epoch: 8.51 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09353464069308817		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.09353464069308817 | validation: 0.1218381638328499]
	TIME [epoch: 8.49 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15151363418992803		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.15151363418992803 | validation: 0.1914911610682671]
	TIME [epoch: 8.49 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11606232242862376		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.11606232242862376 | validation: 0.10893428054845422]
	TIME [epoch: 8.49 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09133990525927702		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.09133990525927702 | validation: 0.11313197301804623]
	TIME [epoch: 8.51 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10971614240116567		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.10971614240116567 | validation: 0.0889518152104064]
	TIME [epoch: 8.49 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12021766146873247		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.12021766146873247 | validation: 0.12583992458958232]
	TIME [epoch: 8.49 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10520134139679645		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.10520134139679645 | validation: 0.0949057470691865]
	TIME [epoch: 8.48 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10827000470247332		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.10827000470247332 | validation: 0.08962645325119795]
	TIME [epoch: 8.51 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10231006222504206		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.10231006222504206 | validation: 0.08359296751826502]
	TIME [epoch: 8.49 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1141475539592571		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.1141475539592571 | validation: 0.11435014729624686]
	TIME [epoch: 8.49 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10554033525490922		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.10554033525490922 | validation: 0.11612292687743919]
	TIME [epoch: 8.49 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09682003098029704		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.09682003098029704 | validation: 0.0651446228878019]
	TIME [epoch: 8.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1017702836154549		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.1017702836154549 | validation: 0.15409689666653492]
	TIME [epoch: 8.49 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10157741717546731		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.10157741717546731 | validation: 0.08236574657398432]
	TIME [epoch: 8.49 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10301346217530827		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.10301346217530827 | validation: 0.06730394138882627]
	TIME [epoch: 8.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09041114153736407		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.09041114153736407 | validation: 0.07437898146704779]
	TIME [epoch: 8.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09452032224919193		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.09452032224919193 | validation: 0.222641739584559]
	TIME [epoch: 8.48 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12271921023648864		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.12271921023648864 | validation: 0.14194597006051535]
	TIME [epoch: 8.48 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11286385040740732		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.11286385040740732 | validation: 0.12439615590764741]
	TIME [epoch: 8.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09932766262741746		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.09932766262741746 | validation: 0.13671355576605215]
	TIME [epoch: 8.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09785238401275526		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.09785238401275526 | validation: 0.08827951285768854]
	TIME [epoch: 8.49 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07244774125615305		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.07244774125615305 | validation: 0.07346379136958019]
	TIME [epoch: 8.49 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07972023636073117		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.07972023636073117 | validation: 0.08153523353348628]
	TIME [epoch: 8.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09151772529293532		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.09151772529293532 | validation: 0.11240323290806323]
	TIME [epoch: 8.49 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10438604794738367		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.10438604794738367 | validation: 0.16171301714948272]
	TIME [epoch: 8.49 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13783990147106284		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.13783990147106284 | validation: 0.1107897031085826]
	TIME [epoch: 8.48 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11764066944471674		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.11764066944471674 | validation: 0.13296641623521796]
	TIME [epoch: 8.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08989516245007353		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.08989516245007353 | validation: 0.10406621750187967]
	TIME [epoch: 8.49 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0951489973468251		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.0951489973468251 | validation: 0.09762954501943352]
	TIME [epoch: 8.49 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1066558730363278		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.1066558730363278 | validation: 0.09464550946218893]
	TIME [epoch: 8.49 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12637524515923484		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.12637524515923484 | validation: 0.08856438931621675]
	TIME [epoch: 8.51 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0865302274350265		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.0865302274350265 | validation: 0.1037372400825915]
	TIME [epoch: 8.49 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10526465856575876		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.10526465856575876 | validation: 0.12614290770366493]
	TIME [epoch: 8.48 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10882127496271295		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.10882127496271295 | validation: 0.12313918873732513]
	TIME [epoch: 8.49 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281578777161551		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.1281578777161551 | validation: 0.13392743290112846]
	TIME [epoch: 8.51 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13356946229184113		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.13356946229184113 | validation: 0.12864959087805988]
	TIME [epoch: 8.49 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12869519579667352		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.12869519579667352 | validation: 0.1184445273129793]
	TIME [epoch: 8.49 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11406957422331436		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.11406957422331436 | validation: 0.12353246699954948]
	TIME [epoch: 8.49 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08628028319669293		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.08628028319669293 | validation: 0.07892107823317288]
	TIME [epoch: 8.51 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09336473748447197		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.09336473748447197 | validation: 0.07353050471683441]
	TIME [epoch: 8.49 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484064480550479		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.1484064480550479 | validation: 0.07345943871866979]
	TIME [epoch: 8.48 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08902845443778548		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.08902845443778548 | validation: 0.11566216452504867]
	TIME [epoch: 8.49 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09672161939167154		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.09672161939167154 | validation: 0.12490794380442422]
	TIME [epoch: 8.51 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12064147534859715		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.12064147534859715 | validation: 0.10488486353484665]
	TIME [epoch: 8.49 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0907010988086949		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.0907010988086949 | validation: 0.09020746350579678]
	TIME [epoch: 8.49 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09039213356725628		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.09039213356725628 | validation: 0.06431751709256345]
	TIME [epoch: 8.49 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11388891980351683		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.11388891980351683 | validation: 0.11327105379852762]
	TIME [epoch: 8.51 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1428894845843632		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.1428894845843632 | validation: 0.13194466908578026]
	TIME [epoch: 8.49 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11574696956131703		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.11574696956131703 | validation: 0.1602761985265401]
	TIME [epoch: 8.49 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11345755962762707		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.11345755962762707 | validation: 0.0789916213062117]
	TIME [epoch: 8.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08686230028283748		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.08686230028283748 | validation: 0.14405335309141148]
	TIME [epoch: 8.51 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09933141276950626		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.09933141276950626 | validation: 0.07109384658699987]
	TIME [epoch: 8.49 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10722462089252145		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.10722462089252145 | validation: 0.077146801503155]
	TIME [epoch: 8.49 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09083683539039403		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.09083683539039403 | validation: 0.09683442058805089]
	TIME [epoch: 8.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096893718412762		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.096893718412762 | validation: 0.10966923689247673]
	TIME [epoch: 8.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10482720603657036		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.10482720603657036 | validation: 0.08811277282484482]
	TIME [epoch: 8.49 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08924420645704224		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.08924420645704224 | validation: 0.0952099244734386]
	TIME [epoch: 8.49 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08678221537989803		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.08678221537989803 | validation: 0.14710654714784427]
	TIME [epoch: 8.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.097292651900388		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.097292651900388 | validation: 0.15764723560596394]
	TIME [epoch: 8.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09663927588186545		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.09663927588186545 | validation: 0.09131807738983341]
	TIME [epoch: 8.49 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13276816467410277		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.13276816467410277 | validation: 0.13941730244096295]
	TIME [epoch: 8.49 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09473464956034844		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.09473464956034844 | validation: 0.08689633880203136]
	TIME [epoch: 8.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12796434891712832		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.12796434891712832 | validation: 0.16701338198108243]
	TIME [epoch: 8.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10429199545709249		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.10429199545709249 | validation: 0.11756281860501874]
	TIME [epoch: 8.49 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08809995454988723		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.08809995454988723 | validation: 0.0746929527488479]
	TIME [epoch: 8.49 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08228746560141867		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.08228746560141867 | validation: 0.07619259187996545]
	TIME [epoch: 8.51 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08768753927128575		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.08768753927128575 | validation: 0.10779605733380418]
	TIME [epoch: 8.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09623590915538696		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.09623590915538696 | validation: 0.09092907325287158]
	TIME [epoch: 8.48 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11153207454653744		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.11153207454653744 | validation: 0.06851185151734776]
	TIME [epoch: 8.49 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10233071184430993		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.10233071184430993 | validation: 0.1902911533188542]
	TIME [epoch: 8.51 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10868235771203116		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.10868235771203116 | validation: 0.10778315183503738]
	TIME [epoch: 8.49 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10002045084581479		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.10002045084581479 | validation: 0.07527722189398195]
	TIME [epoch: 8.48 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11562665190700168		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.11562665190700168 | validation: 0.11946626639076555]
	TIME [epoch: 8.48 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09449692878192298		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.09449692878192298 | validation: 0.11663823937794063]
	TIME [epoch: 8.51 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10644949708983165		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.10644949708983165 | validation: 0.08126335907223257]
	TIME [epoch: 8.49 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07433914135467332		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.07433914135467332 | validation: 0.06228999571338974]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1142.pth
	Model improved!!!
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12401567880522438		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.12401567880522438 | validation: 0.13258255952415288]
	TIME [epoch: 8.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10062776909329421		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.10062776909329421 | validation: 0.0743929885570324]
	TIME [epoch: 8.53 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11780435865409591		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.11780435865409591 | validation: 0.12272289225421329]
	TIME [epoch: 8.51 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10051632730749724		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.10051632730749724 | validation: 0.10648186883487326]
	TIME [epoch: 8.51 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09268060729668771		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.09268060729668771 | validation: 0.08125129769055683]
	TIME [epoch: 8.51 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11048963182617196		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.11048963182617196 | validation: 0.07500788581899676]
	TIME [epoch: 8.53 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10626827748324168		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.10626827748324168 | validation: 0.09514427000009179]
	TIME [epoch: 8.51 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08672278084579493		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.08672278084579493 | validation: 0.07286951916032935]
	TIME [epoch: 8.51 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08633465174005403		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.08633465174005403 | validation: 0.11927091708976369]
	TIME [epoch: 8.52 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1223501341449785		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.1223501341449785 | validation: 0.10088094560259234]
	TIME [epoch: 8.53 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1703702849859383		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.1703702849859383 | validation: 0.11829356591142463]
	TIME [epoch: 8.51 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08912455790444052		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.08912455790444052 | validation: 0.07422902915026233]
	TIME [epoch: 8.51 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12728460761147622		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.12728460761147622 | validation: 0.09602680344898495]
	TIME [epoch: 8.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10286010525869815		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.10286010525869815 | validation: 0.10747719238121195]
	TIME [epoch: 8.52 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09342702557368221		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.09342702557368221 | validation: 0.09925539145228254]
	TIME [epoch: 8.51 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.085100229821376		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.085100229821376 | validation: 0.13136010137866644]
	TIME [epoch: 8.51 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0975050606054339		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.0975050606054339 | validation: 0.19427963193497524]
	TIME [epoch: 8.53 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10591915730710273		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.10591915730710273 | validation: 0.07920456288572428]
	TIME [epoch: 8.52 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0983266885171331		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.0983266885171331 | validation: 0.09171494324111934]
	TIME [epoch: 8.51 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11778412075586328		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.11778412075586328 | validation: 0.09889912459206346]
	TIME [epoch: 8.51 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08292790488834326		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.08292790488834326 | validation: 0.15522346576002502]
	TIME [epoch: 8.53 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10086094432762471		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.10086094432762471 | validation: 0.11492462388709498]
	TIME [epoch: 8.51 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08261352237723237		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.08261352237723237 | validation: 0.07292667328615465]
	TIME [epoch: 8.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394945133619462		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.1394945133619462 | validation: 0.09006992211750242]
	TIME [epoch: 8.51 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11071829234570163		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.11071829234570163 | validation: 0.07225216505201548]
	TIME [epoch: 8.53 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15955374898186458		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.15955374898186458 | validation: 0.1289954176956079]
	TIME [epoch: 8.51 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09620459116973429		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.09620459116973429 | validation: 0.08540036814103846]
	TIME [epoch: 8.51 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08903695470059345		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.08903695470059345 | validation: 0.09994739760420551]
	TIME [epoch: 8.51 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08734654479049508		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.08734654479049508 | validation: 0.08990887785280285]
	TIME [epoch: 8.53 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09985233923962697		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.09985233923962697 | validation: 0.07587119181100627]
	TIME [epoch: 8.51 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0962413449679576		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.0962413449679576 | validation: 0.12050825588282948]
	TIME [epoch: 8.51 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302947447207812		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.1302947447207812 | validation: 0.09078657615617242]
	TIME [epoch: 8.51 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11307162091841061		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.11307162091841061 | validation: 0.08749686672389151]
	TIME [epoch: 8.54 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08781521640918136		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.08781521640918136 | validation: 0.08650895234777606]
	TIME [epoch: 8.51 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09498970497142073		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.09498970497142073 | validation: 0.063226544480741]
	TIME [epoch: 8.51 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07977882332409099		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.07977882332409099 | validation: 0.13146308439527354]
	TIME [epoch: 8.51 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09812438497107444		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.09812438497107444 | validation: 0.122895260638986]
	TIME [epoch: 8.53 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09021196396166273		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.09021196396166273 | validation: 0.12003645949909267]
	TIME [epoch: 8.51 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08213530233508254		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.08213530233508254 | validation: 0.07702738782037405]
	TIME [epoch: 8.51 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08056711299443264		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.08056711299443264 | validation: 0.06822844878111528]
	TIME [epoch: 8.51 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10937078701114408		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.10937078701114408 | validation: 0.0866643529895442]
	TIME [epoch: 8.53 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09093579168438636		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.09093579168438636 | validation: 0.07667145623950354]
	TIME [epoch: 8.51 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1028965655848334		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.1028965655848334 | validation: 0.06137790140845023]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1185.pth
	Model improved!!!
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10215531408649876		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.10215531408649876 | validation: 0.0966529101022344]
	TIME [epoch: 8.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09392870566832526		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.09392870566832526 | validation: 0.10544441384417462]
	TIME [epoch: 8.51 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11921494174433356		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.11921494174433356 | validation: 0.10281053657228337]
	TIME [epoch: 8.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09567461535353035		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.09567461535353035 | validation: 0.1060241182892811]
	TIME [epoch: 8.51 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09421069449694917		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.09421069449694917 | validation: 0.11791324109093354]
	TIME [epoch: 8.52 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08088386676015312		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.08088386676015312 | validation: 0.07678110900218596]
	TIME [epoch: 8.52 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07364611137663407		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.07364611137663407 | validation: 0.07489286280987417]
	TIME [epoch: 8.51 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11866537319725523		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.11866537319725523 | validation: 0.07646167510701815]
	TIME [epoch: 8.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08912773752687228		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.08912773752687228 | validation: 0.10478281493558628]
	TIME [epoch: 8.53 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09403825086400718		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.09403825086400718 | validation: 0.11930866825829275]
	TIME [epoch: 8.52 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10334835241450566		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.10334835241450566 | validation: 0.11119982052944201]
	TIME [epoch: 8.51 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08834642966506083		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.08834642966506083 | validation: 0.09649549064409102]
	TIME [epoch: 8.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09279856523369365		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.09279856523369365 | validation: 0.08165564696095777]
	TIME [epoch: 8.53 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08142603153050224		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.08142603153050224 | validation: 0.07328488836833834]
	TIME [epoch: 8.51 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07950788269908315		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.07950788269908315 | validation: 0.08961363972356684]
	TIME [epoch: 8.51 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.102083033278908		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.102083033278908 | validation: 0.11733606571340413]
	TIME [epoch: 8.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13068669148665243		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.13068669148665243 | validation: 0.1462148155873635]
	TIME [epoch: 8.53 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0925292865281784		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.0925292865281784 | validation: 0.20113120092140163]
	TIME [epoch: 8.51 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12373569486736272		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.12373569486736272 | validation: 0.08042464776894098]
	TIME [epoch: 8.51 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08282488788121323		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.08282488788121323 | validation: 0.08965881694233377]
	TIME [epoch: 8.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07508631177311523		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.07508631177311523 | validation: 0.07583516450442958]
	TIME [epoch: 8.53 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08221730372042341		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.08221730372042341 | validation: 0.08292423688227202]
	TIME [epoch: 8.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11952068520907329		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.11952068520907329 | validation: 0.07569373113177161]
	TIME [epoch: 8.51 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09045778065999432		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.09045778065999432 | validation: 0.13007424571191586]
	TIME [epoch: 8.51 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16834054375565943		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.16834054375565943 | validation: 0.08312212051844708]
	TIME [epoch: 8.53 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09979757432074102		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.09979757432074102 | validation: 0.1277708966812907]
	TIME [epoch: 8.51 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08931589200852469		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.08931589200852469 | validation: 0.07192371833860083]
	TIME [epoch: 8.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08869184037165076		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.08869184037165076 | validation: 0.08457117819906483]
	TIME [epoch: 8.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12299711219407139		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.12299711219407139 | validation: 0.11402338420507797]
	TIME [epoch: 8.53 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12051099381476742		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.12051099381476742 | validation: 0.07940758069696861]
	TIME [epoch: 8.51 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0887762116181102		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.0887762116181102 | validation: 0.09557003545075529]
	TIME [epoch: 8.51 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11311023714910425		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.11311023714910425 | validation: 0.061585137777848596]
	TIME [epoch: 8.51 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07112682831186203		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.07112682831186203 | validation: 0.06789067607301949]
	TIME [epoch: 8.53 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09065106303744051		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.09065106303744051 | validation: 0.12514713558943463]
	TIME [epoch: 8.51 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10131596832460706		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.10131596832460706 | validation: 0.0666477158165169]
	TIME [epoch: 8.51 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07690048526314633		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.07690048526314633 | validation: 0.13273700790238088]
	TIME [epoch: 8.53 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09792624464465297		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.09792624464465297 | validation: 0.08077351118303323]
	TIME [epoch: 8.52 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.117400747917157		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.117400747917157 | validation: 0.08371196915062898]
	TIME [epoch: 8.51 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07767755939287159		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.07767755939287159 | validation: 0.07083694098838972]
	TIME [epoch: 8.51 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08302258513351632		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.08302258513351632 | validation: 0.11456026097009697]
	TIME [epoch: 8.52 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09809963796276588		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.09809963796276588 | validation: 0.07182182216197713]
	TIME [epoch: 8.52 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09898647715163492		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.09898647715163492 | validation: 0.11046769974781928]
	TIME [epoch: 8.51 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13607971260499965		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.13607971260499965 | validation: 0.11257352264903478]
	TIME [epoch: 8.51 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11202229485480004		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.11202229485480004 | validation: 0.13946638032265823]
	TIME [epoch: 8.53 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12448423911068071		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.12448423911068071 | validation: 0.14635251397720062]
	TIME [epoch: 8.51 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13593098254262975		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.13593098254262975 | validation: 0.2303356595426588]
	TIME [epoch: 8.51 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11768904738787271		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.11768904738787271 | validation: 0.13050915721711395]
	TIME [epoch: 8.51 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13039629459107477		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.13039629459107477 | validation: 0.08381383277054666]
	TIME [epoch: 8.53 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12123608670266554		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.12123608670266554 | validation: 0.09074425746297074]
	TIME [epoch: 8.51 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12475135271673665		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.12475135271673665 | validation: 0.08423805474040702]
	TIME [epoch: 8.51 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09986513596529255		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.09986513596529255 | validation: 0.09051612170019756]
	TIME [epoch: 8.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08482351304651674		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.08482351304651674 | validation: 0.16148124942575026]
	TIME [epoch: 8.53 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11518126020022694		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.11518126020022694 | validation: 0.17557272493398346]
	TIME [epoch: 8.51 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1243921303312969		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.1243921303312969 | validation: 0.09687559497118636]
	TIME [epoch: 8.51 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10125604828806653		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.10125604828806653 | validation: 0.18050949483516432]
	TIME [epoch: 8.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16872102793346003		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.16872102793346003 | validation: 0.11794268568207975]
	TIME [epoch: 8.52 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10904028432202431		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.10904028432202431 | validation: 0.0787001710867217]
	TIME [epoch: 8.51 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08907350322376176		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.08907350322376176 | validation: 0.1371358135094698]
	TIME [epoch: 8.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10104296091118634		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.10104296091118634 | validation: 0.0899548606405017]
	TIME [epoch: 8.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1016453208824019		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.1016453208824019 | validation: 0.08360975594632993]
	TIME [epoch: 8.53 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08761006399491574		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.08761006399491574 | validation: 0.10646884155267522]
	TIME [epoch: 8.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12322236707859587		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.12322236707859587 | validation: 0.11944987200595547]
	TIME [epoch: 8.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07806806087556242		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.07806806087556242 | validation: 0.06924617498767395]
	TIME [epoch: 8.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08467809857384268		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.08467809857384268 | validation: 0.08255824155912855]
	TIME [epoch: 8.53 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09538788470730332		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.09538788470730332 | validation: 0.0754351707985735]
	TIME [epoch: 8.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07877702698498146		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.07877702698498146 | validation: 0.13438785134897704]
	TIME [epoch: 8.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08459752490973584		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.08459752490973584 | validation: 0.12357277213693438]
	TIME [epoch: 8.51 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08495682732427703		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.08495682732427703 | validation: 0.07275527384788416]
	TIME [epoch: 8.52 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656381718803221		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.07656381718803221 | validation: 0.07689111477924676]
	TIME [epoch: 8.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0908637002011989		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.0908637002011989 | validation: 0.0768415418926895]
	TIME [epoch: 8.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09207544245664988		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.09207544245664988 | validation: 0.06651166282857536]
	TIME [epoch: 8.51 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07408070660914064		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.07408070660914064 | validation: 0.07898795235052866]
	TIME [epoch: 8.51 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07768661597996458		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.07768661597996458 | validation: 0.08353002492651893]
	TIME [epoch: 8.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562769291672369		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.1562769291672369 | validation: 0.09477698696266934]
	TIME [epoch: 8.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08594718793695222		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.08594718793695222 | validation: 0.10608173866321755]
	TIME [epoch: 8.52 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10080347230359772		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.10080347230359772 | validation: 0.07310339789012132]
	TIME [epoch: 8.52 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.097426729819388		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.097426729819388 | validation: 0.15312623571404788]
	TIME [epoch: 8.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11777278545058593		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.11777278545058593 | validation: 0.05879190971846068]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1263.pth
	Model improved!!!
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08716460887580323		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.08716460887580323 | validation: 0.07840264534176121]
	TIME [epoch: 8.52 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07299278145086875		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.07299278145086875 | validation: 0.0581554507513905]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1265.pth
	Model improved!!!
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08705613980265228		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.08705613980265228 | validation: 0.09162007672649627]
	TIME [epoch: 8.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10401793179552207		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.10401793179552207 | validation: 0.15897795048467528]
	TIME [epoch: 8.51 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09764555334077243		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.09764555334077243 | validation: 0.0827652229063904]
	TIME [epoch: 8.52 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08953670206228688		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.08953670206228688 | validation: 0.09117812417639498]
	TIME [epoch: 8.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07554606094930481		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.07554606094930481 | validation: 0.08167887557148691]
	TIME [epoch: 8.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09441549312931825		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.09441549312931825 | validation: 0.10558977670083021]
	TIME [epoch: 8.49 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08568532829700386		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.08568532829700386 | validation: 0.07328474499147059]
	TIME [epoch: 8.52 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08845896913029008		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.08845896913029008 | validation: 0.10197963503300819]
	TIME [epoch: 8.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08182626676093935		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.08182626676093935 | validation: 0.11384789818145999]
	TIME [epoch: 8.49 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08623355970533991		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.08623355970533991 | validation: 0.0903555476188817]
	TIME [epoch: 8.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10309510959490398		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.10309510959490398 | validation: 0.10912385617903773]
	TIME [epoch: 8.52 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10201393164081422		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.10201393164081422 | validation: 0.08985867232201461]
	TIME [epoch: 8.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11442441305391353		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.11442441305391353 | validation: 0.08007971707248548]
	TIME [epoch: 8.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1024997793249248		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.1024997793249248 | validation: 0.07207838125929625]
	TIME [epoch: 8.51 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1061776181296735		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.1061776181296735 | validation: 0.07598014284771484]
	TIME [epoch: 8.53 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778908306737187		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.0778908306737187 | validation: 0.055628886591571544]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1281.pth
	Model improved!!!
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08141353413960345		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.08141353413960345 | validation: 0.07296923461796753]
	TIME [epoch: 8.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10081166471709133		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.10081166471709133 | validation: 0.05540034056508657]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1283.pth
	Model improved!!!
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07951010757054382		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.07951010757054382 | validation: 0.0608536054091347]
	TIME [epoch: 8.52 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09752809768135873		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.09752809768135873 | validation: 0.0652883112965186]
	TIME [epoch: 8.49 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778658621938445		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.0778658621938445 | validation: 0.07280981765901118]
	TIME [epoch: 8.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10080356357832336		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.10080356357832336 | validation: 0.10271082129848619]
	TIME [epoch: 8.51 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09003782217738614		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.09003782217738614 | validation: 0.08057469284602559]
	TIME [epoch: 8.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07298442008677689		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.07298442008677689 | validation: 0.08606410715573364]
	TIME [epoch: 8.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06675466733342289		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.06675466733342289 | validation: 0.07289308274270218]
	TIME [epoch: 8.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.074305750658028		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.074305750658028 | validation: 0.10202146708725951]
	TIME [epoch: 8.52 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10203032905779974		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.10203032905779974 | validation: 0.09090500561083592]
	TIME [epoch: 8.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08372137664151322		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.08372137664151322 | validation: 0.09973172598430771]
	TIME [epoch: 8.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816722400815049		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.07816722400815049 | validation: 0.08289738350851984]
	TIME [epoch: 8.49 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0781014249153567		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.0781014249153567 | validation: 0.06883834284725526]
	TIME [epoch: 8.52 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10729254009027193		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.10729254009027193 | validation: 0.12372229605003965]
	TIME [epoch: 8.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0885479564089997		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.0885479564089997 | validation: 0.08778890270973708]
	TIME [epoch: 8.49 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08898858472985753		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.08898858472985753 | validation: 0.13041273128207026]
	TIME [epoch: 8.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09901070360750108		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.09901070360750108 | validation: 0.1069745617644775]
	TIME [epoch: 8.52 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07834642242583593		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.07834642242583593 | validation: 0.07620655984782525]
	TIME [epoch: 8.49 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09740549913700416		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.09740549913700416 | validation: 0.05566356860751415]
	TIME [epoch: 8.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06142233744140522		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.06142233744140522 | validation: 0.06600809911735746]
	TIME [epoch: 8.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06642985822112012		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.06642985822112012 | validation: 0.06517519456920691]
	TIME [epoch: 8.52 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08575270250017518		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.08575270250017518 | validation: 0.09983020187721615]
	TIME [epoch: 8.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08184256975138614		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.08184256975138614 | validation: 0.10644087728320445]
	TIME [epoch: 8.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09368100475415853		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.09368100475415853 | validation: 0.060848274396185904]
	TIME [epoch: 8.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07104684983501779		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.07104684983501779 | validation: 0.10135983058148501]
	TIME [epoch: 8.51 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07982433231770444		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.07982433231770444 | validation: 0.06772510088085203]
	TIME [epoch: 8.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08998169032316469		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.08998169032316469 | validation: 0.0646561594141509]
	TIME [epoch: 8.49 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09244512746157382		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.09244512746157382 | validation: 0.10049469661386314]
	TIME [epoch: 8.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10529173746754945		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.10529173746754945 | validation: 0.07772598504347406]
	TIME [epoch: 8.52 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0847776578111137		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.0847776578111137 | validation: 0.10710335266608884]
	TIME [epoch: 8.49 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08245275945778305		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.08245275945778305 | validation: 0.06832014085934932]
	TIME [epoch: 8.49 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07372588734294548		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.07372588734294548 | validation: 0.10693064659160068]
	TIME [epoch: 8.49 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07070467871938688		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.07070467871938688 | validation: 0.08004118345541812]
	TIME [epoch: 8.51 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205721069373232		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.07205721069373232 | validation: 0.08407050363876173]
	TIME [epoch: 8.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09569834531912322		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.09569834531912322 | validation: 0.06690261360734115]
	TIME [epoch: 8.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10365389451344001		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.10365389451344001 | validation: 0.06912839560935258]
	TIME [epoch: 8.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07352538206668774		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.07352538206668774 | validation: 0.09532203799541648]
	TIME [epoch: 8.52 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07845277559494648		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.07845277559494648 | validation: 0.05334269946640912]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1320.pth
	Model improved!!!
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06848837022377081		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.06848837022377081 | validation: 0.07751113657356096]
	TIME [epoch: 8.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07621150130757828		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.07621150130757828 | validation: 0.06241630281720903]
	TIME [epoch: 8.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13423002005477053		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.13423002005477053 | validation: 0.0758700651642575]
	TIME [epoch: 8.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08804651895425523		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.08804651895425523 | validation: 0.07026664542604692]
	TIME [epoch: 8.49 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07062039877470218		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.07062039877470218 | validation: 0.05920999155664855]
	TIME [epoch: 8.48 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09109745538809398		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.09109745538809398 | validation: 0.07552982824294605]
	TIME [epoch: 8.51 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06942836399162886		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.06942836399162886 | validation: 0.06894826230302686]
	TIME [epoch: 8.49 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07806777619212124		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.07806777619212124 | validation: 0.10658257162614332]
	TIME [epoch: 8.49 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09054716676023272		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.09054716676023272 | validation: 0.08713470133370234]
	TIME [epoch: 8.49 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07330585162061702		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.07330585162061702 | validation: 0.0949981095593075]
	TIME [epoch: 8.51 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0726274600855		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.0726274600855 | validation: 0.07963355735099173]
	TIME [epoch: 8.49 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09903338369861828		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.09903338369861828 | validation: 0.0989983880448376]
	TIME [epoch: 8.49 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054028453864852		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.07054028453864852 | validation: 0.0673609485115154]
	TIME [epoch: 8.49 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07903596102097248		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.07903596102097248 | validation: 0.07899645876382161]
	TIME [epoch: 8.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08413062230355264		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.08413062230355264 | validation: 0.07490966603001317]
	TIME [epoch: 8.48 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07393986362595681		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.07393986362595681 | validation: 0.06534376142182742]
	TIME [epoch: 8.48 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07248502641093625		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.07248502641093625 | validation: 0.11022586488424935]
	TIME [epoch: 8.49 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790400766111958		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.0790400766111958 | validation: 0.10066813243221319]
	TIME [epoch: 8.51 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06568355407487754		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.06568355407487754 | validation: 0.07954318940170085]
	TIME [epoch: 8.49 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07494884598304014		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.07494884598304014 | validation: 0.07547378146127859]
	TIME [epoch: 8.49 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07211740501339421		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.07211740501339421 | validation: 0.06799534311800821]
	TIME [epoch: 8.49 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10094144791067239		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.10094144791067239 | validation: 0.06153465194151497]
	TIME [epoch: 8.51 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0731160845353501		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.0731160845353501 | validation: 0.08306418220343109]
	TIME [epoch: 8.49 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07177358217983461		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.07177358217983461 | validation: 0.09440581886595405]
	TIME [epoch: 8.48 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07643836729662527		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.07643836729662527 | validation: 0.09924801939949535]
	TIME [epoch: 8.49 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09016170949066263		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.09016170949066263 | validation: 0.15191773104849932]
	TIME [epoch: 8.51 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11037808361795054		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.11037808361795054 | validation: 0.07386578127713897]
	TIME [epoch: 8.48 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08333803654368435		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.08333803654368435 | validation: 0.0644684337590248]
	TIME [epoch: 8.48 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07403532249171954		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.07403532249171954 | validation: 0.10447939846175824]
	TIME [epoch: 8.49 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09397079802258688		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.09397079802258688 | validation: 0.1029789202624577]
	TIME [epoch: 8.52 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08112241106062329		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.08112241106062329 | validation: 0.15008488505626197]
	TIME [epoch: 8.49 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09785109856903133		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.09785109856903133 | validation: 0.08951160384702736]
	TIME [epoch: 8.49 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07867052861533756		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.07867052861533756 | validation: 0.10374858978544099]
	TIME [epoch: 8.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07877054443074352		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.07877054443074352 | validation: 0.07070877943363253]
	TIME [epoch: 8.49 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07190384445963996		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.07190384445963996 | validation: 0.0957305443932274]
	TIME [epoch: 8.49 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0984773801948219		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.0984773801948219 | validation: 0.09756385260812181]
	TIME [epoch: 8.48 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08646222419759364		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.08646222419759364 | validation: 0.08383993655876501]
	TIME [epoch: 8.49 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09362660666202545		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.09362660666202545 | validation: 0.07206394937655601]
	TIME [epoch: 8.49 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07655507073918008		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.07655507073918008 | validation: 0.06577134065111787]
	TIME [epoch: 8.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06509835123245536		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.06509835123245536 | validation: 0.07737020928712193]
	TIME [epoch: 8.49 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061846348365559446		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.061846348365559446 | validation: 0.0900001971765133]
	TIME [epoch: 8.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08069466904297859		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.08069466904297859 | validation: 0.07450048137082202]
	TIME [epoch: 8.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07121377315269531		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.07121377315269531 | validation: 0.07676080221942956]
	TIME [epoch: 8.49 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500877013245175		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.06500877013245175 | validation: 0.05526788320200375]
	TIME [epoch: 8.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06831580833637593		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.06831580833637593 | validation: 0.07820153292669797]
	TIME [epoch: 8.51 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06312724357417085		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.06312724357417085 | validation: 0.06259162312744253]
	TIME [epoch: 8.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07642737363485093		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.07642737363485093 | validation: 0.12358131032772833]
	TIME [epoch: 8.49 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08054908206925968		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.08054908206925968 | validation: 0.09509276031593383]
	TIME [epoch: 8.49 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07171685374573969		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.07171685374573969 | validation: 0.07506026307446141]
	TIME [epoch: 8.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08042166058452731		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.08042166058452731 | validation: 0.07174588756890335]
	TIME [epoch: 8.48 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06535092131581702		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.06535092131581702 | validation: 0.08011868128482583]
	TIME [epoch: 8.48 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06446503721807603		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.06446503721807603 | validation: 0.07452146971956175]
	TIME [epoch: 8.49 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07103561814808797		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.07103561814808797 | validation: 0.05963104213127231]
	TIME [epoch: 8.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07336802688283348		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.07336802688283348 | validation: 0.08311413557139316]
	TIME [epoch: 8.49 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07325444190523453		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.07325444190523453 | validation: 0.057999811096241194]
	TIME [epoch: 8.48 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07076571334769931		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.07076571334769931 | validation: 0.05556373001358028]
	TIME [epoch: 8.48 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059369116614903086		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.059369116614903086 | validation: 0.12333732652122022]
	TIME [epoch: 8.51 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09689586614131059		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.09689586614131059 | validation: 0.09186864559403678]
	TIME [epoch: 8.48 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0852022655635676		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.0852022655635676 | validation: 0.13220048333874757]
	TIME [epoch: 8.48 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0755517548979858		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.0755517548979858 | validation: 0.06284155324601619]
	TIME [epoch: 8.49 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221218235398148		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.07221218235398148 | validation: 0.08361648451053849]
	TIME [epoch: 8.51 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06986534370212993		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.06986534370212993 | validation: 0.07771817406972863]
	TIME [epoch: 8.49 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06550870801757319		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.06550870801757319 | validation: 0.08402695019891677]
	TIME [epoch: 8.49 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09433423174081029		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.09433423174081029 | validation: 0.09062321578913715]
	TIME [epoch: 8.47 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07514673277372465		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.07514673277372465 | validation: 0.0735249312821956]
	TIME [epoch: 8.51 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09134841319660778		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.09134841319660778 | validation: 0.07077350521539924]
	TIME [epoch: 8.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08011102479937725		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.08011102479937725 | validation: 0.09546888236587754]
	TIME [epoch: 8.48 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981571719200761		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.08981571719200761 | validation: 0.08429723131465576]
	TIME [epoch: 8.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11167181506207632		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.11167181506207632 | validation: 0.1250861586004256]
	TIME [epoch: 8.51 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08328487794572136		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.08328487794572136 | validation: 0.07285498839287824]
	TIME [epoch: 8.49 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0784584766943353		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.0784584766943353 | validation: 0.07351132573822722]
	TIME [epoch: 8.49 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08227693990014542		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.08227693990014542 | validation: 0.10321120057556174]
	TIME [epoch: 8.49 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09499066710941538		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.09499066710941538 | validation: 0.13842601966746496]
	TIME [epoch: 8.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10320675306414104		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.10320675306414104 | validation: 0.0756859762072241]
	TIME [epoch: 8.49 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06941458151090271		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.06941458151090271 | validation: 0.06826904291195499]
	TIME [epoch: 8.49 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062278743865384456		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.062278743865384456 | validation: 0.063305730960428]
	TIME [epoch: 8.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07682826157692915		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.07682826157692915 | validation: 0.06737819925284672]
	TIME [epoch: 8.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06478767637927485		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.06478767637927485 | validation: 0.06629182610162412]
	TIME [epoch: 8.48 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06262327586025185		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.06262327586025185 | validation: 0.06858128110010052]
	TIME [epoch: 8.49 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06865806668117969		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.06865806668117969 | validation: 0.1473615675434945]
	TIME [epoch: 8.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08623039774710661		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.08623039774710661 | validation: 0.07186456524980367]
	TIME [epoch: 8.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07136725857972624		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.07136725857972624 | validation: 0.08680342354800985]
	TIME [epoch: 8.48 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06947326992352998		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.06947326992352998 | validation: 0.059396612167052665]
	TIME [epoch: 8.49 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07737935595555191		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.07737935595555191 | validation: 0.11865038783068675]
	TIME [epoch: 8.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07697637349033384		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.07697637349033384 | validation: 0.1049766034361641]
	TIME [epoch: 8.49 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158339706687776		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.08158339706687776 | validation: 0.07026705021413403]
	TIME [epoch: 8.48 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08229320606474003		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.08229320606474003 | validation: 0.09615732612136914]
	TIME [epoch: 8.49 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08886111043196585		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.08886111043196585 | validation: 0.06466564222604737]
	TIME [epoch: 8.51 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09089911350316313		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.09089911350316313 | validation: 0.12364556839364227]
	TIME [epoch: 8.49 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08733484340378642		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.08733484340378642 | validation: 0.07023410897020718]
	TIME [epoch: 8.48 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07129652256521987		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.07129652256521987 | validation: 0.06551098942031336]
	TIME [epoch: 8.49 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07858852045458771		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.07858852045458771 | validation: 0.08485655899048748]
	TIME [epoch: 8.51 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07843467012281297		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.07843467012281297 | validation: 0.15530498768812911]
	TIME [epoch: 8.48 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07922340253730008		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.07922340253730008 | validation: 0.0672970830390342]
	TIME [epoch: 8.49 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06886458963422164		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.06886458963422164 | validation: 0.059206399698677026]
	TIME [epoch: 8.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07367846075914311		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.07367846075914311 | validation: 0.06056204563854611]
	TIME [epoch: 8.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07105126996496981		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.07105126996496981 | validation: 0.0904068618740347]
	TIME [epoch: 8.48 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10408728915243153		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.10408728915243153 | validation: 0.06379766764716245]
	TIME [epoch: 8.49 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766154648594755		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.0766154648594755 | validation: 0.06653944725006578]
	TIME [epoch: 8.48 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832393034971379		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.0832393034971379 | validation: 0.05525351282771011]
	TIME [epoch: 8.51 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06797600861070249		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.06797600861070249 | validation: 0.06651047168516928]
	TIME [epoch: 8.51 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07153845145086254		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.07153845145086254 | validation: 0.10643230371438667]
	TIME [epoch: 8.49 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0853066033164345		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.0853066033164345 | validation: 0.060643144830956786]
	TIME [epoch: 8.48 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651049287182647		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.0651049287182647 | validation: 0.06292942525929718]
	TIME [epoch: 8.52 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0774054103119738		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.0774054103119738 | validation: 0.07170883031944585]
	TIME [epoch: 8.49 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08075037013546245		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.08075037013546245 | validation: 0.06403031206951582]
	TIME [epoch: 8.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09181340283845571		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.09181340283845571 | validation: 0.07996802515941726]
	TIME [epoch: 8.49 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06795926742257227		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.06795926742257227 | validation: 0.14970592509344238]
	TIME [epoch: 8.51 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09996154500705297		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.09996154500705297 | validation: 0.07441195615908179]
	TIME [epoch: 8.48 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07737061328499215		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.07737061328499215 | validation: 0.06160664396976019]
	TIME [epoch: 8.49 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08629937229784493		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.08629937229784493 | validation: 0.09019072205681292]
	TIME [epoch: 8.49 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08364459859979394		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.08364459859979394 | validation: 0.08192090076082092]
	TIME [epoch: 8.49 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07433623127045622		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.07433623127045622 | validation: 0.07611048320358457]
	TIME [epoch: 8.47 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07890696670639266		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.07890696670639266 | validation: 0.0677181281392203]
	TIME [epoch: 8.48 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0942514383959265		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.0942514383959265 | validation: 0.0763853043953131]
	TIME [epoch: 8.51 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06710422051062254		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.06710422051062254 | validation: 0.10267343631454409]
	TIME [epoch: 8.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07120020087609882		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.07120020087609882 | validation: 0.07798564414583659]
	TIME [epoch: 8.49 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0666636904200359		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.0666636904200359 | validation: 0.06386441852940399]
	TIME [epoch: 8.49 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059096942069088075		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.059096942069088075 | validation: 0.05246881450933086]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1439.pth
	Model improved!!!
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07125302343048294		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.07125302343048294 | validation: 0.059565288992894955]
	TIME [epoch: 8.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07288375457979632		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.07288375457979632 | validation: 0.06783857611033076]
	TIME [epoch: 8.49 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0733403704406443		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.0733403704406443 | validation: 0.12958467702994314]
	TIME [epoch: 8.48 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0810494614877752		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.0810494614877752 | validation: 0.05727247750176081]
	TIME [epoch: 8.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07171699413349575		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.07171699413349575 | validation: 0.13235067925949034]
	TIME [epoch: 8.49 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07858326387944436		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.07858326387944436 | validation: 0.07488772763911836]
	TIME [epoch: 8.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06933680537723895		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.06933680537723895 | validation: 0.059907756227525796]
	TIME [epoch: 8.48 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08127038716312121		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.08127038716312121 | validation: 0.09746182689642893]
	TIME [epoch: 8.51 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09057298699637148		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.09057298699637148 | validation: 0.1056250542885475]
	TIME [epoch: 8.49 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09575100987046095		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.09575100987046095 | validation: 0.0837380411619491]
	TIME [epoch: 8.49 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08015272618569917		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.08015272618569917 | validation: 0.07537451567630671]
	TIME [epoch: 8.48 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06171832417869992		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.06171832417869992 | validation: 0.061548276355953134]
	TIME [epoch: 8.51 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05912914669054601		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.05912914669054601 | validation: 0.06208468174555854]
	TIME [epoch: 8.48 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06550318787816423		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.06550318787816423 | validation: 0.08742833314260293]
	TIME [epoch: 8.49 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07395867205671885		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.07395867205671885 | validation: 0.05756211970848067]
	TIME [epoch: 8.49 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06777430834952172		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.06777430834952172 | validation: 0.050952716132439006]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1455.pth
	Model improved!!!
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06985880696665273		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.06985880696665273 | validation: 0.09928293763626958]
	TIME [epoch: 8.48 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11002783768897917		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.11002783768897917 | validation: 0.06769799808615207]
	TIME [epoch: 8.48 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682349383609195		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.0682349383609195 | validation: 0.06416009166495025]
	TIME [epoch: 8.48 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06305712901859564		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.06305712901859564 | validation: 0.07487430713416572]
	TIME [epoch: 8.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07353315783157514		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.07353315783157514 | validation: 0.12963623905178542]
	TIME [epoch: 8.48 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08956404080093032		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.08956404080093032 | validation: 0.05799312691997299]
	TIME [epoch: 8.48 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06454046007455565		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.06454046007455565 | validation: 0.07566709647526149]
	TIME [epoch: 8.49 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07677859537464102		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.07677859537464102 | validation: 0.059608011083520915]
	TIME [epoch: 8.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0653092989609791		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.0653092989609791 | validation: 0.08695508164338572]
	TIME [epoch: 8.48 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07127984065641371		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.07127984065641371 | validation: 0.06523106413897821]
	TIME [epoch: 8.48 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066375949331882		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.07066375949331882 | validation: 0.07173884550305397]
	TIME [epoch: 8.49 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662911195192507		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.0662911195192507 | validation: 0.0833637226251363]
	TIME [epoch: 8.48 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06280268997425041		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.06280268997425041 | validation: 0.058348344435970395]
	TIME [epoch: 8.49 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05800846447229853		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.05800846447229853 | validation: 0.06062757136074505]
	TIME [epoch: 8.49 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06980699999799436		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.06980699999799436 | validation: 0.06432549549273292]
	TIME [epoch: 8.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07485038865634605		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.07485038865634605 | validation: 0.06638260841567682]
	TIME [epoch: 8.49 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07823682678480294		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.07823682678480294 | validation: 0.06575421695275001]
	TIME [epoch: 8.48 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631421428193132		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.0631421428193132 | validation: 0.08823968430677921]
	TIME [epoch: 8.48 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07421723016580058		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.07421723016580058 | validation: 0.06690630891460397]
	TIME [epoch: 8.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0707305244526254		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.0707305244526254 | validation: 0.10648750441931379]
	TIME [epoch: 8.48 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06929717806580717		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.06929717806580717 | validation: 0.07164490357685357]
	TIME [epoch: 8.48 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790516339335383		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.0790516339335383 | validation: 0.07074631534676401]
	TIME [epoch: 8.49 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06574815817317176		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.06574815817317176 | validation: 0.07798707253544437]
	TIME [epoch: 8.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06540755652169279		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.06540755652169279 | validation: 0.06046462936659126]
	TIME [epoch: 8.48 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062435680625422776		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.062435680625422776 | validation: 0.06529903509667]
	TIME [epoch: 8.49 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06517432820859474		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.06517432820859474 | validation: 0.07068493059227152]
	TIME [epoch: 8.48 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0700511216618398		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.0700511216618398 | validation: 0.10726168572830597]
	TIME [epoch: 8.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0767506714544994		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.0767506714544994 | validation: 0.09049067612553795]
	TIME [epoch: 8.49 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09372028320468509		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.09372028320468509 | validation: 0.07546352749885005]
	TIME [epoch: 8.47 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062003217326493		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.062003217326493 | validation: 0.058099994495565535]
	TIME [epoch: 8.49 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441816463147346		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.06441816463147346 | validation: 0.08613535670503744]
	TIME [epoch: 8.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09129514798639407		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.09129514798639407 | validation: 0.06522566915934574]
	TIME [epoch: 8.47 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06243266810744792		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.06243266810744792 | validation: 0.055659211264452044]
	TIME [epoch: 8.48 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724983277527062		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.06724983277527062 | validation: 0.07757958521956462]
	TIME [epoch: 8.49 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06637029715148313		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.06637029715148313 | validation: 0.07298109965303301]
	TIME [epoch: 8.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07717985348524806		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.07717985348524806 | validation: 0.07902841800196345]
	TIME [epoch: 8.47 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221691819569537		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.07221691819569537 | validation: 0.06371548272142147]
	TIME [epoch: 8.47 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0655833799390871		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.0655833799390871 | validation: 0.10623320630512209]
	TIME [epoch: 8.47 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06811005442350042		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.06811005442350042 | validation: 0.057235459242349185]
	TIME [epoch: 8.49 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676270937135156		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.0676270937135156 | validation: 0.07189720911761546]
	TIME [epoch: 8.48 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0640331765860255		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.0640331765860255 | validation: 0.08188490241753935]
	TIME [epoch: 8.49 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08328600488006013		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.08328600488006013 | validation: 0.08342817702749948]
	TIME [epoch: 8.46 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07927903823398746		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.07927903823398746 | validation: 0.06154460562109115]
	TIME [epoch: 8.49 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07926190936274206		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.07926190936274206 | validation: 0.08091830833114158]
	TIME [epoch: 8.46 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07178893061051136		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.07178893061051136 | validation: 0.08033388341911571]
	TIME [epoch: 8.48 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07348969304526196		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.07348969304526196 | validation: 0.08654533194435664]
	TIME [epoch: 8.48 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08068663462539148		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.08068663462539148 | validation: 0.09810067187643079]
	TIME [epoch: 8.49 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07282253169320027		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.07282253169320027 | validation: 0.07872494307333844]
	TIME [epoch: 8.47 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09237773315983766		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.09237773315983766 | validation: 0.07006464174598187]
	TIME [epoch: 8.47 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07222832244322053		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.07222832244322053 | validation: 0.07079276899043255]
	TIME [epoch: 8.49 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06919383263364332		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.06919383263364332 | validation: 0.076427345895063]
	TIME [epoch: 8.49 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07488562108224453		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.07488562108224453 | validation: 0.07817786239650287]
	TIME [epoch: 8.47 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062434281068783196		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.062434281068783196 | validation: 0.06230338688817515]
	TIME [epoch: 8.47 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0709263426221758		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.0709263426221758 | validation: 0.05051882631013123]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1509.pth
	Model improved!!!
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06187116494449456		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.06187116494449456 | validation: 0.07613266178214732]
	TIME [epoch: 8.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07000316712208558		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.07000316712208558 | validation: 0.05996218356168949]
	TIME [epoch: 8.48 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0748429334088787		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.0748429334088787 | validation: 0.08815477516590406]
	TIME [epoch: 8.49 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05793536158247542		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.05793536158247542 | validation: 0.05129233985444938]
	TIME [epoch: 8.51 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05915464905114613		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.05915464905114613 | validation: 0.07069313222291322]
	TIME [epoch: 8.49 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205718670600078		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.07205718670600078 | validation: 0.0624661616760506]
	TIME [epoch: 8.48 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07163975124269131		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.07163975124269131 | validation: 0.09197954979722547]
	TIME [epoch: 8.49 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059947748570322104		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.059947748570322104 | validation: 0.09871326090013258]
	TIME [epoch: 8.51 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08587120471132702		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.08587120471132702 | validation: 0.0583157468568155]
	TIME [epoch: 8.49 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06342156827152408		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.06342156827152408 | validation: 0.09357430163802888]
	TIME [epoch: 8.49 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06302586907903404		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.06302586907903404 | validation: 0.061675624158465225]
	TIME [epoch: 8.49 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07095231767841097		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.07095231767841097 | validation: 0.06655421455579669]
	TIME [epoch: 8.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0635617674760973		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.0635617674760973 | validation: 0.0742017793057106]
	TIME [epoch: 8.49 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0995460339568395		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.0995460339568395 | validation: 0.06132101150792355]
	TIME [epoch: 8.48 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06178200975457728		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.06178200975457728 | validation: 0.05618215510655951]
	TIME [epoch: 8.49 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060518414589155356		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.060518414589155356 | validation: 0.05900666401029896]
	TIME [epoch: 8.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06460067460074068		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.06460067460074068 | validation: 0.06688449618751781]
	TIME [epoch: 8.49 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0827172008092962		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.0827172008092962 | validation: 0.07264251059246318]
	TIME [epoch: 8.48 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06664262079415478		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.06664262079415478 | validation: 0.1182537734934141]
	TIME [epoch: 8.49 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07961613660744096		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.07961613660744096 | validation: 0.055976445314997174]
	TIME [epoch: 8.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06904564101688462		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.06904564101688462 | validation: 0.06578238452589061]
	TIME [epoch: 8.49 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06838076375657916		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.06838076375657916 | validation: 0.0932458822431296]
	TIME [epoch: 8.48 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07648564884278905		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.07648564884278905 | validation: 0.056170100860268884]
	TIME [epoch: 8.49 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0586786130029992		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.0586786130029992 | validation: 0.06533212667737763]
	TIME [epoch: 8.51 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0565743216292036		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.0565743216292036 | validation: 0.0817081245843321]
	TIME [epoch: 8.49 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11682238058597436		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.11682238058597436 | validation: 0.06592549381426144]
	TIME [epoch: 8.48 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0587143610350796		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.0587143610350796 | validation: 0.07108708938396227]
	TIME [epoch: 8.49 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06365041679154686		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.06365041679154686 | validation: 0.06219863662386593]
	TIME [epoch: 8.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060345833738163455		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.060345833738163455 | validation: 0.059072723862300315]
	TIME [epoch: 8.49 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06353743349028333		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.06353743349028333 | validation: 0.06433653532533201]
	TIME [epoch: 8.49 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06448668293448694		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.06448668293448694 | validation: 0.059240519467675]
	TIME [epoch: 8.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05728123231360752		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.05728123231360752 | validation: 0.057447859084921137]
	TIME [epoch: 8.49 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06825492648864283		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.06825492648864283 | validation: 0.05403911354093799]
	TIME [epoch: 8.49 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05986910425289664		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.05986910425289664 | validation: 0.06761124937963513]
	TIME [epoch: 8.48 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07733372293956509		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.07733372293956509 | validation: 0.07956428900206008]
	TIME [epoch: 8.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06807042701000517		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.06807042701000517 | validation: 0.056079890472330224]
	TIME [epoch: 8.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0630957187279674		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.0630957187279674 | validation: 0.07905877295722624]
	TIME [epoch: 8.49 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07107333478562292		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.07107333478562292 | validation: 0.06241779781744636]
	TIME [epoch: 8.49 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0809274198727598		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.0809274198727598 | validation: 0.07227090237012909]
	TIME [epoch: 8.51 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06297792894050286		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.06297792894050286 | validation: 0.08763535276558326]
	TIME [epoch: 8.49 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07158452005723602		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.07158452005723602 | validation: 0.07962559753882066]
	TIME [epoch: 8.49 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.065575531147153		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.065575531147153 | validation: 0.054968423708897124]
	TIME [epoch: 8.49 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06462125999895377		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.06462125999895377 | validation: 0.051970057334693585]
	TIME [epoch: 8.51 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058854250046938325		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.058854250046938325 | validation: 0.06995142685282164]
	TIME [epoch: 8.49 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07717469080641673		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.07717469080641673 | validation: 0.0888843129716885]
	TIME [epoch: 8.49 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06804830151821172		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.06804830151821172 | validation: 0.06792569802034415]
	TIME [epoch: 8.49 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07283737876846777		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.07283737876846777 | validation: 0.06679926453499624]
	TIME [epoch: 8.51 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05761589790088937		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.05761589790088937 | validation: 0.07135943646335995]
	TIME [epoch: 8.49 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07622487980225334		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.07622487980225334 | validation: 0.093326043768922]
	TIME [epoch: 8.49 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07286815921409628		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.07286815921409628 | validation: 0.07619761161831504]
	TIME [epoch: 8.49 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07187436971099877		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.07187436971099877 | validation: 0.07668136932077359]
	TIME [epoch: 8.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0655054677395759		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.0655054677395759 | validation: 0.07975015184451312]
	TIME [epoch: 8.49 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06937891487517742		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.06937891487517742 | validation: 0.11967659704729519]
	TIME [epoch: 8.49 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06943944998110596		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.06943944998110596 | validation: 0.06714440794114745]
	TIME [epoch: 8.49 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06729978977203828		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.06729978977203828 | validation: 0.06459488115155196]
	TIME [epoch: 8.51 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816861271799422		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.07816861271799422 | validation: 0.08920290977744588]
	TIME [epoch: 8.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07527608455568632		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.07527608455568632 | validation: 0.09789751652644005]
	TIME [epoch: 8.49 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06546623252838513		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.06546623252838513 | validation: 0.07045651336630178]
	TIME [epoch: 8.49 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06488000683373082		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.06488000683373082 | validation: 0.060588584983844423]
	TIME [epoch: 8.51 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06564545073220943		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.06564545073220943 | validation: 0.11149185707222453]
	TIME [epoch: 8.49 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08569542979644082		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.08569542979644082 | validation: 0.07149050154602807]
	TIME [epoch: 8.49 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0773336087963888		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.0773336087963888 | validation: 0.07557352569162912]
	TIME [epoch: 8.49 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07413212909501397		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.07413212909501397 | validation: 0.06624590409819216]
	TIME [epoch: 8.51 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06856092078799228		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.06856092078799228 | validation: 0.062445484313301616]
	TIME [epoch: 8.49 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06078507566910287		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.06078507566910287 | validation: 0.055820707634654354]
	TIME [epoch: 8.49 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0580026823029294		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.0580026823029294 | validation: 0.06787185876388616]
	TIME [epoch: 8.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06511332749131102		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.06511332749131102 | validation: 0.08282480922571141]
	TIME [epoch: 8.51 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06785626192287203		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.06785626192287203 | validation: 0.06813764086855281]
	TIME [epoch: 8.49 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07060387634126887		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.07060387634126887 | validation: 0.08002116021886552]
	TIME [epoch: 8.49 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06580468119601397		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.06580468119601397 | validation: 0.056591636473900656]
	TIME [epoch: 8.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665316099069846		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.0665316099069846 | validation: 0.05302043753822859]
	TIME [epoch: 8.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06662456751311509		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.06662456751311509 | validation: 0.06767885337846193]
	TIME [epoch: 8.49 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07518326112878046		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.07518326112878046 | validation: 0.05243750182474304]
	TIME [epoch: 8.49 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05522881517692405		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.05522881517692405 | validation: 0.06111699257415877]
	TIME [epoch: 8.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0724701174159322		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.0724701174159322 | validation: 0.07400307963096651]
	TIME [epoch: 8.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05569960407045292		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.05569960407045292 | validation: 0.049757630029492406]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1585.pth
	Model improved!!!
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052313460393421475		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.052313460393421475 | validation: 0.08179495527736569]
	TIME [epoch: 8.49 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319458868628		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.06319458868628 | validation: 0.0659232473756925]
	TIME [epoch: 8.51 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05535897986224716		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.05535897986224716 | validation: 0.06215933229106343]
	TIME [epoch: 8.49 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06571998284573502		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.06571998284573502 | validation: 0.06945552233153478]
	TIME [epoch: 8.49 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05851184731324492		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.05851184731324492 | validation: 0.05230245928837461]
	TIME [epoch: 8.49 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056661101450571204		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.056661101450571204 | validation: 0.07729649935685419]
	TIME [epoch: 8.51 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05817331547117912		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.05817331547117912 | validation: 0.07140853502504499]
	TIME [epoch: 8.49 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441126115061332		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.06441126115061332 | validation: 0.07654469940209967]
	TIME [epoch: 8.49 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07428398800037843		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.07428398800037843 | validation: 0.06792164350699204]
	TIME [epoch: 8.49 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057352748336162704		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.057352748336162704 | validation: 0.06495383081008352]
	TIME [epoch: 8.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06008522197631574		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.06008522197631574 | validation: 0.07145686549032845]
	TIME [epoch: 8.49 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407308765950434		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.06407308765950434 | validation: 0.10801363715452508]
	TIME [epoch: 8.49 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0680837200998142		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.0680837200998142 | validation: 0.07123902536377061]
	TIME [epoch: 8.49 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07319620493523403		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.07319620493523403 | validation: 0.05309304757464814]
	TIME [epoch: 8.51 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05570601316609819		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.05570601316609819 | validation: 0.055888515051400495]
	TIME [epoch: 8.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651966002293005		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.06651966002293005 | validation: 0.07734315744278711]
	TIME [epoch: 8.49 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06685127689484496		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.06685127689484496 | validation: 0.05946165543451867]
	TIME [epoch: 8.49 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0608168202914827		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.0608168202914827 | validation: 0.06261148368245224]
	TIME [epoch: 8.51 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054266523209283546		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.054266523209283546 | validation: 0.06550409442336741]
	TIME [epoch: 8.49 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05413677300511871		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.05413677300511871 | validation: 0.05307949691736623]
	TIME [epoch: 8.49 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062199457752331856		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.062199457752331856 | validation: 0.0725891554141156]
	TIME [epoch: 8.49 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06697221708416219		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.06697221708416219 | validation: 0.058307525427855944]
	TIME [epoch: 8.51 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07049081645293995		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.07049081645293995 | validation: 0.06996591431754004]
	TIME [epoch: 8.49 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056629313164977414		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.056629313164977414 | validation: 0.055652055080270955]
	TIME [epoch: 8.49 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05953517300453622		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.05953517300453622 | validation: 0.07205110753378613]
	TIME [epoch: 8.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06376316910220087		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.06376316910220087 | validation: 0.056842275434249495]
	TIME [epoch: 8.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061417707859211766		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.061417707859211766 | validation: 0.07466506486628491]
	TIME [epoch: 8.49 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06646434793179173		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.06646434793179173 | validation: 0.054699195617261914]
	TIME [epoch: 8.49 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06160171518383907		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.06160171518383907 | validation: 0.05818572752348952]
	TIME [epoch: 8.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058031030938684426		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.058031030938684426 | validation: 0.11955671116507527]
	TIME [epoch: 8.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08784935762506894		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.08784935762506894 | validation: 0.06963984960094537]
	TIME [epoch: 8.49 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205847473107308		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.06205847473107308 | validation: 0.048181283203925625]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1617.pth
	Model improved!!!
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05386191676103885		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.05386191676103885 | validation: 0.056356425697106916]
	TIME [epoch: 8.53 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055944882206803805		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.055944882206803805 | validation: 0.07488546707938218]
	TIME [epoch: 8.51 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06808043554469946		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.06808043554469946 | validation: 0.0685225849705898]
	TIME [epoch: 8.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05908446361478076		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.05908446361478076 | validation: 0.05898555067841832]
	TIME [epoch: 8.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05893076942397737		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.05893076942397737 | validation: 0.07838160114919648]
	TIME [epoch: 8.52 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0679846744899662		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.0679846744899662 | validation: 0.05971092409458095]
	TIME [epoch: 8.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051174153259372426		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.051174153259372426 | validation: 0.07084288077265566]
	TIME [epoch: 8.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06778038234526747		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.06778038234526747 | validation: 0.06971775451887441]
	TIME [epoch: 8.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06133352439079294		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.06133352439079294 | validation: 0.06773995814973059]
	TIME [epoch: 8.52 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05831314556172963		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.05831314556172963 | validation: 0.0612173800016663]
	TIME [epoch: 8.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05679797292428557		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.05679797292428557 | validation: 0.06054813997775471]
	TIME [epoch: 8.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06120820393042914		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.06120820393042914 | validation: 0.07933890816357349]
	TIME [epoch: 8.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058504624482555445		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.058504624482555445 | validation: 0.05080205070504855]
	TIME [epoch: 8.53 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05720815094189994		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.05720815094189994 | validation: 0.056105627048898266]
	TIME [epoch: 8.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05844836895239264		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.05844836895239264 | validation: 0.06439882973172263]
	TIME [epoch: 8.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05704195011607503		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.05704195011607503 | validation: 0.053756891838050075]
	TIME [epoch: 8.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05165711399188365		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.05165711399188365 | validation: 0.056155934961688324]
	TIME [epoch: 8.53 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06431086235774823		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.06431086235774823 | validation: 0.059126775840261755]
	TIME [epoch: 8.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056602144330685125		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.056602144330685125 | validation: 0.05943257473844807]
	TIME [epoch: 8.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06142141716000048		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.06142141716000048 | validation: 0.10008726598428319]
	TIME [epoch: 8.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06969645960314416		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.06969645960314416 | validation: 0.07035467256070685]
	TIME [epoch: 8.53 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629712088826185		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.0629712088826185 | validation: 0.06653829127078174]
	TIME [epoch: 8.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06631612056449789		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.06631612056449789 | validation: 0.051412890636031466]
	TIME [epoch: 8.51 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07109602109965724		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.07109602109965724 | validation: 0.07022262656863158]
	TIME [epoch: 8.51 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648996054840094		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.0648996054840094 | validation: 0.07225336823665678]
	TIME [epoch: 8.52 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06728691883265683		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.06728691883265683 | validation: 0.06781441983594054]
	TIME [epoch: 8.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0664037490714534		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.0664037490714534 | validation: 0.05327646675790819]
	TIME [epoch: 8.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0635491894068814		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.0635491894068814 | validation: 0.06884615319577367]
	TIME [epoch: 8.52 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058284942072702094		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.058284942072702094 | validation: 0.06968868443731711]
	TIME [epoch: 8.51 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05858611880404052		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.05858611880404052 | validation: 0.07688141485543458]
	TIME [epoch: 8.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062311984291750534		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.062311984291750534 | validation: 0.06042688784522598]
	TIME [epoch: 8.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07335364119885682		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.07335364119885682 | validation: 0.057702737491368984]
	TIME [epoch: 8.52 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051693470100036484		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.051693470100036484 | validation: 0.04770392962375719]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1650.pth
	Model improved!!!
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05669994918938639		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.05669994918938639 | validation: 0.05586422470011146]
	TIME [epoch: 8.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061617694879961014		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.061617694879961014 | validation: 0.06169609974451451]
	TIME [epoch: 8.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06351084101360949		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.06351084101360949 | validation: 0.05722089790643611]
	TIME [epoch: 8.52 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07279296620419409		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.07279296620419409 | validation: 0.05785471684860969]
	TIME [epoch: 8.51 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06029321065961231		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.06029321065961231 | validation: 0.0547341744876864]
	TIME [epoch: 8.49 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06308326962142684		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.06308326962142684 | validation: 0.06514946953255825]
	TIME [epoch: 8.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05869579406443707		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.05869579406443707 | validation: 0.055958237733718906]
	TIME [epoch: 8.53 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062207729144991473		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.062207729144991473 | validation: 0.05041283696105282]
	TIME [epoch: 8.51 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05297052502197731		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.05297052502197731 | validation: 0.08456971316934087]
	TIME [epoch: 8.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059022051520049454		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.059022051520049454 | validation: 0.05786192937550781]
	TIME [epoch: 8.55 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06284207964276302		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.06284207964276302 | validation: 0.05819371200968171]
	TIME [epoch: 8.52 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06301429302722149		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.06301429302722149 | validation: 0.05181950213972179]
	TIME [epoch: 8.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06466962489188613		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.06466962489188613 | validation: 0.06623811934471072]
	TIME [epoch: 8.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060310560349554024		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.060310560349554024 | validation: 0.060297105795736286]
	TIME [epoch: 8.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060814515339328676		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.060814515339328676 | validation: 0.07954379113421747]
	TIME [epoch: 8.53 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07261471809144512		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.07261471809144512 | validation: 0.07696710275936038]
	TIME [epoch: 8.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06991437250395192		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.06991437250395192 | validation: 0.07989986073846363]
	TIME [epoch: 8.51 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06518338540516862		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.06518338540516862 | validation: 0.07541963902789611]
	TIME [epoch: 8.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07032041927921755		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.07032041927921755 | validation: 0.07947764047619243]
	TIME [epoch: 8.53 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631517157327519		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.0631517157327519 | validation: 0.06547086617067935]
	TIME [epoch: 8.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06617221921831286		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.06617221921831286 | validation: 0.05711243468874892]
	TIME [epoch: 8.51 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221746462767871		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.06221746462767871 | validation: 0.0808645901315879]
	TIME [epoch: 8.51 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07239595006545375		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.07239595006545375 | validation: 0.05014156182256268]
	TIME [epoch: 8.52 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06581563518041264		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.06581563518041264 | validation: 0.08120267932695278]
	TIME [epoch: 8.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07426329487896137		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.07426329487896137 | validation: 0.07304803706313223]
	TIME [epoch: 8.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829911559595504		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.0829911559595504 | validation: 0.09179013031797328]
	TIME [epoch: 8.51 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358902427215758		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.06358902427215758 | validation: 0.06372371180317159]
	TIME [epoch: 8.51 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05821107449224925		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.05821107449224925 | validation: 0.05590133221082017]
	TIME [epoch: 8.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06252543268311898		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.06252543268311898 | validation: 0.06907907051319158]
	TIME [epoch: 8.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05816596114404634		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.05816596114404634 | validation: 0.07680100798764616]
	TIME [epoch: 8.52 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07204570124059938		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.07204570124059938 | validation: 0.05201216489189779]
	TIME [epoch: 8.51 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060262772714361326		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.060262772714361326 | validation: 0.05947458379717667]
	TIME [epoch: 8.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06167513538788736		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.06167513538788736 | validation: 0.06096903220821634]
	TIME [epoch: 8.49 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05813477332641696		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.05813477332641696 | validation: 0.05690266191800527]
	TIME [epoch: 8.51 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05895435283103105		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.05895435283103105 | validation: 0.06284229697506975]
	TIME [epoch: 8.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05661134901450644		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.05661134901450644 | validation: 0.0783322927058909]
	TIME [epoch: 8.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061769283451213616		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.061769283451213616 | validation: 0.07840934276801467]
	TIME [epoch: 8.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06928643200504972		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.06928643200504972 | validation: 0.07272893605057731]
	TIME [epoch: 8.52 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628127270143348		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.0628127270143348 | validation: 0.07421456592420883]
	TIME [epoch: 8.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0692238644511231		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.0692238644511231 | validation: 0.06044740510838709]
	TIME [epoch: 8.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05660504846479072		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.05660504846479072 | validation: 0.07449190451295279]
	TIME [epoch: 8.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07335219207332784		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.07335219207332784 | validation: 0.05399306597425209]
	TIME [epoch: 8.52 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060038261043111184		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.060038261043111184 | validation: 0.07855603396830667]
	TIME [epoch: 8.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07385666372977504		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.07385666372977504 | validation: 0.055697637960448354]
	TIME [epoch: 8.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05557150801684069		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.05557150801684069 | validation: 0.06802742555703717]
	TIME [epoch: 8.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0601416519814824		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.0601416519814824 | validation: 0.06463494439638655]
	TIME [epoch: 8.52 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09428546621386688		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.09428546621386688 | validation: 0.06410263109064669]
	TIME [epoch: 8.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05659915707766679		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.05659915707766679 | validation: 0.07655582078332046]
	TIME [epoch: 8.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06247946850502575		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.06247946850502575 | validation: 0.048493083616087125]
	TIME [epoch: 8.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06131153081036996		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.06131153081036996 | validation: 0.056511519575092234]
	TIME [epoch: 8.52 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056820235579534584		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.056820235579534584 | validation: 0.07854545040076395]
	TIME [epoch: 8.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516675990866568		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.06516675990866568 | validation: 0.06168977723003444]
	TIME [epoch: 8.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057664351705300765		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.057664351705300765 | validation: 0.06164228241103964]
	TIME [epoch: 8.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05576917784134389		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.05576917784134389 | validation: 0.04894252021967463]
	TIME [epoch: 8.52 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05295482490400207		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.05295482490400207 | validation: 0.06560153974987865]
	TIME [epoch: 8.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05801690679850781		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.05801690679850781 | validation: 0.06263650842457694]
	TIME [epoch: 8.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05986915117417204		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.05986915117417204 | validation: 0.05270310846845601]
	TIME [epoch: 8.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642314448215345		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.0642314448215345 | validation: 0.06440400967552476]
	TIME [epoch: 8.51 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914063511725935		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.06914063511725935 | validation: 0.07917969625105403]
	TIME [epoch: 8.49 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07119784410504343		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.07119784410504343 | validation: 0.06070647082369805]
	TIME [epoch: 8.49 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516581293526788		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.06516581293526788 | validation: 0.10871564757881336]
	TIME [epoch: 8.51 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06506167280351807		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.06506167280351807 | validation: 0.04901005192482076]
	TIME [epoch: 8.51 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05135675930972876		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.05135675930972876 | validation: 0.056187220150046194]
	TIME [epoch: 8.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052947832840558116		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.052947832840558116 | validation: 0.06423106554739952]
	TIME [epoch: 8.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052842967938990806		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.052842967938990806 | validation: 0.05181291397306017]
	TIME [epoch: 8.51 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05586742287820805		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.05586742287820805 | validation: 0.061464948828399715]
	TIME [epoch: 8.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0597737074666916		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.0597737074666916 | validation: 0.06540435924919522]
	TIME [epoch: 8.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06506287350431544		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.06506287350431544 | validation: 0.06660829252705931]
	TIME [epoch: 8.49 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056645420335857066		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.056645420335857066 | validation: 0.04849603224021335]
	TIME [epoch: 8.52 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05252311478793945		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.05252311478793945 | validation: 0.05003256681007534]
	TIME [epoch: 8.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05080608878126721		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.05080608878126721 | validation: 0.05939121435118126]
	TIME [epoch: 8.49 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06348661311345191		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.06348661311345191 | validation: 0.07828973720628465]
	TIME [epoch: 8.49 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07729771698888459		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.07729771698888459 | validation: 0.05142009581334771]
	TIME [epoch: 8.52 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05024824070452114		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.05024824070452114 | validation: 0.07518093657689703]
	TIME [epoch: 8.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0681342793636565		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.0681342793636565 | validation: 0.04903064972466423]
	TIME [epoch: 8.49 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059115564197508005		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.059115564197508005 | validation: 0.06798285346637935]
	TIME [epoch: 8.49 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05470345748468001		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.05470345748468001 | validation: 0.05032146560053105]
	TIME [epoch: 8.51 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057819596099928004		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.057819596099928004 | validation: 0.053691998424688844]
	TIME [epoch: 8.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054449592759218624		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.054449592759218624 | validation: 0.057032834241809466]
	TIME [epoch: 8.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05168933797266708		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.05168933797266708 | validation: 0.05651333590754578]
	TIME [epoch: 8.49 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05798473782245521		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.05798473782245521 | validation: 0.05673010862570081]
	TIME [epoch: 8.52 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054937505858898915		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.054937505858898915 | validation: 0.0645466094317816]
	TIME [epoch: 8.49 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056003694149279706		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.056003694149279706 | validation: 0.07258209267076823]
	TIME [epoch: 8.49 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06556848349683705		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.06556848349683705 | validation: 0.06217457935695943]
	TIME [epoch: 8.49 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058234532062289825		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.058234532062289825 | validation: 0.05815375347738391]
	TIME [epoch: 8.52 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0503003460046809		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.0503003460046809 | validation: 0.05218439781576545]
	TIME [epoch: 8.49 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06804767301726436		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.06804767301726436 | validation: 0.07919876848977145]
	TIME [epoch: 8.49 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06440210192187747		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.06440210192187747 | validation: 0.05768709986400443]
	TIME [epoch: 8.49 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06821166719079709		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.06821166719079709 | validation: 0.05925128650568534]
	TIME [epoch: 8.52 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05722566935195297		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.05722566935195297 | validation: 0.07151128590655409]
	TIME [epoch: 8.49 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06925258247055824		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.06925258247055824 | validation: 0.07930594012845087]
	TIME [epoch: 8.49 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06011358374051441		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.06011358374051441 | validation: 0.06012224108343669]
	TIME [epoch: 8.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434984501030391		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.06434984501030391 | validation: 0.07342016848342278]
	TIME [epoch: 8.51 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07988191965146688		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.07988191965146688 | validation: 0.09515144101874747]
	TIME [epoch: 8.49 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07236629897566765		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.07236629897566765 | validation: 0.06928811515480124]
	TIME [epoch: 8.49 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07193283161462859		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.07193283161462859 | validation: 0.10020064128843478]
	TIME [epoch: 8.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06929622919524961		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.06929622919524961 | validation: 0.0639298519143428]
	TIME [epoch: 8.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06116735746430367		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.06116735746430367 | validation: 0.09168481678469506]
	TIME [epoch: 8.49 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06742410863363096		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.06742410863363096 | validation: 0.06300085102826236]
	TIME [epoch: 8.49 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05907237514214984		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.05907237514214984 | validation: 0.07955310033360391]
	TIME [epoch: 8.51 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661655702653986		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.0661655702653986 | validation: 0.06500626514640367]
	TIME [epoch: 8.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05454828149223506		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.05454828149223506 | validation: 0.0630961261810165]
	TIME [epoch: 8.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06120671862667375		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.06120671862667375 | validation: 0.06769630549793935]
	TIME [epoch: 8.49 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06072815868413336		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.06072815868413336 | validation: 0.06025031629275104]
	TIME [epoch: 8.51 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05985718307145754		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.05985718307145754 | validation: 0.06800358093283607]
	TIME [epoch: 8.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06314408330862537		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.06314408330862537 | validation: 0.05147679946480091]
	TIME [epoch: 8.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05494034756074092		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.05494034756074092 | validation: 0.06299164957983769]
	TIME [epoch: 8.49 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06197993425345346		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.06197993425345346 | validation: 0.07500191967693846]
	TIME [epoch: 8.51 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05548989214809461		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.05548989214809461 | validation: 0.05999213140100056]
	TIME [epoch: 8.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05952648860552216		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.05952648860552216 | validation: 0.06673095671430032]
	TIME [epoch: 8.49 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058844783206231696		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.058844783206231696 | validation: 0.06594118539790883]
	TIME [epoch: 8.49 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05551123640691349		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.05551123640691349 | validation: 0.04528299287688544]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1762.pth
	Model improved!!!
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052824445146669265		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.052824445146669265 | validation: 0.06730376855154596]
	TIME [epoch: 8.49 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058053744284817424		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.058053744284817424 | validation: 0.06214085340732278]
	TIME [epoch: 8.49 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05805005040802069		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.05805005040802069 | validation: 0.07099788657886172]
	TIME [epoch: 8.48 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05831434599040545		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.05831434599040545 | validation: 0.05755390789867511]
	TIME [epoch: 8.51 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06008474851476396		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.06008474851476396 | validation: 0.07668572084870999]
	TIME [epoch: 8.49 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06068552001861852		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.06068552001861852 | validation: 0.055916435368130984]
	TIME [epoch: 8.49 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06036010591453006		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.06036010591453006 | validation: 0.059555395637768606]
	TIME [epoch: 8.49 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058069900286360256		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.058069900286360256 | validation: 0.06368466578899716]
	TIME [epoch: 8.51 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05994575795956701		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.05994575795956701 | validation: 0.06619309338696167]
	TIME [epoch: 8.49 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671572294087078		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.06671572294087078 | validation: 0.06730410921124598]
	TIME [epoch: 8.49 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06094655053691098		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.06094655053691098 | validation: 0.05965115790443652]
	TIME [epoch: 8.49 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07135399869666485		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.07135399869666485 | validation: 0.07170226626523969]
	TIME [epoch: 8.51 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06655095224918219		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.06655095224918219 | validation: 0.07175893273369115]
	TIME [epoch: 8.49 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05268446703237746		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.05268446703237746 | validation: 0.05891502843833776]
	TIME [epoch: 8.49 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06860285641433775		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.06860285641433775 | validation: 0.08134399781074267]
	TIME [epoch: 8.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07224227904361433		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.07224227904361433 | validation: 0.07748809550246094]
	TIME [epoch: 8.51 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914711519900515		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.06914711519900515 | validation: 0.06644577687932965]
	TIME [epoch: 8.48 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06352709344511384		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.06352709344511384 | validation: 0.09236772203897488]
	TIME [epoch: 8.49 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07097751055667084		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.07097751055667084 | validation: 0.0676082044070788]
	TIME [epoch: 8.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05598395507946504		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.05598395507946504 | validation: 0.06339926108852065]
	TIME [epoch: 8.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05968637577451785		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.05968637577451785 | validation: 0.06165230906538195]
	TIME [epoch: 8.48 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061798458162913184		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.061798458162913184 | validation: 0.04436334959627952]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240219_184940/states/model_tr_study4_1784.pth
	Model improved!!!
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05598098558666784		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.05598098558666784 | validation: 0.0752882133123386]
	TIME [epoch: 8.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06779643363584067		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.06779643363584067 | validation: 0.06304169253809355]
	TIME [epoch: 8.49 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053993196391094976		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.053993196391094976 | validation: 0.06093739364882331]
	TIME [epoch: 8.49 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05611138682418193		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.05611138682418193 | validation: 0.060269998289580254]
	TIME [epoch: 8.48 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05063178941035854		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.05063178941035854 | validation: 0.06499507180754285]
	TIME [epoch: 8.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05915507061998968		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.05915507061998968 | validation: 0.09410620467259934]
	TIME [epoch: 8.49 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06077096923642875		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.06077096923642875 | validation: 0.07197438085398132]
	TIME [epoch: 8.48 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05926681689193821		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.05926681689193821 | validation: 0.07521974538002768]
	TIME [epoch: 8.49 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06399139153364855		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.06399139153364855 | validation: 0.07293700363881432]
	TIME [epoch: 8.51 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06190889108585897		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.06190889108585897 | validation: 0.06528380123319624]
	TIME [epoch: 8.49 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05676433486757001		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.05676433486757001 | validation: 0.054590061634597876]
	TIME [epoch: 8.48 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06165569645586246		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.06165569645586246 | validation: 0.07195419226947958]
	TIME [epoch: 8.49 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0590139778841577		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.0590139778841577 | validation: 0.07393256237744802]
	TIME [epoch: 8.51 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05995585478353436		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.05995585478353436 | validation: 0.05714760844982079]
	TIME [epoch: 8.49 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05384391145556615		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.05384391145556615 | validation: 0.07152430375323898]
	TIME [epoch: 8.48 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05472180408733176		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.05472180408733176 | validation: 0.0661778603259876]
	TIME [epoch: 8.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05492244710235074		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.05492244710235074 | validation: 0.06263711688944358]
	TIME [epoch: 8.51 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07070848275801941		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.07070848275801941 | validation: 0.0675233840660595]
	TIME [epoch: 8.49 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05253443675486417		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.05253443675486417 | validation: 0.05159063045556261]
	TIME [epoch: 8.49 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05823057023907485		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.05823057023907485 | validation: 0.08518508612909695]
	TIME [epoch: 8.48 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05776856172773172		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.05776856172773172 | validation: 0.06439201999431675]
	TIME [epoch: 8.51 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05555485132035813		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.05555485132035813 | validation: 0.058825079472740543]
	TIME [epoch: 8.48 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06506885063736094		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.06506885063736094 | validation: 0.06058858181793623]
	TIME [epoch: 8.48 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05237101147301594		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.05237101147301594 | validation: 0.05353841959833087]
	TIME [epoch: 8.49 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05002434371514318		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.05002434371514318 | validation: 0.0635152282056583]
	TIME [epoch: 8.51 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05722395179582355		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.05722395179582355 | validation: 0.05631081479181507]
	TIME [epoch: 8.48 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06130219934406338		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.06130219934406338 | validation: 0.05528092668516761]
	TIME [epoch: 8.48 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057089412196962806		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.057089412196962806 | validation: 0.06956602249146832]
	TIME [epoch: 8.49 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05529530312504757		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.05529530312504757 | validation: 0.06084103026952736]
	TIME [epoch: 8.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057182743670932276		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.057182743670932276 | validation: 0.05501974550830897]
	TIME [epoch: 8.48 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056868770574274384		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.056868770574274384 | validation: 0.06212773626430376]
	TIME [epoch: 8.48 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05507351743014045		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.05507351743014045 | validation: 0.059952517418592394]
	TIME [epoch: 8.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05069369383533766		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.05069369383533766 | validation: 0.07512314134453617]
	TIME [epoch: 8.49 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04923453508670866		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.04923453508670866 | validation: 0.06287311117000033]
	TIME [epoch: 8.48 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05968938144723357		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.05968938144723357 | validation: 0.057584563144899056]
	TIME [epoch: 8.49 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04791969141195043		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.04791969141195043 | validation: 0.054152371884050525]
	TIME [epoch: 8.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05909358459869194		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.05909358459869194 | validation: 0.06411456705518528]
	TIME [epoch: 8.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058710731623921375		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.058710731623921375 | validation: 0.07370961274852991]
	TIME [epoch: 8.49 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0594014751745517		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.0594014751745517 | validation: 0.048724815644411945]
	TIME [epoch: 8.49 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05188193926834246		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.05188193926834246 | validation: 0.05548407690392437]
	TIME [epoch: 8.51 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057910646860369584		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.057910646860369584 | validation: 0.07812742191171695]
	TIME [epoch: 8.49 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868866869549237		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.06868866869549237 | validation: 0.05947281324548963]
	TIME [epoch: 8.49 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049729599829077965		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.049729599829077965 | validation: 0.05997750663712304]
	TIME [epoch: 8.48 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05540288853589122		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.05540288853589122 | validation: 0.05650824607931715]
	TIME [epoch: 8.51 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05856206211034941		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.05856206211034941 | validation: 0.06057744904294439]
	TIME [epoch: 8.49 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060655084257966264		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.060655084257966264 | validation: 0.06119902940377432]
	TIME [epoch: 8.49 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060516138110777176		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.060516138110777176 | validation: 0.059224267174960765]
	TIME [epoch: 8.49 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05272201975116161		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.05272201975116161 | validation: 0.06759141569094378]
	TIME [epoch: 8.51 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05790290383277855		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.05790290383277855 | validation: 0.0625519792714597]
	TIME [epoch: 8.49 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060877778014605845		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.060877778014605845 | validation: 0.05060484664003271]
	TIME [epoch: 8.49 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05340559364289268		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.05340559364289268 | validation: 0.06483055399747834]
	TIME [epoch: 8.49 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05707808639750842		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.05707808639750842 | validation: 0.059505923233532494]
	TIME [epoch: 8.51 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06622862263467097		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.06622862263467097 | validation: 0.08026950940632967]
	TIME [epoch: 8.49 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05235612959218093		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.05235612959218093 | validation: 0.054417911122539755]
	TIME [epoch: 8.49 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05144271064622158		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.05144271064622158 | validation: 0.05656633714339711]
	TIME [epoch: 8.48 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05311375434990401		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.05311375434990401 | validation: 0.06462952400039593]
	TIME [epoch: 8.51 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057150360223469296		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.057150360223469296 | validation: 0.0522078649434356]
	TIME [epoch: 8.49 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05917163729414282		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.05917163729414282 | validation: 0.056182657654782676]
	TIME [epoch: 8.49 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264768675668241		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.05264768675668241 | validation: 0.06780808422628938]
	TIME [epoch: 8.49 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05997699725889165		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.05997699725889165 | validation: 0.05656905165975801]
	TIME [epoch: 8.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05705333028037869		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.05705333028037869 | validation: 0.06283648727366807]
	TIME [epoch: 8.49 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05293268545297464		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.05293268545297464 | validation: 0.054738759599583]
	TIME [epoch: 8.49 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051309501944917665		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.051309501944917665 | validation: 0.06134013587891118]
	TIME [epoch: 8.49 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052846666801459594		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.052846666801459594 | validation: 0.0702541870263272]
	TIME [epoch: 8.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05957128104841451		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.05957128104841451 | validation: 0.06828038144565407]
	TIME [epoch: 8.49 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0633085680091063		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.0633085680091063 | validation: 0.07817194917040315]
	TIME [epoch: 8.48 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05865162683097097		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.05865162683097097 | validation: 0.06509133675250722]
	TIME [epoch: 8.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05105285184929541		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.05105285184929541 | validation: 0.06378594462635831]
	TIME [epoch: 8.49 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05619243872665527		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.05619243872665527 | validation: 0.05730131445727886]
	TIME [epoch: 8.48 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05092610756732663		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.05092610756732663 | validation: 0.05048753014150753]
	TIME [epoch: 8.49 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05119452680562546		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.05119452680562546 | validation: 0.048193319897944384]
	TIME [epoch: 8.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344460013449119		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.06344460013449119 | validation: 0.058086063977753774]
	TIME [epoch: 8.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051507305137857264		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.051507305137857264 | validation: 0.06322021487491614]
	TIME [epoch: 8.48 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05296614196761036		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.05296614196761036 | validation: 0.055018344034494]
	TIME [epoch: 8.49 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056426883726380814		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.056426883726380814 | validation: 0.051751659300393396]
	TIME [epoch: 8.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05485676906416416		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.05485676906416416 | validation: 0.04613258111891656]
	TIME [epoch: 8.49 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05415814436082368		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.05415814436082368 | validation: 0.048532825313135776]
	TIME [epoch: 8.49 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05011888792607886		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.05011888792607886 | validation: 0.06301010731838258]
	TIME [epoch: 8.48 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06793259503402829		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.06793259503402829 | validation: 0.04748844560314834]
	TIME [epoch: 8.51 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050978440157194216		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.050978440157194216 | validation: 0.053926076755114634]
	TIME [epoch: 8.49 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050472130298895114		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.050472130298895114 | validation: 0.06568936086010434]
	TIME [epoch: 8.49 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0624494033360186		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.0624494033360186 | validation: 0.059747995847316035]
	TIME [epoch: 8.48 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057573044329126175		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.057573044329126175 | validation: 0.04610750264941099]
	TIME [epoch: 8.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05695955420270003		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.05695955420270003 | validation: 0.07336098113534922]
	TIME [epoch: 8.49 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05771418113971013		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.05771418113971013 | validation: 0.0668038927415149]
	TIME [epoch: 8.48 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06048079511288053		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.06048079511288053 | validation: 0.08080587304393103]
	TIME [epoch: 8.49 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06128389352020065		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.06128389352020065 | validation: 0.058858993443251115]
	TIME [epoch: 8.51 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0584738732776857		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.0584738732776857 | validation: 0.09298409194669457]
	TIME [epoch: 8.49 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061975351440025764		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.061975351440025764 | validation: 0.05641335829121107]
	TIME [epoch: 8.48 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05476612944207755		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.05476612944207755 | validation: 0.06569345721058716]
	TIME [epoch: 8.49 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06369873934772637		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.06369873934772637 | validation: 0.055423239831981615]
	TIME [epoch: 8.51 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06219989379173281		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.06219989379173281 | validation: 0.0483390200997968]
	TIME [epoch: 8.49 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056664310898888494		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.056664310898888494 | validation: 0.06722833291149355]
	TIME [epoch: 8.48 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048185727931117465		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.048185727931117465 | validation: 0.05827698202761318]
	TIME [epoch: 8.48 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06213060776817375		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.06213060776817375 | validation: 0.07268153213443894]
	TIME [epoch: 8.51 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05600259980401132		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.05600259980401132 | validation: 0.05745342596195062]
	TIME [epoch: 8.49 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05935475228736727		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.05935475228736727 | validation: 0.04837375713768602]
	TIME [epoch: 8.48 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052843601220848524		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.052843601220848524 | validation: 0.06129886410543847]
	TIME [epoch: 8.49 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05298946793138491		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.05298946793138491 | validation: 0.0620203072121888]
	TIME [epoch: 8.51 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055126732392465		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.055126732392465 | validation: 0.05418639881546682]
	TIME [epoch: 8.48 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04722119051592435		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.04722119051592435 | validation: 0.04551067143038186]
	TIME [epoch: 8.49 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05264414413716948		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.05264414413716948 | validation: 0.05626999806806532]
	TIME [epoch: 8.49 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054916596053730685		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.054916596053730685 | validation: 0.06069334759670268]
	TIME [epoch: 8.51 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05947900738537758		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.05947900738537758 | validation: 0.05469970544541095]
	TIME [epoch: 8.48 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05513834854610803		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.05513834854610803 | validation: 0.05148059529585858]
	TIME [epoch: 8.49 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05233423108478148		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.05233423108478148 | validation: 0.05438147247333064]
	TIME [epoch: 8.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05172884810728168		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.05172884810728168 | validation: 0.0541050058561975]
	TIME [epoch: 8.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053568944703651346		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.053568944703651346 | validation: 0.05395824444376184]
	TIME [epoch: 8.48 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054256976280441606		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.054256976280441606 | validation: 0.06775629483116455]
	TIME [epoch: 8.49 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057547731876275564		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.057547731876275564 | validation: 0.06012652766259771]
	TIME [epoch: 8.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06075906240460138		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.06075906240460138 | validation: 0.06299424467150104]
	TIME [epoch: 8.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054996040699709446		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.054996040699709446 | validation: 0.05402303070992042]
	TIME [epoch: 8.49 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054052626818390195		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.054052626818390195 | validation: 0.0773903546565406]
	TIME [epoch: 8.48 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05680469042090688		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.05680469042090688 | validation: 0.05006797813767495]
	TIME [epoch: 8.51 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05513838217955208		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.05513838217955208 | validation: 0.06781525620099481]
	TIME [epoch: 8.49 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055999836647171355		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.055999836647171355 | validation: 0.06626919277881092]
	TIME [epoch: 8.49 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060894223838848835		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.060894223838848835 | validation: 0.05966279843233603]
	TIME [epoch: 8.49 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06110130286452151		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.06110130286452151 | validation: 0.053414536177741]
	TIME [epoch: 8.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0555530137670268		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.0555530137670268 | validation: 0.05212928337566816]
	TIME [epoch: 8.49 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05185259630840654		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.05185259630840654 | validation: 0.05302701899720423]
	TIME [epoch: 8.48 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05962815873036964		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.05962815873036964 | validation: 0.052499452975535876]
	TIME [epoch: 8.48 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05376684585210266		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.05376684585210266 | validation: 0.047994618751979655]
	TIME [epoch: 8.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053726411611436445		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.053726411611436445 | validation: 0.060640949861864316]
	TIME [epoch: 8.49 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052539073124951076		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.052539073124951076 | validation: 0.06403437624913594]
	TIME [epoch: 8.49 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05499351814340806		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.05499351814340806 | validation: 0.053365354331268336]
	TIME [epoch: 8.48 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05393100665177538		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.05393100665177538 | validation: 0.061630002630389494]
	TIME [epoch: 8.51 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07140206991189663		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.07140206991189663 | validation: 0.062341060176507035]
	TIME [epoch: 8.49 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05954080343348399		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.05954080343348399 | validation: 0.05414451334553026]
	TIME [epoch: 8.49 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05675953417217139		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.05675953417217139 | validation: 0.07272450852246172]
	TIME [epoch: 8.49 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05317557937070795		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.05317557937070795 | validation: 0.05938442736796094]
	TIME [epoch: 8.51 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05857305501225034		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.05857305501225034 | validation: 0.05832855303120403]
	TIME [epoch: 8.48 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05765436700534741		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.05765436700534741 | validation: 0.059703871659570903]
	TIME [epoch: 8.48 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07168556169016435		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.07168556169016435 | validation: 0.07752290092847089]
	TIME [epoch: 8.49 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060200890109652974		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.060200890109652974 | validation: 0.05399455911515953]
	TIME [epoch: 8.51 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046459137627767155		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.046459137627767155 | validation: 0.062236999376936664]
	TIME [epoch: 8.49 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05412160508305395		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.05412160508305395 | validation: 0.08003869592906421]
	TIME [epoch: 8.49 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493952740836513		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.06493952740836513 | validation: 0.05964181585247376]
	TIME [epoch: 8.49 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0561974822179407		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.0561974822179407 | validation: 0.048630803967399924]
	TIME [epoch: 8.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05723793046534849		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.05723793046534849 | validation: 0.05139389315317555]
	TIME [epoch: 8.48 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05083124016911751		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.05083124016911751 | validation: 0.05316922341859437]
	TIME [epoch: 8.48 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05477161920081839		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.05477161920081839 | validation: 0.05099985076097732]
	TIME [epoch: 8.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055989913275831124		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.055989913275831124 | validation: 0.05965114462539839]
	TIME [epoch: 8.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049472622899974214		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.049472622899974214 | validation: 0.05452434186602488]
	TIME [epoch: 8.49 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05113386945830336		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.05113386945830336 | validation: 0.062363292103395286]
	TIME [epoch: 8.49 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05684894612037354		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.05684894612037354 | validation: 0.06759169562746009]
	TIME [epoch: 8.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054530774831491456		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.054530774831491456 | validation: 0.051951248560685566]
	TIME [epoch: 8.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270376626243546		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.05270376626243546 | validation: 0.07668214787321595]
	TIME [epoch: 8.49 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0552122916202615		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.0552122916202615 | validation: 0.05846257085874186]
	TIME [epoch: 8.49 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05106416073145649		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.05106416073145649 | validation: 0.05459266819627409]
	TIME [epoch: 8.51 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057154074553161724		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.057154074553161724 | validation: 0.06515557573974831]
	TIME [epoch: 8.49 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053226012327854025		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.053226012327854025 | validation: 0.051108519988374956]
	TIME [epoch: 8.49 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05728265503434084		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.05728265503434084 | validation: 0.0536478390838384]
	TIME [epoch: 8.48 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059677849646827166		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.059677849646827166 | validation: 0.07457991167195017]
	TIME [epoch: 8.51 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0626076293182232		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.0626076293182232 | validation: 0.05303955487257293]
	TIME [epoch: 8.49 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05607197227458888		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.05607197227458888 | validation: 0.057518700920457584]
	TIME [epoch: 8.49 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05523486285127527		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.05523486285127527 | validation: 0.0512299216266265]
	TIME [epoch: 8.49 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05120983403160754		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.05120983403160754 | validation: 0.04720305146158954]
	TIME [epoch: 8.51 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053740823193239785		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.053740823193239785 | validation: 0.05320617798937219]
	TIME [epoch: 8.49 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05347210797917208		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.05347210797917208 | validation: 0.06346166024954297]
	TIME [epoch: 8.49 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05770691732868929		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.05770691732868929 | validation: 0.06530087094077112]
	TIME [epoch: 8.49 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058454506635485945		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.058454506635485945 | validation: 0.057993872198307275]
	TIME [epoch: 8.51 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051548381926229014		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.051548381926229014 | validation: 0.06936819774522543]
	TIME [epoch: 8.49 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05655048662998787		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.05655048662998787 | validation: 0.06913175714982764]
	TIME [epoch: 8.49 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549468118863091		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.0549468118863091 | validation: 0.058350224510835144]
	TIME [epoch: 8.48 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048163243860555885		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.048163243860555885 | validation: 0.05295733830678326]
	TIME [epoch: 8.51 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05722710648360892		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.05722710648360892 | validation: 0.06165740897468984]
	TIME [epoch: 8.48 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05504839416500681		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.05504839416500681 | validation: 0.05669652127497542]
	TIME [epoch: 8.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05286077502750384		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.05286077502750384 | validation: 0.05473737426861125]
	TIME [epoch: 8.49 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04987925035034464		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.04987925035034464 | validation: 0.05304522202533345]
	TIME [epoch: 8.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057567906153335235		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.057567906153335235 | validation: 0.053143378602303684]
	TIME [epoch: 8.49 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270636470530151		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.05270636470530151 | validation: 0.04980115003579837]
	TIME [epoch: 8.49 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0545567301109854		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.0545567301109854 | validation: 0.058408338121837544]
	TIME [epoch: 8.51 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319559173155867		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.06319559173155867 | validation: 0.05363873466347813]
	TIME [epoch: 8.52 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0528943089495741		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.0528943089495741 | validation: 0.05374180157820861]
	TIME [epoch: 8.51 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056716482712210636		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.056716482712210636 | validation: 0.05793893204631955]
	TIME [epoch: 8.51 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058316408442078194		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.058316408442078194 | validation: 0.04968478165164954]
	TIME [epoch: 8.52 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048849712711283584		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.048849712711283584 | validation: 0.050467133910412285]
	TIME [epoch: 8.52 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05372747183157619		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.05372747183157619 | validation: 0.05589604172283413]
	TIME [epoch: 8.51 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0537519907366543		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.0537519907366543 | validation: 0.05627402204550269]
	TIME [epoch: 8.51 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05179931211709936		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.05179931211709936 | validation: 0.052820734500242286]
	TIME [epoch: 8.53 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0441583591987061		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.0441583591987061 | validation: 0.06814973463181137]
	TIME [epoch: 8.52 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05013934908655939		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.05013934908655939 | validation: 0.05441402662317668]
	TIME [epoch: 8.51 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05000756549848101		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.05000756549848101 | validation: 0.05606688074253291]
	TIME [epoch: 8.51 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04867034797100648		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.04867034797100648 | validation: 0.05498656157723599]
	TIME [epoch: 8.53 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05385036197394778		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.05385036197394778 | validation: 0.0646243831992194]
	TIME [epoch: 8.52 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049605704324727815		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.049605704324727815 | validation: 0.0589660233542071]
	TIME [epoch: 8.51 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05536715510882141		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.05536715510882141 | validation: 0.0592950865261235]
	TIME [epoch: 8.51 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047259864940333615		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.047259864940333615 | validation: 0.05021399656191295]
	TIME [epoch: 8.53 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046590704360125704		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.046590704360125704 | validation: 0.05910866308484816]
	TIME [epoch: 8.51 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04790281540406696		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.04790281540406696 | validation: 0.049954791327872256]
	TIME [epoch: 8.51 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056641972424516275		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.056641972424516275 | validation: 0.06341240393235936]
	TIME [epoch: 8.51 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05787379535837147		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.05787379535837147 | validation: 0.05363514543476309]
	TIME [epoch: 8.53 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055735182375401204		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.055735182375401204 | validation: 0.05877977370070549]
	TIME [epoch: 8.52 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05320337404535622		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.05320337404535622 | validation: 0.06214785412506541]
	TIME [epoch: 8.52 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05441061997944465		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.05441061997944465 | validation: 0.06011003525754689]
	TIME [epoch: 8.51 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053445010931403955		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.053445010931403955 | validation: 0.0658151767208786]
	TIME [epoch: 8.54 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04750806663344122		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.04750806663344122 | validation: 0.06009160011273404]
	TIME [epoch: 8.52 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05432506819761892		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.05432506819761892 | validation: 0.05182174714997488]
	TIME [epoch: 8.52 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0495573476617133		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.0495573476617133 | validation: 0.04933180740697804]
	TIME [epoch: 8.52 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05310362866417798		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.05310362866417798 | validation: 0.05621370778531412]
	TIME [epoch: 8.54 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0491833278989114		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.0491833278989114 | validation: 0.05742746916832338]
	TIME [epoch: 8.52 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05337226375125368		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.05337226375125368 | validation: 0.056633804429683035]
	TIME [epoch: 8.51 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0547870974099033		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.0547870974099033 | validation: 0.05079457840411196]
	TIME [epoch: 8.51 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04800887943240526		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.04800887943240526 | validation: 0.058599240703049775]
	TIME [epoch: 8.54 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06213536472010931		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.06213536472010931 | validation: 0.056265797662160555]
	TIME [epoch: 8.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05570987254508155		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.05570987254508155 | validation: 0.05430837070819721]
	TIME [epoch: 8.51 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04350067796332947		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.04350067796332947 | validation: 0.047937415139814796]
	TIME [epoch: 8.51 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05068606130154048		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.05068606130154048 | validation: 0.044978334846929015]
	TIME [epoch: 8.53 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047478028234665244		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.047478028234665244 | validation: 0.0551205917455285]
	TIME [epoch: 8.51 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05011631281602387		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.05011631281602387 | validation: 0.048940453202773404]
	TIME [epoch: 8.51 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052692269672044836		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.052692269672044836 | validation: 0.052002880378397176]
	TIME [epoch: 8.53 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055219719628214724		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.055219719628214724 | validation: 0.058989987581352196]
	TIME [epoch: 8.52 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0508182105280887		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.0508182105280887 | validation: 0.047146386079348755]
	TIME [epoch: 8.51 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056898808156384		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.056898808156384 | validation: 0.057611284884219044]
	TIME [epoch: 8.51 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05225274736892397		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.05225274736892397 | validation: 0.06129280464867759]
	TIME [epoch: 8.52 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05288474387641836		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.05288474387641836 | validation: 0.05627943247459517]
	TIME [epoch: 8.52 sec]
Finished training in 17162.846 seconds.
