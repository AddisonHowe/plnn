Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3682106755

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.914628999139707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.914628999139707 | validation: 8.023217346176315]
	TIME [epoch: 79.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.201902823058605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.201902823058605 | validation: 5.474670838622414]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.561861227666286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.561861227666286 | validation: 10.45194369372148]
	TIME [epoch: 8.42 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.879405141435473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.879405141435473 | validation: 7.300540996380217]
	TIME [epoch: 8.4 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.226454827093314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.226454827093314 | validation: 7.879122499680506]
	TIME [epoch: 8.39 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.537274134655402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.537274134655402 | validation: 4.104626188782073]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.110809367694587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.110809367694587 | validation: 9.984412968932254]
	TIME [epoch: 8.42 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.7170876558017225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7170876558017225 | validation: 4.417661529511529]
	TIME [epoch: 8.4 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.385155764101748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.385155764101748 | validation: 4.8668262202206645]
	TIME [epoch: 8.39 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.829039863342894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.829039863342894 | validation: 4.2257370527331215]
	TIME [epoch: 8.39 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.224912512940447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.224912512940447 | validation: 3.9333109173745395]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.247183065249395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.247183065249395 | validation: 3.9965007503453016]
	TIME [epoch: 8.4 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.037892467356982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.037892467356982 | validation: 3.6311302216451793]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.871178366425893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.871178366425893 | validation: 3.964369721402181]
	TIME [epoch: 8.4 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.50139236110073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.50139236110073 | validation: 7.111878384790058]
	TIME [epoch: 8.42 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.475948696633995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.475948696633995 | validation: 7.707161461236008]
	TIME [epoch: 8.39 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.427713635572592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.427713635572592 | validation: 6.015254793503074]
	TIME [epoch: 8.4 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.911502195839959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.911502195839959 | validation: 4.938160834897257]
	TIME [epoch: 8.38 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.787037234624245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.787037234624245 | validation: 4.844417992605605]
	TIME [epoch: 8.42 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.69542620765134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.69542620765134 | validation: 4.337611298962471]
	TIME [epoch: 8.39 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.571525277093544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.571525277093544 | validation: 4.058729838238808]
	TIME [epoch: 8.39 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.347148261194896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.347148261194896 | validation: 5.582241105147089]
	TIME [epoch: 8.39 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.756998860563476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.756998860563476 | validation: 3.691580009437836]
	TIME [epoch: 8.41 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8075640647609696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8075640647609696 | validation: 3.351448854221487]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.46317086959694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.46317086959694 | validation: 3.7620336005645503]
	TIME [epoch: 8.38 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.682549760855472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.682549760855472 | validation: 3.645633576566686]
	TIME [epoch: 8.38 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6506759792598444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6506759792598444 | validation: 5.672246068285825]
	TIME [epoch: 8.4 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.552166550824034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.552166550824034 | validation: 3.4195972210601395]
	TIME [epoch: 8.38 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4008046488524526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4008046488524526 | validation: 4.121985754431279]
	TIME [epoch: 8.38 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.76551016044359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.76551016044359 | validation: 3.319400250535148]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5584947032767618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5584947032767618 | validation: 3.390782780848378]
	TIME [epoch: 8.41 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.36115906597169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.36115906597169 | validation: 3.191233571941223]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.279500695993002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.279500695993002 | validation: 3.906343141328974]
	TIME [epoch: 8.38 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.448724849717317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.448724849717317 | validation: 3.2427319470455727]
	TIME [epoch: 8.39 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3830301240506357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3830301240506357 | validation: 2.940792104139714]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.219626227766662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.219626227766662 | validation: 2.6650576359999514]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.264753137565092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.264753137565092 | validation: 3.889868510612386]
	TIME [epoch: 8.38 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2860672408786193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2860672408786193 | validation: 2.6463470073276896]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5739052474812114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5739052474812114 | validation: 2.922073220552228]
	TIME [epoch: 8.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7691611036158923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7691611036158923 | validation: 2.9884774644043754]
	TIME [epoch: 8.39 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.42679550979911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.42679550979911 | validation: 2.691232022745256]
	TIME [epoch: 8.38 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1045521442184674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1045521442184674 | validation: 1.0010195799978348]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.24109611623526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.24109611623526 | validation: 1.3403979204115573]
	TIME [epoch: 8.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0038166765318874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0038166765318874 | validation: 1.116925115991217]
	TIME [epoch: 8.38 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.957037833921372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.957037833921372 | validation: 0.7836314560000811]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0162818701603495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0162818701603495 | validation: 0.8429405305899884]
	TIME [epoch: 8.41 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8786608922370387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8786608922370387 | validation: 0.6816358922699034]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9318756370749434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9318756370749434 | validation: 0.7513509168634143]
	TIME [epoch: 8.39 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8642313760387121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8642313760387121 | validation: 0.8528833823154012]
	TIME [epoch: 8.39 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8396564942025583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8396564942025583 | validation: 2.3378290941258086]
	TIME [epoch: 8.41 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0328619001282209		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 1.0328619001282209 | validation: 0.9735393162527542]
	TIME [epoch: 8.39 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4654679939098472		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 1.4654679939098472 | validation: 0.7919439614925607]
	TIME [epoch: 8.39 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9274126665081189		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 0.9274126665081189 | validation: 1.1111465760333106]
	TIME [epoch: 8.38 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3087974947870955		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.3087974947870955 | validation: 0.8050983441891086]
	TIME [epoch: 8.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9531075765643493		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 0.9531075765643493 | validation: 0.5627315937199722]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8282250192531038		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 0.8282250192531038 | validation: 0.715902688057821]
	TIME [epoch: 8.39 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8220239734121698		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 0.8220239734121698 | validation: 0.8414055467069084]
	TIME [epoch: 8.38 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8940940283717189		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 0.8940940283717189 | validation: 1.3063517633629296]
	TIME [epoch: 8.41 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9054950574297564		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 0.9054950574297564 | validation: 0.7936503871880343]
	TIME [epoch: 8.38 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8220375832839041		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 0.8220375832839041 | validation: 1.0053659954348093]
	TIME [epoch: 8.38 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8875103851348459		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 0.8875103851348459 | validation: 0.5474069785885156]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9013641183206624		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 0.9013641183206624 | validation: 0.6360115130801455]
	TIME [epoch: 8.41 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6978614166471238		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 0.6978614166471238 | validation: 0.7327859761737252]
	TIME [epoch: 8.39 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9514199076073989		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 0.9514199076073989 | validation: 2.275867740355334]
	TIME [epoch: 8.38 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9363053015522873		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 0.9363053015522873 | validation: 0.7221766428450085]
	TIME [epoch: 8.38 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7969996778210391		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 0.7969996778210391 | validation: 0.8745016000972352]
	TIME [epoch: 8.42 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9155839095592931		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 0.9155839095592931 | validation: 0.7569201358317867]
	TIME [epoch: 8.38 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8789550504572249		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 0.8789550504572249 | validation: 1.1511476059186618]
	TIME [epoch: 8.38 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8011866572393028		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 0.8011866572393028 | validation: 0.8103021735000123]
	TIME [epoch: 8.38 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.970537068748143		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 0.970537068748143 | validation: 0.9140017290448681]
	TIME [epoch: 8.41 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8827751502098702		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 0.8827751502098702 | validation: 0.8048680190238009]
	TIME [epoch: 8.38 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7873693112858542		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 0.7873693112858542 | validation: 0.5878623948093156]
	TIME [epoch: 8.38 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6650896272469675		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 0.6650896272469675 | validation: 0.628837617325031]
	TIME [epoch: 8.38 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8647426518877275		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 0.8647426518877275 | validation: 0.787045810316263]
	TIME [epoch: 8.42 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9091063341198801		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 0.9091063341198801 | validation: 0.8683594403452539]
	TIME [epoch: 8.38 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7097194237919753		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 0.7097194237919753 | validation: 0.5742653527660674]
	TIME [epoch: 8.38 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6436181596360455		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 0.6436181596360455 | validation: 0.8087421784130007]
	TIME [epoch: 8.39 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7682299777139204		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 0.7682299777139204 | validation: 0.5868678242183198]
	TIME [epoch: 8.41 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7529907019544105		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 0.7529907019544105 | validation: 0.5489188427737159]
	TIME [epoch: 8.39 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7382915503214844		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 0.7382915503214844 | validation: 1.1541135814582362]
	TIME [epoch: 8.38 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9497386836190771		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 0.9497386836190771 | validation: 0.6505103789676596]
	TIME [epoch: 8.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7149962232926163		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 0.7149962232926163 | validation: 1.0644792734952113]
	TIME [epoch: 8.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9358370194799862		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 0.9358370194799862 | validation: 1.0915735471801926]
	TIME [epoch: 8.39 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7491908356402942		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 0.7491908356402942 | validation: 0.7294718883992242]
	TIME [epoch: 8.38 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7847101916513946		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 0.7847101916513946 | validation: 0.8407681193484331]
	TIME [epoch: 8.39 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8119623939084903		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 0.8119623939084903 | validation: 1.1092782755248451]
	TIME [epoch: 8.41 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8305268562711994		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 0.8305268562711994 | validation: 1.2311485924487617]
	TIME [epoch: 8.38 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8752642299681707		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 0.8752642299681707 | validation: 0.7122718008859795]
	TIME [epoch: 8.39 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6552864873721695		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 0.6552864873721695 | validation: 0.6477559500100987]
	TIME [epoch: 8.39 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7030516133821503		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 0.7030516133821503 | validation: 0.6970580131719959]
	TIME [epoch: 8.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7991209953871671		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 0.7991209953871671 | validation: 0.6606644440236176]
	TIME [epoch: 8.39 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6600671993703916		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 0.6600671993703916 | validation: 1.0523504561992794]
	TIME [epoch: 8.39 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9044415387775924		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.9044415387775924 | validation: 0.5687108283920446]
	TIME [epoch: 8.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6642526110213292		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 0.6642526110213292 | validation: 0.6047379511405535]
	TIME [epoch: 8.39 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7104441607008573		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 0.7104441607008573 | validation: 0.6631326555018159]
	TIME [epoch: 8.38 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7072624517190892		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 0.7072624517190892 | validation: 0.589818505429559]
	TIME [epoch: 8.38 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8270626958486043		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 0.8270626958486043 | validation: 0.840704844687273]
	TIME [epoch: 8.39 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7731772964686315		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 0.7731772964686315 | validation: 0.562664419417227]
	TIME [epoch: 8.39 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7478758768900018		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 0.7478758768900018 | validation: 0.8463179342401623]
	TIME [epoch: 8.39 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7784260826392565		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 0.7784260826392565 | validation: 0.6256623084057309]
	TIME [epoch: 8.38 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7398467789566042		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 0.7398467789566042 | validation: 0.7661800635010647]
	TIME [epoch: 8.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.791485506157229		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 0.791485506157229 | validation: 0.6091472909567159]
	TIME [epoch: 8.39 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.86168078072564		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 0.86168078072564 | validation: 0.5984506016032038]
	TIME [epoch: 8.39 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7576714548589434		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 0.7576714548589434 | validation: 0.6512625768675647]
	TIME [epoch: 8.38 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7120748860114905		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 0.7120748860114905 | validation: 0.9413126799107605]
	TIME [epoch: 8.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8601226271238787		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 0.8601226271238787 | validation: 1.0129728381523748]
	TIME [epoch: 8.39 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6158868666849423		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 0.6158868666849423 | validation: 0.5367022251202325]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6683777768902879		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 0.6683777768902879 | validation: 0.5642148666699422]
	TIME [epoch: 8.39 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6311114109031053		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 0.6311114109031053 | validation: 0.5495424170708706]
	TIME [epoch: 8.41 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8598427628574227		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 0.8598427628574227 | validation: 0.6712327118940218]
	TIME [epoch: 8.38 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6494085651121992		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 0.6494085651121992 | validation: 0.759291633413222]
	TIME [epoch: 8.38 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6991183038997535		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 0.6991183038997535 | validation: 0.7785819149423387]
	TIME [epoch: 8.38 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8193329478951632		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 0.8193329478951632 | validation: 0.6998864272460176]
	TIME [epoch: 8.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6531716435931989		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 0.6531716435931989 | validation: 0.8213898232137824]
	TIME [epoch: 8.37 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6965050356083187		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 0.6965050356083187 | validation: 0.9469765002517091]
	TIME [epoch: 8.38 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6884486168244177		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 0.6884486168244177 | validation: 0.6035426705065017]
	TIME [epoch: 8.37 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7300280411073365		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.7300280411073365 | validation: 0.5940683432031896]
	TIME [epoch: 8.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.689920702966556		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 0.689920702966556 | validation: 1.2337979989365304]
	TIME [epoch: 8.38 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7666185680917315		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 0.7666185680917315 | validation: 0.6518776110556763]
	TIME [epoch: 8.38 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5865962687497632		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 0.5865962687497632 | validation: 0.6865896707738197]
	TIME [epoch: 8.37 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7398518686611533		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 0.7398518686611533 | validation: 1.5325749847448427]
	TIME [epoch: 8.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8125904766720309		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 0.8125904766720309 | validation: 0.9294174206039099]
	TIME [epoch: 8.39 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6320078295213112		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 0.6320078295213112 | validation: 0.6075138162608931]
	TIME [epoch: 8.38 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6961702025111298		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.6961702025111298 | validation: 0.7782066882077254]
	TIME [epoch: 8.38 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6827060721373234		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.6827060721373234 | validation: 1.0092470423236302]
	TIME [epoch: 8.41 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6969502324545693		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 0.6969502324545693 | validation: 0.652023841756908]
	TIME [epoch: 8.38 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7332467054650312		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 0.7332467054650312 | validation: 0.5603439575021282]
	TIME [epoch: 8.38 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7007060256770872		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.7007060256770872 | validation: 0.4884187081604793]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7251805391149378		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 0.7251805391149378 | validation: 0.5531627150891011]
	TIME [epoch: 8.41 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7072706064858202		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 0.7072706064858202 | validation: 0.6640880274032812]
	TIME [epoch: 8.37 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7358307200405619		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.7358307200405619 | validation: 0.6561927753028457]
	TIME [epoch: 8.38 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6870223327081606		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.6870223327081606 | validation: 0.518712662557324]
	TIME [epoch: 8.38 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.662868449268296		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.662868449268296 | validation: 0.4866591615878236]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7414179493500348		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.7414179493500348 | validation: 0.5989648322972132]
	TIME [epoch: 8.39 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6723189133881513		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.6723189133881513 | validation: 0.7968869544586419]
	TIME [epoch: 8.38 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6156860836634732		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.6156860836634732 | validation: 0.6870196164105189]
	TIME [epoch: 8.38 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6158631331369919		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 0.6158631331369919 | validation: 0.5022922579267677]
	TIME [epoch: 8.41 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6585499074355302		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 0.6585499074355302 | validation: 0.5657641274394944]
	TIME [epoch: 8.37 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.618015365734478		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 0.618015365734478 | validation: 0.5530040406367173]
	TIME [epoch: 8.39 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5851819600377015		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.5851819600377015 | validation: 0.8019512198238465]
	TIME [epoch: 8.38 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.618870312410701		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.618870312410701 | validation: 0.7272593992628826]
	TIME [epoch: 8.41 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6859509695831412		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 0.6859509695831412 | validation: 0.6211124665690597]
	TIME [epoch: 8.38 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6729754473024642		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.6729754473024642 | validation: 0.5092063582057788]
	TIME [epoch: 8.38 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6184040648915226		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.6184040648915226 | validation: 0.45840298528678247]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6501343783679825		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.6501343783679825 | validation: 1.0202151438211118]
	TIME [epoch: 8.42 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.814153612563809		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.814153612563809 | validation: 0.5364506241156379]
	TIME [epoch: 8.39 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5920776640072581		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.5920776640072581 | validation: 0.5565380775255537]
	TIME [epoch: 8.39 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6032204934978956		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.6032204934978956 | validation: 0.6903819525008115]
	TIME [epoch: 8.38 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6892797568798966		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.6892797568798966 | validation: 0.6265037251960965]
	TIME [epoch: 8.39 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6437283575971209		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.6437283575971209 | validation: 0.4794396091882437]
	TIME [epoch: 8.38 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6380167837052952		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.6380167837052952 | validation: 0.5897587370054646]
	TIME [epoch: 8.38 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6438592526806884		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.6438592526806884 | validation: 0.5344690402418049]
	TIME [epoch: 8.39 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.601822284481677		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.601822284481677 | validation: 0.5507202347154665]
	TIME [epoch: 8.39 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7210111637544672		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.7210111637544672 | validation: 0.5220674850681754]
	TIME [epoch: 8.38 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6449895468706709		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.6449895468706709 | validation: 0.6893974489424708]
	TIME [epoch: 8.38 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6623869432072814		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.6623869432072814 | validation: 0.5143504235053706]
	TIME [epoch: 8.39 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5302028294532775		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.5302028294532775 | validation: 0.6055973707671483]
	TIME [epoch: 8.39 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5854882326737678		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.5854882326737678 | validation: 0.6703878894442001]
	TIME [epoch: 8.37 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6119832200467823		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.6119832200467823 | validation: 0.5503668826989556]
	TIME [epoch: 8.37 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5440692934275537		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.5440692934275537 | validation: 0.5710541525026485]
	TIME [epoch: 8.39 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5342754828094588		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.5342754828094588 | validation: 0.5584955926125337]
	TIME [epoch: 8.39 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7355418107851324		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.7355418107851324 | validation: 0.8830075597390253]
	TIME [epoch: 8.37 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7153143264445199		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.7153143264445199 | validation: 0.6427985384901445]
	TIME [epoch: 8.38 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5382080179441722		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.5382080179441722 | validation: 0.783343037389137]
	TIME [epoch: 8.39 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5853152710940434		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.5853152710940434 | validation: 0.530559110016228]
	TIME [epoch: 8.39 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5935637266048766		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.5935637266048766 | validation: 0.4813191095115835]
	TIME [epoch: 8.38 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5768564541747773		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.5768564541747773 | validation: 0.5069280300707069]
	TIME [epoch: 8.38 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.628443534508394		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.628443534508394 | validation: 0.5712527724610525]
	TIME [epoch: 8.39 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5648708323030205		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.5648708323030205 | validation: 0.48157473414490376]
	TIME [epoch: 8.38 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6256359157773068		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.6256359157773068 | validation: 0.5229186281675468]
	TIME [epoch: 8.38 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5489862016790196		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5489862016790196 | validation: 0.5248356285310898]
	TIME [epoch: 8.37 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6178858619741133		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.6178858619741133 | validation: 0.6748087735616328]
	TIME [epoch: 8.39 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.589141976663017		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.589141976663017 | validation: 0.4826033622231104]
	TIME [epoch: 8.38 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5725410381228516		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.5725410381228516 | validation: 0.534638265020373]
	TIME [epoch: 8.38 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6072913343250756		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.6072913343250756 | validation: 0.5598054815793407]
	TIME [epoch: 8.37 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5978137161791555		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.5978137161791555 | validation: 0.5890156339176007]
	TIME [epoch: 8.39 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5852253653965257		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 0.5852253653965257 | validation: 0.8856003385250939]
	TIME [epoch: 8.38 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6591418938263989		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.6591418938263989 | validation: 0.5072412981235918]
	TIME [epoch: 8.38 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5225617559250623		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.5225617559250623 | validation: 0.5685165707853522]
	TIME [epoch: 8.38 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5125404515626941		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.5125404515626941 | validation: 0.46736903532983415]
	TIME [epoch: 8.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5901218654551876		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.5901218654551876 | validation: 0.48211182014274456]
	TIME [epoch: 8.38 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5441463505429525		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.5441463505429525 | validation: 0.4739679538003072]
	TIME [epoch: 8.39 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5614389330099029		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.5614389330099029 | validation: 0.4638778060059995]
	TIME [epoch: 8.38 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5826792987339879		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.5826792987339879 | validation: 0.44196197286684746]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5327084903649936		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.5327084903649936 | validation: 0.7177298428017362]
	TIME [epoch: 8.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6341534719566082		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.6341534719566082 | validation: 0.43209468200923895]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5314987706136174		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.5314987706136174 | validation: 1.4115890783781064]
	TIME [epoch: 8.38 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6805203694679114		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.6805203694679114 | validation: 0.5372451981499908]
	TIME [epoch: 8.41 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824664015531733		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.5824664015531733 | validation: 0.5113450061986081]
	TIME [epoch: 8.39 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5641198617540565		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.5641198617540565 | validation: 0.7033380998903396]
	TIME [epoch: 8.39 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47303029723606854		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.47303029723606854 | validation: 0.41584595317759715]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5215251743093174		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.5215251743093174 | validation: 0.7214206695849419]
	TIME [epoch: 8.42 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5333472714468535		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.5333472714468535 | validation: 0.5156730210389935]
	TIME [epoch: 8.39 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5166647241815657		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.5166647241815657 | validation: 0.46901244584195667]
	TIME [epoch: 8.38 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49653478225869874		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.49653478225869874 | validation: 0.445716683324712]
	TIME [epoch: 8.39 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5207415507943319		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.5207415507943319 | validation: 0.4822345550002627]
	TIME [epoch: 8.42 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5646210340458975		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.5646210340458975 | validation: 0.5058779747355586]
	TIME [epoch: 8.39 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5561050524406081		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.5561050524406081 | validation: 0.662703630066386]
	TIME [epoch: 8.38 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6535915135555713		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.6535915135555713 | validation: 0.5534405703332875]
	TIME [epoch: 8.39 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5239336566312424		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.5239336566312424 | validation: 0.7824729678564304]
	TIME [epoch: 8.42 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5480910224699158		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.5480910224699158 | validation: 0.42270303347939175]
	TIME [epoch: 8.38 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4801324377729651		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.4801324377729651 | validation: 0.41601484160678776]
	TIME [epoch: 8.39 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5679580325701068		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.5679580325701068 | validation: 0.3939855312186168]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4494240740838825		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.4494240740838825 | validation: 0.6392447423839284]
	TIME [epoch: 8.41 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4567135688635287		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.4567135688635287 | validation: 0.6974259061221093]
	TIME [epoch: 8.39 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5226731217038864		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.5226731217038864 | validation: 0.9679107239872675]
	TIME [epoch: 8.39 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5945369701899692		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.5945369701899692 | validation: 0.7856101114540979]
	TIME [epoch: 8.39 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5526377834775893		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.5526377834775893 | validation: 0.5729017595989827]
	TIME [epoch: 8.41 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5439947361450297		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.5439947361450297 | validation: 0.4748948999751098]
	TIME [epoch: 8.39 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49080960166196286		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.49080960166196286 | validation: 0.5730656549145365]
	TIME [epoch: 8.38 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4911114141820878		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.4911114141820878 | validation: 0.6917502852083297]
	TIME [epoch: 8.38 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5278669070482851		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.5278669070482851 | validation: 0.42079063092871727]
	TIME [epoch: 8.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5008255257493586		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.5008255257493586 | validation: 0.3484456030034]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.463044104484111		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.463044104484111 | validation: 0.4379139634450194]
	TIME [epoch: 8.38 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4203283769200216		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.4203283769200216 | validation: 0.43471770096346884]
	TIME [epoch: 8.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6689192045864624		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.6689192045864624 | validation: 0.5555617384375919]
	TIME [epoch: 8.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4750545130428037		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.4750545130428037 | validation: 0.4162365500769739]
	TIME [epoch: 8.38 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4654092873816162		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.4654092873816162 | validation: 0.4374146588227026]
	TIME [epoch: 8.39 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48395771976024093		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.48395771976024093 | validation: 0.4027828021955066]
	TIME [epoch: 8.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4440692785950725		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.4440692785950725 | validation: 0.4231084001179499]
	TIME [epoch: 8.39 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4833164942264874		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.4833164942264874 | validation: 0.5546400583043103]
	TIME [epoch: 8.38 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46541811343865414		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.46541811343865414 | validation: 0.5322745405769305]
	TIME [epoch: 8.38 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5429551217932367		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.5429551217932367 | validation: 0.29532985433588665]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4607090929303535		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.4607090929303535 | validation: 0.3311283812935568]
	TIME [epoch: 8.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44890443258435553		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.44890443258435553 | validation: 0.43593063655524905]
	TIME [epoch: 8.38 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7390954816002497		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.7390954816002497 | validation: 1.1437592018308005]
	TIME [epoch: 8.38 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5546037962962427		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.5546037962962427 | validation: 0.3494863212119351]
	TIME [epoch: 8.41 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3882259806733881		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.3882259806733881 | validation: 0.32468206299431435]
	TIME [epoch: 8.38 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3782431402438023		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.3782431402438023 | validation: 0.6925892969994232]
	TIME [epoch: 8.38 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4315788456246243		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.4315788456246243 | validation: 0.2680934197043988]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4178939620380233		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.4178939620380233 | validation: 0.9148958889907457]
	TIME [epoch: 8.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49690693120074514		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.49690693120074514 | validation: 0.5472386076031146]
	TIME [epoch: 8.38 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4801902318024179		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.4801902318024179 | validation: 0.5921528081301874]
	TIME [epoch: 8.37 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47883442975976215		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.47883442975976215 | validation: 0.47787607548948197]
	TIME [epoch: 8.38 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4076890922750901		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.4076890922750901 | validation: 0.30358189045420647]
	TIME [epoch: 8.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3474672658966544		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.3474672658966544 | validation: 0.3919450562512282]
	TIME [epoch: 8.38 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38069436147890634		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.38069436147890634 | validation: 0.42250650239977816]
	TIME [epoch: 8.38 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37119894936425374		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.37119894936425374 | validation: 0.3873455602075572]
	TIME [epoch: 8.37 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46484204450040306		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.46484204450040306 | validation: 0.5643678299586481]
	TIME [epoch: 8.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42410067504969734		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.42410067504969734 | validation: 0.6346917969048091]
	TIME [epoch: 8.38 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40933532100345243		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.40933532100345243 | validation: 0.44774103345011135]
	TIME [epoch: 8.38 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4182369603691966		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.4182369603691966 | validation: 0.2978975864756294]
	TIME [epoch: 8.38 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4549405464430567		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.4549405464430567 | validation: 0.3661400289519763]
	TIME [epoch: 8.41 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38990341546329577		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.38990341546329577 | validation: 0.681349787050864]
	TIME [epoch: 8.38 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3920450617942147		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.3920450617942147 | validation: 0.311017212821647]
	TIME [epoch: 8.38 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39092072534435995		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.39092072534435995 | validation: 0.4597816161956338]
	TIME [epoch: 8.38 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37134141989775676		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.37134141989775676 | validation: 0.49152329246629867]
	TIME [epoch: 8.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4370371414421693		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.4370371414421693 | validation: 0.9374979420975524]
	TIME [epoch: 8.39 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49927994535144277		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.49927994535144277 | validation: 0.5169627039910542]
	TIME [epoch: 8.38 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40831649356606475		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.40831649356606475 | validation: 0.34833042101001577]
	TIME [epoch: 8.38 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45943684911040766		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.45943684911040766 | validation: 0.394356933100934]
	TIME [epoch: 8.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3453978029602108		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.3453978029602108 | validation: 0.48598124584754576]
	TIME [epoch: 8.38 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4306362393361104		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.4306362393361104 | validation: 0.4684885964039657]
	TIME [epoch: 8.37 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3602255709846943		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.3602255709846943 | validation: 0.3187165542408172]
	TIME [epoch: 8.37 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4721030171561825		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.4721030171561825 | validation: 0.45223372971464015]
	TIME [epoch: 8.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43923396669227516		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.43923396669227516 | validation: 0.49288096696644396]
	TIME [epoch: 8.37 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43706483838571825		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.43706483838571825 | validation: 0.3932510880643919]
	TIME [epoch: 8.38 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38533259066553865		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.38533259066553865 | validation: 0.33228786870891003]
	TIME [epoch: 8.38 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3290683054017823		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.3290683054017823 | validation: 0.41396822728219607]
	TIME [epoch: 8.41 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47313238414620323		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.47313238414620323 | validation: 0.5358352369828241]
	TIME [epoch: 8.38 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38311421944038454		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.38311421944038454 | validation: 0.6039347464115253]
	TIME [epoch: 8.38 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34648727397739176		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.34648727397739176 | validation: 0.6001583076839809]
	TIME [epoch: 8.37 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3788522569205669		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.3788522569205669 | validation: 0.38960116010975565]
	TIME [epoch: 8.41 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4354990646508966		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.4354990646508966 | validation: 0.48180168531246204]
	TIME [epoch: 8.38 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7281816486573057		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.7281816486573057 | validation: 0.3887430417714415]
	TIME [epoch: 8.37 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3514023035565582		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.3514023035565582 | validation: 0.41526441325014074]
	TIME [epoch: 8.38 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4071483443301682		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.4071483443301682 | validation: 0.3727876296188404]
	TIME [epoch: 8.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31696321042005926		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.31696321042005926 | validation: 0.5251947913429383]
	TIME [epoch: 8.38 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47488298966734127		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.47488298966734127 | validation: 0.2992294292155965]
	TIME [epoch: 8.38 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33531978930499867		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.33531978930499867 | validation: 0.4050490817939098]
	TIME [epoch: 8.37 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34888886839112754		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.34888886839112754 | validation: 0.2851309976024389]
	TIME [epoch: 8.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37747427505468284		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.37747427505468284 | validation: 0.33494419609848713]
	TIME [epoch: 8.38 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104701027916401		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.3104701027916401 | validation: 0.3040906191667522]
	TIME [epoch: 8.38 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4523824382597036		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.4523824382597036 | validation: 0.28927131093279607]
	TIME [epoch: 8.37 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3595674250683483		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.3595674250683483 | validation: 0.8913908161831932]
	TIME [epoch: 8.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44551056978574965		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.44551056978574965 | validation: 0.2855475081507618]
	TIME [epoch: 8.37 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3058747891263348		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.3058747891263348 | validation: 0.26714128359721334]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2733950418058204		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.2733950418058204 | validation: 0.2627913051271933]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35053306205188217		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.35053306205188217 | validation: 0.8308566176542249]
	TIME [epoch: 8.39 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4320891259319056		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.4320891259319056 | validation: 0.3293628541823359]
	TIME [epoch: 8.38 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3510304248337012		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.3510304248337012 | validation: 0.3534203795524287]
	TIME [epoch: 8.38 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4378005361092317		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.4378005361092317 | validation: 0.2793974008074557]
	TIME [epoch: 8.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5059789004417071		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.5059789004417071 | validation: 0.457281248656192]
	TIME [epoch: 8.39 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40179644268029663		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.40179644268029663 | validation: 0.4994942566524434]
	TIME [epoch: 8.38 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4864220576396261		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.4864220576396261 | validation: 0.3574571152943168]
	TIME [epoch: 8.38 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3245859368387964		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.3245859368387964 | validation: 0.3673597234803002]
	TIME [epoch: 8.39 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3691693721384942		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.3691693721384942 | validation: 0.7670075999839646]
	TIME [epoch: 8.39 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4852915778776562		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.4852915778776562 | validation: 0.5327606972634612]
	TIME [epoch: 8.38 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38672733092943956		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.38672733092943956 | validation: 0.2992612211823934]
	TIME [epoch: 8.38 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3628152626013787		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.3628152626013787 | validation: 0.3237385545216746]
	TIME [epoch: 8.39 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36486903407954535		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.36486903407954535 | validation: 0.556905430707542]
	TIME [epoch: 8.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4247606482165403		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.4247606482165403 | validation: 0.9223584308801823]
	TIME [epoch: 8.38 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38724241803762305		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.38724241803762305 | validation: 0.2549469294047481]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3128794508614291		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.3128794508614291 | validation: 0.2850219052583653]
	TIME [epoch: 8.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.316639309855807		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.316639309855807 | validation: 1.1167282029470658]
	TIME [epoch: 8.38 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43466617883104364		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.43466617883104364 | validation: 0.31937710002731634]
	TIME [epoch: 8.38 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3538320477180838		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.3538320477180838 | validation: 0.7532478748388045]
	TIME [epoch: 8.37 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6445323809744383		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.6445323809744383 | validation: 0.4385922679021134]
	TIME [epoch: 8.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3754170830594611		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.3754170830594611 | validation: 0.25404741374117457]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3271469669497384		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.3271469669497384 | validation: 0.727815269429791]
	TIME [epoch: 8.37 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35358686498648767		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.35358686498648767 | validation: 0.3627035464174217]
	TIME [epoch: 8.38 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46084487066918534		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.46084487066918534 | validation: 0.5043200428135812]
	TIME [epoch: 8.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49135092036755845		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.49135092036755845 | validation: 0.3106851882969581]
	TIME [epoch: 8.38 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5206530959764303		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.5206530959764303 | validation: 0.560569323679118]
	TIME [epoch: 8.37 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32771171951243416		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.32771171951243416 | validation: 0.36516632824464756]
	TIME [epoch: 8.37 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32366019982617444		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.32366019982617444 | validation: 0.3851669298274335]
	TIME [epoch: 8.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40475907496009766		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.40475907496009766 | validation: 0.25686433413389803]
	TIME [epoch: 8.39 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29513054793889754		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.29513054793889754 | validation: 0.27780569529715793]
	TIME [epoch: 8.38 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37790209069434766		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.37790209069434766 | validation: 0.3397074433593687]
	TIME [epoch: 8.39 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3385077741229543		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.3385077741229543 | validation: 0.35384080266207285]
	TIME [epoch: 8.39 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3512945290619355		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.3512945290619355 | validation: 0.7581398706033564]
	TIME [epoch: 8.38 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3685126163773572		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.3685126163773572 | validation: 0.2844971165778558]
	TIME [epoch: 8.38 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29991363032565016		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.29991363032565016 | validation: 0.425845495892627]
	TIME [epoch: 8.37 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28209122392664504		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.28209122392664504 | validation: 0.31076218698154323]
	TIME [epoch: 8.39 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2992293816562257		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.2992293816562257 | validation: 0.37794355878930397]
	TIME [epoch: 8.38 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306838900927865		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.3306838900927865 | validation: 0.43796659320547415]
	TIME [epoch: 8.38 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020382209936134		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.3020382209936134 | validation: 0.3176762844287645]
	TIME [epoch: 8.38 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27179550061065905		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.27179550061065905 | validation: 0.35129862495456793]
	TIME [epoch: 8.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31988602038679004		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.31988602038679004 | validation: 0.2910318017996085]
	TIME [epoch: 8.38 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3241704773278801		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.3241704773278801 | validation: 0.3027659953077589]
	TIME [epoch: 8.38 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36699876239403195		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.36699876239403195 | validation: 0.2483444937701568]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31070819523044285		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.31070819523044285 | validation: 0.23030074479780027]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38657539083674364		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.38657539083674364 | validation: 0.3607716475823503]
	TIME [epoch: 8.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38559276075183024		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.38559276075183024 | validation: 0.3330438857878216]
	TIME [epoch: 8.39 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35185549362035734		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.35185549362035734 | validation: 0.20871509040727693]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26889678135587236		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.26889678135587236 | validation: 0.26242643407727373]
	TIME [epoch: 8.42 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3774914268282184		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.3774914268282184 | validation: 0.26665748081443574]
	TIME [epoch: 8.39 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35228477415429743		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.35228477415429743 | validation: 0.28886468908325635]
	TIME [epoch: 8.39 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27883508751944414		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.27883508751944414 | validation: 0.20928286435076374]
	TIME [epoch: 8.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2836452608334396		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.2836452608334396 | validation: 0.7673072948523356]
	TIME [epoch: 8.41 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41530946468996516		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.41530946468996516 | validation: 0.3709244851442012]
	TIME [epoch: 8.39 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36877620025392777		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.36877620025392777 | validation: 0.34734381456938634]
	TIME [epoch: 8.39 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39364886129867804		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.39364886129867804 | validation: 0.27023755250941617]
	TIME [epoch: 8.41 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29709321865558247		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.29709321865558247 | validation: 0.23157844399519978]
	TIME [epoch: 8.41 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296015976861774		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.296015976861774 | validation: 0.3203234121420508]
	TIME [epoch: 8.39 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3066759305738739		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.3066759305738739 | validation: 0.22662986124145296]
	TIME [epoch: 8.39 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3424785886380048		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.3424785886380048 | validation: 0.4983311306977054]
	TIME [epoch: 8.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3667065867535813		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.3667065867535813 | validation: 0.2610353036058204]
	TIME [epoch: 8.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42193530468662255		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.42193530468662255 | validation: 0.42293798367684754]
	TIME [epoch: 8.39 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3882681446766788		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.3882681446766788 | validation: 0.2519064038555073]
	TIME [epoch: 8.39 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3253656378843604		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.3253656378843604 | validation: 0.3081481227984473]
	TIME [epoch: 8.42 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34128461865916343		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.34128461865916343 | validation: 0.3169777660304808]
	TIME [epoch: 8.44 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36402393920733217		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.36402393920733217 | validation: 0.2561894131329869]
	TIME [epoch: 8.41 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3278567722383063		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.3278567722383063 | validation: 0.5083367076228309]
	TIME [epoch: 8.41 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3938009307802187		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.3938009307802187 | validation: 0.3475019341762187]
	TIME [epoch: 8.43 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36898751764613313		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.36898751764613313 | validation: 0.25164967201629546]
	TIME [epoch: 8.43 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3046650159282366		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.3046650159282366 | validation: 0.4898664608185355]
	TIME [epoch: 8.41 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4252673376968258		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.4252673376968258 | validation: 0.3943829120197827]
	TIME [epoch: 8.41 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31141177166870937		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.31141177166870937 | validation: 0.29887125391776975]
	TIME [epoch: 8.44 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33530593453621144		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.33530593453621144 | validation: 0.5704218320500147]
	TIME [epoch: 8.42 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3563821072655567		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.3563821072655567 | validation: 0.25140783285491963]
	TIME [epoch: 8.41 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3029811759234136		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.3029811759234136 | validation: 0.2765303989366854]
	TIME [epoch: 8.41 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3372499750781358		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.3372499750781358 | validation: 1.3002194547259716]
	TIME [epoch: 8.44 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3999567043027529		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.3999567043027529 | validation: 0.2731584060682086]
	TIME [epoch: 8.42 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38309734092957604		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.38309734092957604 | validation: 0.3872362679250452]
	TIME [epoch: 8.39 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35743927556696836		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.35743927556696836 | validation: 0.2866305873034301]
	TIME [epoch: 8.39 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2885635545006698		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.2885635545006698 | validation: 0.29085258273247083]
	TIME [epoch: 8.41 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26458377007772166		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.26458377007772166 | validation: 0.25255996070910786]
	TIME [epoch: 8.39 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2572612596901035		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.2572612596901035 | validation: 0.22155704596847725]
	TIME [epoch: 8.4 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2987411013276928		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.2987411013276928 | validation: 0.2467216346912552]
	TIME [epoch: 8.43 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2862586810868224		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.2862586810868224 | validation: 0.2636121277986458]
	TIME [epoch: 8.44 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26877257074638267		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.26877257074638267 | validation: 0.36522314725039867]
	TIME [epoch: 8.42 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30048183590082356		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.30048183590082356 | validation: 0.2840823684763759]
	TIME [epoch: 8.41 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2571413019540027		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.2571413019540027 | validation: 0.5487779244673823]
	TIME [epoch: 8.41 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35125418570695727		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.35125418570695727 | validation: 0.4626147375033537]
	TIME [epoch: 8.42 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31276688476920916		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.31276688476920916 | validation: 0.5352672472311546]
	TIME [epoch: 8.41 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35529110683255727		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.35529110683255727 | validation: 0.3686977809149318]
	TIME [epoch: 8.41 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3238239138519288		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.3238239138519288 | validation: 0.3442011574094639]
	TIME [epoch: 8.39 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.301452851137506		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.301452851137506 | validation: 0.24253032671283103]
	TIME [epoch: 8.41 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727192613038211		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.2727192613038211 | validation: 0.2802364759684185]
	TIME [epoch: 8.39 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3044311816579947		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.3044311816579947 | validation: 0.22937657138972167]
	TIME [epoch: 8.39 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30472287258283026		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.30472287258283026 | validation: 0.40510806642709185]
	TIME [epoch: 8.39 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3212676067423175		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.3212676067423175 | validation: 0.28542624667347527]
	TIME [epoch: 8.42 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2427314533860685		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.2427314533860685 | validation: 0.3208250247604757]
	TIME [epoch: 8.39 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41640449199998153		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.41640449199998153 | validation: 0.3156343355627988]
	TIME [epoch: 8.39 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3271664923141896		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.3271664923141896 | validation: 0.21094246440656306]
	TIME [epoch: 8.39 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2759886819146066		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.2759886819146066 | validation: 0.534436457492957]
	TIME [epoch: 8.42 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109960925556437		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.3109960925556437 | validation: 0.25606971206370266]
	TIME [epoch: 8.39 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861717438742349		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.2861717438742349 | validation: 0.28804979937449127]
	TIME [epoch: 8.39 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27171814586547294		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.27171814586547294 | validation: 0.356360661601611]
	TIME [epoch: 8.39 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3648143535433951		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.3648143535433951 | validation: 0.2660024630186903]
	TIME [epoch: 8.42 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3085579184647999		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.3085579184647999 | validation: 0.2681032313891747]
	TIME [epoch: 8.39 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29707714146968334		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.29707714146968334 | validation: 0.3297913208029382]
	TIME [epoch: 8.39 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3511597274508044		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.3511597274508044 | validation: 0.35587355967909]
	TIME [epoch: 8.39 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2795273319168027		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.2795273319168027 | validation: 0.232579899007956]
	TIME [epoch: 8.42 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3050948242717457		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.3050948242717457 | validation: 0.2363660104405393]
	TIME [epoch: 8.39 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698198051854608		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.2698198051854608 | validation: 0.21132598684576076]
	TIME [epoch: 8.39 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27552389111979864		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.27552389111979864 | validation: 0.4479815076048014]
	TIME [epoch: 8.39 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29941570082640967		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.29941570082640967 | validation: 0.29714154533896997]
	TIME [epoch: 8.42 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28697969931481476		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.28697969931481476 | validation: 0.5168490796450591]
	TIME [epoch: 8.39 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3076301498279437		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.3076301498279437 | validation: 0.2805174498604447]
	TIME [epoch: 8.39 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678210180643835		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.2678210180643835 | validation: 0.6075146847355688]
	TIME [epoch: 8.39 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27160193515080644		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.27160193515080644 | validation: 0.3188405745175165]
	TIME [epoch: 8.41 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41593246735117556		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.41593246735117556 | validation: 0.3171703206051967]
	TIME [epoch: 8.39 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.371163199719362		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.371163199719362 | validation: 0.6357471587107953]
	TIME [epoch: 8.39 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2911255850397377		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.2911255850397377 | validation: 0.39322753906288377]
	TIME [epoch: 8.4 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3402894392894763		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.3402894392894763 | validation: 0.3061169917816457]
	TIME [epoch: 8.41 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3135936477372848		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.3135936477372848 | validation: 0.29235428967152716]
	TIME [epoch: 8.39 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28317809441172404		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.28317809441172404 | validation: 0.20053244226578731]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22228311841871382		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.22228311841871382 | validation: 0.3438576912874306]
	TIME [epoch: 8.41 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26920835931514875		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.26920835931514875 | validation: 0.28013384127303603]
	TIME [epoch: 8.41 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23466365418584414		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.23466365418584414 | validation: 0.22031970725478983]
	TIME [epoch: 8.39 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27581303089340353		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.27581303089340353 | validation: 0.24232098435837368]
	TIME [epoch: 8.39 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27756813117029044		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.27756813117029044 | validation: 0.46135835936946834]
	TIME [epoch: 8.41 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30568678163618207		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.30568678163618207 | validation: 0.2592809972875409]
	TIME [epoch: 8.41 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3017843948854652		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.3017843948854652 | validation: 0.3427746197499595]
	TIME [epoch: 8.39 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2575609168404699		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.2575609168404699 | validation: 0.28020469143577437]
	TIME [epoch: 8.39 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34203198885453456		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.34203198885453456 | validation: 0.2706745438383886]
	TIME [epoch: 8.41 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27129126719501223		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.27129126719501223 | validation: 0.28261309997601375]
	TIME [epoch: 8.41 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24224341967615254		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.24224341967615254 | validation: 0.5144114593495913]
	TIME [epoch: 8.39 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30625472599187764		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.30625472599187764 | validation: 0.24214689047810906]
	TIME [epoch: 8.39 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2658056483921047		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.2658056483921047 | validation: 0.29004073365903926]
	TIME [epoch: 8.41 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38626723394296913		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.38626723394296913 | validation: 0.5460413004697711]
	TIME [epoch: 8.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2960871391388912		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.2960871391388912 | validation: 0.2731546691157347]
	TIME [epoch: 8.39 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28503304981055116		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.28503304981055116 | validation: 0.19859087325594854]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3565162771984917		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.3565162771984917 | validation: 0.5010820632405608]
	TIME [epoch: 8.42 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28172296729174284		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.28172296729174284 | validation: 0.22402835339138008]
	TIME [epoch: 8.39 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426552862306878		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.2426552862306878 | validation: 0.2583590252963551]
	TIME [epoch: 8.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30018203402543897		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.30018203402543897 | validation: 0.3951996690370969]
	TIME [epoch: 8.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27625603897497275		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.27625603897497275 | validation: 0.3885253123205359]
	TIME [epoch: 8.42 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30045400185220444		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.30045400185220444 | validation: 0.21977168991561663]
	TIME [epoch: 8.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22539971088749086		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.22539971088749086 | validation: 0.2361333925371103]
	TIME [epoch: 8.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3654698985369998		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.3654698985369998 | validation: 0.23596083629630488]
	TIME [epoch: 8.39 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22665626853638443		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.22665626853638443 | validation: 0.18028929572150781]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3072704789681713		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.3072704789681713 | validation: 0.3769518026576069]
	TIME [epoch: 8.39 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26464775437978033		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.26464775437978033 | validation: 0.24583323367878013]
	TIME [epoch: 8.39 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25591940319902207		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.25591940319902207 | validation: 0.2153773639599872]
	TIME [epoch: 8.39 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27949702083767647		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.27949702083767647 | validation: 0.2626594335465618]
	TIME [epoch: 8.41 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2666054698781582		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.2666054698781582 | validation: 0.3240449136439213]
	TIME [epoch: 8.39 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250966715095489		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.250966715095489 | validation: 0.20888340328296406]
	TIME [epoch: 8.39 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20871992440105322		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.20871992440105322 | validation: 0.22113804599677506]
	TIME [epoch: 8.39 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2290321527277121		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.2290321527277121 | validation: 0.25270458854445754]
	TIME [epoch: 8.41 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23291555516693915		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.23291555516693915 | validation: 0.30437427616760504]
	TIME [epoch: 8.39 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2501120373624738		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.2501120373624738 | validation: 0.34265053827168246]
	TIME [epoch: 8.39 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2915152338910967		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.2915152338910967 | validation: 0.3219037448808757]
	TIME [epoch: 8.39 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3868133401143538		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.3868133401143538 | validation: 0.3835953733194417]
	TIME [epoch: 8.41 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22103841994722867		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.22103841994722867 | validation: 0.20985300097414847]
	TIME [epoch: 8.39 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2290644942236682		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.2290644942236682 | validation: 0.19807629982988817]
	TIME [epoch: 8.39 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2629525122658595		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.2629525122658595 | validation: 0.21509818366714684]
	TIME [epoch: 8.39 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2640157277188669		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.2640157277188669 | validation: 0.23235948082780608]
	TIME [epoch: 8.41 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26815370299948377		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.26815370299948377 | validation: 0.36450750887104205]
	TIME [epoch: 8.39 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30979403979375003		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.30979403979375003 | validation: 0.2967678947345912]
	TIME [epoch: 8.39 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28596113640913673		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.28596113640913673 | validation: 0.32122687982543463]
	TIME [epoch: 8.39 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23306283473156766		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.23306283473156766 | validation: 0.2078242143386317]
	TIME [epoch: 8.42 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2958319343858225		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.2958319343858225 | validation: 0.27241104118047077]
	TIME [epoch: 8.39 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3055507007203885		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.3055507007203885 | validation: 0.23053835274893386]
	TIME [epoch: 8.39 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27638162630338053		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.27638162630338053 | validation: 0.18039076877853322]
	TIME [epoch: 8.39 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25437614228238803		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.25437614228238803 | validation: 0.22548716677308062]
	TIME [epoch: 8.41 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2964329114854751		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.2964329114854751 | validation: 0.24416363292359658]
	TIME [epoch: 8.39 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24737275834013012		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.24737275834013012 | validation: 0.2346445777086848]
	TIME [epoch: 8.39 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28470134311446715		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.28470134311446715 | validation: 0.3504059526665001]
	TIME [epoch: 8.39 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23914962135765724		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.23914962135765724 | validation: 0.19695802998134182]
	TIME [epoch: 8.42 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2806492849321621		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.2806492849321621 | validation: 0.2030318848603993]
	TIME [epoch: 8.39 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21959394382189035		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.21959394382189035 | validation: 0.2652156901143883]
	TIME [epoch: 8.39 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25850426343341504		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.25850426343341504 | validation: 0.20395430956712995]
	TIME [epoch: 8.39 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27597410179115944		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.27597410179115944 | validation: 0.22854314309507007]
	TIME [epoch: 8.41 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2628758188265928		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.2628758188265928 | validation: 0.18935384906540692]
	TIME [epoch: 8.39 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305359720128559		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.3305359720128559 | validation: 0.20954788369022528]
	TIME [epoch: 8.39 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601961457317468		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.2601961457317468 | validation: 0.2224651985181296]
	TIME [epoch: 8.4 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976297549279536		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.2976297549279536 | validation: 0.35163074024349267]
	TIME [epoch: 8.41 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37334800569234505		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.37334800569234505 | validation: 0.17774340179752202]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22119593145485156		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.22119593145485156 | validation: 0.21037230232325455]
	TIME [epoch: 8.39 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2433172120695049		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.2433172120695049 | validation: 0.2217197763057423]
	TIME [epoch: 8.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.251646245826931		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.251646245826931 | validation: 0.33628445293632653]
	TIME [epoch: 8.39 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2351524266000428		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.2351524266000428 | validation: 0.3867650287049712]
	TIME [epoch: 8.38 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29520214243423987		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.29520214243423987 | validation: 0.32480568511879726]
	TIME [epoch: 8.39 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2552440780678728		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.2552440780678728 | validation: 0.24833840808407245]
	TIME [epoch: 8.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2585112045699273		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.2585112045699273 | validation: 0.24335417412979837]
	TIME [epoch: 8.39 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22687794798503166		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.22687794798503166 | validation: 0.23064966267066858]
	TIME [epoch: 8.38 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.288696115074374		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.288696115074374 | validation: 0.22621468789300544]
	TIME [epoch: 8.38 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24243850124157934		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.24243850124157934 | validation: 0.17613490897818287]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25562663014500714		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.25562663014500714 | validation: 0.23819469508334712]
	TIME [epoch: 8.4 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.264348799528209		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.264348799528209 | validation: 0.2743576604487036]
	TIME [epoch: 8.39 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2463490385516281		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.2463490385516281 | validation: 0.37634333487685945]
	TIME [epoch: 8.39 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788725126822359		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.2788725126822359 | validation: 0.19923764255438584]
	TIME [epoch: 8.41 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22169484236656206		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.22169484236656206 | validation: 0.27012186025768603]
	TIME [epoch: 8.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24575987983812392		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.24575987983812392 | validation: 0.18982912893094492]
	TIME [epoch: 8.39 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389004945985147		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.2389004945985147 | validation: 0.2951036717142767]
	TIME [epoch: 8.39 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22428234484380552		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.22428234484380552 | validation: 0.22488109665139094]
	TIME [epoch: 8.41 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20102731653920553		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.20102731653920553 | validation: 0.22729246243928986]
	TIME [epoch: 8.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24672149570701135		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.24672149570701135 | validation: 0.27666139984299004]
	TIME [epoch: 8.39 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32517161769087605		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.32517161769087605 | validation: 0.19647071252751164]
	TIME [epoch: 8.39 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2809826717097675		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.2809826717097675 | validation: 0.3401555013590179]
	TIME [epoch: 8.42 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698252659813873		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.2698252659813873 | validation: 0.2303589885903406]
	TIME [epoch: 8.39 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25568768634713235		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.25568768634713235 | validation: 0.2209736585737013]
	TIME [epoch: 8.39 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22397520259791004		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.22397520259791004 | validation: 0.20358045510989553]
	TIME [epoch: 8.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23476100388683957		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.23476100388683957 | validation: 0.23257325862514117]
	TIME [epoch: 8.41 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2261277684166069		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.2261277684166069 | validation: 0.19240765480236766]
	TIME [epoch: 8.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2165691211836532		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.2165691211836532 | validation: 0.19138655355708162]
	TIME [epoch: 8.39 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.204721650310535		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.204721650310535 | validation: 0.19888277747302846]
	TIME [epoch: 8.39 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2334937073466123		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.2334937073466123 | validation: 0.22659454713515523]
	TIME [epoch: 8.42 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28964116821121166		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.28964116821121166 | validation: 0.30874395348716477]
	TIME [epoch: 8.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23833746057143412		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.23833746057143412 | validation: 0.5602372529941378]
	TIME [epoch: 8.39 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32096310701963604		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.32096310701963604 | validation: 0.20489166365008465]
	TIME [epoch: 8.39 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32013900578435783		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.32013900578435783 | validation: 0.2450852620156049]
	TIME [epoch: 8.42 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22126030730727883		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.22126030730727883 | validation: 0.2521024076839834]
	TIME [epoch: 8.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2738864417927419		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.2738864417927419 | validation: 0.5602755982593485]
	TIME [epoch: 8.39 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2821837548850847		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.2821837548850847 | validation: 0.1864617371281787]
	TIME [epoch: 8.39 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19535868506091408		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.19535868506091408 | validation: 0.18911512753464807]
	TIME [epoch: 8.41 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2851525190449254		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.2851525190449254 | validation: 0.4113691761486866]
	TIME [epoch: 8.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.262368483833048		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.262368483833048 | validation: 0.29994462274898004]
	TIME [epoch: 8.39 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2755490545581629		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.2755490545581629 | validation: 0.2699676960660061]
	TIME [epoch: 8.39 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594440257373147		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.3594440257373147 | validation: 0.21949627646523162]
	TIME [epoch: 8.42 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26246991264504527		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.26246991264504527 | validation: 0.4869078185213891]
	TIME [epoch: 8.39 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21591831686057317		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.21591831686057317 | validation: 0.1793117269341026]
	TIME [epoch: 8.39 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21703796632120104		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.21703796632120104 | validation: 0.2047276948660931]
	TIME [epoch: 8.39 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24590881519091382		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.24590881519091382 | validation: 0.4068328984632049]
	TIME [epoch: 8.42 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861639719983651		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.2861639719983651 | validation: 0.2468553275655327]
	TIME [epoch: 8.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21072512395312876		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.21072512395312876 | validation: 0.35661900062373963]
	TIME [epoch: 8.39 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23156765430890897		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.23156765430890897 | validation: 0.29944724358830743]
	TIME [epoch: 8.39 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.299917490368898		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.299917490368898 | validation: 0.22462196629352255]
	TIME [epoch: 8.42 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915363744256024		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.1915363744256024 | validation: 0.16589204607043437]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23427564860761696		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.23427564860761696 | validation: 0.15938909174730742]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23904388613100394		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.23904388613100394 | validation: 0.5093515319535881]
	TIME [epoch: 8.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24678308248945524		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.24678308248945524 | validation: 0.19381299859413376]
	TIME [epoch: 8.41 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27362164949844814		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.27362164949844814 | validation: 0.40804414406552664]
	TIME [epoch: 8.38 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2694333665179726		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.2694333665179726 | validation: 0.5546704788899876]
	TIME [epoch: 8.38 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3603307390490292		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.3603307390490292 | validation: 0.20391523267224018]
	TIME [epoch: 8.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2451700232043481		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.2451700232043481 | validation: 0.19801647372170084]
	TIME [epoch: 8.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21534247928589992		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.21534247928589992 | validation: 0.2943054591113094]
	TIME [epoch: 8.39 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2332771012560786		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.2332771012560786 | validation: 0.2679144618779067]
	TIME [epoch: 8.38 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2244133845943698		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.2244133845943698 | validation: 0.25884166558668]
	TIME [epoch: 8.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.225174456457815		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.225174456457815 | validation: 0.4286091153765518]
	TIME [epoch: 8.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27121641117671846		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.27121641117671846 | validation: 0.21739252288421435]
	TIME [epoch: 8.38 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22225187344247566		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.22225187344247566 | validation: 0.273702225761019]
	TIME [epoch: 8.39 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2926815890380655		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.2926815890380655 | validation: 0.2693118565799917]
	TIME [epoch: 8.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3174968922496051		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.3174968922496051 | validation: 0.3327660225228707]
	TIME [epoch: 8.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2688846126361738		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.2688846126361738 | validation: 0.3377833675615962]
	TIME [epoch: 8.38 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28198222458025507		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.28198222458025507 | validation: 0.23978566103125287]
	TIME [epoch: 8.38 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2816512852029449		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.2816512852029449 | validation: 0.19485553194975974]
	TIME [epoch: 8.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21117245855807504		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.21117245855807504 | validation: 0.32613804312617173]
	TIME [epoch: 8.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2460022395992359		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.2460022395992359 | validation: 0.20430834014193894]
	TIME [epoch: 8.39 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2358629777194662		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.2358629777194662 | validation: 0.29187430294112615]
	TIME [epoch: 8.39 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28372640633353646		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.28372640633353646 | validation: 0.22965759308389166]
	TIME [epoch: 8.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2701470395999483		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.2701470395999483 | validation: 0.21427640837036838]
	TIME [epoch: 8.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18034135044897318		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.18034135044897318 | validation: 0.17046393606464394]
	TIME [epoch: 8.38 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19811620743005792		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.19811620743005792 | validation: 0.23416812077148583]
	TIME [epoch: 8.38 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2226304025624827		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.2226304025624827 | validation: 0.21112269565761368]
	TIME [epoch: 8.41 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2583295567539342		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.2583295567539342 | validation: 0.2093682696966741]
	TIME [epoch: 8.39 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21408140771856984		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.21408140771856984 | validation: 0.20213904252551207]
	TIME [epoch: 8.39 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18916000296241325		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.18916000296241325 | validation: 0.17786254517613892]
	TIME [epoch: 8.38 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2666505440147696		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.2666505440147696 | validation: 0.2655450792771371]
	TIME [epoch: 8.41 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24714587129881602		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.24714587129881602 | validation: 0.28993315480123927]
	TIME [epoch: 8.39 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2574435158824143		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.2574435158824143 | validation: 0.2763846843222112]
	TIME [epoch: 8.38 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2754817033068209		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.2754817033068209 | validation: 0.22083382059081055]
	TIME [epoch: 8.39 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19736292605666603		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.19736292605666603 | validation: 0.2503915643407406]
	TIME [epoch: 8.41 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19955073507240526		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.19955073507240526 | validation: 0.23547720149494983]
	TIME [epoch: 8.39 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27653403167311885		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.27653403167311885 | validation: 0.2305982120893027]
	TIME [epoch: 8.39 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3161185671825074		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.3161185671825074 | validation: 0.4646482000282184]
	TIME [epoch: 8.38 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27968176147429863		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.27968176147429863 | validation: 0.1842881159801848]
	TIME [epoch: 8.41 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22676645027285272		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.22676645027285272 | validation: 0.1931903891734963]
	TIME [epoch: 8.39 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2901779228555946		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.2901779228555946 | validation: 0.1839612908833932]
	TIME [epoch: 8.39 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23996992930040503		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.23996992930040503 | validation: 0.2177003931889201]
	TIME [epoch: 8.38 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2790519130298634		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.2790519130298634 | validation: 0.23839601701488816]
	TIME [epoch: 8.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22273590519067618		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.22273590519067618 | validation: 0.20335457093278947]
	TIME [epoch: 8.39 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2732464032038255		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.2732464032038255 | validation: 0.20801838797276045]
	TIME [epoch: 8.38 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25331108799390073		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.25331108799390073 | validation: 0.27442866579608105]
	TIME [epoch: 8.38 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2319128829819311		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.2319128829819311 | validation: 0.18835922170070912]
	TIME [epoch: 8.41 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1890269490805196		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.1890269490805196 | validation: 0.18593811982670014]
	TIME [epoch: 8.39 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22163574673824757		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.22163574673824757 | validation: 0.304198715979234]
	TIME [epoch: 8.38 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21285082549892276		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.21285082549892276 | validation: 0.28116092368656037]
	TIME [epoch: 8.39 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24665394392910436		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.24665394392910436 | validation: 0.1581218315070796]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21221577989379758		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.21221577989379758 | validation: 0.19399993413205002]
	TIME [epoch: 8.39 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.220261468922779		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.220261468922779 | validation: 0.18990879505336747]
	TIME [epoch: 8.38 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20077944852201646		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.20077944852201646 | validation: 0.20606962866224737]
	TIME [epoch: 8.38 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24997638944040426		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.24997638944040426 | validation: 0.27081877272631555]
	TIME [epoch: 8.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26595876718033307		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.26595876718033307 | validation: 0.25269267753827895]
	TIME [epoch: 8.38 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25096874961431787		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.25096874961431787 | validation: 0.3473760847482924]
	TIME [epoch: 8.38 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678175058616422		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.2678175058616422 | validation: 0.21370650245472486]
	TIME [epoch: 8.38 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28371265126746054		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.28371265126746054 | validation: 0.16371465266930363]
	TIME [epoch: 8.41 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2440476466624332		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.2440476466624332 | validation: 0.198703100673791]
	TIME [epoch: 8.38 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23385760463223618		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.23385760463223618 | validation: 0.3144976176480182]
	TIME [epoch: 8.39 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25630834981352413		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.25630834981352413 | validation: 0.4472441448571402]
	TIME [epoch: 8.38 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2455421267619456		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.2455421267619456 | validation: 0.40284365003451095]
	TIME [epoch: 8.41 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2843919271392248		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.2843919271392248 | validation: 0.31356394966199985]
	TIME [epoch: 8.39 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2894602580506253		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.2894602580506253 | validation: 0.34023987940629097]
	TIME [epoch: 8.38 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2521238812975754		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.2521238812975754 | validation: 0.33069772623417293]
	TIME [epoch: 8.39 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2899448188700789		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.2899448188700789 | validation: 0.23562893582490163]
	TIME [epoch: 8.41 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23712737799379005		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.23712737799379005 | validation: 0.20941991067155866]
	TIME [epoch: 8.39 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25991478967235093		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.25991478967235093 | validation: 0.2189810435754905]
	TIME [epoch: 8.38 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2739301588410586		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.2739301588410586 | validation: 0.19040984623552235]
	TIME [epoch: 8.39 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19888224793885473		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.19888224793885473 | validation: 0.19702392762993526]
	TIME [epoch: 8.41 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20420962065914222		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.20420962065914222 | validation: 0.2023344733556507]
	TIME [epoch: 8.39 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2007147797533007		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.2007147797533007 | validation: 0.24320830108182845]
	TIME [epoch: 8.39 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1914469964349088		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.1914469964349088 | validation: 0.26224968120691083]
	TIME [epoch: 8.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20742993358165246		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.20742993358165246 | validation: 0.17562900001899337]
	TIME [epoch: 8.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20926509435394364		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.20926509435394364 | validation: 0.265443352979036]
	TIME [epoch: 8.39 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23847970403448993		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.23847970403448993 | validation: 0.3837376865619675]
	TIME [epoch: 8.39 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40952945087421205		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.40952945087421205 | validation: 0.4015499318957931]
	TIME [epoch: 8.39 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21753601840393091		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.21753601840393091 | validation: 0.2316632272133603]
	TIME [epoch: 8.41 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678263348843028		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.2678263348843028 | validation: 0.17640362496371587]
	TIME [epoch: 8.39 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21137481062318372		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.21137481062318372 | validation: 0.33678599270358267]
	TIME [epoch: 8.39 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23980332747447708		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.23980332747447708 | validation: 0.2634481262028475]
	TIME [epoch: 8.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23861459172211624		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.23861459172211624 | validation: 0.21602128711403687]
	TIME [epoch: 8.39 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2062350588518947		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.2062350588518947 | validation: 0.24388410233024144]
	TIME [epoch: 8.39 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25477925779829624		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.25477925779829624 | validation: 0.21775215933506398]
	TIME [epoch: 8.38 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2241466637093171		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.2241466637093171 | validation: 0.26792244765340156]
	TIME [epoch: 8.41 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.230961902238057		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.230961902238057 | validation: 0.1708031104229617]
	TIME [epoch: 8.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19853169877525897		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.19853169877525897 | validation: 0.20850881916044262]
	TIME [epoch: 8.38 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530047559413021		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.2530047559413021 | validation: 0.17117543673402746]
	TIME [epoch: 8.39 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20182271676507052		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.20182271676507052 | validation: 0.18961902771420455]
	TIME [epoch: 8.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21475625116755603		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.21475625116755603 | validation: 0.20154628927843804]
	TIME [epoch: 8.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21740493855182796		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.21740493855182796 | validation: 0.26593857655457215]
	TIME [epoch: 8.38 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23162613195326007		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.23162613195326007 | validation: 0.17676089377842474]
	TIME [epoch: 8.38 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21635246150789472		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.21635246150789472 | validation: 0.2843241951696537]
	TIME [epoch: 8.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21779916950598457		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.21779916950598457 | validation: 0.24537717300212167]
	TIME [epoch: 8.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22168299352866624		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.22168299352866624 | validation: 0.25140932122972204]
	TIME [epoch: 8.39 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1891207978494494		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.1891207978494494 | validation: 0.20704614971238988]
	TIME [epoch: 8.38 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22358642070962617		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.22358642070962617 | validation: 0.21584079515481136]
	TIME [epoch: 8.41 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2517428065570091		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.2517428065570091 | validation: 0.2687544887458835]
	TIME [epoch: 8.39 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2613003951598758		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.2613003951598758 | validation: 0.288163424331019]
	TIME [epoch: 8.39 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21973625847465467		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.21973625847465467 | validation: 0.19933523933502423]
	TIME [epoch: 8.39 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1985542575383188		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.1985542575383188 | validation: 0.166241702699115]
	TIME [epoch: 8.41 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22538582679844216		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.22538582679844216 | validation: 0.30843131066560237]
	TIME [epoch: 8.39 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22168004977036465		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.22168004977036465 | validation: 0.15137009390021255]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20240209553914967		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.20240209553914967 | validation: 0.19679852481363075]
	TIME [epoch: 8.39 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22793926652566876		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.22793926652566876 | validation: 0.19409118994712943]
	TIME [epoch: 8.41 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23265129791686986		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.23265129791686986 | validation: 0.1795404905170767]
	TIME [epoch: 8.39 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23388129981292988		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.23388129981292988 | validation: 0.20355482901018895]
	TIME [epoch: 8.38 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2023478015857894		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.2023478015857894 | validation: 0.2145457934336231]
	TIME [epoch: 8.39 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19836444631055458		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.19836444631055458 | validation: 0.1643590062122837]
	TIME [epoch: 8.41 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20450249621377745		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.20450249621377745 | validation: 0.15536779683458984]
	TIME [epoch: 8.39 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18878622374377527		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.18878622374377527 | validation: 0.18608389615205934]
	TIME [epoch: 8.38 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2070776492818796		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.2070776492818796 | validation: 0.2082473085328465]
	TIME [epoch: 8.39 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1873916560977662		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.1873916560977662 | validation: 0.26456693312673685]
	TIME [epoch: 8.41 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23237000489305443		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.23237000489305443 | validation: 0.1661838695764625]
	TIME [epoch: 8.39 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2188374523702814		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.2188374523702814 | validation: 0.1674098636062789]
	TIME [epoch: 8.38 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915324805523802		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.1915324805523802 | validation: 0.18896266508037107]
	TIME [epoch: 8.38 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19389834620399943		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.19389834620399943 | validation: 0.22875430501557714]
	TIME [epoch: 8.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20895166404264115		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.20895166404264115 | validation: 0.4019885022783515]
	TIME [epoch: 8.38 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23769499865376026		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.23769499865376026 | validation: 0.1529987585324921]
	TIME [epoch: 8.38 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906045954422882		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.1906045954422882 | validation: 0.19684585237754548]
	TIME [epoch: 8.38 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23677874179041164		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.23677874179041164 | validation: 0.23201878066233658]
	TIME [epoch: 8.41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1875352189948006		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.1875352189948006 | validation: 0.17537552906619402]
	TIME [epoch: 8.38 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2362393422622942		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.2362393422622942 | validation: 0.25782353230982924]
	TIME [epoch: 8.38 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.176369659081435		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.176369659081435 | validation: 0.2866383733665262]
	TIME [epoch: 8.38 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19427422945316158		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.19427422945316158 | validation: 0.25258995257307715]
	TIME [epoch: 8.41 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18626934216219826		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.18626934216219826 | validation: 0.17010186178560865]
	TIME [epoch: 8.39 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1593609815872577		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.1593609815872577 | validation: 0.17952557969440713]
	TIME [epoch: 8.38 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17152049065108713		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.17152049065108713 | validation: 0.15873708761422417]
	TIME [epoch: 8.39 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24248537884239618		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.24248537884239618 | validation: 0.1814087462829046]
	TIME [epoch: 8.41 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1833011304983593		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.1833011304983593 | validation: 0.15414194721624358]
	TIME [epoch: 8.38 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25692414608854397		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.25692414608854397 | validation: 0.23202632020714756]
	TIME [epoch: 8.39 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26155118900336766		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.26155118900336766 | validation: 0.15422607788689308]
	TIME [epoch: 8.37 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20291909757318677		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.20291909757318677 | validation: 0.28613029433822845]
	TIME [epoch: 8.41 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18700852632068082		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.18700852632068082 | validation: 0.1660739776760204]
	TIME [epoch: 8.38 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1791597678613357		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.1791597678613357 | validation: 0.20249913619561358]
	TIME [epoch: 8.38 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24956824012829762		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.24956824012829762 | validation: 0.5071241422828037]
	TIME [epoch: 8.39 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2876826462764427		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.2876826462764427 | validation: 0.17297343657468298]
	TIME [epoch: 8.41 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19523033048037028		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.19523033048037028 | validation: 0.1786480381622768]
	TIME [epoch: 8.38 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19409792644846852		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.19409792644846852 | validation: 0.18945683671271735]
	TIME [epoch: 8.39 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21469582880109545		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.21469582880109545 | validation: 0.16085833632968682]
	TIME [epoch: 8.39 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34136430102823895		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.34136430102823895 | validation: 0.17359185828037738]
	TIME [epoch: 8.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1876712082382582		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.1876712082382582 | validation: 0.24642363799803618]
	TIME [epoch: 8.39 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2361027813855928		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.2361027813855928 | validation: 0.1853142406661615]
	TIME [epoch: 8.38 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18516823655042522		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.18516823655042522 | validation: 0.16897718774721093]
	TIME [epoch: 8.38 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23145838197718321		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.23145838197718321 | validation: 0.2541615946413986]
	TIME [epoch: 8.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1809634158335614		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.1809634158335614 | validation: 0.1873773206621392]
	TIME [epoch: 8.38 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2446966313143081		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.2446966313143081 | validation: 0.15788188928059305]
	TIME [epoch: 8.38 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24890850796434982		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.24890850796434982 | validation: 0.24079447267070545]
	TIME [epoch: 8.39 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24275555228716325		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.24275555228716325 | validation: 0.42518450589161366]
	TIME [epoch: 8.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21481115798001457		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.21481115798001457 | validation: 0.15055557445547074]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23111474577081062		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.23111474577081062 | validation: 0.1781306953320071]
	TIME [epoch: 8.39 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17545418655375578		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.17545418655375578 | validation: 0.1624031276311807]
	TIME [epoch: 8.41 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15901710810229758		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.15901710810229758 | validation: 0.15488502282537484]
	TIME [epoch: 8.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17245765377104125		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.17245765377104125 | validation: 0.29816041239036206]
	TIME [epoch: 8.38 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19977735923836265		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.19977735923836265 | validation: 0.19455773562173495]
	TIME [epoch: 8.37 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19710508598886076		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.19710508598886076 | validation: 0.1724437843318588]
	TIME [epoch: 8.39 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19092856162083588		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.19092856162083588 | validation: 0.2531957275818984]
	TIME [epoch: 8.38 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17920099247312798		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.17920099247312798 | validation: 0.2044052440773776]
	TIME [epoch: 8.37 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1880218901133446		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.1880218901133446 | validation: 0.2133106229570429]
	TIME [epoch: 8.36 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2097708608512455		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.2097708608512455 | validation: 0.194549132946034]
	TIME [epoch: 8.39 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20058599766265423		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.20058599766265423 | validation: 0.18377331208975933]
	TIME [epoch: 8.38 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19306411880895896		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.19306411880895896 | validation: 0.20367238016347092]
	TIME [epoch: 8.37 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17889876346564965		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.17889876346564965 | validation: 0.16641064547331474]
	TIME [epoch: 8.38 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2074905187030983		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.2074905187030983 | validation: 0.2879604863465455]
	TIME [epoch: 8.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26072940589950133		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.26072940589950133 | validation: 0.22248351333579036]
	TIME [epoch: 8.38 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21640851729788504		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.21640851729788504 | validation: 0.25070648853489735]
	TIME [epoch: 8.37 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1961760310572388		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.1961760310572388 | validation: 0.21319869150265805]
	TIME [epoch: 8.37 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19673081151141053		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.19673081151141053 | validation: 0.1715503706120472]
	TIME [epoch: 8.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2247534025241275		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.2247534025241275 | validation: 0.18136221482949139]
	TIME [epoch: 8.38 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18349487929012395		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.18349487929012395 | validation: 0.2170795435495334]
	TIME [epoch: 8.37 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23953304263221525		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.23953304263221525 | validation: 0.17875828095708451]
	TIME [epoch: 8.37 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1811357573818022		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.1811357573818022 | validation: 0.204373398654848]
	TIME [epoch: 8.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24043630142691702		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.24043630142691702 | validation: 0.19541566778904207]
	TIME [epoch: 8.38 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17425574538648037		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.17425574538648037 | validation: 0.15974020364801567]
	TIME [epoch: 8.38 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20897346366041059		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.20897346366041059 | validation: 0.16322057356449834]
	TIME [epoch: 8.38 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18595973087100642		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.18595973087100642 | validation: 0.16834831046613302]
	TIME [epoch: 8.41 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17269006082486923		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.17269006082486923 | validation: 0.22653204527629578]
	TIME [epoch: 8.38 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20678567473132822		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.20678567473132822 | validation: 0.21466146869252717]
	TIME [epoch: 8.38 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20436485229544102		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.20436485229544102 | validation: 0.16190418630071637]
	TIME [epoch: 8.38 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1896548169242979		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.1896548169242979 | validation: 0.22062457346097636]
	TIME [epoch: 8.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22408052006651516		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.22408052006651516 | validation: 0.25087507600575004]
	TIME [epoch: 8.39 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18845828951771348		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.18845828951771348 | validation: 0.15838018204867854]
	TIME [epoch: 8.38 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1778425859150526		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.1778425859150526 | validation: 0.25468888428798486]
	TIME [epoch: 8.39 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24318940892599525		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.24318940892599525 | validation: 0.196885187002324]
	TIME [epoch: 8.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16274779150689855		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.16274779150689855 | validation: 0.1592339349121382]
	TIME [epoch: 8.39 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17401840195936		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.17401840195936 | validation: 0.23665124526884712]
	TIME [epoch: 8.38 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20790730757902964		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.20790730757902964 | validation: 0.14896615499086663]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895555314527695		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.1895555314527695 | validation: 0.1520519653188096]
	TIME [epoch: 8.43 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2246592251152708		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.2246592251152708 | validation: 0.22161643802036798]
	TIME [epoch: 8.39 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17546409538678673		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.17546409538678673 | validation: 0.16773598771537807]
	TIME [epoch: 8.39 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22683149698895036		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.22683149698895036 | validation: 0.18214612467500846]
	TIME [epoch: 8.39 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20230259741926643		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.20230259741926643 | validation: 0.18034997944402442]
	TIME [epoch: 8.42 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2136135844648229		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.2136135844648229 | validation: 0.180686870227193]
	TIME [epoch: 8.39 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17509489295779748		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.17509489295779748 | validation: 0.19463682766248097]
	TIME [epoch: 8.39 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17207115692740235		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.17207115692740235 | validation: 0.23025944809497806]
	TIME [epoch: 8.39 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20188173137557225		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.20188173137557225 | validation: 0.25510758530093647]
	TIME [epoch: 8.41 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1742681377788493		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.1742681377788493 | validation: 0.35481417910200497]
	TIME [epoch: 8.39 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2065198540511525		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.2065198540511525 | validation: 0.20097667221608667]
	TIME [epoch: 8.39 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2033496097841428		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.2033496097841428 | validation: 0.18246425365117808]
	TIME [epoch: 8.39 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25246802048968614		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.25246802048968614 | validation: 0.38576657686434473]
	TIME [epoch: 8.41 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25511794940781496		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.25511794940781496 | validation: 0.33050731337934425]
	TIME [epoch: 8.39 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22156993354265273		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.22156993354265273 | validation: 0.21881544403451433]
	TIME [epoch: 8.39 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20872767139548784		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.20872767139548784 | validation: 0.13743654143992823]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16101414171749653		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.16101414171749653 | validation: 0.20494284882670197]
	TIME [epoch: 8.42 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17200797601022577		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.17200797601022577 | validation: 0.17804774498929388]
	TIME [epoch: 8.38 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2359397494122352		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.2359397494122352 | validation: 0.26339170787014804]
	TIME [epoch: 8.39 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2328412125615162		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.2328412125615162 | validation: 0.20170887795733705]
	TIME [epoch: 8.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19791279801751652		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.19791279801751652 | validation: 0.3261427654061589]
	TIME [epoch: 8.41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1951801757637527		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.1951801757637527 | validation: 0.25808443021354865]
	TIME [epoch: 8.39 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19460762836191464		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.19460762836191464 | validation: 0.16208160145902012]
	TIME [epoch: 8.39 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2434562666946339		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.2434562666946339 | validation: 0.24107536476923]
	TIME [epoch: 8.41 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2067391105244742		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.2067391105244742 | validation: 0.19663644019199236]
	TIME [epoch: 8.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17664908439845953		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.17664908439845953 | validation: 0.18773805910224445]
	TIME [epoch: 8.39 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2089472286740815		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.2089472286740815 | validation: 0.21411573918712468]
	TIME [epoch: 8.38 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16084392254487406		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.16084392254487406 | validation: 0.16416592256717624]
	TIME [epoch: 8.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16352399562328396		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.16352399562328396 | validation: 0.1979219371717731]
	TIME [epoch: 8.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18457053326006548		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.18457053326006548 | validation: 0.169342402248667]
	TIME [epoch: 8.38 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2201660213007167		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.2201660213007167 | validation: 0.2260539193034491]
	TIME [epoch: 8.39 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2332318671564732		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.2332318671564732 | validation: 0.16750132042778137]
	TIME [epoch: 8.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18549101592984388		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.18549101592984388 | validation: 0.15719545270723095]
	TIME [epoch: 8.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20951459156871083		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.20951459156871083 | validation: 0.17509411577415057]
	TIME [epoch: 8.38 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18443533798525152		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.18443533798525152 | validation: 0.1402996316947336]
	TIME [epoch: 8.39 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1691821559816919		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.1691821559816919 | validation: 0.15267365332037164]
	TIME [epoch: 8.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18303596990713317		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.18303596990713317 | validation: 0.2535888655926133]
	TIME [epoch: 8.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22232190853254954		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.22232190853254954 | validation: 0.1838408304849411]
	TIME [epoch: 8.39 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22652287866168302		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.22652287866168302 | validation: 0.23779036172607887]
	TIME [epoch: 8.39 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1914000485190291		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.1914000485190291 | validation: 0.21355824896836084]
	TIME [epoch: 8.41 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17724522890244343		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.17724522890244343 | validation: 0.14899882154756022]
	TIME [epoch: 8.39 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16799331705304127		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.16799331705304127 | validation: 0.25105882936617174]
	TIME [epoch: 8.38 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18908709420118883		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.18908709420118883 | validation: 0.16604561615497265]
	TIME [epoch: 8.38 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1907266127853283		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.1907266127853283 | validation: 0.3238852247285883]
	TIME [epoch: 8.41 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18069235926129082		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.18069235926129082 | validation: 0.14247588317601925]
	TIME [epoch: 8.39 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17841042661347525		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.17841042661347525 | validation: 0.13850608408156687]
	TIME [epoch: 8.39 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17434930056047826		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.17434930056047826 | validation: 0.17128848774151917]
	TIME [epoch: 8.39 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1767465381477898		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.1767465381477898 | validation: 0.19680066537673943]
	TIME [epoch: 8.42 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508592940413857		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.2508592940413857 | validation: 0.20553310043558043]
	TIME [epoch: 8.39 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727347588536115		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.2727347588536115 | validation: 0.14876184839531031]
	TIME [epoch: 8.38 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19447779725878542		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.19447779725878542 | validation: 0.18201524412713632]
	TIME [epoch: 8.38 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18964026133767803		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.18964026133767803 | validation: 0.20140333218636533]
	TIME [epoch: 8.41 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17781869238993114		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.17781869238993114 | validation: 0.1653853993454999]
	TIME [epoch: 8.39 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18491283525241536		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.18491283525241536 | validation: 0.1938263900063733]
	TIME [epoch: 8.39 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17899597884004217		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.17899597884004217 | validation: 0.15598389202051238]
	TIME [epoch: 8.39 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2007942409264512		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.2007942409264512 | validation: 0.14482478018017697]
	TIME [epoch: 8.41 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1697881495437387		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.1697881495437387 | validation: 0.45157121497543856]
	TIME [epoch: 8.39 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21880872857351638		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.21880872857351638 | validation: 0.1899439933006437]
	TIME [epoch: 8.38 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23880211153355585		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.23880211153355585 | validation: 0.23702862508248418]
	TIME [epoch: 8.38 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15818047808133823		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.15818047808133823 | validation: 0.13904780586544221]
	TIME [epoch: 8.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1662078268653598		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.1662078268653598 | validation: 0.5078505449423578]
	TIME [epoch: 8.38 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20873924731399426		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.20873924731399426 | validation: 0.24411960352984455]
	TIME [epoch: 8.38 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2055067111509603		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.2055067111509603 | validation: 0.21267254432209692]
	TIME [epoch: 8.38 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17513055268562666		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.17513055268562666 | validation: 0.1615455202310424]
	TIME [epoch: 8.41 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2347198076829505		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.2347198076829505 | validation: 0.17521767552324238]
	TIME [epoch: 8.39 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17180965535254716		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.17180965535254716 | validation: 0.16283625264707968]
	TIME [epoch: 8.38 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15720986493400688		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.15720986493400688 | validation: 0.1465795196223039]
	TIME [epoch: 8.38 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882868824370892		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.1882868824370892 | validation: 0.3499630582742439]
	TIME [epoch: 8.41 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18600847934434978		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.18600847934434978 | validation: 0.2501608803463634]
	TIME [epoch: 8.39 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1754718574853098		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.1754718574853098 | validation: 0.16966888884875755]
	TIME [epoch: 8.38 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20203399817433326		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.20203399817433326 | validation: 0.21196477396420577]
	TIME [epoch: 8.38 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18286896539264508		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.18286896539264508 | validation: 0.24439184629513064]
	TIME [epoch: 8.41 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513981451832119		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.2513981451832119 | validation: 0.2094371011492001]
	TIME [epoch: 8.38 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16944413483578885		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.16944413483578885 | validation: 0.15511441973608725]
	TIME [epoch: 8.38 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17019959639847607		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.17019959639847607 | validation: 0.15712153520077185]
	TIME [epoch: 8.38 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21574037983293598		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.21574037983293598 | validation: 0.240349228138235]
	TIME [epoch: 8.41 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19185419770920092		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.19185419770920092 | validation: 0.2102797930073378]
	TIME [epoch: 8.39 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17004355219440528		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.17004355219440528 | validation: 0.16408906866158768]
	TIME [epoch: 8.38 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16145577477033035		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.16145577477033035 | validation: 0.21453166781040095]
	TIME [epoch: 8.38 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16857728475168657		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.16857728475168657 | validation: 0.16315826090763033]
	TIME [epoch: 8.41 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16098013372058273		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.16098013372058273 | validation: 0.33985677690803306]
	TIME [epoch: 8.39 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18527993660190858		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.18527993660190858 | validation: 0.25389006211434695]
	TIME [epoch: 8.38 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18831842775519675		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.18831842775519675 | validation: 0.15280314872991918]
	TIME [epoch: 8.39 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16277224503438864		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.16277224503438864 | validation: 0.141316981538957]
	TIME [epoch: 8.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18637201064362607		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.18637201064362607 | validation: 0.17997102793733857]
	TIME [epoch: 8.39 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17360774861859718		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.17360774861859718 | validation: 0.2012445312452107]
	TIME [epoch: 8.38 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20366329754279966		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.20366329754279966 | validation: 0.23680790247590555]
	TIME [epoch: 8.39 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17746817818350075		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.17746817818350075 | validation: 0.2195240685660467]
	TIME [epoch: 8.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2048360318979317		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.2048360318979317 | validation: 0.2779802281273317]
	TIME [epoch: 8.39 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29102684779233046		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.29102684779233046 | validation: 0.34300089106804676]
	TIME [epoch: 8.38 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2211550654140079		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.2211550654140079 | validation: 0.15650704355301803]
	TIME [epoch: 8.39 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16992316071030872		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.16992316071030872 | validation: 0.17223148948419992]
	TIME [epoch: 8.41 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20418812858088997		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.20418812858088997 | validation: 0.14544602652792354]
	TIME [epoch: 8.38 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19401197623260918		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.19401197623260918 | validation: 0.20928221431610347]
	TIME [epoch: 8.38 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1592582395046778		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.1592582395046778 | validation: 0.13000466837209093]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_794.pth
	Model improved!!!
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1484286090359295		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.1484286090359295 | validation: 0.21057284042740507]
	TIME [epoch: 8.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17333162038455457		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.17333162038455457 | validation: 0.27980013842163176]
	TIME [epoch: 8.39 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16840021027942276		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.16840021027942276 | validation: 0.14439311328787693]
	TIME [epoch: 8.38 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15657015039890032		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.15657015039890032 | validation: 0.23152555751418064]
	TIME [epoch: 8.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20630440113693896		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.20630440113693896 | validation: 0.14138297072214911]
	TIME [epoch: 8.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20036393239002742		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.20036393239002742 | validation: 0.18105136817566397]
	TIME [epoch: 8.39 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21282137649873462		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.21282137649873462 | validation: 0.1576233095702044]
	TIME [epoch: 8.39 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16991935771399763		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.16991935771399763 | validation: 0.2523113490809347]
	TIME [epoch: 8.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1902880708487625		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.1902880708487625 | validation: 0.7114234340307306]
	TIME [epoch: 8.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2549450745972218		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.2549450745972218 | validation: 0.1612309018044781]
	TIME [epoch: 8.38 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513270049368884		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.2513270049368884 | validation: 0.2019471012813364]
	TIME [epoch: 8.39 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18334482055207496		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.18334482055207496 | validation: 0.24246070589104204]
	TIME [epoch: 8.41 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21192390689974877		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.21192390689974877 | validation: 0.22778908540439982]
	TIME [epoch: 8.39 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1807584205597074		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.1807584205597074 | validation: 0.20514659184839273]
	TIME [epoch: 8.39 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23760560458858934		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.23760560458858934 | validation: 0.23226790585849855]
	TIME [epoch: 8.39 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1661974560014719		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.1661974560014719 | validation: 0.17466690818185093]
	TIME [epoch: 8.41 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19270103901338345		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.19270103901338345 | validation: 0.18953171847117567]
	TIME [epoch: 8.39 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19200632067704368		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.19200632067704368 | validation: 0.21672481879880584]
	TIME [epoch: 8.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22073742218170672		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.22073742218170672 | validation: 0.24912488182262627]
	TIME [epoch: 8.39 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27220249416681147		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.27220249416681147 | validation: 0.20288636299529955]
	TIME [epoch: 8.41 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18515172531487623		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.18515172531487623 | validation: 0.1907260547887164]
	TIME [epoch: 8.39 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16179689111880474		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.16179689111880474 | validation: 0.2091071734787997]
	TIME [epoch: 8.39 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1750913502926146		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.1750913502926146 | validation: 0.18704950884867566]
	TIME [epoch: 8.38 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16435817489166643		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.16435817489166643 | validation: 0.17437394161941794]
	TIME [epoch: 8.41 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16906580531373908		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.16906580531373908 | validation: 0.21286706649617504]
	TIME [epoch: 8.39 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1592319211555578		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.1592319211555578 | validation: 0.17177728206923093]
	TIME [epoch: 8.39 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14964770264237495		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.14964770264237495 | validation: 0.1599887359377059]
	TIME [epoch: 8.38 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17152397499320082		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.17152397499320082 | validation: 0.17918221185306665]
	TIME [epoch: 8.41 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1985444915910223		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.1985444915910223 | validation: 0.1969568051865861]
	TIME [epoch: 8.39 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22131958939200969		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.22131958939200969 | validation: 0.24053813214767117]
	TIME [epoch: 8.38 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16869763740390936		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.16869763740390936 | validation: 0.1447126729442283]
	TIME [epoch: 8.39 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15954893374126916		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.15954893374126916 | validation: 0.30736201935164675]
	TIME [epoch: 8.41 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18076994390935772		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.18076994390935772 | validation: 0.18342468427886405]
	TIME [epoch: 8.39 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17631415063574657		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.17631415063574657 | validation: 0.15505063894661975]
	TIME [epoch: 8.38 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1722820381602854		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.1722820381602854 | validation: 0.20530762706334582]
	TIME [epoch: 8.38 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17755714209417167		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.17755714209417167 | validation: 0.14227042490274544]
	TIME [epoch: 8.41 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19677813341318717		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.19677813341318717 | validation: 0.1984334755051887]
	TIME [epoch: 8.39 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16474109391986488		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.16474109391986488 | validation: 0.1669292866122603]
	TIME [epoch: 8.39 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1904228901491969		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.1904228901491969 | validation: 0.30650142678323955]
	TIME [epoch: 8.38 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19058883844359192		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.19058883844359192 | validation: 0.1533300632921245]
	TIME [epoch: 8.41 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13510084182784277		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.13510084182784277 | validation: 0.1212147702225234]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_835.pth
	Model improved!!!
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18598146636061202		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.18598146636061202 | validation: 0.17283250831958896]
	TIME [epoch: 8.38 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2109525084414785		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.2109525084414785 | validation: 0.18574331178433134]
	TIME [epoch: 8.38 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1791035012815618		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.1791035012815618 | validation: 0.22932466669095386]
	TIME [epoch: 8.41 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1808044980047627		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.1808044980047627 | validation: 0.1553763203611671]
	TIME [epoch: 8.38 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17290123268421093		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.17290123268421093 | validation: 0.1695670810593652]
	TIME [epoch: 8.38 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18939013973583274		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.18939013973583274 | validation: 0.1724304302127783]
	TIME [epoch: 8.38 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1788531528633313		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.1788531528633313 | validation: 0.1529258428745341]
	TIME [epoch: 8.41 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2739195426679972		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.2739195426679972 | validation: 0.1656455337167409]
	TIME [epoch: 8.38 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15921635504406037		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.15921635504406037 | validation: 0.16106687612121656]
	TIME [epoch: 8.38 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20768026038452642		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.20768026038452642 | validation: 0.3758550973122121]
	TIME [epoch: 8.38 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1724757003605418		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.1724757003605418 | validation: 0.22318718536172538]
	TIME [epoch: 8.41 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18944268728188238		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.18944268728188238 | validation: 0.19169729314057493]
	TIME [epoch: 8.39 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16855111102310646		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.16855111102310646 | validation: 0.18678967504618033]
	TIME [epoch: 8.38 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15733003148622135		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.15733003148622135 | validation: 0.18590700901050167]
	TIME [epoch: 8.39 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14402379114159142		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.14402379114159142 | validation: 0.20354948221172645]
	TIME [epoch: 8.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2175409216301381		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.2175409216301381 | validation: 0.1827444742793327]
	TIME [epoch: 8.38 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1648805613783416		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.1648805613783416 | validation: 0.16943637542275247]
	TIME [epoch: 8.39 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17230124886032755		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.17230124886032755 | validation: 0.1949563049946249]
	TIME [epoch: 8.39 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2165214672528454		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.2165214672528454 | validation: 0.15575324499930582]
	TIME [epoch: 8.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2184794039122686		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.2184794039122686 | validation: 0.16744159537772596]
	TIME [epoch: 8.38 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15529989758901247		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.15529989758901247 | validation: 0.15049933097550228]
	TIME [epoch: 8.38 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18802208645366117		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.18802208645366117 | validation: 0.17361628214284042]
	TIME [epoch: 8.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15658457226683895		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.15658457226683895 | validation: 0.16282440853740393]
	TIME [epoch: 8.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21691466998825254		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.21691466998825254 | validation: 0.18636531309428678]
	TIME [epoch: 8.38 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1810368880428002		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.1810368880428002 | validation: 0.15331577976893115]
	TIME [epoch: 8.38 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16091974762742192		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.16091974762742192 | validation: 0.25534367219637405]
	TIME [epoch: 8.39 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18001849268838196		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.18001849268838196 | validation: 0.17730009453218354]
	TIME [epoch: 8.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15128664984741488		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.15128664984741488 | validation: 0.3237771591253177]
	TIME [epoch: 8.38 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20325217973819004		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.20325217973819004 | validation: 0.1485155451790937]
	TIME [epoch: 8.38 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22220716536423782		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.22220716536423782 | validation: 0.13312044825307845]
	TIME [epoch: 8.41 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22232651318015711		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.22232651318015711 | validation: 0.16813382181494502]
	TIME [epoch: 8.39 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17937481994421695		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.17937481994421695 | validation: 0.16002683700512874]
	TIME [epoch: 8.38 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19251542695761015		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.19251542695761015 | validation: 0.13372984078796624]
	TIME [epoch: 8.38 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1628036408833983		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.1628036408833983 | validation: 0.2204003305311657]
	TIME [epoch: 8.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17296009113258382		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.17296009113258382 | validation: 0.16182723613377487]
	TIME [epoch: 8.39 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1924988413763569		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.1924988413763569 | validation: 0.17525220915960416]
	TIME [epoch: 8.38 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1566068929921932		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.1566068929921932 | validation: 0.13774662740228685]
	TIME [epoch: 8.38 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16957277748435437		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.16957277748435437 | validation: 0.14487214260663453]
	TIME [epoch: 8.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15755054043620748		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.15755054043620748 | validation: 0.1311301949103713]
	TIME [epoch: 8.39 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19819105815108		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.19819105815108 | validation: 0.20941874386027715]
	TIME [epoch: 8.38 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16206874148761602		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.16206874148761602 | validation: 0.1732363536504531]
	TIME [epoch: 8.38 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20975865126037538		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.20975865126037538 | validation: 0.18790364914055518]
	TIME [epoch: 8.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18949597679847316		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.18949597679847316 | validation: 0.19584477998722977]
	TIME [epoch: 8.39 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24482008278897763		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.24482008278897763 | validation: 0.31806511050483777]
	TIME [epoch: 8.38 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1799802131210878		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.1799802131210878 | validation: 0.33041521419650965]
	TIME [epoch: 8.38 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19331090405330145		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.19331090405330145 | validation: 0.24788264141888194]
	TIME [epoch: 8.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2118783706354725		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.2118783706354725 | validation: 0.2290282189164912]
	TIME [epoch: 8.38 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18578425141132254		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.18578425141132254 | validation: 0.18565221713498448]
	TIME [epoch: 8.38 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20249894082251668		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.20249894082251668 | validation: 0.14558306759282222]
	TIME [epoch: 8.38 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1865975386748143		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.1865975386748143 | validation: 0.14161480541658883]
	TIME [epoch: 8.41 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18924738477957664		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.18924738477957664 | validation: 0.1689102913885986]
	TIME [epoch: 8.38 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2334496806517418		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.2334496806517418 | validation: 0.17045003251363444]
	TIME [epoch: 8.38 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750755759798374		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.18750755759798374 | validation: 0.1421364283724148]
	TIME [epoch: 8.38 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1628765734496805		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.1628765734496805 | validation: 0.17229850860301765]
	TIME [epoch: 8.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1605894178636213		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.1605894178636213 | validation: 0.16668206352459075]
	TIME [epoch: 8.38 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15104779049190437		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.15104779049190437 | validation: 0.1964591076032154]
	TIME [epoch: 8.39 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1722902350360235		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.1722902350360235 | validation: 0.16492213151401428]
	TIME [epoch: 8.38 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1938604004321311		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.1938604004321311 | validation: 0.17635606986684546]
	TIME [epoch: 8.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16160953670377748		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.16160953670377748 | validation: 0.15628144648590883]
	TIME [epoch: 8.38 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14884371767538843		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.14884371767538843 | validation: 0.21251691239336334]
	TIME [epoch: 8.38 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17257741750901717		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.17257741750901717 | validation: 0.25015657847652595]
	TIME [epoch: 8.38 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17011334983146492		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.17011334983146492 | validation: 0.19966950151090646]
	TIME [epoch: 8.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2207053642821907		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.2207053642821907 | validation: 0.1892443009434573]
	TIME [epoch: 8.38 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15680978883693125		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.15680978883693125 | validation: 0.20866404662779406]
	TIME [epoch: 8.38 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1564096677990487		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.1564096677990487 | validation: 0.1630852465403851]
	TIME [epoch: 8.38 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1781189299143581		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.1781189299143581 | validation: 0.15589083033132864]
	TIME [epoch: 8.41 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2258031908820159		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.2258031908820159 | validation: 0.13317654822409677]
	TIME [epoch: 8.38 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1675281800388047		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.1675281800388047 | validation: 0.20929207665213556]
	TIME [epoch: 8.38 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1877772208259952		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.1877772208259952 | validation: 0.16156671485414528]
	TIME [epoch: 8.38 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17168682753016662		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.17168682753016662 | validation: 0.2555776303866879]
	TIME [epoch: 8.41 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15474251505790199		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.15474251505790199 | validation: 0.1703588382540871]
	TIME [epoch: 8.38 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16351238371686666		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.16351238371686666 | validation: 0.22559518764327663]
	TIME [epoch: 8.39 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19534535519648083		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.19534535519648083 | validation: 0.27396550464976455]
	TIME [epoch: 8.38 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19268267220250487		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.19268267220250487 | validation: 0.1795510519380809]
	TIME [epoch: 8.41 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15533733103894526		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.15533733103894526 | validation: 0.17056706266901744]
	TIME [epoch: 8.38 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627893333559019		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.1627893333559019 | validation: 0.1932944718092514]
	TIME [epoch: 8.38 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19242498970943805		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.19242498970943805 | validation: 0.15401400291327777]
	TIME [epoch: 8.38 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1828437161227709		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.1828437161227709 | validation: 0.19217994075149356]
	TIME [epoch: 8.41 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1972905181716917		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.1972905181716917 | validation: 0.1521198609004872]
	TIME [epoch: 8.38 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16480384727576655		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.16480384727576655 | validation: 0.15172132494799695]
	TIME [epoch: 8.38 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16483374939318393		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.16483374939318393 | validation: 0.17249441574539326]
	TIME [epoch: 8.38 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18399990624751345		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.18399990624751345 | validation: 0.18263739808221358]
	TIME [epoch: 8.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1639951954430438		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.1639951954430438 | validation: 0.2862469308637447]
	TIME [epoch: 8.38 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855853643724213		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.1855853643724213 | validation: 0.1446537244622288]
	TIME [epoch: 8.38 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1639919925066175		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.1639919925066175 | validation: 0.15305275451863837]
	TIME [epoch: 8.38 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15787553578395783		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.15787553578395783 | validation: 0.26489785691286677]
	TIME [epoch: 8.41 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651154556308953		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.1651154556308953 | validation: 0.17970892030936547]
	TIME [epoch: 8.38 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16237557281703477		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.16237557281703477 | validation: 0.17739713841347765]
	TIME [epoch: 8.38 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1638273658658196		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.1638273658658196 | validation: 0.1515310146853498]
	TIME [epoch: 8.38 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24484949247625915		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.24484949247625915 | validation: 0.21465575514695923]
	TIME [epoch: 8.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1707626480587326		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.1707626480587326 | validation: 0.17438431881850924]
	TIME [epoch: 8.38 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1670028440295837		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.1670028440295837 | validation: 0.16628871910827464]
	TIME [epoch: 8.38 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1514403918851559		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.1514403918851559 | validation: 0.16406162639278443]
	TIME [epoch: 8.39 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17034541018685495		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.17034541018685495 | validation: 0.16674915737038717]
	TIME [epoch: 8.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1833172026764384		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.1833172026764384 | validation: 0.2099892859802557]
	TIME [epoch: 8.38 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16038095576808734		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.16038095576808734 | validation: 0.17373697788642634]
	TIME [epoch: 8.38 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179439468906578		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.179439468906578 | validation: 0.2296888940752109]
	TIME [epoch: 8.39 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16795737146781814		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.16795737146781814 | validation: 0.2489151534734595]
	TIME [epoch: 8.39 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21266837534146976		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.21266837534146976 | validation: 0.2093334653806894]
	TIME [epoch: 8.38 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15119210783214196		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.15119210783214196 | validation: 0.1394764039574512]
	TIME [epoch: 8.38 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1560831489290995		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.1560831489290995 | validation: 0.1580119538608269]
	TIME [epoch: 8.39 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16710141498597902		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.16710141498597902 | validation: 0.1855152040716759]
	TIME [epoch: 8.39 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16208012425516988		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.16208012425516988 | validation: 0.20403260433809617]
	TIME [epoch: 8.38 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15507151717197162		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.15507151717197162 | validation: 0.1411192611550531]
	TIME [epoch: 8.37 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607146529953263		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.1607146529953263 | validation: 0.14890826115734687]
	TIME [epoch: 8.39 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17903314525614658		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.17903314525614658 | validation: 0.23461310843761038]
	TIME [epoch: 8.39 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922370337913145		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.1922370337913145 | validation: 0.17976652320455902]
	TIME [epoch: 8.38 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22862575418514455		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.22862575418514455 | validation: 0.3984744585570904]
	TIME [epoch: 8.38 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25401837780100195		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.25401837780100195 | validation: 0.22784013029546601]
	TIME [epoch: 8.39 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2042380929467321		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.2042380929467321 | validation: 0.17846307021227442]
	TIME [epoch: 8.39 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1668896797047071		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.1668896797047071 | validation: 0.21861175773115238]
	TIME [epoch: 8.38 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16849326234044865		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.16849326234044865 | validation: 0.14841567163433783]
	TIME [epoch: 8.38 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17076539730163623		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.17076539730163623 | validation: 0.1530190404255795]
	TIME [epoch: 8.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1495771537017033		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.1495771537017033 | validation: 0.28544752833546616]
	TIME [epoch: 8.38 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1621260872685824		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.1621260872685824 | validation: 0.16493496206724442]
	TIME [epoch: 8.38 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15327602967141768		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.15327602967141768 | validation: 0.18677156845006274]
	TIME [epoch: 8.38 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15282750472049342		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.15282750472049342 | validation: 0.18460870775991509]
	TIME [epoch: 8.4 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14510750523572497		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.14510750523572497 | validation: 0.17420817801920752]
	TIME [epoch: 8.38 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15304404460978033		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.15304404460978033 | validation: 0.14335643940584655]
	TIME [epoch: 8.37 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16948060869209233		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.16948060869209233 | validation: 0.18686229402870663]
	TIME [epoch: 8.38 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14670044816556171		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.14670044816556171 | validation: 0.14220899336101667]
	TIME [epoch: 8.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1537500158103601		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.1537500158103601 | validation: 0.13243227521022388]
	TIME [epoch: 8.38 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16683075681546117		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.16683075681546117 | validation: 0.14443328212904177]
	TIME [epoch: 8.38 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13246856637435173		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.13246856637435173 | validation: 0.12461754852996626]
	TIME [epoch: 8.37 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16858882369782704		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.16858882369782704 | validation: 0.19273787950632543]
	TIME [epoch: 8.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1518422066300473		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.1518422066300473 | validation: 0.15395479126532496]
	TIME [epoch: 8.38 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28980043359094226		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.28980043359094226 | validation: 0.1355043113267934]
	TIME [epoch: 8.38 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17865306029784794		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.17865306029784794 | validation: 0.19639469705280818]
	TIME [epoch: 8.37 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17367343392760456		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.17367343392760456 | validation: 0.2235858245090866]
	TIME [epoch: 8.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21699254148400512		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.21699254148400512 | validation: 0.16583471144782153]
	TIME [epoch: 8.38 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16424436362488967		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.16424436362488967 | validation: 0.16490153162927076]
	TIME [epoch: 8.38 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16940251702513476		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.16940251702513476 | validation: 0.20325658524364465]
	TIME [epoch: 8.37 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607167080633738		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.1607167080633738 | validation: 0.14310179694230232]
	TIME [epoch: 8.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15385002230962447		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.15385002230962447 | validation: 0.18560158364525217]
	TIME [epoch: 8.38 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17281083426903024		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.17281083426903024 | validation: 0.1473764802204987]
	TIME [epoch: 8.37 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17644579738733948		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.17644579738733948 | validation: 0.13753584916209155]
	TIME [epoch: 8.38 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14963985825793807		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.14963985825793807 | validation: 0.13034356915797754]
	TIME [epoch: 8.39 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1442132630285825		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.1442132630285825 | validation: 0.14384479120125984]
	TIME [epoch: 8.38 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1526210427274569		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.1526210427274569 | validation: 0.12521609314483398]
	TIME [epoch: 8.38 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18719458521145843		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.18719458521145843 | validation: 0.20111696737658585]
	TIME [epoch: 8.38 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1528956913712498		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.1528956913712498 | validation: 0.17177417704337178]
	TIME [epoch: 8.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15699410582021506		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.15699410582021506 | validation: 0.18616639786517208]
	TIME [epoch: 8.38 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14110220620459057		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.14110220620459057 | validation: 0.1385619579866888]
	TIME [epoch: 8.38 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1603772978608758		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.1603772978608758 | validation: 0.17736140317696336]
	TIME [epoch: 8.38 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16236161897402676		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.16236161897402676 | validation: 0.126020986085307]
	TIME [epoch: 8.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14208451911699266		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.14208451911699266 | validation: 0.16992845461041955]
	TIME [epoch: 8.37 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1558378788621751		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.1558378788621751 | validation: 0.1507483984822716]
	TIME [epoch: 8.37 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16134053804077192		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.16134053804077192 | validation: 0.16411155048144938]
	TIME [epoch: 8.37 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13298346232468455		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.13298346232468455 | validation: 0.14771873626487295]
	TIME [epoch: 8.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14774003697510957		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.14774003697510957 | validation: 0.14193326527337288]
	TIME [epoch: 8.38 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14612951521040052		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.14612951521040052 | validation: 0.1684220142730965]
	TIME [epoch: 8.37 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.167917962226914		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.167917962226914 | validation: 0.14436879043106415]
	TIME [epoch: 8.38 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12580630043247215		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.12580630043247215 | validation: 0.1903286468001978]
	TIME [epoch: 8.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2235029785411482		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.2235029785411482 | validation: 0.26003982311897833]
	TIME [epoch: 8.38 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15643256199476913		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.15643256199476913 | validation: 0.1411748625588374]
	TIME [epoch: 8.38 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1923582495784713		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.1923582495784713 | validation: 0.141620337611788]
	TIME [epoch: 8.38 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16387629079380603		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.16387629079380603 | validation: 0.1732146128926501]
	TIME [epoch: 8.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16156656157982122		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.16156656157982122 | validation: 0.17036411038804344]
	TIME [epoch: 8.38 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20783472296442418		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.20783472296442418 | validation: 0.2080798655412453]
	TIME [epoch: 8.38 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1604626999603774		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.1604626999603774 | validation: 0.14289706877840713]
	TIME [epoch: 8.37 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15611603980144212		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.15611603980144212 | validation: 0.2411073183152407]
	TIME [epoch: 8.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16461707335976075		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.16461707335976075 | validation: 0.15162479515334593]
	TIME [epoch: 8.37 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12958412450994863		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.12958412450994863 | validation: 0.15236430979989773]
	TIME [epoch: 8.37 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1708056434072809		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.1708056434072809 | validation: 0.272545240919922]
	TIME [epoch: 8.38 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19500295391485475		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.19500295391485475 | validation: 0.16308907958594576]
	TIME [epoch: 8.39 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17838870449585884		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.17838870449585884 | validation: 0.16933994251514795]
	TIME [epoch: 8.38 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1645999525566638		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.1645999525566638 | validation: 0.16687742710714654]
	TIME [epoch: 8.37 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1690090976339845		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.1690090976339845 | validation: 0.25382261888081986]
	TIME [epoch: 8.38 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16054801270788477		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.16054801270788477 | validation: 0.171849983046584]
	TIME [epoch: 8.39 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16199516609641346		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.16199516609641346 | validation: 0.20694878619283863]
	TIME [epoch: 8.37 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13955589803777307		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.13955589803777307 | validation: 0.20207864997945635]
	TIME [epoch: 8.37 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18599033781806834		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.18599033781806834 | validation: 0.14130627627681916]
	TIME [epoch: 8.39 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1618402302755774		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.1618402302755774 | validation: 0.21530173567731242]
	TIME [epoch: 8.39 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1423077414779116		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.1423077414779116 | validation: 0.18814098416860786]
	TIME [epoch: 8.37 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1496054961108571		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.1496054961108571 | validation: 0.15550103250786046]
	TIME [epoch: 8.37 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467268955863243		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.1467268955863243 | validation: 0.12497717564088512]
	TIME [epoch: 8.38 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1853248358720899		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.1853248358720899 | validation: 0.16936826277946565]
	TIME [epoch: 8.39 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14341891955500102		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.14341891955500102 | validation: 0.12926520111400758]
	TIME [epoch: 8.37 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13915314227060863		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.13915314227060863 | validation: 0.15980228524096357]
	TIME [epoch: 8.37 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16344861620687673		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.16344861620687673 | validation: 0.15786938741324935]
	TIME [epoch: 8.39 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16331024216465118		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.16331024216465118 | validation: 0.1669001770809065]
	TIME [epoch: 8.39 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1602718256708276		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.1602718256708276 | validation: 0.17812272030909204]
	TIME [epoch: 8.37 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14814897933632826		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.14814897933632826 | validation: 0.2079880693923742]
	TIME [epoch: 8.36 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14792999908958643		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.14792999908958643 | validation: 0.19238854871911926]
	TIME [epoch: 8.39 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14908896369037827		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.14908896369037827 | validation: 0.24580745822515027]
	TIME [epoch: 8.38 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16748697880953214		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.16748697880953214 | validation: 0.16309055373454676]
	TIME [epoch: 8.37 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17585992055718722		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.17585992055718722 | validation: 0.13768166421420108]
	TIME [epoch: 8.37 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14764757891027963		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.14764757891027963 | validation: 0.21675875993794924]
	TIME [epoch: 8.38 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1591171968096455		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.1591171968096455 | validation: 0.19017226047495453]
	TIME [epoch: 8.38 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16031364937440273		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.16031364937440273 | validation: 0.19061823762206415]
	TIME [epoch: 8.37 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15312030864784976		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.15312030864784976 | validation: 0.16519668311039307]
	TIME [epoch: 8.37 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972264284814252		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.14972264284814252 | validation: 0.16619153071978257]
	TIME [epoch: 8.39 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1557542481095544		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.1557542481095544 | validation: 0.14912655958104992]
	TIME [epoch: 8.37 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15751837525485654		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.15751837525485654 | validation: 0.1513530312520764]
	TIME [epoch: 8.37 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1580713962852834		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.1580713962852834 | validation: 0.23610519783741274]
	TIME [epoch: 8.37 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13862035837846637		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.13862035837846637 | validation: 0.13375555763466873]
	TIME [epoch: 8.39 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15008917098244598		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.15008917098244598 | validation: 0.14167730307089033]
	TIME [epoch: 8.37 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14064149134110507		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.14064149134110507 | validation: 0.17052369571509146]
	TIME [epoch: 8.37 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15828109256836814		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.15828109256836814 | validation: 0.1679204843997228]
	TIME [epoch: 8.37 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16960062296579542		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.16960062296579542 | validation: 0.13676783956725355]
	TIME [epoch: 8.39 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1450091119560246		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.1450091119560246 | validation: 0.13754906171413897]
	TIME [epoch: 8.37 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13998713200179164		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.13998713200179164 | validation: 0.16870731844643522]
	TIME [epoch: 8.37 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14285287481388018		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.14285287481388018 | validation: 0.24934585482148308]
	TIME [epoch: 8.37 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14316837004765576		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.14316837004765576 | validation: 0.13368549677733635]
	TIME [epoch: 8.39 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15960342499181196		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.15960342499181196 | validation: 0.14135938830522732]
	TIME [epoch: 8.37 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16174742321310287		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.16174742321310287 | validation: 0.14679581206300923]
	TIME [epoch: 8.37 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14782944324949165		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.14782944324949165 | validation: 0.11773289098472298]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16132840566018403		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.16132840566018403 | validation: 0.17568963445128666]
	TIME [epoch: 8.39 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14163668966176385		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.14163668966176385 | validation: 0.21742557272586177]
	TIME [epoch: 8.37 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13840536779297885		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.13840536779297885 | validation: 0.13235867404128415]
	TIME [epoch: 8.37 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229218934666482		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.14229218934666482 | validation: 0.1418161889731933]
	TIME [epoch: 8.37 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15189335646238228		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.15189335646238228 | validation: 0.12866827890999463]
	TIME [epoch: 8.39 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15528070610255715		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.15528070610255715 | validation: 0.1762189706565387]
	TIME [epoch: 8.37 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16931194796142357		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.16931194796142357 | validation: 0.1815479266536167]
	TIME [epoch: 8.36 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1553693521144566		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.1553693521144566 | validation: 0.17476154756738704]
	TIME [epoch: 8.37 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16796924027857404		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.16796924027857404 | validation: 0.13319865774738365]
	TIME [epoch: 8.39 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13558574771816642		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.13558574771816642 | validation: 0.13752971189066535]
	TIME [epoch: 8.37 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16637246484573656		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.16637246484573656 | validation: 0.1363718519413804]
	TIME [epoch: 8.38 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16816120339995552		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.16816120339995552 | validation: 0.15003290058683072]
	TIME [epoch: 8.38 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13151970483198316		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.13151970483198316 | validation: 0.14470271493185588]
	TIME [epoch: 8.41 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14139517823349684		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.14139517823349684 | validation: 0.11831245606746185]
	TIME [epoch: 8.38 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14002213654881007		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.14002213654881007 | validation: 0.12803809219279014]
	TIME [epoch: 8.38 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19648643658857734		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.19648643658857734 | validation: 0.19245144131266034]
	TIME [epoch: 8.38 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16656469209749108		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.16656469209749108 | validation: 0.17118728121423218]
	TIME [epoch: 8.39 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18288731227773355		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.18288731227773355 | validation: 0.19113864815956172]
	TIME [epoch: 8.37 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.197271483062394		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.197271483062394 | validation: 0.132138920140904]
	TIME [epoch: 8.37 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17151964613320225		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.17151964613320225 | validation: 0.21634837305679053]
	TIME [epoch: 8.37 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14387543176014878		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.14387543176014878 | validation: 0.14795717411813109]
	TIME [epoch: 8.39 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1617468514716975		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.1617468514716975 | validation: 0.14288765411982635]
	TIME [epoch: 8.38 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14048321295569094		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.14048321295569094 | validation: 0.15312661213444279]
	TIME [epoch: 8.38 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14073557998273853		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.14073557998273853 | validation: 0.17267960036572777]
	TIME [epoch: 8.37 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14731998995723863		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.14731998995723863 | validation: 0.17785965700346112]
	TIME [epoch: 8.39 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15329877223014501		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.15329877223014501 | validation: 0.14129934523019533]
	TIME [epoch: 8.38 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13381685581075609		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.13381685581075609 | validation: 0.1543235651230299]
	TIME [epoch: 8.38 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14796424715392617		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.14796424715392617 | validation: 0.14535652687782943]
	TIME [epoch: 8.38 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14463895337841967		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.14463895337841967 | validation: 0.1301767574740286]
	TIME [epoch: 8.4 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1545823568413473		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.1545823568413473 | validation: 0.14445028276830413]
	TIME [epoch: 8.38 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15681850627239852		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.15681850627239852 | validation: 0.1296284652866132]
	TIME [epoch: 8.38 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1436699229711304		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.1436699229711304 | validation: 0.17272564576820879]
	TIME [epoch: 8.38 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13053998929553748		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.13053998929553748 | validation: 0.14989226320881183]
	TIME [epoch: 8.39 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1549033011006181		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.1549033011006181 | validation: 0.14526065181498998]
	TIME [epoch: 8.37 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1363838444065199		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.1363838444065199 | validation: 0.14585915082223527]
	TIME [epoch: 8.38 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.184227782311114		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.184227782311114 | validation: 0.20739040130981012]
	TIME [epoch: 8.38 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1573533739680423		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.1573533739680423 | validation: 0.1435318058436921]
	TIME [epoch: 8.4 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1548654169233622		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.1548654169233622 | validation: 0.13741243025726402]
	TIME [epoch: 8.37 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338950249600332		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.1338950249600332 | validation: 0.19730759268365394]
	TIME [epoch: 8.37 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14511917893569795		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.14511917893569795 | validation: 0.12976700637511182]
	TIME [epoch: 8.38 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16476219468672554		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.16476219468672554 | validation: 0.14333832278920144]
	TIME [epoch: 8.38 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15378756632837676		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.15378756632837676 | validation: 0.14668967728229854]
	TIME [epoch: 8.37 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1612519642757923		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.1612519642757923 | validation: 0.27363510432943117]
	TIME [epoch: 8.37 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15644094222749724		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.15644094222749724 | validation: 0.13707770660834384]
	TIME [epoch: 8.39 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13634159703087462		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.13634159703087462 | validation: 0.1707481949750581]
	TIME [epoch: 8.39 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13489440963017965		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.13489440963017965 | validation: 0.19903917726808007]
	TIME [epoch: 8.38 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16166070721435713		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.16166070721435713 | validation: 0.12831643431657633]
	TIME [epoch: 8.36 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13819177828027146		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.13819177828027146 | validation: 0.19588260294273468]
	TIME [epoch: 8.39 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.148650837389067		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.148650837389067 | validation: 0.12795743874573368]
	TIME [epoch: 8.38 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14791260683156535		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.14791260683156535 | validation: 0.16300793124495336]
	TIME [epoch: 8.37 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14223205131738995		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.14223205131738995 | validation: 0.17239081476811968]
	TIME [epoch: 8.36 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14291302569025915		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.14291302569025915 | validation: 0.18970789389198303]
	TIME [epoch: 8.39 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13175893770955274		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.13175893770955274 | validation: 0.13374486250017942]
	TIME [epoch: 8.38 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1329344455834276		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.1329344455834276 | validation: 0.13597770544004786]
	TIME [epoch: 8.36 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12223577757740503		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.12223577757740503 | validation: 0.16848282405058104]
	TIME [epoch: 8.38 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14233317679244115		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.14233317679244115 | validation: 0.12389140466210885]
	TIME [epoch: 8.4 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13607446001444973		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.13607446001444973 | validation: 0.13587272568094833]
	TIME [epoch: 8.38 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15098504964876777		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.15098504964876777 | validation: 0.131842997320717]
	TIME [epoch: 8.37 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13107156337033957		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.13107156337033957 | validation: 0.21874134718240082]
	TIME [epoch: 8.37 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1499583588482269		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.1499583588482269 | validation: 0.1362610048422314]
	TIME [epoch: 8.37 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16429838727826485		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.16429838727826485 | validation: 0.13522457892851064]
	TIME [epoch: 8.38 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14423100323888016		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.14423100323888016 | validation: 0.1372793203819293]
	TIME [epoch: 8.36 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1480742408142356		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.1480742408142356 | validation: 0.19327106053377668]
	TIME [epoch: 8.38 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16234201925873903		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.16234201925873903 | validation: 0.14668432115058216]
	TIME [epoch: 8.4 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14932568535774102		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.14932568535774102 | validation: 0.15650794084609343]
	TIME [epoch: 8.37 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13653685930312426		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.13653685930312426 | validation: 0.2184302290710184]
	TIME [epoch: 8.37 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13874357519731567		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.13874357519731567 | validation: 0.15241140357558164]
	TIME [epoch: 8.37 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14449497316923093		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.14449497316923093 | validation: 0.1623366406832394]
	TIME [epoch: 8.39 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1375780077417504		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.1375780077417504 | validation: 0.18803976440167364]
	TIME [epoch: 8.37 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18022228697369053		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.18022228697369053 | validation: 0.2833154599255733]
	TIME [epoch: 8.37 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17387856334357177		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.17387856334357177 | validation: 0.14289689779058423]
	TIME [epoch: 8.37 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13434752366952485		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.13434752366952485 | validation: 0.17287187935017112]
	TIME [epoch: 8.39 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13078610293082124		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.13078610293082124 | validation: 0.13433732008630742]
	TIME [epoch: 8.37 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13888662740605123		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.13888662740605123 | validation: 0.11906413982145303]
	TIME [epoch: 8.36 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1761762921445814		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.1761762921445814 | validation: 0.1373778280912868]
	TIME [epoch: 8.37 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15132097016063178		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.15132097016063178 | validation: 0.14292452724598895]
	TIME [epoch: 8.39 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15875053856949878		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.15875053856949878 | validation: 0.12894819054629672]
	TIME [epoch: 8.37 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12421060888846396		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.12421060888846396 | validation: 0.15836693907139882]
	TIME [epoch: 8.36 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14109786004150782		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.14109786004150782 | validation: 0.14054936231721715]
	TIME [epoch: 8.38 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257654278135662		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.1257654278135662 | validation: 0.1516588197209671]
	TIME [epoch: 8.39 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14426510462746608		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.14426510462746608 | validation: 0.1186971945386607]
	TIME [epoch: 8.38 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1286446210260695		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.1286446210260695 | validation: 0.14259283446054172]
	TIME [epoch: 8.37 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1315177275981824		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.1315177275981824 | validation: 0.18151500790848857]
	TIME [epoch: 8.38 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15194882212854174		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.15194882212854174 | validation: 0.14415677535479846]
	TIME [epoch: 8.4 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1428902066602591		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.1428902066602591 | validation: 0.19421533502446292]
	TIME [epoch: 8.37 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14516296565035197		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.14516296565035197 | validation: 0.1681255178450876]
	TIME [epoch: 8.37 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16206912939128876		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.16206912939128876 | validation: 0.12713758867985092]
	TIME [epoch: 8.37 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13659746420703428		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.13659746420703428 | validation: 0.22604175823581896]
	TIME [epoch: 8.39 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15187428107256196		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.15187428107256196 | validation: 0.11118497253427748]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1131.pth
	Model improved!!!
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12454867197092509		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.12454867197092509 | validation: 0.14976130200720084]
	TIME [epoch: 8.37 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640790738388213		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.1640790738388213 | validation: 0.21569296861101359]
	TIME [epoch: 8.39 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15115114265310697		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.15115114265310697 | validation: 0.14272300005577238]
	TIME [epoch: 8.4 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13618455476004385		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.13618455476004385 | validation: 0.1551175223806462]
	TIME [epoch: 8.37 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15191429821899277		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.15191429821899277 | validation: 0.15832427341915456]
	TIME [epoch: 8.37 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15875569487629243		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.15875569487629243 | validation: 0.18663577889156507]
	TIME [epoch: 8.38 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14136816425607357		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.14136816425607357 | validation: 0.17675162735375183]
	TIME [epoch: 8.4 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1467140824447636		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.1467140824447636 | validation: 0.21433406849435793]
	TIME [epoch: 8.37 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12585564769320662		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.12585564769320662 | validation: 0.12718717540411614]
	TIME [epoch: 8.38 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16019601473973338		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.16019601473973338 | validation: 0.1828188361227854]
	TIME [epoch: 8.39 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14697166450308932		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.14697166450308932 | validation: 0.14172958051972323]
	TIME [epoch: 8.39 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14408320663925894		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.14408320663925894 | validation: 0.22769244620413165]
	TIME [epoch: 8.37 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15819055747670752		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.15819055747670752 | validation: 0.16880134192955087]
	TIME [epoch: 8.37 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16611465626730162		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.16611465626730162 | validation: 0.14223001875551503]
	TIME [epoch: 8.37 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562195312837179		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.1562195312837179 | validation: 0.16188994706354626]
	TIME [epoch: 8.39 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13347172898211385		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.13347172898211385 | validation: 0.12917686215588964]
	TIME [epoch: 8.38 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516099835647748		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.1516099835647748 | validation: 0.14039084081614994]
	TIME [epoch: 8.37 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13235058519627538		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.13235058519627538 | validation: 0.11901305129311182]
	TIME [epoch: 8.37 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12538531318406093		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.12538531318406093 | validation: 0.11556282869266968]
	TIME [epoch: 8.4 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13369779837745582		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.13369779837745582 | validation: 0.23691678847332437]
	TIME [epoch: 8.37 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15519778052882238		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.15519778052882238 | validation: 0.17706953505964115]
	TIME [epoch: 8.36 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1319091604407156		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.1319091604407156 | validation: 0.14095864021671636]
	TIME [epoch: 8.38 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1299325991903411		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.1299325991903411 | validation: 0.2421630060994437]
	TIME [epoch: 8.38 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1512290413621425		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.1512290413621425 | validation: 0.12345418504551006]
	TIME [epoch: 8.37 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13857950770446809		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.13857950770446809 | validation: 0.1786456845957286]
	TIME [epoch: 8.36 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14816609725939678		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.14816609725939678 | validation: 0.1358522029865053]
	TIME [epoch: 8.38 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1925558961462889		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.1925558961462889 | validation: 0.17028291528914213]
	TIME [epoch: 8.38 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17102397100150368		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.17102397100150368 | validation: 0.11667981088130505]
	TIME [epoch: 8.37 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12713528039401747		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.12713528039401747 | validation: 0.1374735278339654]
	TIME [epoch: 8.37 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11744601973051108		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.11744601973051108 | validation: 0.1342887491400866]
	TIME [epoch: 8.38 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14198850815013636		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.14198850815013636 | validation: 0.20749293868286806]
	TIME [epoch: 8.39 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1458799599532715		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.1458799599532715 | validation: 0.1838611870756473]
	TIME [epoch: 8.37 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14324988688980128		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.14324988688980128 | validation: 0.1490738762311302]
	TIME [epoch: 8.37 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13176934473102692		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.13176934473102692 | validation: 0.21817897566391942]
	TIME [epoch: 8.39 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14180672865424418		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.14180672865424418 | validation: 0.14622705378808998]
	TIME [epoch: 8.38 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12360440159145059		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.12360440159145059 | validation: 0.13877255266242747]
	TIME [epoch: 8.37 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1388254267291756		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.1388254267291756 | validation: 0.12124694165518872]
	TIME [epoch: 8.37 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12502850420993214		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.12502850420993214 | validation: 0.13058080100471403]
	TIME [epoch: 8.38 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1377753774376288		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.1377753774376288 | validation: 0.3764011902451855]
	TIME [epoch: 8.38 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18893970969200666		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.18893970969200666 | validation: 0.1263974060146013]
	TIME [epoch: 8.37 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12367470136648995		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.12367470136648995 | validation: 0.1984892605238835]
	TIME [epoch: 8.37 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14324285369076356		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.14324285369076356 | validation: 0.1122674334742223]
	TIME [epoch: 8.39 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12833575495332578		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.12833575495332578 | validation: 0.19554678840518902]
	TIME [epoch: 8.37 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14071710497527984		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.14071710497527984 | validation: 0.14900804255304181]
	TIME [epoch: 8.36 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13290307666769846		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.13290307666769846 | validation: 0.13533657912589397]
	TIME [epoch: 8.37 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1311394188855985		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.1311394188855985 | validation: 0.15382196603147594]
	TIME [epoch: 8.39 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12711890379039822		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.12711890379039822 | validation: 0.14261260138612167]
	TIME [epoch: 8.37 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.115585125747998		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.115585125747998 | validation: 0.1335314230852796]
	TIME [epoch: 8.37 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2297975523483739		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.2297975523483739 | validation: 0.16392139501368347]
	TIME [epoch: 8.37 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14599225050884296		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.14599225050884296 | validation: 0.13133018263050023]
	TIME [epoch: 8.4 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13886027798837872		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.13886027798837872 | validation: 0.1406315851802425]
	TIME [epoch: 8.38 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12085263601487269		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.12085263601487269 | validation: 0.1272261566844018]
	TIME [epoch: 8.37 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12150029353288531		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.12150029353288531 | validation: 0.16927499089678272]
	TIME [epoch: 8.36 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12151572662517704		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.12151572662517704 | validation: 0.12156912286850012]
	TIME [epoch: 8.39 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13033773198530302		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.13033773198530302 | validation: 0.14392286032849044]
	TIME [epoch: 8.37 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12293352336389969		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.12293352336389969 | validation: 0.1439550197871322]
	TIME [epoch: 8.37 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12976882464302814		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.12976882464302814 | validation: 0.12120818382920842]
	TIME [epoch: 8.37 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11817118179734246		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.11817118179734246 | validation: 0.11693908722523644]
	TIME [epoch: 8.4 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13157112526097667		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.13157112526097667 | validation: 0.163267498188232]
	TIME [epoch: 8.38 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14496069526032837		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.14496069526032837 | validation: 0.16074668603839826]
	TIME [epoch: 8.37 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.132362143241254		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.132362143241254 | validation: 0.13734749239473332]
	TIME [epoch: 8.37 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13962783176385357		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.13962783176385357 | validation: 0.16098874712544728]
	TIME [epoch: 8.39 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13327594085769284		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.13327594085769284 | validation: 0.13153916836026816]
	TIME [epoch: 8.37 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13433728530396422		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.13433728530396422 | validation: 0.20156809485203814]
	TIME [epoch: 8.37 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13541853457852748		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.13541853457852748 | validation: 0.10851921623867522]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1196.pth
	Model improved!!!
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1372999828110226		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.1372999828110226 | validation: 0.15961315210856067]
	TIME [epoch: 8.4 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14693677795981192		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.14693677795981192 | validation: 0.13263519776394525]
	TIME [epoch: 8.37 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1127211323133435		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.1127211323133435 | validation: 0.14270304985729582]
	TIME [epoch: 8.37 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12742094468588855		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.12742094468588855 | validation: 0.1530897468420574]
	TIME [epoch: 8.36 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15548394733147455		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.15548394733147455 | validation: 0.13753342107915048]
	TIME [epoch: 8.4 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12666400270108263		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.12666400270108263 | validation: 0.15236882947409694]
	TIME [epoch: 8.37 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1318062610734771		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.1318062610734771 | validation: 0.13202996825254296]
	TIME [epoch: 8.37 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1262667943714366		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.1262667943714366 | validation: 0.11972513185170679]
	TIME [epoch: 8.37 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12487146395276165		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.12487146395276165 | validation: 0.14586948771926472]
	TIME [epoch: 8.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1486740574084914		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.1486740574084914 | validation: 0.1294426472526655]
	TIME [epoch: 8.37 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1367501900639606		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.1367501900639606 | validation: 0.14785495893152603]
	TIME [epoch: 8.37 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13328270280314808		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.13328270280314808 | validation: 0.2509346464002437]
	TIME [epoch: 8.36 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1390016397124699		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.1390016397124699 | validation: 0.16177186205011618]
	TIME [epoch: 8.39 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12599149785760208		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.12599149785760208 | validation: 0.13616219092750356]
	TIME [epoch: 8.37 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1148498170031285		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.1148498170031285 | validation: 0.11627075812425378]
	TIME [epoch: 8.37 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14226670852384174		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.14226670852384174 | validation: 0.2184566560761318]
	TIME [epoch: 8.37 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13296570524217416		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.13296570524217416 | validation: 0.12716149926839365]
	TIME [epoch: 8.39 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14474585207755558		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.14474585207755558 | validation: 0.14488971513962218]
	TIME [epoch: 8.36 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11365372650313835		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.11365372650313835 | validation: 0.1480750953695933]
	TIME [epoch: 8.37 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14372933325639684		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.14372933325639684 | validation: 0.11062849687123448]
	TIME [epoch: 8.37 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13068381784061328		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.13068381784061328 | validation: 0.18751155950989684]
	TIME [epoch: 8.39 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12694067480263846		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.12694067480263846 | validation: 0.15209730969439153]
	TIME [epoch: 8.37 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14475738239955221		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.14475738239955221 | validation: 0.1624204462891732]
	TIME [epoch: 8.37 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13173728403539314		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.13173728403539314 | validation: 0.12733041552770707]
	TIME [epoch: 8.37 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13606074197141993		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.13606074197141993 | validation: 0.14031149506432566]
	TIME [epoch: 8.39 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12444848943635298		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.12444848943635298 | validation: 0.12010532665809082]
	TIME [epoch: 8.37 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13799919025200416		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.13799919025200416 | validation: 0.13900218495242386]
	TIME [epoch: 8.37 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12979223301111376		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.12979223301111376 | validation: 0.10612300238198616]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1224.pth
	Model improved!!!
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1183751392105727		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.1183751392105727 | validation: 0.15389345620831668]
	TIME [epoch: 8.4 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1506271947220472		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.1506271947220472 | validation: 0.1401281210865678]
	TIME [epoch: 8.37 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12438663964585547		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.12438663964585547 | validation: 0.1215775862428749]
	TIME [epoch: 8.38 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1187936958651978		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.1187936958651978 | validation: 0.14851494203550397]
	TIME [epoch: 8.39 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12545908896334657		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.12545908896334657 | validation: 0.16031134850860368]
	TIME [epoch: 8.38 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13313533588793275		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.13313533588793275 | validation: 0.13295480081071934]
	TIME [epoch: 8.37 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18276614921755266		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.18276614921755266 | validation: 0.28752499596745995]
	TIME [epoch: 8.37 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16107542942995845		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.16107542942995845 | validation: 0.11487814694440783]
	TIME [epoch: 8.39 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11886095426682952		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.11886095426682952 | validation: 0.14376444478140185]
	TIME [epoch: 8.39 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12341470057920816		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.12341470057920816 | validation: 0.1154391163254907]
	TIME [epoch: 8.38 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10677281311552334		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.10677281311552334 | validation: 0.13109537314134467]
	TIME [epoch: 8.37 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12292306622956435		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.12292306622956435 | validation: 0.16593639176379218]
	TIME [epoch: 8.38 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14864823301831073		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.14864823301831073 | validation: 0.1200393002624526]
	TIME [epoch: 8.38 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11939293454759221		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.11939293454759221 | validation: 0.17513639105473738]
	TIME [epoch: 8.37 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13444083029148338		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.13444083029148338 | validation: 0.11874161457795093]
	TIME [epoch: 8.38 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13727589005547086		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.13727589005547086 | validation: 0.1462289722525234]
	TIME [epoch: 8.39 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12647584669217188		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.12647584669217188 | validation: 0.12211519946093627]
	TIME [epoch: 8.38 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12594926310674223		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.12594926310674223 | validation: 0.1269505313739795]
	TIME [epoch: 8.37 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12335368066600771		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.12335368066600771 | validation: 0.13093086862190662]
	TIME [epoch: 8.37 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12167500929583723		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.12167500929583723 | validation: 0.1377350654675125]
	TIME [epoch: 8.39 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16702883216340347		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.16702883216340347 | validation: 0.12780607275583386]
	TIME [epoch: 8.37 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12663703761010608		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.12663703761010608 | validation: 0.13830735497492896]
	TIME [epoch: 8.38 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13213032999767876		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.13213032999767876 | validation: 0.13099092144381774]
	TIME [epoch: 8.37 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1235913788799575		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.1235913788799575 | validation: 0.11983022247599479]
	TIME [epoch: 8.4 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11974387602059107		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.11974387602059107 | validation: 0.13942010721111323]
	TIME [epoch: 8.37 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12367526776512586		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.12367526776512586 | validation: 0.1418968564138749]
	TIME [epoch: 8.37 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12949504528038536		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.12949504528038536 | validation: 0.1742986785341738]
	TIME [epoch: 8.37 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14472888808677425		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.14472888808677425 | validation: 0.1594019840368415]
	TIME [epoch: 8.4 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.136299705516322		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.136299705516322 | validation: 0.13279571640543425]
	TIME [epoch: 8.37 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11009998164969545		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.11009998164969545 | validation: 0.1147148962850988]
	TIME [epoch: 8.37 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13179843415694648		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.13179843415694648 | validation: 0.12116556372276575]
	TIME [epoch: 8.37 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13218489839488706		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.13218489839488706 | validation: 0.14618005392870914]
	TIME [epoch: 8.39 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13610088166713458		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.13610088166713458 | validation: 0.1357364260205387]
	TIME [epoch: 8.37 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11580955684642444		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.11580955684642444 | validation: 0.11981198492376445]
	TIME [epoch: 8.37 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150332928350888		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.11150332928350888 | validation: 0.11571272118507295]
	TIME [epoch: 8.36 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10970173377085932		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.10970173377085932 | validation: 0.12318328211415755]
	TIME [epoch: 8.39 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13074013817035224		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.13074013817035224 | validation: 0.1107396678954497]
	TIME [epoch: 8.37 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11126071936627271		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.11126071936627271 | validation: 0.19731571337921405]
	TIME [epoch: 8.37 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13311547001866747		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.13311547001866747 | validation: 0.1587557238363319]
	TIME [epoch: 8.37 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12642451927345996		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.12642451927345996 | validation: 0.21628348492674815]
	TIME [epoch: 8.4 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12809158295464923		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.12809158295464923 | validation: 0.1281525069283534]
	TIME [epoch: 8.38 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11403426974617852		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.11403426974617852 | validation: 0.1045267206613727]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1266.pth
	Model improved!!!
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12283653929823082		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.12283653929823082 | validation: 0.14274932877726987]
	TIME [epoch: 8.38 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12135406135431417		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.12135406135431417 | validation: 0.12460881197740041]
	TIME [epoch: 8.39 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12048441209423737		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.12048441209423737 | validation: 0.12149316616453415]
	TIME [epoch: 8.37 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12031183625104906		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.12031183625104906 | validation: 0.14405722713094427]
	TIME [epoch: 8.37 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12685239278468435		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.12685239278468435 | validation: 0.14113717178595314]
	TIME [epoch: 8.37 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12704698018452013		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.12704698018452013 | validation: 0.1225668463646469]
	TIME [epoch: 8.4 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1080504878893962		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.1080504878893962 | validation: 0.14363768935235274]
	TIME [epoch: 8.37 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12019284044885592		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.12019284044885592 | validation: 0.1355633753221847]
	TIME [epoch: 8.37 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13240415677284725		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.13240415677284725 | validation: 0.11734919627358013]
	TIME [epoch: 8.37 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12142037277262534		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.12142037277262534 | validation: 0.1559582788396241]
	TIME [epoch: 8.4 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1202267349844218		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.1202267349844218 | validation: 0.15089501573466374]
	TIME [epoch: 8.37 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12219364444888017		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.12219364444888017 | validation: 0.11980336608118253]
	TIME [epoch: 8.37 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11639593440205358		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.11639593440205358 | validation: 0.11282595810767787]
	TIME [epoch: 8.37 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11684079384567456		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.11684079384567456 | validation: 0.12308707334886926]
	TIME [epoch: 8.39 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1108470315839504		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.1108470315839504 | validation: 0.15293762683691148]
	TIME [epoch: 8.37 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13151690637336383		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.13151690637336383 | validation: 0.14235451826891043]
	TIME [epoch: 8.37 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1346467609813366		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.1346467609813366 | validation: 0.11960624637607346]
	TIME [epoch: 8.37 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12608566755190517		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.12608566755190517 | validation: 0.16782667214232747]
	TIME [epoch: 8.4 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13509273816550368		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.13509273816550368 | validation: 0.1369372752521802]
	TIME [epoch: 8.37 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12485320204323189		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.12485320204323189 | validation: 0.12415019333713385]
	TIME [epoch: 8.37 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11751682283008895		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.11751682283008895 | validation: 0.1650801697990702]
	TIME [epoch: 8.37 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12651773609290384		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.12651773609290384 | validation: 0.11497544565043545]
	TIME [epoch: 8.4 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13151368387250115		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.13151368387250115 | validation: 0.18330377745009488]
	TIME [epoch: 8.37 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13215037067593977		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.13215037067593977 | validation: 0.11529493235984264]
	TIME [epoch: 8.37 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11694783843258927		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.11694783843258927 | validation: 0.1636156122852393]
	TIME [epoch: 8.38 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13113822066263525		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.13113822066263525 | validation: 0.11777645438117304]
	TIME [epoch: 8.39 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10537211986448969		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.10537211986448969 | validation: 0.12473166072061834]
	TIME [epoch: 8.37 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1128859574571309		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.1128859574571309 | validation: 0.12234720933433996]
	TIME [epoch: 8.37 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11079424307267091		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.11079424307267091 | validation: 0.11188227548491608]
	TIME [epoch: 8.39 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12105057397624892		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.12105057397624892 | validation: 0.12255715175220014]
	TIME [epoch: 8.38 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11817119983242505		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.11817119983242505 | validation: 0.11488575109344035]
	TIME [epoch: 8.37 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1176394513993571		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.1176394513993571 | validation: 0.12121690025765969]
	TIME [epoch: 8.36 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11453198942842716		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.11453198942842716 | validation: 0.12123774306814256]
	TIME [epoch: 8.37 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11475875913615204		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.11475875913615204 | validation: 0.2705061946273713]
	TIME [epoch: 8.37 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13784469856779544		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.13784469856779544 | validation: 0.16791640702305832]
	TIME [epoch: 8.36 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15919880013970428		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.15919880013970428 | validation: 0.12321289595473726]
	TIME [epoch: 8.38 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102835557137885		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.12102835557137885 | validation: 0.13840361743535595]
	TIME [epoch: 8.39 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225754601368232		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.11225754601368232 | validation: 0.11939095498691675]
	TIME [epoch: 8.38 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1315356235296277		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.1315356235296277 | validation: 0.16903495845560634]
	TIME [epoch: 8.37 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14348913574000777		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.14348913574000777 | validation: 0.12195051965370346]
	TIME [epoch: 8.37 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13019095574970163		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.13019095574970163 | validation: 0.19144982469728083]
	TIME [epoch: 8.38 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13982878440612392		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.13982878440612392 | validation: 0.1351769565162905]
	TIME [epoch: 8.38 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12623174726079636		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.12623174726079636 | validation: 0.15089002392008136]
	TIME [epoch: 8.36 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11051442910969618		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.11051442910969618 | validation: 0.11733477588486577]
	TIME [epoch: 8.36 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1211299842281763		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.1211299842281763 | validation: 0.14826515831369477]
	TIME [epoch: 8.37 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12781767531187144		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.12781767531187144 | validation: 0.10976790446354599]
	TIME [epoch: 8.37 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12074986547756697		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.12074986547756697 | validation: 0.10725081536727146]
	TIME [epoch: 8.35 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12312108682301814		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.12312108682301814 | validation: 0.14605092148617344]
	TIME [epoch: 8.36 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12063164453250393		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.12063164453250393 | validation: 0.11150000773864814]
	TIME [epoch: 8.38 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13435825253786948		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.13435825253786948 | validation: 0.23827646904153382]
	TIME [epoch: 8.37 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11273009587851342		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.11273009587851342 | validation: 0.15070346683287586]
	TIME [epoch: 8.36 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255176021248131		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.1255176021248131 | validation: 0.14939313444551483]
	TIME [epoch: 8.36 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11981192948771255		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.11981192948771255 | validation: 0.11037554373051567]
	TIME [epoch: 8.39 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.118503385219031		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.118503385219031 | validation: 0.1467062796620645]
	TIME [epoch: 8.37 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11764439224955328		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.11764439224955328 | validation: 0.17186139436829895]
	TIME [epoch: 8.36 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11554143713093375		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.11554143713093375 | validation: 0.12603099252531041]
	TIME [epoch: 8.36 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1188527746539646		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.1188527746539646 | validation: 0.14608201605105392]
	TIME [epoch: 8.38 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12803926872883492		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.12803926872883492 | validation: 0.11268979403069707]
	TIME [epoch: 8.37 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11953885233573387		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.11953885233573387 | validation: 0.1161570860305386]
	TIME [epoch: 8.36 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15008727266886632		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.15008727266886632 | validation: 0.18113259827924344]
	TIME [epoch: 8.37 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12743324777397166		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.12743324777397166 | validation: 0.1138260995970827]
	TIME [epoch: 8.38 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1080605132343094		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.1080605132343094 | validation: 0.1498648544783978]
	TIME [epoch: 8.36 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13378498962045013		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.13378498962045013 | validation: 0.11810280885852839]
	TIME [epoch: 8.36 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11628188972773328		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.11628188972773328 | validation: 0.14032497769969077]
	TIME [epoch: 8.37 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13029840336228316		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.13029840336228316 | validation: 0.14102764138705004]
	TIME [epoch: 8.39 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11594486067767225		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.11594486067767225 | validation: 0.11620466038982702]
	TIME [epoch: 8.36 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10646764616919129		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.10646764616919129 | validation: 0.10863518779786191]
	TIME [epoch: 8.37 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11931331553732098		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.11931331553732098 | validation: 0.1769763759393706]
	TIME [epoch: 8.36 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12522575873477035		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.12522575873477035 | validation: 0.10320748854793113]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1335.pth
	Model improved!!!
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10724553747759442		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.10724553747759442 | validation: 0.13229963321857963]
	TIME [epoch: 8.37 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12161332660090567		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.12161332660090567 | validation: 0.13091501467568156]
	TIME [epoch: 8.35 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11767271862465897		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.11767271862465897 | validation: 0.12237306511794079]
	TIME [epoch: 8.36 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1192841589530504		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.1192841589530504 | validation: 0.13292492952777896]
	TIME [epoch: 8.39 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12373674552911776		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.12373674552911776 | validation: 0.13954587101174332]
	TIME [epoch: 8.35 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11274968997895692		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.11274968997895692 | validation: 0.1147675204995818]
	TIME [epoch: 8.36 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11410460301066164		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.11410460301066164 | validation: 0.16530902349047344]
	TIME [epoch: 8.36 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11584316411632911		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.11584316411632911 | validation: 0.10843671199316826]
	TIME [epoch: 8.39 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11464434398541726		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.11464434398541726 | validation: 0.13995633596645163]
	TIME [epoch: 8.36 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.125126442963853		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.125126442963853 | validation: 0.1394856372762417]
	TIME [epoch: 8.36 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11163421114084367		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.11163421114084367 | validation: 0.13799210217245533]
	TIME [epoch: 8.36 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11133621987455027		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.11133621987455027 | validation: 0.11313375128885172]
	TIME [epoch: 8.38 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13579654529643986		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.13579654529643986 | validation: 0.11133651960830356]
	TIME [epoch: 8.37 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11561945514751075		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.11561945514751075 | validation: 0.11520123113807408]
	TIME [epoch: 8.37 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11887457411567932		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.11887457411567932 | validation: 0.11556605810165024]
	TIME [epoch: 8.36 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11262980047066111		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.11262980047066111 | validation: 0.13360988122884043]
	TIME [epoch: 8.39 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12766447396293318		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.12766447396293318 | validation: 0.16219772819175055]
	TIME [epoch: 8.37 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12361372369261063		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.12361372369261063 | validation: 0.1218340365226212]
	TIME [epoch: 8.36 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.106666951031266		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.106666951031266 | validation: 0.13908669127603246]
	TIME [epoch: 8.36 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11573563771158976		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.11573563771158976 | validation: 0.11933635836139177]
	TIME [epoch: 8.39 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09897250490744983		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.09897250490744983 | validation: 0.12162334684130927]
	TIME [epoch: 8.36 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11796577637392994		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.11796577637392994 | validation: 0.14475589122696592]
	TIME [epoch: 8.36 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10910557090264608		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.10910557090264608 | validation: 0.12977610640924372]
	TIME [epoch: 8.36 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12622972480884578		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.12622972480884578 | validation: 0.11501165961983367]
	TIME [epoch: 8.38 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10582861884035102		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.10582861884035102 | validation: 0.1070326057200878]
	TIME [epoch: 8.36 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10237297355317423		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.10237297355317423 | validation: 0.1172649914464873]
	TIME [epoch: 8.37 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11386406825625292		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.11386406825625292 | validation: 0.19746234520572292]
	TIME [epoch: 8.37 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12607357171278016		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.12607357171278016 | validation: 0.10912930074736985]
	TIME [epoch: 8.38 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10748234535647708		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.10748234535647708 | validation: 0.1296316548049777]
	TIME [epoch: 8.36 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10719848337661549		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.10719848337661549 | validation: 0.10843824680664069]
	TIME [epoch: 8.37 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12163252987894657		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.12163252987894657 | validation: 0.20140863534293235]
	TIME [epoch: 8.37 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12829133456052366		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.12829133456052366 | validation: 0.10101013380861837]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1367.pth
	Model improved!!!
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10634181545124462		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.10634181545124462 | validation: 0.11794730266665679]
	TIME [epoch: 8.36 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11174070190872745		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.11174070190872745 | validation: 0.10032019567740477]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1369.pth
	Model improved!!!
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1103335060113078		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.1103335060113078 | validation: 0.136052474157636]
	TIME [epoch: 8.4 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11759348167615873		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.11759348167615873 | validation: 0.16024342359246213]
	TIME [epoch: 8.39 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10894612440545373		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.10894612440545373 | validation: 0.12900397279060916]
	TIME [epoch: 8.38 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11274617798463096		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.11274617798463096 | validation: 0.11672332378126074]
	TIME [epoch: 8.39 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13053701028979775		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.13053701028979775 | validation: 0.10313391879919584]
	TIME [epoch: 8.4 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10913360469044231		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.10913360469044231 | validation: 0.10832141859217331]
	TIME [epoch: 8.39 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10773016533845645		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.10773016533845645 | validation: 0.13658479691800626]
	TIME [epoch: 8.38 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136352628045153		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.1136352628045153 | validation: 0.11852291142793868]
	TIME [epoch: 8.39 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11251819707868209		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.11251819707868209 | validation: 0.13029414033872816]
	TIME [epoch: 8.4 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10223583040740099		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.10223583040740099 | validation: 0.14112120117033553]
	TIME [epoch: 8.39 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11387119799351433		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.11387119799351433 | validation: 0.13164022797116115]
	TIME [epoch: 8.38 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10426000009401053		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.10426000009401053 | validation: 0.12163837427947115]
	TIME [epoch: 8.38 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10551805815524143		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.10551805815524143 | validation: 0.1104614465694497]
	TIME [epoch: 8.4 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1129767719933262		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.1129767719933262 | validation: 0.10746771314703851]
	TIME [epoch: 8.39 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10459903116445597		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.10459903116445597 | validation: 0.10647580525640192]
	TIME [epoch: 8.38 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10798621935900284		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.10798621935900284 | validation: 0.10626270240915976]
	TIME [epoch: 8.38 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12685749261633672		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.12685749261633672 | validation: 0.10637136997865113]
	TIME [epoch: 8.41 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11776698658765125		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.11776698658765125 | validation: 0.10611062561275664]
	TIME [epoch: 8.39 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1083353377046328		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.1083353377046328 | validation: 0.11083044736925318]
	TIME [epoch: 8.39 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10915455719536245		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.10915455719536245 | validation: 0.10921223247464557]
	TIME [epoch: 8.39 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1123442933616275		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.1123442933616275 | validation: 0.13972938683667252]
	TIME [epoch: 8.41 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10262891156062197		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.10262891156062197 | validation: 0.14549872625555843]
	TIME [epoch: 8.39 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12883807260444488		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.12883807260444488 | validation: 0.10871386457060578]
	TIME [epoch: 8.38 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11283141346825323		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.11283141346825323 | validation: 0.12589266294952545]
	TIME [epoch: 8.39 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10869837113585916		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.10869837113585916 | validation: 0.1414594877603301]
	TIME [epoch: 8.41 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10808885772042816		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.10808885772042816 | validation: 0.15837319114269255]
	TIME [epoch: 8.39 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13625407207577273		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.13625407207577273 | validation: 0.11210647104314406]
	TIME [epoch: 8.39 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10483784619333214		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.10483784619333214 | validation: 0.11607717829071543]
	TIME [epoch: 8.38 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11339307030349488		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.11339307030349488 | validation: 0.11163658714559815]
	TIME [epoch: 8.41 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12499707260365303		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.12499707260365303 | validation: 0.11182330532574108]
	TIME [epoch: 8.39 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12082233443230014		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.12082233443230014 | validation: 0.1133588382396866]
	TIME [epoch: 8.38 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.114692213858634		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.114692213858634 | validation: 0.10101254468568266]
	TIME [epoch: 8.38 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11211968548137632		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.11211968548137632 | validation: 0.12877962390957948]
	TIME [epoch: 8.41 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1310854835651055		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.1310854835651055 | validation: 0.11424915422323109]
	TIME [epoch: 8.38 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10516239053219276		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.10516239053219276 | validation: 0.1288281372012509]
	TIME [epoch: 8.38 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12207143933127391		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.12207143933127391 | validation: 0.11594583048777268]
	TIME [epoch: 8.38 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11302861175626333		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.11302861175626333 | validation: 0.12111761432631774]
	TIME [epoch: 8.41 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10730736909735601		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.10730736909735601 | validation: 0.14279367767039705]
	TIME [epoch: 8.38 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1382518065532604		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.1382518065532604 | validation: 0.12611443636661585]
	TIME [epoch: 8.38 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12752980558484858		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.12752980558484858 | validation: 0.11596595147541144]
	TIME [epoch: 8.39 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1043358669281913		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.1043358669281913 | validation: 0.10530844363112149]
	TIME [epoch: 8.41 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10998860631301972		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.10998860631301972 | validation: 0.10952196332723915]
	TIME [epoch: 8.38 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10661519021565236		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.10661519021565236 | validation: 0.09748724839541081]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1412.pth
	Model improved!!!
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11122262120537393		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.11122262120537393 | validation: 0.11359057260127692]
	TIME [epoch: 8.39 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11358382336161692		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.11358382336161692 | validation: 0.16702571677117056]
	TIME [epoch: 8.39 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10671263524246581		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.10671263524246581 | validation: 0.11334733155060087]
	TIME [epoch: 8.38 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11381966188067494		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.11381966188067494 | validation: 0.11295617364487293]
	TIME [epoch: 8.38 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10000061917435125		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.10000061917435125 | validation: 0.10327892190945218]
	TIME [epoch: 8.38 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10857687932472918		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.10857687932472918 | validation: 0.10919383544995179]
	TIME [epoch: 8.4 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11728585954787596		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.11728585954787596 | validation: 0.12124366038294615]
	TIME [epoch: 8.38 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11505853871353273		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.11505853871353273 | validation: 0.10933135190324539]
	TIME [epoch: 8.38 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11772643889371068		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.11772643889371068 | validation: 0.09709979451692463]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1421.pth
	Model improved!!!
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11296800692677482		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.11296800692677482 | validation: 0.13440292815690552]
	TIME [epoch: 8.43 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10317489250218417		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.10317489250218417 | validation: 0.1177906758070127]
	TIME [epoch: 8.38 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1125885357539819		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.1125885357539819 | validation: 0.13324303018167533]
	TIME [epoch: 8.38 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12565234563068395		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.12565234563068395 | validation: 0.15125434078662559]
	TIME [epoch: 8.39 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11151910265305467		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.11151910265305467 | validation: 0.11101661184734576]
	TIME [epoch: 8.38 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461482718803036		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.10461482718803036 | validation: 0.17869658192921228]
	TIME [epoch: 8.38 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257646029257594		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.1257646029257594 | validation: 0.1066762271223925]
	TIME [epoch: 8.38 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1166169312875105		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.1166169312875105 | validation: 0.1116161081453759]
	TIME [epoch: 8.39 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10492347228764017		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.10492347228764017 | validation: 0.10185609995766651]
	TIME [epoch: 8.39 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11141575952275887		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.11141575952275887 | validation: 0.10308901560520534]
	TIME [epoch: 8.37 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10817855593236492		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.10817855593236492 | validation: 0.12684005826510947]
	TIME [epoch: 8.38 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11062655505879349		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.11062655505879349 | validation: 0.10088608322713222]
	TIME [epoch: 8.39 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10996570005690158		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.10996570005690158 | validation: 0.15124521725962356]
	TIME [epoch: 8.39 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10654516350250373		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.10654516350250373 | validation: 0.1116882259613611]
	TIME [epoch: 8.38 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11057056646256683		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.11057056646256683 | validation: 0.11250830525653387]
	TIME [epoch: 8.38 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.109510286861112		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.109510286861112 | validation: 0.14918471528767613]
	TIME [epoch: 8.4 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11594009131606757		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.11594009131606757 | validation: 0.1245429846560679]
	TIME [epoch: 8.39 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11321958302381732		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.11321958302381732 | validation: 0.15326991135190426]
	TIME [epoch: 8.38 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11766526829377766		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.11766526829377766 | validation: 0.12604182692659738]
	TIME [epoch: 8.38 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11652299163766203		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.11652299163766203 | validation: 0.11661928200075239]
	TIME [epoch: 8.4 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11868667548129638		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.11868667548129638 | validation: 0.10786065885953879]
	TIME [epoch: 8.38 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09919279654362792		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.09919279654362792 | validation: 0.10649372937563818]
	TIME [epoch: 8.38 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10235150589630218		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.10235150589630218 | validation: 0.12585009742855924]
	TIME [epoch: 8.38 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1133800507373676		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.1133800507373676 | validation: 0.12240424994806011]
	TIME [epoch: 8.41 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10690905542594038		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.10690905542594038 | validation: 0.11735172315281028]
	TIME [epoch: 8.38 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11989161083110815		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.11989161083110815 | validation: 0.13741577984130807]
	TIME [epoch: 8.38 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11733669449004111		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.11733669449004111 | validation: 0.15623074300381]
	TIME [epoch: 8.38 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13683442651413477		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.13683442651413477 | validation: 0.10374525898747447]
	TIME [epoch: 8.4 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09825206180987942		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.09825206180987942 | validation: 0.11960565242358566]
	TIME [epoch: 8.38 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10768853772486049		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.10768853772486049 | validation: 0.1068760581241511]
	TIME [epoch: 8.37 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09833092707172306		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.09833092707172306 | validation: 0.11115576100315949]
	TIME [epoch: 8.38 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10694138840257336		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.10694138840257336 | validation: 0.10741516666492654]
	TIME [epoch: 8.4 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1422435429552163		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.1422435429552163 | validation: 0.11428396844693467]
	TIME [epoch: 8.38 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12473282461491093		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.12473282461491093 | validation: 0.13916068449168786]
	TIME [epoch: 8.38 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10100679214478889		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.10100679214478889 | validation: 0.11820435608878012]
	TIME [epoch: 8.37 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10995697590630751		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.10995697590630751 | validation: 0.11334072981457127]
	TIME [epoch: 8.4 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1119377460536873		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.1119377460536873 | validation: 0.11468516797890818]
	TIME [epoch: 8.38 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10873105419716882		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.10873105419716882 | validation: 0.13312417678413838]
	TIME [epoch: 8.38 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13291030950363722		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.13291030950363722 | validation: 0.1299169568292838]
	TIME [epoch: 8.38 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10818467044429267		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.10818467044429267 | validation: 0.13572112670034756]
	TIME [epoch: 8.4 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11185549315914718		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.11185549315914718 | validation: 0.11384989577165974]
	TIME [epoch: 8.38 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11363985405130084		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.11363985405130084 | validation: 0.10667532404052288]
	TIME [epoch: 8.38 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1129689044853256		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.1129689044853256 | validation: 0.10115469252365694]
	TIME [epoch: 8.38 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10841009213417789		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.10841009213417789 | validation: 0.1064913954355652]
	TIME [epoch: 8.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09780007126728556		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.09780007126728556 | validation: 0.11443166990372797]
	TIME [epoch: 8.38 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1140646319207758		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.1140646319207758 | validation: 0.11477344143350401]
	TIME [epoch: 8.37 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10486751084639298		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.10486751084639298 | validation: 0.1415810800720434]
	TIME [epoch: 8.38 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12150489615485886		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.12150489615485886 | validation: 0.12688559193342994]
	TIME [epoch: 8.39 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11050063533274153		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.11050063533274153 | validation: 0.12828974898119028]
	TIME [epoch: 8.37 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11173014537208883		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.11173014537208883 | validation: 0.11602823681139024]
	TIME [epoch: 8.38 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10666668878509018		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.10666668878509018 | validation: 0.12336106118478568]
	TIME [epoch: 8.38 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10497596334292647		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.10497596334292647 | validation: 0.1114018690603932]
	TIME [epoch: 8.4 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10413787105127618		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.10413787105127618 | validation: 0.10313254274163086]
	TIME [epoch: 8.37 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09493936696861335		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.09493936696861335 | validation: 0.13334930559078528]
	TIME [epoch: 8.37 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11599079867258666		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.11599079867258666 | validation: 0.10651911588356366]
	TIME [epoch: 8.37 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0992986762570483		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.0992986762570483 | validation: 0.1153282474709317]
	TIME [epoch: 8.39 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1085859177290508		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.1085859177290508 | validation: 0.1160990201530931]
	TIME [epoch: 8.38 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10227271555144987		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.10227271555144987 | validation: 0.13763658624352107]
	TIME [epoch: 8.37 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1150061847426769		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.1150061847426769 | validation: 0.10481525429081948]
	TIME [epoch: 8.38 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10469418388434001		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.10469418388434001 | validation: 0.10685631462535242]
	TIME [epoch: 8.39 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10424960211329674		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.10424960211329674 | validation: 0.132952874552982]
	TIME [epoch: 8.38 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11385719914998108		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.11385719914998108 | validation: 0.11202631943385619]
	TIME [epoch: 8.37 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10824687089727389		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.10824687089727389 | validation: 0.10683330690809445]
	TIME [epoch: 8.38 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1059664115822417		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.1059664115822417 | validation: 0.10660876983754777]
	TIME [epoch: 8.39 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10661367752169124		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.10661367752169124 | validation: 0.10900980189573783]
	TIME [epoch: 8.37 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10691725096251878		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.10691725096251878 | validation: 0.10558635681130327]
	TIME [epoch: 8.38 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314959454102742		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.11314959454102742 | validation: 0.10860201832999486]
	TIME [epoch: 8.38 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10631457780268716		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.10631457780268716 | validation: 0.09591632322831098]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1489.pth
	Model improved!!!
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10483719214848275		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.10483719214848275 | validation: 0.1050515587480973]
	TIME [epoch: 8.37 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11119664814770322		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.11119664814770322 | validation: 0.12033288358119457]
	TIME [epoch: 8.36 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10715540924500819		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.10715540924500819 | validation: 0.11791474283476214]
	TIME [epoch: 8.38 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11422220766444764		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.11422220766444764 | validation: 0.1379127010642304]
	TIME [epoch: 8.38 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11567343680524907		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.11567343680524907 | validation: 0.11549879382858041]
	TIME [epoch: 8.37 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10349702394347386		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.10349702394347386 | validation: 0.11238505722368372]
	TIME [epoch: 8.37 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10801363913378241		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.10801363913378241 | validation: 0.1080787206334857]
	TIME [epoch: 8.38 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10288579577655557		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.10288579577655557 | validation: 0.11322548618643105]
	TIME [epoch: 8.38 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10608646069256591		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.10608646069256591 | validation: 0.10220588787554638]
	TIME [epoch: 8.37 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0985394394654702		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.0985394394654702 | validation: 0.11787930879358019]
	TIME [epoch: 8.37 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10273913401622692		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.10273913401622692 | validation: 0.12262556391294815]
	TIME [epoch: 8.39 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10730316982836333		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.10730316982836333 | validation: 0.15914614441107414]
	TIME [epoch: 8.38 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12493223341997126		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.12493223341997126 | validation: 0.09900577561388232]
	TIME [epoch: 8.37 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10297140924520935		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.10297140924520935 | validation: 0.10439231241505431]
	TIME [epoch: 8.37 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10243911721575878		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.10243911721575878 | validation: 0.11632470597405589]
	TIME [epoch: 8.39 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314854219952061		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.11314854219952061 | validation: 0.12904556029215758]
	TIME [epoch: 8.37 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11258578489487939		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.11258578489487939 | validation: 0.12058685454977049]
	TIME [epoch: 8.37 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10819787606942188		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.10819787606942188 | validation: 0.15608554580137485]
	TIME [epoch: 8.37 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1156963013054775		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.1156963013054775 | validation: 0.11017470899705707]
	TIME [epoch: 8.39 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10744838957103515		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.10744838957103515 | validation: 0.10810072885962058]
	TIME [epoch: 8.37 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09852338224914522		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.09852338224914522 | validation: 0.11151270585118847]
	TIME [epoch: 8.36 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10814436159672498		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.10814436159672498 | validation: 0.12754339368960932]
	TIME [epoch: 8.36 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09686350908216515		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.09686350908216515 | validation: 0.10854489033480234]
	TIME [epoch: 8.39 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11195219944523915		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.11195219944523915 | validation: 0.12336895520872831]
	TIME [epoch: 8.36 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10608702356651112		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.10608702356651112 | validation: 0.12679434788693023]
	TIME [epoch: 8.36 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09856466027963061		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.09856466027963061 | validation: 0.11060084779945431]
	TIME [epoch: 8.36 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09934684417414145		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.09934684417414145 | validation: 0.11620697171423766]
	TIME [epoch: 8.39 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09772213987230778		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.09772213987230778 | validation: 0.1033083136737298]
	TIME [epoch: 8.37 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.101434502363053		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.101434502363053 | validation: 0.10026712278004371]
	TIME [epoch: 8.37 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09797020684618209		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.09797020684618209 | validation: 0.14696274696436748]
	TIME [epoch: 8.37 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1129975712822402		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.1129975712822402 | validation: 0.14786887122412445]
	TIME [epoch: 8.39 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12573987564739456		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.12573987564739456 | validation: 0.15039285602432254]
	TIME [epoch: 8.37 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12103709021575877		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.12103709021575877 | validation: 0.11531475762882218]
	TIME [epoch: 8.37 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10349457710663072		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.10349457710663072 | validation: 0.11447760396042031]
	TIME [epoch: 8.37 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10720133314641438		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.10720133314641438 | validation: 0.12013970940045146]
	TIME [epoch: 8.39 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10539767508902279		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.10539767508902279 | validation: 0.14338928410641844]
	TIME [epoch: 8.37 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1096215449132513		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.1096215449132513 | validation: 0.11055958791073536]
	TIME [epoch: 8.37 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09812851542977544		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.09812851542977544 | validation: 0.12090322924701316]
	TIME [epoch: 8.37 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10131820992352687		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.10131820992352687 | validation: 0.12007875012091382]
	TIME [epoch: 8.38 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09992445236028505		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.09992445236028505 | validation: 0.11346643845549982]
	TIME [epoch: 8.36 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11822079427265733		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.11822079427265733 | validation: 0.09803752125342374]
	TIME [epoch: 8.36 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09982383709758146		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.09982383709758146 | validation: 0.11830150153131089]
	TIME [epoch: 8.36 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09683350552545607		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.09683350552545607 | validation: 0.1294710856021781]
	TIME [epoch: 8.39 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10430044334554486		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.10430044334554486 | validation: 0.1098561838515463]
	TIME [epoch: 8.36 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1091702163258732		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.1091702163258732 | validation: 0.14209375534389881]
	TIME [epoch: 8.36 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1185615078114148		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.1185615078114148 | validation: 0.13496774198694225]
	TIME [epoch: 8.36 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10316533416342791		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.10316533416342791 | validation: 0.10696056807318347]
	TIME [epoch: 8.38 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09122847565003082		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.09122847565003082 | validation: 0.10088261076597949]
	TIME [epoch: 8.36 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0946963009725165		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.0946963009725165 | validation: 0.11817208513692337]
	TIME [epoch: 8.36 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09688863667626185		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.09688863667626185 | validation: 0.10479218349831312]
	TIME [epoch: 8.36 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09604710970697905		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.09604710970697905 | validation: 0.11152266140346989]
	TIME [epoch: 8.38 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10230937071704709		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.10230937071704709 | validation: 0.15857704179233006]
	TIME [epoch: 8.37 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14087257172066386		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.14087257172066386 | validation: 0.11766786579408176]
	TIME [epoch: 8.36 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1078116194493092		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.1078116194493092 | validation: 0.13153888253046891]
	TIME [epoch: 8.37 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10543532844447161		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.10543532844447161 | validation: 0.18844986752259166]
	TIME [epoch: 8.39 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11663070588814457		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.11663070588814457 | validation: 0.11278270587853378]
	TIME [epoch: 8.36 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10015095561521688		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.10015095561521688 | validation: 0.10957156612194524]
	TIME [epoch: 8.37 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10352424882811942		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.10352424882811942 | validation: 0.10566733451612689]
	TIME [epoch: 8.36 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10883107724372236		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.10883107724372236 | validation: 0.11742045376645088]
	TIME [epoch: 8.39 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10007922727781375		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.10007922727781375 | validation: 0.0962971461454863]
	TIME [epoch: 8.36 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10500857686824246		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.10500857686824246 | validation: 0.16244618754282053]
	TIME [epoch: 8.36 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11934680788594638		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.11934680788594638 | validation: 0.11084225274679516]
	TIME [epoch: 8.36 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09594522284814677		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.09594522284814677 | validation: 0.10473389392016012]
	TIME [epoch: 8.37 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0966270125378931		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.0966270125378931 | validation: 0.11003735307266725]
	TIME [epoch: 8.36 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.108340360097712		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.108340360097712 | validation: 0.11938025057405183]
	TIME [epoch: 8.36 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10150865376673213		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.10150865376673213 | validation: 0.11094835513079122]
	TIME [epoch: 8.37 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09962487929492872		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.09962487929492872 | validation: 0.12004752627781065]
	TIME [epoch: 8.37 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10815277603894806		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.10815277603894806 | validation: 0.1415964491960737]
	TIME [epoch: 8.36 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11021271443084066		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.11021271443084066 | validation: 0.1241192997120628]
	TIME [epoch: 8.36 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250854398556199		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.1250854398556199 | validation: 0.11171721463458484]
	TIME [epoch: 8.37 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12606102291360938		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.12606102291360938 | validation: 0.13265220692563096]
	TIME [epoch: 8.38 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12424844741484002		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.12424844741484002 | validation: 0.10849596392152286]
	TIME [epoch: 8.36 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11336774682121271		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.11336774682121271 | validation: 0.12044543093523513]
	TIME [epoch: 8.36 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10111997101319654		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.10111997101319654 | validation: 0.09879302869025972]
	TIME [epoch: 8.38 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09950048860698706		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.09950048860698706 | validation: 0.11053027817171379]
	TIME [epoch: 8.38 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09657673239426207		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.09657673239426207 | validation: 0.11789767710791235]
	TIME [epoch: 8.35 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10856074506654867		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.10856074506654867 | validation: 0.11337932751615996]
	TIME [epoch: 8.36 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09555033833137602		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.09555033833137602 | validation: 0.12029616591622146]
	TIME [epoch: 8.38 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09798442620992825		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.09798442620992825 | validation: 0.10687037473865821]
	TIME [epoch: 8.36 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09741513449533996		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.09741513449533996 | validation: 0.11887137349089483]
	TIME [epoch: 8.36 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11634169194626676		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.11634169194626676 | validation: 0.12545457957862158]
	TIME [epoch: 8.36 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10436045000515323		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.10436045000515323 | validation: 0.13890189319180715]
	TIME [epoch: 8.37 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12142905580175241		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.12142905580175241 | validation: 0.14248925203926438]
	TIME [epoch: 8.36 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11460004075343795		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.11460004075343795 | validation: 0.12386129491161516]
	TIME [epoch: 8.36 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09930364438429577		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.09930364438429577 | validation: 0.11230417521457936]
	TIME [epoch: 8.36 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1083582976642639		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.1083582976642639 | validation: 0.14225213381554463]
	TIME [epoch: 8.38 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11888943892257017		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.11888943892257017 | validation: 0.10990529664764724]
	TIME [epoch: 8.37 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10884004882450907		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.10884004882450907 | validation: 0.13826669544549097]
	TIME [epoch: 8.36 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1123576297126336		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.1123576297126336 | validation: 0.10130135555043049]
	TIME [epoch: 8.36 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10424954748548518		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.10424954748548518 | validation: 0.10125496957679786]
	TIME [epoch: 8.38 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0944893524080404		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.0944893524080404 | validation: 0.10527228077127537]
	TIME [epoch: 8.37 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1006098967184473		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.1006098967184473 | validation: 0.09737130869923917]
	TIME [epoch: 8.36 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10393423677901144		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.10393423677901144 | validation: 0.12144255280539748]
	TIME [epoch: 8.36 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10330222217654492		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.10330222217654492 | validation: 0.10712618940500958]
	TIME [epoch: 8.38 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10939085551687563		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.10939085551687563 | validation: 0.101206538083434]
	TIME [epoch: 8.37 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10537273169770603		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.10537273169770603 | validation: 0.11333749887582054]
	TIME [epoch: 8.35 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10748925666655502		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.10748925666655502 | validation: 0.10440566716191069]
	TIME [epoch: 8.36 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10018201261228106		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.10018201261228106 | validation: 0.12444305077672102]
	TIME [epoch: 8.38 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10444945313637324		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.10444945313637324 | validation: 0.10176160951550395]
	TIME [epoch: 8.36 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10264866510917092		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.10264866510917092 | validation: 0.11630706465651136]
	TIME [epoch: 8.36 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940456746905037		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.0940456746905037 | validation: 0.09202753547372258]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1590.pth
	Model improved!!!
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08906438853279568		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.08906438853279568 | validation: 0.1101689224311268]
	TIME [epoch: 8.39 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09496031246984141		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.09496031246984141 | validation: 0.10139114654386017]
	TIME [epoch: 8.36 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10721403843606983		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.10721403843606983 | validation: 0.13143458739974997]
	TIME [epoch: 8.36 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461987256547844		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.10461987256547844 | validation: 0.10376499357064081]
	TIME [epoch: 8.36 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09989757445473503		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.09989757445473503 | validation: 0.10358958326133448]
	TIME [epoch: 8.38 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09331705110200769		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.09331705110200769 | validation: 0.11387541577539928]
	TIME [epoch: 8.36 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10182629250992785		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.10182629250992785 | validation: 0.10067344332820145]
	TIME [epoch: 8.36 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10124873465272169		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.10124873465272169 | validation: 0.12094625612112783]
	TIME [epoch: 8.37 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09989279543401411		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.09989279543401411 | validation: 0.11567945940162976]
	TIME [epoch: 8.39 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10030462358813774		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.10030462358813774 | validation: 0.13734616782253176]
	TIME [epoch: 8.37 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12481314776299927		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.12481314776299927 | validation: 0.11315768421467853]
	TIME [epoch: 8.36 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10476675706441543		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.10476675706441543 | validation: 0.12710230378026402]
	TIME [epoch: 8.36 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10584347572740183		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.10584347572740183 | validation: 0.11375786639195376]
	TIME [epoch: 8.38 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09184726639521662		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.09184726639521662 | validation: 0.1080828292473319]
	TIME [epoch: 8.36 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09719305817563897		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.09719305817563897 | validation: 0.12893624402571577]
	TIME [epoch: 8.37 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09431429449199756		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.09431429449199756 | validation: 0.10040192130809945]
	TIME [epoch: 8.36 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09842962109419293		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.09842962109419293 | validation: 0.09744673173168057]
	TIME [epoch: 8.38 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11172856532979236		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.11172856532979236 | validation: 0.10041575150940123]
	TIME [epoch: 8.35 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0993539702879253		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.0993539702879253 | validation: 0.14266394284500739]
	TIME [epoch: 8.36 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11078075763828062		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.11078075763828062 | validation: 0.1252447377182798]
	TIME [epoch: 8.36 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10629712913756036		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.10629712913756036 | validation: 0.13394288351929018]
	TIME [epoch: 8.39 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10069251581233574		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.10069251581233574 | validation: 0.12876378940531585]
	TIME [epoch: 8.36 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10919482308203747		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.10919482308203747 | validation: 0.1146221123801284]
	TIME [epoch: 8.36 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10525657297054217		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.10525657297054217 | validation: 0.11594029157965727]
	TIME [epoch: 8.37 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10708545371260683		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.10708545371260683 | validation: 0.11971213050754728]
	TIME [epoch: 8.39 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12383589906445987		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.12383589906445987 | validation: 0.1177316542703174]
	TIME [epoch: 8.37 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10399385270920032		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.10399385270920032 | validation: 0.10223630145905416]
	TIME [epoch: 8.36 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11069514697185719		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.11069514697185719 | validation: 0.1152888238186763]
	TIME [epoch: 8.36 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11448861411116198		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.11448861411116198 | validation: 0.1161237841850808]
	TIME [epoch: 8.39 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1086584272873651		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.1086584272873651 | validation: 0.14023893630261727]
	TIME [epoch: 8.36 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10331560271114293		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.10331560271114293 | validation: 0.12538109445769685]
	TIME [epoch: 8.36 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10307815840446304		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.10307815840446304 | validation: 0.149183103713786]
	TIME [epoch: 8.36 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10384240298723321		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.10384240298723321 | validation: 0.10919342000678453]
	TIME [epoch: 8.38 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10015020441896413		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.10015020441896413 | validation: 0.10231938378920394]
	TIME [epoch: 8.36 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09747345210143452		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.09747345210143452 | validation: 0.11410906707188012]
	TIME [epoch: 8.36 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1099447470824196		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.1099447470824196 | validation: 0.11837287131219912]
	TIME [epoch: 8.36 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461471890743416		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.10461471890743416 | validation: 0.1512767205704355]
	TIME [epoch: 8.38 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10014802438596335		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.10014802438596335 | validation: 0.11223294452683485]
	TIME [epoch: 8.37 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10186469410366483		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.10186469410366483 | validation: 0.11347068771687982]
	TIME [epoch: 8.36 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1197324338512179		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.1197324338512179 | validation: 0.11758438686242931]
	TIME [epoch: 8.38 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11174368352074268		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.11174368352074268 | validation: 0.1205772973384735]
	TIME [epoch: 8.38 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1073173265281093		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.1073173265281093 | validation: 0.13622775249807986]
	TIME [epoch: 8.36 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251945830899553		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.1251945830899553 | validation: 0.1325860084562605]
	TIME [epoch: 8.36 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102596858480626		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.12102596858480626 | validation: 0.11932082839327117]
	TIME [epoch: 8.37 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10264418894999623		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.10264418894999623 | validation: 0.11999476947207699]
	TIME [epoch: 8.38 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10218453408365091		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.10218453408365091 | validation: 0.15522118729922432]
	TIME [epoch: 8.35 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10810036463051642		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.10810036463051642 | validation: 0.11516889559412463]
	TIME [epoch: 8.36 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10667038497748518		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.10667038497748518 | validation: 0.10853866788318026]
	TIME [epoch: 8.37 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10981679435226939		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.10981679435226939 | validation: 0.1137864389357555]
	TIME [epoch: 8.37 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11430521649766964		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.11430521649766964 | validation: 0.11304250469850102]
	TIME [epoch: 8.35 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1074588263214249		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.1074588263214249 | validation: 0.10279702062358068]
	TIME [epoch: 8.35 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09997980206509197		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.09997980206509197 | validation: 0.10999729884602281]
	TIME [epoch: 8.37 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09372937434573705		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.09372937434573705 | validation: 0.11937428396725684]
	TIME [epoch: 8.36 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09588899348247842		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.09588899348247842 | validation: 0.11366720152811641]
	TIME [epoch: 8.36 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09961689543730619		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.09961689543730619 | validation: 0.12233933516450377]
	TIME [epoch: 8.37 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09691665669949853		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.09691665669949853 | validation: 0.11682158298298989]
	TIME [epoch: 8.37 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09174693961061119		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.09174693961061119 | validation: 0.12631145564778865]
	TIME [epoch: 8.37 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10848434554497492		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.10848434554497492 | validation: 0.10535531930989427]
	TIME [epoch: 8.37 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10061434051038347		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.10061434051038347 | validation: 0.12149358748220243]
	TIME [epoch: 8.36 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09975271389758003		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.09975271389758003 | validation: 0.12013538230008627]
	TIME [epoch: 8.38 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11080759146018322		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.11080759146018322 | validation: 0.12495134135785158]
	TIME [epoch: 8.37 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10282326211750673		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.10282326211750673 | validation: 0.11993439264333373]
	TIME [epoch: 8.37 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09777481123319905		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.09777481123319905 | validation: 0.11973237190686446]
	TIME [epoch: 8.37 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10468315012202631		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.10468315012202631 | validation: 0.10702558466186485]
	TIME [epoch: 8.38 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09996183590068178		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.09996183590068178 | validation: 0.11749426785353198]
	TIME [epoch: 8.37 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10143975210706255		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.10143975210706255 | validation: 0.09768097547649246]
	TIME [epoch: 8.37 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10060240806874235		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.10060240806874235 | validation: 0.09266675490050937]
	TIME [epoch: 8.37 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10177994045687391		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.10177994045687391 | validation: 0.11635675100856391]
	TIME [epoch: 8.38 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10851085531554028		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.10851085531554028 | validation: 0.1146122950178014]
	TIME [epoch: 8.37 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10416171138736874		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.10416171138736874 | validation: 0.1083188265782583]
	TIME [epoch: 8.36 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10147642947515331		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.10147642947515331 | validation: 0.1057920161913403]
	TIME [epoch: 8.36 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10331496955741286		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.10331496955741286 | validation: 0.10906385226360742]
	TIME [epoch: 8.39 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10337875365680138		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.10337875365680138 | validation: 0.10318533449038814]
	TIME [epoch: 8.36 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09902007984788384		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.09902007984788384 | validation: 0.10532083496493759]
	TIME [epoch: 8.36 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10228606559779589		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.10228606559779589 | validation: 0.10397802912383214]
	TIME [epoch: 8.37 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10731037200993605		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.10731037200993605 | validation: 0.13711019545609515]
	TIME [epoch: 8.39 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11648990631491067		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.11648990631491067 | validation: 0.13754501370757455]
	TIME [epoch: 8.37 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10789142355363739		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.10789142355363739 | validation: 0.10591727467659603]
	TIME [epoch: 8.36 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09718479825558443		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.09718479825558443 | validation: 0.10884950107548386]
	TIME [epoch: 8.35 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10267709901778214		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.10267709901778214 | validation: 0.11080706967440743]
	TIME [epoch: 8.38 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10406573255883096		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.10406573255883096 | validation: 0.16749645089508192]
	TIME [epoch: 8.36 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10726319713148946		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.10726319713148946 | validation: 0.10003568173321192]
	TIME [epoch: 8.36 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09855989519722443		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.09855989519722443 | validation: 0.10868496384894365]
	TIME [epoch: 8.37 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10156934447231043		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.10156934447231043 | validation: 0.12179970220164157]
	TIME [epoch: 8.38 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09903777967324354		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.09903777967324354 | validation: 0.0988642291236152]
	TIME [epoch: 8.37 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0954877738945717		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.0954877738945717 | validation: 0.10726941208132018]
	TIME [epoch: 8.36 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11665826683100802		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.11665826683100802 | validation: 0.12364877226538923]
	TIME [epoch: 8.37 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10076513528440914		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.10076513528440914 | validation: 0.12130356005242365]
	TIME [epoch: 8.38 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10574290459732942		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.10574290459732942 | validation: 0.10861082812659362]
	TIME [epoch: 8.36 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0954895046724156		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.0954895046724156 | validation: 0.10526990130390865]
	TIME [epoch: 8.36 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09489195819757681		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.09489195819757681 | validation: 0.10298765797694907]
	TIME [epoch: 8.36 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09889050175065989		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.09889050175065989 | validation: 0.12073291138148494]
	TIME [epoch: 8.38 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09739937165262583		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.09739937165262583 | validation: 0.10939804583757054]
	TIME [epoch: 8.36 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09779953761176499		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.09779953761176499 | validation: 0.09645653593487866]
	TIME [epoch: 8.36 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09914107373245731		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.09914107373245731 | validation: 0.11916972507396326]
	TIME [epoch: 8.36 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09519453803729419		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.09519453803729419 | validation: 0.10354077294877945]
	TIME [epoch: 8.38 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09187963594850684		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.09187963594850684 | validation: 0.10377414385111619]
	TIME [epoch: 8.36 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09496204621053887		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.09496204621053887 | validation: 0.10932250682270164]
	TIME [epoch: 8.35 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09680406032375537		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.09680406032375537 | validation: 0.1127820076563583]
	TIME [epoch: 8.36 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10213902414541272		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.10213902414541272 | validation: 0.13324594282860913]
	TIME [epoch: 8.39 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09925909978635786		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.09925909978635786 | validation: 0.10925847802472309]
	TIME [epoch: 8.36 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09547625781249908		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.09547625781249908 | validation: 0.10768368029210958]
	TIME [epoch: 8.35 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09882464628073342		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.09882464628073342 | validation: 0.1156716166479389]
	TIME [epoch: 8.36 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0994347262435987		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.0994347262435987 | validation: 0.09952361454146044]
	TIME [epoch: 8.38 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10044090691164627		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.10044090691164627 | validation: 0.11686554142719649]
	TIME [epoch: 8.35 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1063921343334463		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.1063921343334463 | validation: 0.12816851621032332]
	TIME [epoch: 8.36 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10037057773762859		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.10037057773762859 | validation: 0.11670011485151294]
	TIME [epoch: 8.36 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743699109557317		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.09743699109557317 | validation: 0.1130267281697333]
	TIME [epoch: 8.38 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1051419170395194		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.1051419170395194 | validation: 0.10001910487025263]
	TIME [epoch: 8.36 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09548673764493859		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.09548673764493859 | validation: 0.10975705271463987]
	TIME [epoch: 8.37 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09835556629333628		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.09835556629333628 | validation: 0.10800044793973207]
	TIME [epoch: 8.36 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10202341742153706		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.10202341742153706 | validation: 0.09929319620670302]
	TIME [epoch: 8.39 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09406897644061854		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.09406897644061854 | validation: 0.10292387420475016]
	TIME [epoch: 8.37 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09398376513002996		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.09398376513002996 | validation: 0.12127159118176199]
	TIME [epoch: 8.36 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09988830861559692		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.09988830861559692 | validation: 0.10418212373437119]
	TIME [epoch: 8.36 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09445387866463385		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.09445387866463385 | validation: 0.11220564899787133]
	TIME [epoch: 8.37 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09590539035431651		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.09590539035431651 | validation: 0.11667145131066656]
	TIME [epoch: 8.36 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10046346647420464		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.10046346647420464 | validation: 0.12891670862090515]
	TIME [epoch: 8.36 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10270689551926901		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.10270689551926901 | validation: 0.11433872254581395]
	TIME [epoch: 8.37 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09393308921469293		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.09393308921469293 | validation: 0.10347957767780268]
	TIME [epoch: 8.39 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10439928799603031		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.10439928799603031 | validation: 0.11683037841751262]
	TIME [epoch: 8.37 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09307207642761586		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.09307207642761586 | validation: 0.1212448436167741]
	TIME [epoch: 8.36 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09497102868742632		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.09497102868742632 | validation: 0.09640125691725672]
	TIME [epoch: 8.38 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09102520146460194		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.09102520146460194 | validation: 0.11980505775104261]
	TIME [epoch: 8.37 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09874696775029816		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.09874696775029816 | validation: 0.10206293425004215]
	TIME [epoch: 8.36 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10335992213246228		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.10335992213246228 | validation: 0.10407061736603909]
	TIME [epoch: 8.36 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10120747702739927		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.10120747702739927 | validation: 0.11083992867676956]
	TIME [epoch: 8.38 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09016399243578747		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.09016399243578747 | validation: 0.09920639306660949]
	TIME [epoch: 8.37 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08942111346620975		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.08942111346620975 | validation: 0.11857105745455339]
	TIME [epoch: 8.36 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10407796651412689		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.10407796651412689 | validation: 0.11036484617820386]
	TIME [epoch: 8.36 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09227164272404824		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.09227164272404824 | validation: 0.10899168673487533]
	TIME [epoch: 8.38 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1019337478289869		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.1019337478289869 | validation: 0.11566240353473664]
	TIME [epoch: 8.37 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10865145542159771		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.10865145542159771 | validation: 0.12346139896993025]
	TIME [epoch: 8.37 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09804485034244068		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.09804485034244068 | validation: 0.11707360680266954]
	TIME [epoch: 8.37 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1024799256804025		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.1024799256804025 | validation: 0.11310533533820465]
	TIME [epoch: 8.38 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08999970144810268		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.08999970144810268 | validation: 0.11069870207471305]
	TIME [epoch: 8.37 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10104261147434739		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.10104261147434739 | validation: 0.11145485397227026]
	TIME [epoch: 8.36 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09459227809834271		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.09459227809834271 | validation: 0.10861883181558152]
	TIME [epoch: 8.36 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1147965281612433		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.1147965281612433 | validation: 0.1215383704890115]
	TIME [epoch: 8.38 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09556267871567571		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.09556267871567571 | validation: 0.08960510571536334]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1730.pth
	Model improved!!!
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09688457331796049		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.09688457331796049 | validation: 0.10694446520705245]
	TIME [epoch: 8.37 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09874593721940482		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.09874593721940482 | validation: 0.11413454177687653]
	TIME [epoch: 8.37 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09371985828399382		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.09371985828399382 | validation: 0.1049513613677569]
	TIME [epoch: 8.4 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09733010330510243		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.09733010330510243 | validation: 0.11875516200636421]
	TIME [epoch: 8.38 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09371538075634714		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.09371538075634714 | validation: 0.10816418343534792]
	TIME [epoch: 8.37 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09906475282479538		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.09906475282479538 | validation: 0.09765865692252568]
	TIME [epoch: 8.37 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0992066692363663		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.0992066692363663 | validation: 0.12259338851111262]
	TIME [epoch: 8.4 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10033239903382547		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.10033239903382547 | validation: 0.11310628163034873]
	TIME [epoch: 8.37 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09226258769890702		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.09226258769890702 | validation: 0.10811582911356513]
	TIME [epoch: 8.37 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09799728937874694		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.09799728937874694 | validation: 0.10610307924390122]
	TIME [epoch: 8.36 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0933253699975442		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.0933253699975442 | validation: 0.09957040190964789]
	TIME [epoch: 8.39 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09456606108591378		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.09456606108591378 | validation: 0.09940168018584099]
	TIME [epoch: 8.38 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.098572832302524		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.098572832302524 | validation: 0.1169041716306275]
	TIME [epoch: 8.36 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0956941718355592		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.0956941718355592 | validation: 0.10944560759070465]
	TIME [epoch: 8.37 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09178818220425433		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.09178818220425433 | validation: 0.10901949006772625]
	TIME [epoch: 8.39 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08902362818615298		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.08902362818615298 | validation: 0.1086028244223925]
	TIME [epoch: 8.38 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09290498514919025		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.09290498514919025 | validation: 0.12087103288093282]
	TIME [epoch: 8.37 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09484967447245282		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.09484967447245282 | validation: 0.10188997538290026]
	TIME [epoch: 8.37 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09867950334549162		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.09867950334549162 | validation: 0.12983990143027513]
	TIME [epoch: 8.39 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10003945760721007		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.10003945760721007 | validation: 0.11272676562200777]
	TIME [epoch: 8.37 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10558697401503606		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.10558697401503606 | validation: 0.10667721472042163]
	TIME [epoch: 8.37 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09892034259326118		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.09892034259326118 | validation: 0.09845981422779981]
	TIME [epoch: 8.37 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09647420086713764		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.09647420086713764 | validation: 0.14391867619702786]
	TIME [epoch: 8.39 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09993320118102256		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.09993320118102256 | validation: 0.10967431746799242]
	TIME [epoch: 8.36 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09261208794246156		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.09261208794246156 | validation: 0.1067991922647257]
	TIME [epoch: 8.37 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10521046622035843		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.10521046622035843 | validation: 0.13527951447344566]
	TIME [epoch: 8.38 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10055190552532896		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.10055190552532896 | validation: 0.11385556420735612]
	TIME [epoch: 8.39 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09680359801959529		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.09680359801959529 | validation: 0.10959748436608846]
	TIME [epoch: 8.37 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09589987096396294		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.09589987096396294 | validation: 0.12561758313444973]
	TIME [epoch: 8.38 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10081941091565105		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.10081941091565105 | validation: 0.10075690763591941]
	TIME [epoch: 8.37 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10157868790153737		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.10157868790153737 | validation: 0.1343479512295504]
	TIME [epoch: 8.39 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11873480486135439		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.11873480486135439 | validation: 0.11508395811016034]
	TIME [epoch: 8.37 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1053855481215608		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.1053855481215608 | validation: 0.1079769147581936]
	TIME [epoch: 8.35 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09499149768729484		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.09499149768729484 | validation: 0.10630807228834854]
	TIME [epoch: 8.37 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09269965619816507		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.09269965619816507 | validation: 0.10623273337058327]
	TIME [epoch: 8.39 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09571563046639914		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.09571563046639914 | validation: 0.11636912185395802]
	TIME [epoch: 8.37 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10040835034286252		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.10040835034286252 | validation: 0.12513335908222456]
	TIME [epoch: 8.36 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09338329484346052		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.09338329484346052 | validation: 0.11169371240716208]
	TIME [epoch: 8.37 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09942900045387665		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.09942900045387665 | validation: 0.10103213547778594]
	TIME [epoch: 8.39 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09708806250079105		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.09708806250079105 | validation: 0.11596300033655374]
	TIME [epoch: 8.37 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10134214051096954		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.10134214051096954 | validation: 0.11761203179021763]
	TIME [epoch: 8.37 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09772395705627643		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.09772395705627643 | validation: 0.10499248617240492]
	TIME [epoch: 8.38 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09686658885050449		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.09686658885050449 | validation: 0.09327912461338009]
	TIME [epoch: 8.39 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08685855584530824		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.08685855584530824 | validation: 0.10421542695371608]
	TIME [epoch: 8.37 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09622498321462786		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.09622498321462786 | validation: 0.10372495169705541]
	TIME [epoch: 8.37 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09348708986695466		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.09348708986695466 | validation: 0.11570008292454077]
	TIME [epoch: 8.37 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09598557539024595		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.09598557539024595 | validation: 0.10173521572343858]
	TIME [epoch: 8.38 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10513489413400015		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.10513489413400015 | validation: 0.11994741065512814]
	TIME [epoch: 8.37 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0996663429188948		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.0996663429188948 | validation: 0.12400848007220291]
	TIME [epoch: 8.36 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1020069724193807		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.1020069724193807 | validation: 0.11090507297930033]
	TIME [epoch: 8.38 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09820551851965012		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.09820551851965012 | validation: 0.1294097219969893]
	TIME [epoch: 8.38 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10268294267094655		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.10268294267094655 | validation: 0.11887214663979134]
	TIME [epoch: 8.36 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09418772160481129		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.09418772160481129 | validation: 0.09768953684673122]
	TIME [epoch: 8.37 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09263728868770582		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.09263728868770582 | validation: 0.10316473818814528]
	TIME [epoch: 8.38 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09033787147561179		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.09033787147561179 | validation: 0.11264763322363916]
	TIME [epoch: 8.38 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09033322694682916		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.09033322694682916 | validation: 0.10201472279305554]
	TIME [epoch: 8.36 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09700526721136184		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.09700526721136184 | validation: 0.10424931933982765]
	TIME [epoch: 8.37 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08864369342078836		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.08864369342078836 | validation: 0.10286983669611317]
	TIME [epoch: 8.38 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09089464144599398		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.09089464144599398 | validation: 0.11663913869460035]
	TIME [epoch: 8.37 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0977990289709505		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.0977990289709505 | validation: 0.10829277523594562]
	TIME [epoch: 8.36 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09298988290467167		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.09298988290467167 | validation: 0.10561058606957545]
	TIME [epoch: 8.36 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10286944545276824		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.10286944545276824 | validation: 0.10937554016815836]
	TIME [epoch: 8.39 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09495766093487926		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.09495766093487926 | validation: 0.10390811525353538]
	TIME [epoch: 8.38 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09334685575827027		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.09334685575827027 | validation: 0.09395261509074451]
	TIME [epoch: 8.37 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09261425617495467		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.09261425617495467 | validation: 0.08644978272361004]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r5_20240219_184940/states/model_tr_study4_1795.pth
	Model improved!!!
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09204805161348167		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.09204805161348167 | validation: 0.09630856167229179]
	TIME [epoch: 8.39 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09218232835026297		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.09218232835026297 | validation: 0.1027027709915761]
	TIME [epoch: 8.37 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09186235418403688		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.09186235418403688 | validation: 0.10265022938818397]
	TIME [epoch: 8.36 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09279707989202736		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.09279707989202736 | validation: 0.10567247369048267]
	TIME [epoch: 8.37 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09756721984446388		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.09756721984446388 | validation: 0.10105006731644528]
	TIME [epoch: 8.38 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09543297229121918		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.09543297229121918 | validation: 0.1071006451958286]
	TIME [epoch: 8.37 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09797257924390311		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.09797257924390311 | validation: 0.0990889914141216]
	TIME [epoch: 8.36 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09803023772456089		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.09803023772456089 | validation: 0.10773261105480048]
	TIME [epoch: 8.36 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0948968204982418		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.0948968204982418 | validation: 0.1271679241693721]
	TIME [epoch: 8.38 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1049572553862165		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.1049572553862165 | validation: 0.10133751025932342]
	TIME [epoch: 8.37 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09450760913576708		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.09450760913576708 | validation: 0.10216694748161184]
	TIME [epoch: 8.36 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09181536639473079		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.09181536639473079 | validation: 0.10530701481688826]
	TIME [epoch: 8.37 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09913966546980403		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.09913966546980403 | validation: 0.10189075518188609]
	TIME [epoch: 8.39 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.091738256245298		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.091738256245298 | validation: 0.12124288757551338]
	TIME [epoch: 8.37 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12213393306499472		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.12213393306499472 | validation: 0.12486128284596824]
	TIME [epoch: 8.36 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09886565836991561		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.09886565836991561 | validation: 0.15057149761012217]
	TIME [epoch: 8.36 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10460425253570342		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.10460425253570342 | validation: 0.10469271379462256]
	TIME [epoch: 8.39 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09422080373319296		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.09422080373319296 | validation: 0.11023693973930795]
	TIME [epoch: 8.37 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10244016585253994		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.10244016585253994 | validation: 0.1463863203564348]
	TIME [epoch: 8.36 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10368876614472174		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.10368876614472174 | validation: 0.10315761299104093]
	TIME [epoch: 8.37 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10086905965334092		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.10086905965334092 | validation: 0.10203585644869675]
	TIME [epoch: 8.38 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0938020847550927		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.0938020847550927 | validation: 0.10643932024819448]
	TIME [epoch: 8.37 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10117897562474068		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.10117897562474068 | validation: 0.11055240301303078]
	TIME [epoch: 8.36 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09444529195269052		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.09444529195269052 | validation: 0.10463856080563536]
	TIME [epoch: 8.37 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09305554686737891		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.09305554686737891 | validation: 0.10997434817507358]
	TIME [epoch: 8.39 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09624902174778008		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.09624902174778008 | validation: 0.10716687647583079]
	TIME [epoch: 8.36 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0967817074882101		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.0967817074882101 | validation: 0.1028579473319644]
	TIME [epoch: 8.37 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09932273558505153		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.09932273558505153 | validation: 0.10652221796464423]
	TIME [epoch: 8.37 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09603834259179031		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.09603834259179031 | validation: 0.11019551054430105]
	TIME [epoch: 8.38 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1053209114986797		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.1053209114986797 | validation: 0.1087832009116623]
	TIME [epoch: 8.36 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09359583716354072		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.09359583716354072 | validation: 0.09588847582368827]
	TIME [epoch: 8.36 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08931369978142042		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.08931369978142042 | validation: 0.09420081568990318]
	TIME [epoch: 8.36 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09505901942900562		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.09505901942900562 | validation: 0.1047240670863816]
	TIME [epoch: 8.39 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09541547493717883		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.09541547493717883 | validation: 0.10395920837582781]
	TIME [epoch: 8.36 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09380574053594339		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.09380574053594339 | validation: 0.1084747790321197]
	TIME [epoch: 8.37 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09777129154461692		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.09777129154461692 | validation: 0.09901317398226536]
	TIME [epoch: 8.36 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09115861286743074		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.09115861286743074 | validation: 0.10232382258326433]
	TIME [epoch: 8.38 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0972070617007941		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.0972070617007941 | validation: 0.11272158113891712]
	TIME [epoch: 8.36 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09692098902359512		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.09692098902359512 | validation: 0.10520762509574379]
	TIME [epoch: 8.37 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09339937717885155		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.09339937717885155 | validation: 0.11661345003907031]
	TIME [epoch: 8.36 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09486349306931421		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.09486349306931421 | validation: 0.0937900455561376]
	TIME [epoch: 8.39 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09446045655969507		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.09446045655969507 | validation: 0.09853905785571403]
	TIME [epoch: 8.37 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09327164319854075		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.09327164319854075 | validation: 0.11938683258489877]
	TIME [epoch: 8.36 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09266377618956764		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.09266377618956764 | validation: 0.09352662652379146]
	TIME [epoch: 8.36 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09155869790924255		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.09155869790924255 | validation: 0.09221461706540253]
	TIME [epoch: 8.39 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08955588803796126		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.08955588803796126 | validation: 0.11014135656358649]
	TIME [epoch: 8.35 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09882578747076869		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.09882578747076869 | validation: 0.0924038109964394]
	TIME [epoch: 8.37 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0846191386236712		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.0846191386236712 | validation: 0.10136535744579615]
	TIME [epoch: 8.37 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09358645166595311		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.09358645166595311 | validation: 0.08868540469756625]
	TIME [epoch: 8.38 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0872792017092361		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.0872792017092361 | validation: 0.09879259813729056]
	TIME [epoch: 8.36 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09460170840089954		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.09460170840089954 | validation: 0.0948680448114682]
	TIME [epoch: 8.36 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09525011921712905		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.09525011921712905 | validation: 0.09905629451704283]
	TIME [epoch: 8.37 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09207506920798295		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.09207506920798295 | validation: 0.09891411857633245]
	TIME [epoch: 8.38 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09211517699998288		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.09211517699998288 | validation: 0.09512160928246308]
	TIME [epoch: 8.37 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09882835373149196		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.09882835373149196 | validation: 0.09229154245325749]
	TIME [epoch: 8.36 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10443122975950517		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.10443122975950517 | validation: 0.10542277256992463]
	TIME [epoch: 8.38 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0998153952113914		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.0998153952113914 | validation: 0.10084473494134047]
	TIME [epoch: 8.37 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09785713892953712		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.09785713892953712 | validation: 0.11251894036835898]
	TIME [epoch: 8.35 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0919892601490571		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.0919892601490571 | validation: 0.10465242638511896]
	TIME [epoch: 8.36 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997257159356614		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.0997257159356614 | validation: 0.1127493750439304]
	TIME [epoch: 8.38 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09972250013698683		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.09972250013698683 | validation: 0.10762829126713808]
	TIME [epoch: 8.38 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09051939010935608		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.09051939010935608 | validation: 0.11159462428722156]
	TIME [epoch: 8.37 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09169042491513468		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.09169042491513468 | validation: 0.11215967387846804]
	TIME [epoch: 8.36 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09814635069204339		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.09814635069204339 | validation: 0.08854327968166238]
	TIME [epoch: 8.38 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09237385554217568		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.09237385554217568 | validation: 0.09316191192057954]
	TIME [epoch: 8.38 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0922463844358177		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.0922463844358177 | validation: 0.10742678979601963]
	TIME [epoch: 8.36 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09010314094853175		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.09010314094853175 | validation: 0.11364985253848503]
	TIME [epoch: 8.37 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09042242942862086		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.09042242942862086 | validation: 0.10138818692249513]
	TIME [epoch: 8.38 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09823565243242745		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.09823565243242745 | validation: 0.11702792897872438]
	TIME [epoch: 8.38 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09298406559779707		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.09298406559779707 | validation: 0.10530675489340605]
	TIME [epoch: 8.36 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09965331402667918		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.09965331402667918 | validation: 0.11545465134195629]
	TIME [epoch: 8.36 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10071729876473301		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.10071729876473301 | validation: 0.09716904804430043]
	TIME [epoch: 8.38 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09397334525814485		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.09397334525814485 | validation: 0.09389211792396204]
	TIME [epoch: 8.37 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09441356100670814		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.09441356100670814 | validation: 0.10149665258977096]
	TIME [epoch: 8.36 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09379980668862681		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.09379980668862681 | validation: 0.11182595161061887]
	TIME [epoch: 8.36 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09956064106414096		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.09956064106414096 | validation: 0.09665238865416886]
	TIME [epoch: 8.38 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09841987515393069		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.09841987515393069 | validation: 0.10783477335081186]
	TIME [epoch: 8.37 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09392619390797396		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.09392619390797396 | validation: 0.09216929709011148]
	TIME [epoch: 8.36 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08809203896881997		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.08809203896881997 | validation: 0.0999564877642238]
	TIME [epoch: 8.37 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09116307511617801		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.09116307511617801 | validation: 0.10464566700637591]
	TIME [epoch: 8.38 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09434633043653429		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.09434633043653429 | validation: 0.101991905708692]
	TIME [epoch: 8.37 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08895542876799485		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.08895542876799485 | validation: 0.10556266560443132]
	TIME [epoch: 8.36 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09968872415474875		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.09968872415474875 | validation: 0.12119109716666915]
	TIME [epoch: 8.37 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0934609485826812		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.0934609485826812 | validation: 0.10876411147949512]
	TIME [epoch: 8.39 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10088267584734507		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.10088267584734507 | validation: 0.12761810896602088]
	TIME [epoch: 8.37 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09466007775609486		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.09466007775609486 | validation: 0.10336477883028297]
	TIME [epoch: 8.36 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09519814443440125		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.09519814443440125 | validation: 0.10535183108874022]
	TIME [epoch: 8.36 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08842564135276158		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.08842564135276158 | validation: 0.097683835606416]
	TIME [epoch: 8.38 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09231715777651991		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.09231715777651991 | validation: 0.10389919787376771]
	TIME [epoch: 8.35 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10279838915753814		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.10279838915753814 | validation: 0.10563635674096158]
	TIME [epoch: 8.36 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09841226509800302		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.09841226509800302 | validation: 0.1066226023188418]
	TIME [epoch: 8.36 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09261481563453683		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.09261481563453683 | validation: 0.1040054522303599]
	TIME [epoch: 8.39 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09297624607317216		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.09297624607317216 | validation: 0.11398610918007746]
	TIME [epoch: 8.37 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10840277984739352		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.10840277984739352 | validation: 0.10368943647137357]
	TIME [epoch: 8.37 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08812948862426415		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.08812948862426415 | validation: 0.0959441946267167]
	TIME [epoch: 8.37 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09112048693140126		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.09112048693140126 | validation: 0.10904401763453213]
	TIME [epoch: 8.38 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09436018611992976		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.09436018611992976 | validation: 0.10299988083067464]
	TIME [epoch: 8.37 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08912865087738782		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.08912865087738782 | validation: 0.09283279448780293]
	TIME [epoch: 8.36 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09759353220731468		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.09759353220731468 | validation: 0.14229015480295154]
	TIME [epoch: 8.36 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10742214640317974		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.10742214640317974 | validation: 0.09969684252088684]
	TIME [epoch: 8.38 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08888554676614606		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.08888554676614606 | validation: 0.1157042380901835]
	TIME [epoch: 8.36 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0970691053904416		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.0970691053904416 | validation: 0.09598372090579363]
	TIME [epoch: 8.36 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09752683217589574		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.09752683217589574 | validation: 0.10962926055794381]
	TIME [epoch: 8.36 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0893120681150918		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.0893120681150918 | validation: 0.09676415722228181]
	TIME [epoch: 8.39 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09860880194003589		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.09860880194003589 | validation: 0.09926098405789939]
	TIME [epoch: 8.37 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08859961438919124		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.08859961438919124 | validation: 0.09795971599087769]
	TIME [epoch: 8.36 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08868343697561468		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.08868343697561468 | validation: 0.1119473429985115]
	TIME [epoch: 8.36 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09206525351560943		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.09206525351560943 | validation: 0.11434780553164763]
	TIME [epoch: 8.39 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09044564148051049		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.09044564148051049 | validation: 0.10961893870176867]
	TIME [epoch: 8.36 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09245133275016564		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.09245133275016564 | validation: 0.11495903529168955]
	TIME [epoch: 8.36 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.093073149742585		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.093073149742585 | validation: 0.09686597827156329]
	TIME [epoch: 8.36 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0900107326862459		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.0900107326862459 | validation: 0.09717119315996514]
	TIME [epoch: 8.39 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09510384708564626		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.09510384708564626 | validation: 0.10392351512900926]
	TIME [epoch: 8.37 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.094773980250265		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.094773980250265 | validation: 0.1036269111073415]
	TIME [epoch: 8.36 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09325784374613354		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.09325784374613354 | validation: 0.11798069307255932]
	TIME [epoch: 8.36 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09053616773129493		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.09053616773129493 | validation: 0.1135953992199089]
	TIME [epoch: 8.38 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09954445935914766		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.09954445935914766 | validation: 0.09362862154763316]
	TIME [epoch: 8.37 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09009311497479142		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.09009311497479142 | validation: 0.10011517614825327]
	TIME [epoch: 8.36 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09183403096942974		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.09183403096942974 | validation: 0.1150722640657222]
	TIME [epoch: 8.37 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09282243347625221		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.09282243347625221 | validation: 0.10720764057788594]
	TIME [epoch: 8.38 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08823162175483244		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.08823162175483244 | validation: 0.1045781055605363]
	TIME [epoch: 8.36 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09516619228505514		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.09516619228505514 | validation: 0.12167358289682625]
	TIME [epoch: 8.36 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09465792391912141		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.09465792391912141 | validation: 0.10472808931048082]
	TIME [epoch: 8.37 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08936739196460454		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.08936739196460454 | validation: 0.10483271843327865]
	TIME [epoch: 8.38 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09498264121357873		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.09498264121357873 | validation: 0.11428266884235938]
	TIME [epoch: 8.36 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0929001862807767		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.0929001862807767 | validation: 0.09585499221660485]
	TIME [epoch: 8.37 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09145008912039604		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.09145008912039604 | validation: 0.11685705202761629]
	TIME [epoch: 8.38 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09662072586074512		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.09662072586074512 | validation: 0.09904268323095074]
	TIME [epoch: 8.38 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09565795264198179		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.09565795264198179 | validation: 0.10766372741700045]
	TIME [epoch: 8.36 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09026114852399639		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.09026114852399639 | validation: 0.1034460363877104]
	TIME [epoch: 8.37 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09630160544884508		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.09630160544884508 | validation: 0.11603448001497639]
	TIME [epoch: 8.38 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09724656572299069		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.09724656572299069 | validation: 0.12066209085070644]
	TIME [epoch: 8.38 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08738634001890419		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.08738634001890419 | validation: 0.10194479898883696]
	TIME [epoch: 8.36 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09195192427473337		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.09195192427473337 | validation: 0.11253861800410676]
	TIME [epoch: 8.37 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09739995863512632		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.09739995863512632 | validation: 0.10521228428448007]
	TIME [epoch: 8.38 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09303777395261621		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.09303777395261621 | validation: 0.1073696111808414]
	TIME [epoch: 8.38 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09037793868347319		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.09037793868347319 | validation: 0.09343965371619155]
	TIME [epoch: 8.36 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08936717924835749		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.08936717924835749 | validation: 0.09639048278529377]
	TIME [epoch: 8.37 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09273991337832241		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.09273991337832241 | validation: 0.10519184991412583]
	TIME [epoch: 8.38 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09707873142462162		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.09707873142462162 | validation: 0.11197101949728949]
	TIME [epoch: 8.37 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10496153634189173		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.10496153634189173 | validation: 0.10808883737982898]
	TIME [epoch: 8.37 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936641294640003		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.0936641294640003 | validation: 0.10442651708308315]
	TIME [epoch: 8.36 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09878473701873587		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.09878473701873587 | validation: 0.09297721086612]
	TIME [epoch: 8.38 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09608673150095856		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.09608673150095856 | validation: 0.10321475917461465]
	TIME [epoch: 8.38 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09720969525776138		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.09720969525776138 | validation: 0.10501200247442796]
	TIME [epoch: 8.37 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08466620447317949		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.08466620447317949 | validation: 0.10162067704565172]
	TIME [epoch: 8.38 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09597984480249247		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.09597984480249247 | validation: 0.11738940204623535]
	TIME [epoch: 8.4 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08935985702090919		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.08935985702090919 | validation: 0.10509537992981613]
	TIME [epoch: 8.37 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08833631927270845		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.08833631927270845 | validation: 0.09114152215773771]
	TIME [epoch: 8.38 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0909542143488928		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.0909542143488928 | validation: 0.09263271464691866]
	TIME [epoch: 8.37 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08595804529791104		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.08595804529791104 | validation: 0.09719106202657277]
	TIME [epoch: 8.39 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09005753283213717		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.09005753283213717 | validation: 0.09818797371934372]
	TIME [epoch: 8.38 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09103608289583277		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.09103608289583277 | validation: 0.10900353674987319]
	TIME [epoch: 8.37 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09358393837862215		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.09358393837862215 | validation: 0.09532467131439509]
	TIME [epoch: 8.37 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09257100717302111		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.09257100717302111 | validation: 0.10940300956216491]
	TIME [epoch: 8.39 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940236174190668		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.0940236174190668 | validation: 0.09775750297479743]
	TIME [epoch: 8.37 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08865036451391548		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.08865036451391548 | validation: 0.10619976857605137]
	TIME [epoch: 8.37 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09370751867078363		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.09370751867078363 | validation: 0.11173577026226017]
	TIME [epoch: 8.36 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09713245494105567		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.09713245494105567 | validation: 0.1135193897447076]
	TIME [epoch: 8.39 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08922795360616		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.08922795360616 | validation: 0.10248941903889433]
	TIME [epoch: 8.37 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09016291330410928		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.09016291330410928 | validation: 0.10423794178985096]
	TIME [epoch: 8.37 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09263847691225204		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.09263847691225204 | validation: 0.11292851952987817]
	TIME [epoch: 8.36 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0919675709137174		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.0919675709137174 | validation: 0.10750225291675586]
	TIME [epoch: 8.39 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09237869203142121		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.09237869203142121 | validation: 0.10563418311724784]
	TIME [epoch: 8.37 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09232946339805823		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.09232946339805823 | validation: 0.0975025167957888]
	TIME [epoch: 8.37 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09102222344535361		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.09102222344535361 | validation: 0.0998938992486485]
	TIME [epoch: 8.37 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09132691130193321		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.09132691130193321 | validation: 0.10411436441684317]
	TIME [epoch: 8.39 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09244341281233061		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.09244341281233061 | validation: 0.09871690084291751]
	TIME [epoch: 8.36 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09126766065523827		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.09126766065523827 | validation: 0.1020041407112375]
	TIME [epoch: 8.37 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09468018740733045		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.09468018740733045 | validation: 0.11223174683430637]
	TIME [epoch: 8.37 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09554137542381233		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.09554137542381233 | validation: 0.10681952705484575]
	TIME [epoch: 8.39 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09350752345434084		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.09350752345434084 | validation: 0.09203566170767206]
	TIME [epoch: 8.36 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09847821577902856		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.09847821577902856 | validation: 0.10311784438410379]
	TIME [epoch: 8.37 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08737991498934428		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.08737991498934428 | validation: 0.09676927124567902]
	TIME [epoch: 8.37 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09055481653146877		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.09055481653146877 | validation: 0.10722764122898665]
	TIME [epoch: 8.39 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09646985767023977		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.09646985767023977 | validation: 0.0946477325797552]
	TIME [epoch: 8.37 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0925306522458769		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.0925306522458769 | validation: 0.09955286788911769]
	TIME [epoch: 8.37 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09342329796799366		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.09342329796799366 | validation: 0.09861847537840421]
	TIME [epoch: 8.36 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09067943802659775		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.09067943802659775 | validation: 0.09604193147393734]
	TIME [epoch: 8.39 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09818803408830074		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.09818803408830074 | validation: 0.10148736264576155]
	TIME [epoch: 8.37 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09135805577179826		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.09135805577179826 | validation: 0.10722783028597367]
	TIME [epoch: 8.37 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0986390053325768		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.0986390053325768 | validation: 0.09445231569857651]
	TIME [epoch: 8.37 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09463647513124566		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.09463647513124566 | validation: 0.10275092745557986]
	TIME [epoch: 8.4 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08983079902797594		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.08983079902797594 | validation: 0.10762773959457467]
	TIME [epoch: 8.36 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09267291165256385		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.09267291165256385 | validation: 0.11064282860467824]
	TIME [epoch: 8.36 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10029746043447789		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.10029746043447789 | validation: 0.11114260334539737]
	TIME [epoch: 8.38 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09837258926533313		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.09837258926533313 | validation: 0.10480380691023244]
	TIME [epoch: 8.39 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0916561246235023		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.0916561246235023 | validation: 0.10995618855635368]
	TIME [epoch: 8.37 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09371175920717871		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.09371175920717871 | validation: 0.1073172381022998]
	TIME [epoch: 8.37 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09544473682711552		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.09544473682711552 | validation: 0.10535819667885632]
	TIME [epoch: 8.37 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09359913690969021		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.09359913690969021 | validation: 0.11603819765853693]
	TIME [epoch: 8.38 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10233666665403525		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.10233666665403525 | validation: 0.11855029032394482]
	TIME [epoch: 8.37 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09954156641919305		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.09954156641919305 | validation: 0.11875271012024774]
	TIME [epoch: 8.36 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09526019436846886		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.09526019436846886 | validation: 0.0963854694530421]
	TIME [epoch: 8.37 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09718630886425621		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.09718630886425621 | validation: 0.1143687473404709]
	TIME [epoch: 8.39 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09370425083028056		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.09370425083028056 | validation: 0.11788647508922495]
	TIME [epoch: 8.37 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743309814385809		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.09743309814385809 | validation: 0.10884114188211738]
	TIME [epoch: 8.37 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09629522611307346		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.09629522611307346 | validation: 0.11426277371114112]
	TIME [epoch: 8.37 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08974975580894008		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.08974975580894008 | validation: 0.10044441629311492]
	TIME [epoch: 8.37 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09148398014337365		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.09148398014337365 | validation: 0.09397637198111727]
	TIME [epoch: 8.37 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.093812084920326		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.093812084920326 | validation: 0.1021727582675814]
	TIME [epoch: 8.37 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08985495219677064		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.08985495219677064 | validation: 0.10268635061187069]
	TIME [epoch: 8.38 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0888960064568583		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.0888960064568583 | validation: 0.11445922948866508]
	TIME [epoch: 8.38 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09724177780617838		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.09724177780617838 | validation: 0.0993026579513619]
	TIME [epoch: 8.37 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09375583993679294		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.09375583993679294 | validation: 0.09644244404749232]
	TIME [epoch: 8.36 sec]
Finished training in 16924.440 seconds.
