Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3129299177

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.780337284336131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.780337284336131 | validation: 8.460503308148617]
	TIME [epoch: 79.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.108273597690765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.108273597690765 | validation: 8.17047477177563]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.584955252480983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.584955252480983 | validation: 7.686475765964992]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.982527793737373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.982527793737373 | validation: 6.465673599466419]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.5460240318618315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5460240318618315 | validation: 6.382314567247942]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.3451014026703785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3451014026703785 | validation: 6.685637518105098]
	TIME [epoch: 8.32 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.175042992174939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.175042992174939 | validation: 7.966924478526558]
	TIME [epoch: 8.32 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.538634846051823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.538634846051823 | validation: 7.214026095621736]
	TIME [epoch: 8.32 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.099510303118865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.099510303118865 | validation: 6.3583146923719465]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.118346314003931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.118346314003931 | validation: 6.115757625950062]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.066899224184668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.066899224184668 | validation: 6.085775841183702]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.022797899284747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.022797899284747 | validation: 6.235785086876402]
	TIME [epoch: 8.33 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.912398675148191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.912398675148191 | validation: 6.126905218624232]
	TIME [epoch: 8.33 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.821938347196307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.821938347196307 | validation: 6.382075050731787]
	TIME [epoch: 8.31 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.866580777019019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.866580777019019 | validation: 5.841501807591281]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.579727181143135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.579727181143135 | validation: 5.6196468885586]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.4461808867499375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4461808867499375 | validation: 4.893726198645746]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.964639834985494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.964639834985494 | validation: 4.710098830505137]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.989114760421599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.989114760421599 | validation: 4.363360382012205]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.8480207940578985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8480207940578985 | validation: 4.226562418256375]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.211134093824536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.211134093824536 | validation: 4.361258883619509]
	TIME [epoch: 8.32 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9280634620043884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9280634620043884 | validation: 3.8857486833187895]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9516968305567324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9516968305567324 | validation: 4.104237594754945]
	TIME [epoch: 8.31 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6816290893102774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6816290893102774 | validation: 3.825878601419489]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.548732487954177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.548732487954177 | validation: 2.754427646499985]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1643894004343363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1643894004343363 | validation: 1.3322566493061943]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4030047623997333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4030047623997333 | validation: 1.3082206046798306]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2286156039482958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2286156039482958 | validation: 1.4173996537087472]
	TIME [epoch: 8.33 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2196087595396539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2196087595396539 | validation: 2.0652508829620784]
	TIME [epoch: 8.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.266653610105696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.266653610105696 | validation: 1.4093347781675465]
	TIME [epoch: 8.31 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3127958558078332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3127958558078332 | validation: 1.1742729541793633]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3778219782024632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3778219782024632 | validation: 1.0758792890053424]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2676981972301906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2676981972301906 | validation: 0.7700777328048933]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2814462834464166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2814462834464166 | validation: 1.8754278877450383]
	TIME [epoch: 8.31 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3086402109712632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3086402109712632 | validation: 1.5996878187934054]
	TIME [epoch: 8.32 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0004179706300174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0004179706300174 | validation: 0.8231131303101292]
	TIME [epoch: 8.31 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.219515517454193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.219515517454193 | validation: 0.9325502754247025]
	TIME [epoch: 8.31 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0844462648176663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0844462648176663 | validation: 0.9883088428784302]
	TIME [epoch: 8.31 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0772218082130118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0772218082130118 | validation: 0.8616870749682326]
	TIME [epoch: 8.33 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.006861594096216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.006861594096216 | validation: 0.8482158352391076]
	TIME [epoch: 8.31 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2299592783346855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2299592783346855 | validation: 1.6152559835552867]
	TIME [epoch: 8.3 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.030762630408624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.030762630408624 | validation: 0.995330964205517]
	TIME [epoch: 8.31 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0095127017750787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0095127017750787 | validation: 0.7358058533160211]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9424948745720336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9424948745720336 | validation: 0.6823429881818692]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3593284490013489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3593284490013489 | validation: 0.660331605852577]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9991637698927741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9991637698927741 | validation: 0.7865999907348491]
	TIME [epoch: 8.32 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6053917361283077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6053917361283077 | validation: 1.395943993675117]
	TIME [epoch: 8.34 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2564970890433869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2564970890433869 | validation: 0.729889189458302]
	TIME [epoch: 8.32 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9802315842991842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9802315842991842 | validation: 1.9526809964486005]
	TIME [epoch: 8.32 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9947269739932809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9947269739932809 | validation: 0.8269130308190045]
	TIME [epoch: 8.32 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3246935881119828		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 1.3246935881119828 | validation: 0.7150610513278464]
	TIME [epoch: 8.35 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9863469316117242		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 0.9863469316117242 | validation: 0.6497399334789413]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9950323463052746		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 0.9950323463052746 | validation: 0.5562407270352142]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8426361818907285		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 0.8426361818907285 | validation: 0.6850051012938878]
	TIME [epoch: 8.32 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6936729886328934		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 0.6936729886328934 | validation: 0.5374583924397367]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.062510260619702		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 1.062510260619702 | validation: 1.319332529169619]
	TIME [epoch: 8.32 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8036474821266157		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 0.8036474821266157 | validation: 0.481758600229798]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7071699205068823		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 0.7071699205068823 | validation: 0.5863294007761939]
	TIME [epoch: 8.32 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7043385712118486		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 0.7043385712118486 | validation: 0.41950337553404793]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.620874349399317		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 0.620874349399317 | validation: 1.2755062699480582]
	TIME [epoch: 8.31 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6463185201643357		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 0.6463185201643357 | validation: 0.6755202331049646]
	TIME [epoch: 8.31 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6890174125093188		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 0.6890174125093188 | validation: 0.6028162190847577]
	TIME [epoch: 8.32 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8844974333216248		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 0.8844974333216248 | validation: 0.5605014942558476]
	TIME [epoch: 8.33 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.748044690780487		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 0.748044690780487 | validation: 0.5364877880059307]
	TIME [epoch: 8.31 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5945244669534283		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 0.5945244669534283 | validation: 0.32518156479217997]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5998968696550184		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 0.5998968696550184 | validation: 1.0583448885406899]
	TIME [epoch: 8.33 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6772994855845832		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 0.6772994855845832 | validation: 0.5885959300233135]
	TIME [epoch: 8.31 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.774954267800014		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 0.774954267800014 | validation: 0.5427685169712549]
	TIME [epoch: 8.31 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554412566924609		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 0.5554412566924609 | validation: 1.0673951904970647]
	TIME [epoch: 8.31 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.698324830862129		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 0.698324830862129 | validation: 0.39899137970689574]
	TIME [epoch: 8.32 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5249147850658761		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 0.5249147850658761 | validation: 0.38639602848764365]
	TIME [epoch: 8.32 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5173271072784729		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 0.5173271072784729 | validation: 0.49368796567297735]
	TIME [epoch: 8.31 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6080882408641377		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 0.6080882408641377 | validation: 0.3401140185329809]
	TIME [epoch: 8.31 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5753927442516924		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 0.5753927442516924 | validation: 1.0113412300633258]
	TIME [epoch: 8.32 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7208809877509706		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 0.7208809877509706 | validation: 0.7505673393292817]
	TIME [epoch: 8.31 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7507012151056285		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 0.7507012151056285 | validation: 0.7819615771779507]
	TIME [epoch: 8.31 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5822021288250182		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 0.5822021288250182 | validation: 1.1307276194737876]
	TIME [epoch: 8.31 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6451422767381384		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 0.6451422767381384 | validation: 0.5988631922840859]
	TIME [epoch: 8.33 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5481642674681154		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 0.5481642674681154 | validation: 0.4092926439235113]
	TIME [epoch: 8.32 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5836429835867127		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 0.5836429835867127 | validation: 0.8888711362233264]
	TIME [epoch: 8.31 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5418983647290816		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 0.5418983647290816 | validation: 0.3635260221865362]
	TIME [epoch: 8.31 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6310816600973485		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 0.6310816600973485 | validation: 0.49433354593586054]
	TIME [epoch: 8.33 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.573856644398041		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 0.573856644398041 | validation: 0.3984689171453186]
	TIME [epoch: 8.32 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48260677872175134		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 0.48260677872175134 | validation: 0.5784253450734802]
	TIME [epoch: 8.31 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8616958794268411		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 0.8616958794268411 | validation: 0.5343154275801353]
	TIME [epoch: 8.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7172096032539181		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 0.7172096032539181 | validation: 0.839150552527883]
	TIME [epoch: 8.32 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.690504341783589		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 0.690504341783589 | validation: 0.669952355340821]
	TIME [epoch: 8.32 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4574163143321706		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 0.4574163143321706 | validation: 0.4701115122973266]
	TIME [epoch: 8.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5461811178659284		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 0.5461811178659284 | validation: 0.42073413158863693]
	TIME [epoch: 8.31 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5094559577771162		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 0.5094559577771162 | validation: 0.2915149553281023]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5533666898285536		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 0.5533666898285536 | validation: 1.2965915586238062]
	TIME [epoch: 8.32 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5762295173777983		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 0.5762295173777983 | validation: 0.45313567460530835]
	TIME [epoch: 8.31 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44142215699093895		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.44142215699093895 | validation: 0.3495623423021771]
	TIME [epoch: 8.31 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47784688246737916		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 0.47784688246737916 | validation: 0.6336352458572128]
	TIME [epoch: 8.32 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48571510328908357		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 0.48571510328908357 | validation: 0.2921469328534772]
	TIME [epoch: 8.33 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5113161132037569		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 0.5113161132037569 | validation: 0.49074980593243045]
	TIME [epoch: 8.31 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6171922865805923		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 0.6171922865805923 | validation: 0.2501503561185581]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46669509916566143		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 0.46669509916566143 | validation: 0.4788953619929457]
	TIME [epoch: 8.33 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6376593122955183		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 0.6376593122955183 | validation: 0.5812942175908096]
	TIME [epoch: 8.32 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4868925290172473		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 0.4868925290172473 | validation: 0.6551178701527194]
	TIME [epoch: 8.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4168520401826017		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 0.4168520401826017 | validation: 0.8774510865565806]
	TIME [epoch: 8.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4815830504185742		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 0.4815830504185742 | validation: 1.1962048181651483]
	TIME [epoch: 8.32 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275690935928309		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 0.5275690935928309 | validation: 0.3269243652611912]
	TIME [epoch: 8.32 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4582307685199978		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 0.4582307685199978 | validation: 0.8191050372609212]
	TIME [epoch: 8.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.533209743209785		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 0.533209743209785 | validation: 0.8218603184058771]
	TIME [epoch: 8.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5809797661239868		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 0.5809797661239868 | validation: 0.7212494593288195]
	TIME [epoch: 8.32 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5918876795253126		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 0.5918876795253126 | validation: 0.5123216496779537]
	TIME [epoch: 8.32 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4526953058261336		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 0.4526953058261336 | validation: 0.3124450494169509]
	TIME [epoch: 8.31 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36920748310482054		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 0.36920748310482054 | validation: 0.35210181059623935]
	TIME [epoch: 8.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40345509298539134		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 0.40345509298539134 | validation: 0.35297746187331225]
	TIME [epoch: 8.32 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43460644391647857		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 0.43460644391647857 | validation: 0.3172035011074982]
	TIME [epoch: 8.31 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44399594165133693		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 0.44399594165133693 | validation: 0.2577548181055808]
	TIME [epoch: 8.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47492588237174244		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 0.47492588237174244 | validation: 0.39469144709229453]
	TIME [epoch: 8.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44724921100963655		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 0.44724921100963655 | validation: 0.3671389513430201]
	TIME [epoch: 8.32 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4681728008237166		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 0.4681728008237166 | validation: 0.2760004032510116]
	TIME [epoch: 8.31 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41996882402070257		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 0.41996882402070257 | validation: 0.2893057094899598]
	TIME [epoch: 8.31 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39643539837684194		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.39643539837684194 | validation: 0.5776374048887578]
	TIME [epoch: 8.32 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40823436347195363		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 0.40823436347195363 | validation: 0.5324298622849837]
	TIME [epoch: 8.32 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4277021441219636		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 0.4277021441219636 | validation: 1.4115234044226042]
	TIME [epoch: 8.31 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5735536252189285		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 0.5735536252189285 | validation: 0.26559828560583004]
	TIME [epoch: 8.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45649736026817234		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 0.45649736026817234 | validation: 0.3514219663268097]
	TIME [epoch: 8.31 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4934504852605152		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 0.4934504852605152 | validation: 0.4476760790053834]
	TIME [epoch: 8.33 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4407936095083261		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 0.4407936095083261 | validation: 0.3425818763824622]
	TIME [epoch: 8.31 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.532500909662469		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.532500909662469 | validation: 0.3102500175569486]
	TIME [epoch: 8.31 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35082766155292544		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.35082766155292544 | validation: 0.4930220038020214]
	TIME [epoch: 8.31 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7054152188001848		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 0.7054152188001848 | validation: 0.3218325656707832]
	TIME [epoch: 8.33 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4471478941592081		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 0.4471478941592081 | validation: 0.5171371048416274]
	TIME [epoch: 8.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39195935044412383		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.39195935044412383 | validation: 0.33926444069641737]
	TIME [epoch: 8.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47484152355042547		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 0.47484152355042547 | validation: 0.49514697817102316]
	TIME [epoch: 8.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4064297581546777		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 0.4064297581546777 | validation: 0.5166331661533946]
	TIME [epoch: 8.33 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5544648427837093		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.5544648427837093 | validation: 0.4139766109934836]
	TIME [epoch: 8.31 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3824398003986168		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.3824398003986168 | validation: 0.4591207651920647]
	TIME [epoch: 8.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.401208755015963		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.401208755015963 | validation: 0.38341397015429995]
	TIME [epoch: 8.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4748382493478774		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.4748382493478774 | validation: 0.2914516833979058]
	TIME [epoch: 8.32 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3486641406716896		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.3486641406716896 | validation: 0.48937550955736464]
	TIME [epoch: 8.31 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4961660262241768		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.4961660262241768 | validation: 0.42011953759137366]
	TIME [epoch: 8.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40302983015301014		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 0.40302983015301014 | validation: 0.33192826397844155]
	TIME [epoch: 8.31 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6646074164048006		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 0.6646074164048006 | validation: 1.2087995946769403]
	TIME [epoch: 8.33 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5296911849276468		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 0.5296911849276468 | validation: 0.3615817197383498]
	TIME [epoch: 8.31 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5630206038445714		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.5630206038445714 | validation: 0.313455882762912]
	TIME [epoch: 8.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3714993602847243		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.3714993602847243 | validation: 0.3558145596201256]
	TIME [epoch: 8.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3401652006976564		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 0.3401652006976564 | validation: 0.6157943697220927]
	TIME [epoch: 8.33 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4497980548250121		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.4497980548250121 | validation: 0.43063855782208305]
	TIME [epoch: 8.31 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36815325985888836		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.36815325985888836 | validation: 0.3668117432903359]
	TIME [epoch: 8.31 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4598352242424048		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.4598352242424048 | validation: 0.3426399539811218]
	TIME [epoch: 8.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4322704075070617		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.4322704075070617 | validation: 0.4313205000232574]
	TIME [epoch: 8.33 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35273088175152484		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.35273088175152484 | validation: 0.25664852817526024]
	TIME [epoch: 8.31 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47262791043792296		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.47262791043792296 | validation: 0.3377511842176383]
	TIME [epoch: 8.31 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37881697163932126		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.37881697163932126 | validation: 0.46303304404391454]
	TIME [epoch: 8.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38661734292704486		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.38661734292704486 | validation: 0.4416701060753802]
	TIME [epoch: 8.32 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40254305213271085		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.40254305213271085 | validation: 0.4317595280843446]
	TIME [epoch: 8.32 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3746421423937221		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.3746421423937221 | validation: 0.6530861174097822]
	TIME [epoch: 8.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41470753502795776		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.41470753502795776 | validation: 0.23775287893936098]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3427022034736782		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.3427022034736782 | validation: 0.4405883702149553]
	TIME [epoch: 8.33 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4958419472690288		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.4958419472690288 | validation: 0.706727124130965]
	TIME [epoch: 8.31 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3728993692884901		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.3728993692884901 | validation: 0.46055373830641205]
	TIME [epoch: 8.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30193520006691726		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.30193520006691726 | validation: 0.6421586833108462]
	TIME [epoch: 8.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44075031813627		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.44075031813627 | validation: 0.21385391655380231]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3222557514633686		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.3222557514633686 | validation: 0.856003079152563]
	TIME [epoch: 8.32 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43681429078766626		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.43681429078766626 | validation: 0.38345063083839637]
	TIME [epoch: 8.31 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.331762705146634		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.331762705146634 | validation: 0.33622611230798327]
	TIME [epoch: 8.32 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36377009003862465		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.36377009003862465 | validation: 0.727875939682462]
	TIME [epoch: 8.34 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4687894231665952		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.4687894231665952 | validation: 0.22416848741006515]
	TIME [epoch: 8.32 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4067882009704382		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.4067882009704382 | validation: 0.34012073661057446]
	TIME [epoch: 8.31 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752183951720959		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.2752183951720959 | validation: 0.2643577828484446]
	TIME [epoch: 8.32 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42701122916686024		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.42701122916686024 | validation: 0.268272532240365]
	TIME [epoch: 8.34 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4047976096162754		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.4047976096162754 | validation: 0.31762697725854916]
	TIME [epoch: 8.31 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3762577623611147		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.3762577623611147 | validation: 0.471367099134346]
	TIME [epoch: 8.32 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5903294345492		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.5903294345492 | validation: 0.386863028308588]
	TIME [epoch: 8.32 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39121410237633036		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.39121410237633036 | validation: 0.30842925025926954]
	TIME [epoch: 8.34 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38321155162413534		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.38321155162413534 | validation: 0.25732979694853225]
	TIME [epoch: 8.31 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3779410256724172		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.3779410256724172 | validation: 0.470808285546795]
	TIME [epoch: 8.32 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33594437596492704		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.33594437596492704 | validation: 0.3448719540482355]
	TIME [epoch: 8.32 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36867498539696825		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.36867498539696825 | validation: 0.19703892218025523]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4772879875894184		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.4772879875894184 | validation: 0.3084797970767291]
	TIME [epoch: 8.32 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39886836993981784		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.39886836993981784 | validation: 0.32060588073892393]
	TIME [epoch: 8.32 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3009770567128423		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 0.3009770567128423 | validation: 0.4310074635601596]
	TIME [epoch: 8.33 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33911998503969176		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.33911998503969176 | validation: 0.34377209955556287]
	TIME [epoch: 8.34 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2775464303647577		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.2775464303647577 | validation: 0.3874124418942919]
	TIME [epoch: 8.32 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31314237752119595		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.31314237752119595 | validation: 0.29193977366675694]
	TIME [epoch: 8.31 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788965008492366		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.2788965008492366 | validation: 0.25786267371988447]
	TIME [epoch: 8.32 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43613690464535537		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.43613690464535537 | validation: 0.3134823348815302]
	TIME [epoch: 8.33 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37074459878762267		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.37074459878762267 | validation: 0.21714154874172123]
	TIME [epoch: 8.32 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32218264228428123		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.32218264228428123 | validation: 0.2589195781027537]
	TIME [epoch: 8.32 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2675740598266695		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.2675740598266695 | validation: 0.30263725604370356]
	TIME [epoch: 8.33 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305038466934281		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.3305038466934281 | validation: 0.2798019434163863]
	TIME [epoch: 8.34 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35026376749884164		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.35026376749884164 | validation: 0.2939294796989308]
	TIME [epoch: 8.32 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3061667090828747		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.3061667090828747 | validation: 0.42180473375295247]
	TIME [epoch: 8.31 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.309431937028401		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.309431937028401 | validation: 0.2527031883724888]
	TIME [epoch: 8.32 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32130687345647313		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.32130687345647313 | validation: 0.5059892400075805]
	TIME [epoch: 8.32 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42580780609255253		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.42580780609255253 | validation: 0.37835344418197836]
	TIME [epoch: 8.31 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4629134080589633		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.4629134080589633 | validation: 0.3699428263852995]
	TIME [epoch: 8.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4652112315462757		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.4652112315462757 | validation: 0.344192411595033]
	TIME [epoch: 8.31 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954571861554426		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.2954571861554426 | validation: 0.38767279279226036]
	TIME [epoch: 8.33 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30327403810577763		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.30327403810577763 | validation: 0.3928582669173275]
	TIME [epoch: 8.31 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37588675886790107		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.37588675886790107 | validation: 0.22108785503199058]
	TIME [epoch: 8.31 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175464995084094		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.3175464995084094 | validation: 0.4890011199063786]
	TIME [epoch: 8.32 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45111879424294293		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.45111879424294293 | validation: 0.28553501488573013]
	TIME [epoch: 8.33 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109668221967577		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.3109668221967577 | validation: 0.30702651386643187]
	TIME [epoch: 8.31 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40006632897274796		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.40006632897274796 | validation: 0.15446325416100606]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39352304705516994		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.39352304705516994 | validation: 0.3685037717834984]
	TIME [epoch: 8.32 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3319463950253507		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.3319463950253507 | validation: 0.2165150109364904]
	TIME [epoch: 8.32 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3251106979644528		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.3251106979644528 | validation: 0.3001053001441974]
	TIME [epoch: 8.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3800178107852651		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.3800178107852651 | validation: 0.27393953557773837]
	TIME [epoch: 8.31 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31151788337435427		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.31151788337435427 | validation: 0.2906934355429829]
	TIME [epoch: 8.32 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29004151303041		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.29004151303041 | validation: 0.44357817003606814]
	TIME [epoch: 8.32 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3492287640308525		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.3492287640308525 | validation: 0.25635588145540905]
	TIME [epoch: 8.31 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32508179911668106		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.32508179911668106 | validation: 0.21488638827340348]
	TIME [epoch: 8.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31812228235454326		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.31812228235454326 | validation: 0.634523660249905]
	TIME [epoch: 8.33 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29689572194702124		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.29689572194702124 | validation: 0.304861140951702]
	TIME [epoch: 8.32 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36696031298001824		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.36696031298001824 | validation: 0.2628356866573559]
	TIME [epoch: 8.31 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3265430085008435		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.3265430085008435 | validation: 0.21297258235594957]
	TIME [epoch: 8.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3049189509379884		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.3049189509379884 | validation: 0.18971108193859512]
	TIME [epoch: 8.32 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3092396448971785		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.3092396448971785 | validation: 0.6083415625042662]
	TIME [epoch: 8.31 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.375770652887736		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.375770652887736 | validation: 0.2775156851495044]
	TIME [epoch: 8.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24878707099553457		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.24878707099553457 | validation: 0.24601010977917004]
	TIME [epoch: 8.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.350172478517555		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.350172478517555 | validation: 0.41707152604746467]
	TIME [epoch: 8.32 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2911323931015427		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.2911323931015427 | validation: 0.3291612071435673]
	TIME [epoch: 8.32 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3448978345109157		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.3448978345109157 | validation: 0.2690660928538299]
	TIME [epoch: 8.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31745188732719865		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.31745188732719865 | validation: 0.18640976555292924]
	TIME [epoch: 8.31 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25484574059787307		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.25484574059787307 | validation: 0.24912163166606066]
	TIME [epoch: 8.32 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2525866752859919		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.2525866752859919 | validation: 0.275070576150222]
	TIME [epoch: 8.31 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3435612447688024		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.3435612447688024 | validation: 0.33047029259856364]
	TIME [epoch: 8.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25597473678932026		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.25597473678932026 | validation: 0.27751894954186057]
	TIME [epoch: 8.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2829113124208686		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.2829113124208686 | validation: 0.5026947987547101]
	TIME [epoch: 8.32 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3752426914371918		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.3752426914371918 | validation: 0.2730929749375434]
	TIME [epoch: 8.31 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3551392776719177		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.3551392776719177 | validation: 0.4067872873943622]
	TIME [epoch: 8.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24705567165555237		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.24705567165555237 | validation: 0.15047561232447304]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2304629507379036		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.2304629507379036 | validation: 0.2637426925269751]
	TIME [epoch: 8.32 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27950078199960515		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.27950078199960515 | validation: 0.1876059302657856]
	TIME [epoch: 8.31 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22416105424205765		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.22416105424205765 | validation: 0.22306379213872404]
	TIME [epoch: 8.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25818209474173015		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.25818209474173015 | validation: 0.2779867478072999]
	TIME [epoch: 8.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3399963641929021		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.3399963641929021 | validation: 0.38042779440579677]
	TIME [epoch: 8.32 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31895382451648047		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.31895382451648047 | validation: 0.20428109843772224]
	TIME [epoch: 8.31 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2183957694891942		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.2183957694891942 | validation: 0.21491914204271118]
	TIME [epoch: 8.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33263140760783105		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.33263140760783105 | validation: 0.2340401203595637]
	TIME [epoch: 8.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2964562383575563		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.2964562383575563 | validation: 0.5808883144784326]
	TIME [epoch: 8.31 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3485452949070498		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.3485452949070498 | validation: 0.45101872337262744]
	TIME [epoch: 8.31 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3679427803300216		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.3679427803300216 | validation: 0.2369531022445992]
	TIME [epoch: 8.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20690254562978624		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.20690254562978624 | validation: 0.4031765832841119]
	TIME [epoch: 8.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.286828092382275		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.286828092382275 | validation: 0.4152213806192514]
	TIME [epoch: 8.32 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25960116787633053		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.25960116787633053 | validation: 0.1685056589637241]
	TIME [epoch: 8.31 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3807087739348493		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.3807087739348493 | validation: 0.26061805943544375]
	TIME [epoch: 8.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678059317559738		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.2678059317559738 | validation: 0.2888629349914607]
	TIME [epoch: 8.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28515377869113334		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.28515377869113334 | validation: 0.3458872852989653]
	TIME [epoch: 8.32 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2691130520804995		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.2691130520804995 | validation: 0.2648427285584094]
	TIME [epoch: 8.31 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29417240039176284		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.29417240039176284 | validation: 0.14577967296189703]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22769252118521086		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.22769252118521086 | validation: 0.18544683667717127]
	TIME [epoch: 8.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3634044770977929		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.3634044770977929 | validation: 0.2549863567151471]
	TIME [epoch: 8.33 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4597366454749731		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.4597366454749731 | validation: 0.20131751176358947]
	TIME [epoch: 8.31 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.318124849689239		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.318124849689239 | validation: 0.3501232290111438]
	TIME [epoch: 8.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29855628539806867		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.29855628539806867 | validation: 0.4340582940355455]
	TIME [epoch: 8.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2824046456824857		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.2824046456824857 | validation: 0.4800453980162702]
	TIME [epoch: 8.32 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2779110046966279		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.2779110046966279 | validation: 0.438814820698876]
	TIME [epoch: 8.31 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33153284398185195		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.33153284398185195 | validation: 0.26955846852793114]
	TIME [epoch: 8.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727754295184632		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.2727754295184632 | validation: 0.16022851368236618]
	TIME [epoch: 8.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2361110559543172		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.2361110559543172 | validation: 0.23178710065054942]
	TIME [epoch: 8.32 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2672011443053538		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.2672011443053538 | validation: 0.2916514168715086]
	TIME [epoch: 8.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2691635166391659		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.2691635166391659 | validation: 0.18421251950799333]
	TIME [epoch: 8.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2847048988467581		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.2847048988467581 | validation: 0.25041420364555744]
	TIME [epoch: 8.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3462819745562959		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.3462819745562959 | validation: 0.4236941750949596]
	TIME [epoch: 8.32 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31126809461931404		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.31126809461931404 | validation: 0.3213446283231919]
	TIME [epoch: 8.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30170063158550436		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.30170063158550436 | validation: 0.27048558732161126]
	TIME [epoch: 8.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26296553651241006		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.26296553651241006 | validation: 0.30830685493841375]
	TIME [epoch: 8.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3058656398467745		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.3058656398467745 | validation: 0.21936932249911045]
	TIME [epoch: 8.33 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26556542129743216		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.26556542129743216 | validation: 0.5206309938878186]
	TIME [epoch: 8.31 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3811491688388873		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.3811491688388873 | validation: 0.1674068091101621]
	TIME [epoch: 8.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23865467901400628		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.23865467901400628 | validation: 0.22330886167967068]
	TIME [epoch: 8.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24213569260662632		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.24213569260662632 | validation: 0.26650773462029204]
	TIME [epoch: 8.33 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3523176093384392		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.3523176093384392 | validation: 0.7100744984246466]
	TIME [epoch: 8.31 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35348867653808597		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.35348867653808597 | validation: 0.1461169764592372]
	TIME [epoch: 8.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23389025485307302		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.23389025485307302 | validation: 0.3514501357985935]
	TIME [epoch: 8.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2521893772938556		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.2521893772938556 | validation: 0.4620857881826823]
	TIME [epoch: 8.32 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28411256783671923		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.28411256783671923 | validation: 0.22024860313169847]
	TIME [epoch: 8.31 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556913019726665		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.2556913019726665 | validation: 0.2297393159023363]
	TIME [epoch: 8.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23744449335121062		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.23744449335121062 | validation: 0.3062021348618849]
	TIME [epoch: 8.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21703394773731613		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.21703394773731613 | validation: 0.3921478267377253]
	TIME [epoch: 8.32 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752417694098033		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.2752417694098033 | validation: 0.19510628326974316]
	TIME [epoch: 8.31 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23819624722504135		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.23819624722504135 | validation: 0.1971494683797946]
	TIME [epoch: 8.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144712889058407		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.3144712889058407 | validation: 0.20841578687373316]
	TIME [epoch: 8.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2809376827036368		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.2809376827036368 | validation: 0.23540585766884878]
	TIME [epoch: 8.33 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22937197184401822		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.22937197184401822 | validation: 0.5595036268933151]
	TIME [epoch: 8.31 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3447303445558067		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.3447303445558067 | validation: 0.23889937029696856]
	TIME [epoch: 8.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582207765507158		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.2582207765507158 | validation: 0.17458363572013386]
	TIME [epoch: 8.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22898719897481562		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.22898719897481562 | validation: 0.1304850534360568]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23110179473993978		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.23110179473993978 | validation: 0.14551026496008113]
	TIME [epoch: 8.31 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27995132389169447		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.27995132389169447 | validation: 0.30702034247417065]
	TIME [epoch: 8.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22737828552575387		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.22737828552575387 | validation: 0.4228324367326789]
	TIME [epoch: 8.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2654045357158237		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.2654045357158237 | validation: 0.27147246853497653]
	TIME [epoch: 8.32 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.261641271295062		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.261641271295062 | validation: 0.16857930834708762]
	TIME [epoch: 8.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26041814728766566		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.26041814728766566 | validation: 0.23571330252340356]
	TIME [epoch: 8.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23161810141428857		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.23161810141428857 | validation: 0.3473068063581922]
	TIME [epoch: 8.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28258691126771984		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.28258691126771984 | validation: 0.37724786234041574]
	TIME [epoch: 8.32 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28063940822425093		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.28063940822425093 | validation: 0.2748148212639297]
	TIME [epoch: 8.31 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22669835599604485		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.22669835599604485 | validation: 0.14169571501242434]
	TIME [epoch: 8.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1932870435050461		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.1932870435050461 | validation: 0.1580904566884926]
	TIME [epoch: 8.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31569309147912233		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.31569309147912233 | validation: 0.18772075279312445]
	TIME [epoch: 8.33 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529925438376756		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.2529925438376756 | validation: 0.31268915956660387]
	TIME [epoch: 8.31 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2605242967562529		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.2605242967562529 | validation: 0.3950945262556347]
	TIME [epoch: 8.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2709497993609956		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.2709497993609956 | validation: 0.1819778583066092]
	TIME [epoch: 8.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22711569099501205		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.22711569099501205 | validation: 0.6029618939853729]
	TIME [epoch: 8.33 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3690490825853825		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.3690490825853825 | validation: 0.17198822294843924]
	TIME [epoch: 8.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2791720512372805		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.2791720512372805 | validation: 0.1811808784069504]
	TIME [epoch: 8.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22553131398638201		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.22553131398638201 | validation: 0.27085571626442606]
	TIME [epoch: 8.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456148336073553		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.2456148336073553 | validation: 0.16382321568828306]
	TIME [epoch: 8.32 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21339465214934727		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.21339465214934727 | validation: 0.2483471066600641]
	TIME [epoch: 8.31 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27136756232024173		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.27136756232024173 | validation: 0.14189510376005643]
	TIME [epoch: 8.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22646753659640825		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.22646753659640825 | validation: 0.3160436364842317]
	TIME [epoch: 8.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2603849041132709		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.2603849041132709 | validation: 0.25927375910883443]
	TIME [epoch: 8.32 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1870291894573966		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.1870291894573966 | validation: 0.2029202790795784]
	TIME [epoch: 8.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24524104842096417		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.24524104842096417 | validation: 0.15215386737939712]
	TIME [epoch: 8.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19822762703180286		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.19822762703180286 | validation: 0.2492451933732258]
	TIME [epoch: 8.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21999931081325333		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.21999931081325333 | validation: 0.3804381669534346]
	TIME [epoch: 8.32 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37761774333087655		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.37761774333087655 | validation: 0.20947643253181364]
	TIME [epoch: 8.31 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2421959306866121		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.2421959306866121 | validation: 0.1966828283583683]
	TIME [epoch: 8.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20986244292319137		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.20986244292319137 | validation: 0.15635416305724448]
	TIME [epoch: 8.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926249806615135		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.1926249806615135 | validation: 0.34449865544216185]
	TIME [epoch: 8.32 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25406072818950015		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.25406072818950015 | validation: 0.17140393492818173]
	TIME [epoch: 8.31 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31582708179963676		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.31582708179963676 | validation: 0.16406896749500544]
	TIME [epoch: 8.31 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19504729065448403		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.19504729065448403 | validation: 0.309924731013678]
	TIME [epoch: 8.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995444324007663		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.1995444324007663 | validation: 0.20294979078078162]
	TIME [epoch: 8.32 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1877662897487909		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.1877662897487909 | validation: 0.11624115016720714]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20208241977591695		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.20208241977591695 | validation: 0.19163418990768447]
	TIME [epoch: 8.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600148731114191		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.2600148731114191 | validation: 0.3824989759272147]
	TIME [epoch: 8.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20907509114865502		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.20907509114865502 | validation: 0.23729695910239723]
	TIME [epoch: 8.32 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20492839382265576		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.20492839382265576 | validation: 0.13232287073450683]
	TIME [epoch: 8.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28047660181826434		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.28047660181826434 | validation: 0.20979207197927002]
	TIME [epoch: 8.29 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25014155358556495		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.25014155358556495 | validation: 0.23439673182658347]
	TIME [epoch: 8.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2707357818304122		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.2707357818304122 | validation: 0.2393704967701865]
	TIME [epoch: 8.32 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21700680359054497		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.21700680359054497 | validation: 0.13248043705747203]
	TIME [epoch: 8.29 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16902156491108505		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.16902156491108505 | validation: 0.2711944484882415]
	TIME [epoch: 8.29 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24911084734426678		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.24911084734426678 | validation: 0.2700635590615703]
	TIME [epoch: 8.29 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20114948932162954		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.20114948932162954 | validation: 0.18142059603831137]
	TIME [epoch: 8.32 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24057249582600657		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.24057249582600657 | validation: 0.5991525483020697]
	TIME [epoch: 8.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2648227259082516		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.2648227259082516 | validation: 0.2289089801388308]
	TIME [epoch: 8.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19959054427031137		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.19959054427031137 | validation: 0.18434774754570574]
	TIME [epoch: 8.29 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.281355927987334		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.281355927987334 | validation: 0.40349942051716847]
	TIME [epoch: 8.32 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23357437910672477		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.23357437910672477 | validation: 0.22758563249250074]
	TIME [epoch: 8.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24583688201716908		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.24583688201716908 | validation: 0.29442604512790027]
	TIME [epoch: 8.29 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1811053528748562		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.1811053528748562 | validation: 0.11546708653505502]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23485978168213925		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.23485978168213925 | validation: 0.21471527190867762]
	TIME [epoch: 8.32 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1747535332776195		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.1747535332776195 | validation: 0.19998071742744838]
	TIME [epoch: 8.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20739701033244176		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.20739701033244176 | validation: 0.22351043379068217]
	TIME [epoch: 8.29 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17241649125394493		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.17241649125394493 | validation: 0.1842466752492382]
	TIME [epoch: 8.29 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22232372801830996		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.22232372801830996 | validation: 0.2725668749609066]
	TIME [epoch: 8.31 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2745484873116454		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.2745484873116454 | validation: 0.3761592269757791]
	TIME [epoch: 8.29 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22749566008891892		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.22749566008891892 | validation: 0.14060673852560313]
	TIME [epoch: 8.29 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18225327995042723		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.18225327995042723 | validation: 0.21014960411852668]
	TIME [epoch: 8.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19771795250708885		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.19771795250708885 | validation: 0.15216584252293952]
	TIME [epoch: 8.32 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24567237052692636		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.24567237052692636 | validation: 0.253858436804596]
	TIME [epoch: 8.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26015857431278044		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.26015857431278044 | validation: 0.13635468133919074]
	TIME [epoch: 8.29 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2383590291069316		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.2383590291069316 | validation: 0.2590514150748016]
	TIME [epoch: 8.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17590982908101818		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.17590982908101818 | validation: 0.16194464956759502]
	TIME [epoch: 8.32 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2304910634832616		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.2304910634832616 | validation: 0.15386136064223277]
	TIME [epoch: 8.29 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18189518285199752		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.18189518285199752 | validation: 0.17716790135346455]
	TIME [epoch: 8.29 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19570699932666127		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.19570699932666127 | validation: 0.25193725631515984]
	TIME [epoch: 8.29 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18626112816462595		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.18626112816462595 | validation: 0.16000111651906235]
	TIME [epoch: 8.32 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2250650968425119		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.2250650968425119 | validation: 0.27356674079440957]
	TIME [epoch: 8.29 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28345808371085646		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.28345808371085646 | validation: 0.2452633266651739]
	TIME [epoch: 8.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20579008293978235		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.20579008293978235 | validation: 0.12562763746394565]
	TIME [epoch: 8.29 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24877509278415152		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.24877509278415152 | validation: 0.1387801729306689]
	TIME [epoch: 8.32 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22126243758835037		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.22126243758835037 | validation: 0.12456353089127373]
	TIME [epoch: 8.29 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20203017331523565		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.20203017331523565 | validation: 0.3963987486413032]
	TIME [epoch: 8.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26856556934508313		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.26856556934508313 | validation: 0.24942102005119515]
	TIME [epoch: 8.29 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2053162955491843		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.2053162955491843 | validation: 0.199262918217718]
	TIME [epoch: 8.32 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21228539491435053		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.21228539491435053 | validation: 0.3767438773860651]
	TIME [epoch: 8.29 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22162695902331073		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.22162695902331073 | validation: 0.14890483805947966]
	TIME [epoch: 8.29 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21400463075247966		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.21400463075247966 | validation: 0.4129018998079297]
	TIME [epoch: 8.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2187540270002301		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.2187540270002301 | validation: 0.15717801835666637]
	TIME [epoch: 8.32 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26134399715691126		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.26134399715691126 | validation: 0.13480637692230524]
	TIME [epoch: 8.29 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17575634259011413		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.17575634259011413 | validation: 0.175350994098265]
	TIME [epoch: 8.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16468775979641112		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.16468775979641112 | validation: 0.1437959633965096]
	TIME [epoch: 8.29 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23276118796036518		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.23276118796036518 | validation: 0.18663419113224622]
	TIME [epoch: 8.32 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15323055924559376		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.15323055924559376 | validation: 0.16179740773100781]
	TIME [epoch: 8.29 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19989853453446266		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.19989853453446266 | validation: 0.13597542722949718]
	TIME [epoch: 8.29 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19205762254329523		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.19205762254329523 | validation: 0.11947814023704457]
	TIME [epoch: 8.29 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1795653543546324		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.1795653543546324 | validation: 0.11357310448300952]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21650740448656877		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.21650740448656877 | validation: 0.11300816889394039]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.177389750763672		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.177389750763672 | validation: 0.15851349634732678]
	TIME [epoch: 8.29 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19125624677829822		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.19125624677829822 | validation: 0.16235841151404334]
	TIME [epoch: 8.29 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.230738140049275		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.230738140049275 | validation: 0.14744065472232773]
	TIME [epoch: 8.32 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1942279615427326		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.1942279615427326 | validation: 0.11536238190178874]
	TIME [epoch: 8.29 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23961130320800367		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.23961130320800367 | validation: 0.15459495121220768]
	TIME [epoch: 8.29 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851980690876789		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.1851980690876789 | validation: 0.2811169338721312]
	TIME [epoch: 8.29 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1973961308169774		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.1973961308169774 | validation: 0.16072550331530172]
	TIME [epoch: 8.32 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23834723496009885		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.23834723496009885 | validation: 0.10529536843773118]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17979349614896742		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.17979349614896742 | validation: 0.12801435716265644]
	TIME [epoch: 8.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14705853794415652		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.14705853794415652 | validation: 0.20954200467469253]
	TIME [epoch: 8.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25848545207718343		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.25848545207718343 | validation: 0.16954154203666988]
	TIME [epoch: 8.32 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16369091342097503		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.16369091342097503 | validation: 0.15618742237012534]
	TIME [epoch: 8.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21921454529841658		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.21921454529841658 | validation: 0.21630191941402838]
	TIME [epoch: 8.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24273460363521843		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.24273460363521843 | validation: 0.27975936909454635]
	TIME [epoch: 8.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19753673002672884		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.19753673002672884 | validation: 0.13775594303007171]
	TIME [epoch: 8.33 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19193385007635233		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.19193385007635233 | validation: 0.16395928150514294]
	TIME [epoch: 8.29 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21991420076412133		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.21991420076412133 | validation: 0.21607655227066866]
	TIME [epoch: 8.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1710715595563815		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.1710715595563815 | validation: 0.1363791771824242]
	TIME [epoch: 8.29 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21382201807686702		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.21382201807686702 | validation: 0.3368232694360102]
	TIME [epoch: 8.32 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20302533137639528		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.20302533137639528 | validation: 0.1509499136909495]
	TIME [epoch: 8.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1537923301646522		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.1537923301646522 | validation: 0.21299964243713126]
	TIME [epoch: 8.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2073611069241892		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.2073611069241892 | validation: 0.1127047483549552]
	TIME [epoch: 8.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20506070594150896		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.20506070594150896 | validation: 0.264593610074779]
	TIME [epoch: 8.32 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2421321514857672		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.2421321514857672 | validation: 0.2566726721076905]
	TIME [epoch: 8.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16645852940683004		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.16645852940683004 | validation: 0.3195862378025759]
	TIME [epoch: 8.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18100796160105784		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.18100796160105784 | validation: 0.1583214714529373]
	TIME [epoch: 8.29 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.192133889737038		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.192133889737038 | validation: 0.09938529141662494]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1854547579078841		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.1854547579078841 | validation: 0.1030940773572947]
	TIME [epoch: 8.32 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15512331693557274		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.15512331693557274 | validation: 0.13998321516689063]
	TIME [epoch: 8.32 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16227524761902362		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.16227524761902362 | validation: 0.24224044146448115]
	TIME [epoch: 8.32 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.217361311137973		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.217361311137973 | validation: 0.14491398808780348]
	TIME [epoch: 8.33 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1944945522053107		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.1944945522053107 | validation: 0.18828997695378327]
	TIME [epoch: 8.31 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19877149519671924		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.19877149519671924 | validation: 0.18177867365222383]
	TIME [epoch: 8.31 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15090906984133698		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.15090906984133698 | validation: 0.17497040876313413]
	TIME [epoch: 8.33 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.172522452475125		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.172522452475125 | validation: 0.1734388611791456]
	TIME [epoch: 8.31 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18058563786953835		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.18058563786953835 | validation: 0.10723608982942422]
	TIME [epoch: 8.31 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1850682420229702		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.1850682420229702 | validation: 0.24715398556193524]
	TIME [epoch: 8.31 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17897668743859763		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.17897668743859763 | validation: 0.1058567803218434]
	TIME [epoch: 8.33 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19570366139887577		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.19570366139887577 | validation: 0.1639057356525572]
	TIME [epoch: 8.31 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17578282516532215		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.17578282516532215 | validation: 0.13605822196653988]
	TIME [epoch: 8.31 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1817614468821112		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.1817614468821112 | validation: 0.14865805874873808]
	TIME [epoch: 8.31 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24306899926929432		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.24306899926929432 | validation: 0.1393279478677474]
	TIME [epoch: 8.34 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13781575242966349		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.13781575242966349 | validation: 0.12444887195663273]
	TIME [epoch: 8.32 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16261990675168148		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.16261990675168148 | validation: 0.2592499234372492]
	TIME [epoch: 8.31 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1555497319674055		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.1555497319674055 | validation: 0.10402693962989307]
	TIME [epoch: 8.31 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19796410142331627		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.19796410142331627 | validation: 0.3495493472479968]
	TIME [epoch: 8.34 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18232852196912128		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.18232852196912128 | validation: 0.3591804211195022]
	TIME [epoch: 8.32 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21173314899416265		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.21173314899416265 | validation: 0.21424096648990357]
	TIME [epoch: 8.31 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24425337271541228		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.24425337271541228 | validation: 0.1845253415191896]
	TIME [epoch: 8.31 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23618670329644997		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.23618670329644997 | validation: 0.11946259811403907]
	TIME [epoch: 8.34 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2254945013140049		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.2254945013140049 | validation: 0.3121332968079703]
	TIME [epoch: 8.32 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21926845592967595		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.21926845592967595 | validation: 0.21811439303973326]
	TIME [epoch: 8.31 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19825483530371518		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.19825483530371518 | validation: 0.21449286885826782]
	TIME [epoch: 8.31 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18391740760506906		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.18391740760506906 | validation: 0.18807959976633626]
	TIME [epoch: 8.34 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1507002923489386		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.1507002923489386 | validation: 0.1629893756190901]
	TIME [epoch: 8.31 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15767562663241735		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.15767562663241735 | validation: 0.3320556699781462]
	TIME [epoch: 8.31 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2034991741522107		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.2034991741522107 | validation: 0.1161190897024244]
	TIME [epoch: 8.31 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20114133405520315		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.20114133405520315 | validation: 0.10828559727911416]
	TIME [epoch: 8.34 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18839228846348777		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.18839228846348777 | validation: 0.14838358427839374]
	TIME [epoch: 8.31 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18591763213216753		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.18591763213216753 | validation: 0.16159170713684823]
	TIME [epoch: 8.31 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17773111592061308		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.17773111592061308 | validation: 0.17797129904987355]
	TIME [epoch: 8.31 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24693929121067462		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.24693929121067462 | validation: 0.15541673146081741]
	TIME [epoch: 8.33 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22003218125598037		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.22003218125598037 | validation: 0.14615294254194094]
	TIME [epoch: 8.32 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.190517408439303		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.190517408439303 | validation: 0.1487034555819151]
	TIME [epoch: 8.31 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17186361717741092		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.17186361717741092 | validation: 0.23777361413399414]
	TIME [epoch: 8.31 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15017588202620946		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.15017588202620946 | validation: 0.13664402243880544]
	TIME [epoch: 8.33 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1810796954409873		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.1810796954409873 | validation: 0.2979650774657181]
	TIME [epoch: 8.31 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16066812546640166		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.16066812546640166 | validation: 0.341655001291188]
	TIME [epoch: 8.31 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2049202107057905		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.2049202107057905 | validation: 0.1266406462357819]
	TIME [epoch: 8.31 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15762012449139962		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.15762012449139962 | validation: 0.15411247440836218]
	TIME [epoch: 8.33 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18521641917676296		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.18521641917676296 | validation: 0.1380563613912439]
	TIME [epoch: 8.31 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18261909590482558		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.18261909590482558 | validation: 0.29193517836876093]
	TIME [epoch: 8.31 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1704440155115272		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.1704440155115272 | validation: 0.10808108273215625]
	TIME [epoch: 8.31 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15995511060899797		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.15995511060899797 | validation: 0.11180623012540679]
	TIME [epoch: 8.33 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1954970069231573		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.1954970069231573 | validation: 0.36816874748911765]
	TIME [epoch: 8.31 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529439724540884		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.2529439724540884 | validation: 0.21058889184045024]
	TIME [epoch: 8.31 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16661524838176514		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.16661524838176514 | validation: 0.15127148041688954]
	TIME [epoch: 8.31 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14269084510729063		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.14269084510729063 | validation: 0.09044825170591508]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14462420466400422		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.14462420466400422 | validation: 0.16799439553257708]
	TIME [epoch: 8.31 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17051403064175666		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.17051403064175666 | validation: 0.12144495428056223]
	TIME [epoch: 8.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15586441184784977		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.15586441184784977 | validation: 0.2453864011903053]
	TIME [epoch: 8.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2615257291236151		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.2615257291236151 | validation: 0.17977964215518677]
	TIME [epoch: 8.33 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17880554480913907		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.17880554480913907 | validation: 0.2196497894866103]
	TIME [epoch: 8.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16758969074820013		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.16758969074820013 | validation: 0.1410314369735794]
	TIME [epoch: 8.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16752884726040312		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.16752884726040312 | validation: 0.11802643687057744]
	TIME [epoch: 8.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20228558945591937		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.20228558945591937 | validation: 0.1140929057006331]
	TIME [epoch: 8.32 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18711047946450068		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.18711047946450068 | validation: 0.1599269071158366]
	TIME [epoch: 8.31 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14535163397679068		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.14535163397679068 | validation: 0.08948649881332453]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10994008040732486		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.10994008040732486 | validation: 0.250495204735146]
	TIME [epoch: 8.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20968965583490454		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.20968965583490454 | validation: 0.17640330396289822]
	TIME [epoch: 8.33 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18861455392712503		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.18861455392712503 | validation: 0.30025075305724674]
	TIME [epoch: 8.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16918406649216927		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.16918406649216927 | validation: 0.14997855527270515]
	TIME [epoch: 8.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1790559982369975		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.1790559982369975 | validation: 0.12721755114858685]
	TIME [epoch: 8.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14443274464309103		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.14443274464309103 | validation: 0.21804898792429578]
	TIME [epoch: 8.33 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1596179674395777		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.1596179674395777 | validation: 0.09956887599864109]
	TIME [epoch: 8.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1644728536982542		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.1644728536982542 | validation: 0.22005287241997473]
	TIME [epoch: 8.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650467007917931		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.2650467007917931 | validation: 0.31368244210491547]
	TIME [epoch: 8.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16890656461689593		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.16890656461689593 | validation: 0.10507051389935355]
	TIME [epoch: 8.32 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18984252306808685		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.18984252306808685 | validation: 0.23784134243632166]
	TIME [epoch: 8.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20645802422168727		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.20645802422168727 | validation: 0.12221319345725283]
	TIME [epoch: 8.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.195626408038668		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.195626408038668 | validation: 0.1580579744066751]
	TIME [epoch: 8.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1577541440082732		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.1577541440082732 | validation: 0.16599634957091225]
	TIME [epoch: 8.32 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16921064675810818		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.16921064675810818 | validation: 0.11692394366850775]
	TIME [epoch: 8.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1870427341381697		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.1870427341381697 | validation: 0.14468397763003688]
	TIME [epoch: 8.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1539796048585877		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.1539796048585877 | validation: 0.17839830748733562]
	TIME [epoch: 8.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12042433154956425		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.12042433154956425 | validation: 0.2286483806343642]
	TIME [epoch: 8.33 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17808913201599003		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.17808913201599003 | validation: 0.12978299947853864]
	TIME [epoch: 8.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2007976674264293		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.2007976674264293 | validation: 0.2540611217732282]
	TIME [epoch: 8.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14828155058026943		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.14828155058026943 | validation: 0.20847143698284165]
	TIME [epoch: 8.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1307089771750703		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.1307089771750703 | validation: 0.18959600697990575]
	TIME [epoch: 8.32 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13116579880948157		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.13116579880948157 | validation: 0.09547151270061799]
	TIME [epoch: 8.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.139674225760942		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.139674225760942 | validation: 0.11457167092624708]
	TIME [epoch: 8.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11935552666863258		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.11935552666863258 | validation: 0.10468603568050813]
	TIME [epoch: 8.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15255347001433583		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.15255347001433583 | validation: 0.2516942296156584]
	TIME [epoch: 8.32 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12655709990436864		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.12655709990436864 | validation: 0.07962294998752598]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14263133371218145		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.14263133371218145 | validation: 0.1287409274135824]
	TIME [epoch: 8.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17076379697801763		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.17076379697801763 | validation: 0.221881218122284]
	TIME [epoch: 8.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14024751580211686		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.14024751580211686 | validation: 0.19695723023465223]
	TIME [epoch: 8.32 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1606659007519987		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.1606659007519987 | validation: 0.12110352690401269]
	TIME [epoch: 8.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13036766880390147		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.13036766880390147 | validation: 0.14008905883962344]
	TIME [epoch: 8.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1444017335294503		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.1444017335294503 | validation: 0.2147629577740462]
	TIME [epoch: 8.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16691724337320815		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.16691724337320815 | validation: 0.14965772056610405]
	TIME [epoch: 8.32 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437434687626317		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.1437434687626317 | validation: 0.12768446535735814]
	TIME [epoch: 8.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13199525703964674		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.13199525703964674 | validation: 0.11563896279070245]
	TIME [epoch: 8.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1718062096853985		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.1718062096853985 | validation: 0.07395464391400128]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11544746727899746		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.11544746727899746 | validation: 0.12581344905462055]
	TIME [epoch: 8.32 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15859271148073634		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.15859271148073634 | validation: 0.11165555630960597]
	TIME [epoch: 8.29 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17780450809309614		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.17780450809309614 | validation: 0.21639868634698128]
	TIME [epoch: 8.29 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18016281385614002		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.18016281385614002 | validation: 0.08772167201903064]
	TIME [epoch: 8.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1310456902868055		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.1310456902868055 | validation: 0.10951256733068514]
	TIME [epoch: 8.32 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16606613818834215		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.16606613818834215 | validation: 0.0971124052491695]
	TIME [epoch: 8.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16688452819900662		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.16688452819900662 | validation: 0.22394134658713338]
	TIME [epoch: 8.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15823498477895384		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.15823498477895384 | validation: 0.08240282378155]
	TIME [epoch: 8.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14248554998334312		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.14248554998334312 | validation: 0.16972371824111224]
	TIME [epoch: 8.32 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15279796677774554		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.15279796677774554 | validation: 0.1774515786314137]
	TIME [epoch: 8.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1676139469751547		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.1676139469751547 | validation: 0.09792192190662243]
	TIME [epoch: 8.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18895894571962762		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.18895894571962762 | validation: 0.14855530925084626]
	TIME [epoch: 8.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11678157253765123		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.11678157253765123 | validation: 0.102904722297558]
	TIME [epoch: 8.32 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906311342295009		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.1906311342295009 | validation: 0.1102387626885605]
	TIME [epoch: 8.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11960919071893705		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.11960919071893705 | validation: 0.14537192697781193]
	TIME [epoch: 8.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10631795283598133		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.10631795283598133 | validation: 0.08478704442412177]
	TIME [epoch: 8.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17126780216922588		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.17126780216922588 | validation: 0.11990638692444973]
	TIME [epoch: 8.32 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19832818439596794		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.19832818439596794 | validation: 0.1365032027912299]
	TIME [epoch: 8.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13487660503403162		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.13487660503403162 | validation: 0.42823225131763304]
	TIME [epoch: 8.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21821404291675378		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.21821404291675378 | validation: 0.25396453268592517]
	TIME [epoch: 8.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2036865704187441		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.2036865704187441 | validation: 0.32039832728477224]
	TIME [epoch: 8.32 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15112726618225855		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.15112726618225855 | validation: 0.24000471536891152]
	TIME [epoch: 8.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16259969463121654		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.16259969463121654 | validation: 0.13359882689320451]
	TIME [epoch: 8.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11735600529398585		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.11735600529398585 | validation: 0.0993292947233133]
	TIME [epoch: 8.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11209408834542223		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.11209408834542223 | validation: 0.15065006906921083]
	TIME [epoch: 8.32 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09859495823345218		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.09859495823345218 | validation: 0.05548915648500989]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0958851308000557		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.0958851308000557 | validation: 0.07917500602523148]
	TIME [epoch: 8.29 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16532609635968443		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.16532609635968443 | validation: 0.3518574605904384]
	TIME [epoch: 8.31 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19210597374644833		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.19210597374644833 | validation: 0.2801504014771591]
	TIME [epoch: 8.31 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15639685174821577		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.15639685174821577 | validation: 0.1348813137288869]
	TIME [epoch: 8.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18214535479480137		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.18214535479480137 | validation: 0.08396733857496186]
	TIME [epoch: 8.29 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1395858564347619		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.1395858564347619 | validation: 0.06257412204026536]
	TIME [epoch: 8.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12687009294232499		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.12687009294232499 | validation: 0.16231705430892746]
	TIME [epoch: 8.32 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20481652827344227		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.20481652827344227 | validation: 0.10245949198422506]
	TIME [epoch: 8.29 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13410208459978662		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.13410208459978662 | validation: 0.10669370854979993]
	TIME [epoch: 8.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13271625037450938		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.13271625037450938 | validation: 0.15271436862752213]
	TIME [epoch: 8.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1669942789209906		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.1669942789209906 | validation: 0.10509963763443639]
	TIME [epoch: 8.31 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2033552844302406		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.2033552844302406 | validation: 0.0749270876778905]
	TIME [epoch: 8.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1061678928664391		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.1061678928664391 | validation: 0.26545197770888984]
	TIME [epoch: 8.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27285032485779903		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.27285032485779903 | validation: 0.12309469402196621]
	TIME [epoch: 8.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12706928011869337		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.12706928011869337 | validation: 0.11477352724102072]
	TIME [epoch: 8.31 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17059329754954006		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.17059329754954006 | validation: 0.0917181218363342]
	TIME [epoch: 8.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13223161494114052		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.13223161494114052 | validation: 0.10814643122901643]
	TIME [epoch: 8.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1494581028433914		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.1494581028433914 | validation: 0.19263670837359276]
	TIME [epoch: 8.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19184057149237418		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.19184057149237418 | validation: 0.20930728122184777]
	TIME [epoch: 8.32 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23374324925661058		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.23374324925661058 | validation: 0.24528163377027706]
	TIME [epoch: 8.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17624914193476715		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.17624914193476715 | validation: 0.13257955289367618]
	TIME [epoch: 8.29 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16518832799801936		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.16518832799801936 | validation: 0.08421676646189503]
	TIME [epoch: 8.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13040401515163041		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.13040401515163041 | validation: 0.1343141764628888]
	TIME [epoch: 8.31 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14962328749903453		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.14962328749903453 | validation: 0.10680663660226254]
	TIME [epoch: 8.29 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13530890446847033		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.13530890446847033 | validation: 0.11700400354599305]
	TIME [epoch: 8.29 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09479851289304124		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.09479851289304124 | validation: 0.15021715555219292]
	TIME [epoch: 8.29 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2152164891382129		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.2152164891382129 | validation: 0.2185221714110565]
	TIME [epoch: 8.31 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11982512995983204		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.11982512995983204 | validation: 0.1240520822166423]
	TIME [epoch: 8.29 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13858505636504875		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.13858505636504875 | validation: 0.16572903493323182]
	TIME [epoch: 8.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12634970536120022		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.12634970536120022 | validation: 0.42667804979486224]
	TIME [epoch: 8.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24586728926151064		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.24586728926151064 | validation: 0.1147345768634279]
	TIME [epoch: 8.31 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14363554468259984		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.14363554468259984 | validation: 0.11580092239566411]
	TIME [epoch: 8.29 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14931996233544326		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.14931996233544326 | validation: 0.13117404078499056]
	TIME [epoch: 8.29 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10763990665340444		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.10763990665340444 | validation: 0.195528538258658]
	TIME [epoch: 8.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14235442897273845		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.14235442897273845 | validation: 0.13300987958133878]
	TIME [epoch: 8.31 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13512429950601818		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.13512429950601818 | validation: 0.10270456097679297]
	TIME [epoch: 8.29 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11272046997244847		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.11272046997244847 | validation: 0.09642692091853429]
	TIME [epoch: 8.29 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12319750433513528		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.12319750433513528 | validation: 0.12473592307627654]
	TIME [epoch: 8.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21249910100179883		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.21249910100179883 | validation: 0.2113888770441591]
	TIME [epoch: 8.31 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14535248526939298		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.14535248526939298 | validation: 0.23791739805613935]
	TIME [epoch: 8.29 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12842799657125387		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.12842799657125387 | validation: 0.12412377658942125]
	TIME [epoch: 8.29 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10623447207521952		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.10623447207521952 | validation: 0.16281568963617152]
	TIME [epoch: 8.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12815765946468494		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.12815765946468494 | validation: 0.1536563492982643]
	TIME [epoch: 8.31 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16524985056263913		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.16524985056263913 | validation: 0.08203500432402336]
	TIME [epoch: 8.29 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17617499601203676		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.17617499601203676 | validation: 0.18731772768387103]
	TIME [epoch: 8.29 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14249111585821844		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.14249111585821844 | validation: 0.2079429809092804]
	TIME [epoch: 8.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1743361545243546		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.1743361545243546 | validation: 0.1435375222968366]
	TIME [epoch: 8.31 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14598478370061957		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.14598478370061957 | validation: 0.07717832281222299]
	TIME [epoch: 8.29 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12881160259558685		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.12881160259558685 | validation: 0.12579539491366679]
	TIME [epoch: 8.29 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11398156452748413		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.11398156452748413 | validation: 0.05389465889523477]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_579.pth
	Model improved!!!
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11175193206601539		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.11175193206601539 | validation: 0.09870045693694442]
	TIME [epoch: 8.31 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1625243385841367		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.1625243385841367 | validation: 0.10063318481218708]
	TIME [epoch: 8.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11437030951796805		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.11437030951796805 | validation: 0.08308443730926096]
	TIME [epoch: 8.29 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10879254225766152		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.10879254225766152 | validation: 0.07252094635529305]
	TIME [epoch: 8.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12452149978761817		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.12452149978761817 | validation: 0.13780880310064966]
	TIME [epoch: 8.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2152176626970675		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.2152176626970675 | validation: 0.28249151360302033]
	TIME [epoch: 8.29 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1828271246001937		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.1828271246001937 | validation: 0.1851477978294614]
	TIME [epoch: 8.29 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15494698839835366		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.15494698839835366 | validation: 0.12067204971969686]
	TIME [epoch: 8.31 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13746411536014772		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.13746411536014772 | validation: 0.06517784530525186]
	TIME [epoch: 8.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1235865662583843		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.1235865662583843 | validation: 0.10605885528541648]
	TIME [epoch: 8.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14152067257105827		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.14152067257105827 | validation: 0.1763122294252055]
	TIME [epoch: 8.29 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13205663289179587		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.13205663289179587 | validation: 0.09982467391237568]
	TIME [epoch: 8.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14980948916904774		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.14980948916904774 | validation: 0.13947569310988644]
	TIME [epoch: 8.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13051690314289333		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.13051690314289333 | validation: 0.1050525039551522]
	TIME [epoch: 8.29 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14467519281369476		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.14467519281369476 | validation: 0.09669473604415764]
	TIME [epoch: 8.29 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11296356033385728		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.11296356033385728 | validation: 0.09114005198740308]
	TIME [epoch: 8.31 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10757261608687303		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.10757261608687303 | validation: 0.2282977151145521]
	TIME [epoch: 8.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13305263741116286		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.13305263741116286 | validation: 0.08026433996856608]
	TIME [epoch: 8.29 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10638822615247057		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.10638822615247057 | validation: 0.15432747143016096]
	TIME [epoch: 8.29 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1203435854752658		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.1203435854752658 | validation: 0.1642307445833589]
	TIME [epoch: 8.31 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16444465584379442		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.16444465584379442 | validation: 0.16071316814818185]
	TIME [epoch: 8.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14401571252251252		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.14401571252251252 | validation: 0.1121694334158638]
	TIME [epoch: 8.29 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15694168896871577		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.15694168896871577 | validation: 0.30465964442912347]
	TIME [epoch: 8.29 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1824591000254307		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.1824591000254307 | validation: 0.1797554551586118]
	TIME [epoch: 8.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13632255928824114		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.13632255928824114 | validation: 0.14229761824713646]
	TIME [epoch: 8.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1610328385271915		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.1610328385271915 | validation: 0.11536922341922237]
	TIME [epoch: 8.29 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488658548920373		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.1488658548920373 | validation: 0.13493985885980492]
	TIME [epoch: 8.29 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12733160680082975		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.12733160680082975 | validation: 0.14042542150611648]
	TIME [epoch: 8.31 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1596429330241337		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.1596429330241337 | validation: 0.122234733561399]
	TIME [epoch: 8.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1395779972805436		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.1395779972805436 | validation: 0.10287551899349187]
	TIME [epoch: 8.29 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0977360909406754		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.0977360909406754 | validation: 0.07204594687561156]
	TIME [epoch: 8.29 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11693478812449501		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.11693478812449501 | validation: 0.14364768242648787]
	TIME [epoch: 8.31 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11417793856515268		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.11417793856515268 | validation: 0.11387392621377435]
	TIME [epoch: 8.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1516436785031716		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.1516436785031716 | validation: 0.08787224074078151]
	TIME [epoch: 8.29 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13762029753580707		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.13762029753580707 | validation: 0.08802760203359547]
	TIME [epoch: 8.29 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11268628550520399		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.11268628550520399 | validation: 0.07527232961126734]
	TIME [epoch: 8.31 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10144625083272878		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.10144625083272878 | validation: 0.10167994208614162]
	TIME [epoch: 8.31 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1082452488986827		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.1082452488986827 | validation: 0.12436762673496074]
	TIME [epoch: 8.29 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16691332184056046		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.16691332184056046 | validation: 0.21415931700797475]
	TIME [epoch: 8.29 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12476303309160311		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.12476303309160311 | validation: 0.14844256691273547]
	TIME [epoch: 8.31 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12796949126888443		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.12796949126888443 | validation: 0.30417120948597653]
	TIME [epoch: 8.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334176745194819		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.1334176745194819 | validation: 0.0751980328335178]
	TIME [epoch: 8.29 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1395726641027785		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.1395726641027785 | validation: 0.16414934207236945]
	TIME [epoch: 8.29 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16723136591474635		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.16723136591474635 | validation: 0.07235674527478352]
	TIME [epoch: 8.31 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12801548654385866		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.12801548654385866 | validation: 0.13618285872768224]
	TIME [epoch: 8.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11969100603269704		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.11969100603269704 | validation: 0.13239813972394013]
	TIME [epoch: 8.29 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10419867938756755		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.10419867938756755 | validation: 0.06475263508588211]
	TIME [epoch: 8.29 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1074139287265472		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.1074139287265472 | validation: 0.06786735138871972]
	TIME [epoch: 8.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10222347762565162		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.10222347762565162 | validation: 0.07871505866708538]
	TIME [epoch: 8.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12312541674043631		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.12312541674043631 | validation: 0.24694565026038964]
	TIME [epoch: 8.29 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11598129927578063		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.11598129927578063 | validation: 0.09530763139563281]
	TIME [epoch: 8.29 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16386465443219098		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.16386465443219098 | validation: 0.12740066843335499]
	TIME [epoch: 8.31 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13075904994284027		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.13075904994284027 | validation: 0.18360562811718995]
	TIME [epoch: 8.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10316303460431694		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.10316303460431694 | validation: 0.0691894015421267]
	TIME [epoch: 8.29 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09974145310739119		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.09974145310739119 | validation: 0.3107285715815581]
	TIME [epoch: 8.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12576323479264118		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.12576323479264118 | validation: 0.06400616736962793]
	TIME [epoch: 8.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11642172182098671		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.11642172182098671 | validation: 0.06185323500187136]
	TIME [epoch: 8.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08884612369264792		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.08884612369264792 | validation: 0.07880900054894281]
	TIME [epoch: 8.29 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13747998873955808		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.13747998873955808 | validation: 0.09785589731807937]
	TIME [epoch: 8.29 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13437046847932982		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.13437046847932982 | validation: 0.21444501024544044]
	TIME [epoch: 8.31 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13667638255858267		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.13667638255858267 | validation: 0.11563889655053675]
	TIME [epoch: 8.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12842099765717535		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.12842099765717535 | validation: 0.09793920466472703]
	TIME [epoch: 8.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08230729255806574		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.08230729255806574 | validation: 0.1126565416917285]
	TIME [epoch: 8.29 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09313571561637876		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.09313571561637876 | validation: 0.10450101124593895]
	TIME [epoch: 8.32 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13222825509065103		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.13222825509065103 | validation: 0.10994878348852538]
	TIME [epoch: 8.31 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09035781142869502		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.09035781142869502 | validation: 0.0819898908063823]
	TIME [epoch: 8.29 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17277087969874672		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.17277087969874672 | validation: 0.09597682911295286]
	TIME [epoch: 8.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1109118961912142		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.1109118961912142 | validation: 0.15110198019193818]
	TIME [epoch: 8.31 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14965305105286275		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.14965305105286275 | validation: 0.15310040540509162]
	TIME [epoch: 8.31 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10802557836155724		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.10802557836155724 | validation: 0.2303521847918671]
	TIME [epoch: 8.29 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1202948252495462		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.1202948252495462 | validation: 0.08786625247521718]
	TIME [epoch: 8.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09006372956273001		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.09006372956273001 | validation: 0.05461367601738616]
	TIME [epoch: 8.31 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13853796469448215		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.13853796469448215 | validation: 0.06974696400186522]
	TIME [epoch: 8.31 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10983594726538062		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.10983594726538062 | validation: 0.06256602115574447]
	TIME [epoch: 8.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09036883885490057		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.09036883885490057 | validation: 0.08735969329765321]
	TIME [epoch: 8.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11488095602422514		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.11488095602422514 | validation: 0.1337367475275922]
	TIME [epoch: 8.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09945856245721915		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.09945856245721915 | validation: 0.07962465748050901]
	TIME [epoch: 8.31 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10468055234919252		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.10468055234919252 | validation: 0.13104122824080777]
	TIME [epoch: 8.29 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12256102252473325		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.12256102252473325 | validation: 0.05844151195949866]
	TIME [epoch: 8.29 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1004112436261159		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.1004112436261159 | validation: 0.1472710541192356]
	TIME [epoch: 8.32 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.103355500762252		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.103355500762252 | validation: 0.14201196372200248]
	TIME [epoch: 8.31 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10107242535512062		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.10107242535512062 | validation: 0.14591035251647616]
	TIME [epoch: 8.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1138031778705422		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.1138031778705422 | validation: 0.1320059669668887]
	TIME [epoch: 8.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1414332132046597		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.1414332132046597 | validation: 0.12537221662669637]
	TIME [epoch: 8.31 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14474262891895723		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.14474262891895723 | validation: 0.23570922812959913]
	TIME [epoch: 8.31 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11012539409138408		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.11012539409138408 | validation: 0.06019857827839398]
	TIME [epoch: 8.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12695401643894844		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.12695401643894844 | validation: 0.07342037705851154]
	TIME [epoch: 8.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12128963559580644		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.12128963559580644 | validation: 0.07528363714762284]
	TIME [epoch: 8.31 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09030770466235595		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.09030770466235595 | validation: 0.07205171916450916]
	TIME [epoch: 8.31 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08772728591524069		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.08772728591524069 | validation: 0.08746997871334855]
	TIME [epoch: 8.29 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11320250571057529		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.11320250571057529 | validation: 0.17116761854909784]
	TIME [epoch: 8.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13887648427807933		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.13887648427807933 | validation: 0.057642016641915234]
	TIME [epoch: 8.31 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488077981683894		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.1488077981683894 | validation: 0.11041311096218308]
	TIME [epoch: 8.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09421086401583557		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.09421086401583557 | validation: 0.18603050237421886]
	TIME [epoch: 8.29 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12010936189177482		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.12010936189177482 | validation: 0.15150548258699664]
	TIME [epoch: 8.29 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09939467058815045		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.09939467058815045 | validation: 0.3057938766780762]
	TIME [epoch: 8.31 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1605558399767389		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.1605558399767389 | validation: 0.10548653668356389]
	TIME [epoch: 8.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18625672476266392		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.18625672476266392 | validation: 0.13872663784807868]
	TIME [epoch: 8.29 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1206807136263602		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.1206807136263602 | validation: 0.10068241767361032]
	TIME [epoch: 8.29 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08883552664844133		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.08883552664844133 | validation: 0.17894704727527114]
	TIME [epoch: 8.32 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1187554766671464		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.1187554766671464 | validation: 0.06301267459525313]
	TIME [epoch: 8.31 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07873042024745922		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.07873042024745922 | validation: 0.14187495849871667]
	TIME [epoch: 8.29 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12375453527323463		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.12375453527323463 | validation: 0.19328522621576955]
	TIME [epoch: 8.29 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12673168441440277		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.12673168441440277 | validation: 0.29284758312068254]
	TIME [epoch: 8.31 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297969844686518		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.1297969844686518 | validation: 0.07432563884466674]
	TIME [epoch: 8.31 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08758407635246082		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.08758407635246082 | validation: 0.06000849884421679]
	TIME [epoch: 8.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07490503052102908		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.07490503052102908 | validation: 0.08777329935826797]
	TIME [epoch: 8.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10193167102100256		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.10193167102100256 | validation: 0.1604980190696333]
	TIME [epoch: 8.31 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1218254143801479		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.1218254143801479 | validation: 0.14148725366700585]
	TIME [epoch: 8.31 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13220064742410917		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.13220064742410917 | validation: 0.10886370710674782]
	TIME [epoch: 8.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10404833164742433		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.10404833164742433 | validation: 0.06033670260200618]
	TIME [epoch: 8.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07611954023851689		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.07611954023851689 | validation: 0.19874632997869865]
	TIME [epoch: 8.32 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15705204739422743		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.15705204739422743 | validation: 0.19175635329859758]
	TIME [epoch: 8.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09216175748562025		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.09216175748562025 | validation: 0.09035684829109987]
	TIME [epoch: 8.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09715639845465801		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.09715639845465801 | validation: 0.0771612841608949]
	TIME [epoch: 8.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08442907200724108		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.08442907200724108 | validation: 0.2984476043380921]
	TIME [epoch: 8.31 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476900478039997		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.1476900478039997 | validation: 0.18997876045770581]
	TIME [epoch: 8.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11239958018112231		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.11239958018112231 | validation: 0.06851838252044799]
	TIME [epoch: 8.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08575719114306303		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.08575719114306303 | validation: 0.04562442180374749]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08476047894586576		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.08476047894586576 | validation: 0.08444326745930889]
	TIME [epoch: 8.32 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08800547261384217		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.08800547261384217 | validation: 0.11758182610834977]
	TIME [epoch: 8.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12634391039643464		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.12634391039643464 | validation: 0.06670881850495068]
	TIME [epoch: 8.29 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09722697767681027		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.09722697767681027 | validation: 0.20552332749904584]
	TIME [epoch: 8.29 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18959049374653256		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.18959049374653256 | validation: 0.07650897327060029]
	TIME [epoch: 8.31 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09382377627257238		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.09382377627257238 | validation: 0.05794999651227978]
	TIME [epoch: 8.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11356545576051427		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.11356545576051427 | validation: 0.08466800528730609]
	TIME [epoch: 8.29 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08256422929261027		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.08256422929261027 | validation: 0.12769769050550378]
	TIME [epoch: 8.29 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10363325676683402		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.10363325676683402 | validation: 0.0914399588575902]
	TIME [epoch: 8.31 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06832849643962413		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.06832849643962413 | validation: 0.09772557869638246]
	TIME [epoch: 8.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14440447630737027		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.14440447630737027 | validation: 0.06690016567085579]
	TIME [epoch: 8.29 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09218401409542251		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.09218401409542251 | validation: 0.12016231090407123]
	TIME [epoch: 8.29 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08461279382450135		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.08461279382450135 | validation: 0.33934352325905603]
	TIME [epoch: 8.32 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14372949382116634		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.14372949382116634 | validation: 0.08390516396633482]
	TIME [epoch: 8.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11678155201280771		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.11678155201280771 | validation: 0.116082970243852]
	TIME [epoch: 8.29 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12284797369208351		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.12284797369208351 | validation: 0.08034884552553473]
	TIME [epoch: 8.29 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09484012686621957		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.09484012686621957 | validation: 0.07659102723163029]
	TIME [epoch: 8.31 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10605568833861576		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.10605568833861576 | validation: 0.08141109880662419]
	TIME [epoch: 8.29 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14663891127096979		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.14663891127096979 | validation: 0.06267860691132354]
	TIME [epoch: 8.29 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08206517003581423		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.08206517003581423 | validation: 0.11813584220974926]
	TIME [epoch: 8.29 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11431854078719232		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.11431854078719232 | validation: 0.14876852047214095]
	TIME [epoch: 8.31 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09746727304967981		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.09746727304967981 | validation: 0.09819631754835872]
	TIME [epoch: 8.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10272923698634655		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.10272923698634655 | validation: 0.0645020597016721]
	TIME [epoch: 8.29 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0815458016271597		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.0815458016271597 | validation: 0.06905612070022973]
	TIME [epoch: 8.29 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07532749590244074		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.07532749590244074 | validation: 0.1956522645025611]
	TIME [epoch: 8.31 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1181911477599846		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.1181911477599846 | validation: 0.08278002663634257]
	TIME [epoch: 8.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12130440811744927		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.12130440811744927 | validation: 0.11891060027133976]
	TIME [epoch: 8.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10166953852518894		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.10166953852518894 | validation: 0.11903855729422624]
	TIME [epoch: 8.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15154995751034234		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.15154995751034234 | validation: 0.092537150164794]
	TIME [epoch: 8.32 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10068252991642641		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.10068252991642641 | validation: 0.10174496726125265]
	TIME [epoch: 8.29 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12022468037929208		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.12022468037929208 | validation: 0.07567346419701748]
	TIME [epoch: 8.29 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12509571078044618		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.12509571078044618 | validation: 0.16985008733105117]
	TIME [epoch: 8.29 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09429659293204296		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.09429659293204296 | validation: 0.06164483862491842]
	TIME [epoch: 8.31 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1269703917658631		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.1269703917658631 | validation: 0.06235177123795253]
	TIME [epoch: 8.29 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10623226167837604		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.10623226167837604 | validation: 0.08243736411668579]
	TIME [epoch: 8.29 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1054365143269056		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.1054365143269056 | validation: 0.16805994910501462]
	TIME [epoch: 8.29 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09774859946037769		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.09774859946037769 | validation: 0.0763648907889182]
	TIME [epoch: 8.31 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10342892264731962		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.10342892264731962 | validation: 0.04706710985104423]
	TIME [epoch: 8.29 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11493962809104026		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.11493962809104026 | validation: 0.11052990511170903]
	TIME [epoch: 8.29 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09826826693878958		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.09826826693878958 | validation: 0.066533036596125]
	TIME [epoch: 8.29 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07735613709855152		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.07735613709855152 | validation: 0.11293620909369814]
	TIME [epoch: 8.32 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12633972362374388		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.12633972362374388 | validation: 0.17127471134608274]
	TIME [epoch: 8.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12220883405751033		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.12220883405751033 | validation: 0.1111132683789045]
	TIME [epoch: 8.29 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09122096740925141		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.09122096740925141 | validation: 0.06869958808121279]
	TIME [epoch: 8.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0893372272396093		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.0893372272396093 | validation: 0.14788777611022802]
	TIME [epoch: 8.33 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10780553786934884		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.10780553786934884 | validation: 0.05420776942469497]
	TIME [epoch: 8.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11534922034763954		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.11534922034763954 | validation: 0.06866325843809555]
	TIME [epoch: 8.29 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11033811870726254		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.11033811870726254 | validation: 0.10797147722293823]
	TIME [epoch: 8.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08203024250512927		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.08203024250512927 | validation: 0.07066775572560237]
	TIME [epoch: 8.31 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10393851633227662		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.10393851633227662 | validation: 0.19183902761451832]
	TIME [epoch: 8.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12164029634893989		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.12164029634893989 | validation: 0.07365953463548446]
	TIME [epoch: 8.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15145585355084418		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.15145585355084418 | validation: 0.10042333891282625]
	TIME [epoch: 8.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10407904525842246		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.10407904525842246 | validation: 0.0751815494643422]
	TIME [epoch: 8.33 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12006720562975555		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.12006720562975555 | validation: 0.09105370425034226]
	TIME [epoch: 8.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1332832109904493		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.1332832109904493 | validation: 0.22435127228353458]
	TIME [epoch: 8.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11964950107864587		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.11964950107864587 | validation: 0.07172474617596081]
	TIME [epoch: 8.29 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11211541586781229		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.11211541586781229 | validation: 0.2427668157602244]
	TIME [epoch: 8.32 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09230196336872278		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.09230196336872278 | validation: 0.10612860493115611]
	TIME [epoch: 8.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11629370799801317		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.11629370799801317 | validation: 0.07019938255214941]
	TIME [epoch: 8.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08578242200443421		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.08578242200443421 | validation: 0.121796893811182]
	TIME [epoch: 8.29 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12994974545605092		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.12994974545605092 | validation: 0.15066872115589955]
	TIME [epoch: 8.32 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08359685599301513		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.08359685599301513 | validation: 0.23828284463969152]
	TIME [epoch: 8.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12389182530048597		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.12389182530048597 | validation: 0.08831548600773245]
	TIME [epoch: 8.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11252838824981999		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.11252838824981999 | validation: 0.10839204582463954]
	TIME [epoch: 8.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0819053404155923		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.0819053404155923 | validation: 0.061186957074178205]
	TIME [epoch: 8.32 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09619095836996346		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.09619095836996346 | validation: 0.08301160869963324]
	TIME [epoch: 8.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09899071162265		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.09899071162265 | validation: 0.15436829131793986]
	TIME [epoch: 8.29 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10817246129649778		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.10817246129649778 | validation: 0.0910382534239885]
	TIME [epoch: 8.29 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10643587301306086		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.10643587301306086 | validation: 0.08213056131474394]
	TIME [epoch: 8.31 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09598147730646274		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.09598147730646274 | validation: 0.08298504645476754]
	TIME [epoch: 8.29 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07944123859984537		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.07944123859984537 | validation: 0.06229732209478886]
	TIME [epoch: 8.29 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07561930802817526		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.07561930802817526 | validation: 0.10842964214017226]
	TIME [epoch: 8.29 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08958222290306557		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.08958222290306557 | validation: 0.10477424337086616]
	TIME [epoch: 8.32 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09154663013357763		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.09154663013357763 | validation: 0.10991848984340612]
	TIME [epoch: 8.29 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08887477134940067		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.08887477134940067 | validation: 0.09469639721200523]
	TIME [epoch: 8.29 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13211012181120962		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.13211012181120962 | validation: 0.12081593184532063]
	TIME [epoch: 8.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09373352439230812		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.09373352439230812 | validation: 0.06675298676843343]
	TIME [epoch: 8.32 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08213337502215508		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.08213337502215508 | validation: 0.08220936857204927]
	TIME [epoch: 8.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08892699366443417		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.08892699366443417 | validation: 0.07616600745806221]
	TIME [epoch: 8.29 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12698819942440553		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.12698819942440553 | validation: 0.07042128818401466]
	TIME [epoch: 8.29 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10094536191652137		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.10094536191652137 | validation: 0.06710597256428308]
	TIME [epoch: 8.31 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11448239025827316		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.11448239025827316 | validation: 0.07573862296930589]
	TIME [epoch: 8.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10799668404210072		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.10799668404210072 | validation: 0.09131266631378376]
	TIME [epoch: 8.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08361550769657122		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.08361550769657122 | validation: 0.09344099989772395]
	TIME [epoch: 8.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11197277941576766		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.11197277941576766 | validation: 0.07104241808884026]
	TIME [epoch: 8.32 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08478269964379456		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.08478269964379456 | validation: 0.0966250967389081]
	TIME [epoch: 8.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08632859996061235		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.08632859996061235 | validation: 0.08398818564279353]
	TIME [epoch: 8.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08000198788503629		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.08000198788503629 | validation: 0.08461329803666146]
	TIME [epoch: 8.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12842873696259888		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.12842873696259888 | validation: 0.10363059897577002]
	TIME [epoch: 8.32 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1254337107177927		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.1254337107177927 | validation: 0.07070790787676388]
	TIME [epoch: 8.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0969989106345079		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.0969989106345079 | validation: 0.07133530353339426]
	TIME [epoch: 8.29 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10566574203803603		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.10566574203803603 | validation: 0.15157564111645241]
	TIME [epoch: 8.29 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09668669652579508		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.09668669652579508 | validation: 0.07695669254553726]
	TIME [epoch: 8.32 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09384888768128341		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.09384888768128341 | validation: 0.06306585233222357]
	TIME [epoch: 8.31 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0909230698925108		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.0909230698925108 | validation: 0.07105979945934379]
	TIME [epoch: 8.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08475806017735872		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.08475806017735872 | validation: 0.11453393012715204]
	TIME [epoch: 8.29 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08922698451046075		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.08922698451046075 | validation: 0.14948126405541828]
	TIME [epoch: 8.32 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10400681746611515		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.10400681746611515 | validation: 0.09783474242694154]
	TIME [epoch: 8.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1197977282931965		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.1197977282931965 | validation: 0.07909218669159154]
	TIME [epoch: 8.29 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10067746555933635		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.10067746555933635 | validation: 0.14647385081958708]
	TIME [epoch: 8.29 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09180832859810006		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.09180832859810006 | validation: 0.09748962278164941]
	TIME [epoch: 8.31 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08056690968332907		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.08056690968332907 | validation: 0.06417567554402707]
	TIME [epoch: 8.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09034814415836015		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.09034814415836015 | validation: 0.1263092701588092]
	TIME [epoch: 8.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0999370739589673		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.0999370739589673 | validation: 0.13540640819971522]
	TIME [epoch: 8.29 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08983578297494928		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.08983578297494928 | validation: 0.05924786897373584]
	TIME [epoch: 8.32 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09160753453455035		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.09160753453455035 | validation: 0.07419305787204324]
	TIME [epoch: 8.29 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08893634642548792		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.08893634642548792 | validation: 0.07721262894328623]
	TIME [epoch: 8.29 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07606848457454575		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.07606848457454575 | validation: 0.1281825451650913]
	TIME [epoch: 8.29 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09204405332556542		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.09204405332556542 | validation: 0.07541628960397853]
	TIME [epoch: 8.32 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0955743755402903		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.0955743755402903 | validation: 0.0921551252331588]
	TIME [epoch: 8.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08699058891246857		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.08699058891246857 | validation: 0.058108876915911926]
	TIME [epoch: 8.29 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0853911282261768		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.0853911282261768 | validation: 0.1051517431141453]
	TIME [epoch: 8.29 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07379827099888733		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.07379827099888733 | validation: 0.16015866805008358]
	TIME [epoch: 8.31 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11545849209689822		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.11545849209689822 | validation: 0.11875018758952217]
	TIME [epoch: 8.29 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11021624866741897		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.11021624866741897 | validation: 0.10622795595668053]
	TIME [epoch: 8.29 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09489031893404586		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.09489031893404586 | validation: 0.08797386539483847]
	TIME [epoch: 8.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0880061352531053		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.0880061352531053 | validation: 0.11757990126840896]
	TIME [epoch: 8.32 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10933007517917648		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.10933007517917648 | validation: 0.06724333681281883]
	TIME [epoch: 8.29 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14982157084344722		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.14982157084344722 | validation: 0.08957953740525784]
	TIME [epoch: 8.29 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09277560585535437		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.09277560585535437 | validation: 0.06922395867114554]
	TIME [epoch: 8.29 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07939313883135284		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.07939313883135284 | validation: 0.09564922606330921]
	TIME [epoch: 8.31 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09369350174402062		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.09369350174402062 | validation: 0.10003343932482889]
	TIME [epoch: 8.29 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09687645655442487		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.09687645655442487 | validation: 0.06688762019244046]
	TIME [epoch: 8.29 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08390755593581571		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.08390755593581571 | validation: 0.07830340381093706]
	TIME [epoch: 8.29 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07796317952354528		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.07796317952354528 | validation: 0.1213898613117404]
	TIME [epoch: 8.31 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12505665778605624		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.12505665778605624 | validation: 0.11255862300986208]
	TIME [epoch: 8.29 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10188535184260541		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.10188535184260541 | validation: 0.056049863752554566]
	TIME [epoch: 8.29 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10016325710062839		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.10016325710062839 | validation: 0.07535308934290227]
	TIME [epoch: 8.29 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09826683742844097		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.09826683742844097 | validation: 0.07938875295546802]
	TIME [epoch: 8.31 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0837308112291258		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.0837308112291258 | validation: 0.08024411265643713]
	TIME [epoch: 8.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06635151461684247		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.06635151461684247 | validation: 0.10129480357398357]
	TIME [epoch: 8.29 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08776951544695324		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.08776951544695324 | validation: 0.1619790968265089]
	TIME [epoch: 8.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08921753700396515		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.08921753700396515 | validation: 0.10075306673275458]
	TIME [epoch: 8.31 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10684201290979782		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.10684201290979782 | validation: 0.09260387278359693]
	TIME [epoch: 8.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09511266236054143		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.09511266236054143 | validation: 0.1981001929936333]
	TIME [epoch: 8.29 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1387671387331585		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.1387671387331585 | validation: 0.09980126443895934]
	TIME [epoch: 8.29 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10919364055764964		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.10919364055764964 | validation: 0.0731441561819359]
	TIME [epoch: 8.31 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0929996730568723		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.0929996730568723 | validation: 0.13507704561420006]
	TIME [epoch: 8.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1036653562185963		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.1036653562185963 | validation: 0.06809951438662148]
	TIME [epoch: 8.29 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07747022996637956		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.07747022996637956 | validation: 0.10827889705157244]
	TIME [epoch: 8.29 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08448787844816444		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.08448787844816444 | validation: 0.10708260597903729]
	TIME [epoch: 8.33 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08419733231245642		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.08419733231245642 | validation: 0.08867376404174312]
	TIME [epoch: 8.29 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10173017438446293		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.10173017438446293 | validation: 0.10868122010883682]
	TIME [epoch: 8.29 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07782500762570733		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.07782500762570733 | validation: 0.07608121132993997]
	TIME [epoch: 8.29 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12936766449096465		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.12936766449096465 | validation: 0.06914462896362197]
	TIME [epoch: 8.32 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10129087886980466		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.10129087886980466 | validation: 0.06651682091530046]
	TIME [epoch: 8.29 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12780093304118387		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.12780093304118387 | validation: 0.11481916046521588]
	TIME [epoch: 8.28 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08468108366775992		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.08468108366775992 | validation: 0.05148039115151528]
	TIME [epoch: 8.29 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07705265535323265		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.07705265535323265 | validation: 0.07712785126990598]
	TIME [epoch: 8.32 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12394973362852708		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.12394973362852708 | validation: 0.1103683060755691]
	TIME [epoch: 8.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06297815983216312		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.06297815983216312 | validation: 0.05995588689552542]
	TIME [epoch: 8.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07628129533551034		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.07628129533551034 | validation: 0.07330886393081343]
	TIME [epoch: 8.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06776514185324387		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.06776514185324387 | validation: 0.06280294705167894]
	TIME [epoch: 8.32 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0925449770986074		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.0925449770986074 | validation: 0.17150132549394925]
	TIME [epoch: 8.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0887101945517105		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.0887101945517105 | validation: 0.28427797194940396]
	TIME [epoch: 8.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12948696600838128		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.12948696600838128 | validation: 0.09376938734662495]
	TIME [epoch: 8.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09119802498947815		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.09119802498947815 | validation: 0.10642258911316213]
	TIME [epoch: 8.32 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09510062193227417		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.09510062193227417 | validation: 0.06358456082056714]
	TIME [epoch: 8.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08331072789974284		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.08331072789974284 | validation: 0.10374952564888482]
	TIME [epoch: 8.31 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09305117729807087		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.09305117729807087 | validation: 0.1934175629700231]
	TIME [epoch: 8.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08994437562652181		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.08994437562652181 | validation: 0.052541860646794496]
	TIME [epoch: 8.32 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09671674988810294		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.09671674988810294 | validation: 0.18501206868777953]
	TIME [epoch: 8.29 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09719083374987209		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.09719083374987209 | validation: 0.06229125384197361]
	TIME [epoch: 8.29 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06664979571507328		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.06664979571507328 | validation: 0.0602471012008573]
	TIME [epoch: 8.29 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885896211838907		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.06885896211838907 | validation: 0.05713691011055645]
	TIME [epoch: 8.32 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059603117628570935		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.059603117628570935 | validation: 0.06797409908621788]
	TIME [epoch: 8.29 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11224725209527278		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.11224725209527278 | validation: 0.058076847125854134]
	TIME [epoch: 8.29 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11651673666367465		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.11651673666367465 | validation: 0.06719643111213483]
	TIME [epoch: 8.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07560931915223126		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.07560931915223126 | validation: 0.05021503941113831]
	TIME [epoch: 8.32 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09062764559155571		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.09062764559155571 | validation: 0.05810391013222529]
	TIME [epoch: 8.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0910455676720821		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.0910455676720821 | validation: 0.09548264793646247]
	TIME [epoch: 8.28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16466299878312382		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.16466299878312382 | validation: 0.22683618184186322]
	TIME [epoch: 8.29 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10075639406335132		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.10075639406335132 | validation: 0.09844691333717251]
	TIME [epoch: 8.32 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08110870878036194		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.08110870878036194 | validation: 0.07562403013567409]
	TIME [epoch: 8.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09308443031642762		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.09308443031642762 | validation: 0.12824920943832682]
	TIME [epoch: 8.29 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08972823673591901		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.08972823673591901 | validation: 0.08542634821212311]
	TIME [epoch: 8.29 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09322179292948102		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.09322179292948102 | validation: 0.05918910321800027]
	TIME [epoch: 8.32 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07652241052834961		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.07652241052834961 | validation: 0.06071129983413086]
	TIME [epoch: 8.29 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07129098555870707		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.07129098555870707 | validation: 0.1435828113779611]
	TIME [epoch: 8.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08249347061121826		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.08249347061121826 | validation: 0.1233184490905008]
	TIME [epoch: 8.29 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12096856490652763		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.12096856490652763 | validation: 0.07540800142257972]
	TIME [epoch: 8.33 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07058745129499151		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.07058745129499151 | validation: 0.08088694680356254]
	TIME [epoch: 8.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0588163388770772		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.0588163388770772 | validation: 0.07983814910143633]
	TIME [epoch: 8.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08507019811851811		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.08507019811851811 | validation: 0.13764632398593266]
	TIME [epoch: 8.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07980602551156335		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.07980602551156335 | validation: 0.0738973614428202]
	TIME [epoch: 8.31 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08152483691522283		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.08152483691522283 | validation: 0.14204915260084114]
	TIME [epoch: 8.29 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09632784875902392		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.09632784875902392 | validation: 0.07588116214459162]
	TIME [epoch: 8.28 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08573476875828746		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.08573476875828746 | validation: 0.10027781983461909]
	TIME [epoch: 8.29 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0744471342123268		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.0744471342123268 | validation: 0.05932356601054804]
	TIME [epoch: 8.31 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05965351950705968		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.05965351950705968 | validation: 0.09852003181565608]
	TIME [epoch: 8.29 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08240482987114495		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.08240482987114495 | validation: 0.07382177818644972]
	TIME [epoch: 8.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08156530906632938		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.08156530906632938 | validation: 0.053404483782640816]
	TIME [epoch: 8.28 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07563534543293544		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.07563534543293544 | validation: 0.0769537487570862]
	TIME [epoch: 8.31 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08441825929747174		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.08441825929747174 | validation: 0.09052723264651635]
	TIME [epoch: 8.29 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08258978425144455		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.08258978425144455 | validation: 0.0800811658452657]
	TIME [epoch: 8.29 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0928702436589086		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.0928702436589086 | validation: 0.05729703334825487]
	TIME [epoch: 8.29 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09556734172317975		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.09556734172317975 | validation: 0.06613313058054922]
	TIME [epoch: 8.31 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10033135996803935		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.10033135996803935 | validation: 0.07483449314827562]
	TIME [epoch: 8.29 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08280094274880401		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.08280094274880401 | validation: 0.0540519945297858]
	TIME [epoch: 8.29 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0732984288118077		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.0732984288118077 | validation: 0.09255183614811027]
	TIME [epoch: 8.28 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06221768800074223		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.06221768800074223 | validation: 0.05297469491054365]
	TIME [epoch: 8.31 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06356332033336452		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.06356332033336452 | validation: 0.06963438030880252]
	TIME [epoch: 8.29 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08178991473839665		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.08178991473839665 | validation: 0.07218496505007269]
	TIME [epoch: 8.29 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09161494234171967		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.09161494234171967 | validation: 0.07451294129902442]
	TIME [epoch: 8.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07259596518542825		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.07259596518542825 | validation: 0.11164757991527335]
	TIME [epoch: 8.32 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0672473276324039		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.0672473276324039 | validation: 0.17618958994850265]
	TIME [epoch: 8.29 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09407171305621999		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.09407171305621999 | validation: 0.10009240742612033]
	TIME [epoch: 8.29 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07492185320524722		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.07492185320524722 | validation: 0.04713495437165374]
	TIME [epoch: 8.29 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09972724647765568		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.09972724647765568 | validation: 0.12849246596207065]
	TIME [epoch: 8.32 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09145242661785515		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.09145242661785515 | validation: 0.06997094241525835]
	TIME [epoch: 8.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07291117576918141		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.07291117576918141 | validation: 0.059963217491461225]
	TIME [epoch: 8.29 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06057184076261703		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.06057184076261703 | validation: 0.08569787724045824]
	TIME [epoch: 8.29 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0816304564894122		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.0816304564894122 | validation: 0.05818601324597157]
	TIME [epoch: 8.32 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0888668800110973		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.0888668800110973 | validation: 0.057822726549711906]
	TIME [epoch: 8.29 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07335751806480025		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.07335751806480025 | validation: 0.08351792615218431]
	TIME [epoch: 8.29 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08719813905968542		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.08719813905968542 | validation: 0.07660497740392772]
	TIME [epoch: 8.29 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06955907790374642		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.06955907790374642 | validation: 0.13954293766601578]
	TIME [epoch: 8.32 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08004348039427725		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.08004348039427725 | validation: 0.06455553021284174]
	TIME [epoch: 8.29 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08317755508116184		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.08317755508116184 | validation: 0.06581900786356974]
	TIME [epoch: 8.29 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0637480138964071		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.0637480138964071 | validation: 0.059253058928337946]
	TIME [epoch: 8.29 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06882326613772238		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.06882326613772238 | validation: 0.07537991772049452]
	TIME [epoch: 8.31 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06236370667122285		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.06236370667122285 | validation: 0.06159063820699817]
	TIME [epoch: 8.29 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11160846729467351		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.11160846729467351 | validation: 0.1385329582197606]
	TIME [epoch: 8.29 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10683472150877316		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.10683472150877316 | validation: 0.09125757436900785]
	TIME [epoch: 8.3 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878990146489232		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.0878990146489232 | validation: 0.08969016056688713]
	TIME [epoch: 8.32 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10219013992528717		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.10219013992528717 | validation: 0.05737532799684447]
	TIME [epoch: 8.29 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07916415281065649		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.07916415281065649 | validation: 0.08316710592356118]
	TIME [epoch: 8.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07324599383648914		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.07324599383648914 | validation: 0.2561118889822761]
	TIME [epoch: 8.29 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09029253377432375		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.09029253377432375 | validation: 0.07716580748852171]
	TIME [epoch: 8.31 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10402888691027838		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.10402888691027838 | validation: 0.0757919949607754]
	TIME [epoch: 8.29 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07006249410896942		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.07006249410896942 | validation: 0.09020341229286642]
	TIME [epoch: 8.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07688399884871458		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.07688399884871458 | validation: 0.0662487923849109]
	TIME [epoch: 8.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08872572602705771		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.08872572602705771 | validation: 0.09056419107482658]
	TIME [epoch: 8.32 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06852520722484107		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.06852520722484107 | validation: 0.08364955911455327]
	TIME [epoch: 8.29 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07896952717055913		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.07896952717055913 | validation: 0.08663554320611908]
	TIME [epoch: 8.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08188872012339934		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.08188872012339934 | validation: 0.05961172270985764]
	TIME [epoch: 8.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0917399406161026		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.0917399406161026 | validation: 0.12877983957919917]
	TIME [epoch: 8.32 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08617274085528458		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.08617274085528458 | validation: 0.06737989487950534]
	TIME [epoch: 8.29 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07482955625953766		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.07482955625953766 | validation: 0.07247352398643334]
	TIME [epoch: 8.29 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05976767896421518		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.05976767896421518 | validation: 0.06542802387160059]
	TIME [epoch: 8.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07098370041999509		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.07098370041999509 | validation: 0.05745266265259234]
	TIME [epoch: 8.32 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0561018674132875		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.0561018674132875 | validation: 0.14238032250462485]
	TIME [epoch: 8.29 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09154537840953889		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.09154537840953889 | validation: 0.05306887621949591]
	TIME [epoch: 8.29 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05823012221298977		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.05823012221298977 | validation: 0.09076021321097492]
	TIME [epoch: 8.29 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060492499212453865		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.060492499212453865 | validation: 0.04515936309566914]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_943.pth
	Model improved!!!
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08240007529170114		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.08240007529170114 | validation: 0.13481241738847785]
	TIME [epoch: 8.29 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.077615375957751		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.077615375957751 | validation: 0.09506966395778169]
	TIME [epoch: 8.29 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10006755779834742		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.10006755779834742 | validation: 0.09148251392442708]
	TIME [epoch: 8.29 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07475692488985616		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.07475692488985616 | validation: 0.08376479011998894]
	TIME [epoch: 8.31 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05315152696213615		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.05315152696213615 | validation: 0.055451768031995405]
	TIME [epoch: 8.28 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0710893158376806		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.0710893158376806 | validation: 0.062324478078819336]
	TIME [epoch: 8.29 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062431617603494985		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.062431617603494985 | validation: 0.07904807984441553]
	TIME [epoch: 8.29 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08014873395342188		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.08014873395342188 | validation: 0.10090565361754009]
	TIME [epoch: 8.32 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08156534794676842		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.08156534794676842 | validation: 0.07273306381507588]
	TIME [epoch: 8.28 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06756607035261619		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.06756607035261619 | validation: 0.07562773160752528]
	TIME [epoch: 8.28 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06751341112870049		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.06751341112870049 | validation: 0.05140923059726044]
	TIME [epoch: 8.28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06993052738605268		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.06993052738605268 | validation: 0.06256340831644867]
	TIME [epoch: 8.31 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07467922265174505		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.07467922265174505 | validation: 0.07568585373891998]
	TIME [epoch: 8.29 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07304702547130394		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.07304702547130394 | validation: 0.05851860346295956]
	TIME [epoch: 8.29 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05610395030483832		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.05610395030483832 | validation: 0.06575001225633623]
	TIME [epoch: 8.29 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07039024882352543		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.07039024882352543 | validation: 0.12306367252164749]
	TIME [epoch: 8.31 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08487630674542038		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.08487630674542038 | validation: 0.10518280309180175]
	TIME [epoch: 8.28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08265084026791379		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.08265084026791379 | validation: 0.07313714981496683]
	TIME [epoch: 8.29 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07531056198523603		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.07531056198523603 | validation: 0.050131923836961856]
	TIME [epoch: 8.31 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08314075156406549		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.08314075156406549 | validation: 0.05825854826549922]
	TIME [epoch: 8.31 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09564698185345658		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.09564698185345658 | validation: 0.073206005196398]
	TIME [epoch: 8.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0701398648622812		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.0701398648622812 | validation: 0.0801227318988699]
	TIME [epoch: 8.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07393576391786866		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.07393576391786866 | validation: 0.12225713718340184]
	TIME [epoch: 8.29 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09066327592849366		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.09066327592849366 | validation: 0.06089395231120384]
	TIME [epoch: 8.31 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07822192680449162		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.07822192680449162 | validation: 0.056310341425930194]
	TIME [epoch: 8.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0710829470379071		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.0710829470379071 | validation: 0.046062934920723886]
	TIME [epoch: 8.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07374090184005311		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.07374090184005311 | validation: 0.09776703153792271]
	TIME [epoch: 8.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08784172141565035		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.08784172141565035 | validation: 0.0906222845192235]
	TIME [epoch: 8.32 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07223781558000997		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.07223781558000997 | validation: 0.10052931486575967]
	TIME [epoch: 8.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06406232842423765		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.06406232842423765 | validation: 0.060904168754839616]
	TIME [epoch: 8.29 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08728137110428472		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.08728137110428472 | validation: 0.07893513720331805]
	TIME [epoch: 8.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05566946293397408		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.05566946293397408 | validation: 0.050373604292941354]
	TIME [epoch: 8.31 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06324478847374178		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.06324478847374178 | validation: 0.09387088284988097]
	TIME [epoch: 8.29 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0917311184733873		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.0917311184733873 | validation: 0.09292889815530485]
	TIME [epoch: 8.29 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06409035759823414		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.06409035759823414 | validation: 0.0718038885107008]
	TIME [epoch: 8.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06959417935195211		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.06959417935195211 | validation: 0.0805408486056231]
	TIME [epoch: 8.32 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07076329746206013		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.07076329746206013 | validation: 0.08933713154280414]
	TIME [epoch: 8.29 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07179472449459938		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.07179472449459938 | validation: 0.09230402235979368]
	TIME [epoch: 8.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997869319543847		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.0997869319543847 | validation: 0.09735225638775948]
	TIME [epoch: 8.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701231210028106		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.07701231210028106 | validation: 0.06102100878876375]
	TIME [epoch: 8.32 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07374739548364627		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.07374739548364627 | validation: 0.05204347880963915]
	TIME [epoch: 8.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07325489876971672		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.07325489876971672 | validation: 0.08918430339056542]
	TIME [epoch: 8.29 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0803110791762789		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.0803110791762789 | validation: 0.07677047338877936]
	TIME [epoch: 8.31 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07015465225835939		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.07015465225835939 | validation: 0.2271426919980308]
	TIME [epoch: 8.31 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10948571635675346		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.10948571635675346 | validation: 0.09256346204080648]
	TIME [epoch: 8.29 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07670437975518879		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.07670437975518879 | validation: 0.08105637193338265]
	TIME [epoch: 8.29 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382802081566687		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.08382802081566687 | validation: 0.07067120065829893]
	TIME [epoch: 8.29 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06000469058494502		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.06000469058494502 | validation: 0.073269986884576]
	TIME [epoch: 8.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07292499519684012		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.07292499519684012 | validation: 0.07271673275525517]
	TIME [epoch: 8.28 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766906627503395		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.0766906627503395 | validation: 0.13748835350455652]
	TIME [epoch: 8.29 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07832327213453244		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.07832327213453244 | validation: 0.05735991641866593]
	TIME [epoch: 8.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09129134929310119		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.09129134929310119 | validation: 0.05553162152949495]
	TIME [epoch: 8.31 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06190436394350054		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.06190436394350054 | validation: 0.08378730928210848]
	TIME [epoch: 8.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06502429226633635		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.06502429226633635 | validation: 0.06758602855976756]
	TIME [epoch: 8.29 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07385029716732637		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.07385029716732637 | validation: 0.050267226688767416]
	TIME [epoch: 8.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04976551076398149		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.04976551076398149 | validation: 0.03754201999267244]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09192312083135631		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.09192312083135631 | validation: 0.18703514365012325]
	TIME [epoch: 8.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09691976943607566		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.09691976943607566 | validation: 0.04118892182908192]
	TIME [epoch: 8.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05655460349096384		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.05655460349096384 | validation: 0.06251441511329706]
	TIME [epoch: 8.32 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07590238178351721		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.07590238178351721 | validation: 0.09295180887400498]
	TIME [epoch: 8.31 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11040880771031884		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.11040880771031884 | validation: 0.12271259747078868]
	TIME [epoch: 8.29 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284597576431334		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.07284597576431334 | validation: 0.0934316121742386]
	TIME [epoch: 8.29 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056471729962669935		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.056471729962669935 | validation: 0.05646451713308631]
	TIME [epoch: 8.31 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07196715297485619		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.07196715297485619 | validation: 0.03833738849217736]
	TIME [epoch: 8.31 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06355791662257299		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.06355791662257299 | validation: 0.10130989372187836]
	TIME [epoch: 8.29 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06564206605703209		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.06564206605703209 | validation: 0.0679013658601875]
	TIME [epoch: 8.29 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06228210306757413		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.06228210306757413 | validation: 0.07092820758682736]
	TIME [epoch: 8.31 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07584750229125754		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.07584750229125754 | validation: 0.1036456658384939]
	TIME [epoch: 8.29 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07790719879991885		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.07790719879991885 | validation: 0.06076150493108319]
	TIME [epoch: 8.29 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06741904094278185		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.06741904094278185 | validation: 0.051537370846699196]
	TIME [epoch: 8.28 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05726202111020188		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.05726202111020188 | validation: 0.047568329249502085]
	TIME [epoch: 8.31 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05901350020168837		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.05901350020168837 | validation: 0.09932234209885032]
	TIME [epoch: 8.29 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0809731116982532		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.0809731116982532 | validation: 0.07417513636791734]
	TIME [epoch: 8.29 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07403567641344524		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.07403567641344524 | validation: 0.08892998863753804]
	TIME [epoch: 8.29 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07090918102207015		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.07090918102207015 | validation: 0.05887269277727636]
	TIME [epoch: 8.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0540103004901706		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.0540103004901706 | validation: 0.047503208248583395]
	TIME [epoch: 8.31 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07831576849287944		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.07831576849287944 | validation: 0.07557276490440162]
	TIME [epoch: 8.29 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07419240253193785		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.07419240253193785 | validation: 0.06983102555508006]
	TIME [epoch: 8.29 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06144697534365038		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.06144697534365038 | validation: 0.050721989344730364]
	TIME [epoch: 8.31 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05737777445586497		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.05737777445586497 | validation: 0.07938833126197975]
	TIME [epoch: 8.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0811717657747725		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.0811717657747725 | validation: 0.07485717717372242]
	TIME [epoch: 8.29 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06781097849315351		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.06781097849315351 | validation: 0.049498717825045356]
	TIME [epoch: 8.28 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07998944433783446		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.07998944433783446 | validation: 0.07204801402698723]
	TIME [epoch: 8.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07500821942456012		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.07500821942456012 | validation: 0.10501810086763205]
	TIME [epoch: 8.29 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0798886108831279		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.0798886108831279 | validation: 0.0538803863573227]
	TIME [epoch: 8.29 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05529637288453924		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.05529637288453924 | validation: 0.08508054050712685]
	TIME [epoch: 8.29 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06003881305477338		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.06003881305477338 | validation: 0.05572032156586495]
	TIME [epoch: 8.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06746620138400686		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.06746620138400686 | validation: 0.06353001454372742]
	TIME [epoch: 8.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0515410518745105		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.0515410518745105 | validation: 0.06842383231246857]
	TIME [epoch: 8.29 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07217474710751871		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.07217474710751871 | validation: 0.059870854893570344]
	TIME [epoch: 8.28 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04891498829068379		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.04891498829068379 | validation: 0.04687356643125233]
	TIME [epoch: 8.31 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06160333612696327		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.06160333612696327 | validation: 0.06333072710701962]
	TIME [epoch: 8.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05777321314774474		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.05777321314774474 | validation: 0.105732989877837]
	TIME [epoch: 8.29 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10101717067751623		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.10101717067751623 | validation: 0.07653336580575665]
	TIME [epoch: 8.29 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07596031261561162		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.07596031261561162 | validation: 0.06369798701198667]
	TIME [epoch: 8.3 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06164498814543867		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.06164498814543867 | validation: 0.07100046723470196]
	TIME [epoch: 8.29 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08267970940174696		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.08267970940174696 | validation: 0.06632472403252201]
	TIME [epoch: 8.29 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06328258712201089		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.06328258712201089 | validation: 0.11485921977947194]
	TIME [epoch: 8.28 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06604454531492676		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.06604454531492676 | validation: 0.07089301613891667]
	TIME [epoch: 8.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936923621064838		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.05936923621064838 | validation: 0.058688716470302216]
	TIME [epoch: 8.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062378646725693265		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.062378646725693265 | validation: 0.058930302101949245]
	TIME [epoch: 8.29 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05136741593389035		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.05136741593389035 | validation: 0.03427241943610013]
	TIME [epoch: 8.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04676978928702901		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.04676978928702901 | validation: 0.06978243172776888]
	TIME [epoch: 8.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07545109266841286		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.07545109266841286 | validation: 0.058538500033795446]
	TIME [epoch: 8.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057074751932955546		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.057074751932955546 | validation: 0.0745112926913609]
	TIME [epoch: 8.29 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05797532496616061		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.05797532496616061 | validation: 0.05026600761906232]
	TIME [epoch: 8.29 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378283823759988		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.06378283823759988 | validation: 0.08923856859425965]
	TIME [epoch: 8.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052319047427462		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.052319047427462 | validation: 0.037377130279271094]
	TIME [epoch: 8.3 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047866712620179885		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.047866712620179885 | validation: 0.06555326778083573]
	TIME [epoch: 8.29 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06877320110578676		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.06877320110578676 | validation: 0.06030324301479591]
	TIME [epoch: 8.29 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07071059895943711		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.07071059895943711 | validation: 0.05720588740882733]
	TIME [epoch: 8.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05963160550026193		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.05963160550026193 | validation: 0.05807943576588254]
	TIME [epoch: 8.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09576917649622715		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.09576917649622715 | validation: 0.05351729940852267]
	TIME [epoch: 8.28 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049258335078089174		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.049258335078089174 | validation: 0.06306326378255499]
	TIME [epoch: 8.29 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09202585538499047		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.09202585538499047 | validation: 0.08196138128825323]
	TIME [epoch: 8.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09474282008410222		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.09474282008410222 | validation: 0.0890725961092462]
	TIME [epoch: 8.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08338103610607142		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.08338103610607142 | validation: 0.06245132021066126]
	TIME [epoch: 8.28 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06890226612189827		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.06890226612189827 | validation: 0.06933946371410445]
	TIME [epoch: 8.29 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06893897029280763		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.06893897029280763 | validation: 0.04771950962374665]
	TIME [epoch: 8.31 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07013885050269232		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.07013885050269232 | validation: 0.07949029009908444]
	TIME [epoch: 8.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05893240773931072		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.05893240773931072 | validation: 0.14996014450233996]
	TIME [epoch: 8.29 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08270608398948429		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.08270608398948429 | validation: 0.05120701164153074]
	TIME [epoch: 8.29 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04690369335389284		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.04690369335389284 | validation: 0.06919497287316029]
	TIME [epoch: 8.31 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04999887352433395		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.04999887352433395 | validation: 0.06156685692651113]
	TIME [epoch: 8.29 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06026719218872436		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.06026719218872436 | validation: 0.056914382743995476]
	TIME [epoch: 8.29 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048885551839734864		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.048885551839734864 | validation: 0.06735124023977904]
	TIME [epoch: 8.29 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05809760557390634		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.05809760557390634 | validation: 0.1291302319623164]
	TIME [epoch: 8.31 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06117484098294742		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.06117484098294742 | validation: 0.07628332688080211]
	TIME [epoch: 8.29 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062114100698586916		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.062114100698586916 | validation: 0.052968663080552106]
	TIME [epoch: 8.28 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0467399695863361		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.0467399695863361 | validation: 0.041935508233997595]
	TIME [epoch: 8.29 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07093620734008323		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.07093620734008323 | validation: 0.05450780155568985]
	TIME [epoch: 8.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06817973751067195		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.06817973751067195 | validation: 0.04845290964889916]
	TIME [epoch: 8.29 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057453942245563286		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.057453942245563286 | validation: 0.060073938109365635]
	TIME [epoch: 8.28 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06832263496797684		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.06832263496797684 | validation: 0.10323151859458929]
	TIME [epoch: 8.29 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07601999896508246		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.07601999896508246 | validation: 0.04302717510674846]
	TIME [epoch: 8.31 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045842739651091424		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.045842739651091424 | validation: 0.1772398654291712]
	TIME [epoch: 8.29 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07353064584650545		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.07353064584650545 | validation: 0.04950050507028203]
	TIME [epoch: 8.29 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05829395072274973		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.05829395072274973 | validation: 0.04662202510842653]
	TIME [epoch: 8.29 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04544393373698298		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.04544393373698298 | validation: 0.08404843971813598]
	TIME [epoch: 8.31 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052577852219901355		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.052577852219901355 | validation: 0.04782425048957517]
	TIME [epoch: 8.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050807150149604706		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.050807150149604706 | validation: 0.062215577576684875]
	TIME [epoch: 8.29 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05313901691580886		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.05313901691580886 | validation: 0.04815918672246667]
	TIME [epoch: 8.29 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05736163029957403		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.05736163029957403 | validation: 0.05375079830515904]
	TIME [epoch: 8.31 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06648389171313987		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.06648389171313987 | validation: 0.058960061470348046]
	TIME [epoch: 8.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06975058759737829		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.06975058759737829 | validation: 0.0794199157254753]
	TIME [epoch: 8.29 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06580990608082421		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.06580990608082421 | validation: 0.04778452115995975]
	TIME [epoch: 8.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061185134386885255		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.061185134386885255 | validation: 0.060271335681440025]
	TIME [epoch: 8.31 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105917566931875		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.06105917566931875 | validation: 0.06595867968674415]
	TIME [epoch: 8.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05986755090510978		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.05986755090510978 | validation: 0.0631889068929903]
	TIME [epoch: 8.29 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06163765018313351		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.06163765018313351 | validation: 0.061256082140331264]
	TIME [epoch: 8.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05212025562871762		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.05212025562871762 | validation: 0.04698924785664621]
	TIME [epoch: 8.31 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056998348609913055		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.056998348609913055 | validation: 0.08495251925868572]
	TIME [epoch: 8.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05269913579669579		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.05269913579669579 | validation: 0.0647471272155527]
	TIME [epoch: 8.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05198112790204704		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.05198112790204704 | validation: 0.06051331012142812]
	TIME [epoch: 8.29 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06888404817824739		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.06888404817824739 | validation: 0.06316216457803091]
	TIME [epoch: 8.32 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0462832031175984		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.0462832031175984 | validation: 0.16008469965137528]
	TIME [epoch: 8.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11499631716170729		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.11499631716170729 | validation: 0.08247440485450125]
	TIME [epoch: 8.29 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500876385376499		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.06500876385376499 | validation: 0.059024930368158465]
	TIME [epoch: 8.29 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08786215756502266		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.08786215756502266 | validation: 0.15416542783811832]
	TIME [epoch: 8.31 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06583700421519588		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.06583700421519588 | validation: 0.06440012639753498]
	TIME [epoch: 8.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05316085152836003		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.05316085152836003 | validation: 0.06233551372534387]
	TIME [epoch: 8.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051832822269663716		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.051832822269663716 | validation: 0.08393561182602047]
	TIME [epoch: 8.29 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060648076316853636		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.060648076316853636 | validation: 0.09668120298887975]
	TIME [epoch: 8.31 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06862730643686962		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.06862730643686962 | validation: 0.06306568967701856]
	TIME [epoch: 8.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07234246651092233		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.07234246651092233 | validation: 0.08446564102943063]
	TIME [epoch: 8.29 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07084134929111277		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.07084134929111277 | validation: 0.09656871694416791]
	TIME [epoch: 8.29 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07448317980093959		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.07448317980093959 | validation: 0.11931949119272703]
	TIME [epoch: 8.31 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0664032392902901		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.0664032392902901 | validation: 0.04773606101995898]
	TIME [epoch: 8.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051729675111177834		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.051729675111177834 | validation: 0.1487192136377305]
	TIME [epoch: 8.29 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06485083033423542		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.06485083033423542 | validation: 0.05301522975465141]
	TIME [epoch: 8.29 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05425311088758792		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.05425311088758792 | validation: 0.04473320382284496]
	TIME [epoch: 8.32 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0843341361542942		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.0843341361542942 | validation: 0.2366704815229214]
	TIME [epoch: 8.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09080484148657877		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.09080484148657877 | validation: 0.0465334400195926]
	TIME [epoch: 8.29 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055231327455532796		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.055231327455532796 | validation: 0.07608943280201588]
	TIME [epoch: 8.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051502160557466516		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.051502160557466516 | validation: 0.1170477418363376]
	TIME [epoch: 8.32 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05896176070832343		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.05896176070832343 | validation: 0.08015632714134685]
	TIME [epoch: 8.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06349056645535059		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.06349056645535059 | validation: 0.06435999672776363]
	TIME [epoch: 8.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04982530361711367		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.04982530361711367 | validation: 0.047932168348658544]
	TIME [epoch: 8.29 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07297002534252336		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.07297002534252336 | validation: 0.08151287374034025]
	TIME [epoch: 8.32 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07298139852167537		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.07298139852167537 | validation: 0.078242312986344]
	TIME [epoch: 8.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06850468899710713		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.06850468899710713 | validation: 0.06751663732726176]
	TIME [epoch: 8.29 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0798092966466628		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.0798092966466628 | validation: 0.04103932782073249]
	TIME [epoch: 8.29 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057036248627504706		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.057036248627504706 | validation: 0.055369908586388246]
	TIME [epoch: 8.31 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05859532662859131		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.05859532662859131 | validation: 0.054094771776284106]
	TIME [epoch: 8.3 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055482816226082185		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.055482816226082185 | validation: 0.09405621492441654]
	TIME [epoch: 8.29 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053891265275758424		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.053891265275758424 | validation: 0.05190505373722494]
	TIME [epoch: 8.29 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05124624963203156		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.05124624963203156 | validation: 0.059194137318278044]
	TIME [epoch: 8.32 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06113710417933922		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.06113710417933922 | validation: 0.06222618099772491]
	TIME [epoch: 8.29 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05650504301361707		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.05650504301361707 | validation: 0.05650693700940432]
	TIME [epoch: 8.29 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04934118127466018		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.04934118127466018 | validation: 0.046899795453223425]
	TIME [epoch: 8.29 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058986862667788666		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.058986862667788666 | validation: 0.08347179115278078]
	TIME [epoch: 8.3 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05792556726362537		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.05792556726362537 | validation: 0.03900749552353043]
	TIME [epoch: 8.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052993899354602414		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.052993899354602414 | validation: 0.09181274056621809]
	TIME [epoch: 8.29 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06467309871158236		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.06467309871158236 | validation: 0.07372431989674505]
	TIME [epoch: 8.29 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0950238585096789		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.0950238585096789 | validation: 0.04522860346369403]
	TIME [epoch: 8.31 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045811370311472935		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.045811370311472935 | validation: 0.07179865714091166]
	TIME [epoch: 8.29 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05516028667551716		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.05516028667551716 | validation: 0.2291585737019654]
	TIME [epoch: 8.29 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08704973039692301		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.08704973039692301 | validation: 0.05008431874636488]
	TIME [epoch: 8.29 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08880845969049625		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.08880845969049625 | validation: 0.059611924355794925]
	TIME [epoch: 8.31 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07577037998094878		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.07577037998094878 | validation: 0.08520599791150366]
	TIME [epoch: 8.29 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06918737470982307		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.06918737470982307 | validation: 0.053505432937101916]
	TIME [epoch: 8.29 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06918305911577015		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.06918305911577015 | validation: 0.09358069119754156]
	TIME [epoch: 8.29 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07122226116210202		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.07122226116210202 | validation: 0.11907246252043452]
	TIME [epoch: 8.31 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06574449310891148		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.06574449310891148 | validation: 0.05568340585062967]
	TIME [epoch: 8.29 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05810285888778777		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.05810285888778777 | validation: 0.06008375013205951]
	TIME [epoch: 8.28 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06985751851547996		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.06985751851547996 | validation: 0.05936527421338538]
	TIME [epoch: 8.28 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060556697364857914		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.060556697364857914 | validation: 0.1351616171367701]
	TIME [epoch: 8.31 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533606773428044		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.06533606773428044 | validation: 0.057227991025677175]
	TIME [epoch: 8.29 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047631799208123854		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.047631799208123854 | validation: 0.05897605229517683]
	TIME [epoch: 8.29 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04435463349554949		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.04435463349554949 | validation: 0.0495032053337847]
	TIME [epoch: 8.29 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05170854746022176		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.05170854746022176 | validation: 0.06598288434716185]
	TIME [epoch: 8.31 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06657391536350907		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.06657391536350907 | validation: 0.08485927902016671]
	TIME [epoch: 8.29 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053041238089478415		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.053041238089478415 | validation: 0.0643145530012975]
	TIME [epoch: 8.29 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04580181855933781		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.04580181855933781 | validation: 0.08432687495655591]
	TIME [epoch: 8.29 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05678192091503267		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.05678192091503267 | validation: 0.05339626718212258]
	TIME [epoch: 8.31 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05921063964264668		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.05921063964264668 | validation: 0.058729944672074215]
	TIME [epoch: 8.29 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045029937820963886		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.045029937820963886 | validation: 0.05447598023349845]
	TIME [epoch: 8.29 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0702659203955146		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.0702659203955146 | validation: 0.08966117241662708]
	TIME [epoch: 8.29 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05360249720001816		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.05360249720001816 | validation: 0.04922342533401695]
	TIME [epoch: 8.31 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05039723806266344		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.05039723806266344 | validation: 0.05169247618047387]
	TIME [epoch: 8.29 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04987060972221298		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.04987060972221298 | validation: 0.07210682446729536]
	TIME [epoch: 8.29 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04946935902169582		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.04946935902169582 | validation: 0.05011840506015739]
	TIME [epoch: 8.29 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05209947424369964		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.05209947424369964 | validation: 0.05273468497115108]
	TIME [epoch: 8.31 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07308383497415014		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.07308383497415014 | validation: 0.04260590796450971]
	TIME [epoch: 8.3 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06150251891771845		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.06150251891771845 | validation: 0.04670660256470127]
	TIME [epoch: 8.29 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05529553535352867		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.05529553535352867 | validation: 0.0806819111028538]
	TIME [epoch: 8.29 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07544079573826563		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.07544079573826563 | validation: 0.0456952911108096]
	TIME [epoch: 8.31 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04848098148502422		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.04848098148502422 | validation: 0.05376436254139241]
	TIME [epoch: 8.29 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05095297110313775		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.05095297110313775 | validation: 0.04612588624786346]
	TIME [epoch: 8.29 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05073900446923054		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.05073900446923054 | validation: 0.0669162622857633]
	TIME [epoch: 8.29 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049507749915619126		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.049507749915619126 | validation: 0.051882398767014906]
	TIME [epoch: 8.32 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04391301599467275		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.04391301599467275 | validation: 0.0849635607249622]
	TIME [epoch: 8.29 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05398217004865304		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.05398217004865304 | validation: 0.04996686591625348]
	TIME [epoch: 8.29 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06982663371987455		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.06982663371987455 | validation: 0.056723075735078746]
	TIME [epoch: 8.29 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06299129933532441		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.06299129933532441 | validation: 0.04679680781759985]
	TIME [epoch: 8.31 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05851071974235311		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.05851071974235311 | validation: 0.04567239755954447]
	TIME [epoch: 8.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04427275549627103		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.04427275549627103 | validation: 0.04883862098915232]
	TIME [epoch: 8.29 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06415138279589515		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.06415138279589515 | validation: 0.06142460618035213]
	TIME [epoch: 8.29 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05118621927527003		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.05118621927527003 | validation: 0.04224803346707562]
	TIME [epoch: 8.31 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04669057801342885		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.04669057801342885 | validation: 0.053531296308432494]
	TIME [epoch: 8.29 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05944668577564823		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.05944668577564823 | validation: 0.04460923005785607]
	TIME [epoch: 8.29 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043480640422539664		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.043480640422539664 | validation: 0.05931286325737989]
	TIME [epoch: 8.29 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05610647156712566		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.05610647156712566 | validation: 0.08893913469973161]
	TIME [epoch: 8.31 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06589916196734708		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.06589916196734708 | validation: 0.04733619775303336]
	TIME [epoch: 8.29 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04449879377108382		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.04449879377108382 | validation: 0.054038851810212514]
	TIME [epoch: 8.29 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06363191337474179		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.06363191337474179 | validation: 0.0999105718901834]
	TIME [epoch: 8.29 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07200924324138477		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.07200924324138477 | validation: 0.03952913264968837]
	TIME [epoch: 8.31 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05150438039444967		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.05150438039444967 | validation: 0.04954105647716228]
	TIME [epoch: 8.29 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07469370706878087		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.07469370706878087 | validation: 0.04366211554183655]
	TIME [epoch: 8.29 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06029538921107362		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.06029538921107362 | validation: 0.04100466662434152]
	TIME [epoch: 8.29 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05138063627620011		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.05138063627620011 | validation: 0.06414525012054428]
	TIME [epoch: 8.31 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04917013523194883		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.04917013523194883 | validation: 0.05817288980293832]
	TIME [epoch: 8.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05872835683746601		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.05872835683746601 | validation: 0.054553878667512504]
	TIME [epoch: 8.29 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043661679904870944		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.043661679904870944 | validation: 0.03863666461740933]
	TIME [epoch: 8.29 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05020043356468236		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.05020043356468236 | validation: 0.03775041160077314]
	TIME [epoch: 8.31 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04583725982809889		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.04583725982809889 | validation: 0.04277930410161222]
	TIME [epoch: 8.29 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05477990015677063		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.05477990015677063 | validation: 0.05797168395178816]
	TIME [epoch: 8.28 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047428682683102644		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.047428682683102644 | validation: 0.07183610858423849]
	TIME [epoch: 8.29 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05232413545509333		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.05232413545509333 | validation: 0.043719770651223955]
	TIME [epoch: 8.32 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04138964958058876		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.04138964958058876 | validation: 0.07767626913013354]
	TIME [epoch: 8.29 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05866665170167319		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.05866665170167319 | validation: 0.041625127771820675]
	TIME [epoch: 8.29 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08439333496658723		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.08439333496658723 | validation: 0.06767794238131118]
	TIME [epoch: 8.29 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05331483490965115		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.05331483490965115 | validation: 0.07021548158601823]
	TIME [epoch: 8.31 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048357917457520064		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.048357917457520064 | validation: 0.038896659410801546]
	TIME [epoch: 8.29 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04182155018552355		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.04182155018552355 | validation: 0.089203787920239]
	TIME [epoch: 8.29 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04226416917494938		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.04226416917494938 | validation: 0.07541349620214909]
	TIME [epoch: 8.28 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05105170969037354		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.05105170969037354 | validation: 0.04375884417010997]
	TIME [epoch: 8.31 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05496861772614355		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.05496861772614355 | validation: 0.11067496612793379]
	TIME [epoch: 8.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055283081460532194		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.055283081460532194 | validation: 0.0797995895278581]
	TIME [epoch: 8.29 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0544599603336066		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.0544599603336066 | validation: 0.03564990555392064]
	TIME [epoch: 8.29 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0401105269821289		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.0401105269821289 | validation: 0.06283277569171639]
	TIME [epoch: 8.31 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06119631731202228		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.06119631731202228 | validation: 0.05613766847959501]
	TIME [epoch: 8.28 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046995450999961816		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.046995450999961816 | validation: 0.05825065816732372]
	TIME [epoch: 8.29 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07399916692253808		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.07399916692253808 | validation: 0.08289824009134944]
	TIME [epoch: 8.29 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049243606016003236		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.049243606016003236 | validation: 0.08130802405079972]
	TIME [epoch: 8.31 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06050538343313357		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.06050538343313357 | validation: 0.028826638741817272]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1219.pth
	Model improved!!!
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047229351272448185		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.047229351272448185 | validation: 0.04061693944362833]
	TIME [epoch: 8.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03943686134423067		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.03943686134423067 | validation: 0.033865975562784284]
	TIME [epoch: 8.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06775442293309816		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.06775442293309816 | validation: 0.05746534490133201]
	TIME [epoch: 8.33 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07389280154381607		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.07389280154381607 | validation: 0.04879879199754]
	TIME [epoch: 8.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052397217177130896		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.052397217177130896 | validation: 0.04696446489541254]
	TIME [epoch: 8.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05286980540529883		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.05286980540529883 | validation: 0.05398267216147512]
	TIME [epoch: 8.32 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04166352921251848		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.04166352921251848 | validation: 0.04688193819330552]
	TIME [epoch: 8.32 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03694612098044208		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.03694612098044208 | validation: 0.032341373846305296]
	TIME [epoch: 8.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05389430348580201		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.05389430348580201 | validation: 0.06480725092275669]
	TIME [epoch: 8.31 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040379156754952655		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.040379156754952655 | validation: 0.03881623244686627]
	TIME [epoch: 8.32 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048101261773482354		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.048101261773482354 | validation: 0.07472886428677378]
	TIME [epoch: 8.32 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05745778702622493		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.05745778702622493 | validation: 0.03588483922308526]
	TIME [epoch: 8.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056502725428954445		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.056502725428954445 | validation: 0.06274425558125772]
	TIME [epoch: 8.31 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050172626150000864		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.050172626150000864 | validation: 0.03623749804237883]
	TIME [epoch: 8.32 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037911982672325775		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.037911982672325775 | validation: 0.06153499453848458]
	TIME [epoch: 8.31 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05645547072220396		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.05645547072220396 | validation: 0.04668264502302076]
	TIME [epoch: 8.3 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07568006123201951		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.07568006123201951 | validation: 0.07051613591056295]
	TIME [epoch: 8.3 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04309289088450889		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.04309289088450889 | validation: 0.07405703546235065]
	TIME [epoch: 8.32 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05094044176795345		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.05094044176795345 | validation: 0.06845131301420854]
	TIME [epoch: 8.31 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0462839718115747		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.0462839718115747 | validation: 0.060049900524531935]
	TIME [epoch: 8.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05163679306210396		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.05163679306210396 | validation: 0.06942665910450402]
	TIME [epoch: 8.3 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673027245571002		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.04673027245571002 | validation: 0.05380361002657391]
	TIME [epoch: 8.32 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04843822894748105		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.04843822894748105 | validation: 0.07922986176363453]
	TIME [epoch: 8.31 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058497898409207924		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.058497898409207924 | validation: 0.06261791828668468]
	TIME [epoch: 8.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05348551506393294		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.05348551506393294 | validation: 0.038457446518006894]
	TIME [epoch: 8.31 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04464292422710683		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.04464292422710683 | validation: 0.05075258793955475]
	TIME [epoch: 8.32 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04628923427577693		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.04628923427577693 | validation: 0.03683076302640993]
	TIME [epoch: 8.32 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05614823395558177		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.05614823395558177 | validation: 0.1065293391519092]
	TIME [epoch: 8.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0550255419246526		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.0550255419246526 | validation: 0.05249907716741641]
	TIME [epoch: 8.31 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05073965587198239		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.05073965587198239 | validation: 0.0796570605953983]
	TIME [epoch: 8.32 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04766573441028154		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.04766573441028154 | validation: 0.04371665848326607]
	TIME [epoch: 8.31 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053731666525743606		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.053731666525743606 | validation: 0.0467670266606669]
	TIME [epoch: 8.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042520316862286384		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.042520316862286384 | validation: 0.05302013888504943]
	TIME [epoch: 8.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047931454148810004		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.047931454148810004 | validation: 0.044294871471716214]
	TIME [epoch: 8.32 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048243302214736654		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.048243302214736654 | validation: 0.06001923506383998]
	TIME [epoch: 8.31 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04792572157551246		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.04792572157551246 | validation: 0.040952226945061065]
	TIME [epoch: 8.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039607144514927674		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.039607144514927674 | validation: 0.07837795551437958]
	TIME [epoch: 8.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052033981479941815		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.052033981479941815 | validation: 0.061110936432608176]
	TIME [epoch: 8.32 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050088797227968974		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.050088797227968974 | validation: 0.046324753934212676]
	TIME [epoch: 8.31 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0686777971719251		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.0686777971719251 | validation: 0.04758660089477137]
	TIME [epoch: 8.31 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043241764165163135		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.043241764165163135 | validation: 0.05312231360558346]
	TIME [epoch: 8.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054523449733498895		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.054523449733498895 | validation: 0.0683771384500083]
	TIME [epoch: 8.32 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04047321972475474		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.04047321972475474 | validation: 0.06370908339848141]
	TIME [epoch: 8.31 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040383471014103736		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.040383471014103736 | validation: 0.05018003228465843]
	TIME [epoch: 8.31 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04051361658433361		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.04051361658433361 | validation: 0.036940587399804506]
	TIME [epoch: 8.31 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06955278945471814		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.06955278945471814 | validation: 0.04517418336963097]
	TIME [epoch: 8.32 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03996984157963163		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.03996984157963163 | validation: 0.03648249735517067]
	TIME [epoch: 8.31 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03662651293829548		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.03662651293829548 | validation: 0.04239967053673557]
	TIME [epoch: 8.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03931527487485563		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.03931527487485563 | validation: 0.04887961886769483]
	TIME [epoch: 8.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04453574368505079		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.04453574368505079 | validation: 0.07378030651907486]
	TIME [epoch: 8.32 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04549086638331461		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.04549086638331461 | validation: 0.051075937196546614]
	TIME [epoch: 8.31 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0495553174677477		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.0495553174677477 | validation: 0.050993959088346454]
	TIME [epoch: 8.31 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040487086961046		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.07040487086961046 | validation: 0.07528648467091775]
	TIME [epoch: 8.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05144668927419843		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.05144668927419843 | validation: 0.038057911214159704]
	TIME [epoch: 8.33 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056693625147429184		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.056693625147429184 | validation: 0.06724075899433155]
	TIME [epoch: 8.31 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05720188498371768		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.05720188498371768 | validation: 0.06990524642406581]
	TIME [epoch: 8.31 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039540382424690906		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.039540382424690906 | validation: 0.03810253640312447]
	TIME [epoch: 8.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04812169675004535		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.04812169675004535 | validation: 0.04327244235725014]
	TIME [epoch: 8.33 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04432993038632701		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.04432993038632701 | validation: 0.06812936461602012]
	TIME [epoch: 8.31 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05990308236193422		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.05990308236193422 | validation: 0.04769351038292226]
	TIME [epoch: 8.31 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04275245628167308		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.04275245628167308 | validation: 0.037698858558856824]
	TIME [epoch: 8.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0380210036009507		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.0380210036009507 | validation: 0.05676976189389571]
	TIME [epoch: 8.33 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0479570579853426		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.0479570579853426 | validation: 0.0517467081876488]
	TIME [epoch: 8.31 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04211279906744579		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.04211279906744579 | validation: 0.027830247871601828]
	TIME [epoch: 8.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1283.pth
	Model improved!!!
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036142517722027055		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.036142517722027055 | validation: 0.05044889530378303]
	TIME [epoch: 8.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035593374380713		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.035593374380713 | validation: 0.03953212804517038]
	TIME [epoch: 8.32 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03862480816082044		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.03862480816082044 | validation: 0.03773358930072489]
	TIME [epoch: 8.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0424948610538428		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.0424948610538428 | validation: 0.05590424483721419]
	TIME [epoch: 8.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05482516681278141		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.05482516681278141 | validation: 0.039941851526060765]
	TIME [epoch: 8.3 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039583757317186885		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.039583757317186885 | validation: 0.05678523520170947]
	TIME [epoch: 8.32 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046520322575450204		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.046520322575450204 | validation: 0.05261722784142299]
	TIME [epoch: 8.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04667122956694193		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.04667122956694193 | validation: 0.06783305657667747]
	TIME [epoch: 8.29 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037411943099402364		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.037411943099402364 | validation: 0.045897662655793495]
	TIME [epoch: 8.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05928832576352747		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.05928832576352747 | validation: 0.09131189082924042]
	TIME [epoch: 8.32 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062307374343020264		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.062307374343020264 | validation: 0.0716070564321904]
	TIME [epoch: 8.3 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05367911461803847		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.05367911461803847 | validation: 0.06391842656580915]
	TIME [epoch: 8.3 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04790763609855533		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.04790763609855533 | validation: 0.04457760402325418]
	TIME [epoch: 8.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04151531036999505		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.04151531036999505 | validation: 0.04414506997387832]
	TIME [epoch: 8.32 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05252779338509659		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.05252779338509659 | validation: 0.06167860227932101]
	TIME [epoch: 8.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05474709339821323		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.05474709339821323 | validation: 0.05342289911467087]
	TIME [epoch: 8.3 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04505274720609631		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.04505274720609631 | validation: 0.04006443550307478]
	TIME [epoch: 8.3 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04932507207421831		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.04932507207421831 | validation: 0.05947078216504224]
	TIME [epoch: 8.32 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059470252367520404		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.059470252367520404 | validation: 0.04772746562161564]
	TIME [epoch: 8.3 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05072352901611356		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.05072352901611356 | validation: 0.06970932761405296]
	TIME [epoch: 8.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03809981627958577		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.03809981627958577 | validation: 0.04793854761772777]
	TIME [epoch: 8.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040740954871328186		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.040740954871328186 | validation: 0.05905002136757603]
	TIME [epoch: 8.32 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04190102560001895		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.04190102560001895 | validation: 0.046315983625470285]
	TIME [epoch: 8.3 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0445201205506528		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.0445201205506528 | validation: 0.04985223301477935]
	TIME [epoch: 8.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046993995448137385		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.046993995448137385 | validation: 0.051533659996215425]
	TIME [epoch: 8.29 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04866021815488347		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.04866021815488347 | validation: 0.0499149067992697]
	TIME [epoch: 8.32 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044550111212993924		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.044550111212993924 | validation: 0.06310923788970893]
	TIME [epoch: 8.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04792780833743393		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.04792780833743393 | validation: 0.03532141376750719]
	TIME [epoch: 8.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03840431862612933		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.03840431862612933 | validation: 0.04674634625335106]
	TIME [epoch: 8.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04677863626682293		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.04677863626682293 | validation: 0.04928202902365334]
	TIME [epoch: 8.32 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03916677639893697		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.03916677639893697 | validation: 0.043326720163649725]
	TIME [epoch: 8.31 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03971515309230954		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.03971515309230954 | validation: 0.03359496760453153]
	TIME [epoch: 8.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03492110125953171		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.03492110125953171 | validation: 0.057349866835690426]
	TIME [epoch: 8.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043486295053247706		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.043486295053247706 | validation: 0.062248642649253755]
	TIME [epoch: 8.32 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05031020354389608		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.05031020354389608 | validation: 0.05175598958561338]
	TIME [epoch: 8.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04207054863457578		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.04207054863457578 | validation: 0.04435488435939436]
	TIME [epoch: 8.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03373948131100176		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.03373948131100176 | validation: 0.04826110883543453]
	TIME [epoch: 8.3 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03659968746877525		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.03659968746877525 | validation: 0.04580453434730801]
	TIME [epoch: 8.32 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03692289656704411		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.03692289656704411 | validation: 0.03879810556016231]
	TIME [epoch: 8.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038250350187629456		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.038250350187629456 | validation: 0.04162275318552043]
	TIME [epoch: 8.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04582460327668231		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.04582460327668231 | validation: 0.05061867526801989]
	TIME [epoch: 8.3 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0350490243169144		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.0350490243169144 | validation: 0.058850265344155314]
	TIME [epoch: 8.31 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07334226087437616		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.07334226087437616 | validation: 0.07188558560407673]
	TIME [epoch: 8.3 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04805530145212606		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.04805530145212606 | validation: 0.041691385360961994]
	TIME [epoch: 8.3 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042850464289108645		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.042850464289108645 | validation: 0.06514535151844436]
	TIME [epoch: 8.3 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042224000490312365		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.042224000490312365 | validation: 0.04759061627981066]
	TIME [epoch: 8.32 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040369688279225636		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.040369688279225636 | validation: 0.045991910058559266]
	TIME [epoch: 8.3 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0433841195485733		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.0433841195485733 | validation: 0.05195083693129018]
	TIME [epoch: 8.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035712515234726336		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.035712515234726336 | validation: 0.04910640745655757]
	TIME [epoch: 8.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057429353287960117		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.057429353287960117 | validation: 0.04521880387811652]
	TIME [epoch: 8.32 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04414073397395678		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.04414073397395678 | validation: 0.04685492861838904]
	TIME [epoch: 8.3 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04339319990300147		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.04339319990300147 | validation: 0.051186695851943596]
	TIME [epoch: 8.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06212619415232125		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.06212619415232125 | validation: 0.10801942196291822]
	TIME [epoch: 8.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04667005698281747		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.04667005698281747 | validation: 0.05125399697537772]
	TIME [epoch: 8.32 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0417191835637847		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.0417191835637847 | validation: 0.052525329408750654]
	TIME [epoch: 8.3 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04475038372088032		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.04475038372088032 | validation: 0.06341710184949055]
	TIME [epoch: 8.29 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04696414680205663		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.04696414680205663 | validation: 0.06541709373985272]
	TIME [epoch: 8.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04345408917578387		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.04345408917578387 | validation: 0.051365610893720465]
	TIME [epoch: 8.32 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047824056195286666		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.047824056195286666 | validation: 0.06422367952818592]
	TIME [epoch: 8.3 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03692998867394337		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.03692998867394337 | validation: 0.04094088156541372]
	TIME [epoch: 8.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03664712708398991		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.03664712708398991 | validation: 0.04423554616497247]
	TIME [epoch: 8.29 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04432658646919925		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.04432658646919925 | validation: 0.05633631610818203]
	TIME [epoch: 8.32 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049845886497287606		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.049845886497287606 | validation: 0.04658537840061843]
	TIME [epoch: 8.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04047268374688347		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.04047268374688347 | validation: 0.046330300848204276]
	TIME [epoch: 8.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434243755662614		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.06434243755662614 | validation: 0.06360747093294544]
	TIME [epoch: 8.29 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06179664201406856		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.06179664201406856 | validation: 0.05199181729266028]
	TIME [epoch: 8.31 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049513600102779304		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.049513600102779304 | validation: 0.04702220235294606]
	TIME [epoch: 8.29 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04571028065703218		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.04571028065703218 | validation: 0.05311657753948611]
	TIME [epoch: 8.29 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04290993597651788		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.04290993597651788 | validation: 0.0614800294558621]
	TIME [epoch: 8.3 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0409994600124459		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.0409994600124459 | validation: 0.042726213483234673]
	TIME [epoch: 8.32 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03915308563096216		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.03915308563096216 | validation: 0.040001595943917057]
	TIME [epoch: 8.3 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04494894012940938		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.04494894012940938 | validation: 0.055503849627192355]
	TIME [epoch: 8.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04025812721648157		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.04025812721648157 | validation: 0.04288795896862689]
	TIME [epoch: 8.3 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04578924107232064		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.04578924107232064 | validation: 0.04201809086451461]
	TIME [epoch: 8.32 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03444248557205716		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.03444248557205716 | validation: 0.0393201456450769]
	TIME [epoch: 8.3 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0458330051454		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.0458330051454 | validation: 0.0903164085439229]
	TIME [epoch: 8.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04869521845047615		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.04869521845047615 | validation: 0.04179008490728088]
	TIME [epoch: 8.29 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04304844784114316		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.04304844784114316 | validation: 0.05020957883317766]
	TIME [epoch: 8.32 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06110815435177741		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.06110815435177741 | validation: 0.03948714930752289]
	TIME [epoch: 8.3 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03215935108236222		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.03215935108236222 | validation: 0.03716722319654389]
	TIME [epoch: 8.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04964386917050832		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.04964386917050832 | validation: 0.03223260805207316]
	TIME [epoch: 8.29 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03446546086662043		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.03446546086662043 | validation: 0.051014992204142684]
	TIME [epoch: 8.32 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03829958344539548		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.03829958344539548 | validation: 0.03257263590686692]
	TIME [epoch: 8.29 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04613419131994083		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.04613419131994083 | validation: 0.050328483672252095]
	TIME [epoch: 8.3 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04917983955853821		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.04917983955853821 | validation: 0.03606179505051249]
	TIME [epoch: 8.29 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05241776443123146		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.05241776443123146 | validation: 0.055235831599804774]
	TIME [epoch: 8.32 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04405427749700066		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.04405427749700066 | validation: 0.040523035143454796]
	TIME [epoch: 8.31 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05226082155035072		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.05226082155035072 | validation: 0.053385928526455635]
	TIME [epoch: 8.3 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03874268650029993		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.03874268650029993 | validation: 0.046594716155415966]
	TIME [epoch: 8.31 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03329254733619077		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.03329254733619077 | validation: 0.03829044126886523]
	TIME [epoch: 8.32 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04695700043762758		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.04695700043762758 | validation: 0.08259896622167182]
	TIME [epoch: 8.31 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05530055190060294		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.05530055190060294 | validation: 0.0618814498212917]
	TIME [epoch: 8.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049806412393983146		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.049806412393983146 | validation: 0.04212588044790987]
	TIME [epoch: 8.3 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03191183376288417		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.03191183376288417 | validation: 0.05692968592417055]
	TIME [epoch: 8.32 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040002531224618755		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.040002531224618755 | validation: 0.04060711436659083]
	TIME [epoch: 8.3 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03830155410747568		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.03830155410747568 | validation: 0.04026335358629949]
	TIME [epoch: 8.31 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03652451614602538		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.03652451614602538 | validation: 0.03782930044866515]
	TIME [epoch: 8.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05281147452378761		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.05281147452378761 | validation: 0.04846850576060731]
	TIME [epoch: 8.32 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04337237114844371		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.04337237114844371 | validation: 0.053241622693913304]
	TIME [epoch: 8.3 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04527181301783415		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.04527181301783415 | validation: 0.05212882790900768]
	TIME [epoch: 8.29 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043463692767103816		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.043463692767103816 | validation: 0.0524575433563267]
	TIME [epoch: 8.29 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03920202492406576		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.03920202492406576 | validation: 0.0403123144868024]
	TIME [epoch: 8.32 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04732205139156334		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.04732205139156334 | validation: 0.0754718544995745]
	TIME [epoch: 8.29 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046235233571737255		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.046235233571737255 | validation: 0.06991473312637607]
	TIME [epoch: 8.29 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05642552625917768		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.05642552625917768 | validation: 0.051951165288788244]
	TIME [epoch: 8.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04700629742873926		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.04700629742873926 | validation: 0.04079769973278778]
	TIME [epoch: 8.31 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039385505887981745		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.039385505887981745 | validation: 0.03973291101604921]
	TIME [epoch: 8.29 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036877376754920095		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.036877376754920095 | validation: 0.03898449726736099]
	TIME [epoch: 8.29 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04887777402884342		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.04887777402884342 | validation: 0.044706878980757994]
	TIME [epoch: 8.3 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04273320917210464		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.04273320917210464 | validation: 0.057699589195059076]
	TIME [epoch: 8.32 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053350610956857204		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.053350610956857204 | validation: 0.04726146950437866]
	TIME [epoch: 8.31 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0496310109321461		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.0496310109321461 | validation: 0.04276725980497999]
	TIME [epoch: 8.29 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035808322309336345		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.035808322309336345 | validation: 0.05106831332124784]
	TIME [epoch: 8.29 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049783343973413205		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.049783343973413205 | validation: 0.04740351046231277]
	TIME [epoch: 8.33 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04829419935436853		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.04829419935436853 | validation: 0.03735007745574219]
	TIME [epoch: 8.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05829816503152999		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.05829816503152999 | validation: 0.058257478242534744]
	TIME [epoch: 8.31 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05147747799505992		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.05147747799505992 | validation: 0.05000021840827812]
	TIME [epoch: 8.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04138002974767863		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.04138002974767863 | validation: 0.05279975225132827]
	TIME [epoch: 8.32 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035658637153702086		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.035658637153702086 | validation: 0.06738764440669952]
	TIME [epoch: 8.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061200178772632896		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.061200178772632896 | validation: 0.06086858644362295]
	TIME [epoch: 8.29 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04698419943461566		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.04698419943461566 | validation: 0.06009664319114991]
	TIME [epoch: 8.29 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044340041824783516		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.044340041824783516 | validation: 0.041578653110249095]
	TIME [epoch: 8.31 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051900043098200656		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.051900043098200656 | validation: 0.044654674454337004]
	TIME [epoch: 8.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043983750535864355		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.043983750535864355 | validation: 0.04512246723788581]
	TIME [epoch: 8.3 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040282918579219215		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.040282918579219215 | validation: 0.04181696413815058]
	TIME [epoch: 8.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03495981138825153		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.03495981138825153 | validation: 0.04031550130149025]
	TIME [epoch: 8.32 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042758852483580724		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.042758852483580724 | validation: 0.037452311084879036]
	TIME [epoch: 8.29 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036939429740104314		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.036939429740104314 | validation: 0.03557170873112757]
	TIME [epoch: 8.29 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03513083016414415		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.03513083016414415 | validation: 0.04361355498090513]
	TIME [epoch: 8.3 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04246728548196586		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.04246728548196586 | validation: 0.045415125676493584]
	TIME [epoch: 8.33 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05480037926391956		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.05480037926391956 | validation: 0.03875587274492126]
	TIME [epoch: 8.29 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05915397033489077		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.05915397033489077 | validation: 0.05095751077576618]
	TIME [epoch: 8.29 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047929538745494694		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.047929538745494694 | validation: 0.04758349961820986]
	TIME [epoch: 8.29 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04218840994837332		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.04218840994837332 | validation: 0.03562390935896803]
	TIME [epoch: 8.31 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037142791979319356		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.037142791979319356 | validation: 0.04310130900841744]
	TIME [epoch: 8.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03779350628037337		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.03779350628037337 | validation: 0.04916845691835672]
	TIME [epoch: 8.29 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03731430910711113		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.03731430910711113 | validation: 0.03562618435220956]
	TIME [epoch: 8.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038080873608234776		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.038080873608234776 | validation: 0.049070511062155445]
	TIME [epoch: 8.33 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03981307079227993		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.03981307079227993 | validation: 0.060196059222835205]
	TIME [epoch: 8.29 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05004370379101798		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.05004370379101798 | validation: 0.057074566571311824]
	TIME [epoch: 8.3 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054541071782423976		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.054541071782423976 | validation: 0.08086478484765214]
	TIME [epoch: 8.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044438290589768656		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.044438290589768656 | validation: 0.04206021906150339]
	TIME [epoch: 8.32 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034849151151434485		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.034849151151434485 | validation: 0.03880646799490658]
	TIME [epoch: 8.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034520333435788426		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.034520333435788426 | validation: 0.05594279451317688]
	TIME [epoch: 8.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043256711918445		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.043256711918445 | validation: 0.05016645882670208]
	TIME [epoch: 8.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04680320165967706		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.04680320165967706 | validation: 0.04410642971844207]
	TIME [epoch: 8.31 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03670007615922659		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.03670007615922659 | validation: 0.04917419627041866]
	TIME [epoch: 8.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047338383484068706		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.047338383484068706 | validation: 0.04361291166619073]
	TIME [epoch: 8.29 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04151002953663633		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.04151002953663633 | validation: 0.05024040077637536]
	TIME [epoch: 8.31 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044014537234010456		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.044014537234010456 | validation: 0.050834632927767714]
	TIME [epoch: 8.31 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04245755761110662		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.04245755761110662 | validation: 0.04207127654804254]
	TIME [epoch: 8.3 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04247051138282433		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.04247051138282433 | validation: 0.06526756781498902]
	TIME [epoch: 8.3 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04969349924069995		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.04969349924069995 | validation: 0.035009224425364124]
	TIME [epoch: 8.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035063834219634986		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.035063834219634986 | validation: 0.040423917278475927]
	TIME [epoch: 8.31 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03449528632680643		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.03449528632680643 | validation: 0.045617854888043305]
	TIME [epoch: 8.29 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03940217703895473		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.03940217703895473 | validation: 0.05173787799427078]
	TIME [epoch: 8.29 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04214482012371543		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.04214482012371543 | validation: 0.04436948648030853]
	TIME [epoch: 8.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048151464317380224		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.048151464317380224 | validation: 0.06300850863194456]
	TIME [epoch: 8.31 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038242430972926414		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.038242430972926414 | validation: 0.05571771282403663]
	TIME [epoch: 8.29 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04016417204331551		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.04016417204331551 | validation: 0.04374516188430226]
	TIME [epoch: 8.28 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045382226086941965		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.045382226086941965 | validation: 0.05204851234889501]
	TIME [epoch: 8.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04092047460006384		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.04092047460006384 | validation: 0.031368359437333834]
	TIME [epoch: 8.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042515146395963196		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.042515146395963196 | validation: 0.0573774725561193]
	TIME [epoch: 8.29 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0566216741015057		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.0566216741015057 | validation: 0.04616974402654003]
	TIME [epoch: 8.29 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035046877183810395		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.035046877183810395 | validation: 0.04184843106024245]
	TIME [epoch: 8.3 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033229235523224966		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.033229235523224966 | validation: 0.06134494251384771]
	TIME [epoch: 8.3 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036547412946588025		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.036547412946588025 | validation: 0.03918094733361967]
	TIME [epoch: 8.29 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031928431716468156		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.031928431716468156 | validation: 0.03881498945144819]
	TIME [epoch: 8.29 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047211563290084205		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.047211563290084205 | validation: 0.038849236326870984]
	TIME [epoch: 8.29 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05108293723488837		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.05108293723488837 | validation: 0.02955202221746276]
	TIME [epoch: 8.3 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031638752735389		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.031638752735389 | validation: 0.03196178189101386]
	TIME [epoch: 8.29 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03760170945506304		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.03760170945506304 | validation: 0.06639789304923548]
	TIME [epoch: 8.29 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04984478095287311		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.04984478095287311 | validation: 0.05835939985023554]
	TIME [epoch: 8.29 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054911398405029774		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.054911398405029774 | validation: 0.04571512551604352]
	TIME [epoch: 8.31 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04033976229962048		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.04033976229962048 | validation: 0.04478148255217329]
	TIME [epoch: 8.28 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03244899692165199		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.03244899692165199 | validation: 0.03823526251847347]
	TIME [epoch: 8.28 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03909497410082235		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.03909497410082235 | validation: 0.03803420858547514]
	TIME [epoch: 8.29 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03244354520574026		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.03244354520574026 | validation: 0.04534075836362349]
	TIME [epoch: 8.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04253748020768473		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.04253748020768473 | validation: 0.04898862261881682]
	TIME [epoch: 8.28 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038560814404935265		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.038560814404935265 | validation: 0.050577401549321624]
	TIME [epoch: 8.29 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03499412727895795		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.03499412727895795 | validation: 0.03403171960374361]
	TIME [epoch: 8.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035676136550830725		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.035676136550830725 | validation: 0.050869722127617534]
	TIME [epoch: 8.3 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03648324539140152		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.03648324539140152 | validation: 0.05900753149669399]
	TIME [epoch: 8.28 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06951336206987281		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.06951336206987281 | validation: 0.052179010098445666]
	TIME [epoch: 8.29 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0551129651209631		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.0551129651209631 | validation: 0.08094101969388627]
	TIME [epoch: 8.31 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04530020580118216		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.04530020580118216 | validation: 0.050253696173298085]
	TIME [epoch: 8.31 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04438891552236301		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.04438891552236301 | validation: 0.09287310110638212]
	TIME [epoch: 8.28 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059666069859646356		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.059666069859646356 | validation: 0.06470604681616907]
	TIME [epoch: 8.28 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03203436154559231		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.03203436154559231 | validation: 0.036015780521942084]
	TIME [epoch: 8.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04360035665586111		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.04360035665586111 | validation: 0.03687576904516767]
	TIME [epoch: 8.3 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04694765717649962		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.04694765717649962 | validation: 0.07951551722888482]
	TIME [epoch: 8.28 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048699161081473354		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.048699161081473354 | validation: 0.04671347941676667]
	TIME [epoch: 8.29 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03493268941769772		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.03493268941769772 | validation: 0.04707630509993695]
	TIME [epoch: 8.32 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04148156399307454		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.04148156399307454 | validation: 0.04641191989564894]
	TIME [epoch: 8.3 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036467799457316		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.036467799457316 | validation: 0.04692550364694854]
	TIME [epoch: 8.29 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040091651893104		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.040091651893104 | validation: 0.042447765723505934]
	TIME [epoch: 8.28 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03411685696989516		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.03411685696989516 | validation: 0.06990646486189503]
	TIME [epoch: 8.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05153053923636075		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.05153053923636075 | validation: 0.03448646944206542]
	TIME [epoch: 8.3 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03751351808825108		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.03751351808825108 | validation: 0.030582752239990872]
	TIME [epoch: 8.29 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03827094587800854		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.03827094587800854 | validation: 0.07888777508665404]
	TIME [epoch: 8.3 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05102455877330046		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.05102455877330046 | validation: 0.06652601053578672]
	TIME [epoch: 8.31 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05149592656059476		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.05149592656059476 | validation: 0.054470744730954423]
	TIME [epoch: 8.29 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04220536727102725		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.04220536727102725 | validation: 0.05019105800841332]
	TIME [epoch: 8.28 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03916051196360391		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.03916051196360391 | validation: 0.043543429800854]
	TIME [epoch: 8.28 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04472195865301839		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.04472195865301839 | validation: 0.039713038251520845]
	TIME [epoch: 8.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040881348418405		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.040881348418405 | validation: 0.050874864134767016]
	TIME [epoch: 8.31 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03385012966195858		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.03385012966195858 | validation: 0.04735577620900863]
	TIME [epoch: 8.29 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03763473500523576		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.03763473500523576 | validation: 0.05419808124182235]
	TIME [epoch: 8.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040250975413692686		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.040250975413692686 | validation: 0.05191069711076167]
	TIME [epoch: 8.31 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03336385998053412		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.03336385998053412 | validation: 0.05037256694600616]
	TIME [epoch: 8.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03354259309093671		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.03354259309093671 | validation: 0.03908190752217887]
	TIME [epoch: 8.29 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03875366766697959		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.03875366766697959 | validation: 0.04143775568775991]
	TIME [epoch: 8.29 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037639751470041616		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.037639751470041616 | validation: 0.04691495898107233]
	TIME [epoch: 8.32 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03632720242946164		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.03632720242946164 | validation: 0.04713387005920835]
	TIME [epoch: 8.3 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050391370603414795		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.050391370603414795 | validation: 0.04088789666973176]
	TIME [epoch: 8.28 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034572549807183814		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.034572549807183814 | validation: 0.03752384884894862]
	TIME [epoch: 8.28 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03550884601563979		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.03550884601563979 | validation: 0.0326908588947367]
	TIME [epoch: 8.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03998844637899848		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.03998844637899848 | validation: 0.0473115444229312]
	TIME [epoch: 8.3 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0311868001517834		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.0311868001517834 | validation: 0.0354349548476383]
	TIME [epoch: 8.28 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03427232680844272		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.03427232680844272 | validation: 0.04844712562202324]
	TIME [epoch: 8.29 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0338383457349753		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.0338383457349753 | validation: 0.0367571927259487]
	TIME [epoch: 8.3 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034935342423049416		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.034935342423049416 | validation: 0.03698738018498382]
	TIME [epoch: 8.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030884929183036435		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.030884929183036435 | validation: 0.05406825771358545]
	TIME [epoch: 8.29 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0452582538062904		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.0452582538062904 | validation: 0.05457168567582846]
	TIME [epoch: 8.29 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0399391505184636		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.0399391505184636 | validation: 0.05445899780646817]
	TIME [epoch: 8.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05978625335635999		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.05978625335635999 | validation: 0.07861058795891149]
	TIME [epoch: 8.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04031440266027414		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.04031440266027414 | validation: 0.04443370721508996]
	TIME [epoch: 8.29 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03508859176072622		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.03508859176072622 | validation: 0.03812281696465049]
	TIME [epoch: 8.29 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0371320885307126		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.0371320885307126 | validation: 0.06160921622424337]
	TIME [epoch: 8.31 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04073346121361278		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.04073346121361278 | validation: 0.035122512079629485]
	TIME [epoch: 8.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035318681380948534		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.035318681380948534 | validation: 0.052171629487504353]
	TIME [epoch: 8.3 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03714806596634032		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.03714806596634032 | validation: 0.04844245177389127]
	TIME [epoch: 8.29 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04749409194198576		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.04749409194198576 | validation: 0.06217052822712588]
	TIME [epoch: 8.31 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042485106141542536		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.042485106141542536 | validation: 0.0438028301690829]
	TIME [epoch: 8.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037097376069136115		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.037097376069136115 | validation: 0.0493006302097475]
	TIME [epoch: 8.3 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04383854888045746		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.04383854888045746 | validation: 0.04092645208603492]
	TIME [epoch: 8.29 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028053788490077287		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.028053788490077287 | validation: 0.06493194138036909]
	TIME [epoch: 8.31 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041850633047758136		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.041850633047758136 | validation: 0.049549960346835974]
	TIME [epoch: 8.3 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036002797039451764		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.036002797039451764 | validation: 0.042061882321748185]
	TIME [epoch: 8.29 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04040572864498112		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.04040572864498112 | validation: 0.06206216237639475]
	TIME [epoch: 8.29 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04852204563641934		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.04852204563641934 | validation: 0.03655225858719688]
	TIME [epoch: 8.3 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03517285142056843		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.03517285142056843 | validation: 0.03910509443356022]
	TIME [epoch: 8.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03469276254334348		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.03469276254334348 | validation: 0.05261858633149716]
	TIME [epoch: 8.28 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040777186943806984		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.040777186943806984 | validation: 0.034160447085261475]
	TIME [epoch: 8.29 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03666439977618282		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.03666439977618282 | validation: 0.04354345305549691]
	TIME [epoch: 8.31 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03160388605062618		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.03160388605062618 | validation: 0.04460120232346955]
	TIME [epoch: 8.3 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04498502031212976		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.04498502031212976 | validation: 0.047958073841635473]
	TIME [epoch: 8.29 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282138265463798		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.04282138265463798 | validation: 0.05212239715590115]
	TIME [epoch: 8.3 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03852146172667834		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.03852146172667834 | validation: 0.04714653139608013]
	TIME [epoch: 8.31 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04457467573085148		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.04457467573085148 | validation: 0.046427940121492844]
	TIME [epoch: 8.31 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04434453502883075		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.04434453502883075 | validation: 0.04098860793616794]
	TIME [epoch: 8.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036411180519343674		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.036411180519343674 | validation: 0.04840796257548878]
	TIME [epoch: 8.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03396838981001888		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.03396838981001888 | validation: 0.04593417997511555]
	TIME [epoch: 8.31 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04026130738857065		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.04026130738857065 | validation: 0.04323548085743926]
	TIME [epoch: 8.3 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030362737675923873		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.030362737675923873 | validation: 0.03320961624715968]
	TIME [epoch: 8.28 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03342662232699746		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.03342662232699746 | validation: 0.039421857587541576]
	TIME [epoch: 8.29 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03974399062452995		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.03974399062452995 | validation: 0.031783125580222095]
	TIME [epoch: 8.31 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035847067563579346		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.035847067563579346 | validation: 0.051185045631984616]
	TIME [epoch: 8.29 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03345459664849327		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.03345459664849327 | validation: 0.05182326482336648]
	TIME [epoch: 8.28 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036075564166133424		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.036075564166133424 | validation: 0.04298496785068964]
	TIME [epoch: 8.3 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045877461321197056		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.045877461321197056 | validation: 0.05284099629909784]
	TIME [epoch: 8.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032987222994233636		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.032987222994233636 | validation: 0.05120278714045687]
	TIME [epoch: 8.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037971265520270574		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.037971265520270574 | validation: 0.043173093779089095]
	TIME [epoch: 8.29 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034022051354644665		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.034022051354644665 | validation: 0.03964250383102651]
	TIME [epoch: 8.29 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029409475162852743		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.029409475162852743 | validation: 0.054773987249564206]
	TIME [epoch: 8.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03213002486842621		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.03213002486842621 | validation: 0.04716458724630689]
	TIME [epoch: 8.29 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03467352437382902		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.03467352437382902 | validation: 0.034069165175856786]
	TIME [epoch: 8.29 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03108510965023299		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.03108510965023299 | validation: 0.04559518500200441]
	TIME [epoch: 8.3 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03565517830588359		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.03565517830588359 | validation: 0.04696577691472253]
	TIME [epoch: 8.31 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039537829383604645		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.039537829383604645 | validation: 0.042264026435840804]
	TIME [epoch: 8.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0374857163914738		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.0374857163914738 | validation: 0.0413590582262987]
	TIME [epoch: 8.3 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031305617995305735		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.031305617995305735 | validation: 0.05119652929537932]
	TIME [epoch: 8.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03529430641196872		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.03529430641196872 | validation: 0.03812105479465097]
	TIME [epoch: 8.32 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03535320230998174		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.03535320230998174 | validation: 0.04139134058410976]
	TIME [epoch: 8.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03263138166286471		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.03263138166286471 | validation: 0.049754796320580316]
	TIME [epoch: 8.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0414144122135711		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.0414144122135711 | validation: 0.050103964300064516]
	TIME [epoch: 8.29 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042069344166808714		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.042069344166808714 | validation: 0.054796088065758114]
	TIME [epoch: 8.31 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043901344372512155		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.043901344372512155 | validation: 0.03895365098347035]
	TIME [epoch: 8.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03800013307859781		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.03800013307859781 | validation: 0.04550216271406725]
	TIME [epoch: 8.29 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04008873943970389		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.04008873943970389 | validation: 0.047918838735054974]
	TIME [epoch: 8.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03584814243183633		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.03584814243183633 | validation: 0.03545273954994817]
	TIME [epoch: 8.32 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036795162119626794		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.036795162119626794 | validation: 0.06362633509485548]
	TIME [epoch: 8.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04164051803363038		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.04164051803363038 | validation: 0.034234127502503924]
	TIME [epoch: 8.29 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03263611268288637		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.03263611268288637 | validation: 0.051906926557073824]
	TIME [epoch: 8.29 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03508589146284995		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.03508589146284995 | validation: 0.04738510561731218]
	TIME [epoch: 8.31 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03595668362585562		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.03595668362585562 | validation: 0.04897249854257622]
	TIME [epoch: 8.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04228660128071346		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.04228660128071346 | validation: 0.051239626176730675]
	TIME [epoch: 8.29 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030591419193071994		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.030591419193071994 | validation: 0.033030299335920846]
	TIME [epoch: 8.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03412610535320489		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.03412610535320489 | validation: 0.042117489227346275]
	TIME [epoch: 8.32 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03034974954480062		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.03034974954480062 | validation: 0.03797604710309721]
	TIME [epoch: 8.3 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03654102834083607		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.03654102834083607 | validation: 0.04118386273394625]
	TIME [epoch: 8.29 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028913578661676487		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.028913578661676487 | validation: 0.04407062852304375]
	TIME [epoch: 8.29 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032765772255886574		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.032765772255886574 | validation: 0.03206027105021938]
	TIME [epoch: 8.32 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046706187152723164		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.046706187152723164 | validation: 0.07960106415905797]
	TIME [epoch: 8.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04927190594719325		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.04927190594719325 | validation: 0.04073863998706197]
	TIME [epoch: 8.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037858187720724384		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.037858187720724384 | validation: 0.04159321251694997]
	TIME [epoch: 8.3 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041743835779923195		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.041743835779923195 | validation: 0.05124113524236794]
	TIME [epoch: 8.32 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032918324460357154		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.032918324460357154 | validation: 0.04458142467367876]
	TIME [epoch: 8.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03684880251829823		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.03684880251829823 | validation: 0.0377765020846743]
	TIME [epoch: 8.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04027927376945893		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.04027927376945893 | validation: 0.04469223199525256]
	TIME [epoch: 8.3 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044292151700885816		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.044292151700885816 | validation: 0.04991972965558718]
	TIME [epoch: 8.32 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02664508611638684		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.02664508611638684 | validation: 0.051029584199122055]
	TIME [epoch: 8.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05041251047655576		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.05041251047655576 | validation: 0.05029094412627069]
	TIME [epoch: 8.3 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03925949369889206		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.03925949369889206 | validation: 0.0379978388825586]
	TIME [epoch: 8.3 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03571521383823573		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.03571521383823573 | validation: 0.04964958053995656]
	TIME [epoch: 8.32 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039285637350961834		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.039285637350961834 | validation: 0.04949285035053201]
	TIME [epoch: 8.31 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036789431328884556		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.036789431328884556 | validation: 0.054236078276472345]
	TIME [epoch: 8.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03965076138306929		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.03965076138306929 | validation: 0.032577266446491435]
	TIME [epoch: 8.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036124171288065665		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.036124171288065665 | validation: 0.03163326340084996]
	TIME [epoch: 8.32 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03673164426661177		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.03673164426661177 | validation: 0.057414217150087474]
	TIME [epoch: 8.31 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041334426891461905		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.041334426891461905 | validation: 0.04380625132485076]
	TIME [epoch: 8.3 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03885686997304485		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.03885686997304485 | validation: 0.0394881146731742]
	TIME [epoch: 8.29 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037083504277704876		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.037083504277704876 | validation: 0.06218508662818108]
	TIME [epoch: 8.32 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03760176821613641		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.03760176821613641 | validation: 0.040235256458314814]
	TIME [epoch: 8.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028654156246947993		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.028654156246947993 | validation: 0.03347911809133388]
	TIME [epoch: 8.29 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03575138656740992		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.03575138656740992 | validation: 0.04894508517329053]
	TIME [epoch: 8.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03548484120078669		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.03548484120078669 | validation: 0.04438155255286383]
	TIME [epoch: 8.32 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04015342321452782		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.04015342321452782 | validation: 0.037138143244749636]
	TIME [epoch: 8.31 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03346173049924484		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.03346173049924484 | validation: 0.037817636708008216]
	TIME [epoch: 8.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04298495534914483		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.04298495534914483 | validation: 0.0416352509464446]
	TIME [epoch: 8.31 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04446643451676462		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.04446643451676462 | validation: 0.045253591079171346]
	TIME [epoch: 8.32 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04232479334086283		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.04232479334086283 | validation: 0.05098749133622013]
	TIME [epoch: 8.3 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03473341129962495		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.03473341129962495 | validation: 0.04520221806589285]
	TIME [epoch: 8.3 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03604991664661278		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.03604991664661278 | validation: 0.0439172456833386]
	TIME [epoch: 8.3 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03305682371289492		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.03305682371289492 | validation: 0.04144856930623203]
	TIME [epoch: 8.32 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03536518648781015		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.03536518648781015 | validation: 0.029000151186445812]
	TIME [epoch: 8.3 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03562645314817518		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.03562645314817518 | validation: 0.06467772349498357]
	TIME [epoch: 8.3 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04926190933572544		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.04926190933572544 | validation: 0.04122064566916629]
	TIME [epoch: 8.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03835623431826807		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.03835623431826807 | validation: 0.03481553397468107]
	TIME [epoch: 8.32 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035777420551894576		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.035777420551894576 | validation: 0.04219987126661573]
	TIME [epoch: 8.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031505642170905505		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.031505642170905505 | validation: 0.04297128267689897]
	TIME [epoch: 8.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031474136557176666		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.031474136557176666 | validation: 0.042053085630089485]
	TIME [epoch: 8.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03727967494675904		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.03727967494675904 | validation: 0.0539369944498317]
	TIME [epoch: 8.32 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03207198883453728		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.03207198883453728 | validation: 0.04748349963163797]
	TIME [epoch: 8.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03413136963303544		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.03413136963303544 | validation: 0.040948508528061985]
	TIME [epoch: 8.3 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03458366164638582		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.03458366164638582 | validation: 0.053793963705151326]
	TIME [epoch: 8.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04186019068844253		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.04186019068844253 | validation: 0.06022402613082653]
	TIME [epoch: 8.32 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04649397358694183		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.04649397358694183 | validation: 0.055817601765728045]
	TIME [epoch: 8.3 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03477313005016323		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.03477313005016323 | validation: 0.054069608273273076]
	TIME [epoch: 8.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03694538081691612		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.03694538081691612 | validation: 0.03658774664420391]
	TIME [epoch: 8.29 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03914156964199285		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.03914156964199285 | validation: 0.054643649368492836]
	TIME [epoch: 8.32 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03504328482351348		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.03504328482351348 | validation: 0.036227250382141724]
	TIME [epoch: 8.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03415817871659783		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.03415817871659783 | validation: 0.048340230893990234]
	TIME [epoch: 8.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04323829624473244		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.04323829624473244 | validation: 0.03887066487312164]
	TIME [epoch: 8.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03683055155578439		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.03683055155578439 | validation: 0.044446825313286774]
	TIME [epoch: 8.32 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032975468179766335		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.032975468179766335 | validation: 0.04265889493993133]
	TIME [epoch: 8.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042020431472746665		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.042020431472746665 | validation: 0.05096748104460823]
	TIME [epoch: 8.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04030130223716159		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.04030130223716159 | validation: 0.04709239588778029]
	TIME [epoch: 8.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03898806041136392		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.03898806041136392 | validation: 0.044083239934811905]
	TIME [epoch: 8.32 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03826332027358068		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.03826332027358068 | validation: 0.041837776385765406]
	TIME [epoch: 8.3 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0324604255750558		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.0324604255750558 | validation: 0.04036612273633215]
	TIME [epoch: 8.3 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031706538073238304		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.031706538073238304 | validation: 0.044891507356245586]
	TIME [epoch: 8.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03551184166451483		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.03551184166451483 | validation: 0.03817033272946662]
	TIME [epoch: 8.32 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035826600816683034		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.035826600816683034 | validation: 0.04101672576303926]
	TIME [epoch: 8.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032047987525752		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.032047987525752 | validation: 0.03835977556501889]
	TIME [epoch: 8.3 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030217329042715225		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.030217329042715225 | validation: 0.03857719415435998]
	TIME [epoch: 8.3 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03195474239597963		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.03195474239597963 | validation: 0.031846798341081894]
	TIME [epoch: 8.32 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03045629012021201		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.03045629012021201 | validation: 0.03825596770585765]
	TIME [epoch: 8.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03457397396221033		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.03457397396221033 | validation: 0.04487718755203887]
	TIME [epoch: 8.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034234993889880286		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.034234993889880286 | validation: 0.0544278619177218]
	TIME [epoch: 8.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05487318991382038		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.05487318991382038 | validation: 0.037168205772689956]
	TIME [epoch: 8.32 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026081157875941736		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.026081157875941736 | validation: 0.04115454833625014]
	TIME [epoch: 8.3 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03866583850452834		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.03866583850452834 | validation: 0.04482028493619819]
	TIME [epoch: 8.31 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028576890251258508		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.028576890251258508 | validation: 0.040637426559893594]
	TIME [epoch: 8.29 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037199419788316215		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.037199419788316215 | validation: 0.0373359942088494]
	TIME [epoch: 8.32 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0344283128219358		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.0344283128219358 | validation: 0.03219503962931865]
	TIME [epoch: 8.3 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029161247243020567		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.029161247243020567 | validation: 0.039151348730562245]
	TIME [epoch: 8.29 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03276054305824037		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.03276054305824037 | validation: 0.05739051620325039]
	TIME [epoch: 8.3 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035798953441658385		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.035798953441658385 | validation: 0.045823642988046656]
	TIME [epoch: 8.31 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03520891008741491		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.03520891008741491 | validation: 0.046761790046497574]
	TIME [epoch: 8.29 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0463670668572445		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.0463670668572445 | validation: 0.0378136278167099]
	TIME [epoch: 8.29 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030713032721156313		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.030713032721156313 | validation: 0.031261676865091015]
	TIME [epoch: 8.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03287021111734698		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.03287021111734698 | validation: 0.03367551778606517]
	TIME [epoch: 8.32 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03529487853178474		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.03529487853178474 | validation: 0.05905425607861045]
	TIME [epoch: 8.3 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03593708619057364		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.03593708619057364 | validation: 0.04172932555537311]
	TIME [epoch: 8.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039184912575244604		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.039184912575244604 | validation: 0.04741263946778241]
	TIME [epoch: 8.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041745655980010746		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.041745655980010746 | validation: 0.04231538978197126]
	TIME [epoch: 8.33 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03734196994728638		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.03734196994728638 | validation: 0.03558377829290006]
	TIME [epoch: 8.3 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039678590986326825		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.039678590986326825 | validation: 0.03291102648364238]
	TIME [epoch: 8.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025912479435460222		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.025912479435460222 | validation: 0.03693191927281876]
	TIME [epoch: 8.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03010828189277235		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.03010828189277235 | validation: 0.03470726437068683]
	TIME [epoch: 8.32 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030236366034031747		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.030236366034031747 | validation: 0.05591124921316818]
	TIME [epoch: 8.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026237176064535867		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.026237176064535867 | validation: 0.044478777207596236]
	TIME [epoch: 8.29 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03733266773433131		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.03733266773433131 | validation: 0.040927632239476]
	TIME [epoch: 8.3 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03949871579668192		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.03949871579668192 | validation: 0.04330032915440725]
	TIME [epoch: 8.33 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027271825494958612		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.027271825494958612 | validation: 0.03440938572638244]
	TIME [epoch: 8.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02955414422124524		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.02955414422124524 | validation: 0.0386767873950543]
	TIME [epoch: 8.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045579066347984296		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.045579066347984296 | validation: 0.039034451131258335]
	TIME [epoch: 8.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03233995848175587		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.03233995848175587 | validation: 0.0350072484609765]
	TIME [epoch: 8.32 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032621860163779846		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.032621860163779846 | validation: 0.033582465814522726]
	TIME [epoch: 8.3 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040816273734495166		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.040816273734495166 | validation: 0.04125989600143709]
	TIME [epoch: 8.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03513799810847125		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.03513799810847125 | validation: 0.0402183920079911]
	TIME [epoch: 8.29 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039045824864698035		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.039045824864698035 | validation: 0.04842676456510614]
	TIME [epoch: 8.31 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02898178294639008		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.02898178294639008 | validation: 0.028577128579356292]
	TIME [epoch: 8.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04283887334249138		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.04283887334249138 | validation: 0.04900234396065773]
	TIME [epoch: 8.29 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03712890009125295		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.03712890009125295 | validation: 0.04497978604299137]
	TIME [epoch: 8.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031056333932282337		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.031056333932282337 | validation: 0.035574865945694326]
	TIME [epoch: 8.32 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02538931805200017		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.02538931805200017 | validation: 0.033428866459936646]
	TIME [epoch: 8.3 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03134252203554373		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.03134252203554373 | validation: 0.03809387894619625]
	TIME [epoch: 8.29 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032665710026214066		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.032665710026214066 | validation: 0.037397039912811236]
	TIME [epoch: 8.29 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04776361622757165		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.04776361622757165 | validation: 0.05443749033464397]
	TIME [epoch: 8.32 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035490079395474015		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.035490079395474015 | validation: 0.03872358346678133]
	TIME [epoch: 8.29 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03279739516664952		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.03279739516664952 | validation: 0.03193695929896627]
	TIME [epoch: 8.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028518788514092404		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.028518788514092404 | validation: 0.03512982530101095]
	TIME [epoch: 8.29 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028118659052236462		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.028118659052236462 | validation: 0.03794523563854606]
	TIME [epoch: 8.31 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0312612368465721		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.0312612368465721 | validation: 0.04129967271711485]
	TIME [epoch: 8.29 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03258087817685221		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.03258087817685221 | validation: 0.03420784517478037]
	TIME [epoch: 8.29 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033546423720193966		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.033546423720193966 | validation: 0.037015648315197006]
	TIME [epoch: 8.29 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03273211780716685		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.03273211780716685 | validation: 0.047295674041544]
	TIME [epoch: 8.31 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040946054338252276		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.040946054338252276 | validation: 0.040903498425324744]
	TIME [epoch: 8.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027916079434506393		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.027916079434506393 | validation: 0.04119452886088476]
	TIME [epoch: 8.3 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03531791776586992		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.03531791776586992 | validation: 0.04830334808939819]
	TIME [epoch: 8.3 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03918244830140713		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.03918244830140713 | validation: 0.037624763803557164]
	TIME [epoch: 8.31 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029017980475154692		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.029017980475154692 | validation: 0.037605290738048455]
	TIME [epoch: 8.29 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031221698130652863		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.031221698130652863 | validation: 0.037640745161042155]
	TIME [epoch: 8.29 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030642386816842317		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.030642386816842317 | validation: 0.0325449176725235]
	TIME [epoch: 8.29 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030665223185625673		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.030665223185625673 | validation: 0.03871529257250647]
	TIME [epoch: 8.32 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03398871434619465		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.03398871434619465 | validation: 0.03403388567665226]
	TIME [epoch: 8.29 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03441472234969302		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.03441472234969302 | validation: 0.029649148020760137]
	TIME [epoch: 8.29 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0324804887111714		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.0324804887111714 | validation: 0.048052023782880524]
	TIME [epoch: 8.29 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045703174615386546		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.045703174615386546 | validation: 0.03996300475055331]
	TIME [epoch: 8.31 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04129059528472139		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.04129059528472139 | validation: 0.05084196579141155]
	TIME [epoch: 8.29 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03862540932858904		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.03862540932858904 | validation: 0.03252014874607606]
	TIME [epoch: 8.28 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03295921245625347		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.03295921245625347 | validation: 0.037417068324537096]
	TIME [epoch: 8.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03165340127967782		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.03165340127967782 | validation: 0.04666123550799479]
	TIME [epoch: 8.31 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0337496536317911		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.0337496536317911 | validation: 0.04778542259148835]
	TIME [epoch: 8.29 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029584522991922897		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.029584522991922897 | validation: 0.047565686283626715]
	TIME [epoch: 8.29 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0330982296246858		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.0330982296246858 | validation: 0.037323499807965066]
	TIME [epoch: 8.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03102430872650446		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.03102430872650446 | validation: 0.043715370556103875]
	TIME [epoch: 8.31 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03659157692087788		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.03659157692087788 | validation: 0.035485092286809974]
	TIME [epoch: 8.29 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04046912680866136		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.04046912680866136 | validation: 0.0429549736883414]
	TIME [epoch: 8.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02924982724431554		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.02924982724431554 | validation: 0.04312627297364612]
	TIME [epoch: 8.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03833861849731872		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.03833861849731872 | validation: 0.039408950061475864]
	TIME [epoch: 8.31 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028560505158565796		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.028560505158565796 | validation: 0.04670786606385903]
	TIME [epoch: 8.3 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03691801220047963		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.03691801220047963 | validation: 0.032300721646534185]
	TIME [epoch: 8.29 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029348827001128286		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.029348827001128286 | validation: 0.033756513078280176]
	TIME [epoch: 8.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03196254925566984		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.03196254925566984 | validation: 0.04235643731701851]
	TIME [epoch: 8.31 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03145961138484628		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.03145961138484628 | validation: 0.03002662556067927]
	TIME [epoch: 8.31 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03076245352473416		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.03076245352473416 | validation: 0.03532335006314474]
	TIME [epoch: 8.3 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037404577443589306		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.037404577443589306 | validation: 0.03521725273930598]
	TIME [epoch: 8.31 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030387045915540627		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.030387045915540627 | validation: 0.03197850485543514]
	TIME [epoch: 8.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033171916739584126		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.033171916739584126 | validation: 0.04044926663170293]
	TIME [epoch: 8.29 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031205620062006927		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.031205620062006927 | validation: 0.03268342596778433]
	TIME [epoch: 8.28 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036675814410164244		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.036675814410164244 | validation: 0.034133578262546524]
	TIME [epoch: 8.3 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035160758144321104		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.035160758144321104 | validation: 0.04050453196437995]
	TIME [epoch: 8.31 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0355850076730824		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.0355850076730824 | validation: 0.03410821751418316]
	TIME [epoch: 8.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03167021399354444		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.03167021399354444 | validation: 0.03859847963272339]
	TIME [epoch: 8.29 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0365050300107088		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.0365050300107088 | validation: 0.04209491468146352]
	TIME [epoch: 8.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032609497656718875		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.032609497656718875 | validation: 0.038900942899631655]
	TIME [epoch: 8.31 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030866481783211164		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.030866481783211164 | validation: 0.045092580715900006]
	TIME [epoch: 8.28 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032282902295451374		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.032282902295451374 | validation: 0.04287125443222896]
	TIME [epoch: 8.3 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03044841036915318		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.03044841036915318 | validation: 0.041903458279430095]
	TIME [epoch: 8.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03947269134711544		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.03947269134711544 | validation: 0.03972568228553721]
	TIME [epoch: 8.31 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026026495520273092		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.026026495520273092 | validation: 0.03512527893073522]
	TIME [epoch: 8.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03366640252545616		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.03366640252545616 | validation: 0.04198883994514231]
	TIME [epoch: 8.3 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03251178860660222		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.03251178860660222 | validation: 0.0437566918213466]
	TIME [epoch: 8.31 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04114777686786047		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.04114777686786047 | validation: 0.04083443547831983]
	TIME [epoch: 8.31 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035436093599543216		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.035436093599543216 | validation: 0.04283328746900612]
	TIME [epoch: 8.29 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039434320194870275		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.039434320194870275 | validation: 0.036252128314617965]
	TIME [epoch: 8.29 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0372425825966947		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.0372425825966947 | validation: 0.06807522881919997]
	TIME [epoch: 8.31 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03632422361137615		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.03632422361137615 | validation: 0.036240403973256535]
	TIME [epoch: 8.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031991125018338055		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.031991125018338055 | validation: 0.03769468873254728]
	TIME [epoch: 8.29 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03370376215142367		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.03370376215142367 | validation: 0.039266284754059876]
	TIME [epoch: 8.29 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030935186087374993		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.030935186087374993 | validation: 0.0316837612125429]
	TIME [epoch: 8.31 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03334517749730716		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.03334517749730716 | validation: 0.04539277646610762]
	TIME [epoch: 8.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03031480417180025		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.03031480417180025 | validation: 0.035426809386530915]
	TIME [epoch: 8.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03290851371460919		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.03290851371460919 | validation: 0.028645168281424313]
	TIME [epoch: 8.3 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03107134535766664		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.03107134535766664 | validation: 0.0448101320849775]
	TIME [epoch: 8.31 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03277895639042022		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.03277895639042022 | validation: 0.0356869014785778]
	TIME [epoch: 8.31 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029123843384031477		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.029123843384031477 | validation: 0.050129743885756695]
	TIME [epoch: 8.29 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03164169487554871		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.03164169487554871 | validation: 0.033786361423717715]
	TIME [epoch: 8.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04490062532221173		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.04490062532221173 | validation: 0.05654014643839374]
	TIME [epoch: 8.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03354784611940827		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.03354784611940827 | validation: 0.03845298706410254]
	TIME [epoch: 8.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028190238428934894		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.028190238428934894 | validation: 0.03701517726565862]
	TIME [epoch: 8.29 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030929276209020418		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.030929276209020418 | validation: 0.0341014896708524]
	TIME [epoch: 8.29 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034712431540603474		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.034712431540603474 | validation: 0.025916560740543344]
	TIME [epoch: 8.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1759.pth
	Model improved!!!
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031486096883156164		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.031486096883156164 | validation: 0.042283802246381695]
	TIME [epoch: 8.29 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035837535988853544		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.035837535988853544 | validation: 0.03242431666780422]
	TIME [epoch: 8.29 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039105177940156256		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.039105177940156256 | validation: 0.048826518444054334]
	TIME [epoch: 8.28 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0309593902037827		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.0309593902037827 | validation: 0.034708899430510975]
	TIME [epoch: 8.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02959355135622031		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.02959355135622031 | validation: 0.039909562513512256]
	TIME [epoch: 8.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03232941160081341		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.03232941160081341 | validation: 0.03951703938130374]
	TIME [epoch: 8.29 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034524979539422865		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.034524979539422865 | validation: 0.03648383102147858]
	TIME [epoch: 8.29 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030489753360453807		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.030489753360453807 | validation: 0.0468914222524434]
	TIME [epoch: 8.3 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035548301331927344		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.035548301331927344 | validation: 0.046925485542259074]
	TIME [epoch: 8.29 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026781859041545415		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.026781859041545415 | validation: 0.03958154100238709]
	TIME [epoch: 8.29 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03207682116088627		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.03207682116088627 | validation: 0.04054287530585286]
	TIME [epoch: 8.28 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027867326566527073		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.027867326566527073 | validation: 0.02902110259330643]
	TIME [epoch: 8.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030617840324395233		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.030617840324395233 | validation: 0.04277211931164271]
	TIME [epoch: 8.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02830884335414179		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.02830884335414179 | validation: 0.037899249492072316]
	TIME [epoch: 8.29 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024884209632530654		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.024884209632530654 | validation: 0.029458926325323802]
	TIME [epoch: 8.29 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03623875162149305		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.03623875162149305 | validation: 0.042331592292099776]
	TIME [epoch: 8.31 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03073681384454887		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.03073681384454887 | validation: 0.03993606230221182]
	TIME [epoch: 8.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031193000807088655		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.031193000807088655 | validation: 0.04389963249402845]
	TIME [epoch: 8.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03738120728626122		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.03738120728626122 | validation: 0.043769418940661]
	TIME [epoch: 8.29 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035771098696010674		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.035771098696010674 | validation: 0.030556327440062658]
	TIME [epoch: 8.31 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031434182845754235		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.031434182845754235 | validation: 0.03020738788710341]
	TIME [epoch: 8.29 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027706217650235333		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.027706217650235333 | validation: 0.038220813461210604]
	TIME [epoch: 8.28 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04026179538604483		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.04026179538604483 | validation: 0.05250785020710752]
	TIME [epoch: 8.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046629568982877206		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.046629568982877206 | validation: 0.038164531195603396]
	TIME [epoch: 8.31 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029354602657721857		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.029354602657721857 | validation: 0.035247620106594754]
	TIME [epoch: 8.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02988384344686189		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.02988384344686189 | validation: 0.03239541648942282]
	TIME [epoch: 8.28 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030343911647629136		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.030343911647629136 | validation: 0.047310590997690305]
	TIME [epoch: 8.29 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03009121120478377		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.03009121120478377 | validation: 0.0558346226916097]
	TIME [epoch: 8.31 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03286391888422291		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.03286391888422291 | validation: 0.04140534585855167]
	TIME [epoch: 8.29 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029008456649351137		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.029008456649351137 | validation: 0.028368030482143036]
	TIME [epoch: 8.29 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028305742773495606		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.028305742773495606 | validation: 0.03150416983564532]
	TIME [epoch: 8.29 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030543102164403563		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.030543102164403563 | validation: 0.04152489426929195]
	TIME [epoch: 8.31 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02988660833243088		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.02988660833243088 | validation: 0.032355352468502095]
	TIME [epoch: 8.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03429304437779592		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.03429304437779592 | validation: 0.05898271346678372]
	TIME [epoch: 8.29 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04362627823765598		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.04362627823765598 | validation: 0.053997855461936944]
	TIME [epoch: 8.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03991385005271099		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.03991385005271099 | validation: 0.03575854238249553]
	TIME [epoch: 8.31 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03465616397563771		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.03465616397563771 | validation: 0.04467395106619425]
	TIME [epoch: 8.29 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04070647984847532		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.04070647984847532 | validation: 0.042621019851091776]
	TIME [epoch: 8.28 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03500940256052522		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.03500940256052522 | validation: 0.0380469502173153]
	TIME [epoch: 8.29 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030366802579038		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.030366802579038 | validation: 0.048658056282501194]
	TIME [epoch: 8.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043374026133568486		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.043374026133568486 | validation: 0.04086947361852779]
	TIME [epoch: 8.29 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03238264155199159		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.03238264155199159 | validation: 0.03409796170576951]
	TIME [epoch: 8.29 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027186048770725325		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.027186048770725325 | validation: 0.03634466240605888]
	TIME [epoch: 8.28 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02814562164337723		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.02814562164337723 | validation: 0.036762560550006734]
	TIME [epoch: 8.31 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02962469060590891		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.02962469060590891 | validation: 0.038310113540224046]
	TIME [epoch: 8.29 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029331768271017928		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.029331768271017928 | validation: 0.034948272147430716]
	TIME [epoch: 8.28 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035060051516121314		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.035060051516121314 | validation: 0.041943747985355384]
	TIME [epoch: 8.28 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025515153214409135		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.025515153214409135 | validation: 0.03898798225522335]
	TIME [epoch: 8.31 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028077729222518777		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.028077729222518777 | validation: 0.03466899556922877]
	TIME [epoch: 8.29 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03454455907670704		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.03454455907670704 | validation: 0.0396716776457863]
	TIME [epoch: 8.28 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027357870223918175		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.027357870223918175 | validation: 0.03616799885628052]
	TIME [epoch: 8.28 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03039451455979881		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.03039451455979881 | validation: 0.04229630301858235]
	TIME [epoch: 8.31 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025287059918983425		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.025287059918983425 | validation: 0.03924793751903945]
	TIME [epoch: 8.3 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027686076279229543		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.027686076279229543 | validation: 0.044389103116729216]
	TIME [epoch: 8.29 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03241210577517134		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.03241210577517134 | validation: 0.04206779754525117]
	TIME [epoch: 8.29 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03795122694399604		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.03795122694399604 | validation: 0.036747887318162864]
	TIME [epoch: 8.32 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0295327286199214		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.0295327286199214 | validation: 0.03348317453305756]
	TIME [epoch: 8.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02814165633728578		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.02814165633728578 | validation: 0.04038902433670841]
	TIME [epoch: 8.29 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027517693981207993		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.027517693981207993 | validation: 0.036627011403378894]
	TIME [epoch: 8.29 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03296778735511163		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.03296778735511163 | validation: 0.03154699794138746]
	TIME [epoch: 8.31 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03224686698813213		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.03224686698813213 | validation: 0.04651512471977358]
	TIME [epoch: 8.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030367092383886223		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.030367092383886223 | validation: 0.027650690975053037]
	TIME [epoch: 8.29 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027545582981191308		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.027545582981191308 | validation: 0.03332982049227523]
	TIME [epoch: 8.29 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02940970818924855		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.02940970818924855 | validation: 0.029088057636418287]
	TIME [epoch: 8.31 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030023819325017752		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.030023819325017752 | validation: 0.036956350840628344]
	TIME [epoch: 8.29 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03144643961394208		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.03144643961394208 | validation: 0.03498806221872548]
	TIME [epoch: 8.29 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03472398114677068		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.03472398114677068 | validation: 0.04676055149354552]
	TIME [epoch: 8.28 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03261087519468164		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.03261087519468164 | validation: 0.04150532531066355]
	TIME [epoch: 8.31 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02993708800689544		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.02993708800689544 | validation: 0.025139113878772622]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1828.pth
	Model improved!!!
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03216998280241583		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.03216998280241583 | validation: 0.0468021792559595]
	TIME [epoch: 8.29 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043720820224582575		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.043720820224582575 | validation: 0.03970219444375098]
	TIME [epoch: 8.29 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0343626451933827		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.0343626451933827 | validation: 0.041095522173166574]
	TIME [epoch: 8.32 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030985147713013618		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.030985147713013618 | validation: 0.041799323621664795]
	TIME [epoch: 8.29 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027630834167882735		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.027630834167882735 | validation: 0.053793354741002906]
	TIME [epoch: 8.28 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028522241069868726		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.028522241069868726 | validation: 0.043901085592865124]
	TIME [epoch: 8.29 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030881036926896126		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.030881036926896126 | validation: 0.046602563236725736]
	TIME [epoch: 8.31 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0341080760097998		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.0341080760097998 | validation: 0.05200885728119774]
	TIME [epoch: 8.29 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03613953595357003		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.03613953595357003 | validation: 0.032488202643424106]
	TIME [epoch: 8.29 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02367600047684886		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.02367600047684886 | validation: 0.03463861580270252]
	TIME [epoch: 8.29 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030902820634917595		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.030902820634917595 | validation: 0.03339874826839188]
	TIME [epoch: 8.31 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03748812114532407		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.03748812114532407 | validation: 0.03179574009434567]
	TIME [epoch: 8.29 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03189645031258741		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.03189645031258741 | validation: 0.046011940013492715]
	TIME [epoch: 8.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03152946672074437		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.03152946672074437 | validation: 0.036766927432507465]
	TIME [epoch: 8.29 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0362327145453851		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.0362327145453851 | validation: 0.038879197584195835]
	TIME [epoch: 8.31 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03178435749038376		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.03178435749038376 | validation: 0.031151853527762764]
	TIME [epoch: 8.29 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03040247437053603		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.03040247437053603 | validation: 0.03736736207677592]
	TIME [epoch: 8.3 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030055484482362393		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.030055484482362393 | validation: 0.019191887930660345]
	TIME [epoch: 8.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r1_20240219_184940/states/model_tr_study4_1846.pth
	Model improved!!!
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027020810504528814		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.027020810504528814 | validation: 0.029828617169991346]
	TIME [epoch: 8.32 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032245048954709234		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.032245048954709234 | validation: 0.04100651973677535]
	TIME [epoch: 8.29 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03052718654708194		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.03052718654708194 | validation: 0.037231608594718205]
	TIME [epoch: 8.28 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036214686610213855		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.036214686610213855 | validation: 0.03594870597343644]
	TIME [epoch: 8.29 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03552086763439954		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.03552086763439954 | validation: 0.04253136846995288]
	TIME [epoch: 8.31 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030091410796231965		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.030091410796231965 | validation: 0.03541478049014757]
	TIME [epoch: 8.29 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025281549175424155		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.025281549175424155 | validation: 0.033273768263388154]
	TIME [epoch: 8.3 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034032444588533474		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.034032444588533474 | validation: 0.045487639815163815]
	TIME [epoch: 8.29 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028552371208409606		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.028552371208409606 | validation: 0.038992177705654635]
	TIME [epoch: 8.32 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034802657449942244		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.034802657449942244 | validation: 0.041127213015904496]
	TIME [epoch: 8.28 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03637751977328253		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.03637751977328253 | validation: 0.053534937868672056]
	TIME [epoch: 8.29 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03336918275205492		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.03336918275205492 | validation: 0.03568311316809886]
	TIME [epoch: 8.29 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027551621462813362		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.027551621462813362 | validation: 0.04094016163640225]
	TIME [epoch: 8.31 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028167612624066328		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.028167612624066328 | validation: 0.03110406605345322]
	TIME [epoch: 8.29 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028439267512772048		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.028439267512772048 | validation: 0.03270821990157097]
	TIME [epoch: 8.3 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03146496556192405		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.03146496556192405 | validation: 0.02963385473640743]
	TIME [epoch: 8.28 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03429054430695164		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.03429054430695164 | validation: 0.02876648436082574]
	TIME [epoch: 8.32 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027981024050313285		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.027981024050313285 | validation: 0.03056585273870709]
	TIME [epoch: 8.29 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034020505960712454		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.034020505960712454 | validation: 0.03980140797967435]
	TIME [epoch: 8.28 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030160057652684046		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.030160057652684046 | validation: 0.040378291714473546]
	TIME [epoch: 8.28 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029771184132074902		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.029771184132074902 | validation: 0.0390578792163043]
	TIME [epoch: 8.31 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028260893199869897		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.028260893199869897 | validation: 0.02867856550199925]
	TIME [epoch: 8.28 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03289181537947329		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.03289181537947329 | validation: 0.046625794976237825]
	TIME [epoch: 8.28 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032688062324672515		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.032688062324672515 | validation: 0.04173915586551597]
	TIME [epoch: 8.28 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029049998963882724		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.029049998963882724 | validation: 0.03850982966445721]
	TIME [epoch: 8.31 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02623219831269692		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.02623219831269692 | validation: 0.04400582276218727]
	TIME [epoch: 8.28 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03247650552760029		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.03247650552760029 | validation: 0.030325254626256636]
	TIME [epoch: 8.29 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03237613646194686		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.03237613646194686 | validation: 0.03401174337483452]
	TIME [epoch: 8.29 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029347816036725843		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.029347816036725843 | validation: 0.04181067754249005]
	TIME [epoch: 8.31 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03376005283759662		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.03376005283759662 | validation: 0.0422468731597303]
	TIME [epoch: 8.29 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033224447627329436		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.033224447627329436 | validation: 0.04188471904081101]
	TIME [epoch: 8.28 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03372626911737421		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.03372626911737421 | validation: 0.04523081703834181]
	TIME [epoch: 8.29 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02555553485285139		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.02555553485285139 | validation: 0.03515095251706592]
	TIME [epoch: 8.32 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02611780775862092		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.02611780775862092 | validation: 0.03538537419266191]
	TIME [epoch: 8.29 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029423853012620516		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.029423853012620516 | validation: 0.0325115383383745]
	TIME [epoch: 8.29 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031005142240482585		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.031005142240482585 | validation: 0.03791192353789824]
	TIME [epoch: 8.28 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036523039966301935		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.036523039966301935 | validation: 0.04406826838216338]
	TIME [epoch: 8.31 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03201541767595047		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.03201541767595047 | validation: 0.048282401250567764]
	TIME [epoch: 8.29 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03269954581992052		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.03269954581992052 | validation: 0.04610150740074046]
	TIME [epoch: 8.3 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031773319831764464		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.031773319831764464 | validation: 0.03833876500263125]
	TIME [epoch: 8.29 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03416727656994875		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.03416727656994875 | validation: 0.029600562998359156]
	TIME [epoch: 8.3 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02653432578417576		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.02653432578417576 | validation: 0.04559529781984921]
	TIME [epoch: 8.28 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029091277327571063		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.029091277327571063 | validation: 0.036540274388729393]
	TIME [epoch: 8.29 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02342564471265399		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.02342564471265399 | validation: 0.04457724419671394]
	TIME [epoch: 8.29 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038477386631591504		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.038477386631591504 | validation: 0.052549496859901984]
	TIME [epoch: 8.3 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03610780109627191		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.03610780109627191 | validation: 0.02513953792720145]
	TIME [epoch: 8.29 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02854787306104507		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.02854787306104507 | validation: 0.03253651687983429]
	TIME [epoch: 8.29 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0286568352244658		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.0286568352244658 | validation: 0.03655714884528128]
	TIME [epoch: 8.29 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029335238211345566		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.029335238211345566 | validation: 0.031289826612020864]
	TIME [epoch: 8.3 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03098707513179732		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.03098707513179732 | validation: 0.04000991839919361]
	TIME [epoch: 8.28 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0336114649822649		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.0336114649822649 | validation: 0.03112250918959352]
	TIME [epoch: 8.29 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030174578106866034		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.030174578106866034 | validation: 0.03614498051548759]
	TIME [epoch: 8.28 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03234666411727383		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.03234666411727383 | validation: 0.0481152356092603]
	TIME [epoch: 8.31 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03873833492240976		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.03873833492240976 | validation: 0.031081417106123922]
	TIME [epoch: 8.28 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03348909622701548		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.03348909622701548 | validation: 0.03999153950705036]
	TIME [epoch: 8.29 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028951104018170182		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.028951104018170182 | validation: 0.037655527488644945]
	TIME [epoch: 8.28 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02488044976564254		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.02488044976564254 | validation: 0.03303584554482815]
	TIME [epoch: 8.31 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03154833527308851		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.03154833527308851 | validation: 0.0307492176708764]
	TIME [epoch: 8.28 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03437817011465723		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.03437817011465723 | validation: 0.029473239597261343]
	TIME [epoch: 8.29 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025877230355553192		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.025877230355553192 | validation: 0.035710996541482895]
	TIME [epoch: 8.29 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033733406501252595		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.033733406501252595 | validation: 0.043299309579386186]
	TIME [epoch: 8.31 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02793815298403658		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.02793815298403658 | validation: 0.033881212539692535]
	TIME [epoch: 8.29 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029078087837084536		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.029078087837084536 | validation: 0.037069003276439826]
	TIME [epoch: 8.29 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03255277464091093		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.03255277464091093 | validation: 0.04267016652758604]
	TIME [epoch: 8.32 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031195227983329583		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.031195227983329583 | validation: 0.04757494378987803]
	TIME [epoch: 8.31 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037774304008901124		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.037774304008901124 | validation: 0.03577815365389497]
	TIME [epoch: 8.28 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03061218006960939		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.03061218006960939 | validation: 0.04447955783998164]
	TIME [epoch: 8.29 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03169488662875733		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.03169488662875733 | validation: 0.05322916401387621]
	TIME [epoch: 8.28 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036327979418571535		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.036327979418571535 | validation: 0.03541915988601217]
	TIME [epoch: 8.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02773120134264707		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.02773120134264707 | validation: 0.04319764772858321]
	TIME [epoch: 8.3 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03310487057849355		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.03310487057849355 | validation: 0.038347107458291715]
	TIME [epoch: 8.29 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03898256850530865		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.03898256850530865 | validation: 0.040876394778619055]
	TIME [epoch: 8.29 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027925084765328588		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.027925084765328588 | validation: 0.0367644368165014]
	TIME [epoch: 8.3 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02805264342644062		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.02805264342644062 | validation: 0.04371415159018552]
	TIME [epoch: 8.28 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03047838485236251		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.03047838485236251 | validation: 0.03586320681754339]
	TIME [epoch: 8.29 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03149022745264011		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.03149022745264011 | validation: 0.028806781590533827]
	TIME [epoch: 8.29 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02815139171969642		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.02815139171969642 | validation: 0.03377131693976794]
	TIME [epoch: 8.3 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027240339184309532		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.027240339184309532 | validation: 0.03335732096853175]
	TIME [epoch: 8.29 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03312557503016349		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.03312557503016349 | validation: 0.03105039147711065]
	TIME [epoch: 8.29 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03451926398469242		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.03451926398469242 | validation: 0.03736644955209865]
	TIME [epoch: 8.3 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03049076260472061		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.03049076260472061 | validation: 0.03778259456817641]
	TIME [epoch: 8.3 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02827771640289145		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.02827771640289145 | validation: 0.02952944589606503]
	TIME [epoch: 8.29 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03096261384968843		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.03096261384968843 | validation: 0.043803890980291915]
	TIME [epoch: 8.29 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026561552605377688		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.026561552605377688 | validation: 0.0309262553487816]
	TIME [epoch: 8.29 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027963239384314796		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.027963239384314796 | validation: 0.02606024669754424]
	TIME [epoch: 8.3 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02484808602838056		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.02484808602838056 | validation: 0.04373144778132539]
	TIME [epoch: 8.28 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03073262703012335		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.03073262703012335 | validation: 0.03662540490991177]
	TIME [epoch: 8.3 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026877326986640228		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.026877326986640228 | validation: 0.03696769727680281]
	TIME [epoch: 8.29 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029918720927440495		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.029918720927440495 | validation: 0.036058081754545994]
	TIME [epoch: 8.31 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031757163347984924		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.031757163347984924 | validation: 0.03868063000530837]
	TIME [epoch: 8.29 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026275076292900722		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.026275076292900722 | validation: 0.02978378682720008]
	TIME [epoch: 8.3 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030927839924790358		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.030927839924790358 | validation: 0.03139542434450931]
	TIME [epoch: 8.35 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027275047869492086		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.027275047869492086 | validation: 0.037980471817185446]
	TIME [epoch: 8.3 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024768774869837258		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.024768774869837258 | validation: 0.03956721538810012]
	TIME [epoch: 8.28 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027312646274067553		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.027312646274067553 | validation: 0.02305254464204506]
	TIME [epoch: 8.28 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02669161702738449		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.02669161702738449 | validation: 0.040883487710064434]
	TIME [epoch: 8.29 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027686907103578705		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.027686907103578705 | validation: 0.03881810178921681]
	TIME [epoch: 8.3 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04037696357801164		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.04037696357801164 | validation: 0.036270375222183966]
	TIME [epoch: 8.29 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029078409076516282		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.029078409076516282 | validation: 0.03794523509708016]
	TIME [epoch: 8.28 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029604770698337706		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.029604770698337706 | validation: 0.039849860401938705]
	TIME [epoch: 8.29 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028199107618476688		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.028199107618476688 | validation: 0.02990171911836019]
	TIME [epoch: 8.3 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032513072109887256		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.032513072109887256 | validation: 0.027861393108176292]
	TIME [epoch: 8.29 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03000707288337139		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.03000707288337139 | validation: 0.0410575173785436]
	TIME [epoch: 8.29 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03026440998337638		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.03026440998337638 | validation: 0.038750787306226]
	TIME [epoch: 8.3 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03151552757073401		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.03151552757073401 | validation: 0.03234613529766048]
	TIME [epoch: 8.31 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0277702449099519		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.0277702449099519 | validation: 0.032616317816180546]
	TIME [epoch: 8.29 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029010762823700863		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.029010762823700863 | validation: 0.031854786930592384]
	TIME [epoch: 8.28 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03441024996287766		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.03441024996287766 | validation: 0.03168954624131596]
	TIME [epoch: 8.3 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030824278049103686		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.030824278049103686 | validation: 0.03943144716684231]
	TIME [epoch: 8.29 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028010438364132428		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.028010438364132428 | validation: 0.04476792240496775]
	TIME [epoch: 8.29 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031022707296383872		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.031022707296383872 | validation: 0.03300102850935117]
	TIME [epoch: 8.29 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029726191384015516		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.029726191384015516 | validation: 0.031013968621658113]
	TIME [epoch: 8.3 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027918916747599776		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.027918916747599776 | validation: 0.04220196818944978]
	TIME [epoch: 8.29 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025793404176555103		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.025793404176555103 | validation: 0.034293292111152104]
	TIME [epoch: 8.28 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026614184729550527		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.026614184729550527 | validation: 0.028836504030095675]
	TIME [epoch: 8.28 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03363932781449342		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.03363932781449342 | validation: 0.03524576496505091]
	TIME [epoch: 8.29 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022616393367588285		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.022616393367588285 | validation: 0.04030465837830516]
	TIME [epoch: 8.29 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027526661607712378		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.027526661607712378 | validation: 0.04368641651913338]
	TIME [epoch: 8.29 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02802343481179671		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.02802343481179671 | validation: 0.03900541105311785]
	TIME [epoch: 8.28 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02880687630151152		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.02880687630151152 | validation: 0.03266144614885191]
	TIME [epoch: 8.3 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031727721894765776		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.031727721894765776 | validation: 0.032476328016687595]
	TIME [epoch: 8.29 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024486163650397658		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.024486163650397658 | validation: 0.03343232940836626]
	TIME [epoch: 8.28 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028749529596510576		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.028749529596510576 | validation: 0.026841713337157007]
	TIME [epoch: 8.28 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03585316208410053		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.03585316208410053 | validation: 0.04184431535308433]
	TIME [epoch: 8.3 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029629675884255836		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.029629675884255836 | validation: 0.03429599229337444]
	TIME [epoch: 8.29 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034565177730509655		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.034565177730509655 | validation: 0.031179164152372797]
	TIME [epoch: 8.28 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026405069238656605		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.026405069238656605 | validation: 0.040765453110696084]
	TIME [epoch: 8.28 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02991685867737403		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.02991685867737403 | validation: 0.03291892038444124]
	TIME [epoch: 8.3 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02826051860849917		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.02826051860849917 | validation: 0.03344385667261161]
	TIME [epoch: 8.3 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0255385579718234		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.0255385579718234 | validation: 0.036189297073555546]
	TIME [epoch: 8.29 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028928843465857133		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.028928843465857133 | validation: 0.038816402614952616]
	TIME [epoch: 8.28 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024741332815834856		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.024741332815834856 | validation: 0.03551649955869285]
	TIME [epoch: 8.3 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02728723042513531		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.02728723042513531 | validation: 0.04966043014226104]
	TIME [epoch: 8.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040167357812496585		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.040167357812496585 | validation: 0.04001251366742632]
	TIME [epoch: 8.29 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030095648983558532		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.030095648983558532 | validation: 0.036463007539103726]
	TIME [epoch: 8.28 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031288823549834706		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.031288823549834706 | validation: 0.037443049920442784]
	TIME [epoch: 8.3 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03317053791485326		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.03317053791485326 | validation: 0.03564050000620224]
	TIME [epoch: 8.3 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02705018439699227		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.02705018439699227 | validation: 0.034446316423105604]
	TIME [epoch: 8.29 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024386725236248664		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.024386725236248664 | validation: 0.02950221883608877]
	TIME [epoch: 8.29 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029971070466899747		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.029971070466899747 | validation: 0.039601566333190535]
	TIME [epoch: 8.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02816783280339171		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.02816783280339171 | validation: 0.051651250879353]
	TIME [epoch: 8.3 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031245640755682424		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.031245640755682424 | validation: 0.028836835361270963]
	TIME [epoch: 8.28 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023456698619860765		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.023456698619860765 | validation: 0.036553883822410836]
	TIME [epoch: 8.29 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028034808648712505		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.028034808648712505 | validation: 0.03467379184824431]
	TIME [epoch: 8.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025993283358772372		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.025993283358772372 | validation: 0.03066187195651189]
	TIME [epoch: 8.29 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025997776182129156		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.025997776182129156 | validation: 0.032611426817064804]
	TIME [epoch: 8.28 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024959845869940343		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.024959845869940343 | validation: 0.036950339356900105]
	TIME [epoch: 8.29 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033418322883255885		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.033418322883255885 | validation: 0.04147716770522669]
	TIME [epoch: 8.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030837113397318712		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.030837113397318712 | validation: 0.03408494491225124]
	TIME [epoch: 8.29 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026427595596455567		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.026427595596455567 | validation: 0.03063749520429801]
	TIME [epoch: 8.28 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029026535331798786		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.029026535331798786 | validation: 0.04210525734588892]
	TIME [epoch: 8.29 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02885010278182897		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.02885010278182897 | validation: 0.045508210557467225]
	TIME [epoch: 8.31 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03443867706294127		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.03443867706294127 | validation: 0.029952274045351966]
	TIME [epoch: 8.3 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031547685771205536		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.031547685771205536 | validation: 0.03418520516103099]
	TIME [epoch: 8.29 sec]
Finished training in 16759.899 seconds.
