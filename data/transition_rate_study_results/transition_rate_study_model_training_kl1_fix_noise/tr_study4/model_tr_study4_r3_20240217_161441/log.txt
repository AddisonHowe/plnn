Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 790575901

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.656827279968384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.656827279968384 | validation: 8.350703547965107]
	TIME [epoch: 70.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.748350124745597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.748350124745597 | validation: 7.852537215891331]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.817770386997575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.817770386997575 | validation: 6.867808374914086]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.190607298583696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.190607298583696 | validation: 6.089064696863469]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.522964600960379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.522964600960379 | validation: 5.848280545493838]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.6637103905512545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6637103905512545 | validation: 4.336986291216906]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.891590199745826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.891590199745826 | validation: 3.7211581615828218]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.637851020539823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.637851020539823 | validation: 6.498572389775155]
	TIME [epoch: 9.1 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.830676712535604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.830676712535604 | validation: 4.441809240486075]
	TIME [epoch: 9.09 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.917662931467488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.917662931467488 | validation: 9.212237871453041]
	TIME [epoch: 9.06 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.931175728620969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.931175728620969 | validation: 4.106497364680705]
	TIME [epoch: 9.07 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.989440282445373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.989440282445373 | validation: 3.6656053569909517]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.6282949388569685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6282949388569685 | validation: 6.529971931659082]
	TIME [epoch: 9.11 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.45940817982974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.45940817982974 | validation: 4.237448073484567]
	TIME [epoch: 9.09 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8313386056658763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8313386056658763 | validation: 3.485493180772602]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.335361118811986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.335361118811986 | validation: 3.718149293027877]
	TIME [epoch: 9.07 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.720113327347295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.720113327347295 | validation: 8.86942753918232]
	TIME [epoch: 9.08 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.986282238435927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.986282238435927 | validation: 3.5768720251945174]
	TIME [epoch: 9.08 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.889618299542485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.889618299542485 | validation: 4.455318045677425]
	TIME [epoch: 9.06 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9497071073368843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9497071073368843 | validation: 4.750047578192632]
	TIME [epoch: 9.07 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.5463590249989623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5463590249989623 | validation: 3.7440869717370515]
	TIME [epoch: 9.06 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.125413417775751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.125413417775751 | validation: 3.5755075023902223]
	TIME [epoch: 9.1 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.5681317259570973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5681317259570973 | validation: 3.0867884843221955]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.866116042007372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.866116042007372 | validation: 3.05070285088762]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.808607268365162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.808607268365162 | validation: 0.826264526296996]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2389895783145186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2389895783145186 | validation: 1.1144078676745315]
	TIME [epoch: 9.08 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9222528221466932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9222528221466932 | validation: 0.9074994498384016]
	TIME [epoch: 9.09 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.049455850802065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.049455850802065 | validation: 1.252690268663568]
	TIME [epoch: 9.07 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.922252499055595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.922252499055595 | validation: 1.5226314936572947]
	TIME [epoch: 9.08 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8913295145387913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8913295145387913 | validation: 0.5389708216900293]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8861151796439959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8861151796439959 | validation: 0.7935525820330125]
	TIME [epoch: 9.1 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7622991633543741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7622991633543741 | validation: 2.2403244120247963]
	TIME [epoch: 9.08 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1547267320728334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1547267320728334 | validation: 0.6113497877706586]
	TIME [epoch: 9.07 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7221143682282812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7221143682282812 | validation: 1.0919987010211525]
	TIME [epoch: 9.08 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7954742908716512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7954742908716512 | validation: 0.7362266123127132]
	TIME [epoch: 9.08 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8834218381950827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8834218381950827 | validation: 1.8638399529486267]
	TIME [epoch: 9.09 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2712154770516038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2712154770516038 | validation: 1.2734284451611209]
	TIME [epoch: 9.07 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2589954725371362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2589954725371362 | validation: 1.2150387101284539]
	TIME [epoch: 9.07 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0060427815339694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0060427815339694 | validation: 1.856694111152252]
	TIME [epoch: 9.08 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.263416431412461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.263416431412461 | validation: 1.4709711573503623]
	TIME [epoch: 9.1 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2901809796149524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2901809796149524 | validation: 1.177248453717206]
	TIME [epoch: 9.08 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8762530772847394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8762530772847394 | validation: 1.0487709010953188]
	TIME [epoch: 9.07 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0401154309638685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0401154309638685 | validation: 2.047222582961412]
	TIME [epoch: 9.07 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1345941962599233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1345941962599233 | validation: 1.7220065262388102]
	TIME [epoch: 9.08 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2557460530623978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2557460530623978 | validation: 1.492058035388611]
	TIME [epoch: 9.1 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0139271840208868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0139271840208868 | validation: 1.7505675052205933]
	TIME [epoch: 9.07 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.131123745164767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.131123745164767 | validation: 1.3240594409700126]
	TIME [epoch: 9.07 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1781799042447965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1781799042447965 | validation: 1.1164960634260876]
	TIME [epoch: 9.07 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8630553245293257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8630553245293257 | validation: 0.6781692876620364]
	TIME [epoch: 9.09 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.793781257268811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.793781257268811 | validation: 0.6361861742698237]
	TIME [epoch: 9.09 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.170618110365119		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 1.170618110365119 | validation: 1.3068651699717027]
	TIME [epoch: 9.07 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0204339496707828		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.0204339496707828 | validation: 0.6718709077769938]
	TIME [epoch: 9.07 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.18266242929027		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 1.18266242929027 | validation: 0.7695560700130106]
	TIME [epoch: 9.07 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7879719792956299		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 0.7879719792956299 | validation: 1.4771890059123436]
	TIME [epoch: 9.1 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9105152814008589		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 0.9105152814008589 | validation: 0.6058988908072895]
	TIME [epoch: 9.08 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8025202815597522		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.8025202815597522 | validation: 0.67447733782828]
	TIME [epoch: 9.08 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7365324675646592		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 0.7365324675646592 | validation: 0.6177236864276217]
	TIME [epoch: 9.07 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1779463736038882		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.1779463736038882 | validation: 0.760746499840296]
	TIME [epoch: 9.08 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0983432563128894		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.0983432563128894 | validation: 0.6587373054807226]
	TIME [epoch: 9.08 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8168467731392306		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.8168467731392306 | validation: 0.6620361592173688]
	TIME [epoch: 9.08 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1177923467761048		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 1.1177923467761048 | validation: 0.7887269705477147]
	TIME [epoch: 9.06 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9042547736518924		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 0.9042547736518924 | validation: 0.9884028607279449]
	TIME [epoch: 9.07 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9062437141106136		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.9062437141106136 | validation: 0.7229535229634445]
	TIME [epoch: 9.09 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8883342677297381		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 0.8883342677297381 | validation: 0.6158002192734193]
	TIME [epoch: 9.07 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9011152853636167		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.9011152853636167 | validation: 0.9572952580385854]
	TIME [epoch: 9.07 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6971606457729524		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.6971606457729524 | validation: 0.7961289495623591]
	TIME [epoch: 9.07 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8805183762979152		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 0.8805183762979152 | validation: 0.6630559111127952]
	TIME [epoch: 9.09 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0685994366967835		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.0685994366967835 | validation: 0.76752577861397]
	TIME [epoch: 9.09 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8930183256818685		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.8930183256818685 | validation: 0.5890479988675572]
	TIME [epoch: 9.07 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0647517297704352		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.0647517297704352 | validation: 1.050886705551739]
	TIME [epoch: 9.07 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7892230284050598		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.7892230284050598 | validation: 0.8739505829413335]
	TIME [epoch: 9.06 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7367054452933149		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.7367054452933149 | validation: 1.6444358623035105]
	TIME [epoch: 9.09 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8565909287638819		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.8565909287638819 | validation: 0.7978069932044065]
	TIME [epoch: 9.07 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8489325640010353		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.8489325640010353 | validation: 0.7744041599885174]
	TIME [epoch: 9.06 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6705119933348895		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.6705119933348895 | validation: 0.5484247023744603]
	TIME [epoch: 9.07 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7066978897996362		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.7066978897996362 | validation: 0.5958179009472957]
	TIME [epoch: 9.07 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6957479624606202		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.6957479624606202 | validation: 1.3942311158511485]
	TIME [epoch: 9.09 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8436439172071453		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.8436439172071453 | validation: 1.8276026440524842]
	TIME [epoch: 9.07 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8269671223475615		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.8269671223475615 | validation: 0.8432608790623517]
	TIME [epoch: 9.07 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.664350095354253		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.664350095354253 | validation: 0.5967474044076683]
	TIME [epoch: 9.07 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8215458990505466		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.8215458990505466 | validation: 0.8299590798275476]
	TIME [epoch: 9.08 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8405498903673596		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.8405498903673596 | validation: 0.6369041165050956]
	TIME [epoch: 9.09 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1612362025395082		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.1612362025395082 | validation: 0.9082223694765833]
	TIME [epoch: 9.07 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6614222534076231		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.6614222534076231 | validation: 0.7685591792403901]
	TIME [epoch: 9.07 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7542242235983997		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.7542242235983997 | validation: 1.0155840507529694]
	TIME [epoch: 9.07 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8096266651114549		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.8096266651114549 | validation: 0.6108981724030085]
	TIME [epoch: 9.1 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7391358355847891		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.7391358355847891 | validation: 0.831093615221725]
	TIME [epoch: 9.07 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0400563146910722		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.0400563146910722 | validation: 1.2573543430144216]
	TIME [epoch: 9.07 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8084499818930813		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.8084499818930813 | validation: 0.685137605050439]
	TIME [epoch: 9.07 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7150427801820927		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.7150427801820927 | validation: 0.5926555830172195]
	TIME [epoch: 9.08 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7864138549843642		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.7864138549843642 | validation: 0.984905828357753]
	TIME [epoch: 9.08 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9267396999200844		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.9267396999200844 | validation: 0.585811429447752]
	TIME [epoch: 9.07 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8563021284157291		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.8563021284157291 | validation: 1.0644908142360487]
	TIME [epoch: 9.08 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.659227475137172		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.659227475137172 | validation: 0.6010714955431253]
	TIME [epoch: 9.07 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7054922755500264		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.7054922755500264 | validation: 0.6778716134435048]
	TIME [epoch: 9.1 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7052373685396324		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.7052373685396324 | validation: 0.6410227020500208]
	TIME [epoch: 9.08 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7207717707097403		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.7207717707097403 | validation: 0.5250780168275504]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7436983805117122		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.7436983805117122 | validation: 0.7722991642841786]
	TIME [epoch: 9.09 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9193731627223052		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.9193731627223052 | validation: 1.117350151420973]
	TIME [epoch: 9.09 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7669991408428151		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.7669991408428151 | validation: 0.7482382231146727]
	TIME [epoch: 9.09 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7226976981470354		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.7226976981470354 | validation: 0.8230750710696053]
	TIME [epoch: 9.08 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5663811286776006		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.5663811286776006 | validation: 0.7194993497429847]
	TIME [epoch: 9.07 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5980280616626544		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.5980280616626544 | validation: 0.7069575595304611]
	TIME [epoch: 9.08 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5735297031226118		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.5735297031226118 | validation: 0.44276910648626144]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5640661116453655		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.5640661116453655 | validation: 0.46344516203614117]
	TIME [epoch: 9.08 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7112307330004187		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.7112307330004187 | validation: 0.5713402614381663]
	TIME [epoch: 9.08 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5720176242385441		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.5720176242385441 | validation: 0.5211547903794413]
	TIME [epoch: 9.07 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5867106625811315		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.5867106625811315 | validation: 0.44060578774139353]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_108.pth
	Model improved!!!
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7054628789345229		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.7054628789345229 | validation: 0.5395083201407078]
	TIME [epoch: 9.11 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5378447111649867		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.5378447111649867 | validation: 0.48622491174983895]
	TIME [epoch: 9.08 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6652760108804416		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.6652760108804416 | validation: 0.5458148519029006]
	TIME [epoch: 9.08 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5410769870323066		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.5410769870323066 | validation: 0.4457111871926145]
	TIME [epoch: 9.07 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1580664816705633		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.1580664816705633 | validation: 0.8095287188216753]
	TIME [epoch: 9.1 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5857185161071801		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.5857185161071801 | validation: 0.714682515883506]
	TIME [epoch: 9.08 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.574379174527875		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.574379174527875 | validation: 0.4721934887027597]
	TIME [epoch: 9.08 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5752891877373774		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5752891877373774 | validation: 0.4306229262486516]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_116.pth
	Model improved!!!
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5428602159900056		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.5428602159900056 | validation: 0.5309173711175673]
	TIME [epoch: 9.07 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5690419251757235		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.5690419251757235 | validation: 0.5676576251648655]
	TIME [epoch: 9.1 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5240632045202266		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.5240632045202266 | validation: 0.3876346372734068]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_119.pth
	Model improved!!!
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5931348474654509		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.5931348474654509 | validation: 0.6081231652579696]
	TIME [epoch: 9.07 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5398654933955077		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.5398654933955077 | validation: 0.5253918635282459]
	TIME [epoch: 9.07 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6571395877231664		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.6571395877231664 | validation: 1.6722868512648574]
	TIME [epoch: 9.08 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8715482340896843		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.8715482340896843 | validation: 0.5822118561046727]
	TIME [epoch: 9.08 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5084352078953911		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.5084352078953911 | validation: 0.5941482445012745]
	TIME [epoch: 9.06 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5478433674262871		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.5478433674262871 | validation: 0.3729438739035448]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_125.pth
	Model improved!!!
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6191956853853454		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.6191956853853454 | validation: 0.46525632260286565]
	TIME [epoch: 9.07 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6700616402444435		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.6700616402444435 | validation: 0.45169775992516403]
	TIME [epoch: 9.08 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5047040376262435		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5047040376262435 | validation: 0.6059853297149479]
	TIME [epoch: 9.06 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49977802834126805		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.49977802834126805 | validation: 0.45598048062316265]
	TIME [epoch: 9.06 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5372285949169864		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.5372285949169864 | validation: 0.6278061663235447]
	TIME [epoch: 9.05 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5711864969154494		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.5711864969154494 | validation: 0.6289329402100448]
	TIME [epoch: 9.08 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5408943616198533		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.5408943616198533 | validation: 0.5458566537584436]
	TIME [epoch: 9.08 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5979239119167367		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.5979239119167367 | validation: 0.54157367774381]
	TIME [epoch: 9.07 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5304172044689958		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.5304172044689958 | validation: 0.5502831803685198]
	TIME [epoch: 9.06 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.521793310884222		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.521793310884222 | validation: 0.8025389586305358]
	TIME [epoch: 9.07 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5544709181544109		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.5544709181544109 | validation: 0.45919539677885446]
	TIME [epoch: 9.09 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5384548482852956		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.5384548482852956 | validation: 0.531893750800355]
	TIME [epoch: 9.07 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5697513275375579		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.5697513275375579 | validation: 0.47851396965164955]
	TIME [epoch: 9.06 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49497168604002234		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.49497168604002234 | validation: 0.6448085119682043]
	TIME [epoch: 9.06 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601971675295855		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.5601971675295855 | validation: 0.3828637231878631]
	TIME [epoch: 9.06 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4716530166685855		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.4716530166685855 | validation: 0.9892885087185804]
	TIME [epoch: 9.09 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5382109926830032		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.5382109926830032 | validation: 0.6124931007311281]
	TIME [epoch: 9.06 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5207352659104145		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.5207352659104145 | validation: 0.4892849615530699]
	TIME [epoch: 9.06 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5879069028259323		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.5879069028259323 | validation: 0.6732430327868232]
	TIME [epoch: 9.07 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5754385466859898		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.5754385466859898 | validation: 0.594607255580191]
	TIME [epoch: 9.08 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48536442149684644		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.48536442149684644 | validation: 1.1766552048765115]
	TIME [epoch: 9.08 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5978222140638325		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.5978222140638325 | validation: 0.6240285983788729]
	TIME [epoch: 9.07 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5877382202123276		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.5877382202123276 | validation: 0.579380966499181]
	TIME [epoch: 9.07 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5934337182569551		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.5934337182569551 | validation: 0.3700951700889971]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_149.pth
	Model improved!!!
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4947215253345642		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.4947215253345642 | validation: 0.7262158744468482]
	TIME [epoch: 9.09 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5466849652901453		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.5466849652901453 | validation: 0.5047796304058463]
	TIME [epoch: 9.07 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5808195680917375		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.5808195680917375 | validation: 0.3535036391257764]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_152.pth
	Model improved!!!
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47600486492328997		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.47600486492328997 | validation: 0.374775475841876]
	TIME [epoch: 9.06 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4932932907292494		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.4932932907292494 | validation: 0.3518277002794201]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_154.pth
	Model improved!!!
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.534551431325591		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.534551431325591 | validation: 0.3984791261703823]
	TIME [epoch: 9.08 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49360306991927627		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.49360306991927627 | validation: 1.266934782422917]
	TIME [epoch: 9.07 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.675108278856236		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.675108278856236 | validation: 0.5351452350237751]
	TIME [epoch: 9.07 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5018995928972922		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.5018995928972922 | validation: 0.7865164572171253]
	TIME [epoch: 9.06 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5143756624779825		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.5143756624779825 | validation: 0.4636685356646125]
	TIME [epoch: 9.1 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5193025262711121		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.5193025262711121 | validation: 0.4028711945473896]
	TIME [epoch: 9.08 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4305086077280869		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.4305086077280869 | validation: 0.3927008074812395]
	TIME [epoch: 9.07 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4266323283244402		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.4266323283244402 | validation: 0.3942957355068225]
	TIME [epoch: 9.07 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47959940051787414		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.47959940051787414 | validation: 0.45879760088721655]
	TIME [epoch: 9.07 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5162444382653649		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.5162444382653649 | validation: 0.40404165096328776]
	TIME [epoch: 9.08 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5256797448221443		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.5256797448221443 | validation: 0.5582371588652089]
	TIME [epoch: 9.07 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5553299068037651		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5553299068037651 | validation: 0.38796403191645107]
	TIME [epoch: 9.07 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6606443902152301		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.6606443902152301 | validation: 0.34864285950243434]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_167.pth
	Model improved!!!
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4266560830702346		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.4266560830702346 | validation: 0.3694203601346794]
	TIME [epoch: 9.09 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45738881358038974		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.45738881358038974 | validation: 0.6909765018126343]
	TIME [epoch: 9.07 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46362583861093415		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.46362583861093415 | validation: 0.6819457139849812]
	TIME [epoch: 9.06 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4735037594301623		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.4735037594301623 | validation: 0.4317712223731462]
	TIME [epoch: 9.06 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4648528215486035		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.4648528215486035 | validation: 0.4873136238999998]
	TIME [epoch: 9.09 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4828595660378924		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.4828595660378924 | validation: 0.4419032909614494]
	TIME [epoch: 9.08 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43208313163528905		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.43208313163528905 | validation: 1.4960687278021259]
	TIME [epoch: 9.08 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6256793415844966		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.6256793415844966 | validation: 0.37789224760391493]
	TIME [epoch: 9.07 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5049628131013719		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.5049628131013719 | validation: 0.5297691961166953]
	TIME [epoch: 9.07 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3922026932563492		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.3922026932563492 | validation: 0.6516604272918509]
	TIME [epoch: 9.09 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5160601661986982		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.5160601661986982 | validation: 0.534189223068545]
	TIME [epoch: 9.07 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4467846082159679		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.4467846082159679 | validation: 0.3565412774685347]
	TIME [epoch: 9.07 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3869819857569413		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.3869819857569413 | validation: 0.46362038313513154]
	TIME [epoch: 9.07 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5108654409171491		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.5108654409171491 | validation: 0.45930448329436574]
	TIME [epoch: 9.07 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4209868418080826		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.4209868418080826 | validation: 0.32175989685813744]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_182.pth
	Model improved!!!
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48017295926832826		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.48017295926832826 | validation: 0.3932803996702453]
	TIME [epoch: 9.07 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41815735095822043		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.41815735095822043 | validation: 0.3529775232755984]
	TIME [epoch: 9.07 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49327308752316		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.49327308752316 | validation: 0.45135403945362973]
	TIME [epoch: 9.07 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44230928884774956		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.44230928884774956 | validation: 0.3043220143296502]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47304698866302186		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.47304698866302186 | validation: 0.5812246461168608]
	TIME [epoch: 9.08 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898272155758084		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.3898272155758084 | validation: 0.35134053719303127]
	TIME [epoch: 9.06 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37422104922909827		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.37422104922909827 | validation: 0.3942314642170795]
	TIME [epoch: 9.06 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4022967784602386		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.4022967784602386 | validation: 0.3916550673862137]
	TIME [epoch: 9.06 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3776352344183359		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.3776352344183359 | validation: 0.44106833699781994]
	TIME [epoch: 9.08 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34877259845893255		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.34877259845893255 | validation: 0.4516441734154595]
	TIME [epoch: 9.06 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5172638302531091		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.5172638302531091 | validation: 0.3188543590131393]
	TIME [epoch: 9.07 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4746400547589558		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.4746400547589558 | validation: 0.34083670426745905]
	TIME [epoch: 9.05 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3894436989457947		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.3894436989457947 | validation: 0.5329452551512602]
	TIME [epoch: 9.07 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43083594418031834		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.43083594418031834 | validation: 0.7581851010787148]
	TIME [epoch: 9.07 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5112703596963492		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.5112703596963492 | validation: 0.3547414006278968]
	TIME [epoch: 9.06 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34136936301711623		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.34136936301711623 | validation: 0.31125420707439927]
	TIME [epoch: 9.07 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5896408065366167		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.5896408065366167 | validation: 0.6097103951247673]
	TIME [epoch: 9.07 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5020748883817839		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.5020748883817839 | validation: 0.5630193034113652]
	TIME [epoch: 9.09 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5123012882982282		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.5123012882982282 | validation: 0.44113617647651737]
	TIME [epoch: 9.07 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3486507490239633		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.3486507490239633 | validation: 0.7109536486476201]
	TIME [epoch: 9.07 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45127024483145145		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.45127024483145145 | validation: 0.5209500228143322]
	TIME [epoch: 9.06 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3992620695787071		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.3992620695787071 | validation: 0.45624248229336417]
	TIME [epoch: 9.07 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37145873071798496		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.37145873071798496 | validation: 0.45009597581054606]
	TIME [epoch: 9.08 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3957200562648289		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.3957200562648289 | validation: 0.3913204792902377]
	TIME [epoch: 9.06 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3787533316484481		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.3787533316484481 | validation: 0.4410797402469099]
	TIME [epoch: 9.07 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3995531706312702		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.3995531706312702 | validation: 0.6049284293085357]
	TIME [epoch: 9.07 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4459607573968796		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.4459607573968796 | validation: 0.5005040209069203]
	TIME [epoch: 9.09 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38054206418768094		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.38054206418768094 | validation: 0.45220050093482916]
	TIME [epoch: 9.07 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3599695909966206		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.3599695909966206 | validation: 0.38300986188607056]
	TIME [epoch: 9.06 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37028789087828473		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.37028789087828473 | validation: 0.45716101941590503]
	TIME [epoch: 9.08 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3691434438371003		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.3691434438371003 | validation: 0.3040868436920692]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_213.pth
	Model improved!!!
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35333376816416673		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.35333376816416673 | validation: 0.4517729477197383]
	TIME [epoch: 9.09 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3677561608989424		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.3677561608989424 | validation: 0.5059500592702135]
	TIME [epoch: 9.05 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39018402233290217		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.39018402233290217 | validation: 0.32426237596448626]
	TIME [epoch: 9.06 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39345600956754556		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.39345600956754556 | validation: 0.5412251134846473]
	TIME [epoch: 9.07 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33435696221786004		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.33435696221786004 | validation: 0.2690593279505828]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_218.pth
	Model improved!!!
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3395102700476502		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.3395102700476502 | validation: 0.33380460173687676]
	TIME [epoch: 9.06 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33474339666875763		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.33474339666875763 | validation: 0.31419149269597524]
	TIME [epoch: 9.05 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3908987826534901		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.3908987826534901 | validation: 0.3142800882914908]
	TIME [epoch: 9.05 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3303990049517139		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.3303990049517139 | validation: 0.2684375996489597]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_222.pth
	Model improved!!!
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3239952902412807		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.3239952902412807 | validation: 0.23716325077659434]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_223.pth
	Model improved!!!
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39034594775446324		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.39034594775446324 | validation: 0.24907265965937062]
	TIME [epoch: 9.05 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33608221724750176		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.33608221724750176 | validation: 0.29468707511342085]
	TIME [epoch: 9.06 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31874170392088896		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.31874170392088896 | validation: 0.3908141327628728]
	TIME [epoch: 9.06 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3524670408212338		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.3524670408212338 | validation: 0.38505072324055856]
	TIME [epoch: 9.07 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43006088054711133		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.43006088054711133 | validation: 0.3581837240496284]
	TIME [epoch: 9.07 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.336898275637976		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.336898275637976 | validation: 0.25870364962487263]
	TIME [epoch: 9.04 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734273489578106		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.2734273489578106 | validation: 0.2600360150269031]
	TIME [epoch: 9.05 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3350237898338457		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.3350237898338457 | validation: 0.5674308959419085]
	TIME [epoch: 9.05 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38046855884184405		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.38046855884184405 | validation: 0.30045486196494464]
	TIME [epoch: 9.07 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3278709536981489		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.3278709536981489 | validation: 0.4342851386860829]
	TIME [epoch: 9.06 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3250495820660286		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.3250495820660286 | validation: 0.34689947301675256]
	TIME [epoch: 9.05 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3466089839044081		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.3466089839044081 | validation: 0.3477550384291844]
	TIME [epoch: 9.05 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3211976188052543		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.3211976188052543 | validation: 0.31780008169268514]
	TIME [epoch: 9.06 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34456198607566774		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.34456198607566774 | validation: 0.3391107121335965]
	TIME [epoch: 9.06 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38703721258209856		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.38703721258209856 | validation: 0.31597549773767836]
	TIME [epoch: 9.06 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2591519683420802		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.2591519683420802 | validation: 0.3094946424658853]
	TIME [epoch: 9.06 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3473970593245367		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.3473970593245367 | validation: 0.3368816280798487]
	TIME [epoch: 9.06 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3199315262692023		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.3199315262692023 | validation: 0.26461260385302193]
	TIME [epoch: 9.08 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104223600308271		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.3104223600308271 | validation: 0.5747473371413989]
	TIME [epoch: 9.05 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3767760466557267		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.3767760466557267 | validation: 0.36274275596659433]
	TIME [epoch: 9.06 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40270894677262625		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.40270894677262625 | validation: 0.6164079182286502]
	TIME [epoch: 9.06 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42157133875254854		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.42157133875254854 | validation: 0.4495226625808363]
	TIME [epoch: 9.06 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35545936764356856		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.35545936764356856 | validation: 0.3093030203449808]
	TIME [epoch: 9.08 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32712353066414074		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.32712353066414074 | validation: 0.35511969421227507]
	TIME [epoch: 9.06 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34220167244037414		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.34220167244037414 | validation: 0.2637827962940637]
	TIME [epoch: 9.06 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34463122343689256		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.34463122343689256 | validation: 0.28626946419852195]
	TIME [epoch: 9.05 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3384252600643651		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.3384252600643651 | validation: 0.20950849757923887]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_250.pth
	Model improved!!!
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28446750314506974		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.28446750314506974 | validation: 0.20998260250894504]
	TIME [epoch: 9.08 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3163936744380239		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.3163936744380239 | validation: 0.3944706908119765]
	TIME [epoch: 9.06 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29937033499003796		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.29937033499003796 | validation: 0.2542449381575617]
	TIME [epoch: 9.07 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30966303657331173		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.30966303657331173 | validation: 0.3474892825070235]
	TIME [epoch: 9.06 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40125158248833215		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.40125158248833215 | validation: 0.4381460986796935]
	TIME [epoch: 9.08 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3557634077199068		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.3557634077199068 | validation: 0.3448836556562685]
	TIME [epoch: 9.05 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32558887568229583		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.32558887568229583 | validation: 0.27819565104122423]
	TIME [epoch: 9.05 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.282932689230197		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.282932689230197 | validation: 0.3073113271559036]
	TIME [epoch: 9.06 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31369479280200957		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.31369479280200957 | validation: 0.2700287506338578]
	TIME [epoch: 9.06 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28114462662632056		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.28114462662632056 | validation: 0.3104369433670112]
	TIME [epoch: 9.07 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2784295196077301		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.2784295196077301 | validation: 0.32437276296722467]
	TIME [epoch: 9.06 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30593547265413223		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.30593547265413223 | validation: 0.23446124931092732]
	TIME [epoch: 9.06 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30826303984115266		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.30826303984115266 | validation: 0.22009619292606264]
	TIME [epoch: 9.06 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29319145458936724		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.29319145458936724 | validation: 0.1865308120089223]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_264.pth
	Model improved!!!
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861573101493016		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.2861573101493016 | validation: 0.24903434972897528]
	TIME [epoch: 9.07 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2709766494044007		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.2709766494044007 | validation: 0.21354356896118085]
	TIME [epoch: 9.06 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26205933555103117		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.26205933555103117 | validation: 0.21356069859448287]
	TIME [epoch: 9.06 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3005718049439093		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.3005718049439093 | validation: 0.27310367107555694]
	TIME [epoch: 9.06 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2848370562010893		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.2848370562010893 | validation: 0.3194746176847776]
	TIME [epoch: 9.07 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2562622450831412		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.2562622450831412 | validation: 0.3518142839980438]
	TIME [epoch: 9.05 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3595170515227738		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.3595170515227738 | validation: 0.8800106463573494]
	TIME [epoch: 9.05 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38652578708945035		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.38652578708945035 | validation: 0.16483768362350698]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_272.pth
	Model improved!!!
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25308959077296767		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.25308959077296767 | validation: 0.31907957478361293]
	TIME [epoch: 9.08 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2528931734665326		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.2528931734665326 | validation: 0.2827713934648619]
	TIME [epoch: 9.06 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2416110224245823		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.2416110224245823 | validation: 0.33004770996586946]
	TIME [epoch: 9.05 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2609693290400685		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.2609693290400685 | validation: 0.20788424945043069]
	TIME [epoch: 9.05 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2514492553860984		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.2514492553860984 | validation: 0.29378610517933346]
	TIME [epoch: 9.06 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31885469049173926		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.31885469049173926 | validation: 0.2448165170170074]
	TIME [epoch: 9.09 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3007559407205879		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.3007559407205879 | validation: 0.4541287671951212]
	TIME [epoch: 9.07 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3222268944689555		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.3222268944689555 | validation: 0.36295225401017833]
	TIME [epoch: 9.06 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24461814016346678		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.24461814016346678 | validation: 0.18756764343367816]
	TIME [epoch: 9.05 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2594798990794366		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.2594798990794366 | validation: 0.204808501656975]
	TIME [epoch: 9.06 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22676620619738563		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.22676620619738563 | validation: 0.27343059018239224]
	TIME [epoch: 9.06 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769111323058207		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.2769111323058207 | validation: 0.26337974656154806]
	TIME [epoch: 9.06 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26848120217161		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.26848120217161 | validation: 0.25273943191621506]
	TIME [epoch: 9.04 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2522758301234274		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.2522758301234274 | validation: 0.16982858076856994]
	TIME [epoch: 9.05 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2156984148994459		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.2156984148994459 | validation: 0.24554117856486057]
	TIME [epoch: 9.08 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929878689017609		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.2929878689017609 | validation: 0.2370160995157689]
	TIME [epoch: 9.05 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2591954924045781		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.2591954924045781 | validation: 0.19412491422700986]
	TIME [epoch: 9.06 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2352691984259546		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.2352691984259546 | validation: 0.21256817164567887]
	TIME [epoch: 9.05 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2796829183182374		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.2796829183182374 | validation: 0.20524824785525897]
	TIME [epoch: 9.08 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20469610377140895		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.20469610377140895 | validation: 0.1994099522041563]
	TIME [epoch: 9.09 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2836221967025681		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.2836221967025681 | validation: 0.1840987748641269]
	TIME [epoch: 9.05 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2694909551630372		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.2694909551630372 | validation: 0.23027393833711174]
	TIME [epoch: 9.05 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2185724012597663		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.2185724012597663 | validation: 0.3012612699183698]
	TIME [epoch: 9.05 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2131390606974862		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.2131390606974862 | validation: 0.2595483286242919]
	TIME [epoch: 9.08 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25992561291650373		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.25992561291650373 | validation: 0.20477567608278813]
	TIME [epoch: 9.06 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20598211066764432		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.20598211066764432 | validation: 0.18722098057732356]
	TIME [epoch: 9.06 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21538742066195674		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.21538742066195674 | validation: 0.37881213943478514]
	TIME [epoch: 9.06 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30378749739534106		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.30378749739534106 | validation: 0.7237052136062364]
	TIME [epoch: 9.06 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31354094750112566		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.31354094750112566 | validation: 0.17036819049341984]
	TIME [epoch: 9.09 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933709175912383		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.1933709175912383 | validation: 0.2737712737198861]
	TIME [epoch: 9.05 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27695437725446875		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.27695437725446875 | validation: 0.33403337893835927]
	TIME [epoch: 9.05 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2305698053480766		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.2305698053480766 | validation: 0.18148069864055708]
	TIME [epoch: 9.06 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22898787765982856		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.22898787765982856 | validation: 0.15437315926459522]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2536226148559466		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.2536226148559466 | validation: 0.20017047313438793]
	TIME [epoch: 9.06 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2042171053934687		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.2042171053934687 | validation: 0.2508546781061187]
	TIME [epoch: 9.04 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24077363646905123		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.24077363646905123 | validation: 0.3401180776972441]
	TIME [epoch: 9.04 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24185005460327474		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.24185005460327474 | validation: 0.25270282236166836]
	TIME [epoch: 9.04 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24843611474948984		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.24843611474948984 | validation: 0.23361846729565416]
	TIME [epoch: 9.06 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24521251637002012		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.24521251637002012 | validation: 0.20201937748972507]
	TIME [epoch: 9.04 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711967842781502		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.2711967842781502 | validation: 0.2077631163828178]
	TIME [epoch: 9.04 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23328577232678124		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.23328577232678124 | validation: 0.2851605571484098]
	TIME [epoch: 9.04 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21423506314100535		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.21423506314100535 | validation: 0.251601892579825]
	TIME [epoch: 9.05 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22292999948056838		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.22292999948056838 | validation: 0.2872879503342731]
	TIME [epoch: 9.06 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2348943880648942		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.2348943880648942 | validation: 0.21362057869056122]
	TIME [epoch: 9.05 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18984852058776186		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.18984852058776186 | validation: 0.18475640866205273]
	TIME [epoch: 9.07 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20122278162854945		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.20122278162854945 | validation: 0.19711673654984496]
	TIME [epoch: 9.06 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2119643718700043		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.2119643718700043 | validation: 0.20069172795743995]
	TIME [epoch: 9.09 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19333855368256256		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.19333855368256256 | validation: 0.17629190215386742]
	TIME [epoch: 9.06 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19778257641587943		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.19778257641587943 | validation: 0.3310692182392018]
	TIME [epoch: 9.06 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2357678918840465		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.2357678918840465 | validation: 0.2102034325010061]
	TIME [epoch: 9.04 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20849299247537703		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.20849299247537703 | validation: 0.22462342017071535]
	TIME [epoch: 9.05 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822774848125501		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.2822774848125501 | validation: 0.17075166362964628]
	TIME [epoch: 9.07 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21304326848138685		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.21304326848138685 | validation: 0.15996038687464312]
	TIME [epoch: 9.05 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20893332261620107		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.20893332261620107 | validation: 0.3030142829136848]
	TIME [epoch: 9.05 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2191375890819101		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.2191375890819101 | validation: 0.20265496777541125]
	TIME [epoch: 9.05 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18877150035394089		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.18877150035394089 | validation: 0.25868835349382047]
	TIME [epoch: 9.06 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26204182473661974		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.26204182473661974 | validation: 0.28525430473189906]
	TIME [epoch: 9.05 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20589855016445546		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.20589855016445546 | validation: 0.17284232505681268]
	TIME [epoch: 9.05 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19743138802097518		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.19743138802097518 | validation: 0.19680463696199552]
	TIME [epoch: 9.05 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20956629877474517		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.20956629877474517 | validation: 0.26085568086838495]
	TIME [epoch: 9.05 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24881972326639037		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.24881972326639037 | validation: 0.17781259911028882]
	TIME [epoch: 9.08 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21802996882708828		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.21802996882708828 | validation: 0.19052123226126894]
	TIME [epoch: 9.05 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20817601298202063		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.20817601298202063 | validation: 0.20356682839641782]
	TIME [epoch: 9.05 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22035874172827996		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.22035874172827996 | validation: 0.18884475186071176]
	TIME [epoch: 9.05 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20792282695614533		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.20792282695614533 | validation: 0.6438326539606452]
	TIME [epoch: 9.06 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.341114209588853		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.341114209588853 | validation: 0.14120247364734964]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_338.pth
	Model improved!!!
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19249147664934899		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.19249147664934899 | validation: 0.1858782798126145]
	TIME [epoch: 9.06 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17832485857991295		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.17832485857991295 | validation: 0.19793761523828374]
	TIME [epoch: 9.06 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2046916354860703		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.2046916354860703 | validation: 0.23406624400770307]
	TIME [epoch: 9.04 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20484802692583853		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.20484802692583853 | validation: 0.15180030639944234]
	TIME [epoch: 9.07 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2017445835545511		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.2017445835545511 | validation: 0.18675565332453362]
	TIME [epoch: 9.04 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2502168743922573		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.2502168743922573 | validation: 0.2658830890922107]
	TIME [epoch: 9.07 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19475777950894643		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.19475777950894643 | validation: 0.3066602037447337]
	TIME [epoch: 9.06 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1983296189012244		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.1983296189012244 | validation: 0.1785798889171165]
	TIME [epoch: 9.08 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23365092278005634		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.23365092278005634 | validation: 0.22289424792848272]
	TIME [epoch: 9.08 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18919285142043785		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.18919285142043785 | validation: 0.21634949225450473]
	TIME [epoch: 9.05 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21200832743307663		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.21200832743307663 | validation: 0.13618856896188028]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_349.pth
	Model improved!!!
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19978927802294597		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.19978927802294597 | validation: 0.191824920408166]
	TIME [epoch: 9.07 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1763564900189693		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.1763564900189693 | validation: 0.13448415576404044]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_351.pth
	Model improved!!!
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.187337546857222		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.187337546857222 | validation: 0.17844332153503745]
	TIME [epoch: 9.07 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1754189917368447		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.1754189917368447 | validation: 0.24936184218832735]
	TIME [epoch: 9.06 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22337755183096233		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.22337755183096233 | validation: 0.19965261206687177]
	TIME [epoch: 9.06 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17538707315671231		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.17538707315671231 | validation: 0.13296071207524982]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_355.pth
	Model improved!!!
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22173271108246467		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.22173271108246467 | validation: 0.1814933491081856]
	TIME [epoch: 9.08 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18078337632745		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.18078337632745 | validation: 0.19877698778711084]
	TIME [epoch: 9.08 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20923173389778568		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.20923173389778568 | validation: 0.17006416742297864]
	TIME [epoch: 9.07 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2064057628092472		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.2064057628092472 | validation: 0.21411384500994168]
	TIME [epoch: 9.07 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21952348905626776		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.21952348905626776 | validation: 0.2963704873631765]
	TIME [epoch: 9.08 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19466533102418998		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.19466533102418998 | validation: 0.1502176187259227]
	TIME [epoch: 9.08 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21698231656662686		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.21698231656662686 | validation: 0.19965694072114237]
	TIME [epoch: 9.07 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24442492524225806		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.24442492524225806 | validation: 0.3517291026327077]
	TIME [epoch: 9.07 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2149440212228198		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.2149440212228198 | validation: 0.1701044364106974]
	TIME [epoch: 9.08 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1713254793527055		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.1713254793527055 | validation: 0.1850083136199945]
	TIME [epoch: 9.09 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18370661216174972		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.18370661216174972 | validation: 0.1723118425299041]
	TIME [epoch: 9.08 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2398034431958076		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.2398034431958076 | validation: 0.24711713862490803]
	TIME [epoch: 9.07 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20795958965967526		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.20795958965967526 | validation: 0.15401404857879852]
	TIME [epoch: 9.07 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19201254191264366		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.19201254191264366 | validation: 0.16356482351926688]
	TIME [epoch: 9.07 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16149001880134844		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.16149001880134844 | validation: 0.1753686140750541]
	TIME [epoch: 9.1 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16035313997132597		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.16035313997132597 | validation: 0.137100240069311]
	TIME [epoch: 9.08 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17985587753999047		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.17985587753999047 | validation: 0.1521242818271494]
	TIME [epoch: 9.08 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15309752808699378		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.15309752808699378 | validation: 0.17973019207657642]
	TIME [epoch: 9.08 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17966021944500182		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.17966021944500182 | validation: 0.17831888015491126]
	TIME [epoch: 9.07 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1860106118953592		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.1860106118953592 | validation: 0.18319351273912746]
	TIME [epoch: 9.09 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801424815581961		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.1801424815581961 | validation: 0.16920650014441188]
	TIME [epoch: 9.07 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1678443213698141		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.1678443213698141 | validation: 0.13354863047249033]
	TIME [epoch: 9.07 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16681281162986436		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.16681281162986436 | validation: 0.1567315734614082]
	TIME [epoch: 9.07 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1734283849114939		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.1734283849114939 | validation: 0.16816571842951572]
	TIME [epoch: 9.08 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2262403211370895		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2262403211370895 | validation: 0.19810913367421829]
	TIME [epoch: 9.08 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15683982877011277		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.15683982877011277 | validation: 0.13620358941043556]
	TIME [epoch: 9.07 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16591591327787117		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.16591591327787117 | validation: 0.18795831862767187]
	TIME [epoch: 9.07 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2320112476792086		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.2320112476792086 | validation: 0.17494624070492398]
	TIME [epoch: 9.07 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17389198347548082		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.17389198347548082 | validation: 0.23336491866939876]
	TIME [epoch: 9.1 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17333091850370524		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.17333091850370524 | validation: 0.17742793427853898]
	TIME [epoch: 9.08 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2757884977946251		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.2757884977946251 | validation: 0.20785278489047032]
	TIME [epoch: 9.08 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19471820654013908		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.19471820654013908 | validation: 0.1607401049311914]
	TIME [epoch: 9.07 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18954927836731367		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.18954927836731367 | validation: 0.276660039730682]
	TIME [epoch: 9.08 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18373773654063233		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.18373773654063233 | validation: 0.14277072951372777]
	TIME [epoch: 9.08 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21656298663471843		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.21656298663471843 | validation: 0.19193192464430564]
	TIME [epoch: 9.08 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19084996723205178		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.19084996723205178 | validation: 0.1287227658785638]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_391.pth
	Model improved!!!
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17712382185218298		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.17712382185218298 | validation: 0.15525746028461052]
	TIME [epoch: 9.08 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1819180804501305		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.1819180804501305 | validation: 0.1373090803550437]
	TIME [epoch: 9.1 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17146349032560942		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.17146349032560942 | validation: 0.2001933516418784]
	TIME [epoch: 9.07 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18186804849751265		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.18186804849751265 | validation: 0.24353296235919936]
	TIME [epoch: 9.07 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19355213265291507		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.19355213265291507 | validation: 0.223948244590492]
	TIME [epoch: 9.07 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16068601141635958		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.16068601141635958 | validation: 0.16286006533110237]
	TIME [epoch: 9.08 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22909835847042767		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.22909835847042767 | validation: 0.16588269590090218]
	TIME [epoch: 9.1 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21182498555953516		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.21182498555953516 | validation: 0.16643495756691407]
	TIME [epoch: 9.08 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17063739963494856		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.17063739963494856 | validation: 0.1701746859269586]
	TIME [epoch: 9.07 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19583922457091796		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.19583922457091796 | validation: 0.28999487653483147]
	TIME [epoch: 9.07 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1878056996634317		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.1878056996634317 | validation: 0.1683702386253198]
	TIME [epoch: 9.08 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17253829594050568		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.17253829594050568 | validation: 0.17779481387508195]
	TIME [epoch: 9.09 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16635929542886013		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.16635929542886013 | validation: 0.12950723733108568]
	TIME [epoch: 9.07 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1870529825185725		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.1870529825185725 | validation: 0.15895254383352964]
	TIME [epoch: 9.1 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18595410976154203		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.18595410976154203 | validation: 0.2833208972625607]
	TIME [epoch: 9.07 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17369842438879962		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.17369842438879962 | validation: 0.1312145311360281]
	TIME [epoch: 9.08 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15624375893006356		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.15624375893006356 | validation: 0.1571460369232937]
	TIME [epoch: 9.07 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1449154374368758		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.1449154374368758 | validation: 0.15571080419494301]
	TIME [epoch: 9.06 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.141669012644311		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.141669012644311 | validation: 0.1491968922200388]
	TIME [epoch: 9.07 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18648884571132235		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.18648884571132235 | validation: 0.1487459407106314]
	TIME [epoch: 9.08 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1614755511461446		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.1614755511461446 | validation: 0.15775045401819268]
	TIME [epoch: 9.09 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15375605535584197		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.15375605535584197 | validation: 0.2891840321865712]
	TIME [epoch: 9.07 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19145568821184605		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.19145568821184605 | validation: 0.15613399834806974]
	TIME [epoch: 9.07 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1738747843821432		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.1738747843821432 | validation: 0.1708966780888267]
	TIME [epoch: 9.07 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509773850827395		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.1509773850827395 | validation: 0.13534293776358838]
	TIME [epoch: 9.09 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1561500173228234		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.1561500173228234 | validation: 0.16782485106204303]
	TIME [epoch: 9.07 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16731920304037673		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.16731920304037673 | validation: 0.27353064254872617]
	TIME [epoch: 9.07 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1912845628973509		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.1912845628973509 | validation: 0.1744229058108624]
	TIME [epoch: 9.07 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18688975105066463		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.18688975105066463 | validation: 0.15039190731813853]
	TIME [epoch: 9.07 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15683035198486495		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.15683035198486495 | validation: 0.16154413663101008]
	TIME [epoch: 9.11 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15906442784807587		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.15906442784807587 | validation: 0.1466610645485673]
	TIME [epoch: 9.07 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16310072330005793		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.16310072330005793 | validation: 0.1314864602889076]
	TIME [epoch: 9.08 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17042709736751618		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.17042709736751618 | validation: 0.14767748048268436]
	TIME [epoch: 9.08 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13361980570245993		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.13361980570245993 | validation: 0.15831965994333735]
	TIME [epoch: 9.09 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607677486673917		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.1607677486673917 | validation: 0.15932799771467604]
	TIME [epoch: 9.09 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1522516768641829		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.1522516768641829 | validation: 0.17554278468609913]
	TIME [epoch: 9.08 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16480660260602836		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.16480660260602836 | validation: 0.15628930863224808]
	TIME [epoch: 9.08 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452010500522071		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.1452010500522071 | validation: 0.14814396522145323]
	TIME [epoch: 9.08 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16972723936527936		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.16972723936527936 | validation: 0.12483983680648612]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_430.pth
	Model improved!!!
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13957941836751298		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.13957941836751298 | validation: 0.20964420125063293]
	TIME [epoch: 9.08 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17477700545636937		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.17477700545636937 | validation: 0.13747892824770852]
	TIME [epoch: 9.07 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1412359106752045		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.1412359106752045 | validation: 0.1873990221406694]
	TIME [epoch: 9.08 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1888905261381699		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.1888905261381699 | validation: 0.2081592132214624]
	TIME [epoch: 9.08 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15793251830462968		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.15793251830462968 | validation: 0.14267331001257066]
	TIME [epoch: 9.09 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15010263317596667		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.15010263317596667 | validation: 0.15240053057735709]
	TIME [epoch: 9.08 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13707670860480628		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.13707670860480628 | validation: 0.11893970601647569]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_437.pth
	Model improved!!!
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1436178269128696		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.1436178269128696 | validation: 0.11658368390604133]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_438.pth
	Model improved!!!
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1369990210169155		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.1369990210169155 | validation: 0.12683305315480659]
	TIME [epoch: 9.1 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14458390528840676		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.14458390528840676 | validation: 0.140896853470049]
	TIME [epoch: 9.07 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1470054213138619		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.1470054213138619 | validation: 0.1640371205782984]
	TIME [epoch: 9.07 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.161710429745263		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.161710429745263 | validation: 0.12173281564552524]
	TIME [epoch: 9.07 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16772697280005247		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.16772697280005247 | validation: 0.18857039196529665]
	TIME [epoch: 9.07 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17476566250444847		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.17476566250444847 | validation: 0.1258211577608676]
	TIME [epoch: 9.09 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13161265697692298		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.13161265697692298 | validation: 0.21010594448363965]
	TIME [epoch: 9.07 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1860970879823056		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.1860970879823056 | validation: 0.125105128418734]
	TIME [epoch: 9.07 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1377081693263594		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.1377081693263594 | validation: 0.12915113993139493]
	TIME [epoch: 9.07 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1335698974690407		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.1335698974690407 | validation: 0.12559382910904338]
	TIME [epoch: 9.07 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20713241814625488		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.20713241814625488 | validation: 0.5061759675171437]
	TIME [epoch: 9.09 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21738503633751724		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.21738503633751724 | validation: 0.1394585146060705]
	TIME [epoch: 9.08 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13429718748091746		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.13429718748091746 | validation: 0.1923497871191811]
	TIME [epoch: 9.08 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17102136902801787		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.17102136902801787 | validation: 0.12581330709687094]
	TIME [epoch: 9.07 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1688581921162562		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.1688581921162562 | validation: 0.1299511625001609]
	TIME [epoch: 9.08 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18450649254705537		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.18450649254705537 | validation: 0.32926500908463485]
	TIME [epoch: 9.08 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16328157290980067		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.16328157290980067 | validation: 0.12783994869699383]
	TIME [epoch: 9.07 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12809677672914144		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.12809677672914144 | validation: 0.16395496241451515]
	TIME [epoch: 9.08 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13825374684637853		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.13825374684637853 | validation: 0.13417469401532628]
	TIME [epoch: 9.07 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15842496791549104		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.15842496791549104 | validation: 0.1140424003625479]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_458.pth
	Model improved!!!
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1684761815264239		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.1684761815264239 | validation: 0.17869826038539066]
	TIME [epoch: 9.06 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14714329892912845		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.14714329892912845 | validation: 0.15864744621680027]
	TIME [epoch: 9.05 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17147817402975074		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.17147817402975074 | validation: 0.1395162290512172]
	TIME [epoch: 9.06 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16498637868883453		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.16498637868883453 | validation: 0.14147132926454908]
	TIME [epoch: 9.06 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15693089925623022		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.15693089925623022 | validation: 0.1899661016545054]
	TIME [epoch: 9.08 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12291000158913375		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.12291000158913375 | validation: 0.13175709734089303]
	TIME [epoch: 9.07 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1536503852200251		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.1536503852200251 | validation: 0.12457592127166231]
	TIME [epoch: 9.06 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1396923524115223		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.1396923524115223 | validation: 0.22897107189201957]
	TIME [epoch: 9.06 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15992715509884148		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.15992715509884148 | validation: 0.1405496985285371]
	TIME [epoch: 9.07 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17772602496443415		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.17772602496443415 | validation: 0.16071410721180845]
	TIME [epoch: 9.07 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16712396323530632		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.16712396323530632 | validation: 0.12239619384713496]
	TIME [epoch: 9.07 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13003446584086503		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.13003446584086503 | validation: 0.1315910145374533]
	TIME [epoch: 9.06 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14033933092622683		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.14033933092622683 | validation: 0.120452420338369]
	TIME [epoch: 9.06 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13958480140265173		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.13958480140265173 | validation: 0.16976309847879661]
	TIME [epoch: 9.08 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342254943936534		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.1342254943936534 | validation: 0.1457788950714388]
	TIME [epoch: 9.06 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257450430416513		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.1257450430416513 | validation: 0.1270839822344008]
	TIME [epoch: 9.06 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15103327850918072		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.15103327850918072 | validation: 0.12922634544798656]
	TIME [epoch: 9.05 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13950277152894466		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.13950277152894466 | validation: 0.1377185321728668]
	TIME [epoch: 9.07 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12537487983854373		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.12537487983854373 | validation: 0.13144516052291322]
	TIME [epoch: 9.1 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1424053370545942		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.1424053370545942 | validation: 0.14281099452471513]
	TIME [epoch: 9.06 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13618841958713995		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.13618841958713995 | validation: 0.1570705813009889]
	TIME [epoch: 9.06 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13979872908154764		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.13979872908154764 | validation: 0.11792578546931672]
	TIME [epoch: 9.05 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1483080213017567		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.1483080213017567 | validation: 0.15020542782190832]
	TIME [epoch: 9.07 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15104595059532788		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.15104595059532788 | validation: 0.22328480625751515]
	TIME [epoch: 9.08 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21147873943675646		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.21147873943675646 | validation: 0.2363431620052381]
	TIME [epoch: 9.06 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19023871702851014		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.19023871702851014 | validation: 0.16360422229565164]
	TIME [epoch: 9.07 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12443513062034332		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.12443513062034332 | validation: 0.1383133704312251]
	TIME [epoch: 9.06 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13527126552673624		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.13527126552673624 | validation: 0.13038747458420474]
	TIME [epoch: 9.08 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12165557749224798		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.12165557749224798 | validation: 0.10851382694366203]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_487.pth
	Model improved!!!
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13052391850702139		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.13052391850702139 | validation: 0.11181429552602931]
	TIME [epoch: 9.05 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15760864567565425		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.15760864567565425 | validation: 0.12328444401682674]
	TIME [epoch: 9.06 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12812202477441686		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.12812202477441686 | validation: 0.11979562214990773]
	TIME [epoch: 9.07 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14943472634712363		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.14943472634712363 | validation: 0.1264631272711551]
	TIME [epoch: 9.08 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16569293722269324		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.16569293722269324 | validation: 0.12037717347035126]
	TIME [epoch: 9.06 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12252279507958459		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.12252279507958459 | validation: 0.17047592525021837]
	TIME [epoch: 9.05 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1620392551897596		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.1620392551897596 | validation: 0.11782655064762391]
	TIME [epoch: 9.06 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12892408423048235		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.12892408423048235 | validation: 0.1631332506722513]
	TIME [epoch: 9.08 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17041980183799285		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.17041980183799285 | validation: 0.14824835482645166]
	TIME [epoch: 9.06 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13794593658182208		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.13794593658182208 | validation: 0.1554022748295809]
	TIME [epoch: 9.06 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1474684560190212		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.1474684560190212 | validation: 0.10968333542875096]
	TIME [epoch: 9.05 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1415356133128947		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.1415356133128947 | validation: 0.15368150711098627]
	TIME [epoch: 9.05 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1295417932379174		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.1295417932379174 | validation: 0.13856412183055497]
	TIME [epoch: 9.07 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12697252905561746		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.12697252905561746 | validation: 0.14545959001949438]
	TIME [epoch: 9.05 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12850491274889683		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.12850491274889683 | validation: 0.11947129740642656]
	TIME [epoch: 9.06 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13252915625200123		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.13252915625200123 | validation: 0.2364084603590258]
	TIME [epoch: 9.06 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15865285970748524		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.15865285970748524 | validation: 0.13502094076302967]
	TIME [epoch: 9.06 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1499932369132261		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.1499932369132261 | validation: 0.1369573500629443]
	TIME [epoch: 9.09 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13366061445755467		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.13366061445755467 | validation: 0.13510160805224442]
	TIME [epoch: 9.05 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14722847924662968		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.14722847924662968 | validation: 0.21905110972372538]
	TIME [epoch: 9.06 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16047978302120322		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.16047978302120322 | validation: 0.12663422601756777]
	TIME [epoch: 9.05 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14481128230671858		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.14481128230671858 | validation: 0.1117130709051766]
	TIME [epoch: 9.07 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11697108374991591		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.11697108374991591 | validation: 0.12328017197404023]
	TIME [epoch: 9.06 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12272596953114816		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.12272596953114816 | validation: 0.19195809147067328]
	TIME [epoch: 9.06 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15311367337058435		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.15311367337058435 | validation: 0.09702866369224358]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_512.pth
	Model improved!!!
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12215577857024333		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.12215577857024333 | validation: 0.15423694276195876]
	TIME [epoch: 9.06 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14151375541162287		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.14151375541162287 | validation: 0.14030355307072584]
	TIME [epoch: 9.08 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14306677715903993		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.14306677715903993 | validation: 0.10542566256359578]
	TIME [epoch: 9.07 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12139639586831681		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.12139639586831681 | validation: 0.12885944355146325]
	TIME [epoch: 9.06 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14597595467597957		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.14597595467597957 | validation: 0.15740646990122137]
	TIME [epoch: 9.08 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13414983556281818		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.13414983556281818 | validation: 0.103840916793298]
	TIME [epoch: 9.08 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12239673684523018		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.12239673684523018 | validation: 0.10437292612519827]
	TIME [epoch: 9.08 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.146670372936937		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.146670372936937 | validation: 0.09469548671354514]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_520.pth
	Model improved!!!
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10940407826789682		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.10940407826789682 | validation: 0.14392341863072278]
	TIME [epoch: 9.05 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12672591945566136		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.12672591945566136 | validation: 0.12136510088076445]
	TIME [epoch: 9.06 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12275094621403024		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.12275094621403024 | validation: 0.11547027346642098]
	TIME [epoch: 9.07 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12311663759563088		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.12311663759563088 | validation: 0.12122326990068025]
	TIME [epoch: 9.09 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.126287852041819		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.126287852041819 | validation: 0.12348971008809448]
	TIME [epoch: 9.06 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12520315000010185		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.12520315000010185 | validation: 0.1426269629094573]
	TIME [epoch: 9.05 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13184658672362906		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.13184658672362906 | validation: 0.12290658646144592]
	TIME [epoch: 9.05 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11087112295267157		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.11087112295267157 | validation: 0.14126049227260543]
	TIME [epoch: 9.07 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13328949572469403		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.13328949572469403 | validation: 0.09831740938365247]
	TIME [epoch: 9.06 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1191439658931561		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.1191439658931561 | validation: 0.11529717920226218]
	TIME [epoch: 9.06 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12866528133486677		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.12866528133486677 | validation: 0.22174067594944472]
	TIME [epoch: 9.06 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14796134526883972		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.14796134526883972 | validation: 0.1591561255433845]
	TIME [epoch: 9.06 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11871274227743667		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.11871274227743667 | validation: 0.11452991978897598]
	TIME [epoch: 9.08 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13131831412839623		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.13131831412839623 | validation: 0.10550004485133165]
	TIME [epoch: 9.05 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11808006725322566		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.11808006725322566 | validation: 0.14500427036593957]
	TIME [epoch: 9.06 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13580026096677084		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.13580026096677084 | validation: 0.15208868434581063]
	TIME [epoch: 9.05 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14123363075730846		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.14123363075730846 | validation: 0.11720662947616817]
	TIME [epoch: 9.07 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13408892575860792		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.13408892575860792 | validation: 0.10594725511271147]
	TIME [epoch: 9.07 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13305939821912033		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.13305939821912033 | validation: 0.11066757516287773]
	TIME [epoch: 9.05 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11953447473766057		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.11953447473766057 | validation: 0.13729100837907315]
	TIME [epoch: 9.06 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1323198606212438		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.1323198606212438 | validation: 0.10065708641928263]
	TIME [epoch: 9.06 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10708923309677225		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.10708923309677225 | validation: 0.10836833510738143]
	TIME [epoch: 9.09 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1280839201986544		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.1280839201986544 | validation: 0.11356644633440108]
	TIME [epoch: 9.07 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10706715590108562		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.10706715590108562 | validation: 0.10419281155890855]
	TIME [epoch: 9.07 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11042666904192236		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.11042666904192236 | validation: 0.12619226536807893]
	TIME [epoch: 9.06 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11841307453562014		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.11841307453562014 | validation: 0.11139784330488603]
	TIME [epoch: 9.06 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12161200673483064		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.12161200673483064 | validation: 0.12369511082786169]
	TIME [epoch: 9.08 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13827942233944832		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.13827942233944832 | validation: 0.13729749396020036]
	TIME [epoch: 9.06 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12763753114827286		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.12763753114827286 | validation: 0.09320619366867655]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_549.pth
	Model improved!!!
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1125308735682264		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.1125308735682264 | validation: 0.11025508414125826]
	TIME [epoch: 9.07 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1172172827323283		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.1172172827323283 | validation: 0.10060470573728719]
	TIME [epoch: 9.08 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10924703812740381		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.10924703812740381 | validation: 0.11385338789108529]
	TIME [epoch: 9.06 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09787307151135581		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.09787307151135581 | validation: 0.10498977130397709]
	TIME [epoch: 9.06 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11146197663681626		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.11146197663681626 | validation: 0.10720938303091213]
	TIME [epoch: 9.05 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12447190121067939		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.12447190121067939 | validation: 0.1359080179127065]
	TIME [epoch: 9.07 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12919133090661156		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.12919133090661156 | validation: 0.12948412431666562]
	TIME [epoch: 9.1 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14061173851231262		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.14061173851231262 | validation: 0.156947856288495]
	TIME [epoch: 9.15 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11508384652028933		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.11508384652028933 | validation: 0.20767437851826281]
	TIME [epoch: 9.06 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13826671128466517		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.13826671128466517 | validation: 0.10888245063002351]
	TIME [epoch: 9.04 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11604390814305932		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.11604390814305932 | validation: 0.13055988404591165]
	TIME [epoch: 9.05 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12574974818477175		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.12574974818477175 | validation: 0.13397754129275866]
	TIME [epoch: 9.08 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12096041375878035		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.12096041375878035 | validation: 0.11938512335079957]
	TIME [epoch: 9.06 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12129279711612392		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.12129279711612392 | validation: 0.11352285020283957]
	TIME [epoch: 9.06 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13215023218833524		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.13215023218833524 | validation: 0.12627206935838656]
	TIME [epoch: 9.05 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11707647968732302		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.11707647968732302 | validation: 0.13088714640429244]
	TIME [epoch: 9.07 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10939012376072829		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.10939012376072829 | validation: 0.16101544476593854]
	TIME [epoch: 9.07 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14258711766251836		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.14258711766251836 | validation: 0.11754893657563903]
	TIME [epoch: 9.06 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12138991220431458		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.12138991220431458 | validation: 0.1124793896546134]
	TIME [epoch: 9.07 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11731459320877173		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.11731459320877173 | validation: 0.11761946413967815]
	TIME [epoch: 9.08 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10715617521216618		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.10715617521216618 | validation: 0.10305922305577789]
	TIME [epoch: 9.09 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10719465719309018		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.10719465719309018 | validation: 0.10035472171455065]
	TIME [epoch: 9.07 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1254149204769417		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.1254149204769417 | validation: 0.11114856263264264]
	TIME [epoch: 9.06 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12168139640700937		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.12168139640700937 | validation: 0.11599148144434576]
	TIME [epoch: 9.06 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10110474484802283		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.10110474484802283 | validation: 0.10896966108429552]
	TIME [epoch: 9.06 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13185869741424355		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.13185869741424355 | validation: 0.10026064077402567]
	TIME [epoch: 9.07 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11720693947945941		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.11720693947945941 | validation: 0.11984905930245206]
	TIME [epoch: 9.06 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11207762413790967		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.11207762413790967 | validation: 0.12398625659255616]
	TIME [epoch: 9.06 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12151407065979503		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.12151407065979503 | validation: 0.2001761660514249]
	TIME [epoch: 9.06 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13546044738311075		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.13546044738311075 | validation: 0.09471473091023475]
	TIME [epoch: 9.08 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10917690483278164		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.10917690483278164 | validation: 0.16957130365171086]
	TIME [epoch: 9.06 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13089474046974137		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.13089474046974137 | validation: 0.21520928171337367]
	TIME [epoch: 9.07 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16920045744907414		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.16920045744907414 | validation: 0.10794907772078724]
	TIME [epoch: 9.07 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10316621468795859		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.10316621468795859 | validation: 0.12415080884001733]
	TIME [epoch: 9.07 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12712206930286934		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.12712206930286934 | validation: 0.11819567129458583]
	TIME [epoch: 9.09 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11225766989648614		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.11225766989648614 | validation: 0.14638396725355518]
	TIME [epoch: 9.06 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12980306073927725		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.12980306073927725 | validation: 0.138627397486683]
	TIME [epoch: 9.06 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1221212997380922		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.1221212997380922 | validation: 0.1146660453038949]
	TIME [epoch: 9.05 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11436232258000993		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.11436232258000993 | validation: 0.09928761968983552]
	TIME [epoch: 9.08 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10348606754912064		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.10348606754912064 | validation: 0.12301709729047108]
	TIME [epoch: 9.08 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11727430018236625		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.11727430018236625 | validation: 0.10618929572742553]
	TIME [epoch: 9.06 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11931234592678124		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.11931234592678124 | validation: 0.11966829581718658]
	TIME [epoch: 9.06 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12281360400795874		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.12281360400795874 | validation: 0.131977463807607]
	TIME [epoch: 9.05 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12784399422554713		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.12784399422554713 | validation: 0.11378574308827996]
	TIME [epoch: 9.07 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09681908292166119		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.09681908292166119 | validation: 0.129859952603929]
	TIME [epoch: 9.06 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12686992831241214		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.12686992831241214 | validation: 0.1292489464011141]
	TIME [epoch: 9.06 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12698207177320783		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.12698207177320783 | validation: 0.19907512374679143]
	TIME [epoch: 9.06 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12007479294354384		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.12007479294354384 | validation: 0.09399067773480349]
	TIME [epoch: 9.07 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10652011047542746		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.10652011047542746 | validation: 0.10866369132192831]
	TIME [epoch: 9.08 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11597159372198909		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.11597159372198909 | validation: 0.09804195061634369]
	TIME [epoch: 9.06 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10669210328568021		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.10669210328568021 | validation: 0.10552850794470528]
	TIME [epoch: 9.05 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10894608290723162		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.10894608290723162 | validation: 0.1099636560157474]
	TIME [epoch: 9.06 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1135184612037859		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.1135184612037859 | validation: 0.10011907479391713]
	TIME [epoch: 9.08 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10886794397651907		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.10886794397651907 | validation: 0.08804272079108937]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_603.pth
	Model improved!!!
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1119328233324004		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.1119328233324004 | validation: 0.08810089830302004]
	TIME [epoch: 9.06 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10129077389550545		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.10129077389550545 | validation: 0.10918282076865604]
	TIME [epoch: 9.05 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102001856472258		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.12102001856472258 | validation: 0.10658267655092954]
	TIME [epoch: 9.05 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666641032558193		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.11666641032558193 | validation: 0.11514630722259911]
	TIME [epoch: 9.07 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12026787753008712		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.12026787753008712 | validation: 0.10712071145882482]
	TIME [epoch: 9.05 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10708639737159545		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.10708639737159545 | validation: 0.0931737045608603]
	TIME [epoch: 9.06 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11022999072039633		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.11022999072039633 | validation: 0.10344419659076629]
	TIME [epoch: 9.06 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10069947241477473		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.10069947241477473 | validation: 0.09890875912856445]
	TIME [epoch: 9.08 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10257501490131185		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.10257501490131185 | validation: 0.0883623306891079]
	TIME [epoch: 9.05 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11352537112346159		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.11352537112346159 | validation: 0.10566103192547618]
	TIME [epoch: 9.05 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1069599474386896		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.1069599474386896 | validation: 0.1264114231432557]
	TIME [epoch: 9.05 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11482709995278195		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.11482709995278195 | validation: 0.10081540286302793]
	TIME [epoch: 9.05 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1399851909232897		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.1399851909232897 | validation: 0.10954065945572808]
	TIME [epoch: 9.08 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10481660431340512		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.10481660431340512 | validation: 0.11726726839778848]
	TIME [epoch: 9.06 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09576700368645304		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.09576700368645304 | validation: 0.1199695086596398]
	TIME [epoch: 9.05 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10505490446282761		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.10505490446282761 | validation: 0.10718304763907788]
	TIME [epoch: 9.05 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09869386544515715		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.09869386544515715 | validation: 0.10047633131872633]
	TIME [epoch: 9.05 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10421759444460763		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.10421759444460763 | validation: 0.10566690465336812]
	TIME [epoch: 9.09 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11082229240700026		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.11082229240700026 | validation: 0.0876938017725076]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_622.pth
	Model improved!!!
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09862728567225651		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.09862728567225651 | validation: 0.08699911886040254]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_623.pth
	Model improved!!!
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09458603089071657		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.09458603089071657 | validation: 0.10121856044193253]
	TIME [epoch: 9.05 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09604778265376815		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.09604778265376815 | validation: 0.0963067091418107]
	TIME [epoch: 9.06 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10854999748286742		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.10854999748286742 | validation: 0.1459614955455289]
	TIME [epoch: 9.05 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12005464560224381		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.12005464560224381 | validation: 0.09660638033184366]
	TIME [epoch: 9.05 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10982470803439728		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.10982470803439728 | validation: 0.12458860568830452]
	TIME [epoch: 9.05 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10407389738256345		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.10407389738256345 | validation: 0.10302385686643076]
	TIME [epoch: 9.05 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12433826327998476		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.12433826327998476 | validation: 0.18155008484680718]
	TIME [epoch: 9.07 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10119670394178057		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.10119670394178057 | validation: 0.08696322033821643]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_631.pth
	Model improved!!!
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09909085688917076		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.09909085688917076 | validation: 0.08332388077386245]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_632.pth
	Model improved!!!
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10629344620178963		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.10629344620178963 | validation: 0.11313265554339968]
	TIME [epoch: 9.05 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10096749744282588		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.10096749744282588 | validation: 0.09358853580495644]
	TIME [epoch: 9.05 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0956042266703725		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.0956042266703725 | validation: 0.09495948887337938]
	TIME [epoch: 9.08 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10586966364163039		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.10586966364163039 | validation: 0.0895734991472007]
	TIME [epoch: 9.05 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11627944962090708		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.11627944962090708 | validation: 0.11398228746274996]
	TIME [epoch: 9.05 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10726691481911044		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.10726691481911044 | validation: 0.10860965725498706]
	TIME [epoch: 9.05 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.097308693083202		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.097308693083202 | validation: 0.10667288350449486]
	TIME [epoch: 9.06 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09351327264215982		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.09351327264215982 | validation: 0.10966674038979936]
	TIME [epoch: 9.07 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11653518168261581		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.11653518168261581 | validation: 0.10188944573969454]
	TIME [epoch: 9.04 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11024442976900048		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.11024442976900048 | validation: 0.09391219102568782]
	TIME [epoch: 9.06 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10416805512346312		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.10416805512346312 | validation: 0.10126070783616511]
	TIME [epoch: 9.04 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09339937671548987		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.09339937671548987 | validation: 0.11017745025989771]
	TIME [epoch: 9.13 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10982189832692997		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.10982189832692997 | validation: 0.124201513259836]
	TIME [epoch: 9.05 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11005792318293306		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.11005792318293306 | validation: 0.10752059013174592]
	TIME [epoch: 9.05 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10976568715234011		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.10976568715234011 | validation: 0.10804395403917684]
	TIME [epoch: 9.06 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11124586711355244		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.11124586711355244 | validation: 0.15910759021881082]
	TIME [epoch: 9.05 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10150030759656752		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.10150030759656752 | validation: 0.08766003379240542]
	TIME [epoch: 9.08 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09818473061874286		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.09818473061874286 | validation: 0.11934696987696491]
	TIME [epoch: 9.06 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10403904265085957		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.10403904265085957 | validation: 0.0949628334950447]
	TIME [epoch: 9.05 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10546006427701571		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.10546006427701571 | validation: 0.12221603364602085]
	TIME [epoch: 9.05 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10991082534195078		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.10991082534195078 | validation: 0.0868641429921686]
	TIME [epoch: 9.06 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10925168362582079		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.10925168362582079 | validation: 0.1336878362417831]
	TIME [epoch: 9.06 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10017945847181728		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.10017945847181728 | validation: 0.08789431669890894]
	TIME [epoch: 9.05 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09973323852331155		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.09973323852331155 | validation: 0.1503054298498132]
	TIME [epoch: 9.04 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10246252097520003		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.10246252097520003 | validation: 0.10088975458227135]
	TIME [epoch: 9.04 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10669762939460914		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.10669762939460914 | validation: 0.11045140965036863]
	TIME [epoch: 9.07 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10198291572759585		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.10198291572759585 | validation: 0.10589054828341032]
	TIME [epoch: 9.05 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10108095638208747		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.10108095638208747 | validation: 0.12099549128731898]
	TIME [epoch: 9.05 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09450306972471381		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.09450306972471381 | validation: 0.10353148588761893]
	TIME [epoch: 9.04 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10048904066236324		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.10048904066236324 | validation: 0.10466240047588896]
	TIME [epoch: 9.05 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10687432450975332		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.10687432450975332 | validation: 0.10654873708111118]
	TIME [epoch: 9.07 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.098710194392195		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.098710194392195 | validation: 0.10232089287657942]
	TIME [epoch: 9.04 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10636395356668549		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.10636395356668549 | validation: 0.1306483917895514]
	TIME [epoch: 9.05 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11609274375195897		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.11609274375195897 | validation: 0.14323932711446302]
	TIME [epoch: 9.05 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10029080287973395		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.10029080287973395 | validation: 0.09913410405962436]
	TIME [epoch: 9.06 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08744833818076266		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.08744833818076266 | validation: 0.08852577833029349]
	TIME [epoch: 9.06 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0952243647066843		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.0952243647066843 | validation: 0.09335548801493077]
	TIME [epoch: 9.04 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08999280244356651		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.08999280244356651 | validation: 0.08399784761320839]
	TIME [epoch: 9.05 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09164017690738545		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.09164017690738545 | validation: 0.10316995626816941]
	TIME [epoch: 9.04 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10080727967464398		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.10080727967464398 | validation: 0.104534161287308]
	TIME [epoch: 9.07 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09676473529918958		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.09676473529918958 | validation: 0.08536464566064186]
	TIME [epoch: 9.05 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10290656898205688		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.10290656898205688 | validation: 0.08744594484507857]
	TIME [epoch: 9.05 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10414521947712382		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.10414521947712382 | validation: 0.15901301129386997]
	TIME [epoch: 9.05 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11160430532221766		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.11160430532221766 | validation: 0.1091764492183939]
	TIME [epoch: 9.06 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10335534249037708		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.10335534249037708 | validation: 0.09380015836149186]
	TIME [epoch: 9.06 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09474880929888704		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.09474880929888704 | validation: 0.10246853877239685]
	TIME [epoch: 9.05 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1164498177663027		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.1164498177663027 | validation: 0.11808634422781145]
	TIME [epoch: 9.04 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10918454950149718		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.10918454950149718 | validation: 0.10027168921474362]
	TIME [epoch: 9.05 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743517366235158		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.09743517366235158 | validation: 0.0796481947268873]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_681.pth
	Model improved!!!
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09084481107074655		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.09084481107074655 | validation: 0.09246487195024289]
	TIME [epoch: 9.04 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10035490762384769		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.10035490762384769 | validation: 0.11054058663686826]
	TIME [epoch: 9.05 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11931148482887184		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.11931148482887184 | validation: 0.12744078138646134]
	TIME [epoch: 9.04 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10412613655200778		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.10412613655200778 | validation: 0.12779249567303416]
	TIME [epoch: 9.05 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1004809854512779		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.1004809854512779 | validation: 0.10821474307133339]
	TIME [epoch: 9.07 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10855535100491528		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.10855535100491528 | validation: 0.08826591425722397]
	TIME [epoch: 9.06 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09266571395191255		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.09266571395191255 | validation: 0.09955534392918035]
	TIME [epoch: 9.06 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10582179868026102		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.10582179868026102 | validation: 0.13307779502300535]
	TIME [epoch: 9.05 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12173033958946264		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.12173033958946264 | validation: 0.09837112826177005]
	TIME [epoch: 9.05 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09647800285651272		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.09647800285651272 | validation: 0.10076240181367517]
	TIME [epoch: 9.07 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10064449516074118		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.10064449516074118 | validation: 0.09584805033848642]
	TIME [epoch: 9.05 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09159808183186766		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.09159808183186766 | validation: 0.10271947121508203]
	TIME [epoch: 9.06 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09833302646990152		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.09833302646990152 | validation: 0.10415605311927231]
	TIME [epoch: 9.05 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09167898260927641		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.09167898260927641 | validation: 0.09224387763345007]
	TIME [epoch: 9.07 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10490585963415688		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.10490585963415688 | validation: 0.1251370029891475]
	TIME [epoch: 9.06 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09943154641158661		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.09943154641158661 | validation: 0.11361285231515493]
	TIME [epoch: 9.04 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0992136809269447		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.0992136809269447 | validation: 0.10742904496895211]
	TIME [epoch: 9.05 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09188201715049585		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.09188201715049585 | validation: 0.10869677738230035]
	TIME [epoch: 9.05 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09807184573759985		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.09807184573759985 | validation: 0.10781888761727265]
	TIME [epoch: 9.09 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08698632067507481		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.08698632067507481 | validation: 0.08948806200055093]
	TIME [epoch: 9.06 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09436311734332545		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.09436311734332545 | validation: 0.0945558567399464]
	TIME [epoch: 9.05 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09624940574274224		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.09624940574274224 | validation: 0.08880320817051436]
	TIME [epoch: 9.06 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09985846070704038		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.09985846070704038 | validation: 0.09955413763385956]
	TIME [epoch: 9.05 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08734834666751763		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.08734834666751763 | validation: 0.11445969872871056]
	TIME [epoch: 9.06 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09560146293195552		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.09560146293195552 | validation: 0.1252268287475673]
	TIME [epoch: 9.05 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10440063314516604		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.10440063314516604 | validation: 0.09844813186177775]
	TIME [epoch: 9.05 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10637580842711955		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.10637580842711955 | validation: 0.08966171383202176]
	TIME [epoch: 9.05 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09728001784959545		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.09728001784959545 | validation: 0.09936380788953987]
	TIME [epoch: 9.08 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09006476919468932		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.09006476919468932 | validation: 0.10424845745296643]
	TIME [epoch: 9.05 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09005054047958724		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.09005054047958724 | validation: 0.08773174978837017]
	TIME [epoch: 9.05 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09260699553258622		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.09260699553258622 | validation: 0.09830075439287567]
	TIME [epoch: 9.05 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0881189964651808		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.0881189964651808 | validation: 0.08782111688816922]
	TIME [epoch: 9.08 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08765837208363167		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.08765837208363167 | validation: 0.08832179045101352]
	TIME [epoch: 9.08 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0848416372910136		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.0848416372910136 | validation: 0.0982302595676545]
	TIME [epoch: 9.06 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08834024654270382		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.08834024654270382 | validation: 0.08544005996065568]
	TIME [epoch: 9.06 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09196921883007568		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.09196921883007568 | validation: 0.09528078952661384]
	TIME [epoch: 9.06 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09185235547419847		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.09185235547419847 | validation: 0.10212020586679732]
	TIME [epoch: 9.07 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08945836326832886		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.08945836326832886 | validation: 0.08521612410421361]
	TIME [epoch: 9.05 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09458183464994882		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.09458183464994882 | validation: 0.0934724995803286]
	TIME [epoch: 9.05 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09653536719420952		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.09653536719420952 | validation: 0.13316628347809328]
	TIME [epoch: 9.05 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10327123907143435		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.10327123907143435 | validation: 0.08750069624542095]
	TIME [epoch: 9.06 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08636813603770906		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.08636813603770906 | validation: 0.08806988704756134]
	TIME [epoch: 9.07 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0935786806754578		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.0935786806754578 | validation: 0.08979405413219613]
	TIME [epoch: 9.05 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09193213570418869		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.09193213570418869 | validation: 0.09160656575313639]
	TIME [epoch: 9.05 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10699642900902775		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.10699642900902775 | validation: 0.1050159778495941]
	TIME [epoch: 9.06 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09270907229154096		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.09270907229154096 | validation: 0.09869749381569755]
	TIME [epoch: 9.08 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09768638958036582		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.09768638958036582 | validation: 0.09309714822485798]
	TIME [epoch: 9.07 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832577314385296		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.0832577314385296 | validation: 0.12947068018786062]
	TIME [epoch: 9.06 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10103096628173838		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.10103096628173838 | validation: 0.07819460491542443]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_730.pth
	Model improved!!!
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08636940954493191		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.08636940954493191 | validation: 0.07828239336691636]
	TIME [epoch: 9.06 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08865698933829139		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.08865698933829139 | validation: 0.10238517142456663]
	TIME [epoch: 9.08 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09713316299209762		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.09713316299209762 | validation: 0.10515917358981643]
	TIME [epoch: 9.05 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921210826678646		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.0921210826678646 | validation: 0.08980195083470466]
	TIME [epoch: 9.04 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08821417192870293		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.08821417192870293 | validation: 0.09875955103868125]
	TIME [epoch: 9.05 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09232553942230191		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.09232553942230191 | validation: 0.10490788044534971]
	TIME [epoch: 9.05 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09948964772404616		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.09948964772404616 | validation: 0.10339996777263646]
	TIME [epoch: 9.08 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09257115661906887		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.09257115661906887 | validation: 0.08517017675709637]
	TIME [epoch: 9.05 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.095445707165521		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.095445707165521 | validation: 0.08960084983167976]
	TIME [epoch: 9.07 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0859857101235819		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.0859857101235819 | validation: 0.1141114464296923]
	TIME [epoch: 9.05 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12760496253070905		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.12760496253070905 | validation: 0.09501987688690294]
	TIME [epoch: 9.08 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08557717324359589		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.08557717324359589 | validation: 0.09604223068189116]
	TIME [epoch: 9.06 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08997659991229898		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.08997659991229898 | validation: 0.0948454598323291]
	TIME [epoch: 9.05 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.092031370829982		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.092031370829982 | validation: 0.09094689376116312]
	TIME [epoch: 9.05 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08945073295231473		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.08945073295231473 | validation: 0.08148293156302677]
	TIME [epoch: 9.04 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09288963326552281		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.09288963326552281 | validation: 0.09725212571637454]
	TIME [epoch: 9.08 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09208882416986189		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.09208882416986189 | validation: 0.09186337145548122]
	TIME [epoch: 9.06 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08962519084935405		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.08962519084935405 | validation: 0.11281430776677795]
	TIME [epoch: 9.05 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09795990963573228		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.09795990963573228 | validation: 0.09727053930137988]
	TIME [epoch: 9.06 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08941142006385991		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.08941142006385991 | validation: 0.09892742951768105]
	TIME [epoch: 9.06 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08707354815982354		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.08707354815982354 | validation: 0.0965669344448701]
	TIME [epoch: 9.07 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09762998710856312		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.09762998710856312 | validation: 0.09206139414984518]
	TIME [epoch: 9.04 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08839922880624904		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.08839922880624904 | validation: 0.09170901702959633]
	TIME [epoch: 9.05 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10783498294466738		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.10783498294466738 | validation: 0.09165852233678007]
	TIME [epoch: 9.05 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09341392255418271		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.09341392255418271 | validation: 0.08875963814659205]
	TIME [epoch: 9.07 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08250290800559507		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.08250290800559507 | validation: 0.09230451771257267]
	TIME [epoch: 9.05 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09118105250393571		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.09118105250393571 | validation: 0.0865626349515465]
	TIME [epoch: 9.05 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739721824182464		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.08739721824182464 | validation: 0.09333415537470831]
	TIME [epoch: 9.04 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0824055208068889		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.0824055208068889 | validation: 0.0831396908400323]
	TIME [epoch: 9.06 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09070977799685143		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.09070977799685143 | validation: 0.10070220304752835]
	TIME [epoch: 9.07 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0932541998864119		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.0932541998864119 | validation: 0.10493303135860324]
	TIME [epoch: 9.05 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08857129625962169		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.08857129625962169 | validation: 0.09245579806390587]
	TIME [epoch: 9.06 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11019298454153659		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.11019298454153659 | validation: 0.0970222717873418]
	TIME [epoch: 9.06 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08559674130158985		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.08559674130158985 | validation: 0.09443357430740662]
	TIME [epoch: 9.08 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08457568840907473		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.08457568840907473 | validation: 0.09880416359143188]
	TIME [epoch: 9.06 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08463145866217615		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.08463145866217615 | validation: 0.09815081055656487]
	TIME [epoch: 9.06 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09651026071199831		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.09651026071199831 | validation: 0.08877400340105948]
	TIME [epoch: 9.05 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09087529688339722		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.09087529688339722 | validation: 0.08754329882732183]
	TIME [epoch: 9.05 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10453051016405948		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.10453051016405948 | validation: 0.08080479076751831]
	TIME [epoch: 9.08 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0866041780786828		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.0866041780786828 | validation: 0.10420380058355022]
	TIME [epoch: 9.04 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09433274434536215		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.09433274434536215 | validation: 0.09268001542034116]
	TIME [epoch: 9.05 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08985703429513849		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.08985703429513849 | validation: 0.11072156918246043]
	TIME [epoch: 9.06 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09344353213363503		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.09344353213363503 | validation: 0.09432986716208544]
	TIME [epoch: 9.07 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09698130474976922		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.09698130474976922 | validation: 0.10641501596679807]
	TIME [epoch: 9.08 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09029519336205379		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.09029519336205379 | validation: 0.08103268603473374]
	TIME [epoch: 9.04 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08836974125938638		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.08836974125938638 | validation: 0.10188557550680366]
	TIME [epoch: 9.05 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08614507495870508		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.08614507495870508 | validation: 0.0841405437889757]
	TIME [epoch: 9.04 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08722220721793256		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.08722220721793256 | validation: 0.0921128836932196]
	TIME [epoch: 9.07 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08293461149315316		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.08293461149315316 | validation: 0.11310427375414212]
	TIME [epoch: 9.07 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10941629204141994		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.10941629204141994 | validation: 0.08474352339218058]
	TIME [epoch: 9.07 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08534195389839382		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.08534195389839382 | validation: 0.08861755076724799]
	TIME [epoch: 9.06 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0848964736885109		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.0848964736885109 | validation: 0.0866109782924785]
	TIME [epoch: 9.06 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08800834009810733		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.08800834009810733 | validation: 0.08932933065666537]
	TIME [epoch: 9.08 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08622703834558644		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.08622703834558644 | validation: 0.08419585594120815]
	TIME [epoch: 9.06 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09128866426362821		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.09128866426362821 | validation: 0.07630140953470052]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_785.pth
	Model improved!!!
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08128541258126994		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.08128541258126994 | validation: 0.09049611319898478]
	TIME [epoch: 9.05 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08779706260842975		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.08779706260842975 | validation: 0.10263527687702959]
	TIME [epoch: 9.08 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0945095802441814		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.0945095802441814 | validation: 0.10701466743392475]
	TIME [epoch: 9.04 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1041919617761113		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.1041919617761113 | validation: 0.10999896273704261]
	TIME [epoch: 9.05 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08981649611014461		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.08981649611014461 | validation: 0.10719439771229976]
	TIME [epoch: 9.04 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08914739570010104		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.08914739570010104 | validation: 0.0862965226522607]
	TIME [epoch: 9.04 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08607424012784479		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.08607424012784479 | validation: 0.08414560119220027]
	TIME [epoch: 9.08 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08689820133049649		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.08689820133049649 | validation: 0.09576111226409803]
	TIME [epoch: 9.06 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09096237556109066		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.09096237556109066 | validation: 0.09389226766438658]
	TIME [epoch: 9.04 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08924171804404109		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.08924171804404109 | validation: 0.09664689114371194]
	TIME [epoch: 9.05 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.092094361491325		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.092094361491325 | validation: 0.08464176533503526]
	TIME [epoch: 9.04 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08953913655908742		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.08953913655908742 | validation: 0.0847434237861338]
	TIME [epoch: 9.07 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08113449923522291		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.08113449923522291 | validation: 0.10150615641668068]
	TIME [epoch: 9.04 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10171212468532649		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.10171212468532649 | validation: 0.08766531326487165]
	TIME [epoch: 9.05 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09560845859672647		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.09560845859672647 | validation: 0.11422333388271891]
	TIME [epoch: 9.04 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08796662742010669		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.08796662742010669 | validation: 0.08719316552455961]
	TIME [epoch: 9.05 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09044353754021872		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.09044353754021872 | validation: 0.10171136739597686]
	TIME [epoch: 9.06 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09591411808446963		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.09591411808446963 | validation: 0.08853858688355726]
	TIME [epoch: 9.04 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08397019200632204		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.08397019200632204 | validation: 0.08831026372282774]
	TIME [epoch: 9.03 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832575336296207		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.0832575336296207 | validation: 0.09572608504639066]
	TIME [epoch: 9.04 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10698584367982625		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.10698584367982625 | validation: 0.10004882602172968]
	TIME [epoch: 9.06 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10169559569848477		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.10169559569848477 | validation: 0.11040986594503244]
	TIME [epoch: 9.05 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08468446275089092		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.08468446275089092 | validation: 0.09088304810667719]
	TIME [epoch: 9.04 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08711588774586901		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.08711588774586901 | validation: 0.08958849470976869]
	TIME [epoch: 9.03 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08908453849313977		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.08908453849313977 | validation: 0.0937500469843745]
	TIME [epoch: 9.05 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0850692069473689		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.0850692069473689 | validation: 0.08834798771503467]
	TIME [epoch: 9.06 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08892167483384923		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.08892167483384923 | validation: 0.12198422873271453]
	TIME [epoch: 9.05 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09365662844887163		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.09365662844887163 | validation: 0.09098278839216319]
	TIME [epoch: 9.03 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247691993771532		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.08247691993771532 | validation: 0.08970551257855484]
	TIME [epoch: 9.04 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08206946687866179		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.08206946687866179 | validation: 0.08733875941144095]
	TIME [epoch: 9.06 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08957522084018137		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.08957522084018137 | validation: 0.09402098487360547]
	TIME [epoch: 9.04 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07955209439060792		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.07955209439060792 | validation: 0.08691380029698104]
	TIME [epoch: 9.04 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07811056558948269		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.07811056558948269 | validation: 0.09661942686012354]
	TIME [epoch: 9.04 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08702237735956489		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.08702237735956489 | validation: 0.12990947630771585]
	TIME [epoch: 9.05 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09251449587465474		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.09251449587465474 | validation: 0.08510874051984002]
	TIME [epoch: 9.07 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09523234487136856		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.09523234487136856 | validation: 0.13608043802497674]
	TIME [epoch: 9.05 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.093120028379953		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.093120028379953 | validation: 0.09046496743184533]
	TIME [epoch: 9.04 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08641109214697736		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.08641109214697736 | validation: 0.08561214075407814]
	TIME [epoch: 9.04 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0840426397238037		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.0840426397238037 | validation: 0.09260574683414084]
	TIME [epoch: 9.05 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08872425099614097		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.08872425099614097 | validation: 0.08883961609721089]
	TIME [epoch: 9.05 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08802945132034228		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.08802945132034228 | validation: 0.08566466355174379]
	TIME [epoch: 9.04 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08521420072339998		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.08521420072339998 | validation: 0.07644990147361477]
	TIME [epoch: 9.05 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07960886894259048		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.07960886894259048 | validation: 0.09475009547840836]
	TIME [epoch: 9.07 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.089882424703793		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.089882424703793 | validation: 0.09311830511307287]
	TIME [epoch: 9.06 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08607307315984991		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.08607307315984991 | validation: 0.0985928989237175]
	TIME [epoch: 9.04 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0965221927988941		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.0965221927988941 | validation: 0.08409254411347669]
	TIME [epoch: 9.04 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08494747559235585		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.08494747559235585 | validation: 0.0835895975582564]
	TIME [epoch: 9.05 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09182603432443437		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.09182603432443437 | validation: 0.10058133719405851]
	TIME [epoch: 9.05 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10325282224925189		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.10325282224925189 | validation: 0.09491079348556371]
	TIME [epoch: 9.06 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0857020012450602		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.0857020012450602 | validation: 0.09284944786985827]
	TIME [epoch: 9.04 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08592557898221471		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.08592557898221471 | validation: 0.08726941837560755]
	TIME [epoch: 9.03 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09088337124101463		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.09088337124101463 | validation: 0.0842413796373052]
	TIME [epoch: 9.03 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08813841513525289		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.08813841513525289 | validation: 0.08980748615423606]
	TIME [epoch: 9.06 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08209307273789743		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.08209307273789743 | validation: 0.08655809557306825]
	TIME [epoch: 9.04 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08238446631279281		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.08238446631279281 | validation: 0.09360061177738585]
	TIME [epoch: 9.04 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07812090825808496		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.07812090825808496 | validation: 0.08334127036659414]
	TIME [epoch: 9.03 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08936152577561156		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.08936152577561156 | validation: 0.0930464225451609]
	TIME [epoch: 9.04 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08015032998345181		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.08015032998345181 | validation: 0.10580826942515086]
	TIME [epoch: 9.06 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09591863231113372		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.09591863231113372 | validation: 0.09192742098809004]
	TIME [epoch: 9.04 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08833172193924198		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.08833172193924198 | validation: 0.10042206931611626]
	TIME [epoch: 9.05 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08837501655653886		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.08837501655653886 | validation: 0.09046281412156273]
	TIME [epoch: 9.05 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08705736804366333		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.08705736804366333 | validation: 0.08704966534812184]
	TIME [epoch: 9.07 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656980844090892		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.08656980844090892 | validation: 0.08191311532914392]
	TIME [epoch: 9.05 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08613347105066885		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.08613347105066885 | validation: 0.09744521709107765]
	TIME [epoch: 9.05 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08990704281300452		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.08990704281300452 | validation: 0.103931496561294]
	TIME [epoch: 9.04 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0909280164805703		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.0909280164805703 | validation: 0.0842180171135763]
	TIME [epoch: 9.04 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07865027922662213		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.07865027922662213 | validation: 0.07075970731516033]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_852.pth
	Model improved!!!
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08889841850968783		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.08889841850968783 | validation: 0.07759599868745513]
	TIME [epoch: 9.05 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09028295933500674		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.09028295933500674 | validation: 0.0840288707725419]
	TIME [epoch: 9.03 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08039558872434924		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.08039558872434924 | validation: 0.09930090462843916]
	TIME [epoch: 9.04 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08680512151883978		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.08680512151883978 | validation: 0.08557463106604901]
	TIME [epoch: 9.04 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0803366184396354		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.0803366184396354 | validation: 0.0865050460299582]
	TIME [epoch: 9.05 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07861838424051112		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.07861838424051112 | validation: 0.0878578169051786]
	TIME [epoch: 9.04 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08547859257238734		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.08547859257238734 | validation: 0.0866119944199737]
	TIME [epoch: 9.04 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829258901830103		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.0829258901830103 | validation: 0.08456930134202638]
	TIME [epoch: 9.06 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08706821971438942		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.08706821971438942 | validation: 0.08229468189315664]
	TIME [epoch: 9.06 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07944482725444788		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.07944482725444788 | validation: 0.08758434284752618]
	TIME [epoch: 9.03 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0888806350976478		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.0888806350976478 | validation: 0.09540964773243832]
	TIME [epoch: 9.05 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08523009024389012		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.08523009024389012 | validation: 0.09282914476202828]
	TIME [epoch: 9.03 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09170782281907346		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.09170782281907346 | validation: 0.08370460478908677]
	TIME [epoch: 9.05 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08513574178784974		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.08513574178784974 | validation: 0.09031137885131343]
	TIME [epoch: 9.06 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08511117136498733		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.08511117136498733 | validation: 0.1002905348394596]
	TIME [epoch: 9.04 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09677283538526579		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.09677283538526579 | validation: 0.10151153688636246]
	TIME [epoch: 9.04 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07738600026285165		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.07738600026285165 | validation: 0.0911292919499726]
	TIME [epoch: 9.04 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814645062662415		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.07814645062662415 | validation: 0.08299343894863194]
	TIME [epoch: 9.05 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08506705208363925		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.08506705208363925 | validation: 0.08374380003666948]
	TIME [epoch: 9.06 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08450996837547022		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.08450996837547022 | validation: 0.08119935151401872]
	TIME [epoch: 9.05 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07781632884938362		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.07781632884938362 | validation: 0.09400103505457776]
	TIME [epoch: 9.05 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09329657828021737		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.09329657828021737 | validation: 0.08762898135465846]
	TIME [epoch: 9.04 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0785129655580121		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.0785129655580121 | validation: 0.07940442236100327]
	TIME [epoch: 9.07 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08025732750976364		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.08025732750976364 | validation: 0.07780510426750502]
	TIME [epoch: 9.05 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08187406603348965		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.08187406603348965 | validation: 0.08222962627152783]
	TIME [epoch: 9.04 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08913361584223993		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.08913361584223993 | validation: 0.08070261575048052]
	TIME [epoch: 9.04 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08968181394072833		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.08968181394072833 | validation: 0.07683027099106975]
	TIME [epoch: 9.04 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800020077322913		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.0800020077322913 | validation: 0.08189151006667401]
	TIME [epoch: 9.07 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07817531038122563		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.07817531038122563 | validation: 0.08114311491220222]
	TIME [epoch: 9.05 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08256257514467075		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.08256257514467075 | validation: 0.08014313979250827]
	TIME [epoch: 9.04 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08001162392440236		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.08001162392440236 | validation: 0.08261565927231498]
	TIME [epoch: 9.05 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07641230886266667		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.07641230886266667 | validation: 0.08371623443806078]
	TIME [epoch: 9.06 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08195058210582379		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.08195058210582379 | validation: 0.08988792549368464]
	TIME [epoch: 9.05 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08255612142035364		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.08255612142035364 | validation: 0.08678422125469104]
	TIME [epoch: 9.04 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013461569428108		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.08013461569428108 | validation: 0.09137885844453544]
	TIME [epoch: 9.05 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08156593957889073		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.08156593957889073 | validation: 0.07748948825210544]
	TIME [epoch: 9.04 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158011843332728		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.08158011843332728 | validation: 0.08520965944602187]
	TIME [epoch: 9.06 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08787049957689862		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.08787049957689862 | validation: 0.0827157448714313]
	TIME [epoch: 9.04 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08478946209865726		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.08478946209865726 | validation: 0.06886657319232521]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_891.pth
	Model improved!!!
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08451571804194252		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.08451571804194252 | validation: 0.10501435228749628]
	TIME [epoch: 9.04 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09548964668521086		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.09548964668521086 | validation: 0.09042253704131734]
	TIME [epoch: 9.04 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0826487723467896		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.0826487723467896 | validation: 0.08334894871516993]
	TIME [epoch: 9.05 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08327504271798192		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.08327504271798192 | validation: 0.08625974892310574]
	TIME [epoch: 9.04 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08496006737740103		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.08496006737740103 | validation: 0.08398570003061082]
	TIME [epoch: 9.04 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0880196218940226		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.0880196218940226 | validation: 0.09510527691170162]
	TIME [epoch: 9.04 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08475836642854538		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.08475836642854538 | validation: 0.0875193120045569]
	TIME [epoch: 9.07 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761632177994529		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.0761632177994529 | validation: 0.08422977606930966]
	TIME [epoch: 9.04 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08020073280944787		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.08020073280944787 | validation: 0.08045210560337619]
	TIME [epoch: 9.05 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0788348510695723		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.0788348510695723 | validation: 0.08220702019860028]
	TIME [epoch: 9.05 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07942726626887071		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.07942726626887071 | validation: 0.07982210939113495]
	TIME [epoch: 9.03 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07790894833870851		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.07790894833870851 | validation: 0.08491439540281658]
	TIME [epoch: 9.06 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0840420286203323		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.0840420286203323 | validation: 0.08682749901893391]
	TIME [epoch: 9.04 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0896416355200392		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.0896416355200392 | validation: 0.076762760535509]
	TIME [epoch: 9.04 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08542317892032923		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.08542317892032923 | validation: 0.09019789707115272]
	TIME [epoch: 9.04 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08264004030517709		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.08264004030517709 | validation: 0.07762821996282149]
	TIME [epoch: 9.05 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08237898128656056		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.08237898128656056 | validation: 0.10306771863401143]
	TIME [epoch: 9.07 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0899529918453714		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.0899529918453714 | validation: 0.09758792466811156]
	TIME [epoch: 9.04 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0820958204701874		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.0820958204701874 | validation: 0.08264400247417836]
	TIME [epoch: 9.04 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07862673274089395		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.07862673274089395 | validation: 0.09901686471058369]
	TIME [epoch: 9.05 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07869567165655558		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.07869567165655558 | validation: 0.08503608310529956]
	TIME [epoch: 9.07 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07740352428583425		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.07740352428583425 | validation: 0.08657660854634337]
	TIME [epoch: 9.06 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08223717344367285		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.08223717344367285 | validation: 0.08614538689271004]
	TIME [epoch: 9.05 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07982721962722895		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.07982721962722895 | validation: 0.08438775205402463]
	TIME [epoch: 9.04 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875680696619052		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.07875680696619052 | validation: 0.09225590491802585]
	TIME [epoch: 9.04 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08706880569967115		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.08706880569967115 | validation: 0.09417527068590736]
	TIME [epoch: 9.07 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09393995185355972		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.09393995185355972 | validation: 0.10105498478876951]
	TIME [epoch: 9.05 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0825085310860206		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.0825085310860206 | validation: 0.07461216610753627]
	TIME [epoch: 9.05 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08463967263583314		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.08463967263583314 | validation: 0.08722963689056121]
	TIME [epoch: 9.04 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08258417630729467		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.08258417630729467 | validation: 0.07379707615522621]
	TIME [epoch: 9.06 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08032365008431393		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.08032365008431393 | validation: 0.0818472234256034]
	TIME [epoch: 9.06 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08136832704632783		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.08136832704632783 | validation: 0.09028703228816917]
	TIME [epoch: 9.03 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0825047847743539		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.0825047847743539 | validation: 0.09370598909113856]
	TIME [epoch: 9.05 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08674682021680116		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.08674682021680116 | validation: 0.08026607516542143]
	TIME [epoch: 9.05 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08304886336532999		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.08304886336532999 | validation: 0.07880894406800332]
	TIME [epoch: 9.08 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08452899465347541		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.08452899465347541 | validation: 0.08220367963305636]
	TIME [epoch: 9.05 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064369815854817		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.08064369815854817 | validation: 0.0820632405680585]
	TIME [epoch: 9.05 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08408545553749383		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.08408545553749383 | validation: 0.07987811805758394]
	TIME [epoch: 9.05 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08507863470622917		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.08507863470622917 | validation: 0.0868678364914926]
	TIME [epoch: 9.05 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08480036753993263		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.08480036753993263 | validation: 0.08578641525904177]
	TIME [epoch: 9.06 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08445833250146245		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.08445833250146245 | validation: 0.08049351508988983]
	TIME [epoch: 9.05 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0828396961444251		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.0828396961444251 | validation: 0.0895305076948576]
	TIME [epoch: 9.05 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08939174010343666		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.08939174010343666 | validation: 0.09355770928026969]
	TIME [epoch: 9.05 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08501893649522167		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.08501893649522167 | validation: 0.08135384948777828]
	TIME [epoch: 9.06 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08567973408371723		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.08567973408371723 | validation: 0.08496815856325464]
	TIME [epoch: 9.05 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08315133864171471		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.08315133864171471 | validation: 0.08767090024641641]
	TIME [epoch: 9.06 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07880476259121214		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.07880476259121214 | validation: 0.0780700788893656]
	TIME [epoch: 9.05 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07708885916925795		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.07708885916925795 | validation: 0.080892584683659]
	TIME [epoch: 9.06 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08316057391764539		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.08316057391764539 | validation: 0.09365780742867545]
	TIME [epoch: 9.08 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656673822206407		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.07656673822206407 | validation: 0.09111301267096775]
	TIME [epoch: 9.06 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08438536457518842		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.08438536457518842 | validation: 0.07640147015109905]
	TIME [epoch: 9.06 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07366607330535416		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.07366607330535416 | validation: 0.08772510902282674]
	TIME [epoch: 9.05 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07933105723776031		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.07933105723776031 | validation: 0.08405988219922317]
	TIME [epoch: 9.08 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07823086821862327		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.07823086821862327 | validation: 0.07423584079377618]
	TIME [epoch: 9.16 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08068855994463416		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.08068855994463416 | validation: 0.0829435851155838]
	TIME [epoch: 9.04 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775342511833334		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.0775342511833334 | validation: 0.0813029687453547]
	TIME [epoch: 9.04 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07731830788120084		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.07731830788120084 | validation: 0.08174825453488027]
	TIME [epoch: 9.04 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07714000139755398		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.07714000139755398 | validation: 0.09067393143947479]
	TIME [epoch: 9.06 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07758290546694244		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.07758290546694244 | validation: 0.08501530255014675]
	TIME [epoch: 9.05 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07633981043053464		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.07633981043053464 | validation: 0.09069956230543541]
	TIME [epoch: 9.05 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07804491926004473		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.07804491926004473 | validation: 0.08669545451245114]
	TIME [epoch: 9.06 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08646834189952948		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.08646834189952948 | validation: 0.07815754329134485]
	TIME [epoch: 9.06 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07849097990414537		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.07849097990414537 | validation: 0.09099087702187839]
	TIME [epoch: 9.06 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08153844129129803		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.08153844129129803 | validation: 0.08599717687405312]
	TIME [epoch: 9.04 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07803957956866293		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.07803957956866293 | validation: 0.07299129467915783]
	TIME [epoch: 9.03 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08119160238320385		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.08119160238320385 | validation: 0.06958598023149162]
	TIME [epoch: 9.05 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07619197767558508		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.07619197767558508 | validation: 0.08833089829527119]
	TIME [epoch: 9.08 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07903728220057035		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.07903728220057035 | validation: 0.07568790329926936]
	TIME [epoch: 9.05 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08434926334909972		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.08434926334909972 | validation: 0.08620646339206495]
	TIME [epoch: 9.04 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07451347564079577		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.07451347564079577 | validation: 0.0839080599463756]
	TIME [epoch: 9.04 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07810607404179139		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.07810607404179139 | validation: 0.07953456561754424]
	TIME [epoch: 9.06 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0820076444659221		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.0820076444659221 | validation: 0.08059200362253262]
	TIME [epoch: 9.06 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0851445413638449		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.0851445413638449 | validation: 0.09063446497391563]
	TIME [epoch: 9.05 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08965011889588514		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.08965011889588514 | validation: 0.0838886225327776]
	TIME [epoch: 9.06 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08750496012773047		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.08750496012773047 | validation: 0.07955684198161295]
	TIME [epoch: 9.04 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08532293703279295		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.08532293703279295 | validation: 0.09295724060234314]
	TIME [epoch: 9.07 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09476880129105132		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.09476880129105132 | validation: 0.09271026955465579]
	TIME [epoch: 9.05 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08169601804437783		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.08169601804437783 | validation: 0.09299922980471652]
	TIME [epoch: 9.05 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07783101059252193		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.07783101059252193 | validation: 0.07269041100978066]
	TIME [epoch: 9.04 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829083505916151		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.0829083505916151 | validation: 0.08867354358249764]
	TIME [epoch: 9.05 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07778908694816389		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.07778908694816389 | validation: 0.09234677235535146]
	TIME [epoch: 9.07 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08260102272865778		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.08260102272865778 | validation: 0.09271177269648795]
	TIME [epoch: 9.04 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08354743577410088		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.08354743577410088 | validation: 0.08642289806855721]
	TIME [epoch: 9.04 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08004297989150513		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.08004297989150513 | validation: 0.08557638756345212]
	TIME [epoch: 9.04 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08134417277707622		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.08134417277707622 | validation: 0.08757816953648573]
	TIME [epoch: 9.05 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08481312144543393		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.08481312144543393 | validation: 0.080177314981381]
	TIME [epoch: 9.07 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07851667215017703		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.07851667215017703 | validation: 0.08596392846859657]
	TIME [epoch: 9.06 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07840031641517353		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.07840031641517353 | validation: 0.07679688910874309]
	TIME [epoch: 9.06 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0801339702458487		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.0801339702458487 | validation: 0.09325425906875351]
	TIME [epoch: 9.06 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08182847489697413		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.08182847489697413 | validation: 0.0818147718630158]
	TIME [epoch: 9.06 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07590407867170797		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.07590407867170797 | validation: 0.07996894070023874]
	TIME [epoch: 9.04 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08008668020197322		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.08008668020197322 | validation: 0.0772061022109193]
	TIME [epoch: 9.05 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07931659597792347		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.07931659597792347 | validation: 0.08508219786816842]
	TIME [epoch: 9.05 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08277592526565947		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.08277592526565947 | validation: 0.0861122492746933]
	TIME [epoch: 9.06 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07832859721471128		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.07832859721471128 | validation: 0.09017978075678129]
	TIME [epoch: 9.07 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08413607459918451		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.08413607459918451 | validation: 0.06080113518376525]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r3_20240217_161441/states/model_tr_study4_987.pth
	Model improved!!!
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07496354281453661		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.07496354281453661 | validation: 0.08185017640913612]
	TIME [epoch: 9.05 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08628136179963167		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.08628136179963167 | validation: 0.09112720491193407]
	TIME [epoch: 9.04 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08116641035595072		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.08116641035595072 | validation: 0.08274510671623915]
	TIME [epoch: 9.08 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08137119773469992		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.08137119773469992 | validation: 0.07245312184365461]
	TIME [epoch: 9.06 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08046888832654805		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.08046888832654805 | validation: 0.08232063273570357]
	TIME [epoch: 9.05 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07914279760356767		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.07914279760356767 | validation: 0.07549770528939716]
	TIME [epoch: 9.04 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08154830585184396		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.08154830585184396 | validation: 0.08506192286129854]
	TIME [epoch: 9.04 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08061249576573029		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.08061249576573029 | validation: 0.0799095730904687]
	TIME [epoch: 9.06 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08267619087526693		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.08267619087526693 | validation: 0.07242685669006846]
	TIME [epoch: 9.04 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07508894476661518		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.07508894476661518 | validation: 0.07230449990302396]
	TIME [epoch: 9.03 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08076343282235157		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.08076343282235157 | validation: 0.0823237198975772]
	TIME [epoch: 9.04 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08844804418856403		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.08844804418856403 | validation: 0.08834502451953309]
	TIME [epoch: 9.03 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08242598064372424		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.08242598064372424 | validation: 0.07536480231361162]
	TIME [epoch: 9.06 sec]
Finished training in 9168.135 seconds.
