Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2712901357

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.455376386341118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.455376386341118 | validation: 9.137486062646204]
	TIME [epoch: 71.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.358344209074632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.358344209074632 | validation: 8.07390255647826]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.391829675620758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.391829675620758 | validation: 6.1009237732836485]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.464171506055145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.464171506055145 | validation: 5.341194450975772]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.791928580531586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.791928580531586 | validation: 5.5485055822204306]
	TIME [epoch: 9.12 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.426268290455535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.426268290455535 | validation: 9.18031052794663]
	TIME [epoch: 9.11 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.274161973840325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.274161973840325 | validation: 5.281136718338977]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.244370312127733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.244370312127733 | validation: 5.03952470463238]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.261479765685532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.261479765685532 | validation: 4.775893322944402]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.7535684608800834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7535684608800834 | validation: 4.955863857038337]
	TIME [epoch: 9.12 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.908900290766833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.908900290766833 | validation: 6.505115445707961]
	TIME [epoch: 9.11 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.021017612233061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.021017612233061 | validation: 7.257319027127359]
	TIME [epoch: 9.11 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.337085397350615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.337085397350615 | validation: 4.854780757961249]
	TIME [epoch: 9.11 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.4874344179377728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4874344179377728 | validation: 3.921644962478831]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.780303883451464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.780303883451464 | validation: 6.518352603944875]
	TIME [epoch: 9.12 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.137704593189544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.137704593189544 | validation: 4.679176257082336]
	TIME [epoch: 9.13 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.487103177813961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.487103177813961 | validation: 4.592533520284866]
	TIME [epoch: 9.15 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.1748424511597255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1748424511597255 | validation: 5.248826636128561]
	TIME [epoch: 9.12 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.130394838204576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.130394838204576 | validation: 7.949482847119921]
	TIME [epoch: 9.12 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.317294479417083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.317294479417083 | validation: 4.662034866922085]
	TIME [epoch: 9.12 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.4686130221422555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4686130221422555 | validation: 4.14579424802652]
	TIME [epoch: 9.13 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.528477196140537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.528477196140537 | validation: 5.957426097073894]
	TIME [epoch: 9.12 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.61708188668212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.61708188668212 | validation: 6.62054897732136]
	TIME [epoch: 9.11 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.453625546967747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.453625546967747 | validation: 7.0964032907098336]
	TIME [epoch: 9.1 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.665060375055447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.665060375055447 | validation: 6.485524978555446]
	TIME [epoch: 9.1 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.644673715736365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.644673715736365 | validation: 3.809876813685075]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.9649579591030406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9649579591030406 | validation: 3.5985624950496544]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.0099071161679714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0099071161679714 | validation: 4.156193935261616]
	TIME [epoch: 9.1 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3140375816431886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3140375816431886 | validation: 3.353585662403926]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.084112340171938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.084112340171938 | validation: 5.189449882628908]
	TIME [epoch: 9.12 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.4839731992825556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4839731992825556 | validation: 3.904066860581339]
	TIME [epoch: 9.11 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.192510871570918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.192510871570918 | validation: 4.06823606700244]
	TIME [epoch: 9.09 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2868580403798724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2868580403798724 | validation: 3.834733954510549]
	TIME [epoch: 9.09 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.9073582996527563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9073582996527563 | validation: 3.5884317024261185]
	TIME [epoch: 9.1 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.90655584554285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.90655584554285 | validation: 3.43789722415217]
	TIME [epoch: 9.12 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2393358297463193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2393358297463193 | validation: 5.28573215097655]
	TIME [epoch: 9.11 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.45057460640619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.45057460640619 | validation: 3.2101609622042058]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.236777236400089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.236777236400089 | validation: 5.379143985284085]
	TIME [epoch: 9.4 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3803067937215525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3803067937215525 | validation: 3.3120020099405365]
	TIME [epoch: 9.13 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.746253593972479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.746253593972479 | validation: 3.5325969155145236]
	TIME [epoch: 9.12 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.676987130253898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.676987130253898 | validation: 3.5636842083752605]
	TIME [epoch: 9.12 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.8309567277163956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8309567277163956 | validation: 4.518661801162409]
	TIME [epoch: 9.11 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3577360782568086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3577360782568086 | validation: 3.5134010193822105]
	TIME [epoch: 9.12 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.8330749291568837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8330749291568837 | validation: 4.042475817520674]
	TIME [epoch: 9.13 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.5930093111010413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5930093111010413 | validation: 3.8985725725993197]
	TIME [epoch: 9.11 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.1464197932141262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1464197932141262 | validation: 3.6137193079978545]
	TIME [epoch: 9.12 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2009872669859893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2009872669859893 | validation: 3.9675136453556457]
	TIME [epoch: 9.11 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.1926747337769337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1926747337769337 | validation: 3.609601948668688]
	TIME [epoch: 9.11 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.888248872984371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.888248872984371 | validation: 3.202209508689651]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.0076123365975134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0076123365975134 | validation: 3.124436215462012]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.84525068360463		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 2.84525068360463 | validation: 2.984716048693967]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3163960285149354		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.3163960285149354 | validation: 2.901909837466782]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.8183987527912264		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.8183987527912264 | validation: 3.119094090707799]
	TIME [epoch: 9.13 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.6379496385837786		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.6379496385837786 | validation: 3.238855860802704]
	TIME [epoch: 9.12 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5330564176345782		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.5330564176345782 | validation: 2.9770909503163283]
	TIME [epoch: 9.12 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.206422604911443		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.206422604911443 | validation: 2.003202531082037]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3697960097674478		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.3697960097674478 | validation: 1.265259797583526]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1117721313126687		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.1117721313126687 | validation: 0.7550007747090368]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.914408503917801		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.914408503917801 | validation: 0.7757739075592953]
	TIME [epoch: 9.12 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8018553250267241		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.8018553250267241 | validation: 0.701461174458357]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7068104106062281		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 0.7068104106062281 | validation: 0.603819856157892]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6683408861985756		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 0.6683408861985756 | validation: 0.6897650982531396]
	TIME [epoch: 9.13 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8329466318054131		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.8329466318054131 | validation: 0.8014741583419047]
	TIME [epoch: 9.1 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6558930733175782		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 0.6558930733175782 | validation: 0.6917473197721111]
	TIME [epoch: 9.09 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8652586548703607		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.8652586548703607 | validation: 0.7083424897730817]
	TIME [epoch: 9.09 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6789212307338297		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.6789212307338297 | validation: 0.7708407068629786]
	TIME [epoch: 9.1 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6695450418712635		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 0.6695450418712635 | validation: 0.6136404532917896]
	TIME [epoch: 9.12 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7485687670563671		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 0.7485687670563671 | validation: 0.6403121992730891]
	TIME [epoch: 9.11 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7222852371019125		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.7222852371019125 | validation: 0.6005909700779852]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_69.pth
	Model improved!!!
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7215340067144315		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.7215340067144315 | validation: 1.1843974623293874]
	TIME [epoch: 9.11 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7835378167360273		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.7835378167360273 | validation: 0.6431971469649546]
	TIME [epoch: 9.12 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824805657259843		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.5824805657259843 | validation: 1.2173670222030264]
	TIME [epoch: 9.11 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6620405568813561		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.6620405568813561 | validation: 0.4050753612876141]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.538271795043306		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.538271795043306 | validation: 0.5236692102558685]
	TIME [epoch: 9.1 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6271153241402336		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.6271153241402336 | validation: 0.5380733466105976]
	TIME [epoch: 9.1 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7095172977595172		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.7095172977595172 | validation: 0.6077422427733126]
	TIME [epoch: 9.12 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9501475158566961		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.9501475158566961 | validation: 0.5029078014624605]
	TIME [epoch: 9.1 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0080535680435176		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.0080535680435176 | validation: 0.7826108173135584]
	TIME [epoch: 9.1 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5823700219379145		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.5823700219379145 | validation: 0.5955273893875815]
	TIME [epoch: 9.1 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6439061970065204		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.6439061970065204 | validation: 0.4193278678436229]
	TIME [epoch: 9.13 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7684028398028401		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.7684028398028401 | validation: 0.9368395001937907]
	TIME [epoch: 9.11 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7192549890547791		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.7192549890547791 | validation: 0.4373540856336406]
	TIME [epoch: 9.11 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6727915694309023		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.6727915694309023 | validation: 0.7401917765610422]
	TIME [epoch: 9.11 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6035769164765105		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.6035769164765105 | validation: 0.7557381832373673]
	TIME [epoch: 9.1 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6493916754339532		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.6493916754339532 | validation: 0.6032425748654338]
	TIME [epoch: 9.13 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7016584727867028		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.7016584727867028 | validation: 0.6920095965534541]
	TIME [epoch: 9.11 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.649069252811718		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.649069252811718 | validation: 0.4938591362363596]
	TIME [epoch: 9.1 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.728570233609088		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.728570233609088 | validation: 0.8870169239611134]
	TIME [epoch: 9.11 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6379528934072476		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.6379528934072476 | validation: 1.1923525506293662]
	TIME [epoch: 9.12 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7541199268091348		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.7541199268091348 | validation: 0.6605287773077918]
	TIME [epoch: 9.11 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5880153933400926		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.5880153933400926 | validation: 0.5783723588196943]
	TIME [epoch: 9.1 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6718430002629832		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.6718430002629832 | validation: 0.5220877473007421]
	TIME [epoch: 9.11 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7224618628067552		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.7224618628067552 | validation: 1.5272336776811728]
	TIME [epoch: 9.12 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7261153394910677		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.7261153394910677 | validation: 0.7417685704780128]
	TIME [epoch: 9.13 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5412584803122958		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.5412584803122958 | validation: 0.47790085913640934]
	TIME [epoch: 9.12 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.008229857637858		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.008229857637858 | validation: 0.5235542178535957]
	TIME [epoch: 9.11 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4943735570885943		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.4943735570885943 | validation: 0.4593092908260926]
	TIME [epoch: 9.11 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5793359437241691		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.5793359437241691 | validation: 0.45066077553058825]
	TIME [epoch: 9.11 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.513271786417981		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.513271786417981 | validation: 0.4784206557148852]
	TIME [epoch: 9.12 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5554858566288189		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.5554858566288189 | validation: 0.5851691767539056]
	TIME [epoch: 9.11 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5374420342756496		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.5374420342756496 | validation: 0.5556914967439304]
	TIME [epoch: 9.1 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7930445849791267		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.7930445849791267 | validation: 0.63723629956402]
	TIME [epoch: 9.1 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4375545717040274		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.4375545717040274 | validation: 0.5615873401371738]
	TIME [epoch: 9.12 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5473669648492596		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.5473669648492596 | validation: 0.49888412801178506]
	TIME [epoch: 9.11 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5173035667691096		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.5173035667691096 | validation: 0.3850433621450363]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4874778516661501		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.4874778516661501 | validation: 0.46208030114747656]
	TIME [epoch: 9.11 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49798978205674527		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.49798978205674527 | validation: 0.5521885273258813]
	TIME [epoch: 9.1 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.820909396160767		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.820909396160767 | validation: 0.48063044576463143]
	TIME [epoch: 9.13 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5298843547511192		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5298843547511192 | validation: 0.466546411579159]
	TIME [epoch: 9.1 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5896049741380489		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.5896049741380489 | validation: 0.3882513141807288]
	TIME [epoch: 9.1 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5287041559309129		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.5287041559309129 | validation: 0.47665545021352407]
	TIME [epoch: 9.1 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5360194295794134		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.5360194295794134 | validation: 0.3279309608650872]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41189902319842425		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.41189902319842425 | validation: 0.35406383359117094]
	TIME [epoch: 9.11 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5205284334041224		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.5205284334041224 | validation: 0.388056891253499]
	TIME [epoch: 9.09 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.482974805500797		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.482974805500797 | validation: 0.3572263572338179]
	TIME [epoch: 9.09 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5459532853694338		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5459532853694338 | validation: 0.6187646204013257]
	TIME [epoch: 9.1 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4459415878092881		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.4459415878092881 | validation: 0.31880160928506035]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_117.pth
	Model improved!!!
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5820180889704741		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.5820180889704741 | validation: 0.7969979078093314]
	TIME [epoch: 9.11 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4690570321109875		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.4690570321109875 | validation: 0.43392079684491436]
	TIME [epoch: 9.12 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4806729542353877		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.4806729542353877 | validation: 0.9221547788342126]
	TIME [epoch: 9.11 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5897574697593975		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.5897574697593975 | validation: 0.545033038667838]
	TIME [epoch: 9.13 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47715100859109105		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.47715100859109105 | validation: 0.39925233799411586]
	TIME [epoch: 9.12 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4963585867288261		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.4963585867288261 | validation: 0.49755390234546704]
	TIME [epoch: 9.11 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4645718716717903		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.4645718716717903 | validation: 0.6199520342771222]
	TIME [epoch: 9.1 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5567889145344125		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.5567889145344125 | validation: 0.9301578285394005]
	TIME [epoch: 9.1 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46134025497255376		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.46134025497255376 | validation: 0.4215798197581537]
	TIME [epoch: 9.12 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4411168928891553		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.4411168928891553 | validation: 0.6932367076302546]
	TIME [epoch: 9.11 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5418737854173286		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5418737854173286 | validation: 0.5161165351084545]
	TIME [epoch: 9.11 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46201603653675455		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.46201603653675455 | validation: 0.3667973489674808]
	TIME [epoch: 9.11 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4511979378196703		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.4511979378196703 | validation: 0.712878323459555]
	TIME [epoch: 9.12 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.440094655884523		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.440094655884523 | validation: 0.35221518992924983]
	TIME [epoch: 9.11 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42678212724035125		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.42678212724035125 | validation: 0.34327520278234447]
	TIME [epoch: 9.1 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4450359562356314		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.4450359562356314 | validation: 0.358556052149661]
	TIME [epoch: 9.11 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5426340210619662		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.5426340210619662 | validation: 0.43666271208187696]
	TIME [epoch: 9.11 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4682837883276448		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.4682837883276448 | validation: 0.423801984071365]
	TIME [epoch: 9.12 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4183191777008493		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.4183191777008493 | validation: 0.6713046500163099]
	TIME [epoch: 9.1 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4511532053202136		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.4511532053202136 | validation: 0.4719859406237964]
	TIME [epoch: 9.1 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5524799904341251		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.5524799904341251 | validation: 0.6499690658894515]
	TIME [epoch: 9.1 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45605684526819046		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.45605684526819046 | validation: 0.416059337383923]
	TIME [epoch: 9.11 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41645432869029886		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.41645432869029886 | validation: 0.6497086540480761]
	TIME [epoch: 9.12 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5563188998404861		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.5563188998404861 | validation: 0.6561304183233045]
	TIME [epoch: 9.11 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.523641255792882		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.523641255792882 | validation: 0.43214297784268113]
	TIME [epoch: 9.1 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38273379419327763		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.38273379419327763 | validation: 0.327361237066779]
	TIME [epoch: 9.1 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44126128107559304		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.44126128107559304 | validation: 0.2975934663490959]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_144.pth
	Model improved!!!
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41426707231636756		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.41426707231636756 | validation: 0.6152512463681669]
	TIME [epoch: 9.11 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5032527936902659		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.5032527936902659 | validation: 0.533780129276789]
	TIME [epoch: 9.12 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44565961964809225		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.44565961964809225 | validation: 0.39882156189695833]
	TIME [epoch: 9.11 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43164520301857373		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.43164520301857373 | validation: 0.4007728910119748]
	TIME [epoch: 9.11 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38732443891422336		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.38732443891422336 | validation: 0.39301945443181463]
	TIME [epoch: 9.13 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.397377930526044		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.397377930526044 | validation: 0.3724841379546403]
	TIME [epoch: 9.1 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42507423456562315		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.42507423456562315 | validation: 0.3266737353697712]
	TIME [epoch: 9.11 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4552173244093667		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.4552173244093667 | validation: 0.3102477221751865]
	TIME [epoch: 9.11 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.384754699316025		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.384754699316025 | validation: 0.3464564647569246]
	TIME [epoch: 9.12 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.384164466253317		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.384164466253317 | validation: 0.2938388654791514]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_154.pth
	Model improved!!!
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4633613708734824		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.4633613708734824 | validation: 0.3957794799322687]
	TIME [epoch: 9.1 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4564511379543812		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.4564511379543812 | validation: 0.343093993748703]
	TIME [epoch: 9.1 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42533655578942015		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.42533655578942015 | validation: 0.3870827310997351]
	TIME [epoch: 9.09 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4396342623700241		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.4396342623700241 | validation: 0.34202661463296213]
	TIME [epoch: 9.13 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3951769507679729		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.3951769507679729 | validation: 0.31973697418807073]
	TIME [epoch: 9.11 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4143089156224363		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.4143089156224363 | validation: 0.3409628768277101]
	TIME [epoch: 9.11 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5061021443263687		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.5061021443263687 | validation: 0.5057975682972702]
	TIME [epoch: 9.1 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4509708700730989		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.4509708700730989 | validation: 0.394559771962468]
	TIME [epoch: 9.11 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34109151144550043		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.34109151144550043 | validation: 0.37473860912876783]
	TIME [epoch: 9.12 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3597007916591276		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.3597007916591276 | validation: 0.34554968228660576]
	TIME [epoch: 9.11 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47738809383690084		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.47738809383690084 | validation: 0.3883518037931438]
	TIME [epoch: 9.11 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.427035545739173		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.427035545739173 | validation: 0.3459219252356846]
	TIME [epoch: 9.11 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4662361737433541		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.4662361737433541 | validation: 0.3851938276476948]
	TIME [epoch: 9.13 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3682728026663519		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.3682728026663519 | validation: 0.40318910456291]
	TIME [epoch: 9.1 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3518412720444512		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.3518412720444512 | validation: 0.2826809271896753]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_169.pth
	Model improved!!!
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3037043617191125		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.3037043617191125 | validation: 0.31405221904635794]
	TIME [epoch: 9.1 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4676136581424905		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.4676136581424905 | validation: 0.3341198110025512]
	TIME [epoch: 9.12 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4171574156357831		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.4171574156357831 | validation: 0.39145353396575844]
	TIME [epoch: 9.12 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39636916054873556		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.39636916054873556 | validation: 0.8754977189905742]
	TIME [epoch: 9.1 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47542547516718175		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.47542547516718175 | validation: 0.4089030699057097]
	TIME [epoch: 9.1 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3622120942555519		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.3622120942555519 | validation: 0.26382396764481075]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4112804666068259		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.4112804666068259 | validation: 0.42269597330645714]
	TIME [epoch: 9.12 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35123966887572966		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.35123966887572966 | validation: 0.28204225104876646]
	TIME [epoch: 9.09 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3213809711131207		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.3213809711131207 | validation: 0.38639334640352285]
	TIME [epoch: 9.08 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35956399936877764		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.35956399936877764 | validation: 0.4887680801345887]
	TIME [epoch: 9.09 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4228392317561231		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.4228392317561231 | validation: 0.5261573096061678]
	TIME [epoch: 9.1 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37491920825092173		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.37491920825092173 | validation: 0.28349335924322666]
	TIME [epoch: 9.11 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014721974389916		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.3014721974389916 | validation: 0.2807170471085457]
	TIME [epoch: 9.1 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3258365144405656		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.3258365144405656 | validation: 0.37393386567041964]
	TIME [epoch: 9.1 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28757501698265986		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.28757501698265986 | validation: 0.34344047892016694]
	TIME [epoch: 9.1 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32461388979449896		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.32461388979449896 | validation: 0.46703219001239976]
	TIME [epoch: 9.12 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30157268166980444		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.30157268166980444 | validation: 0.1921041945079456]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2974947660134792		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.2974947660134792 | validation: 0.20094981240684331]
	TIME [epoch: 9.12 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3939364002138126		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.3939364002138126 | validation: 0.3154712379015948]
	TIME [epoch: 9.1 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3308269643183829		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.3308269643183829 | validation: 0.19393065033346088]
	TIME [epoch: 9.09 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3404066123127866		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.3404066123127866 | validation: 0.3494841616848039]
	TIME [epoch: 9.13 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29413012949834355		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.29413012949834355 | validation: 0.34914117915200293]
	TIME [epoch: 9.1 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37298606401400275		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.37298606401400275 | validation: 0.4814374044200759]
	TIME [epoch: 9.1 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31152786399106336		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.31152786399106336 | validation: 0.32882268364686873]
	TIME [epoch: 9.1 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3757997870471097		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.3757997870471097 | validation: 0.27326389652614885]
	TIME [epoch: 9.09 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2602855342768571		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.2602855342768571 | validation: 0.2948810518399908]
	TIME [epoch: 9.1 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34654212724264444		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.34654212724264444 | validation: 0.22313908583936218]
	TIME [epoch: 9.08 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737034189682266		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.2737034189682266 | validation: 0.281477065847687]
	TIME [epoch: 9.1 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4614477935497677		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.4614477935497677 | validation: 0.2929985163423334]
	TIME [epoch: 9.09 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35333989087066947		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.35333989087066947 | validation: 0.3203638963310163]
	TIME [epoch: 9.12 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3215807229845676		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.3215807229845676 | validation: 0.36548785172104997]
	TIME [epoch: 9.1 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42774537745474606		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.42774537745474606 | validation: 0.7365461874655925]
	TIME [epoch: 9.09 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35871712178180315		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.35871712178180315 | validation: 0.38768615119986266]
	TIME [epoch: 9.09 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3336375027342788		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.3336375027342788 | validation: 0.45814947387151084]
	TIME [epoch: 9.1 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121709816308307		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.3121709816308307 | validation: 0.1876318973275648]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_204.pth
	Model improved!!!
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2986677667634052		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.2986677667634052 | validation: 0.2757627054863285]
	TIME [epoch: 9.1 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3392398880266199		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.3392398880266199 | validation: 0.20067348292211015]
	TIME [epoch: 9.1 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3437515604889899		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.3437515604889899 | validation: 0.2898821362068542]
	TIME [epoch: 9.09 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32247466903163013		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.32247466903163013 | validation: 0.2369858570480351]
	TIME [epoch: 9.12 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3250428712507469		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.3250428712507469 | validation: 0.280387809525372]
	TIME [epoch: 9.1 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26113308804641894		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.26113308804641894 | validation: 0.25745680933558984]
	TIME [epoch: 9.1 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25570181454031793		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.25570181454031793 | validation: 0.286426622584696]
	TIME [epoch: 9.09 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30466092570416436		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.30466092570416436 | validation: 0.16348097286436916]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_212.pth
	Model improved!!!
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28527599213283217		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.28527599213283217 | validation: 0.21739445687541756]
	TIME [epoch: 9.12 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2580664015940213		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.2580664015940213 | validation: 0.22132498016774427]
	TIME [epoch: 9.09 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27467886047138074		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.27467886047138074 | validation: 0.5211631031977544]
	TIME [epoch: 9.09 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3291858068203916		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.3291858068203916 | validation: 0.5035545546575763]
	TIME [epoch: 9.1 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30288887643646106		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.30288887643646106 | validation: 0.2940606513861368]
	TIME [epoch: 9.1 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25441327058228136		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.25441327058228136 | validation: 0.20939682148279531]
	TIME [epoch: 9.12 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496553606445831		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.2496553606445831 | validation: 0.26225739949834687]
	TIME [epoch: 9.1 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2497779805568911		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.2497779805568911 | validation: 0.28339871366091873]
	TIME [epoch: 9.09 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27145230940279796		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.27145230940279796 | validation: 0.18511474330570776]
	TIME [epoch: 9.1 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29042632554340864		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.29042632554340864 | validation: 0.20050658116858866]
	TIME [epoch: 9.09 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3394485550578702		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.3394485550578702 | validation: 0.27671224953916435]
	TIME [epoch: 9.12 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24426052136815338		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.24426052136815338 | validation: 0.26416221292775943]
	TIME [epoch: 9.11 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2324995945355462		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.2324995945355462 | validation: 0.18140538927519664]
	TIME [epoch: 9.1 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23011705510672303		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.23011705510672303 | validation: 0.21325391232453877]
	TIME [epoch: 9.1 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752741192334156		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.2752741192334156 | validation: 0.18367863962389874]
	TIME [epoch: 9.11 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25181194232822396		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.25181194232822396 | validation: 0.22126221564637644]
	TIME [epoch: 9.11 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24664876332909183		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.24664876332909183 | validation: 0.22877096242647543]
	TIME [epoch: 9.1 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2857232652064968		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.2857232652064968 | validation: 0.23989195285811005]
	TIME [epoch: 9.1 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534386719719193		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.2534386719719193 | validation: 0.18777901625931037]
	TIME [epoch: 9.1 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2195132984676067		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.2195132984676067 | validation: 0.22670631283847342]
	TIME [epoch: 9.13 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601440184259473		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.2601440184259473 | validation: 0.270871658286349]
	TIME [epoch: 9.11 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556515671171097		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.2556515671171097 | validation: 0.293933633305946]
	TIME [epoch: 9.1 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3311675425171721		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.3311675425171721 | validation: 0.31560522726612183]
	TIME [epoch: 9.09 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21500949957632792		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.21500949957632792 | validation: 0.40003337995151633]
	TIME [epoch: 9.16 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2543845609173482		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.2543845609173482 | validation: 0.26470384061473556]
	TIME [epoch: 9.11 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20398787881258826		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.20398787881258826 | validation: 0.5030652491468828]
	TIME [epoch: 9.11 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27974729655254277		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.27974729655254277 | validation: 0.18291721742910122]
	TIME [epoch: 9.1 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25028951742308775		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.25028951742308775 | validation: 0.16063763451043633]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_240.pth
	Model improved!!!
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23392584228637237		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.23392584228637237 | validation: 0.1950077788718177]
	TIME [epoch: 9.12 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25091455765881704		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.25091455765881704 | validation: 0.32788637281280386]
	TIME [epoch: 9.09 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25071005853806716		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.25071005853806716 | validation: 0.15814237307831697]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_243.pth
	Model improved!!!
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22823075639267482		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.22823075639267482 | validation: 0.2237731784086805]
	TIME [epoch: 9.1 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19870680586124007		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.19870680586124007 | validation: 0.27300848241588827]
	TIME [epoch: 9.1 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3488941076034987		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.3488941076034987 | validation: 0.16859097986013322]
	TIME [epoch: 9.11 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20675838603527064		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.20675838603527064 | validation: 0.2249212103868504]
	TIME [epoch: 9.08 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27143708603318845		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.27143708603318845 | validation: 0.3834583925164121]
	TIME [epoch: 9.09 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21350672176976962		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.21350672176976962 | validation: 0.20409903611439084]
	TIME [epoch: 9.09 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2379757136236189		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.2379757136236189 | validation: 0.19308603974814254]
	TIME [epoch: 9.1 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2208371518626103		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.2208371518626103 | validation: 0.5230059863811196]
	TIME [epoch: 9.12 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2703557482588758		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.2703557482588758 | validation: 0.2391945157079064]
	TIME [epoch: 9.1 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.263999208009566		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.263999208009566 | validation: 0.18471160766005673]
	TIME [epoch: 9.1 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25459717317501135		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.25459717317501135 | validation: 0.2224874525261304]
	TIME [epoch: 9.09 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641864353425124		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.2641864353425124 | validation: 0.2660988159637928]
	TIME [epoch: 9.1 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2544272644713738		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.2544272644713738 | validation: 0.2399498791530667]
	TIME [epoch: 9.11 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23737919509479055		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.23737919509479055 | validation: 0.2591232700829885]
	TIME [epoch: 9.1 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23326450844202423		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.23326450844202423 | validation: 0.24270482900494983]
	TIME [epoch: 9.09 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2159537800843076		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.2159537800843076 | validation: 0.25305090618546705]
	TIME [epoch: 9.1 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21681720638308297		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.21681720638308297 | validation: 0.17783133272150498]
	TIME [epoch: 9.1 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2483303207474285		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.2483303207474285 | validation: 0.2117577165418455]
	TIME [epoch: 9.12 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.187246349762573		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.187246349762573 | validation: 0.31849780826569024]
	TIME [epoch: 9.1 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37069228471979976		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.37069228471979976 | validation: 0.16349982784936617]
	TIME [epoch: 9.09 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1678127129578225		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.1678127129578225 | validation: 0.2562155390122989]
	TIME [epoch: 9.11 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20126682074644836		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.20126682074644836 | validation: 0.23662663159301392]
	TIME [epoch: 9.11 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2609521398211535		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.2609521398211535 | validation: 0.1721404065731557]
	TIME [epoch: 9.12 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20681381889084288		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.20681381889084288 | validation: 0.1628361033862688]
	TIME [epoch: 9.09 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21674340645201365		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.21674340645201365 | validation: 0.20086450102097242]
	TIME [epoch: 9.08 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22581538343445753		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.22581538343445753 | validation: 0.20133012611559012]
	TIME [epoch: 9.1 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21743427592219539		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.21743427592219539 | validation: 0.1482336523834997]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_270.pth
	Model improved!!!
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19872117250604662		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.19872117250604662 | validation: 0.2215810650523411]
	TIME [epoch: 9.11 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2012173743106122		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.2012173743106122 | validation: 0.23248314254770092]
	TIME [epoch: 9.43 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24558075336352775		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.24558075336352775 | validation: 0.13072801486402022]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_273.pth
	Model improved!!!
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16930350850795917		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.16930350850795917 | validation: 0.10919440473482427]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_274.pth
	Model improved!!!
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863666299529968		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.2863666299529968 | validation: 0.19064641537013807]
	TIME [epoch: 9.14 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21551207706920952		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.21551207706920952 | validation: 0.36852554005581684]
	TIME [epoch: 9.14 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24297088688371157		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.24297088688371157 | validation: 0.2051345083329601]
	TIME [epoch: 9.13 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28168328447064017		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.28168328447064017 | validation: 0.15632734033477613]
	TIME [epoch: 9.12 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2064156321904424		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.2064156321904424 | validation: 0.13793518837673158]
	TIME [epoch: 9.13 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17814070703765658		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.17814070703765658 | validation: 0.31793750346183697]
	TIME [epoch: 9.14 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19910473205338014		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.19910473205338014 | validation: 0.1619598114688378]
	TIME [epoch: 9.13 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933375852845135		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.1933375852845135 | validation: 0.18730802720711426]
	TIME [epoch: 9.12 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19485505949061313		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.19485505949061313 | validation: 0.24162621552586394]
	TIME [epoch: 9.12 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23991014098885008		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.23991014098885008 | validation: 0.2292513838605966]
	TIME [epoch: 9.12 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16429576712859756		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.16429576712859756 | validation: 0.2068962245655887]
	TIME [epoch: 9.14 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18218706496091458		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.18218706496091458 | validation: 0.21670194264846931]
	TIME [epoch: 9.12 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20390900072046686		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.20390900072046686 | validation: 0.1911528978868558]
	TIME [epoch: 9.12 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22656243302103704		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.22656243302103704 | validation: 0.19800492096962596]
	TIME [epoch: 9.12 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20253364629245016		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.20253364629245016 | validation: 0.2955638979079755]
	TIME [epoch: 9.12 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22665266052811067		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.22665266052811067 | validation: 0.32216790332735973]
	TIME [epoch: 9.15 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1817987186279401		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.1817987186279401 | validation: 0.15756540903616764]
	TIME [epoch: 9.13 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2019259759737035		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.2019259759737035 | validation: 0.14561745779804575]
	TIME [epoch: 9.12 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1845277917560051		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.1845277917560051 | validation: 0.2385576554634986]
	TIME [epoch: 9.12 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1938429271457219		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.1938429271457219 | validation: 0.13874372413436653]
	TIME [epoch: 9.11 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921006035510357		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.1921006035510357 | validation: 0.1343770463909438]
	TIME [epoch: 9.14 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17239166367407252		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.17239166367407252 | validation: 0.14909258877634818]
	TIME [epoch: 9.12 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15974703689950615		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.15974703689950615 | validation: 0.18015084129492315]
	TIME [epoch: 9.12 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16947692019041993		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.16947692019041993 | validation: 0.15868734345084629]
	TIME [epoch: 9.12 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17124040461675225		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.17124040461675225 | validation: 0.1396519447037809]
	TIME [epoch: 9.12 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1813171080395045		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.1813171080395045 | validation: 0.1313843186366073]
	TIME [epoch: 9.14 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2224514935989324		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.2224514935989324 | validation: 0.1566824541188254]
	TIME [epoch: 9.12 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562604911720163		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.1562604911720163 | validation: 0.14356627266120098]
	TIME [epoch: 9.12 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2950902433630687		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.2950902433630687 | validation: 0.3160754064729297]
	TIME [epoch: 9.12 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16778856196518943		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.16778856196518943 | validation: 0.15225079038565853]
	TIME [epoch: 9.11 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3067086107862015		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.3067086107862015 | validation: 0.33166070103958323]
	TIME [epoch: 9.14 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1842848705045955		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.1842848705045955 | validation: 0.1969471315505205]
	TIME [epoch: 9.11 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14122513079119264		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.14122513079119264 | validation: 0.20398827874033168]
	TIME [epoch: 9.12 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18805693682973368		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.18805693682973368 | validation: 0.1444874135744016]
	TIME [epoch: 9.11 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22556307043275842		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.22556307043275842 | validation: 0.2809628909259071]
	TIME [epoch: 9.11 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598090308734753		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.2598090308734753 | validation: 0.197148270764202]
	TIME [epoch: 9.14 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2127585777595756		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.2127585777595756 | validation: 0.22081200134211454]
	TIME [epoch: 9.12 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1783754010726074		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.1783754010726074 | validation: 0.23305369657909594]
	TIME [epoch: 9.11 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21103008600691756		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.21103008600691756 | validation: 0.22325609654329365]
	TIME [epoch: 9.11 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17578481664539522		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.17578481664539522 | validation: 0.12062328929386291]
	TIME [epoch: 9.12 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1657306908403512		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.1657306908403512 | validation: 0.15531317090922403]
	TIME [epoch: 9.13 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.152414652888256		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.152414652888256 | validation: 0.1412367764919354]
	TIME [epoch: 9.13 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15294893250307778		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.15294893250307778 | validation: 0.33212112081802725]
	TIME [epoch: 9.12 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19992144309879983		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.19992144309879983 | validation: 0.14841874121026216]
	TIME [epoch: 9.12 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1723246410005185		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.1723246410005185 | validation: 0.25797880473658563]
	TIME [epoch: 9.12 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19962341445642445		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.19962341445642445 | validation: 0.15967349473067183]
	TIME [epoch: 9.14 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14190786190357205		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.14190786190357205 | validation: 0.1484713201398641]
	TIME [epoch: 9.12 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15855927695996105		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.15855927695996105 | validation: 0.12542533150430807]
	TIME [epoch: 9.12 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15001555632267297		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.15001555632267297 | validation: 0.1287681099999924]
	TIME [epoch: 9.12 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23785386942575437		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.23785386942575437 | validation: 0.1500078830222526]
	TIME [epoch: 9.11 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2579690370976237		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.2579690370976237 | validation: 0.12263722816992687]
	TIME [epoch: 9.14 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15161052412900206		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.15161052412900206 | validation: 0.1553631580338082]
	TIME [epoch: 9.12 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1597066172153367		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.1597066172153367 | validation: 0.16102964856349478]
	TIME [epoch: 9.11 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1953076221417035		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.1953076221417035 | validation: 0.15263392680523785]
	TIME [epoch: 9.13 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1384964399690475		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.1384964399690475 | validation: 0.16372767260176557]
	TIME [epoch: 9.12 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1414160189459433		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.1414160189459433 | validation: 0.20745379423878418]
	TIME [epoch: 9.14 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15379487768477587		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.15379487768477587 | validation: 0.20856131895822544]
	TIME [epoch: 9.13 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16063847784443155		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.16063847784443155 | validation: 0.11471789225821896]
	TIME [epoch: 9.11 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13708174952692848		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.13708174952692848 | validation: 0.15293023599667793]
	TIME [epoch: 9.12 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490593964132322		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.1490593964132322 | validation: 0.24700150790466824]
	TIME [epoch: 9.11 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17517410699194574		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.17517410699194574 | validation: 0.1598737476338648]
	TIME [epoch: 9.13 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1428810084082834		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.1428810084082834 | validation: 0.16294806222713545]
	TIME [epoch: 9.12 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13483443470038095		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.13483443470038095 | validation: 0.12466922598780725]
	TIME [epoch: 9.1 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16042035129494742		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.16042035129494742 | validation: 0.13044496151638013]
	TIME [epoch: 9.11 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12433473876185257		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.12433473876185257 | validation: 0.11663047715044841]
	TIME [epoch: 9.1 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12229796882236657		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.12229796882236657 | validation: 0.17076883976337404]
	TIME [epoch: 9.13 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13820983486653618		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.13820983486653618 | validation: 0.1445184480051737]
	TIME [epoch: 9.11 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13570897303229612		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.13570897303229612 | validation: 0.13040771554279423]
	TIME [epoch: 9.11 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1648709675028826		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.1648709675028826 | validation: 0.1423204301311387]
	TIME [epoch: 9.11 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17573961812536326		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.17573961812536326 | validation: 0.23298051922515267]
	TIME [epoch: 9.11 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1640334657682928		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.1640334657682928 | validation: 0.14967461006260946]
	TIME [epoch: 9.13 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16078569419087083		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.16078569419087083 | validation: 0.19619431940295584]
	TIME [epoch: 9.11 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16780438707038775		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.16780438707038775 | validation: 0.1258811246714744]
	TIME [epoch: 9.11 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16771464818372966		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.16771464818372966 | validation: 0.1665367097570644]
	TIME [epoch: 9.11 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12184604995015536		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.12184604995015536 | validation: 0.13784733978570135]
	TIME [epoch: 9.11 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19259154822454094		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.19259154822454094 | validation: 0.09338440960409508]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_350.pth
	Model improved!!!
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11152005770062068		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.11152005770062068 | validation: 0.21324835718587884]
	TIME [epoch: 9.11 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20713011499495249		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.20713011499495249 | validation: 0.08066169220735235]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_352.pth
	Model improved!!!
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1497843343125704		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.1497843343125704 | validation: 0.15011174219023354]
	TIME [epoch: 9.11 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15038866917944443		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.15038866917944443 | validation: 0.1068621131138182]
	TIME [epoch: 9.12 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11104030074964621		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.11104030074964621 | validation: 0.09761744571911372]
	TIME [epoch: 9.14 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14926279043966031		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.14926279043966031 | validation: 0.11399493702107463]
	TIME [epoch: 9.13 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14516748702592083		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.14516748702592083 | validation: 0.20779220711015253]
	TIME [epoch: 9.12 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16203815205413202		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.16203815205413202 | validation: 0.09665779928228838]
	TIME [epoch: 9.12 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1783080743289594		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.1783080743289594 | validation: 0.2691187946707487]
	TIME [epoch: 9.12 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14698763377989893		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.14698763377989893 | validation: 0.111842988040986]
	TIME [epoch: 9.14 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1784470901439823		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.1784470901439823 | validation: 0.11827287411589421]
	TIME [epoch: 9.12 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11685167569550955		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.11685167569550955 | validation: 0.3040033732032817]
	TIME [epoch: 9.12 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21583710280980797		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.21583710280980797 | validation: 0.09905693116988737]
	TIME [epoch: 9.12 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14562021133193787		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.14562021133193787 | validation: 0.11160257290799996]
	TIME [epoch: 9.11 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1299217957022269		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.1299217957022269 | validation: 0.15427631067219527]
	TIME [epoch: 9.13 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12624093390449054		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.12624093390449054 | validation: 0.13067489738382082]
	TIME [epoch: 9.12 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12130477876736356		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.12130477876736356 | validation: 0.1819750951045586]
	TIME [epoch: 9.11 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1369386194734872		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.1369386194734872 | validation: 0.13212616224010743]
	TIME [epoch: 9.12 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11496321253944215		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.11496321253944215 | validation: 0.1394071915059982]
	TIME [epoch: 9.12 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.150483251905962		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.150483251905962 | validation: 0.22593962847703264]
	TIME [epoch: 9.14 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13949513510557152		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.13949513510557152 | validation: 0.2596669529081076]
	TIME [epoch: 9.13 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14243010453304708		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.14243010453304708 | validation: 0.2028356890146717]
	TIME [epoch: 9.12 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16605474103985468		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.16605474103985468 | validation: 0.09700412773169229]
	TIME [epoch: 9.12 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13252096947795916		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.13252096947795916 | validation: 0.12520074231701928]
	TIME [epoch: 9.12 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15393812426541037		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.15393812426541037 | validation: 0.14442544755470574]
	TIME [epoch: 9.14 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1222192553665324		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.1222192553665324 | validation: 0.11504333332301361]
	TIME [epoch: 9.12 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12520843043715033		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.12520843043715033 | validation: 0.18931043946373985]
	TIME [epoch: 9.12 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12505707280159722		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.12505707280159722 | validation: 0.11811751539242829]
	TIME [epoch: 9.12 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16947439621027088		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.16947439621027088 | validation: 0.14386567986573334]
	TIME [epoch: 9.11 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15273127743093545		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.15273127743093545 | validation: 0.09709398587251561]
	TIME [epoch: 9.13 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15248600512616695		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.15248600512616695 | validation: 0.12293609803628563]
	TIME [epoch: 9.12 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10654159504257969		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.10654159504257969 | validation: 0.13005363028324352]
	TIME [epoch: 9.13 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14875786725288598		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.14875786725288598 | validation: 0.09709790349306759]
	TIME [epoch: 9.12 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12999309001278106		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.12999309001278106 | validation: 0.13054504125070418]
	TIME [epoch: 9.12 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13263829096173782		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.13263829096173782 | validation: 0.12508727860286897]
	TIME [epoch: 9.14 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12314231405953364		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.12314231405953364 | validation: 0.12059206383570051]
	TIME [epoch: 9.12 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11568670578815418		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.11568670578815418 | validation: 0.08377471401335185]
	TIME [epoch: 9.11 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10904544059064544		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.10904544059064544 | validation: 0.1419867990053384]
	TIME [epoch: 9.12 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10926143947978013		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.10926143947978013 | validation: 0.12409991436846848]
	TIME [epoch: 9.12 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12993393692394165		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.12993393692394165 | validation: 0.11044194458228129]
	TIME [epoch: 9.14 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12763641363088735		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.12763641363088735 | validation: 0.2205345708159105]
	TIME [epoch: 9.12 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16679291921431147		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.16679291921431147 | validation: 0.17355526324888843]
	TIME [epoch: 9.11 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13005486806811786		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.13005486806811786 | validation: 0.10060097139893101]
	TIME [epoch: 9.11 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12616846708487664		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.12616846708487664 | validation: 0.09627788120386749]
	TIME [epoch: 9.11 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1328321829120203		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.1328321829120203 | validation: 0.11894053272571918]
	TIME [epoch: 9.14 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13502544779063044		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.13502544779063044 | validation: 0.15764484198720013]
	TIME [epoch: 9.12 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19410863541416365		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.19410863541416365 | validation: 0.09548944357958707]
	TIME [epoch: 9.12 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10512812533405971		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.10512812533405971 | validation: 0.10534319478104914]
	TIME [epoch: 9.11 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13027980637295417		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.13027980637295417 | validation: 0.23239806981925676]
	TIME [epoch: 9.12 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1393789888289026		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.1393789888289026 | validation: 0.13292682772342768]
	TIME [epoch: 9.14 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10072992031249947		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.10072992031249947 | validation: 0.09368879521488394]
	TIME [epoch: 9.12 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12682647285970364		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.12682647285970364 | validation: 0.1326307308552056]
	TIME [epoch: 9.12 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12250443378473955		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.12250443378473955 | validation: 0.1467632442367529]
	TIME [epoch: 9.11 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10517829605966411		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.10517829605966411 | validation: 0.11060684714164472]
	TIME [epoch: 9.12 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13373177560402344		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.13373177560402344 | validation: 0.14173544427081775]
	TIME [epoch: 9.13 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10886109174851619		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.10886109174851619 | validation: 0.11667215716486233]
	TIME [epoch: 9.11 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1805416362873419		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.1805416362873419 | validation: 0.2419356976065582]
	TIME [epoch: 9.11 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562812692928427		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.1562812692928427 | validation: 0.15164142464909114]
	TIME [epoch: 9.12 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10407687831474899		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.10407687831474899 | validation: 0.13631431037642489]
	TIME [epoch: 9.12 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10732318989236034		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.10732318989236034 | validation: 0.08207481563643904]
	TIME [epoch: 9.14 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11680854978976549		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.11680854978976549 | validation: 0.1450228307655969]
	TIME [epoch: 9.11 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09022506739411873		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.09022506739411873 | validation: 0.13642285805308407]
	TIME [epoch: 9.11 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16491577854030054		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.16491577854030054 | validation: 0.13637411237287117]
	TIME [epoch: 9.11 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13013032218818038		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.13013032218818038 | validation: 0.12783758886888796]
	TIME [epoch: 9.11 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1291778376156118		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.1291778376156118 | validation: 0.15048515682885646]
	TIME [epoch: 9.13 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11988782337028836		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.11988782337028836 | validation: 0.19649300647492934]
	TIME [epoch: 9.11 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12368163017434394		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.12368163017434394 | validation: 0.09529686898974189]
	TIME [epoch: 9.11 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11137062685797061		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.11137062685797061 | validation: 0.10429272158023642]
	TIME [epoch: 9.11 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0986458075871402		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.0986458075871402 | validation: 0.09205186615984873]
	TIME [epoch: 9.11 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14104390974604605		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.14104390974604605 | validation: 0.1712793393054637]
	TIME [epoch: 9.12 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1237542758738845		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.1237542758738845 | validation: 0.09541389562752049]
	TIME [epoch: 9.12 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13362904615283752		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.13362904615283752 | validation: 0.12199732688963141]
	TIME [epoch: 9.11 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09787898748988601		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.09787898748988601 | validation: 0.12807106001600205]
	TIME [epoch: 9.11 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09693031522332902		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.09693031522332902 | validation: 0.09870825458920557]
	TIME [epoch: 9.12 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13798944664989776		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.13798944664989776 | validation: 0.08691578668284863]
	TIME [epoch: 9.13 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08807495646469851		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.08807495646469851 | validation: 0.08986191842695716]
	TIME [epoch: 9.11 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0858766222595845		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.0858766222595845 | validation: 0.1086493931200517]
	TIME [epoch: 9.1 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1140912533192191		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.1140912533192191 | validation: 0.22905320603563395]
	TIME [epoch: 9.11 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12284355296464929		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.12284355296464929 | validation: 0.08515993717972517]
	TIME [epoch: 9.11 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07837421300193645		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.07837421300193645 | validation: 0.2142012260884419]
	TIME [epoch: 9.13 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12481955537976579		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.12481955537976579 | validation: 0.10272735266772255]
	TIME [epoch: 9.11 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0962747035809113		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.0962747035809113 | validation: 0.10378369319065858]
	TIME [epoch: 9.1 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11373902776614116		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.11373902776614116 | validation: 0.09973115404407851]
	TIME [epoch: 9.1 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10311205036634952		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.10311205036634952 | validation: 0.08233442715996005]
	TIME [epoch: 9.11 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0827768217224284		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.0827768217224284 | validation: 0.12114579451839863]
	TIME [epoch: 9.13 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11755075857684043		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.11755075857684043 | validation: 0.18253037169561664]
	TIME [epoch: 9.12 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10242164376181084		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.10242164376181084 | validation: 0.09964613108358557]
	TIME [epoch: 9.1 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12176489115105468		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.12176489115105468 | validation: 0.14030991161006084]
	TIME [epoch: 9.11 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1269090007807464		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.1269090007807464 | validation: 0.11075792101775438]
	TIME [epoch: 9.11 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13099776611720793		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.13099776611720793 | validation: 0.1051436979477312]
	TIME [epoch: 9.12 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08866874295664795		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.08866874295664795 | validation: 0.09787272919685891]
	TIME [epoch: 9.11 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09096961905132878		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.09096961905132878 | validation: 0.07469619524749758]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_442.pth
	Model improved!!!
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08629427869446885		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.08629427869446885 | validation: 0.1243752733708799]
	TIME [epoch: 9.1 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11258059697947806		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.11258059697947806 | validation: 0.11244699865327909]
	TIME [epoch: 9.1 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09081961085290727		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.09081961085290727 | validation: 0.10691530970050006]
	TIME [epoch: 9.11 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10252616314890799		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.10252616314890799 | validation: 0.08191972163564391]
	TIME [epoch: 9.1 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10790519667020444		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.10790519667020444 | validation: 0.299680201224842]
	TIME [epoch: 9.11 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14959574197237874		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.14959574197237874 | validation: 0.1326566556866483]
	TIME [epoch: 9.11 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0904694585482638		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.0904694585482638 | validation: 0.09409594461541104]
	TIME [epoch: 9.12 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07962419662387524		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.07962419662387524 | validation: 0.10398316670263072]
	TIME [epoch: 9.11 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0991402656021924		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.0991402656021924 | validation: 0.12167971370417208]
	TIME [epoch: 9.1 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1523294679291922		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.1523294679291922 | validation: 0.11507257930079623]
	TIME [epoch: 9.09 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10498008544955895		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.10498008544955895 | validation: 0.11716489474393305]
	TIME [epoch: 9.1 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08792458919721766		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.08792458919721766 | validation: 0.0942103956960957]
	TIME [epoch: 9.11 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08968007787468879		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.08968007787468879 | validation: 0.07814156504305665]
	TIME [epoch: 9.11 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11541067857837514		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.11541067857837514 | validation: 0.16422800228125084]
	TIME [epoch: 9.11 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1151300058558917		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.1151300058558917 | validation: 0.08475199083568717]
	TIME [epoch: 9.1 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10048586173401344		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.10048586173401344 | validation: 0.07370015355970205]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_458.pth
	Model improved!!!
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08199894519616889		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.08199894519616889 | validation: 0.06494781749211263]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_459.pth
	Model improved!!!
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10000212587485442		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.10000212587485442 | validation: 0.13268117377822028]
	TIME [epoch: 9.11 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08648466538175018		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.08648466538175018 | validation: 0.07580552861860218]
	TIME [epoch: 9.1 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09786755549967918		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.09786755549967918 | validation: 0.12077333674756766]
	TIME [epoch: 9.1 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013330027388281		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.1013330027388281 | validation: 0.07319413339990374]
	TIME [epoch: 9.1 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08863338018339466		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.08863338018339466 | validation: 0.06634475455198618]
	TIME [epoch: 9.1 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08436499602831363		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.08436499602831363 | validation: 0.1212970629589008]
	TIME [epoch: 9.11 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0924633712125236		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.0924633712125236 | validation: 0.077394332342365]
	TIME [epoch: 9.1 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09013112354214796		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.09013112354214796 | validation: 0.07044154573611884]
	TIME [epoch: 9.1 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09310445800948444		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.09310445800948444 | validation: 0.13376686819545475]
	TIME [epoch: 9.09 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08597782779951166		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.08597782779951166 | validation: 0.1086866683978723]
	TIME [epoch: 9.11 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11427670675023682		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.11427670675023682 | validation: 0.08567495264855321]
	TIME [epoch: 9.11 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08513791021072262		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.08513791021072262 | validation: 0.07785886803267988]
	TIME [epoch: 9.1 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1035857952780459		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.1035857952780459 | validation: 0.14599027201206435]
	TIME [epoch: 9.1 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09950026142124566		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.09950026142124566 | validation: 0.12663840548008126]
	TIME [epoch: 9.1 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08595907991854665		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.08595907991854665 | validation: 0.15234495872171058]
	TIME [epoch: 9.11 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08652965109701227		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.08652965109701227 | validation: 0.0692935085083001]
	TIME [epoch: 9.11 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08539129174519974		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.08539129174519974 | validation: 0.09484214794696971]
	TIME [epoch: 9.11 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09531695825977889		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.09531695825977889 | validation: 0.13426269875044652]
	TIME [epoch: 9.1 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09653192815022624		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.09653192815022624 | validation: 0.10036315795447048]
	TIME [epoch: 9.09 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0984079385382887		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.0984079385382887 | validation: 0.12198724455938019]
	TIME [epoch: 9.11 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0632109226299746		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.0632109226299746 | validation: 0.09123303493275886]
	TIME [epoch: 9.11 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11237532117409985		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.11237532117409985 | validation: 0.09600154597792268]
	TIME [epoch: 9.1 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10843207722304005		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.10843207722304005 | validation: 0.07305597522080005]
	TIME [epoch: 9.11 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07727833319965097		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.07727833319965097 | validation: 0.1211503222441146]
	TIME [epoch: 9.1 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07868169185191698		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.07868169185191698 | validation: 0.06788121323994367]
	TIME [epoch: 9.11 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09691315956223517		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.09691315956223517 | validation: 0.09047288701755041]
	TIME [epoch: 9.11 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07071702522958764		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.07071702522958764 | validation: 0.08486652374552396]
	TIME [epoch: 9.1 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07359010355066396		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.07359010355066396 | validation: 0.06942769233114908]
	TIME [epoch: 9.11 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10937281492349496		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.10937281492349496 | validation: 0.11194496139386306]
	TIME [epoch: 9.1 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11057408834187958		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.11057408834187958 | validation: 0.057637319607676554]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_489.pth
	Model improved!!!
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10048384043106202		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.10048384043106202 | validation: 0.05761404676185366]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_490.pth
	Model improved!!!
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.082792114642052		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.082792114642052 | validation: 0.06952626997997939]
	TIME [epoch: 9.09 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08024912835174716		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.08024912835174716 | validation: 0.1479785893474233]
	TIME [epoch: 9.09 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08652371834537917		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.08652371834537917 | validation: 0.27415939786261556]
	TIME [epoch: 9.1 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13641427978748313		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.13641427978748313 | validation: 0.06593159181911301]
	TIME [epoch: 9.11 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1354206888696807		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.1354206888696807 | validation: 0.1490465285954226]
	TIME [epoch: 9.11 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08731558689117103		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.08731558689117103 | validation: 0.07578033364329781]
	TIME [epoch: 9.1 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11480122620052129		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.11480122620052129 | validation: 0.1020079865922613]
	TIME [epoch: 9.1 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08539925856427415		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.08539925856427415 | validation: 0.08300667531299871]
	TIME [epoch: 9.09 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07551241825633474		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.07551241825633474 | validation: 0.0923586648308086]
	TIME [epoch: 9.12 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08115458310169824		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.08115458310169824 | validation: 0.0762476582775704]
	TIME [epoch: 9.12 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06859582066638911		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.06859582066638911 | validation: 0.0648685805576924]
	TIME [epoch: 9.11 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09393347993167742		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.09393347993167742 | validation: 0.06890530937323094]
	TIME [epoch: 9.11 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05198071213346075		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.05198071213346075 | validation: 0.05998288110908525]
	TIME [epoch: 9.09 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0743064079024798		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.0743064079024798 | validation: 0.06380960900309392]
	TIME [epoch: 9.11 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07017093771086783		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.07017093771086783 | validation: 0.06881167207889789]
	TIME [epoch: 9.1 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07175900503286413		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.07175900503286413 | validation: 0.12502327580315664]
	TIME [epoch: 9.1 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07467503436839444		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.07467503436839444 | validation: 0.07470329297102252]
	TIME [epoch: 9.11 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07789721365615451		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.07789721365615451 | validation: 0.07650963871620078]
	TIME [epoch: 9.11 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06723487448502083		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.06723487448502083 | validation: 0.0565964706845555]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_509.pth
	Model improved!!!
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06984144684247512		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.06984144684247512 | validation: 0.07144734521344107]
	TIME [epoch: 9.1 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.080693916388241		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.080693916388241 | validation: 0.10514668717379559]
	TIME [epoch: 9.09 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09975853957835239		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.09975853957835239 | validation: 0.13543324230350978]
	TIME [epoch: 9.09 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10745133890263121		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.10745133890263121 | validation: 0.07928376908532583]
	TIME [epoch: 9.1 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10055841346136066		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.10055841346136066 | validation: 0.06329129093999947]
	TIME [epoch: 9.13 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05625598595879348		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.05625598595879348 | validation: 0.08238014636389915]
	TIME [epoch: 9.12 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06757945606042035		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.06757945606042035 | validation: 0.0641039158084708]
	TIME [epoch: 9.1 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07070173424187201		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.07070173424187201 | validation: 0.07393662257492101]
	TIME [epoch: 9.09 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08059755274623852		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.08059755274623852 | validation: 0.06717710718297834]
	TIME [epoch: 9.09 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07407972925324194		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.07407972925324194 | validation: 0.056752992501245825]
	TIME [epoch: 9.12 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07466013390246856		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.07466013390246856 | validation: 0.19064389512540367]
	TIME [epoch: 9.11 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09562038961743824		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.09562038961743824 | validation: 0.07232502584023992]
	TIME [epoch: 9.1 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06809756894576564		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.06809756894576564 | validation: 0.04512062770599023]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_522.pth
	Model improved!!!
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378638680825711		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.06378638680825711 | validation: 0.07285016083887819]
	TIME [epoch: 9.11 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018602782040832		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.07018602782040832 | validation: 0.10398900398577832]
	TIME [epoch: 9.12 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857575611731824		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.06857575611731824 | validation: 0.0633109760563031]
	TIME [epoch: 9.1 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10918236288374242		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.10918236288374242 | validation: 0.1033653808491187]
	TIME [epoch: 9.1 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08228257955378153		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.08228257955378153 | validation: 0.12168360176625423]
	TIME [epoch: 9.11 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06668755461507514		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.06668755461507514 | validation: 0.11655591434497031]
	TIME [epoch: 9.11 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08854782041629922		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.08854782041629922 | validation: 0.0509448003758906]
	TIME [epoch: 9.12 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07700684339528747		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.07700684339528747 | validation: 0.07952640919099646]
	TIME [epoch: 9.1 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07517560832228955		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.07517560832228955 | validation: 0.07251730125691128]
	TIME [epoch: 9.1 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06435799851967097		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.06435799851967097 | validation: 0.09333982550748299]
	TIME [epoch: 9.09 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06450320055390639		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.06450320055390639 | validation: 0.06011852614274389]
	TIME [epoch: 9.11 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05280996631050774		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.05280996631050774 | validation: 0.13620070159856518]
	TIME [epoch: 9.12 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0726059648046027		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.0726059648046027 | validation: 0.0722828782120432]
	TIME [epoch: 9.11 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654606728957331		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.0654606728957331 | validation: 0.11548293520311032]
	TIME [epoch: 9.1 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08079329421294038		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.08079329421294038 | validation: 0.07673656928068787]
	TIME [epoch: 9.1 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07277121554367738		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.07277121554367738 | validation: 0.10600514496053214]
	TIME [epoch: 9.1 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0650767221348357		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.0650767221348357 | validation: 0.08375707128077517]
	TIME [epoch: 9.13 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10121388232682775		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.10121388232682775 | validation: 0.0920524651757711]
	TIME [epoch: 9.12 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09979284686572991		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.09979284686572991 | validation: 0.08615317822528842]
	TIME [epoch: 9.11 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.065668900357262		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.065668900357262 | validation: 0.06393572033404926]
	TIME [epoch: 9.1 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06343459895947177		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.06343459895947177 | validation: 0.06622227841606976]
	TIME [epoch: 9.1 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12862416591903666		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.12862416591903666 | validation: 0.10172326621350447]
	TIME [epoch: 9.12 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07836101984190405		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.07836101984190405 | validation: 0.08770655726771981]
	TIME [epoch: 9.12 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08343931862443563		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.08343931862443563 | validation: 0.17819469960372047]
	TIME [epoch: 9.1 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08614176078991487		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.08614176078991487 | validation: 0.09093740671635939]
	TIME [epoch: 9.1 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07726530864097693		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.07726530864097693 | validation: 0.11587666990930202]
	TIME [epoch: 9.11 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07421633208069289		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.07421633208069289 | validation: 0.09588963206457957]
	TIME [epoch: 9.12 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09901931502991104		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.09901931502991104 | validation: 0.0980266440634586]
	TIME [epoch: 9.11 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09538760115394149		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.09538760115394149 | validation: 0.08547977302096163]
	TIME [epoch: 9.1 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07725573442997918		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.07725573442997918 | validation: 0.06379468093829008]
	TIME [epoch: 9.11 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07358246333593269		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.07358246333593269 | validation: 0.05962358158625389]
	TIME [epoch: 9.11 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885849271788896		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.06885849271788896 | validation: 0.12226732066676171]
	TIME [epoch: 9.14 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10028088651658082		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.10028088651658082 | validation: 0.0584691937751005]
	TIME [epoch: 9.1 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10700727710651121		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.10700727710651121 | validation: 0.09180193639137428]
	TIME [epoch: 9.1 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07432417995375215		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.07432417995375215 | validation: 0.06112762039896828]
	TIME [epoch: 9.1 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09820359923369758		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.09820359923369758 | validation: 0.056420009238473776]
	TIME [epoch: 9.1 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651684771117287		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.06651684771117287 | validation: 0.08135363490554649]
	TIME [epoch: 9.12 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06978366507129506		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.06978366507129506 | validation: 0.09467885063972264]
	TIME [epoch: 9.1 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06507784546146278		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.06507784546146278 | validation: 0.06572835384848472]
	TIME [epoch: 9.1 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09080709882994252		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.09080709882994252 | validation: 0.05618179263547374]
	TIME [epoch: 9.1 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06592588697111498		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.06592588697111498 | validation: 0.06370439280809437]
	TIME [epoch: 9.1 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06039800467431752		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.06039800467431752 | validation: 0.11615102454850085]
	TIME [epoch: 9.13 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07200602573171012		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.07200602573171012 | validation: 0.07388974388267744]
	TIME [epoch: 9.11 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0759038708368447		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.0759038708368447 | validation: 0.10050000217717969]
	TIME [epoch: 9.11 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08292071749975864		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.08292071749975864 | validation: 0.056658540913589205]
	TIME [epoch: 9.1 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0701662726650705		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.0701662726650705 | validation: 0.06543647340945664]
	TIME [epoch: 9.11 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06095823495662026		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.06095823495662026 | validation: 0.08466490210750074]
	TIME [epoch: 9.13 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05779402033446864		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.05779402033446864 | validation: 0.08120674873758343]
	TIME [epoch: 9.09 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08481913263409122		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.08481913263409122 | validation: 0.08576939157490027]
	TIME [epoch: 9.1 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07702553668183981		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.07702553668183981 | validation: 0.09399167719582921]
	TIME [epoch: 9.09 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06222800718671519		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.06222800718671519 | validation: 0.05755654700096384]
	TIME [epoch: 9.1 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06297380851489684		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.06297380851489684 | validation: 0.06013476270082445]
	TIME [epoch: 9.12 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936806369505365		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.05936806369505365 | validation: 0.0949560299302001]
	TIME [epoch: 9.1 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06405363181227158		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.06405363181227158 | validation: 0.12490462037773921]
	TIME [epoch: 9.11 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.076820664890206		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.076820664890206 | validation: 0.059447581867570445]
	TIME [epoch: 9.1 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053632815723411074		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.053632815723411074 | validation: 0.0659887645464374]
	TIME [epoch: 9.11 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05650311376556033		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.05650311376556033 | validation: 0.06288212922211378]
	TIME [epoch: 9.14 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06283199199838843		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.06283199199838843 | validation: 0.06167980556131007]
	TIME [epoch: 9.11 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07371168496786464		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.07371168496786464 | validation: 0.07367304396470017]
	TIME [epoch: 9.11 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215762825094665		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.07215762825094665 | validation: 0.06498340342013983]
	TIME [epoch: 9.11 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.060121143553071896		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.060121143553071896 | validation: 0.11062882921369419]
	TIME [epoch: 9.1 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0763609882995153		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.0763609882995153 | validation: 0.08192221111945389]
	TIME [epoch: 9.13 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.056570104486474405		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.056570104486474405 | validation: 0.07050749089198209]
	TIME [epoch: 9.11 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0686922730339408		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.0686922730339408 | validation: 0.07548574434715674]
	TIME [epoch: 9.1 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066356487844634		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.07066356487844634 | validation: 0.11028386942320074]
	TIME [epoch: 9.11 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07924627204999532		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.07924627204999532 | validation: 0.06260959729732267]
	TIME [epoch: 9.1 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06278163912909682		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.06278163912909682 | validation: 0.059994970172670456]
	TIME [epoch: 9.12 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05414695665908994		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.05414695665908994 | validation: 0.07825464016781045]
	TIME [epoch: 9.1 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06630475721448949		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.06630475721448949 | validation: 0.05886862774257569]
	TIME [epoch: 9.1 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06689056183097486		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.06689056183097486 | validation: 0.06514342723597094]
	TIME [epoch: 9.11 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06064313939156117		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.06064313939156117 | validation: 0.04775044155021253]
	TIME [epoch: 9.11 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06908475625570724		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.06908475625570724 | validation: 0.066583747333435]
	TIME [epoch: 9.14 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04775939114107074		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.04775939114107074 | validation: 0.0895414150528358]
	TIME [epoch: 9.11 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05854976691242221		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.05854976691242221 | validation: 0.08114765829920581]
	TIME [epoch: 9.11 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06334819702502922		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.06334819702502922 | validation: 0.04914595614279236]
	TIME [epoch: 9.1 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05766167935064862		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.05766167935064862 | validation: 0.07731748170474537]
	TIME [epoch: 9.1 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05562339645197976		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.05562339645197976 | validation: 0.059404561033901335]
	TIME [epoch: 9.12 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04780370071196444		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.04780370071196444 | validation: 0.04746300961252635]
	TIME [epoch: 9.11 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05483326982218206		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.05483326982218206 | validation: 0.08718969362188264]
	TIME [epoch: 9.1 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06488444852619442		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.06488444852619442 | validation: 0.059759097102135325]
	TIME [epoch: 9.11 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07127200878768385		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.07127200878768385 | validation: 0.07266542167572021]
	TIME [epoch: 9.1 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04843763796381621		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.04843763796381621 | validation: 0.061657408861405597]
	TIME [epoch: 9.13 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05653521874381693		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.05653521874381693 | validation: 0.08462803206067009]
	TIME [epoch: 9.12 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05020193622129614		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.05020193622129614 | validation: 0.0598609836098395]
	TIME [epoch: 9.12 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07865903173082223		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.07865903173082223 | validation: 0.15488128495183923]
	TIME [epoch: 9.11 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09385774795866338		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.09385774795866338 | validation: 0.07511967762642113]
	TIME [epoch: 9.11 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07135683283579204		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.07135683283579204 | validation: 0.07995069491597634]
	TIME [epoch: 9.13 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08036864304727791		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.08036864304727791 | validation: 0.053124924495818016]
	TIME [epoch: 9.11 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053671472251267546		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.053671472251267546 | validation: 0.05531606909876202]
	TIME [epoch: 9.11 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06169430524428673		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.06169430524428673 | validation: 0.04706185878250875]
	TIME [epoch: 9.11 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0599407219849732		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.0599407219849732 | validation: 0.050010216263141595]
	TIME [epoch: 9.1 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051044436294499076		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.051044436294499076 | validation: 0.07059016449197282]
	TIME [epoch: 9.13 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05652499033292839		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.05652499033292839 | validation: 0.07854536564443625]
	TIME [epoch: 9.11 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048628540638448646		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.048628540638448646 | validation: 0.06099667456782111]
	TIME [epoch: 9.1 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06413490546891246		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.06413490546891246 | validation: 0.09606238221046401]
	TIME [epoch: 9.11 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05620584697297222		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.05620584697297222 | validation: 0.05468001747650318]
	TIME [epoch: 9.11 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.057971581576570244		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.057971581576570244 | validation: 0.07062265007443619]
	TIME [epoch: 9.14 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06755601470095944		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.06755601470095944 | validation: 0.062048468191375224]
	TIME [epoch: 9.12 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05118707260497592		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.05118707260497592 | validation: 0.07242840675027076]
	TIME [epoch: 9.11 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07081218620970059		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.07081218620970059 | validation: 0.06163987532080993]
	TIME [epoch: 9.11 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961522350726573		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.06961522350726573 | validation: 0.05349165645522122]
	TIME [epoch: 9.11 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050716696196024716		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.050716696196024716 | validation: 0.06593764028929838]
	TIME [epoch: 9.13 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06070674929314333		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.06070674929314333 | validation: 0.1084527877927672]
	TIME [epoch: 9.11 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0776206732684933		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.0776206732684933 | validation: 0.09711915533062722]
	TIME [epoch: 9.11 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07145992378204355		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.07145992378204355 | validation: 0.07222470436881573]
	TIME [epoch: 9.11 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06050052596109471		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.06050052596109471 | validation: 0.06656710660362308]
	TIME [epoch: 9.1 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0680675741700002		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.0680675741700002 | validation: 0.0557622771400003]
	TIME [epoch: 9.12 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924753507972761		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.04924753507972761 | validation: 0.07607970367833865]
	TIME [epoch: 9.1 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723927362352255		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.0723927362352255 | validation: 0.08313084976504871]
	TIME [epoch: 9.11 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0574395106882965		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.0574395106882965 | validation: 0.060192147518688885]
	TIME [epoch: 9.11 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04545591226724198		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.04545591226724198 | validation: 0.06378794309085675]
	TIME [epoch: 9.12 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05434786822319364		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.05434786822319364 | validation: 0.09099726371768714]
	TIME [epoch: 9.13 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05812287956864801		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.05812287956864801 | validation: 0.05078662470669617]
	TIME [epoch: 9.11 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044174930849209405		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.044174930849209405 | validation: 0.08880938305894821]
	TIME [epoch: 9.11 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.059610011662644125		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.059610011662644125 | validation: 0.06756556473219277]
	TIME [epoch: 9.1 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05603132960756181		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.05603132960756181 | validation: 0.09027060103882778]
	TIME [epoch: 9.11 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09397538929590571		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.09397538929590571 | validation: 0.053393355492925156]
	TIME [epoch: 9.13 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06894833094048955		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.06894833094048955 | validation: 0.06423540522335522]
	TIME [epoch: 9.12 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04786290342652033		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.04786290342652033 | validation: 0.05793343872454047]
	TIME [epoch: 9.11 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05622892970991179		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.05622892970991179 | validation: 0.0688664910021062]
	TIME [epoch: 9.11 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05573763468091793		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.05573763468091793 | validation: 0.06728142153693062]
	TIME [epoch: 9.11 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0516247134945174		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.0516247134945174 | validation: 0.04830217130004834]
	TIME [epoch: 9.13 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05930364794595899		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.05930364794595899 | validation: 0.09549787860352846]
	TIME [epoch: 9.12 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06608315073424086		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.06608315073424086 | validation: 0.0721662429523503]
	TIME [epoch: 9.12 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05740141631491552		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.05740141631491552 | validation: 0.05706197307117057]
	TIME [epoch: 9.12 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0483485266657991		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.0483485266657991 | validation: 0.0569418748208025]
	TIME [epoch: 9.12 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05966818306923209		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.05966818306923209 | validation: 0.06509318727887034]
	TIME [epoch: 9.12 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04988914799226975		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.04988914799226975 | validation: 0.06946818517097174]
	TIME [epoch: 9.11 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06273845745632682		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.06273845745632682 | validation: 0.06390074738417828]
	TIME [epoch: 9.12 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0580751833654081		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.0580751833654081 | validation: 0.06298388437665323]
	TIME [epoch: 9.11 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05419376423396085		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.05419376423396085 | validation: 0.04804174403881127]
	TIME [epoch: 9.12 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03905705069187328		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.03905705069187328 | validation: 0.05029416419998761]
	TIME [epoch: 9.13 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05249165276980596		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.05249165276980596 | validation: 0.06264422786484738]
	TIME [epoch: 9.11 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07007941056598173		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.07007941056598173 | validation: 0.05087446791537427]
	TIME [epoch: 9.11 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06543022424980728		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.06543022424980728 | validation: 0.05164608674735414]
	TIME [epoch: 9.11 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05802131104157463		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.05802131104157463 | validation: 0.058634038143881434]
	TIME [epoch: 9.11 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048901730090512165		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.048901730090512165 | validation: 0.053403123340134195]
	TIME [epoch: 9.12 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0487267820903616		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.0487267820903616 | validation: 0.07374096341285082]
	TIME [epoch: 9.11 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05426282340692299		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.05426282340692299 | validation: 0.05501693422419081]
	TIME [epoch: 9.11 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05913081842551711		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.05913081842551711 | validation: 0.07201494094014796]
	TIME [epoch: 9.1 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664663303598409		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.05664663303598409 | validation: 0.056215219148681154]
	TIME [epoch: 9.12 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06436020334461894		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.06436020334461894 | validation: 0.04480815787538738]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_664.pth
	Model improved!!!
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05808226450489198		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.05808226450489198 | validation: 0.05721025797291305]
	TIME [epoch: 9.1 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04985453647352884		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.04985453647352884 | validation: 0.060113467592245666]
	TIME [epoch: 9.1 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050985785989247724		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.050985785989247724 | validation: 0.05322145918971165]
	TIME [epoch: 9.09 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05779431011795436		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.05779431011795436 | validation: 0.05807905388005136]
	TIME [epoch: 9.1 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05520415995293463		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.05520415995293463 | validation: 0.061275665013544506]
	TIME [epoch: 9.11 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04429089865414309		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.04429089865414309 | validation: 0.06312204774079604]
	TIME [epoch: 9.1 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833342044908072		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.05833342044908072 | validation: 0.060550885813918626]
	TIME [epoch: 9.1 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06864804658002502		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.06864804658002502 | validation: 0.06378955662865254]
	TIME [epoch: 9.1 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0841186627775524		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.0841186627775524 | validation: 0.09938996730686382]
	TIME [epoch: 9.11 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.09770375608276097		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.09770375608276097 | validation: 0.060313490876470706]
	TIME [epoch: 9.1 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04717491592843772		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.04717491592843772 | validation: 0.044840669338276753]
	TIME [epoch: 9.09 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04306283246550503		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.04306283246550503 | validation: 0.04666662747431241]
	TIME [epoch: 9.09 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049533770139705766		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.049533770139705766 | validation: 0.051086422364374676]
	TIME [epoch: 9.09 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043073082761648306		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.043073082761648306 | validation: 0.06293087250758435]
	TIME [epoch: 9.1 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043917765552310646		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.043917765552310646 | validation: 0.052668808096161174]
	TIME [epoch: 9.1 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05403985296127857		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.05403985296127857 | validation: 0.05571753303511894]
	TIME [epoch: 9.1 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04478427295368265		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.04478427295368265 | validation: 0.06706972016427595]
	TIME [epoch: 9.1 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05319938364520767		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.05319938364520767 | validation: 0.061394338505976]
	TIME [epoch: 9.09 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04813011064743652		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.04813011064743652 | validation: 0.055837111489907026]
	TIME [epoch: 9.11 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.08443732092051853		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.08443732092051853 | validation: 0.054839471830900904]
	TIME [epoch: 9.12 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049371778624834446		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.049371778624834446 | validation: 0.07797469418181388]
	TIME [epoch: 9.1 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040657789274107584		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.040657789274107584 | validation: 0.06665738502522109]
	TIME [epoch: 9.1 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06234667101312598		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.06234667101312598 | validation: 0.06620790409173435]
	TIME [epoch: 9.1 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0460354532925519		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.0460354532925519 | validation: 0.08746362497445645]
	TIME [epoch: 9.1 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051593804045181366		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.051593804045181366 | validation: 0.049541214715562845]
	TIME [epoch: 9.12 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0494224261350271		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.0494224261350271 | validation: 0.041760943671044076]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_690.pth
	Model improved!!!
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042550543039901516		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.042550543039901516 | validation: 0.07063382134156478]
	TIME [epoch: 9.1 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04947487304503734		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.04947487304503734 | validation: 0.051484736452686544]
	TIME [epoch: 9.09 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04317794149334657		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.04317794149334657 | validation: 0.06918126759351043]
	TIME [epoch: 9.1 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04744576492749869		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.04744576492749869 | validation: 0.04600754959555112]
	TIME [epoch: 9.11 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053400967734647274		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.053400967734647274 | validation: 0.08588929794928463]
	TIME [epoch: 9.09 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.07078467210216736		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.07078467210216736 | validation: 0.05301365728254166]
	TIME [epoch: 9.09 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04889315360342765		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.04889315360342765 | validation: 0.04168158480043861]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_697.pth
	Model improved!!!
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05421356857969025		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.05421356857969025 | validation: 0.06322065312669278]
	TIME [epoch: 9.09 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.058525422940548855		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.058525422940548855 | validation: 0.04158138430834982]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_699.pth
	Model improved!!!
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05916740283983267		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.05916740283983267 | validation: 0.062324672800500906]
	TIME [epoch: 9.09 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05729137394624221		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.05729137394624221 | validation: 0.08840075664284687]
	TIME [epoch: 9.09 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05554748788660766		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.05554748788660766 | validation: 0.06804623753977415]
	TIME [epoch: 9.08 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.046554704363634035		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.046554704363634035 | validation: 0.06873678628053462]
	TIME [epoch: 9.09 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054642223746823926		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.054642223746823926 | validation: 0.06896271632465965]
	TIME [epoch: 9.11 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04785534133483081		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.04785534133483081 | validation: 0.04175654065326128]
	TIME [epoch: 9.08 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052867633165543285		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.052867633165543285 | validation: 0.055157136876544]
	TIME [epoch: 9.08 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05526173933583067		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.05526173933583067 | validation: 0.056767131968061754]
	TIME [epoch: 9.09 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04832547768739921		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.04832547768739921 | validation: 0.06157277478499461]
	TIME [epoch: 9.09 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040760400163320096		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.040760400163320096 | validation: 0.057684243303700304]
	TIME [epoch: 9.1 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04967113824118259		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.04967113824118259 | validation: 0.0664063656032457]
	TIME [epoch: 9.1 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.041193745135618916		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.041193745135618916 | validation: 0.049286989930745526]
	TIME [epoch: 9.09 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04245067520955072		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.04245067520955072 | validation: 0.06222480780913732]
	TIME [epoch: 9.1 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04123235046416499		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.04123235046416499 | validation: 0.07765439212143951]
	TIME [epoch: 9.1 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0540700278732487		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.0540700278732487 | validation: 0.052798214617050546]
	TIME [epoch: 9.1 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047309672189193006		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.047309672189193006 | validation: 0.06996249471034131]
	TIME [epoch: 9.08 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04705713301933576		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.04705713301933576 | validation: 0.0667645261699746]
	TIME [epoch: 9.09 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04804838963058858		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.04804838963058858 | validation: 0.05405204708006432]
	TIME [epoch: 9.1 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06386380831994323		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.06386380831994323 | validation: 0.07170631523964624]
	TIME [epoch: 9.1 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04107072883502371		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.04107072883502371 | validation: 0.06192239878879693]
	TIME [epoch: 9.11 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04387800483032321		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.04387800483032321 | validation: 0.060799606794511185]
	TIME [epoch: 9.09 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04374170334738521		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.04374170334738521 | validation: 0.05308181357614648]
	TIME [epoch: 9.08 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0563514679118592		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.0563514679118592 | validation: 0.056876740373713354]
	TIME [epoch: 9.08 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05493425170058105		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.05493425170058105 | validation: 0.08934042732770636]
	TIME [epoch: 9.11 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.053090315769051113		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.053090315769051113 | validation: 0.04663363383646657]
	TIME [epoch: 9.1 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04073821314999326		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.04073821314999326 | validation: 0.050403812514520085]
	TIME [epoch: 9.09 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.041926191369323566		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.041926191369323566 | validation: 0.04367364352759781]
	TIME [epoch: 9.08 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04342929511600942		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.04342929511600942 | validation: 0.0643720579754554]
	TIME [epoch: 9.09 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04423948575068892		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.04423948575068892 | validation: 0.04111394362735013]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_728.pth
	Model improved!!!
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05160874872925013		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.05160874872925013 | validation: 0.05491759707564055]
	TIME [epoch: 9.11 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04739224552488233		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.04739224552488233 | validation: 0.0723291785043433]
	TIME [epoch: 9.1 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.06556358896485803		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.06556358896485803 | validation: 0.06043122232288624]
	TIME [epoch: 9.08 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04426565493477547		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.04426565493477547 | validation: 0.06375107695846047]
	TIME [epoch: 9.08 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04300855437647516		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.04300855437647516 | validation: 0.05914064813658382]
	TIME [epoch: 9.1 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05680654762547842		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.05680654762547842 | validation: 0.06122664942471496]
	TIME [epoch: 9.09 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045501896663803776		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.045501896663803776 | validation: 0.051950126155781665]
	TIME [epoch: 9.08 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0458054888204125		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.0458054888204125 | validation: 0.05269449904526667]
	TIME [epoch: 9.09 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05364840318501065		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.05364840318501065 | validation: 0.04526189895835618]
	TIME [epoch: 9.1 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0373638896778206		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.0373638896778206 | validation: 0.0495938305211079]
	TIME [epoch: 9.12 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05557433565622707		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.05557433565622707 | validation: 0.07966481016493998]
	TIME [epoch: 9.09 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.041960220160127376		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.041960220160127376 | validation: 0.03691055741982242]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_740.pth
	Model improved!!!
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04361367409476891		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.04361367409476891 | validation: 0.05697126523342194]
	TIME [epoch: 9.08 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04906512854363794		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.04906512854363794 | validation: 0.05929560425199089]
	TIME [epoch: 9.09 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0447898327303277		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.0447898327303277 | validation: 0.0408381546034548]
	TIME [epoch: 9.11 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03976410887119551		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.03976410887119551 | validation: 0.04439014899868192]
	TIME [epoch: 9.09 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03897453548319301		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.03897453548319301 | validation: 0.05109706461979136]
	TIME [epoch: 9.09 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04613901686924538		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.04613901686924538 | validation: 0.06345956211490561]
	TIME [epoch: 9.08 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0401286731107733		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.0401286731107733 | validation: 0.05054958347383536]
	TIME [epoch: 9.08 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045340929835905826		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.045340929835905826 | validation: 0.047675061914617296]
	TIME [epoch: 9.1 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03629093717519173		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.03629093717519173 | validation: 0.047273553698245985]
	TIME [epoch: 9.08 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044973944056832395		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.044973944056832395 | validation: 0.05542968642381653]
	TIME [epoch: 9.1 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04281465526573967		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.04281465526573967 | validation: 0.0583204389721258]
	TIME [epoch: 9.09 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04883937553181801		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.04883937553181801 | validation: 0.0590691577558759]
	TIME [epoch: 9.09 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051062272457781055		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.051062272457781055 | validation: 0.061698055746585684]
	TIME [epoch: 9.11 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05026946481998009		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.05026946481998009 | validation: 0.06398622880987247]
	TIME [epoch: 9.08 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04621946658946851		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.04621946658946851 | validation: 0.051148157240026096]
	TIME [epoch: 9.08 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04761621188197645		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.04761621188197645 | validation: 0.07015090624942164]
	TIME [epoch: 9.08 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0550731733518381		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.0550731733518381 | validation: 0.08878106321758228]
	TIME [epoch: 9.08 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047372769749170145		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.047372769749170145 | validation: 0.0470939944916957]
	TIME [epoch: 9.11 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0444221638150263		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.0444221638150263 | validation: 0.05109459615078947]
	TIME [epoch: 9.09 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0425645873343661		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.0425645873343661 | validation: 0.04298742563378286]
	TIME [epoch: 9.08 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042001043445257534		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.042001043445257534 | validation: 0.06695887545300895]
	TIME [epoch: 9.08 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04431930279774056		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.04431930279774056 | validation: 0.05300767975688546]
	TIME [epoch: 9.08 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04126963511783713		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.04126963511783713 | validation: 0.05146592842290168]
	TIME [epoch: 9.11 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035419345837353164		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.035419345837353164 | validation: 0.05023097243901443]
	TIME [epoch: 9.09 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03769577123988148		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.03769577123988148 | validation: 0.05157125668543941]
	TIME [epoch: 9.09 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03792266863781217		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.03792266863781217 | validation: 0.0458066450572205]
	TIME [epoch: 9.08 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045843209932336246		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.045843209932336246 | validation: 0.061469520697100016]
	TIME [epoch: 9.08 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05940840326115031		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.05940840326115031 | validation: 0.06298147859110523]
	TIME [epoch: 9.11 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038331737548967584		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.038331737548967584 | validation: 0.054419689540708735]
	TIME [epoch: 9.09 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.054656008289747246		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.054656008289747246 | validation: 0.050058496064679985]
	TIME [epoch: 9.09 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05395027111259981		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.05395027111259981 | validation: 0.05772997590719102]
	TIME [epoch: 9.09 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04747002834997992		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.04747002834997992 | validation: 0.05487780445395443]
	TIME [epoch: 9.08 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0407573124663437		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.0407573124663437 | validation: 0.05223309384734423]
	TIME [epoch: 9.11 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045023028577668954		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.045023028577668954 | validation: 0.06167448447634616]
	TIME [epoch: 9.09 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04926986824251563		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.04926986824251563 | validation: 0.0473628901610324]
	TIME [epoch: 9.1 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.050681567684760065		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.050681567684760065 | validation: 0.050490072563868574]
	TIME [epoch: 9.11 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043218435772165026		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.043218435772165026 | validation: 0.05296323919962741]
	TIME [epoch: 9.1 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04402163800642177		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.04402163800642177 | validation: 0.039356791890896914]
	TIME [epoch: 9.13 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0477500291402155		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.0477500291402155 | validation: 0.054938685396228815]
	TIME [epoch: 9.09 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03847285986352877		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.03847285986352877 | validation: 0.06467202418668935]
	TIME [epoch: 9.09 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05686543412769686		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.05686543412769686 | validation: 0.057079491110488795]
	TIME [epoch: 9.09 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04093482034373131		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.04093482034373131 | validation: 0.049326650599335414]
	TIME [epoch: 9.09 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04677718627521191		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.04677718627521191 | validation: 0.048362819476571006]
	TIME [epoch: 9.12 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040183429350804115		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.040183429350804115 | validation: 0.04685260672299957]
	TIME [epoch: 9.1 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03627240503369001		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.03627240503369001 | validation: 0.048591306704403384]
	TIME [epoch: 9.09 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03986241488953465		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.03986241488953465 | validation: 0.045381482505286716]
	TIME [epoch: 9.1 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047059439598837016		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.047059439598837016 | validation: 0.0533470307297948]
	TIME [epoch: 9.09 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04626341997624435		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.04626341997624435 | validation: 0.05296579010570883]
	TIME [epoch: 9.12 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04332008012052779		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.04332008012052779 | validation: 0.044953469282339176]
	TIME [epoch: 9.11 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034807669189139016		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.034807669189139016 | validation: 0.04841751764994828]
	TIME [epoch: 9.1 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03992439640887829		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.03992439640887829 | validation: 0.05250668536982708]
	TIME [epoch: 9.1 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03974492824399004		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.03974492824399004 | validation: 0.059728651988748487]
	TIME [epoch: 9.09 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.049675922328251396		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.049675922328251396 | validation: 0.06147864133273593]
	TIME [epoch: 9.12 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044159277048148704		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.044159277048148704 | validation: 0.05173989389976502]
	TIME [epoch: 9.09 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044253632384578065		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.044253632384578065 | validation: 0.06329803676455134]
	TIME [epoch: 9.08 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04071741129724633		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.04071741129724633 | validation: 0.04655357176250466]
	TIME [epoch: 9.09 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05070705119958676		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.05070705119958676 | validation: 0.061922375890794724]
	TIME [epoch: 9.09 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039290530895299186		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.039290530895299186 | validation: 0.044469078985367894]
	TIME [epoch: 9.11 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05254938186825562		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.05254938186825562 | validation: 0.04759198200974675]
	TIME [epoch: 9.09 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04227814342550495		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.04227814342550495 | validation: 0.04474533106433713]
	TIME [epoch: 9.08 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03797688081323704		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.03797688081323704 | validation: 0.06264561900583954]
	TIME [epoch: 9.09 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04101408183393527		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.04101408183393527 | validation: 0.0677783053456815]
	TIME [epoch: 9.1 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044132285363124815		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.044132285363124815 | validation: 0.049878096378922945]
	TIME [epoch: 9.12 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0363696674307601		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.0363696674307601 | validation: 0.05735521261977036]
	TIME [epoch: 9.1 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04312572406970349		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.04312572406970349 | validation: 0.052066633165269535]
	TIME [epoch: 9.09 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03921749762194187		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.03921749762194187 | validation: 0.058672808063947555]
	TIME [epoch: 9.09 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044636096069298505		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.044636096069298505 | validation: 0.05253141322272148]
	TIME [epoch: 9.08 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04409153764877188		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.04409153764877188 | validation: 0.049687694423979974]
	TIME [epoch: 9.11 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037106961275206775		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.037106961275206775 | validation: 0.06140039121614567]
	TIME [epoch: 9.09 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04743718884624372		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.04743718884624372 | validation: 0.07184903005222275]
	TIME [epoch: 9.08 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05336315575770114		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.05336315575770114 | validation: 0.07699462770307974]
	TIME [epoch: 9.09 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05289889694112314		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.05289889694112314 | validation: 0.0654192917366603]
	TIME [epoch: 9.08 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04360588912823042		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.04360588912823042 | validation: 0.05169531301265784]
	TIME [epoch: 9.11 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.043989736112830066		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.043989736112830066 | validation: 0.054495212658019765]
	TIME [epoch: 9.09 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03939733537693255		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.03939733537693255 | validation: 0.05264363066634811]
	TIME [epoch: 9.09 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04148614934701143		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.04148614934701143 | validation: 0.044886392533355274]
	TIME [epoch: 9.09 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03772224602295045		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.03772224602295045 | validation: 0.04117635716296816]
	TIME [epoch: 9.1 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04376262939616818		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.04376262939616818 | validation: 0.05007195436737709]
	TIME [epoch: 9.11 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03728538383612107		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.03728538383612107 | validation: 0.0531206662111976]
	TIME [epoch: 9.09 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03914124914970113		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.03914124914970113 | validation: 0.054338579903925634]
	TIME [epoch: 9.08 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0450010199844728		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.0450010199844728 | validation: 0.08191269538060687]
	TIME [epoch: 9.09 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04929808486200433		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.04929808486200433 | validation: 0.047846353147564274]
	TIME [epoch: 9.09 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03636054837574464		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.03636054837574464 | validation: 0.03986179608795766]
	TIME [epoch: 9.09 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03254814211025364		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.03254814211025364 | validation: 0.040734008823319706]
	TIME [epoch: 9.09 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04864216099339689		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.04864216099339689 | validation: 0.064987722576313]
	TIME [epoch: 9.08 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04937589712419814		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.04937589712419814 | validation: 0.04800162023710852]
	TIME [epoch: 9.08 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04536544092036834		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.04536544092036834 | validation: 0.056556057370898104]
	TIME [epoch: 9.09 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.052777649469913424		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.052777649469913424 | validation: 0.03920366973795529]
	TIME [epoch: 9.1 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04588393597715289		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.04588393597715289 | validation: 0.0513577518355713]
	TIME [epoch: 9.09 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04752608597910708		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.04752608597910708 | validation: 0.08303942115929672]
	TIME [epoch: 9.08 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04899513647777913		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.04899513647777913 | validation: 0.04817569049957851]
	TIME [epoch: 9.09 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042289608507981254		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.042289608507981254 | validation: 0.04154543150425642]
	TIME [epoch: 9.08 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040828316150267045		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.040828316150267045 | validation: 0.04966990742439081]
	TIME [epoch: 9.09 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04172415060960368		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.04172415060960368 | validation: 0.04570259112751001]
	TIME [epoch: 9.09 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04004158994836077		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.04004158994836077 | validation: 0.04353250100118203]
	TIME [epoch: 9.09 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03379420737220436		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.03379420737220436 | validation: 0.052422193558481406]
	TIME [epoch: 9.08 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.044012495937262155		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.044012495937262155 | validation: 0.048254471401473834]
	TIME [epoch: 9.08 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.05340527825520519		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.05340527825520519 | validation: 0.060258535290429405]
	TIME [epoch: 9.1 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045286352058922924		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.045286352058922924 | validation: 0.0460387632185928]
	TIME [epoch: 9.08 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03833786354508488		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.03833786354508488 | validation: 0.04812864572265703]
	TIME [epoch: 9.08 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04276566814297752		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.04276566814297752 | validation: 0.04221803111468862]
	TIME [epoch: 9.08 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.029555074701846217		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.029555074701846217 | validation: 0.055711114959885594]
	TIME [epoch: 9.1 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040304786373223836		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.040304786373223836 | validation: 0.05438784695950251]
	TIME [epoch: 9.12 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04227898333323482		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.04227898333323482 | validation: 0.05238324350013304]
	TIME [epoch: 9.09 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035210183663343345		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.035210183663343345 | validation: 0.04728456666455068]
	TIME [epoch: 9.08 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04270630060720525		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.04270630060720525 | validation: 0.049475550713210664]
	TIME [epoch: 9.08 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04738218424336355		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.04738218424336355 | validation: 0.05297585013916606]
	TIME [epoch: 9.08 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040134581498354575		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.040134581498354575 | validation: 0.04084428651963348]
	TIME [epoch: 9.1 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037878542107642535		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.037878542107642535 | validation: 0.04074608614325538]
	TIME [epoch: 9.1 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03956110692264224		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.03956110692264224 | validation: 0.03789124767771452]
	TIME [epoch: 9.08 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037204615271753186		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.037204615271753186 | validation: 0.05214350325586037]
	TIME [epoch: 9.08 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03754200578633924		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.03754200578633924 | validation: 0.05863664657532742]
	TIME [epoch: 9.09 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.041262839197185965		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.041262839197185965 | validation: 0.05592666319791359]
	TIME [epoch: 9.11 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0376087241284905		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.0376087241284905 | validation: 0.05880755147998217]
	TIME [epoch: 9.09 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04027051933939517		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.04027051933939517 | validation: 0.0492041917492758]
	TIME [epoch: 9.09 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037646712308738686		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.037646712308738686 | validation: 0.0512291699389122]
	TIME [epoch: 9.08 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042599642143785726		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.042599642143785726 | validation: 0.04501103123961786]
	TIME [epoch: 9.1 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.045260909001507046		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.045260909001507046 | validation: 0.05642651017215278]
	TIME [epoch: 9.11 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.046135375811434884		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.046135375811434884 | validation: 0.04150914468992506]
	TIME [epoch: 9.09 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03822166853599775		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.03822166853599775 | validation: 0.04600607186407109]
	TIME [epoch: 9.09 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03723358196524505		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.03723358196524505 | validation: 0.051883588656751294]
	TIME [epoch: 9.08 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036844403556781376		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.036844403556781376 | validation: 0.05262280003837745]
	TIME [epoch: 9.08 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04295982658198012		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.04295982658198012 | validation: 0.05624760148481779]
	TIME [epoch: 9.11 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042817620416060256		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.042817620416060256 | validation: 0.04598779386672902]
	TIME [epoch: 9.09 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03508262269149855		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.03508262269149855 | validation: 0.04635866953572911]
	TIME [epoch: 9.08 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04269545220672456		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.04269545220672456 | validation: 0.06495458765441495]
	TIME [epoch: 9.08 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042905639890123595		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.042905639890123595 | validation: 0.04482391145735605]
	TIME [epoch: 9.09 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03246277495656961		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.03246277495656961 | validation: 0.053734301558416325]
	TIME [epoch: 9.11 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04056323709977991		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.04056323709977991 | validation: 0.05179973879472948]
	TIME [epoch: 9.09 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042170431366858455		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.042170431366858455 | validation: 0.043204656253570776]
	TIME [epoch: 9.09 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872273898593502		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.03872273898593502 | validation: 0.05222675764706468]
	TIME [epoch: 9.09 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040613815701142565		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.040613815701142565 | validation: 0.054893053575025184]
	TIME [epoch: 9.08 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03670720177809743		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.03670720177809743 | validation: 0.044435052407931164]
	TIME [epoch: 9.11 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035961875244857854		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.035961875244857854 | validation: 0.06377217787601247]
	TIME [epoch: 9.08 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04780980905077627		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.04780980905077627 | validation: 0.055682366579041645]
	TIME [epoch: 9.09 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04010502560907544		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.04010502560907544 | validation: 0.04500266161705983]
	TIME [epoch: 9.08 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034295030247792915		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.034295030247792915 | validation: 0.06151497267006671]
	TIME [epoch: 9.09 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.046955864120616246		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.046955864120616246 | validation: 0.04713655778398822]
	TIME [epoch: 9.12 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033604672750784825		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.033604672750784825 | validation: 0.057489977705385234]
	TIME [epoch: 9.09 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03621284197402007		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.03621284197402007 | validation: 0.044588679862546735]
	TIME [epoch: 9.08 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042924041849783025		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.042924041849783025 | validation: 0.04188384350755342]
	TIME [epoch: 9.08 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03598606680019457		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.03598606680019457 | validation: 0.04500663673642161]
	TIME [epoch: 9.09 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0409041729556905		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.0409041729556905 | validation: 0.04652311271419382]
	TIME [epoch: 9.12 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0397146353367581		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.0397146353367581 | validation: 0.04400232339825866]
	TIME [epoch: 9.09 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040712183677025296		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.040712183677025296 | validation: 0.046151290109961635]
	TIME [epoch: 9.08 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03521420020639327		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.03521420020639327 | validation: 0.056656151499308235]
	TIME [epoch: 9.07 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04549857084579242		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.04549857084579242 | validation: 0.06942826745302152]
	TIME [epoch: 9.08 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.051059040842719824		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.051059040842719824 | validation: 0.03980223728265671]
	TIME [epoch: 9.11 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03811435454074587		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.03811435454074587 | validation: 0.04148528046361104]
	TIME [epoch: 9.08 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038858977896437524		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.038858977896437524 | validation: 0.05636719647091812]
	TIME [epoch: 9.08 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042347631941976896		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.042347631941976896 | validation: 0.05356260302645388]
	TIME [epoch: 9.09 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04339062219245778		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.04339062219245778 | validation: 0.05338336165053241]
	TIME [epoch: 9.08 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03296058001197677		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.03296058001197677 | validation: 0.04465294212479583]
	TIME [epoch: 9.1 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03875563930004376		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.03875563930004376 | validation: 0.0657370874641199]
	TIME [epoch: 9.09 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.042031997795590206		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.042031997795590206 | validation: 0.0535494615763355]
	TIME [epoch: 9.1 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040436261388535254		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.040436261388535254 | validation: 0.0407533202740454]
	TIME [epoch: 9.09 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03483393612175702		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.03483393612175702 | validation: 0.0492266767550272]
	TIME [epoch: 9.09 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039215390952641885		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.039215390952641885 | validation: 0.04554225858812111]
	TIME [epoch: 9.11 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036759637510957864		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.036759637510957864 | validation: 0.05643943126961624]
	TIME [epoch: 9.08 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03677230057347566		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.03677230057347566 | validation: 0.03815063471344511]
	TIME [epoch: 9.09 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03560017182614436		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.03560017182614436 | validation: 0.052497779955217594]
	TIME [epoch: 9.09 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.047608605139231944		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.047608605139231944 | validation: 0.054297817775435644]
	TIME [epoch: 9.08 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033983124234708374		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.033983124234708374 | validation: 0.04443569501091307]
	TIME [epoch: 9.12 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033161857684694186		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.033161857684694186 | validation: 0.04762017885692333]
	TIME [epoch: 9.08 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03711438518075383		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.03711438518075383 | validation: 0.046601385422381986]
	TIME [epoch: 9.09 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034333851931581616		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.034333851931581616 | validation: 0.04524110848612854]
	TIME [epoch: 9.08 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0397907772393919		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.0397907772393919 | validation: 0.03991031029838554]
	TIME [epoch: 9.09 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0331054117364891		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.0331054117364891 | validation: 0.054069162040537355]
	TIME [epoch: 9.12 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0324352654207168		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.0324352654207168 | validation: 0.039769206126680265]
	TIME [epoch: 9.09 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04491171927003944		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.04491171927003944 | validation: 0.05396872386809293]
	TIME [epoch: 9.09 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03631249194938509		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.03631249194938509 | validation: 0.045751225627016556]
	TIME [epoch: 9.08 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036627833457398354		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.036627833457398354 | validation: 0.0502538688199752]
	TIME [epoch: 9.08 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039874795990044135		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.039874795990044135 | validation: 0.052531076770450456]
	TIME [epoch: 9.1 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03818093456226265		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.03818093456226265 | validation: 0.0652654218827022]
	TIME [epoch: 9.09 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0361447622377055		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.0361447622377055 | validation: 0.04372333662744206]
	TIME [epoch: 9.09 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03833033710538249		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.03833033710538249 | validation: 0.04944751763929991]
	TIME [epoch: 9.08 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04216088664871982		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.04216088664871982 | validation: 0.05075434324969824]
	TIME [epoch: 9.08 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03532553642056668		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.03532553642056668 | validation: 0.041808104499969016]
	TIME [epoch: 9.12 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039978899923911425		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.039978899923911425 | validation: 0.04315615135786685]
	TIME [epoch: 9.08 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03681947942347431		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.03681947942347431 | validation: 0.04138645206172681]
	TIME [epoch: 9.08 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03358164232185453		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.03358164232185453 | validation: 0.04065930645635024]
	TIME [epoch: 9.09 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03029332387991689		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.03029332387991689 | validation: 0.04595827377153923]
	TIME [epoch: 9.08 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03457752131094672		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.03457752131094672 | validation: 0.05008443180388408]
	TIME [epoch: 9.11 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04185915944484171		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.04185915944484171 | validation: 0.04431804685167161]
	TIME [epoch: 9.08 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03567019720891079		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.03567019720891079 | validation: 0.048295054567369544]
	TIME [epoch: 9.08 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03526825939303345		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.03526825939303345 | validation: 0.04694330723168036]
	TIME [epoch: 9.08 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04118716655800306		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.04118716655800306 | validation: 0.053642242704928796]
	TIME [epoch: 9.08 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.048987026230769594		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.048987026230769594 | validation: 0.0456185381318359]
	TIME [epoch: 9.11 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040844893870023144		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.040844893870023144 | validation: 0.05099643283682765]
	TIME [epoch: 9.08 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035445254059481526		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.035445254059481526 | validation: 0.044435283849909975]
	TIME [epoch: 9.08 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033355210757228027		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.033355210757228027 | validation: 0.0500397035392518]
	TIME [epoch: 9.08 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03138835537801367		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.03138835537801367 | validation: 0.05722389143449267]
	TIME [epoch: 9.08 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03508520451192668		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.03508520451192668 | validation: 0.050879287348990276]
	TIME [epoch: 9.11 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04438430429492744		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.04438430429492744 | validation: 0.0424930874514809]
	TIME [epoch: 9.08 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03973471329464551		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.03973471329464551 | validation: 0.04172293366484217]
	TIME [epoch: 9.08 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03696525029260385		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.03696525029260385 | validation: 0.043276337200712084]
	TIME [epoch: 9.08 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034465789560860834		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.034465789560860834 | validation: 0.04751843379709499]
	TIME [epoch: 9.08 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03869178805167245		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.03869178805167245 | validation: 0.046401556806740574]
	TIME [epoch: 9.1 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0389284716358785		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.0389284716358785 | validation: 0.05049651867173553]
	TIME [epoch: 9.09 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.037083793090000934		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.037083793090000934 | validation: 0.0500781770472104]
	TIME [epoch: 9.09 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03336998245080275		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.03336998245080275 | validation: 0.048715483195258195]
	TIME [epoch: 9.09 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04004882645855342		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.04004882645855342 | validation: 0.04558890131387426]
	TIME [epoch: 9.08 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03743599284263399		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.03743599284263399 | validation: 0.04051243927211205]
	TIME [epoch: 9.11 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03713959652327097		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.03713959652327097 | validation: 0.04033083465524841]
	TIME [epoch: 9.09 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03855653887665854		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.03855653887665854 | validation: 0.05200108657544981]
	TIME [epoch: 9.08 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038315956814088115		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.038315956814088115 | validation: 0.028450503663161188]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r0_20240217_161441/states/model_tr_study4_946.pth
	Model improved!!!
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033496969791111095		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.033496969791111095 | validation: 0.05631028449432514]
	TIME [epoch: 9.09 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038409415465129944		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.038409415465129944 | validation: 0.04965327057507674]
	TIME [epoch: 9.09 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03928954794888541		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.03928954794888541 | validation: 0.04535730974034853]
	TIME [epoch: 9.08 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036819161234834544		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.036819161234834544 | validation: 0.046007497292500546]
	TIME [epoch: 9.07 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03687978590664467		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.03687978590664467 | validation: 0.042949661029857006]
	TIME [epoch: 9.08 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.032939589127352134		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.032939589127352134 | validation: 0.06204221702734046]
	TIME [epoch: 9.08 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03591179151115059		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.03591179151115059 | validation: 0.03911757172600651]
	TIME [epoch: 9.09 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03333184784288808		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.03333184784288808 | validation: 0.053717477404236075]
	TIME [epoch: 9.08 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03368602809547932		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.03368602809547932 | validation: 0.03717685433482392]
	TIME [epoch: 9.08 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04431204414041138		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.04431204414041138 | validation: 0.04754848145601973]
	TIME [epoch: 9.09 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03429212440364793		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.03429212440364793 | validation: 0.039538713919560785]
	TIME [epoch: 9.09 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03622338501922745		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.03622338501922745 | validation: 0.05349809493505803]
	TIME [epoch: 9.1 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03928966971400978		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.03928966971400978 | validation: 0.046106909436873234]
	TIME [epoch: 9.08 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.036217331678966055		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.036217331678966055 | validation: 0.039762958015339064]
	TIME [epoch: 9.09 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.032973423775187194		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.032973423775187194 | validation: 0.03606191331368677]
	TIME [epoch: 9.08 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03859740318744113		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.03859740318744113 | validation: 0.03854581606835446]
	TIME [epoch: 9.09 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04041507998307211		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.04041507998307211 | validation: 0.05272104235503763]
	TIME [epoch: 9.1 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03831472835905271		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.03831472835905271 | validation: 0.05297390154147767]
	TIME [epoch: 9.07 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039317568694264546		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.039317568694264546 | validation: 0.04291498760815961]
	TIME [epoch: 9.08 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.030416950062665392		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.030416950062665392 | validation: 0.04207273880615945]
	TIME [epoch: 9.09 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040519126052834094		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.040519126052834094 | validation: 0.04712397680399316]
	TIME [epoch: 9.09 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.038854443143349945		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.038854443143349945 | validation: 0.04398814418146117]
	TIME [epoch: 9.1 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03429072062880257		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.03429072062880257 | validation: 0.050267142822525604]
	TIME [epoch: 9.09 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03757299746237325		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.03757299746237325 | validation: 0.04890243272124273]
	TIME [epoch: 9.08 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.040762156953456516		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.040762156953456516 | validation: 0.04065338534680503]
	TIME [epoch: 9.08 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034144126343018714		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.034144126343018714 | validation: 0.03982450781672847]
	TIME [epoch: 9.08 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03274899317100473		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.03274899317100473 | validation: 0.0538254291802724]
	TIME [epoch: 9.1 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03582154974155932		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.03582154974155932 | validation: 0.051749682495340246]
	TIME [epoch: 9.1 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03190880871774465		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.03190880871774465 | validation: 0.043134594272537095]
	TIME [epoch: 9.1 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03712967272293656		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.03712967272293656 | validation: 0.05116293306199404]
	TIME [epoch: 9.09 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03413660805418116		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.03413660805418116 | validation: 0.04182648795131677]
	TIME [epoch: 9.09 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03402959325517947		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.03402959325517947 | validation: 0.04534115350511493]
	TIME [epoch: 9.1 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.033734774896433055		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.033734774896433055 | validation: 0.04062908522841016]
	TIME [epoch: 9.09 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03170086968207668		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.03170086968207668 | validation: 0.0431964383896247]
	TIME [epoch: 9.09 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04069580266507743		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.04069580266507743 | validation: 0.04434346609351904]
	TIME [epoch: 9.08 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.04163525622423906		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.04163525622423906 | validation: 0.04105569854140868]
	TIME [epoch: 9.09 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03415540054421756		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.03415540054421756 | validation: 0.046115542890647385]
	TIME [epoch: 9.1 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03274912465591191		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.03274912465591191 | validation: 0.038252010531948134]
	TIME [epoch: 9.09 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03931089153672369		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.03931089153672369 | validation: 0.04545372307817093]
	TIME [epoch: 9.08 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03252157291513395		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.03252157291513395 | validation: 0.04304896139264559]
	TIME [epoch: 9.09 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03435935783192698		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.03435935783192698 | validation: 0.0411780300992642]
	TIME [epoch: 9.1 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.035266243109075786		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.035266243109075786 | validation: 0.05294627572098419]
	TIME [epoch: 9.1 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034389404208265854		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.034389404208265854 | validation: 0.03957831967259233]
	TIME [epoch: 9.09 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03430827570259603		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.03430827570259603 | validation: 0.04349531276074761]
	TIME [epoch: 9.09 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03412214248326535		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.03412214248326535 | validation: 0.03542611199030336]
	TIME [epoch: 9.08 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03645194487583557		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.03645194487583557 | validation: 0.04478209699724283]
	TIME [epoch: 9.08 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03528026981901449		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.03528026981901449 | validation: 0.04317551498964466]
	TIME [epoch: 9.1 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03497477947587444		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.03497477947587444 | validation: 0.047390645489149445]
	TIME [epoch: 9.09 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.039765895176322744		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.039765895176322744 | validation: 0.04169628688985977]
	TIME [epoch: 9.07 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.034406522156617		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.034406522156617 | validation: 0.04144730479022771]
	TIME [epoch: 9.03 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03756501718103637		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.03756501718103637 | validation: 0.042308159153257724]
	TIME [epoch: 9.05 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03771587082009559		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.03771587082009559 | validation: 0.041642675856913]
	TIME [epoch: 9.05 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.03778050039470177		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.03778050039470177 | validation: 0.050951703072828654]
	TIME [epoch: 9.04 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.0315049527409843		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.0315049527409843 | validation: 0.03922088892259172]
	TIME [epoch: 9.05 sec]
Finished training in 9200.651 seconds.
