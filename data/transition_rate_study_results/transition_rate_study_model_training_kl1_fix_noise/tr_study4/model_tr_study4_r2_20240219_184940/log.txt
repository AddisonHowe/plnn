Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1664979047

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.975920463569214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.975920463569214 | validation: 8.295222871039531]
	TIME [epoch: 79.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.655742631838374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.655742631838374 | validation: 8.161020572786947]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.46261083360452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.46261083360452 | validation: 7.944784767650136]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.6886576630978425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6886576630978425 | validation: 5.120939055383128]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.788171597785193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.788171597785193 | validation: 4.814000676333544]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.659152293404363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.659152293404363 | validation: 4.932602936213362]
	TIME [epoch: 8.54 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.269957974715885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.269957974715885 | validation: 5.712117960461773]
	TIME [epoch: 8.53 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.393734966548799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.393734966548799 | validation: 4.671517736881791]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.405519893608202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.405519893608202 | validation: 5.367411642675772]
	TIME [epoch: 8.55 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.231486718938324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.231486718938324 | validation: 4.725112612499606]
	TIME [epoch: 8.55 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.067640747104575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.067640747104575 | validation: 5.674200292663096]
	TIME [epoch: 8.54 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.909116402358308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.909116402358308 | validation: 4.233466064187391]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.00635528656052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.00635528656052 | validation: 4.168525738674976]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.470957320419576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.470957320419576 | validation: 4.008068833708001]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.451412780383536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.451412780383536 | validation: 3.788867284590019]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.130535235698254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.130535235698254 | validation: 3.5813172462861003]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.98110418037552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.98110418037552 | validation: 3.6405056943937684]
	TIME [epoch: 8.54 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.937470608618303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.937470608618303 | validation: 3.522688556987249]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.621563107895507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.621563107895507 | validation: 3.1831064067816364]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.178096281386091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.178096281386091 | validation: 2.6440063525094573]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4177544004425053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4177544004425053 | validation: 1.7422986896663804]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.073630914271075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.073630914271075 | validation: 1.158692431965576]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9422882468014646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9422882468014646 | validation: 1.4399314346915695]
	TIME [epoch: 8.54 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.782261060337746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.782261060337746 | validation: 1.3439506861878456]
	TIME [epoch: 8.54 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0369500925325994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0369500925325994 | validation: 1.7906065501564157]
	TIME [epoch: 8.53 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8418655299182813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8418655299182813 | validation: 1.7386961381899577]
	TIME [epoch: 8.52 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9188627070451947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9188627070451947 | validation: 2.405126812148678]
	TIME [epoch: 8.54 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7201670045864603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7201670045864603 | validation: 2.7152536136786702]
	TIME [epoch: 8.54 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.10624007840118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.10624007840118 | validation: 1.7057845668329947]
	TIME [epoch: 8.53 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8910900674094815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8910900674094815 | validation: 1.4691399903055902]
	TIME [epoch: 8.52 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.526690364340594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.526690364340594 | validation: 1.066430711226527]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4720561445199531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4720561445199531 | validation: 1.4562800194901886]
	TIME [epoch: 8.53 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.665117064189759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.665117064189759 | validation: 2.713750955420533]
	TIME [epoch: 8.53 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9620045935384334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9620045935384334 | validation: 1.1330655863484034]
	TIME [epoch: 8.53 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6386083461848848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6386083461848848 | validation: 1.0948352145137754]
	TIME [epoch: 8.55 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.406226211506117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.406226211506117 | validation: 2.0513455635509716]
	TIME [epoch: 8.53 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7078154946957462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7078154946957462 | validation: 1.6415518712212598]
	TIME [epoch: 8.52 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4896812018705454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4896812018705454 | validation: 1.019348861986084]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0618900373306928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0618900373306928 | validation: 1.1601131847915302]
	TIME [epoch: 8.56 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3916816020594776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3916816020594776 | validation: 0.975740059993702]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.129757319828581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.129757319828581 | validation: 1.1184021806745055]
	TIME [epoch: 8.54 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0684131535596733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0684131535596733 | validation: 1.6564913354769062]
	TIME [epoch: 8.54 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.184447225278703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.184447225278703 | validation: 0.968981283313106]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0223627859955418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0223627859955418 | validation: 0.9132275920105344]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8541157804586674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8541157804586674 | validation: 0.8757888629856447]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0879982702218156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0879982702218156 | validation: 1.1574938036840776]
	TIME [epoch: 8.57 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9697718547715098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9697718547715098 | validation: 0.809719316286805]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7853528886746871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7853528886746871 | validation: 0.420471307606024]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4429013086507234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4429013086507234 | validation: 0.853943512120233]
	TIME [epoch: 8.55 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8909375885937209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8909375885937209 | validation: 0.880980645459225]
	TIME [epoch: 8.55 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7380614580811071		[learning rate: 0.0099788]
	Learning Rate: 0.00997877
	LOSS [training: 0.7380614580811071 | validation: 0.9326820736764596]
	TIME [epoch: 8.57 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8474326619881257		[learning rate: 0.0099552]
	Learning Rate: 0.00995523
	LOSS [training: 0.8474326619881257 | validation: 0.8844084371236078]
	TIME [epoch: 8.54 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7552118598430908		[learning rate: 0.0099317]
	Learning Rate: 0.00993175
	LOSS [training: 0.7552118598430908 | validation: 0.7384502629638533]
	TIME [epoch: 8.54 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7591448207136654		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 0.7591448207136654 | validation: 0.6181645328872067]
	TIME [epoch: 8.55 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9658936541611002		[learning rate: 0.0098849]
	Learning Rate: 0.00988495
	LOSS [training: 0.9658936541611002 | validation: 0.8099341787719639]
	TIME [epoch: 8.55 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0019366267432253		[learning rate: 0.0098616]
	Learning Rate: 0.00986163
	LOSS [training: 1.0019366267432253 | validation: 0.6711253277437879]
	TIME [epoch: 8.54 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7913397283589176		[learning rate: 0.0098384]
	Learning Rate: 0.00983837
	LOSS [training: 0.7913397283589176 | validation: 0.7985768107334256]
	TIME [epoch: 8.54 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.03926937079606		[learning rate: 0.0098152]
	Learning Rate: 0.00981516
	LOSS [training: 1.03926937079606 | validation: 0.6387753277731216]
	TIME [epoch: 8.56 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.783834478193819		[learning rate: 0.009792]
	Learning Rate: 0.00979201
	LOSS [training: 0.783834478193819 | validation: 0.6898687160870006]
	TIME [epoch: 8.56 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6653918346446809		[learning rate: 0.0097689]
	Learning Rate: 0.00976891
	LOSS [training: 0.6653918346446809 | validation: 0.4675744900588269]
	TIME [epoch: 8.54 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6340736181466446		[learning rate: 0.0097459]
	Learning Rate: 0.00974587
	LOSS [training: 0.6340736181466446 | validation: 0.594191194274358]
	TIME [epoch: 8.54 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8998079042747451		[learning rate: 0.0097229]
	Learning Rate: 0.00972288
	LOSS [training: 0.8998079042747451 | validation: 0.5496163023766931]
	TIME [epoch: 8.56 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6951419120192873		[learning rate: 0.0096999]
	Learning Rate: 0.00969994
	LOSS [training: 0.6951419120192873 | validation: 0.45818401690149724]
	TIME [epoch: 8.54 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.665372615122896		[learning rate: 0.0096771]
	Learning Rate: 0.00967706
	LOSS [training: 0.665372615122896 | validation: 1.2394161448601313]
	TIME [epoch: 8.54 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6342175261895154		[learning rate: 0.0096542]
	Learning Rate: 0.00965424
	LOSS [training: 0.6342175261895154 | validation: 0.6753744018327199]
	TIME [epoch: 8.54 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6813315283138415		[learning rate: 0.0096315]
	Learning Rate: 0.00963146
	LOSS [training: 0.6813315283138415 | validation: 0.5471001578066826]
	TIME [epoch: 8.56 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.609272360701348		[learning rate: 0.0096087]
	Learning Rate: 0.00960874
	LOSS [training: 0.609272360701348 | validation: 0.38983760308529203]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48396686254459126		[learning rate: 0.0095861]
	Learning Rate: 0.00958608
	LOSS [training: 0.48396686254459126 | validation: 0.30563536029777305]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4854257806532267		[learning rate: 0.0095635]
	Learning Rate: 0.00956347
	LOSS [training: 0.4854257806532267 | validation: 0.5720664026548521]
	TIME [epoch: 8.54 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6022004582280728		[learning rate: 0.0095409]
	Learning Rate: 0.00954091
	LOSS [training: 0.6022004582280728 | validation: 0.5372661880213354]
	TIME [epoch: 8.56 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6164353704510582		[learning rate: 0.0095184]
	Learning Rate: 0.0095184
	LOSS [training: 0.6164353704510582 | validation: 0.6363280981686343]
	TIME [epoch: 8.53 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8473061281698466		[learning rate: 0.009496]
	Learning Rate: 0.00949595
	LOSS [training: 0.8473061281698466 | validation: 1.227690671572058]
	TIME [epoch: 8.54 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.627307125562624		[learning rate: 0.0094736]
	Learning Rate: 0.00947355
	LOSS [training: 0.627307125562624 | validation: 0.9387975220526714]
	TIME [epoch: 8.53 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6464405946106235		[learning rate: 0.0094512]
	Learning Rate: 0.0094512
	LOSS [training: 0.6464405946106235 | validation: 0.8410568058800578]
	TIME [epoch: 8.56 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5516462473702165		[learning rate: 0.0094289]
	Learning Rate: 0.00942891
	LOSS [training: 0.5516462473702165 | validation: 0.6081872950150936]
	TIME [epoch: 8.53 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5734292576588014		[learning rate: 0.0094067]
	Learning Rate: 0.00940667
	LOSS [training: 0.5734292576588014 | validation: 0.7621467886889275]
	TIME [epoch: 8.54 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6451989259204753		[learning rate: 0.0093845]
	Learning Rate: 0.00938448
	LOSS [training: 0.6451989259204753 | validation: 0.598621100677247]
	TIME [epoch: 8.54 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.688377756016257		[learning rate: 0.0093623]
	Learning Rate: 0.00936234
	LOSS [training: 0.688377756016257 | validation: 0.48038870054066635]
	TIME [epoch: 8.56 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5477563161327023		[learning rate: 0.0093403]
	Learning Rate: 0.00934026
	LOSS [training: 0.5477563161327023 | validation: 0.5689149479283577]
	TIME [epoch: 8.54 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5829279802617171		[learning rate: 0.0093182]
	Learning Rate: 0.00931823
	LOSS [training: 0.5829279802617171 | validation: 0.6965318485701819]
	TIME [epoch: 8.53 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5773872112928263		[learning rate: 0.0092962]
	Learning Rate: 0.00929625
	LOSS [training: 0.5773872112928263 | validation: 0.5908186657284518]
	TIME [epoch: 8.55 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225684201491026		[learning rate: 0.0092743]
	Learning Rate: 0.00927432
	LOSS [training: 0.6225684201491026 | validation: 0.5858031263849559]
	TIME [epoch: 8.55 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5130334596645525		[learning rate: 0.0092524]
	Learning Rate: 0.00925244
	LOSS [training: 0.5130334596645525 | validation: 0.3768354453114582]
	TIME [epoch: 8.54 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5011127041807153		[learning rate: 0.0092306]
	Learning Rate: 0.00923062
	LOSS [training: 0.5011127041807153 | validation: 0.37966871093982496]
	TIME [epoch: 8.54 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4951266581441508		[learning rate: 0.0092088]
	Learning Rate: 0.00920884
	LOSS [training: 0.4951266581441508 | validation: 0.8633502528033228]
	TIME [epoch: 8.55 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5871358495343033		[learning rate: 0.0091871]
	Learning Rate: 0.00918712
	LOSS [training: 0.5871358495343033 | validation: 0.88131186520945]
	TIME [epoch: 8.55 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7582589764575414		[learning rate: 0.0091655]
	Learning Rate: 0.00916545
	LOSS [training: 0.7582589764575414 | validation: 1.1828444135830165]
	TIME [epoch: 8.54 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6636569957999967		[learning rate: 0.0091438]
	Learning Rate: 0.00914383
	LOSS [training: 0.6636569957999967 | validation: 0.6158486254404502]
	TIME [epoch: 8.53 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6102947047809277		[learning rate: 0.0091223]
	Learning Rate: 0.00912226
	LOSS [training: 0.6102947047809277 | validation: 0.4615656534782443]
	TIME [epoch: 8.55 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4913965574384497		[learning rate: 0.0091007]
	Learning Rate: 0.00910074
	LOSS [training: 0.4913965574384497 | validation: 0.5262707652472804]
	TIME [epoch: 8.54 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5212735679712959		[learning rate: 0.0090793]
	Learning Rate: 0.00907928
	LOSS [training: 0.5212735679712959 | validation: 0.4357316404000209]
	TIME [epoch: 8.53 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4837391745452254		[learning rate: 0.0090579]
	Learning Rate: 0.00905786
	LOSS [training: 0.4837391745452254 | validation: 0.43220244914841177]
	TIME [epoch: 8.53 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463487017088696		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.5463487017088696 | validation: 0.5262922701405399]
	TIME [epoch: 8.56 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5124900265281853		[learning rate: 0.0090152]
	Learning Rate: 0.00901518
	LOSS [training: 0.5124900265281853 | validation: 0.3829789525011347]
	TIME [epoch: 8.54 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6296376784443647		[learning rate: 0.0089939]
	Learning Rate: 0.00899391
	LOSS [training: 0.6296376784443647 | validation: 0.4056076543959302]
	TIME [epoch: 8.53 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5725644732929651		[learning rate: 0.0089727]
	Learning Rate: 0.0089727
	LOSS [training: 0.5725644732929651 | validation: 0.5346009714414028]
	TIME [epoch: 8.53 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4342285154474741		[learning rate: 0.0089515]
	Learning Rate: 0.00895153
	LOSS [training: 0.4342285154474741 | validation: 0.41699810547023286]
	TIME [epoch: 8.56 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4133584318583325		[learning rate: 0.0089304]
	Learning Rate: 0.00893042
	LOSS [training: 0.4133584318583325 | validation: 0.7213343594279552]
	TIME [epoch: 8.54 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5492334276405475		[learning rate: 0.0089094]
	Learning Rate: 0.00890935
	LOSS [training: 0.5492334276405475 | validation: 1.014000726762006]
	TIME [epoch: 8.53 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5674908480657543		[learning rate: 0.0088883]
	Learning Rate: 0.00888834
	LOSS [training: 0.5674908480657543 | validation: 0.30160256835862786]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5004440027311026		[learning rate: 0.0088674]
	Learning Rate: 0.00886737
	LOSS [training: 0.5004440027311026 | validation: 0.3302548097212952]
	TIME [epoch: 8.56 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5604178059051212		[learning rate: 0.0088465]
	Learning Rate: 0.00884645
	LOSS [training: 0.5604178059051212 | validation: 0.42947872803299325]
	TIME [epoch: 8.53 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5219428423823256		[learning rate: 0.0088256]
	Learning Rate: 0.00882559
	LOSS [training: 0.5219428423823256 | validation: 0.6596474462953144]
	TIME [epoch: 8.53 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5410326426040764		[learning rate: 0.0088048]
	Learning Rate: 0.00880477
	LOSS [training: 0.5410326426040764 | validation: 0.5278883409042754]
	TIME [epoch: 8.53 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41648871078159466		[learning rate: 0.008784]
	Learning Rate: 0.008784
	LOSS [training: 0.41648871078159466 | validation: 0.2778682309364574]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5084370132417466		[learning rate: 0.0087633]
	Learning Rate: 0.00876328
	LOSS [training: 0.5084370132417466 | validation: 0.29650205595511747]
	TIME [epoch: 8.53 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5767946527898994		[learning rate: 0.0087426]
	Learning Rate: 0.00874261
	LOSS [training: 0.5767946527898994 | validation: 0.35453374993514203]
	TIME [epoch: 8.53 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48219096633601677		[learning rate: 0.008722]
	Learning Rate: 0.00872199
	LOSS [training: 0.48219096633601677 | validation: 0.32579363452396837]
	TIME [epoch: 8.54 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662264339565546		[learning rate: 0.0087014]
	Learning Rate: 0.00870141
	LOSS [training: 0.3662264339565546 | validation: 0.4352797757036197]
	TIME [epoch: 8.55 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5289779252405716		[learning rate: 0.0086809]
	Learning Rate: 0.00868089
	LOSS [training: 0.5289779252405716 | validation: 0.7704724930907743]
	TIME [epoch: 8.53 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5402702804666283		[learning rate: 0.0086604]
	Learning Rate: 0.00866041
	LOSS [training: 0.5402702804666283 | validation: 0.38794861971089034]
	TIME [epoch: 8.54 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39801729617343845		[learning rate: 0.00864]
	Learning Rate: 0.00863998
	LOSS [training: 0.39801729617343845 | validation: 1.111153908343907]
	TIME [epoch: 8.54 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.663620399835981		[learning rate: 0.0086196]
	Learning Rate: 0.0086196
	LOSS [training: 0.663620399835981 | validation: 0.40256322684202717]
	TIME [epoch: 8.54 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3858151583211444		[learning rate: 0.0085993]
	Learning Rate: 0.00859927
	LOSS [training: 0.3858151583211444 | validation: 0.31865142944947455]
	TIME [epoch: 8.53 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4398996735002479		[learning rate: 0.008579]
	Learning Rate: 0.00857898
	LOSS [training: 0.4398996735002479 | validation: 0.35101202341464455]
	TIME [epoch: 8.53 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.428934701273017		[learning rate: 0.0085587]
	Learning Rate: 0.00855875
	LOSS [training: 0.428934701273017 | validation: 0.3855781515264991]
	TIME [epoch: 8.54 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42604569697137845		[learning rate: 0.0085386]
	Learning Rate: 0.00853856
	LOSS [training: 0.42604569697137845 | validation: 0.3302452261199372]
	TIME [epoch: 8.55 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5362352992753695		[learning rate: 0.0085184]
	Learning Rate: 0.00851842
	LOSS [training: 0.5362352992753695 | validation: 0.4360778414387729]
	TIME [epoch: 8.54 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4191256375093184		[learning rate: 0.0084983]
	Learning Rate: 0.00849833
	LOSS [training: 0.4191256375093184 | validation: 0.3728052013402249]
	TIME [epoch: 8.53 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4509870454441816		[learning rate: 0.0084783]
	Learning Rate: 0.00847828
	LOSS [training: 0.4509870454441816 | validation: 0.571909023019265]
	TIME [epoch: 8.55 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41697062155848574		[learning rate: 0.0084583]
	Learning Rate: 0.00845828
	LOSS [training: 0.41697062155848574 | validation: 0.3269439464870635]
	TIME [epoch: 8.53 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4080031115299859		[learning rate: 0.0084383]
	Learning Rate: 0.00843833
	LOSS [training: 0.4080031115299859 | validation: 0.29189706044689934]
	TIME [epoch: 8.52 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5413015951167672		[learning rate: 0.0084184]
	Learning Rate: 0.00841842
	LOSS [training: 0.5413015951167672 | validation: 0.39435510757311654]
	TIME [epoch: 8.53 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5398920695802933		[learning rate: 0.0083986]
	Learning Rate: 0.00839857
	LOSS [training: 0.5398920695802933 | validation: 0.4821748276912399]
	TIME [epoch: 8.55 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40465945908906403		[learning rate: 0.0083788]
	Learning Rate: 0.00837875
	LOSS [training: 0.40465945908906403 | validation: 0.386569486784498]
	TIME [epoch: 8.54 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47754323946236		[learning rate: 0.008359]
	Learning Rate: 0.00835899
	LOSS [training: 0.47754323946236 | validation: 0.4128146192581631]
	TIME [epoch: 8.53 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5292685438846594		[learning rate: 0.0083393]
	Learning Rate: 0.00833927
	LOSS [training: 0.5292685438846594 | validation: 0.30251731261808634]
	TIME [epoch: 8.52 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40466890040674547		[learning rate: 0.0083196]
	Learning Rate: 0.0083196
	LOSS [training: 0.40466890040674547 | validation: 0.45554131969429656]
	TIME [epoch: 8.56 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.504530424362905		[learning rate: 0.0083]
	Learning Rate: 0.00829998
	LOSS [training: 0.504530424362905 | validation: 0.3046933731815165]
	TIME [epoch: 8.53 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49218739141761725		[learning rate: 0.0082804]
	Learning Rate: 0.0082804
	LOSS [training: 0.49218739141761725 | validation: 0.5202431190098553]
	TIME [epoch: 8.53 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4266812271656598		[learning rate: 0.0082609]
	Learning Rate: 0.00826087
	LOSS [training: 0.4266812271656598 | validation: 0.2841030902215621]
	TIME [epoch: 8.52 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48189087477505443		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.48189087477505443 | validation: 0.48900774012344905]
	TIME [epoch: 8.55 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46648174290411715		[learning rate: 0.0082219]
	Learning Rate: 0.00822194
	LOSS [training: 0.46648174290411715 | validation: 0.3291744808828979]
	TIME [epoch: 8.53 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42128430395256694		[learning rate: 0.0082025]
	Learning Rate: 0.00820255
	LOSS [training: 0.42128430395256694 | validation: 0.807889334819033]
	TIME [epoch: 8.53 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5737221226478593		[learning rate: 0.0081832]
	Learning Rate: 0.0081832
	LOSS [training: 0.5737221226478593 | validation: 0.4310712518506159]
	TIME [epoch: 8.53 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4329657206628303		[learning rate: 0.0081639]
	Learning Rate: 0.00816389
	LOSS [training: 0.4329657206628303 | validation: 0.5887973038403301]
	TIME [epoch: 8.55 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38160804001345144		[learning rate: 0.0081446]
	Learning Rate: 0.00814464
	LOSS [training: 0.38160804001345144 | validation: 0.27997354082758275]
	TIME [epoch: 8.53 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4256302788417032		[learning rate: 0.0081254]
	Learning Rate: 0.00812543
	LOSS [training: 0.4256302788417032 | validation: 0.8092736776582682]
	TIME [epoch: 8.53 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5392870745985249		[learning rate: 0.0081063]
	Learning Rate: 0.00810626
	LOSS [training: 0.5392870745985249 | validation: 0.24884014405255214]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3486980733108468		[learning rate: 0.0080871]
	Learning Rate: 0.00808714
	LOSS [training: 0.3486980733108468 | validation: 0.8075648378579714]
	TIME [epoch: 8.55 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4678258534942465		[learning rate: 0.0080681]
	Learning Rate: 0.00806806
	LOSS [training: 0.4678258534942465 | validation: 0.29485397781122635]
	TIME [epoch: 8.52 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37925853000040965		[learning rate: 0.008049]
	Learning Rate: 0.00804903
	LOSS [training: 0.37925853000040965 | validation: 0.2945963941676396]
	TIME [epoch: 8.53 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42787800362105893		[learning rate: 0.00803]
	Learning Rate: 0.00803004
	LOSS [training: 0.42787800362105893 | validation: 0.4291134099402666]
	TIME [epoch: 8.54 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3815994026691071		[learning rate: 0.0080111]
	Learning Rate: 0.0080111
	LOSS [training: 0.3815994026691071 | validation: 0.22125029591482506]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3771060696296203		[learning rate: 0.0079922]
	Learning Rate: 0.00799221
	LOSS [training: 0.3771060696296203 | validation: 0.468761915347668]
	TIME [epoch: 8.52 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4531964060232985		[learning rate: 0.0079734]
	Learning Rate: 0.00797335
	LOSS [training: 0.4531964060232985 | validation: 0.5161524275188657]
	TIME [epoch: 8.53 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3967340680431565		[learning rate: 0.0079545]
	Learning Rate: 0.00795455
	LOSS [training: 0.3967340680431565 | validation: 0.44128873500714605]
	TIME [epoch: 8.54 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46185816809270125		[learning rate: 0.0079358]
	Learning Rate: 0.00793578
	LOSS [training: 0.46185816809270125 | validation: 0.4376126891084041]
	TIME [epoch: 8.53 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36060756572723535		[learning rate: 0.0079171]
	Learning Rate: 0.00791706
	LOSS [training: 0.36060756572723535 | validation: 0.21722611668848674]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40199600738320707		[learning rate: 0.0078984]
	Learning Rate: 0.00789839
	LOSS [training: 0.40199600738320707 | validation: 0.4353205237209238]
	TIME [epoch: 8.53 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5543667972408299		[learning rate: 0.0078798]
	Learning Rate: 0.00787976
	LOSS [training: 0.5543667972408299 | validation: 0.24374713777584409]
	TIME [epoch: 8.55 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32343756602040546		[learning rate: 0.0078612]
	Learning Rate: 0.00786117
	LOSS [training: 0.32343756602040546 | validation: 0.37610237985431183]
	TIME [epoch: 8.55 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39651447931417866		[learning rate: 0.0078426]
	Learning Rate: 0.00784263
	LOSS [training: 0.39651447931417866 | validation: 0.5852514591795396]
	TIME [epoch: 8.53 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.412242006560819		[learning rate: 0.0078241]
	Learning Rate: 0.00782413
	LOSS [training: 0.412242006560819 | validation: 0.5580683345634222]
	TIME [epoch: 8.54 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3660104194045647		[learning rate: 0.0078057]
	Learning Rate: 0.00780567
	LOSS [training: 0.3660104194045647 | validation: 0.5798188824131905]
	TIME [epoch: 8.56 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4228264436484747		[learning rate: 0.0077873]
	Learning Rate: 0.00778726
	LOSS [training: 0.4228264436484747 | validation: 0.4044449504474562]
	TIME [epoch: 8.54 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37202671890970695		[learning rate: 0.0077689]
	Learning Rate: 0.00776889
	LOSS [training: 0.37202671890970695 | validation: 0.2769907831203073]
	TIME [epoch: 8.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4633411579047313		[learning rate: 0.0077506]
	Learning Rate: 0.00775056
	LOSS [training: 0.4633411579047313 | validation: 0.2644436428435863]
	TIME [epoch: 8.53 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.415865226300248		[learning rate: 0.0077323]
	Learning Rate: 0.00773228
	LOSS [training: 0.415865226300248 | validation: 0.31417649975028855]
	TIME [epoch: 8.56 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.386267780708181		[learning rate: 0.007714]
	Learning Rate: 0.00771404
	LOSS [training: 0.386267780708181 | validation: 0.2941189039049904]
	TIME [epoch: 8.54 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.371367633157933		[learning rate: 0.0076958]
	Learning Rate: 0.00769585
	LOSS [training: 0.371367633157933 | validation: 0.37799698761274114]
	TIME [epoch: 8.54 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38333645794675614		[learning rate: 0.0076777]
	Learning Rate: 0.00767769
	LOSS [training: 0.38333645794675614 | validation: 0.31830848622542884]
	TIME [epoch: 8.54 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4459232993450969		[learning rate: 0.0076596]
	Learning Rate: 0.00765958
	LOSS [training: 0.4459232993450969 | validation: 0.2110179848312431]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3713600298302143		[learning rate: 0.0076415]
	Learning Rate: 0.00764151
	LOSS [training: 0.3713600298302143 | validation: 0.3211751300704323]
	TIME [epoch: 8.54 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42422694862868227		[learning rate: 0.0076235]
	Learning Rate: 0.00762349
	LOSS [training: 0.42422694862868227 | validation: 0.4138710623459074]
	TIME [epoch: 8.54 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.675049807871549		[learning rate: 0.0076055]
	Learning Rate: 0.00760551
	LOSS [training: 0.675049807871549 | validation: 0.3164979725150534]
	TIME [epoch: 8.54 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3850339513145725		[learning rate: 0.0075876]
	Learning Rate: 0.00758757
	LOSS [training: 0.3850339513145725 | validation: 0.4699327721298423]
	TIME [epoch: 8.56 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46566151543263545		[learning rate: 0.0075697]
	Learning Rate: 0.00756967
	LOSS [training: 0.46566151543263545 | validation: 0.7432103833865021]
	TIME [epoch: 8.53 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47815449439886404		[learning rate: 0.0075518]
	Learning Rate: 0.00755181
	LOSS [training: 0.47815449439886404 | validation: 0.1777610358630494]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2736145020052426		[learning rate: 0.007534]
	Learning Rate: 0.007534
	LOSS [training: 0.2736145020052426 | validation: 0.5143030334041332]
	TIME [epoch: 8.56 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40280340418453375		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.40280340418453375 | validation: 0.21878441965486214]
	TIME [epoch: 8.56 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2960333802559771		[learning rate: 0.0074985]
	Learning Rate: 0.0074985
	LOSS [training: 0.2960333802559771 | validation: 0.3259235701988571]
	TIME [epoch: 8.54 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4053589785608307		[learning rate: 0.0074808]
	Learning Rate: 0.00748081
	LOSS [training: 0.4053589785608307 | validation: 0.6993545986328169]
	TIME [epoch: 8.54 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36995277130126547		[learning rate: 0.0074632]
	Learning Rate: 0.00746317
	LOSS [training: 0.36995277130126547 | validation: 0.33831506620156565]
	TIME [epoch: 8.55 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3219663483611309		[learning rate: 0.0074456]
	Learning Rate: 0.00744556
	LOSS [training: 0.3219663483611309 | validation: 0.22986047399856716]
	TIME [epoch: 8.54 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4338029835963645		[learning rate: 0.007428]
	Learning Rate: 0.007428
	LOSS [training: 0.4338029835963645 | validation: 0.25378678008806327]
	TIME [epoch: 8.53 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37798208413319134		[learning rate: 0.0074105]
	Learning Rate: 0.00741048
	LOSS [training: 0.37798208413319134 | validation: 0.2977228470275976]
	TIME [epoch: 8.53 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39418537811682386		[learning rate: 0.007393]
	Learning Rate: 0.007393
	LOSS [training: 0.39418537811682386 | validation: 0.2198523519871048]
	TIME [epoch: 8.55 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662621383211046		[learning rate: 0.0073756]
	Learning Rate: 0.00737556
	LOSS [training: 0.3662621383211046 | validation: 0.40372323574757984]
	TIME [epoch: 8.53 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7501067795130637		[learning rate: 0.0073582]
	Learning Rate: 0.00735816
	LOSS [training: 0.7501067795130637 | validation: 0.5230811033409967]
	TIME [epoch: 8.53 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40249525558879223		[learning rate: 0.0073408]
	Learning Rate: 0.0073408
	LOSS [training: 0.40249525558879223 | validation: 0.24751194713630933]
	TIME [epoch: 8.53 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4038540920637062		[learning rate: 0.0073235]
	Learning Rate: 0.00732349
	LOSS [training: 0.4038540920637062 | validation: 0.33433346200527436]
	TIME [epoch: 8.55 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5186560695582767		[learning rate: 0.0073062]
	Learning Rate: 0.00730621
	LOSS [training: 0.5186560695582767 | validation: 0.4712379601088022]
	TIME [epoch: 8.53 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4828877687331056		[learning rate: 0.007289]
	Learning Rate: 0.00728898
	LOSS [training: 0.4828877687331056 | validation: 0.34196838859752793]
	TIME [epoch: 8.53 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45939131203156497		[learning rate: 0.0072718]
	Learning Rate: 0.00727178
	LOSS [training: 0.45939131203156497 | validation: 0.24032374426288794]
	TIME [epoch: 8.52 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.430420585091705		[learning rate: 0.0072546]
	Learning Rate: 0.00725463
	LOSS [training: 0.430420585091705 | validation: 0.38774288134736]
	TIME [epoch: 8.55 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4346085224945492		[learning rate: 0.0072375]
	Learning Rate: 0.00723752
	LOSS [training: 0.4346085224945492 | validation: 0.5388260186496401]
	TIME [epoch: 8.53 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6194846373286815		[learning rate: 0.0072204]
	Learning Rate: 0.00722045
	LOSS [training: 0.6194846373286815 | validation: 0.3146988650797179]
	TIME [epoch: 8.53 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41579600986064336		[learning rate: 0.0072034]
	Learning Rate: 0.00720342
	LOSS [training: 0.41579600986064336 | validation: 0.38793284936862804]
	TIME [epoch: 8.53 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5656607982619934		[learning rate: 0.0071864]
	Learning Rate: 0.00718642
	LOSS [training: 0.5656607982619934 | validation: 0.3773609205951957]
	TIME [epoch: 8.55 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39386889071320325		[learning rate: 0.0071695]
	Learning Rate: 0.00716947
	LOSS [training: 0.39386889071320325 | validation: 0.5462850368227193]
	TIME [epoch: 8.53 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42057506398093636		[learning rate: 0.0071526]
	Learning Rate: 0.00715256
	LOSS [training: 0.42057506398093636 | validation: 0.4828855313674121]
	TIME [epoch: 8.53 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44574534237012164		[learning rate: 0.0071357]
	Learning Rate: 0.00713569
	LOSS [training: 0.44574534237012164 | validation: 0.7725396207961861]
	TIME [epoch: 8.53 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49695842249387184		[learning rate: 0.0071189]
	Learning Rate: 0.00711886
	LOSS [training: 0.49695842249387184 | validation: 0.4521467503193525]
	TIME [epoch: 8.55 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43174551219033724		[learning rate: 0.0071021]
	Learning Rate: 0.00710206
	LOSS [training: 0.43174551219033724 | validation: 0.38724064330398345]
	TIME [epoch: 8.53 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4497610925466861		[learning rate: 0.0070853]
	Learning Rate: 0.00708531
	LOSS [training: 0.4497610925466861 | validation: 0.3201983555455703]
	TIME [epoch: 8.53 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5008759745077764		[learning rate: 0.0070686]
	Learning Rate: 0.0070686
	LOSS [training: 0.5008759745077764 | validation: 0.3156818814823671]
	TIME [epoch: 8.53 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47677798951513195		[learning rate: 0.0070519]
	Learning Rate: 0.00705192
	LOSS [training: 0.47677798951513195 | validation: 0.22461200093278633]
	TIME [epoch: 8.56 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4293666280297105		[learning rate: 0.0070353]
	Learning Rate: 0.00703529
	LOSS [training: 0.4293666280297105 | validation: 0.3196965511514299]
	TIME [epoch: 8.54 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5386508235855254		[learning rate: 0.0070187]
	Learning Rate: 0.0070187
	LOSS [training: 0.5386508235855254 | validation: 0.3915690520505135]
	TIME [epoch: 8.53 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5185289567369631		[learning rate: 0.0070021]
	Learning Rate: 0.00700214
	LOSS [training: 0.5185289567369631 | validation: 0.5044135603576964]
	TIME [epoch: 8.54 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35640884376461146		[learning rate: 0.0069856]
	Learning Rate: 0.00698562
	LOSS [training: 0.35640884376461146 | validation: 0.40324321195824664]
	TIME [epoch: 8.56 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5164814953257953		[learning rate: 0.0069691]
	Learning Rate: 0.00696914
	LOSS [training: 0.5164814953257953 | validation: 0.389224527774766]
	TIME [epoch: 8.54 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5556909006048084		[learning rate: 0.0069527]
	Learning Rate: 0.00695271
	LOSS [training: 0.5556909006048084 | validation: 0.6544386141347669]
	TIME [epoch: 8.53 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6787843819469401		[learning rate: 0.0069363]
	Learning Rate: 0.00693631
	LOSS [training: 0.6787843819469401 | validation: 0.6338897380218802]
	TIME [epoch: 8.55 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4649072549064079		[learning rate: 0.0069199]
	Learning Rate: 0.00691994
	LOSS [training: 0.4649072549064079 | validation: 0.41092797117622015]
	TIME [epoch: 8.55 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.404805697464369		[learning rate: 0.0069036]
	Learning Rate: 0.00690362
	LOSS [training: 0.404805697464369 | validation: 0.18956639463527825]
	TIME [epoch: 8.53 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5836114143749092		[learning rate: 0.0068873]
	Learning Rate: 0.00688734
	LOSS [training: 0.5836114143749092 | validation: 0.48908818529636844]
	TIME [epoch: 8.54 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35260833809592457		[learning rate: 0.0068711]
	Learning Rate: 0.00687109
	LOSS [training: 0.35260833809592457 | validation: 0.44040808319406666]
	TIME [epoch: 8.55 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40431433057893906		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.40431433057893906 | validation: 1.4637870157309156]
	TIME [epoch: 8.55 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5406264103256757		[learning rate: 0.0068387]
	Learning Rate: 0.00683871
	LOSS [training: 0.5406264103256757 | validation: 0.5359005532843446]
	TIME [epoch: 8.54 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4605020006084117		[learning rate: 0.0068226]
	Learning Rate: 0.00682258
	LOSS [training: 0.4605020006084117 | validation: 1.0511521800898018]
	TIME [epoch: 8.54 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4782464053787602		[learning rate: 0.0068065]
	Learning Rate: 0.00680649
	LOSS [training: 0.4782464053787602 | validation: 0.3032052588248251]
	TIME [epoch: 8.57 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4747325774834392		[learning rate: 0.0067904]
	Learning Rate: 0.00679043
	LOSS [training: 0.4747325774834392 | validation: 0.5150585296176848]
	TIME [epoch: 8.55 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41915130089358454		[learning rate: 0.0067744]
	Learning Rate: 0.00677441
	LOSS [training: 0.41915130089358454 | validation: 0.9690377651345821]
	TIME [epoch: 8.54 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4406925186377699		[learning rate: 0.0067584]
	Learning Rate: 0.00675843
	LOSS [training: 0.4406925186377699 | validation: 0.2141090989296116]
	TIME [epoch: 8.54 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45964543298165417		[learning rate: 0.0067425]
	Learning Rate: 0.00674249
	LOSS [training: 0.45964543298165417 | validation: 0.5834746577451569]
	TIME [epoch: 8.57 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4107493755704409		[learning rate: 0.0067266]
	Learning Rate: 0.00672659
	LOSS [training: 0.4107493755704409 | validation: 0.5577279590397177]
	TIME [epoch: 8.54 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7687796179512223		[learning rate: 0.0067107]
	Learning Rate: 0.00671072
	LOSS [training: 0.7687796179512223 | validation: 0.3808833401532686]
	TIME [epoch: 8.54 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47435879920314405		[learning rate: 0.0066949]
	Learning Rate: 0.00669489
	LOSS [training: 0.47435879920314405 | validation: 0.6634379237775221]
	TIME [epoch: 8.54 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3697454298511384		[learning rate: 0.0066791]
	Learning Rate: 0.0066791
	LOSS [training: 0.3697454298511384 | validation: 0.4339992170596131]
	TIME [epoch: 8.57 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5269292609826469		[learning rate: 0.0066633]
	Learning Rate: 0.00666334
	LOSS [training: 0.5269292609826469 | validation: 0.32101077428217284]
	TIME [epoch: 8.55 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3786663691732307		[learning rate: 0.0066476]
	Learning Rate: 0.00664763
	LOSS [training: 0.3786663691732307 | validation: 0.45730169828842854]
	TIME [epoch: 8.55 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42517495335560884		[learning rate: 0.0066319]
	Learning Rate: 0.00663195
	LOSS [training: 0.42517495335560884 | validation: 1.1391383143203413]
	TIME [epoch: 8.54 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43617958415815605		[learning rate: 0.0066163]
	Learning Rate: 0.0066163
	LOSS [training: 0.43617958415815605 | validation: 0.5110681637520605]
	TIME [epoch: 8.57 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48229820123761086		[learning rate: 0.0066007]
	Learning Rate: 0.0066007
	LOSS [training: 0.48229820123761086 | validation: 0.6180300665798499]
	TIME [epoch: 8.55 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4861211777944955		[learning rate: 0.0065851]
	Learning Rate: 0.00658513
	LOSS [training: 0.4861211777944955 | validation: 0.38877069462055736]
	TIME [epoch: 8.54 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5539323198980792		[learning rate: 0.0065696]
	Learning Rate: 0.00656959
	LOSS [training: 0.5539323198980792 | validation: 1.1272976905933123]
	TIME [epoch: 8.54 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5255029591325747		[learning rate: 0.0065541]
	Learning Rate: 0.0065541
	LOSS [training: 0.5255029591325747 | validation: 0.7919012397378016]
	TIME [epoch: 8.57 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5556777490002581		[learning rate: 0.0065386]
	Learning Rate: 0.00653864
	LOSS [training: 0.5556777490002581 | validation: 0.4765516244390966]
	TIME [epoch: 8.54 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39191725646326214		[learning rate: 0.0065232]
	Learning Rate: 0.00652321
	LOSS [training: 0.39191725646326214 | validation: 0.19106132595652914]
	TIME [epoch: 8.55 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35706891462309387		[learning rate: 0.0065078]
	Learning Rate: 0.00650783
	LOSS [training: 0.35706891462309387 | validation: 0.9740057585515706]
	TIME [epoch: 8.54 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5864899616046744		[learning rate: 0.0064925]
	Learning Rate: 0.00649247
	LOSS [training: 0.5864899616046744 | validation: 0.3756591423222815]
	TIME [epoch: 8.57 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3184589658594392		[learning rate: 0.0064772]
	Learning Rate: 0.00647716
	LOSS [training: 0.3184589658594392 | validation: 0.20485972966738783]
	TIME [epoch: 8.54 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42458576059103875		[learning rate: 0.0064619]
	Learning Rate: 0.00646188
	LOSS [training: 0.42458576059103875 | validation: 0.3910840342563052]
	TIME [epoch: 8.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5899311888235634		[learning rate: 0.0064466]
	Learning Rate: 0.00644664
	LOSS [training: 0.5899311888235634 | validation: 0.6809402748811917]
	TIME [epoch: 8.55 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.574744208215023		[learning rate: 0.0064314]
	Learning Rate: 0.00643143
	LOSS [training: 0.574744208215023 | validation: 0.3582046551983959]
	TIME [epoch: 8.56 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5268839419366137		[learning rate: 0.0064163]
	Learning Rate: 0.00641626
	LOSS [training: 0.5268839419366137 | validation: 0.5343597921146248]
	TIME [epoch: 8.55 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5499511937038155		[learning rate: 0.0064011]
	Learning Rate: 0.00640113
	LOSS [training: 0.5499511937038155 | validation: 0.19648833390193626]
	TIME [epoch: 8.54 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3772442495671115		[learning rate: 0.006386]
	Learning Rate: 0.00638603
	LOSS [training: 0.3772442495671115 | validation: 0.569984658931777]
	TIME [epoch: 8.56 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36094749234532264		[learning rate: 0.006371]
	Learning Rate: 0.00637096
	LOSS [training: 0.36094749234532264 | validation: 0.6610884118509317]
	TIME [epoch: 8.55 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38745792025488296		[learning rate: 0.0063559]
	Learning Rate: 0.00635594
	LOSS [training: 0.38745792025488296 | validation: 0.2126339950106819]
	TIME [epoch: 8.55 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.433903219840151		[learning rate: 0.0063409]
	Learning Rate: 0.00634094
	LOSS [training: 0.433903219840151 | validation: 0.2495924032422262]
	TIME [epoch: 8.54 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3253975286083354		[learning rate: 0.006326]
	Learning Rate: 0.00632599
	LOSS [training: 0.3253975286083354 | validation: 0.2800116246723454]
	TIME [epoch: 8.56 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5067420154170844		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.5067420154170844 | validation: 0.27376153993660224]
	TIME [epoch: 8.55 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5264553917528514		[learning rate: 0.0062962]
	Learning Rate: 0.00629618
	LOSS [training: 0.5264553917528514 | validation: 0.37489397715835093]
	TIME [epoch: 8.54 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2992644247765127		[learning rate: 0.0062813]
	Learning Rate: 0.00628133
	LOSS [training: 0.2992644247765127 | validation: 0.8814139214286966]
	TIME [epoch: 8.55 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.521616847536483		[learning rate: 0.0062665]
	Learning Rate: 0.00626651
	LOSS [training: 0.521616847536483 | validation: 0.16740177814985568]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3569183642774021		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.3569183642774021 | validation: 0.28682521699724994]
	TIME [epoch: 8.55 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.393726193440014		[learning rate: 0.006237]
	Learning Rate: 0.00623698
	LOSS [training: 0.393726193440014 | validation: 0.317729786282957]
	TIME [epoch: 8.54 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3532380403437645		[learning rate: 0.0062223]
	Learning Rate: 0.00622227
	LOSS [training: 0.3532380403437645 | validation: 0.36616080059580913]
	TIME [epoch: 8.54 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42500050910655346		[learning rate: 0.0062076]
	Learning Rate: 0.00620759
	LOSS [training: 0.42500050910655346 | validation: 0.5262671174211011]
	TIME [epoch: 8.56 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36945450592641915		[learning rate: 0.0061929]
	Learning Rate: 0.00619295
	LOSS [training: 0.36945450592641915 | validation: 0.7742649683633314]
	TIME [epoch: 8.55 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4416602810727688		[learning rate: 0.0061783]
	Learning Rate: 0.00617834
	LOSS [training: 0.4416602810727688 | validation: 0.38477968436518684]
	TIME [epoch: 8.54 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3481379233197162		[learning rate: 0.0061638]
	Learning Rate: 0.00616377
	LOSS [training: 0.3481379233197162 | validation: 0.4828227532234343]
	TIME [epoch: 8.55 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33948270143460124		[learning rate: 0.0061492]
	Learning Rate: 0.00614923
	LOSS [training: 0.33948270143460124 | validation: 0.24414933085022916]
	TIME [epoch: 8.57 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4677212818630984		[learning rate: 0.0061347]
	Learning Rate: 0.00613472
	LOSS [training: 0.4677212818630984 | validation: 0.2223415192744434]
	TIME [epoch: 8.55 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28960606318247695		[learning rate: 0.0061203]
	Learning Rate: 0.00612025
	LOSS [training: 0.28960606318247695 | validation: 0.1780601872741236]
	TIME [epoch: 8.54 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29930218867065544		[learning rate: 0.0061058]
	Learning Rate: 0.00610581
	LOSS [training: 0.29930218867065544 | validation: 0.3577734489524828]
	TIME [epoch: 8.54 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3096017316451594		[learning rate: 0.0060914]
	Learning Rate: 0.00609141
	LOSS [training: 0.3096017316451594 | validation: 0.27456548651961243]
	TIME [epoch: 8.57 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3385122902540046		[learning rate: 0.006077]
	Learning Rate: 0.00607704
	LOSS [training: 0.3385122902540046 | validation: 0.4512995103205608]
	TIME [epoch: 8.55 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5140774849240499		[learning rate: 0.0060627]
	Learning Rate: 0.00606271
	LOSS [training: 0.5140774849240499 | validation: 0.5720266444207935]
	TIME [epoch: 8.54 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.390323984653438		[learning rate: 0.0060484]
	Learning Rate: 0.00604841
	LOSS [training: 0.390323984653438 | validation: 0.8177321543191516]
	TIME [epoch: 8.54 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4972766978169507		[learning rate: 0.0060341]
	Learning Rate: 0.00603414
	LOSS [training: 0.4972766978169507 | validation: 0.44643862084692043]
	TIME [epoch: 8.57 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5781037372727197		[learning rate: 0.0060199]
	Learning Rate: 0.00601991
	LOSS [training: 0.5781037372727197 | validation: 0.5730969737589927]
	TIME [epoch: 8.55 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34463458932063956		[learning rate: 0.0060057]
	Learning Rate: 0.00600571
	LOSS [training: 0.34463458932063956 | validation: 0.22953424015814422]
	TIME [epoch: 8.55 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31573210249397576		[learning rate: 0.0059915]
	Learning Rate: 0.00599154
	LOSS [training: 0.31573210249397576 | validation: 0.4511119461863984]
	TIME [epoch: 8.54 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38463710633405934		[learning rate: 0.0059774]
	Learning Rate: 0.00597741
	LOSS [training: 0.38463710633405934 | validation: 0.2502928723878825]
	TIME [epoch: 8.57 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40917094225082573		[learning rate: 0.0059633]
	Learning Rate: 0.00596331
	LOSS [training: 0.40917094225082573 | validation: 0.30614258324226795]
	TIME [epoch: 8.55 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36409165460991516		[learning rate: 0.0059492]
	Learning Rate: 0.00594924
	LOSS [training: 0.36409165460991516 | validation: 0.5024065714586661]
	TIME [epoch: 8.55 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6971777620732597		[learning rate: 0.0059352]
	Learning Rate: 0.00593521
	LOSS [training: 0.6971777620732597 | validation: 0.5504952826245945]
	TIME [epoch: 8.55 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4993770310944484		[learning rate: 0.0059212]
	Learning Rate: 0.00592121
	LOSS [training: 0.4993770310944484 | validation: 0.3404435027804473]
	TIME [epoch: 8.58 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32480549544287785		[learning rate: 0.0059072]
	Learning Rate: 0.00590724
	LOSS [training: 0.32480549544287785 | validation: 0.2847283068804147]
	TIME [epoch: 8.55 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3582477591924788		[learning rate: 0.0058933]
	Learning Rate: 0.00589331
	LOSS [training: 0.3582477591924788 | validation: 0.32829097875205765]
	TIME [epoch: 8.55 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41129250258206546		[learning rate: 0.0058794]
	Learning Rate: 0.0058794
	LOSS [training: 0.41129250258206546 | validation: 0.1993445841541622]
	TIME [epoch: 8.56 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39255804041428266		[learning rate: 0.0058655]
	Learning Rate: 0.00586554
	LOSS [training: 0.39255804041428266 | validation: 0.2611381102394221]
	TIME [epoch: 8.57 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3694566242218494		[learning rate: 0.0058517]
	Learning Rate: 0.0058517
	LOSS [training: 0.3694566242218494 | validation: 0.5672865554461043]
	TIME [epoch: 8.54 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3677735344850425		[learning rate: 0.0058379]
	Learning Rate: 0.0058379
	LOSS [training: 0.3677735344850425 | validation: 0.2169350587002709]
	TIME [epoch: 8.55 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37177001897282497		[learning rate: 0.0058241]
	Learning Rate: 0.00582413
	LOSS [training: 0.37177001897282497 | validation: 0.35829471353402376]
	TIME [epoch: 8.56 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3724875617975433		[learning rate: 0.0058104]
	Learning Rate: 0.00581039
	LOSS [training: 0.3724875617975433 | validation: 0.5360173514360831]
	TIME [epoch: 8.56 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3052064109826245		[learning rate: 0.0057967]
	Learning Rate: 0.00579668
	LOSS [training: 0.3052064109826245 | validation: 0.32849079124170755]
	TIME [epoch: 8.55 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35097889303403373		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.35097889303403373 | validation: 0.48379724416209136]
	TIME [epoch: 8.55 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34117487549230685		[learning rate: 0.0057694]
	Learning Rate: 0.00576937
	LOSS [training: 0.34117487549230685 | validation: 0.21226572020315077]
	TIME [epoch: 8.56 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3108395572492162		[learning rate: 0.0057558]
	Learning Rate: 0.00575576
	LOSS [training: 0.3108395572492162 | validation: 0.2659709353019665]
	TIME [epoch: 8.56 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34884941226937916		[learning rate: 0.0057422]
	Learning Rate: 0.00574218
	LOSS [training: 0.34884941226937916 | validation: 0.3020067290597691]
	TIME [epoch: 8.55 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37775510601033974		[learning rate: 0.0057286]
	Learning Rate: 0.00572864
	LOSS [training: 0.37775510601033974 | validation: 0.3289516031304919]
	TIME [epoch: 8.55 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4240456115611907		[learning rate: 0.0057151]
	Learning Rate: 0.00571512
	LOSS [training: 0.4240456115611907 | validation: 0.4104694555536353]
	TIME [epoch: 8.57 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29239619698835473		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.29239619698835473 | validation: 0.31996155953968186]
	TIME [epoch: 8.55 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3272752392062634		[learning rate: 0.0056882]
	Learning Rate: 0.00568819
	LOSS [training: 0.3272752392062634 | validation: 0.3983345775737903]
	TIME [epoch: 8.55 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2783419502542772		[learning rate: 0.0056748]
	Learning Rate: 0.00567478
	LOSS [training: 0.2783419502542772 | validation: 0.28621299073598566]
	TIME [epoch: 8.54 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30314602504500293		[learning rate: 0.0056614]
	Learning Rate: 0.00566139
	LOSS [training: 0.30314602504500293 | validation: 0.6045322382339]
	TIME [epoch: 8.57 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39111730538629136		[learning rate: 0.005648]
	Learning Rate: 0.00564804
	LOSS [training: 0.39111730538629136 | validation: 0.32074854099911265]
	TIME [epoch: 8.55 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3394693740732996		[learning rate: 0.0056347]
	Learning Rate: 0.00563471
	LOSS [training: 0.3394693740732996 | validation: 0.26723171559145276]
	TIME [epoch: 8.55 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3214375328454207		[learning rate: 0.0056214]
	Learning Rate: 0.00562142
	LOSS [training: 0.3214375328454207 | validation: 0.26947846669897246]
	TIME [epoch: 8.54 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4196636239080709		[learning rate: 0.0056082]
	Learning Rate: 0.00560816
	LOSS [training: 0.4196636239080709 | validation: 0.26309723425199316]
	TIME [epoch: 8.57 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38231702566490794		[learning rate: 0.0055949]
	Learning Rate: 0.00559493
	LOSS [training: 0.38231702566490794 | validation: 0.3386521069681905]
	TIME [epoch: 8.55 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31496055749659246		[learning rate: 0.0055817]
	Learning Rate: 0.00558173
	LOSS [training: 0.31496055749659246 | validation: 0.19971756137147229]
	TIME [epoch: 8.54 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32709882591671796		[learning rate: 0.0055686]
	Learning Rate: 0.00556857
	LOSS [training: 0.32709882591671796 | validation: 0.5382915541947291]
	TIME [epoch: 8.54 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40617256056937884		[learning rate: 0.0055554]
	Learning Rate: 0.00555543
	LOSS [training: 0.40617256056937884 | validation: 0.2050554365675088]
	TIME [epoch: 8.57 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3293727374493317		[learning rate: 0.0055423]
	Learning Rate: 0.00554233
	LOSS [training: 0.3293727374493317 | validation: 0.2506416372996739]
	TIME [epoch: 8.55 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31000629010255987		[learning rate: 0.0055293]
	Learning Rate: 0.00552926
	LOSS [training: 0.31000629010255987 | validation: 0.2877790516326265]
	TIME [epoch: 8.54 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902792056426412		[learning rate: 0.0055162]
	Learning Rate: 0.00551621
	LOSS [training: 0.2902792056426412 | validation: 0.2509654889390858]
	TIME [epoch: 8.55 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3555994296100776		[learning rate: 0.0055032]
	Learning Rate: 0.0055032
	LOSS [training: 0.3555994296100776 | validation: 0.6230950431591041]
	TIME [epoch: 8.57 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37049789863794463		[learning rate: 0.0054902]
	Learning Rate: 0.00549022
	LOSS [training: 0.37049789863794463 | validation: 0.24802522164045107]
	TIME [epoch: 8.54 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3425528880679693		[learning rate: 0.0054773]
	Learning Rate: 0.00547727
	LOSS [training: 0.3425528880679693 | validation: 0.24304491839160086]
	TIME [epoch: 8.54 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31775450703719815		[learning rate: 0.0054643]
	Learning Rate: 0.00546435
	LOSS [training: 0.31775450703719815 | validation: 0.47572086681356746]
	TIME [epoch: 8.55 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3089247516173475		[learning rate: 0.0054515]
	Learning Rate: 0.00545146
	LOSS [training: 0.3089247516173475 | validation: 0.2466915787813712]
	TIME [epoch: 8.56 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31367810394291656		[learning rate: 0.0054386]
	Learning Rate: 0.0054386
	LOSS [training: 0.31367810394291656 | validation: 0.20569511312243094]
	TIME [epoch: 8.55 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3163447831408772		[learning rate: 0.0054258]
	Learning Rate: 0.00542577
	LOSS [training: 0.3163447831408772 | validation: 0.32549709730891074]
	TIME [epoch: 8.54 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2384637671955505		[learning rate: 0.005413]
	Learning Rate: 0.00541297
	LOSS [training: 0.2384637671955505 | validation: 0.3044497455337086]
	TIME [epoch: 8.55 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3393853445525584		[learning rate: 0.0054002]
	Learning Rate: 0.00540021
	LOSS [training: 0.3393853445525584 | validation: 0.3435021251896806]
	TIME [epoch: 8.55 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3731597989301753		[learning rate: 0.0053875]
	Learning Rate: 0.00538747
	LOSS [training: 0.3731597989301753 | validation: 0.22172374949376356]
	TIME [epoch: 8.54 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4536605432087851		[learning rate: 0.0053748]
	Learning Rate: 0.00537476
	LOSS [training: 0.4536605432087851 | validation: 0.4104460304239568]
	TIME [epoch: 8.54 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30786698462934936		[learning rate: 0.0053621]
	Learning Rate: 0.00536208
	LOSS [training: 0.30786698462934936 | validation: 0.5347444434395386]
	TIME [epoch: 8.56 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3364149392778122		[learning rate: 0.0053494]
	Learning Rate: 0.00534943
	LOSS [training: 0.3364149392778122 | validation: 0.24193662121357346]
	TIME [epoch: 8.56 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2615372333025263		[learning rate: 0.0053368]
	Learning Rate: 0.00533681
	LOSS [training: 0.2615372333025263 | validation: 0.26632107355764234]
	TIME [epoch: 8.55 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28455711426548874		[learning rate: 0.0053242]
	Learning Rate: 0.00532423
	LOSS [training: 0.28455711426548874 | validation: 0.179151928091]
	TIME [epoch: 8.55 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4188172619884898		[learning rate: 0.0053117]
	Learning Rate: 0.00531167
	LOSS [training: 0.4188172619884898 | validation: 0.27980811760532]
	TIME [epoch: 8.57 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4313020354293194		[learning rate: 0.0052991]
	Learning Rate: 0.00529914
	LOSS [training: 0.4313020354293194 | validation: 0.5462080738011875]
	TIME [epoch: 8.55 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3196046732035341		[learning rate: 0.0052866]
	Learning Rate: 0.00528664
	LOSS [training: 0.3196046732035341 | validation: 0.28338637999512606]
	TIME [epoch: 8.54 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3011667341007439		[learning rate: 0.0052742]
	Learning Rate: 0.00527417
	LOSS [training: 0.3011667341007439 | validation: 0.39702315075893274]
	TIME [epoch: 8.54 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27725816768979666		[learning rate: 0.0052617]
	Learning Rate: 0.00526173
	LOSS [training: 0.27725816768979666 | validation: 0.7747065139560867]
	TIME [epoch: 8.57 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37634434456578403		[learning rate: 0.0052493]
	Learning Rate: 0.00524931
	LOSS [training: 0.37634434456578403 | validation: 0.36033151701607846]
	TIME [epoch: 8.55 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3677804764251958		[learning rate: 0.0052369]
	Learning Rate: 0.00523693
	LOSS [training: 0.3677804764251958 | validation: 0.2081999040616031]
	TIME [epoch: 8.54 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3045810307904143		[learning rate: 0.0052246]
	Learning Rate: 0.00522458
	LOSS [training: 0.3045810307904143 | validation: 0.39641960438815205]
	TIME [epoch: 8.54 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3247140601206538		[learning rate: 0.0052123]
	Learning Rate: 0.00521225
	LOSS [training: 0.3247140601206538 | validation: 0.3662907208640317]
	TIME [epoch: 8.57 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3756562527241725		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.3756562527241725 | validation: 0.5086322010663671]
	TIME [epoch: 8.55 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.409949931834948		[learning rate: 0.0051877]
	Learning Rate: 0.00518769
	LOSS [training: 0.409949931834948 | validation: 0.22141811419403565]
	TIME [epoch: 8.55 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.259155802299332		[learning rate: 0.0051755]
	Learning Rate: 0.00517546
	LOSS [training: 0.259155802299332 | validation: 0.4873094912190258]
	TIME [epoch: 8.55 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29597428037095813		[learning rate: 0.0051632]
	Learning Rate: 0.00516325
	LOSS [training: 0.29597428037095813 | validation: 0.3802428691709469]
	TIME [epoch: 8.57 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3626228308591195		[learning rate: 0.0051511]
	Learning Rate: 0.00515107
	LOSS [training: 0.3626228308591195 | validation: 0.4527124128572223]
	TIME [epoch: 8.55 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.573986754744601		[learning rate: 0.0051389]
	Learning Rate: 0.00513892
	LOSS [training: 0.573986754744601 | validation: 0.398368843923787]
	TIME [epoch: 8.55 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2914552317789773		[learning rate: 0.0051268]
	Learning Rate: 0.0051268
	LOSS [training: 0.2914552317789773 | validation: 0.2185740531646828]
	TIME [epoch: 8.54 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978875795467451		[learning rate: 0.0051147]
	Learning Rate: 0.0051147
	LOSS [training: 0.2978875795467451 | validation: 0.3615752841889447]
	TIME [epoch: 8.57 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26508448664778883		[learning rate: 0.0051026]
	Learning Rate: 0.00510264
	LOSS [training: 0.26508448664778883 | validation: 0.1924673031831096]
	TIME [epoch: 8.54 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31662041248735096		[learning rate: 0.0050906]
	Learning Rate: 0.0050906
	LOSS [training: 0.31662041248735096 | validation: 0.19691942591068334]
	TIME [epoch: 8.54 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37158623589762596		[learning rate: 0.0050786]
	Learning Rate: 0.00507859
	LOSS [training: 0.37158623589762596 | validation: 0.30620369131863423]
	TIME [epoch: 8.54 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788778169173901		[learning rate: 0.0050666]
	Learning Rate: 0.00506661
	LOSS [training: 0.2788778169173901 | validation: 0.4798144883660081]
	TIME [epoch: 8.58 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36434620837029924		[learning rate: 0.0050547]
	Learning Rate: 0.00505466
	LOSS [training: 0.36434620837029924 | validation: 0.2947208647009584]
	TIME [epoch: 8.55 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29504734350914025		[learning rate: 0.0050427]
	Learning Rate: 0.00504274
	LOSS [training: 0.29504734350914025 | validation: 0.2645115654961293]
	TIME [epoch: 8.55 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2789409383042599		[learning rate: 0.0050308]
	Learning Rate: 0.00503085
	LOSS [training: 0.2789409383042599 | validation: 0.18844873592487213]
	TIME [epoch: 8.55 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3024204761056116		[learning rate: 0.005019]
	Learning Rate: 0.00501898
	LOSS [training: 0.3024204761056116 | validation: 0.28058478330675046]
	TIME [epoch: 8.57 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2912961997507668		[learning rate: 0.0050071]
	Learning Rate: 0.00500714
	LOSS [training: 0.2912961997507668 | validation: 0.2534732656412175]
	TIME [epoch: 8.54 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29811199797427584		[learning rate: 0.0049953]
	Learning Rate: 0.00499533
	LOSS [training: 0.29811199797427584 | validation: 0.3221265522671437]
	TIME [epoch: 8.54 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3890517505605186		[learning rate: 0.0049835]
	Learning Rate: 0.00498355
	LOSS [training: 0.3890517505605186 | validation: 0.23367892742246676]
	TIME [epoch: 8.56 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34376120122465603		[learning rate: 0.0049718]
	Learning Rate: 0.00497179
	LOSS [training: 0.34376120122465603 | validation: 0.21070023791572756]
	TIME [epoch: 8.56 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3023361788495875		[learning rate: 0.0049601]
	Learning Rate: 0.00496006
	LOSS [training: 0.3023361788495875 | validation: 0.22824170751135198]
	TIME [epoch: 8.54 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3782829675415614		[learning rate: 0.0049484]
	Learning Rate: 0.00494836
	LOSS [training: 0.3782829675415614 | validation: 0.35660522176815257]
	TIME [epoch: 8.54 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4049008392071075		[learning rate: 0.0049367]
	Learning Rate: 0.00493669
	LOSS [training: 0.4049008392071075 | validation: 0.5627241732357888]
	TIME [epoch: 8.56 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4549751053324186		[learning rate: 0.004925]
	Learning Rate: 0.00492505
	LOSS [training: 0.4549751053324186 | validation: 0.2598651217000465]
	TIME [epoch: 8.55 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44174346283734856		[learning rate: 0.0049134]
	Learning Rate: 0.00491343
	LOSS [training: 0.44174346283734856 | validation: 0.2637127027581509]
	TIME [epoch: 8.54 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32905403922477994		[learning rate: 0.0049018]
	Learning Rate: 0.00490184
	LOSS [training: 0.32905403922477994 | validation: 0.19232667111581753]
	TIME [epoch: 8.54 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25736913440193354		[learning rate: 0.0048903]
	Learning Rate: 0.00489028
	LOSS [training: 0.25736913440193354 | validation: 0.333644374684929]
	TIME [epoch: 8.56 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4527830796246516		[learning rate: 0.0048787]
	Learning Rate: 0.00487874
	LOSS [training: 0.4527830796246516 | validation: 0.233900218261302]
	TIME [epoch: 8.54 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2614368316298013		[learning rate: 0.0048672]
	Learning Rate: 0.00486723
	LOSS [training: 0.2614368316298013 | validation: 0.28594406777625225]
	TIME [epoch: 8.54 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3987467554090892		[learning rate: 0.0048558]
	Learning Rate: 0.00485575
	LOSS [training: 0.3987467554090892 | validation: 0.545159763673297]
	TIME [epoch: 8.54 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43010552965566634		[learning rate: 0.0048443]
	Learning Rate: 0.0048443
	LOSS [training: 0.43010552965566634 | validation: 0.20397263392667506]
	TIME [epoch: 8.57 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2767040495022898		[learning rate: 0.0048329]
	Learning Rate: 0.00483287
	LOSS [training: 0.2767040495022898 | validation: 0.28174585100910743]
	TIME [epoch: 8.54 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41045589268914506		[learning rate: 0.0048215]
	Learning Rate: 0.00482147
	LOSS [training: 0.41045589268914506 | validation: 0.23140864623038926]
	TIME [epoch: 8.54 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2958925120559571		[learning rate: 0.0048101]
	Learning Rate: 0.0048101
	LOSS [training: 0.2958925120559571 | validation: 0.29411482752875306]
	TIME [epoch: 8.54 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020733673036523		[learning rate: 0.0047988]
	Learning Rate: 0.00479875
	LOSS [training: 0.3020733673036523 | validation: 0.408530319723301]
	TIME [epoch: 8.57 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3219287812691598		[learning rate: 0.0047874]
	Learning Rate: 0.00478743
	LOSS [training: 0.3219287812691598 | validation: 0.20582100323300512]
	TIME [epoch: 8.55 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.311736184630478		[learning rate: 0.0047761]
	Learning Rate: 0.00477614
	LOSS [training: 0.311736184630478 | validation: 0.2850423842186598]
	TIME [epoch: 8.54 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3162932236939743		[learning rate: 0.0047649]
	Learning Rate: 0.00476487
	LOSS [training: 0.3162932236939743 | validation: 0.26454253588264653]
	TIME [epoch: 8.54 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31779077567200015		[learning rate: 0.0047536]
	Learning Rate: 0.00475363
	LOSS [training: 0.31779077567200015 | validation: 0.20303538038445776]
	TIME [epoch: 8.57 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30316843022014756		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.30316843022014756 | validation: 0.22324707324462734]
	TIME [epoch: 8.55 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33513653180885544		[learning rate: 0.0047312]
	Learning Rate: 0.00473123
	LOSS [training: 0.33513653180885544 | validation: 0.2696367223100727]
	TIME [epoch: 8.54 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3400604432219107		[learning rate: 0.0047201]
	Learning Rate: 0.00472007
	LOSS [training: 0.3400604432219107 | validation: 0.4125719805246394]
	TIME [epoch: 8.54 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33835101676888685		[learning rate: 0.0047089]
	Learning Rate: 0.00470894
	LOSS [training: 0.33835101676888685 | validation: 0.3412581019932617]
	TIME [epoch: 8.56 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3044281367839656		[learning rate: 0.0046978]
	Learning Rate: 0.00469783
	LOSS [training: 0.3044281367839656 | validation: 0.5227585480698218]
	TIME [epoch: 8.54 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2773147373382035		[learning rate: 0.0046868]
	Learning Rate: 0.00468675
	LOSS [training: 0.2773147373382035 | validation: 0.2541652962248216]
	TIME [epoch: 8.54 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3377920425083262		[learning rate: 0.0046757]
	Learning Rate: 0.00467569
	LOSS [training: 0.3377920425083262 | validation: 0.17984002547154074]
	TIME [epoch: 8.55 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671074856856623		[learning rate: 0.0046647]
	Learning Rate: 0.00466467
	LOSS [training: 0.2671074856856623 | validation: 0.19587160923564134]
	TIME [epoch: 8.56 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25424782911594845		[learning rate: 0.0046537]
	Learning Rate: 0.00465366
	LOSS [training: 0.25424782911594845 | validation: 0.36548539405187785]
	TIME [epoch: 8.54 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26816193990009873		[learning rate: 0.0046427]
	Learning Rate: 0.00464268
	LOSS [training: 0.26816193990009873 | validation: 0.43744406899614346]
	TIME [epoch: 8.54 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3292245857009034		[learning rate: 0.0046317]
	Learning Rate: 0.00463173
	LOSS [training: 0.3292245857009034 | validation: 0.4260625369996831]
	TIME [epoch: 8.55 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4347700282684389		[learning rate: 0.0046208]
	Learning Rate: 0.00462081
	LOSS [training: 0.4347700282684389 | validation: 0.32287386372735066]
	TIME [epoch: 8.56 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105692552419771		[learning rate: 0.0046099]
	Learning Rate: 0.00460991
	LOSS [training: 0.3105692552419771 | validation: 0.28013870905464333]
	TIME [epoch: 8.55 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3258146267186037		[learning rate: 0.004599]
	Learning Rate: 0.00459903
	LOSS [training: 0.3258146267186037 | validation: 0.3085329538722409]
	TIME [epoch: 8.54 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3457846054980948		[learning rate: 0.0045882]
	Learning Rate: 0.00458819
	LOSS [training: 0.3457846054980948 | validation: 0.19167705246317834]
	TIME [epoch: 8.56 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2590156878396126		[learning rate: 0.0045774]
	Learning Rate: 0.00457736
	LOSS [training: 0.2590156878396126 | validation: 0.2471500188948394]
	TIME [epoch: 8.55 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24808095262962673		[learning rate: 0.0045666]
	Learning Rate: 0.00456657
	LOSS [training: 0.24808095262962673 | validation: 0.252604644456196]
	TIME [epoch: 8.54 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3182182165510965		[learning rate: 0.0045558]
	Learning Rate: 0.00455579
	LOSS [training: 0.3182182165510965 | validation: 0.24326668534868384]
	TIME [epoch: 8.54 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2933351413744445		[learning rate: 0.004545]
	Learning Rate: 0.00454505
	LOSS [training: 0.2933351413744445 | validation: 0.33706639736439553]
	TIME [epoch: 8.56 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31086531332161216		[learning rate: 0.0045343]
	Learning Rate: 0.00453433
	LOSS [training: 0.31086531332161216 | validation: 0.21698340513461373]
	TIME [epoch: 8.54 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28969780450708477		[learning rate: 0.0045236]
	Learning Rate: 0.00452363
	LOSS [training: 0.28969780450708477 | validation: 0.32725548409851724]
	TIME [epoch: 8.54 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2826479895368421		[learning rate: 0.004513]
	Learning Rate: 0.00451296
	LOSS [training: 0.2826479895368421 | validation: 0.3094312983459826]
	TIME [epoch: 8.54 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34084123444063286		[learning rate: 0.0045023]
	Learning Rate: 0.00450232
	LOSS [training: 0.34084123444063286 | validation: 0.3599491176895424]
	TIME [epoch: 8.56 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33436330626153665		[learning rate: 0.0044917]
	Learning Rate: 0.00449169
	LOSS [training: 0.33436330626153665 | validation: 0.3738488149050475]
	TIME [epoch: 8.54 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3577747569577454		[learning rate: 0.0044811]
	Learning Rate: 0.0044811
	LOSS [training: 0.3577747569577454 | validation: 0.7726695911303751]
	TIME [epoch: 8.54 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3785456992743368		[learning rate: 0.0044705]
	Learning Rate: 0.00447053
	LOSS [training: 0.3785456992743368 | validation: 0.33080258836078125]
	TIME [epoch: 8.54 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702176505387965		[learning rate: 0.00446]
	Learning Rate: 0.00445998
	LOSS [training: 0.2702176505387965 | validation: 0.3066155240939208]
	TIME [epoch: 8.56 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109175469830819		[learning rate: 0.0044495]
	Learning Rate: 0.00444946
	LOSS [training: 0.3109175469830819 | validation: 0.2870178489108545]
	TIME [epoch: 8.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25228301955408533		[learning rate: 0.004439]
	Learning Rate: 0.00443897
	LOSS [training: 0.25228301955408533 | validation: 0.1391131544968065]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_394.pth
	Model improved!!!
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2736503468849648		[learning rate: 0.0044285]
	Learning Rate: 0.0044285
	LOSS [training: 0.2736503468849648 | validation: 0.21702115395535604]
	TIME [epoch: 8.54 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.259367332437563		[learning rate: 0.0044181]
	Learning Rate: 0.00441805
	LOSS [training: 0.259367332437563 | validation: 0.17902366419058258]
	TIME [epoch: 8.57 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28696050606380263		[learning rate: 0.0044076]
	Learning Rate: 0.00440763
	LOSS [training: 0.28696050606380263 | validation: 0.16869126422236025]
	TIME [epoch: 8.55 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760270598341927		[learning rate: 0.0043972]
	Learning Rate: 0.00439723
	LOSS [training: 0.2760270598341927 | validation: 0.19089860828873118]
	TIME [epoch: 8.55 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26619207570800774		[learning rate: 0.0043869]
	Learning Rate: 0.00438686
	LOSS [training: 0.26619207570800774 | validation: 0.15921168556398949]
	TIME [epoch: 8.55 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24763619271262827		[learning rate: 0.0043765]
	Learning Rate: 0.00437651
	LOSS [training: 0.24763619271262827 | validation: 0.14873715306523652]
	TIME [epoch: 8.57 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22172170435148258		[learning rate: 0.0043662]
	Learning Rate: 0.00436619
	LOSS [training: 0.22172170435148258 | validation: 0.224651510439335]
	TIME [epoch: 8.54 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22999513180654016		[learning rate: 0.0043559]
	Learning Rate: 0.00435589
	LOSS [training: 0.22999513180654016 | validation: 0.12613122113283776]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3157938124885823		[learning rate: 0.0043456]
	Learning Rate: 0.00434561
	LOSS [training: 0.3157938124885823 | validation: 0.1445358443595559]
	TIME [epoch: 8.55 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23567686307736352		[learning rate: 0.0043354]
	Learning Rate: 0.00433536
	LOSS [training: 0.23567686307736352 | validation: 0.1661050127306229]
	TIME [epoch: 8.55 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29457076894190826		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.29457076894190826 | validation: 0.21299599920506918]
	TIME [epoch: 8.54 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22316788023452575		[learning rate: 0.0043149]
	Learning Rate: 0.00431494
	LOSS [training: 0.22316788023452575 | validation: 0.3590746608572365]
	TIME [epoch: 8.54 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2754972422599813		[learning rate: 0.0043048]
	Learning Rate: 0.00430476
	LOSS [training: 0.2754972422599813 | validation: 0.2894001552090005]
	TIME [epoch: 8.55 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27457351160591054		[learning rate: 0.0042946]
	Learning Rate: 0.0042946
	LOSS [training: 0.27457351160591054 | validation: 0.14153933673736752]
	TIME [epoch: 8.55 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22126755868332199		[learning rate: 0.0042845]
	Learning Rate: 0.00428447
	LOSS [training: 0.22126755868332199 | validation: 0.46834510925698736]
	TIME [epoch: 8.54 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3750523532413419		[learning rate: 0.0042744]
	Learning Rate: 0.00427437
	LOSS [training: 0.3750523532413419 | validation: 0.48630689972782026]
	TIME [epoch: 8.53 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25965448174840045		[learning rate: 0.0042643]
	Learning Rate: 0.00426428
	LOSS [training: 0.25965448174840045 | validation: 0.12896980288774673]
	TIME [epoch: 8.56 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22612771955863992		[learning rate: 0.0042542]
	Learning Rate: 0.00425423
	LOSS [training: 0.22612771955863992 | validation: 0.12873327524651035]
	TIME [epoch: 8.55 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36026270389277537		[learning rate: 0.0042442]
	Learning Rate: 0.00424419
	LOSS [training: 0.36026270389277537 | validation: 0.14367051060981137]
	TIME [epoch: 8.54 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27000191286350594		[learning rate: 0.0042342]
	Learning Rate: 0.00423418
	LOSS [training: 0.27000191286350594 | validation: 0.2191976216187741]
	TIME [epoch: 8.54 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006456729481476		[learning rate: 0.0042242]
	Learning Rate: 0.00422419
	LOSS [training: 0.3006456729481476 | validation: 0.12732415743967115]
	TIME [epoch: 8.57 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1975188386008774		[learning rate: 0.0042142]
	Learning Rate: 0.00421423
	LOSS [training: 0.1975188386008774 | validation: 0.29064735173511413]
	TIME [epoch: 8.54 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29535722761937244		[learning rate: 0.0042043]
	Learning Rate: 0.00420429
	LOSS [training: 0.29535722761937244 | validation: 0.42721199600795656]
	TIME [epoch: 8.54 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24041097042521914		[learning rate: 0.0041944]
	Learning Rate: 0.00419437
	LOSS [training: 0.24041097042521914 | validation: 0.18651965780698665]
	TIME [epoch: 8.53 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27938570817932595		[learning rate: 0.0041845]
	Learning Rate: 0.00418448
	LOSS [training: 0.27938570817932595 | validation: 0.2369320945500869]
	TIME [epoch: 8.56 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3147180094529161		[learning rate: 0.0041746]
	Learning Rate: 0.0041746
	LOSS [training: 0.3147180094529161 | validation: 0.33847576918838485]
	TIME [epoch: 8.54 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34120516902451625		[learning rate: 0.0041648]
	Learning Rate: 0.00416476
	LOSS [training: 0.34120516902451625 | validation: 0.2135871716911963]
	TIME [epoch: 8.53 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23560252200722606		[learning rate: 0.0041549]
	Learning Rate: 0.00415493
	LOSS [training: 0.23560252200722606 | validation: 0.14882777503744835]
	TIME [epoch: 8.54 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601828204399985		[learning rate: 0.0041451]
	Learning Rate: 0.00414513
	LOSS [training: 0.2601828204399985 | validation: 0.2875281796878484]
	TIME [epoch: 8.57 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2768202909803738		[learning rate: 0.0041354]
	Learning Rate: 0.00413535
	LOSS [training: 0.2768202909803738 | validation: 0.3557095277297535]
	TIME [epoch: 8.54 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760965375834381		[learning rate: 0.0041256]
	Learning Rate: 0.0041256
	LOSS [training: 0.2760965375834381 | validation: 0.30006248896568666]
	TIME [epoch: 8.54 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24913973161670064		[learning rate: 0.0041159]
	Learning Rate: 0.00411587
	LOSS [training: 0.24913973161670064 | validation: 0.11600754908385116]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22755438526297408		[learning rate: 0.0041062]
	Learning Rate: 0.00410616
	LOSS [training: 0.22755438526297408 | validation: 0.13847720143509423]
	TIME [epoch: 8.57 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23219833440140297		[learning rate: 0.0040965]
	Learning Rate: 0.00409647
	LOSS [training: 0.23219833440140297 | validation: 0.2131157242650476]
	TIME [epoch: 8.54 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2695431752646689		[learning rate: 0.0040868]
	Learning Rate: 0.00408681
	LOSS [training: 0.2695431752646689 | validation: 0.17693791939500125]
	TIME [epoch: 8.54 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2342118331752067		[learning rate: 0.0040772]
	Learning Rate: 0.00407717
	LOSS [training: 0.2342118331752067 | validation: 0.15905805334933448]
	TIME [epoch: 8.54 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2620737833554054		[learning rate: 0.0040676]
	Learning Rate: 0.00406755
	LOSS [training: 0.2620737833554054 | validation: 0.2352952043633827]
	TIME [epoch: 8.56 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2257834112624281		[learning rate: 0.004058]
	Learning Rate: 0.00405796
	LOSS [training: 0.2257834112624281 | validation: 0.12496448083582266]
	TIME [epoch: 8.54 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24583763426457866		[learning rate: 0.0040484]
	Learning Rate: 0.00404839
	LOSS [training: 0.24583763426457866 | validation: 0.24122353526741713]
	TIME [epoch: 8.53 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27679931968616744		[learning rate: 0.0040388]
	Learning Rate: 0.00403884
	LOSS [training: 0.27679931968616744 | validation: 0.2599047240516104]
	TIME [epoch: 8.55 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2717538629229146		[learning rate: 0.0040293]
	Learning Rate: 0.00402931
	LOSS [training: 0.2717538629229146 | validation: 0.1735327093649295]
	TIME [epoch: 8.55 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19042886438071777		[learning rate: 0.0040198]
	Learning Rate: 0.00401981
	LOSS [training: 0.19042886438071777 | validation: 0.16570342790118198]
	TIME [epoch: 8.54 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3134324618333709		[learning rate: 0.0040103]
	Learning Rate: 0.00401032
	LOSS [training: 0.3134324618333709 | validation: 0.1786650939028705]
	TIME [epoch: 8.53 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22305642302723827		[learning rate: 0.0040009]
	Learning Rate: 0.00400086
	LOSS [training: 0.22305642302723827 | validation: 0.21018464620511368]
	TIME [epoch: 8.55 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19867109358629495		[learning rate: 0.0039914]
	Learning Rate: 0.00399143
	LOSS [training: 0.19867109358629495 | validation: 0.1581316164860898]
	TIME [epoch: 8.55 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.315468042787064		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.315468042787064 | validation: 0.13640271448315708]
	TIME [epoch: 8.54 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2823109392393515		[learning rate: 0.0039726]
	Learning Rate: 0.00397262
	LOSS [training: 0.2823109392393515 | validation: 0.15000106594157478]
	TIME [epoch: 8.54 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3422432892349924		[learning rate: 0.0039632]
	Learning Rate: 0.00396325
	LOSS [training: 0.3422432892349924 | validation: 0.34111413738545915]
	TIME [epoch: 8.56 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21596207110593796		[learning rate: 0.0039539]
	Learning Rate: 0.0039539
	LOSS [training: 0.21596207110593796 | validation: 0.29260346822161476]
	TIME [epoch: 8.54 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2189625359133677		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.2189625359133677 | validation: 0.1811761438191124]
	TIME [epoch: 8.54 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23063722892852806		[learning rate: 0.0039353]
	Learning Rate: 0.00393527
	LOSS [training: 0.23063722892852806 | validation: 0.4201554233523326]
	TIME [epoch: 8.54 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2646564159819537		[learning rate: 0.003926]
	Learning Rate: 0.00392599
	LOSS [training: 0.2646564159819537 | validation: 0.3251272125604501]
	TIME [epoch: 8.56 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506842261433838		[learning rate: 0.0039167]
	Learning Rate: 0.00391672
	LOSS [training: 0.2506842261433838 | validation: 0.27449364053322756]
	TIME [epoch: 8.54 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23665257386319535		[learning rate: 0.0039075]
	Learning Rate: 0.00390749
	LOSS [training: 0.23665257386319535 | validation: 0.19748627659452025]
	TIME [epoch: 8.54 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2374412639582184		[learning rate: 0.0038983]
	Learning Rate: 0.00389827
	LOSS [training: 0.2374412639582184 | validation: 0.32982549985293164]
	TIME [epoch: 8.54 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30833670759884074		[learning rate: 0.0038891]
	Learning Rate: 0.00388907
	LOSS [training: 0.30833670759884074 | validation: 0.21415048041283236]
	TIME [epoch: 8.57 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3010311963947493		[learning rate: 0.0038799]
	Learning Rate: 0.0038799
	LOSS [training: 0.3010311963947493 | validation: 0.1952815996729984]
	TIME [epoch: 8.54 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23524504562149065		[learning rate: 0.0038707]
	Learning Rate: 0.00387075
	LOSS [training: 0.23524504562149065 | validation: 0.549022854744931]
	TIME [epoch: 8.54 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4155954068363905		[learning rate: 0.0038616]
	Learning Rate: 0.00386162
	LOSS [training: 0.4155954068363905 | validation: 0.2179727177490425]
	TIME [epoch: 8.54 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27266768158543064		[learning rate: 0.0038525]
	Learning Rate: 0.00385251
	LOSS [training: 0.27266768158543064 | validation: 0.278686419118633]
	TIME [epoch: 8.57 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27409389982274		[learning rate: 0.0038434]
	Learning Rate: 0.00384342
	LOSS [training: 0.27409389982274 | validation: 0.1934410696718754]
	TIME [epoch: 8.54 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.286279466576318		[learning rate: 0.0038344]
	Learning Rate: 0.00383435
	LOSS [training: 0.286279466576318 | validation: 0.18563233141530477]
	TIME [epoch: 8.54 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2134403931742387		[learning rate: 0.0038253]
	Learning Rate: 0.00382531
	LOSS [training: 0.2134403931742387 | validation: 0.1985870653310169]
	TIME [epoch: 8.54 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24665358628424183		[learning rate: 0.0038163]
	Learning Rate: 0.00381629
	LOSS [training: 0.24665358628424183 | validation: 0.23371657450067784]
	TIME [epoch: 8.56 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20793627994970282		[learning rate: 0.0038073]
	Learning Rate: 0.00380728
	LOSS [training: 0.20793627994970282 | validation: 0.2762068028569503]
	TIME [epoch: 8.54 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2747092255495839		[learning rate: 0.0037983]
	Learning Rate: 0.0037983
	LOSS [training: 0.2747092255495839 | validation: 0.36740084077120894]
	TIME [epoch: 8.54 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2529317843505607		[learning rate: 0.0037893]
	Learning Rate: 0.00378934
	LOSS [training: 0.2529317843505607 | validation: 0.19159659048251643]
	TIME [epoch: 8.54 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072627665112705		[learning rate: 0.0037804]
	Learning Rate: 0.00378041
	LOSS [training: 0.2072627665112705 | validation: 0.12465530427774357]
	TIME [epoch: 8.57 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20022279149807115		[learning rate: 0.0037715]
	Learning Rate: 0.00377149
	LOSS [training: 0.20022279149807115 | validation: 0.3552261630220128]
	TIME [epoch: 8.54 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24638126641147046		[learning rate: 0.0037626]
	Learning Rate: 0.00376259
	LOSS [training: 0.24638126641147046 | validation: 0.17887688389481743]
	TIME [epoch: 8.54 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20953695870212816		[learning rate: 0.0037537]
	Learning Rate: 0.00375372
	LOSS [training: 0.20953695870212816 | validation: 0.2772357529912939]
	TIME [epoch: 8.55 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24893453381701902		[learning rate: 0.0037449]
	Learning Rate: 0.00374486
	LOSS [training: 0.24893453381701902 | validation: 0.3251474763164268]
	TIME [epoch: 8.57 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24350552323892888		[learning rate: 0.003736]
	Learning Rate: 0.00373603
	LOSS [training: 0.24350552323892888 | validation: 0.15355858166415204]
	TIME [epoch: 8.54 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20196354564906355		[learning rate: 0.0037272]
	Learning Rate: 0.00372722
	LOSS [training: 0.20196354564906355 | validation: 0.17669179633707094]
	TIME [epoch: 8.54 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17411886373638502		[learning rate: 0.0037184]
	Learning Rate: 0.00371842
	LOSS [training: 0.17411886373638502 | validation: 0.14252503804984323]
	TIME [epoch: 8.56 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16387629498585943		[learning rate: 0.0037097]
	Learning Rate: 0.00370965
	LOSS [training: 0.16387629498585943 | validation: 0.25302489767114145]
	TIME [epoch: 8.55 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20306392581903973		[learning rate: 0.0037009]
	Learning Rate: 0.0037009
	LOSS [training: 0.20306392581903973 | validation: 0.20366906760652537]
	TIME [epoch: 8.54 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18533860043471945		[learning rate: 0.0036922]
	Learning Rate: 0.00369217
	LOSS [training: 0.18533860043471945 | validation: 0.4042904476291138]
	TIME [epoch: 8.54 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2173845127648908		[learning rate: 0.0036835]
	Learning Rate: 0.00368346
	LOSS [training: 0.2173845127648908 | validation: 0.19616555272980254]
	TIME [epoch: 8.56 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29925227722034503		[learning rate: 0.0036748]
	Learning Rate: 0.00367478
	LOSS [training: 0.29925227722034503 | validation: 0.17650761735531106]
	TIME [epoch: 8.55 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296804733270395		[learning rate: 0.0036661]
	Learning Rate: 0.00366611
	LOSS [training: 0.2296804733270395 | validation: 0.26002727590235497]
	TIME [epoch: 8.54 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34238374603970845		[learning rate: 0.0036575]
	Learning Rate: 0.00365746
	LOSS [training: 0.34238374603970845 | validation: 0.16307399736300707]
	TIME [epoch: 8.54 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19864260479573895		[learning rate: 0.0036488]
	Learning Rate: 0.00364883
	LOSS [training: 0.19864260479573895 | validation: 0.21027379847523742]
	TIME [epoch: 8.56 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2243797271233546		[learning rate: 0.0036402]
	Learning Rate: 0.00364022
	LOSS [training: 0.2243797271233546 | validation: 0.32883223244916643]
	TIME [epoch: 8.55 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23472290104402607		[learning rate: 0.0036316]
	Learning Rate: 0.00363164
	LOSS [training: 0.23472290104402607 | validation: 0.29011053465140235]
	TIME [epoch: 8.54 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2537227991553891		[learning rate: 0.0036231]
	Learning Rate: 0.00362307
	LOSS [training: 0.2537227991553891 | validation: 0.3802803106518603]
	TIME [epoch: 8.55 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3620195088884043		[learning rate: 0.0036145]
	Learning Rate: 0.00361453
	LOSS [training: 0.3620195088884043 | validation: 0.25039419945282]
	TIME [epoch: 8.56 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25408755273943445		[learning rate: 0.003606]
	Learning Rate: 0.003606
	LOSS [training: 0.25408755273943445 | validation: 0.25265315183231535]
	TIME [epoch: 8.55 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26825326465471877		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.26825326465471877 | validation: 0.14682345950975376]
	TIME [epoch: 8.54 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35014638367291007		[learning rate: 0.003589]
	Learning Rate: 0.00358901
	LOSS [training: 0.35014638367291007 | validation: 0.7561998100996818]
	TIME [epoch: 8.54 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3450229683296147		[learning rate: 0.0035805]
	Learning Rate: 0.00358054
	LOSS [training: 0.3450229683296147 | validation: 0.34823982753760596]
	TIME [epoch: 8.57 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797385244337084		[learning rate: 0.0035721]
	Learning Rate: 0.0035721
	LOSS [training: 0.2797385244337084 | validation: 0.3058527813763734]
	TIME [epoch: 8.55 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23180510385184894		[learning rate: 0.0035637]
	Learning Rate: 0.00356367
	LOSS [training: 0.23180510385184894 | validation: 0.24225280596252674]
	TIME [epoch: 8.54 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24804346293771112		[learning rate: 0.0035553]
	Learning Rate: 0.00355526
	LOSS [training: 0.24804346293771112 | validation: 0.30991793849971794]
	TIME [epoch: 8.55 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28963226367665285		[learning rate: 0.0035469]
	Learning Rate: 0.00354688
	LOSS [training: 0.28963226367665285 | validation: 0.40370763939138965]
	TIME [epoch: 8.57 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28282869886261064		[learning rate: 0.0035385]
	Learning Rate: 0.00353851
	LOSS [training: 0.28282869886261064 | validation: 0.2350027689467678]
	TIME [epoch: 8.54 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21545111103699294		[learning rate: 0.0035302]
	Learning Rate: 0.00353016
	LOSS [training: 0.21545111103699294 | validation: 0.19406257067204224]
	TIME [epoch: 8.54 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24038701954862662		[learning rate: 0.0035218]
	Learning Rate: 0.00352184
	LOSS [training: 0.24038701954862662 | validation: 0.2560064467664144]
	TIME [epoch: 8.54 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24263503912299123		[learning rate: 0.0035135]
	Learning Rate: 0.00351353
	LOSS [training: 0.24263503912299123 | validation: 0.19495797308557417]
	TIME [epoch: 8.57 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21325761561138412		[learning rate: 0.0035052]
	Learning Rate: 0.00350524
	LOSS [training: 0.21325761561138412 | validation: 0.3409041256663107]
	TIME [epoch: 8.54 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3031689853898957		[learning rate: 0.003497]
	Learning Rate: 0.00349697
	LOSS [training: 0.3031689853898957 | validation: 0.24729985375483565]
	TIME [epoch: 8.54 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2453791408229761		[learning rate: 0.0034887]
	Learning Rate: 0.00348872
	LOSS [training: 0.2453791408229761 | validation: 0.27174730912596967]
	TIME [epoch: 8.55 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24768619349001822		[learning rate: 0.0034805]
	Learning Rate: 0.00348049
	LOSS [training: 0.24768619349001822 | validation: 0.31778783322582765]
	TIME [epoch: 8.56 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34656335268184746		[learning rate: 0.0034723]
	Learning Rate: 0.00347228
	LOSS [training: 0.34656335268184746 | validation: 0.18356422072507833]
	TIME [epoch: 8.55 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2448125099398871		[learning rate: 0.0034641]
	Learning Rate: 0.00346409
	LOSS [training: 0.2448125099398871 | validation: 0.21628416693628055]
	TIME [epoch: 8.54 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556011160783328		[learning rate: 0.0034559]
	Learning Rate: 0.00345592
	LOSS [training: 0.2556011160783328 | validation: 0.26219033087722476]
	TIME [epoch: 8.56 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2726013683248595		[learning rate: 0.0034478]
	Learning Rate: 0.00344777
	LOSS [training: 0.2726013683248595 | validation: 0.19943716040676157]
	TIME [epoch: 8.55 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22929980138441075		[learning rate: 0.0034396]
	Learning Rate: 0.00343964
	LOSS [training: 0.22929980138441075 | validation: 0.1631983641186987]
	TIME [epoch: 8.54 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2384746182641412		[learning rate: 0.0034315]
	Learning Rate: 0.00343152
	LOSS [training: 0.2384746182641412 | validation: 0.25259947100744995]
	TIME [epoch: 8.54 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661898238568724		[learning rate: 0.0034234]
	Learning Rate: 0.00342343
	LOSS [training: 0.2661898238568724 | validation: 0.21463664994761866]
	TIME [epoch: 8.55 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18508812011245793		[learning rate: 0.0034154]
	Learning Rate: 0.00341535
	LOSS [training: 0.18508812011245793 | validation: 0.2870862929561372]
	TIME [epoch: 8.55 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21532068507436422		[learning rate: 0.0034073]
	Learning Rate: 0.0034073
	LOSS [training: 0.21532068507436422 | validation: 0.1992889005598887]
	TIME [epoch: 8.54 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1960139073859813		[learning rate: 0.0033993]
	Learning Rate: 0.00339926
	LOSS [training: 0.1960139073859813 | validation: 0.32366779537844775]
	TIME [epoch: 8.53 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23187502206157617		[learning rate: 0.0033912]
	Learning Rate: 0.00339124
	LOSS [training: 0.23187502206157617 | validation: 0.21974218817533187]
	TIME [epoch: 8.56 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18913657084311458		[learning rate: 0.0033832]
	Learning Rate: 0.00338324
	LOSS [training: 0.18913657084311458 | validation: 0.4492511654250504]
	TIME [epoch: 8.54 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3311718025143816		[learning rate: 0.0033753]
	Learning Rate: 0.00337526
	LOSS [training: 0.3311718025143816 | validation: 0.31449943990323603]
	TIME [epoch: 8.54 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2361165193362551		[learning rate: 0.0033673]
	Learning Rate: 0.0033673
	LOSS [training: 0.2361165193362551 | validation: 0.18194015227804128]
	TIME [epoch: 8.54 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22436925243995223		[learning rate: 0.0033594]
	Learning Rate: 0.00335936
	LOSS [training: 0.22436925243995223 | validation: 0.16309941805366834]
	TIME [epoch: 8.56 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23916632353978168		[learning rate: 0.0033514]
	Learning Rate: 0.00335143
	LOSS [training: 0.23916632353978168 | validation: 0.17516961731106967]
	TIME [epoch: 8.54 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17301964812098752		[learning rate: 0.0033435]
	Learning Rate: 0.00334353
	LOSS [training: 0.17301964812098752 | validation: 0.23183254822597207]
	TIME [epoch: 8.54 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17520061433891795		[learning rate: 0.0033356]
	Learning Rate: 0.00333564
	LOSS [training: 0.17520061433891795 | validation: 0.44562686878240265]
	TIME [epoch: 8.54 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105924249300237		[learning rate: 0.0033278]
	Learning Rate: 0.00332777
	LOSS [training: 0.3105924249300237 | validation: 0.27018335873157584]
	TIME [epoch: 8.56 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2169947039526424		[learning rate: 0.0033199]
	Learning Rate: 0.00331992
	LOSS [training: 0.2169947039526424 | validation: 0.2627766669551944]
	TIME [epoch: 8.54 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22253022352114957		[learning rate: 0.0033121]
	Learning Rate: 0.00331209
	LOSS [training: 0.22253022352114957 | validation: 0.12306462272042587]
	TIME [epoch: 8.54 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20685395404854207		[learning rate: 0.0033043]
	Learning Rate: 0.00330428
	LOSS [training: 0.20685395404854207 | validation: 0.2497088290818531]
	TIME [epoch: 8.53 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359399939490264		[learning rate: 0.0032965]
	Learning Rate: 0.00329649
	LOSS [training: 0.17359399939490264 | validation: 0.12999940448999878]
	TIME [epoch: 8.56 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17972667935179606		[learning rate: 0.0032887]
	Learning Rate: 0.00328871
	LOSS [training: 0.17972667935179606 | validation: 0.10187995162190519]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16931308979070156		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.16931308979070156 | validation: 0.13827786005219372]
	TIME [epoch: 8.53 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21490562526129775		[learning rate: 0.0032732]
	Learning Rate: 0.00327321
	LOSS [training: 0.21490562526129775 | validation: 0.2488726584167557]
	TIME [epoch: 8.53 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23458661417261154		[learning rate: 0.0032655]
	Learning Rate: 0.00326549
	LOSS [training: 0.23458661417261154 | validation: 0.23585891310586582]
	TIME [epoch: 8.56 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22039396611129206		[learning rate: 0.0032578]
	Learning Rate: 0.00325779
	LOSS [training: 0.22039396611129206 | validation: 0.1237657655051837]
	TIME [epoch: 8.53 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19813159946986464		[learning rate: 0.0032501]
	Learning Rate: 0.00325011
	LOSS [training: 0.19813159946986464 | validation: 0.17859059580789383]
	TIME [epoch: 8.53 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19703571943764436		[learning rate: 0.0032424]
	Learning Rate: 0.00324244
	LOSS [training: 0.19703571943764436 | validation: 0.20589961951299085]
	TIME [epoch: 8.54 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2053147235794444		[learning rate: 0.0032348]
	Learning Rate: 0.00323479
	LOSS [training: 0.2053147235794444 | validation: 0.20474176980296166]
	TIME [epoch: 8.55 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20862297111850375		[learning rate: 0.0032272]
	Learning Rate: 0.00322716
	LOSS [training: 0.20862297111850375 | validation: 0.3297745744566776]
	TIME [epoch: 8.53 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28063317055431025		[learning rate: 0.0032195]
	Learning Rate: 0.00321955
	LOSS [training: 0.28063317055431025 | validation: 0.22491921922868613]
	TIME [epoch: 8.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24956570959755883		[learning rate: 0.003212]
	Learning Rate: 0.00321195
	LOSS [training: 0.24956570959755883 | validation: 0.1364447214698083]
	TIME [epoch: 8.55 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19569051417476013		[learning rate: 0.0032044]
	Learning Rate: 0.00320438
	LOSS [training: 0.19569051417476013 | validation: 0.19064340926843398]
	TIME [epoch: 8.54 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22937679681830056		[learning rate: 0.0031968]
	Learning Rate: 0.00319682
	LOSS [training: 0.22937679681830056 | validation: 0.21852725442528936]
	TIME [epoch: 8.53 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22805597029968688		[learning rate: 0.0031893]
	Learning Rate: 0.00318928
	LOSS [training: 0.22805597029968688 | validation: 0.19395744639188944]
	TIME [epoch: 8.53 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22863355168161875		[learning rate: 0.0031818]
	Learning Rate: 0.00318175
	LOSS [training: 0.22863355168161875 | validation: 0.14097937774021058]
	TIME [epoch: 8.54 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19181805857385825		[learning rate: 0.0031742]
	Learning Rate: 0.00317425
	LOSS [training: 0.19181805857385825 | validation: 0.14386055099078937]
	TIME [epoch: 8.54 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19082535517607813		[learning rate: 0.0031668]
	Learning Rate: 0.00316676
	LOSS [training: 0.19082535517607813 | validation: 0.17561959439242705]
	TIME [epoch: 8.53 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26026872823178315		[learning rate: 0.0031593]
	Learning Rate: 0.00315929
	LOSS [training: 0.26026872823178315 | validation: 0.15031365932220112]
	TIME [epoch: 8.53 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18113698600255773		[learning rate: 0.0031518]
	Learning Rate: 0.00315184
	LOSS [training: 0.18113698600255773 | validation: 0.13381447929080104]
	TIME [epoch: 8.55 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19987553548906498		[learning rate: 0.0031444]
	Learning Rate: 0.0031444
	LOSS [training: 0.19987553548906498 | validation: 0.1185611253130131]
	TIME [epoch: 8.54 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16013307930559492		[learning rate: 0.003137]
	Learning Rate: 0.00313699
	LOSS [training: 0.16013307930559492 | validation: 0.2324167108891104]
	TIME [epoch: 8.53 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906142568777496		[learning rate: 0.0031296]
	Learning Rate: 0.00312959
	LOSS [training: 0.1906142568777496 | validation: 0.18752459829724627]
	TIME [epoch: 8.53 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1960327644603214		[learning rate: 0.0031222]
	Learning Rate: 0.00312221
	LOSS [training: 0.1960327644603214 | validation: 0.18170748643585402]
	TIME [epoch: 8.55 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296387486833849		[learning rate: 0.0031148]
	Learning Rate: 0.00311484
	LOSS [training: 0.2296387486833849 | validation: 0.1565711676586281]
	TIME [epoch: 8.53 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19443947079376614		[learning rate: 0.0031075]
	Learning Rate: 0.00310749
	LOSS [training: 0.19443947079376614 | validation: 0.26888099619430217]
	TIME [epoch: 8.53 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2071601450551756		[learning rate: 0.0031002]
	Learning Rate: 0.00310016
	LOSS [training: 0.2071601450551756 | validation: 0.4559469423496332]
	TIME [epoch: 8.53 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2619372795693093		[learning rate: 0.0030929]
	Learning Rate: 0.00309285
	LOSS [training: 0.2619372795693093 | validation: 0.3668200233260855]
	TIME [epoch: 8.55 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21105518949059882		[learning rate: 0.0030856]
	Learning Rate: 0.00308556
	LOSS [training: 0.21105518949059882 | validation: 0.26163663999228076]
	TIME [epoch: 8.53 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19307484265780955		[learning rate: 0.0030783]
	Learning Rate: 0.00307828
	LOSS [training: 0.19307484265780955 | validation: 0.1663236085525018]
	TIME [epoch: 8.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19598648486985562		[learning rate: 0.003071]
	Learning Rate: 0.00307102
	LOSS [training: 0.19598648486985562 | validation: 0.1168577960351099]
	TIME [epoch: 8.53 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995287339785859		[learning rate: 0.0030638]
	Learning Rate: 0.00306377
	LOSS [training: 0.1995287339785859 | validation: 0.12932985557894602]
	TIME [epoch: 8.55 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22898031807829833		[learning rate: 0.0030565]
	Learning Rate: 0.00305654
	LOSS [training: 0.22898031807829833 | validation: 0.14532790328203]
	TIME [epoch: 8.53 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18307002762122976		[learning rate: 0.0030493]
	Learning Rate: 0.00304933
	LOSS [training: 0.18307002762122976 | validation: 0.16878717020918343]
	TIME [epoch: 8.53 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19560810298883313		[learning rate: 0.0030421]
	Learning Rate: 0.00304214
	LOSS [training: 0.19560810298883313 | validation: 0.16087614894001376]
	TIME [epoch: 8.53 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2250092828693931		[learning rate: 0.003035]
	Learning Rate: 0.00303497
	LOSS [training: 0.2250092828693931 | validation: 0.21952177202398976]
	TIME [epoch: 8.55 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19350498525133294		[learning rate: 0.0030278]
	Learning Rate: 0.00302781
	LOSS [training: 0.19350498525133294 | validation: 0.1765013387328096]
	TIME [epoch: 8.53 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16396474606538117		[learning rate: 0.0030207]
	Learning Rate: 0.00302066
	LOSS [training: 0.16396474606538117 | validation: 0.10370671112762139]
	TIME [epoch: 8.53 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18017731807507592		[learning rate: 0.0030135]
	Learning Rate: 0.00301354
	LOSS [training: 0.18017731807507592 | validation: 0.17379109231503526]
	TIME [epoch: 8.53 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17101586670206595		[learning rate: 0.0030064]
	Learning Rate: 0.00300643
	LOSS [training: 0.17101586670206595 | validation: 0.308212562831177]
	TIME [epoch: 8.55 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23380371036061592		[learning rate: 0.0029993]
	Learning Rate: 0.00299934
	LOSS [training: 0.23380371036061592 | validation: 0.1139891098060271]
	TIME [epoch: 8.53 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18525808518034045		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.18525808518034045 | validation: 0.1371847855442638]
	TIME [epoch: 8.53 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17740065999413082		[learning rate: 0.0029852]
	Learning Rate: 0.00298521
	LOSS [training: 0.17740065999413082 | validation: 0.13758312546586052]
	TIME [epoch: 8.54 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18461938433239816		[learning rate: 0.0029782]
	Learning Rate: 0.00297816
	LOSS [training: 0.18461938433239816 | validation: 0.12551214494279045]
	TIME [epoch: 8.54 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20045856565743098		[learning rate: 0.0029711]
	Learning Rate: 0.00297114
	LOSS [training: 0.20045856565743098 | validation: 0.19743847541340603]
	TIME [epoch: 8.53 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16296391639827962		[learning rate: 0.0029641]
	Learning Rate: 0.00296413
	LOSS [training: 0.16296391639827962 | validation: 0.3903779249005251]
	TIME [epoch: 8.53 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1875674450942774		[learning rate: 0.0029571]
	Learning Rate: 0.00295714
	LOSS [training: 0.1875674450942774 | validation: 0.08759850761838572]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14012321790906834		[learning rate: 0.0029502]
	Learning Rate: 0.00295016
	LOSS [training: 0.14012321790906834 | validation: 0.6144593827841993]
	TIME [epoch: 8.54 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601110289394094		[learning rate: 0.0029432]
	Learning Rate: 0.0029432
	LOSS [training: 0.2601110289394094 | validation: 0.18912009080812592]
	TIME [epoch: 8.53 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16471311570515387		[learning rate: 0.0029363]
	Learning Rate: 0.00293626
	LOSS [training: 0.16471311570515387 | validation: 0.10757194324061417]
	TIME [epoch: 8.53 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23705871542583803		[learning rate: 0.0029293]
	Learning Rate: 0.00292934
	LOSS [training: 0.23705871542583803 | validation: 0.18403292121712989]
	TIME [epoch: 8.55 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20687601640669126		[learning rate: 0.0029224]
	Learning Rate: 0.00292243
	LOSS [training: 0.20687601640669126 | validation: 0.15068677305072323]
	TIME [epoch: 8.53 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18538718873221433		[learning rate: 0.0029155]
	Learning Rate: 0.00291553
	LOSS [training: 0.18538718873221433 | validation: 0.1409220738573122]
	TIME [epoch: 8.53 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17958001094148984		[learning rate: 0.0029087]
	Learning Rate: 0.00290866
	LOSS [training: 0.17958001094148984 | validation: 0.1257799029270329]
	TIME [epoch: 8.54 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1616867620333222		[learning rate: 0.0029018]
	Learning Rate: 0.00290179
	LOSS [training: 0.1616867620333222 | validation: 0.17165040357690803]
	TIME [epoch: 8.56 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.229276880846287		[learning rate: 0.0028949]
	Learning Rate: 0.00289495
	LOSS [training: 0.229276880846287 | validation: 0.12429747429623503]
	TIME [epoch: 8.54 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24234522156933522		[learning rate: 0.0028881]
	Learning Rate: 0.00288812
	LOSS [training: 0.24234522156933522 | validation: 0.23768316696838157]
	TIME [epoch: 8.53 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19558209168658863		[learning rate: 0.0028813]
	Learning Rate: 0.00288131
	LOSS [training: 0.19558209168658863 | validation: 0.22566592268309382]
	TIME [epoch: 8.53 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750567428416579		[learning rate: 0.0028745]
	Learning Rate: 0.00287451
	LOSS [training: 0.18750567428416579 | validation: 0.11466785991031811]
	TIME [epoch: 8.55 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834603337227984		[learning rate: 0.0028677]
	Learning Rate: 0.00286773
	LOSS [training: 0.1834603337227984 | validation: 0.14762110041578014]
	TIME [epoch: 8.53 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19841437763278902		[learning rate: 0.002861]
	Learning Rate: 0.00286097
	LOSS [training: 0.19841437763278902 | validation: 0.18927133107270716]
	TIME [epoch: 8.53 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1818402328064804		[learning rate: 0.0028542]
	Learning Rate: 0.00285422
	LOSS [training: 0.1818402328064804 | validation: 0.19545631551844028]
	TIME [epoch: 8.53 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21479322417040972		[learning rate: 0.0028475]
	Learning Rate: 0.00284749
	LOSS [training: 0.21479322417040972 | validation: 0.1619534379336114]
	TIME [epoch: 8.56 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16394057867608497		[learning rate: 0.0028408]
	Learning Rate: 0.00284077
	LOSS [training: 0.16394057867608497 | validation: 0.10153414195203164]
	TIME [epoch: 8.53 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359457148414809		[learning rate: 0.0028341]
	Learning Rate: 0.00283407
	LOSS [training: 0.17359457148414809 | validation: 0.17306258644506622]
	TIME [epoch: 8.53 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15595033036149775		[learning rate: 0.0028274]
	Learning Rate: 0.00282738
	LOSS [training: 0.15595033036149775 | validation: 0.13819651063650448]
	TIME [epoch: 8.54 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17765679330603007		[learning rate: 0.0028207]
	Learning Rate: 0.00282071
	LOSS [training: 0.17765679330603007 | validation: 0.12555970930425667]
	TIME [epoch: 8.56 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.178881818262332		[learning rate: 0.0028141]
	Learning Rate: 0.00281406
	LOSS [training: 0.178881818262332 | validation: 0.10597959630899303]
	TIME [epoch: 8.53 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22642539498094627		[learning rate: 0.0028074]
	Learning Rate: 0.00280742
	LOSS [training: 0.22642539498094627 | validation: 0.13631825664900976]
	TIME [epoch: 8.54 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.154532590238989		[learning rate: 0.0028008]
	Learning Rate: 0.0028008
	LOSS [training: 0.154532590238989 | validation: 0.12468004056110552]
	TIME [epoch: 8.54 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20043233171680347		[learning rate: 0.0027942]
	Learning Rate: 0.00279419
	LOSS [training: 0.20043233171680347 | validation: 0.10685991367857278]
	TIME [epoch: 8.55 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17445922375013598		[learning rate: 0.0027876]
	Learning Rate: 0.0027876
	LOSS [training: 0.17445922375013598 | validation: 0.16342427878116045]
	TIME [epoch: 8.53 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16514558425490128		[learning rate: 0.002781]
	Learning Rate: 0.00278103
	LOSS [training: 0.16514558425490128 | validation: 0.20686723470001456]
	TIME [epoch: 8.53 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20838270357020736		[learning rate: 0.0027745]
	Learning Rate: 0.00277447
	LOSS [training: 0.20838270357020736 | validation: 0.0939172900988941]
	TIME [epoch: 8.55 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17690875001057724		[learning rate: 0.0027679]
	Learning Rate: 0.00276792
	LOSS [training: 0.17690875001057724 | validation: 0.19906638752404932]
	TIME [epoch: 8.54 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18652711600525612		[learning rate: 0.0027614]
	Learning Rate: 0.00276139
	LOSS [training: 0.18652711600525612 | validation: 0.138890725382403]
	TIME [epoch: 8.53 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18633671993300033		[learning rate: 0.0027549]
	Learning Rate: 0.00275488
	LOSS [training: 0.18633671993300033 | validation: 0.23010248597182806]
	TIME [epoch: 8.53 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18658438830469098		[learning rate: 0.0027484]
	Learning Rate: 0.00274838
	LOSS [training: 0.18658438830469098 | validation: 0.07533350073618228]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_597.pth
	Model improved!!!
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18581125697075446		[learning rate: 0.0027419]
	Learning Rate: 0.0027419
	LOSS [training: 0.18581125697075446 | validation: 0.14569012441530393]
	TIME [epoch: 8.54 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16435093571474138		[learning rate: 0.0027354]
	Learning Rate: 0.00273543
	LOSS [training: 0.16435093571474138 | validation: 0.14293326155681113]
	TIME [epoch: 8.53 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18329443889512234		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.18329443889512234 | validation: 0.12113226412928932]
	TIME [epoch: 8.52 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18125016263631188		[learning rate: 0.0027225]
	Learning Rate: 0.00272254
	LOSS [training: 0.18125016263631188 | validation: 0.23178224073438297]
	TIME [epoch: 8.54 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2066971143103027		[learning rate: 0.0027161]
	Learning Rate: 0.00271612
	LOSS [training: 0.2066971143103027 | validation: 0.15595581255077684]
	TIME [epoch: 8.53 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17200494425916482		[learning rate: 0.0027097]
	Learning Rate: 0.00270971
	LOSS [training: 0.17200494425916482 | validation: 0.1850518369872483]
	TIME [epoch: 8.52 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14793575083679222		[learning rate: 0.0027033]
	Learning Rate: 0.00270332
	LOSS [training: 0.14793575083679222 | validation: 0.11650791454624826]
	TIME [epoch: 8.53 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1843655531170437		[learning rate: 0.0026969]
	Learning Rate: 0.00269694
	LOSS [training: 0.1843655531170437 | validation: 0.13105801518939236]
	TIME [epoch: 8.55 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17985657033279817		[learning rate: 0.0026906]
	Learning Rate: 0.00269058
	LOSS [training: 0.17985657033279817 | validation: 0.1563445143669938]
	TIME [epoch: 8.53 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15073926141371766		[learning rate: 0.0026842]
	Learning Rate: 0.00268423
	LOSS [training: 0.15073926141371766 | validation: 0.13124598901555934]
	TIME [epoch: 8.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14288562674266023		[learning rate: 0.0026779]
	Learning Rate: 0.0026779
	LOSS [training: 0.14288562674266023 | validation: 0.17709312998146737]
	TIME [epoch: 8.53 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17172271389791405		[learning rate: 0.0026716]
	Learning Rate: 0.00267159
	LOSS [training: 0.17172271389791405 | validation: 0.13219783569480775]
	TIME [epoch: 8.54 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17395902458125612		[learning rate: 0.0026653]
	Learning Rate: 0.00266528
	LOSS [training: 0.17395902458125612 | validation: 0.1126335484615085]
	TIME [epoch: 8.53 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17327426563536147		[learning rate: 0.002659]
	Learning Rate: 0.002659
	LOSS [training: 0.17327426563536147 | validation: 0.178138887661883]
	TIME [epoch: 8.53 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.185434609880963		[learning rate: 0.0026527]
	Learning Rate: 0.00265273
	LOSS [training: 0.185434609880963 | validation: 0.07206586684728894]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14152426549299119		[learning rate: 0.0026465]
	Learning Rate: 0.00264647
	LOSS [training: 0.14152426549299119 | validation: 0.15580692567584142]
	TIME [epoch: 8.56 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14388603699937583		[learning rate: 0.0026402]
	Learning Rate: 0.00264023
	LOSS [training: 0.14388603699937583 | validation: 0.36058521763087303]
	TIME [epoch: 8.53 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20215654024979432		[learning rate: 0.002634]
	Learning Rate: 0.002634
	LOSS [training: 0.20215654024979432 | validation: 0.0845397384804559]
	TIME [epoch: 8.53 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17530958547594994		[learning rate: 0.0026278]
	Learning Rate: 0.00262778
	LOSS [training: 0.17530958547594994 | validation: 0.32107170079285335]
	TIME [epoch: 8.53 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21381120829950775		[learning rate: 0.0026216]
	Learning Rate: 0.00262159
	LOSS [training: 0.21381120829950775 | validation: 0.07365195512143735]
	TIME [epoch: 8.56 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11654769863073569		[learning rate: 0.0026154]
	Learning Rate: 0.0026154
	LOSS [training: 0.11654769863073569 | validation: 0.36483365415534247]
	TIME [epoch: 8.52 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22013539381681974		[learning rate: 0.0026092]
	Learning Rate: 0.00260923
	LOSS [training: 0.22013539381681974 | validation: 0.23322381046607082]
	TIME [epoch: 8.53 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1451751080052213		[learning rate: 0.0026031]
	Learning Rate: 0.00260308
	LOSS [training: 0.1451751080052213 | validation: 0.14877143373652002]
	TIME [epoch: 8.53 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17052653519913796		[learning rate: 0.0025969]
	Learning Rate: 0.00259694
	LOSS [training: 0.17052653519913796 | validation: 0.11235900986148847]
	TIME [epoch: 8.55 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16335500426098626		[learning rate: 0.0025908]
	Learning Rate: 0.00259081
	LOSS [training: 0.16335500426098626 | validation: 0.06736752559791159]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1432191083438606		[learning rate: 0.0025847]
	Learning Rate: 0.0025847
	LOSS [training: 0.1432191083438606 | validation: 0.0812964325167331]
	TIME [epoch: 8.53 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15435554258963163		[learning rate: 0.0025786]
	Learning Rate: 0.0025786
	LOSS [training: 0.15435554258963163 | validation: 0.08798284138504545]
	TIME [epoch: 8.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17208865098114862		[learning rate: 0.0025725]
	Learning Rate: 0.00257252
	LOSS [training: 0.17208865098114862 | validation: 0.11048448963437366]
	TIME [epoch: 8.53 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1615668752395535		[learning rate: 0.0025665]
	Learning Rate: 0.00256645
	LOSS [training: 0.1615668752395535 | validation: 0.20249868527564216]
	TIME [epoch: 8.52 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15649715360762867		[learning rate: 0.0025604]
	Learning Rate: 0.0025604
	LOSS [training: 0.15649715360762867 | validation: 0.30436294170241196]
	TIME [epoch: 8.52 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17668653315905497		[learning rate: 0.0025544]
	Learning Rate: 0.00255436
	LOSS [training: 0.17668653315905497 | validation: 0.14542867322618996]
	TIME [epoch: 8.54 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17985873814052927		[learning rate: 0.0025483]
	Learning Rate: 0.00254833
	LOSS [training: 0.17985873814052927 | validation: 0.10282496992193722]
	TIME [epoch: 8.53 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11671149984137226		[learning rate: 0.0025423]
	Learning Rate: 0.00254232
	LOSS [training: 0.11671149984137226 | validation: 0.20727991159883075]
	TIME [epoch: 8.52 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15158516916378395		[learning rate: 0.0025363]
	Learning Rate: 0.00253633
	LOSS [training: 0.15158516916378395 | validation: 0.12400486141668374]
	TIME [epoch: 8.53 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19681359878458543		[learning rate: 0.0025303]
	Learning Rate: 0.00253034
	LOSS [training: 0.19681359878458543 | validation: 0.09305811630252692]
	TIME [epoch: 8.54 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2343349664405825		[learning rate: 0.0025244]
	Learning Rate: 0.00252437
	LOSS [training: 0.2343349664405825 | validation: 0.1253297827459148]
	TIME [epoch: 8.53 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1547062695578479		[learning rate: 0.0025184]
	Learning Rate: 0.00251842
	LOSS [training: 0.1547062695578479 | validation: 0.1275846425536848]
	TIME [epoch: 8.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15911245672598665		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.15911245672598665 | validation: 0.3315945458883427]
	TIME [epoch: 8.52 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27284179735000136		[learning rate: 0.0025066]
	Learning Rate: 0.00250655
	LOSS [training: 0.27284179735000136 | validation: 0.13416559138678852]
	TIME [epoch: 8.55 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1458420481454893		[learning rate: 0.0025006]
	Learning Rate: 0.00250064
	LOSS [training: 0.1458420481454893 | validation: 0.13202648922247373]
	TIME [epoch: 8.54 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13840639164233678		[learning rate: 0.0024947]
	Learning Rate: 0.00249474
	LOSS [training: 0.13840639164233678 | validation: 0.3832822479189213]
	TIME [epoch: 8.53 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2097137729132216		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.2097137729132216 | validation: 0.13090561318782623]
	TIME [epoch: 8.53 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1813453324660052		[learning rate: 0.002483]
	Learning Rate: 0.00248299
	LOSS [training: 0.1813453324660052 | validation: 0.1300034849977682]
	TIME [epoch: 8.55 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17755477271855052		[learning rate: 0.0024771]
	Learning Rate: 0.00247713
	LOSS [training: 0.17755477271855052 | validation: 0.08813733385053618]
	TIME [epoch: 8.52 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13828479537880964		[learning rate: 0.0024713]
	Learning Rate: 0.00247129
	LOSS [training: 0.13828479537880964 | validation: 0.15272158120045495]
	TIME [epoch: 8.52 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15149250910875717		[learning rate: 0.0024655]
	Learning Rate: 0.00246546
	LOSS [training: 0.15149250910875717 | validation: 0.0775725651753914]
	TIME [epoch: 8.52 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14814242052361032		[learning rate: 0.0024596]
	Learning Rate: 0.00245964
	LOSS [training: 0.14814242052361032 | validation: 0.1650082363042948]
	TIME [epoch: 8.54 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13755017188327343		[learning rate: 0.0024538]
	Learning Rate: 0.00245384
	LOSS [training: 0.13755017188327343 | validation: 0.2378954249531942]
	TIME [epoch: 8.52 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.175045484989232		[learning rate: 0.0024481]
	Learning Rate: 0.00244805
	LOSS [training: 0.175045484989232 | validation: 0.07111577270529695]
	TIME [epoch: 8.52 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16087077527704585		[learning rate: 0.0024423]
	Learning Rate: 0.00244228
	LOSS [training: 0.16087077527704585 | validation: 0.14266412682561175]
	TIME [epoch: 8.52 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19581179467172558		[learning rate: 0.0024365]
	Learning Rate: 0.00243652
	LOSS [training: 0.19581179467172558 | validation: 0.1646884137345599]
	TIME [epoch: 8.55 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16730271429532792		[learning rate: 0.0024308]
	Learning Rate: 0.00243077
	LOSS [training: 0.16730271429532792 | validation: 0.15308604779536236]
	TIME [epoch: 8.52 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1531805086403217		[learning rate: 0.002425]
	Learning Rate: 0.00242503
	LOSS [training: 0.1531805086403217 | validation: 0.12450891977298234]
	TIME [epoch: 8.52 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.140361969146001		[learning rate: 0.0024193]
	Learning Rate: 0.00241931
	LOSS [training: 0.140361969146001 | validation: 0.15004136606277962]
	TIME [epoch: 8.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14375680398677673		[learning rate: 0.0024136]
	Learning Rate: 0.00241361
	LOSS [training: 0.14375680398677673 | validation: 0.12195798511978381]
	TIME [epoch: 8.54 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1763630007498108		[learning rate: 0.0024079]
	Learning Rate: 0.00240791
	LOSS [training: 0.1763630007498108 | validation: 0.16529304355876323]
	TIME [epoch: 8.51 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14396060759301216		[learning rate: 0.0024022]
	Learning Rate: 0.00240223
	LOSS [training: 0.14396060759301216 | validation: 0.11755472333328161]
	TIME [epoch: 8.52 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1962738402395628		[learning rate: 0.0023966]
	Learning Rate: 0.00239657
	LOSS [training: 0.1962738402395628 | validation: 0.07405935652164082]
	TIME [epoch: 8.53 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12611083036450826		[learning rate: 0.0023909]
	Learning Rate: 0.00239092
	LOSS [training: 0.12611083036450826 | validation: 0.12478509510247947]
	TIME [epoch: 8.53 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17005280344189516		[learning rate: 0.0023853]
	Learning Rate: 0.00238527
	LOSS [training: 0.17005280344189516 | validation: 0.10929989886976062]
	TIME [epoch: 8.52 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1840447129251444		[learning rate: 0.0023796]
	Learning Rate: 0.00237965
	LOSS [training: 0.1840447129251444 | validation: 0.07294267410564698]
	TIME [epoch: 8.52 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18966272909256016		[learning rate: 0.002374]
	Learning Rate: 0.00237404
	LOSS [training: 0.18966272909256016 | validation: 0.225096666864531]
	TIME [epoch: 8.54 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15347371466591592		[learning rate: 0.0023684]
	Learning Rate: 0.00236844
	LOSS [training: 0.15347371466591592 | validation: 0.07122544412091322]
	TIME [epoch: 8.52 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1713639328966162		[learning rate: 0.0023628]
	Learning Rate: 0.00236285
	LOSS [training: 0.1713639328966162 | validation: 0.06991406283686094]
	TIME [epoch: 8.52 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1561346862314558		[learning rate: 0.0023573]
	Learning Rate: 0.00235727
	LOSS [training: 0.1561346862314558 | validation: 0.1834281854349456]
	TIME [epoch: 8.51 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12428196777097615		[learning rate: 0.0023517]
	Learning Rate: 0.00235171
	LOSS [training: 0.12428196777097615 | validation: 0.12100579033717174]
	TIME [epoch: 8.53 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14388769584420041		[learning rate: 0.0023462]
	Learning Rate: 0.00234617
	LOSS [training: 0.14388769584420041 | validation: 0.10621285052664073]
	TIME [epoch: 8.52 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13159314548292417		[learning rate: 0.0023406]
	Learning Rate: 0.00234063
	LOSS [training: 0.13159314548292417 | validation: 0.1302071685239996]
	TIME [epoch: 8.52 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316378630942857		[learning rate: 0.0023351]
	Learning Rate: 0.00233511
	LOSS [training: 0.1316378630942857 | validation: 0.12208423732703674]
	TIME [epoch: 8.52 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18371060329380837		[learning rate: 0.0023296]
	Learning Rate: 0.0023296
	LOSS [training: 0.18371060329380837 | validation: 0.12201473032635769]
	TIME [epoch: 8.54 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13822605842334232		[learning rate: 0.0023241]
	Learning Rate: 0.00232411
	LOSS [training: 0.13822605842334232 | validation: 0.1261629893204452]
	TIME [epoch: 8.53 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12391634133186087		[learning rate: 0.0023186]
	Learning Rate: 0.00231863
	LOSS [training: 0.12391634133186087 | validation: 0.10531985664823973]
	TIME [epoch: 8.52 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14598223899223092		[learning rate: 0.0023132]
	Learning Rate: 0.00231316
	LOSS [training: 0.14598223899223092 | validation: 0.23090938832171667]
	TIME [epoch: 8.52 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1697764491154547		[learning rate: 0.0023077]
	Learning Rate: 0.0023077
	LOSS [training: 0.1697764491154547 | validation: 0.2027690290605913]
	TIME [epoch: 8.54 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13422728803900963		[learning rate: 0.0023023]
	Learning Rate: 0.00230226
	LOSS [training: 0.13422728803900963 | validation: 0.06547978399053325]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_672.pth
	Model improved!!!
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16812212871511364		[learning rate: 0.0022968]
	Learning Rate: 0.00229683
	LOSS [training: 0.16812212871511364 | validation: 0.0953575813066119]
	TIME [epoch: 8.52 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13732417808088196		[learning rate: 0.0022914]
	Learning Rate: 0.00229141
	LOSS [training: 0.13732417808088196 | validation: 0.19662179094728316]
	TIME [epoch: 8.52 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11218006679972		[learning rate: 0.002286]
	Learning Rate: 0.002286
	LOSS [training: 0.11218006679972 | validation: 0.052768631241538314]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1540555246669393		[learning rate: 0.0022806]
	Learning Rate: 0.00228061
	LOSS [training: 0.1540555246669393 | validation: 0.16861370810615015]
	TIME [epoch: 8.51 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11721686086180216		[learning rate: 0.0022752]
	Learning Rate: 0.00227523
	LOSS [training: 0.11721686086180216 | validation: 0.1527842963756868]
	TIME [epoch: 8.52 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12337786957283614		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.12337786957283614 | validation: 0.13406824620679675]
	TIME [epoch: 8.51 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13474752829433329		[learning rate: 0.0022645]
	Learning Rate: 0.00226451
	LOSS [training: 0.13474752829433329 | validation: 0.1959070109444409]
	TIME [epoch: 8.54 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12595828992453825		[learning rate: 0.0022592]
	Learning Rate: 0.00225917
	LOSS [training: 0.12595828992453825 | validation: 0.11136863823349]
	TIME [epoch: 8.51 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14442292040894908		[learning rate: 0.0022538]
	Learning Rate: 0.00225384
	LOSS [training: 0.14442292040894908 | validation: 0.17633685987675635]
	TIME [epoch: 8.52 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15059950701010089		[learning rate: 0.0022485]
	Learning Rate: 0.00224852
	LOSS [training: 0.15059950701010089 | validation: 0.06981388879138875]
	TIME [epoch: 8.54 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355047794849267		[learning rate: 0.0022432]
	Learning Rate: 0.00224322
	LOSS [training: 0.1355047794849267 | validation: 0.14690400233637027]
	TIME [epoch: 8.55 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13336142779890603		[learning rate: 0.0022379]
	Learning Rate: 0.00223793
	LOSS [training: 0.13336142779890603 | validation: 0.14662356939357707]
	TIME [epoch: 8.53 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12430947975992543		[learning rate: 0.0022326]
	Learning Rate: 0.00223265
	LOSS [training: 0.12430947975992543 | validation: 0.31316306407859124]
	TIME [epoch: 8.53 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17260773315695369		[learning rate: 0.0022274]
	Learning Rate: 0.00222738
	LOSS [training: 0.17260773315695369 | validation: 0.0656472227125373]
	TIME [epoch: 8.55 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1396230336775691		[learning rate: 0.0022221]
	Learning Rate: 0.00222213
	LOSS [training: 0.1396230336775691 | validation: 0.09259680563410219]
	TIME [epoch: 8.54 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11122264812411528		[learning rate: 0.0022169]
	Learning Rate: 0.00221689
	LOSS [training: 0.11122264812411528 | validation: 0.2428652171536439]
	TIME [epoch: 8.51 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20085374348230514		[learning rate: 0.0022117]
	Learning Rate: 0.00221166
	LOSS [training: 0.20085374348230514 | validation: 0.1759089436266798]
	TIME [epoch: 8.52 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1582051445479503		[learning rate: 0.0022064]
	Learning Rate: 0.00220644
	LOSS [training: 0.1582051445479503 | validation: 0.1282201555990796]
	TIME [epoch: 8.54 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14770248354466017		[learning rate: 0.0022012]
	Learning Rate: 0.00220124
	LOSS [training: 0.14770248354466017 | validation: 0.09606511290719064]
	TIME [epoch: 8.53 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14840922236185738		[learning rate: 0.002196]
	Learning Rate: 0.00219604
	LOSS [training: 0.14840922236185738 | validation: 0.15083909041372073]
	TIME [epoch: 8.53 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11882163354790905		[learning rate: 0.0021909]
	Learning Rate: 0.00219086
	LOSS [training: 0.11882163354790905 | validation: 0.07484896127883155]
	TIME [epoch: 8.53 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14513751621781784		[learning rate: 0.0021857]
	Learning Rate: 0.0021857
	LOSS [training: 0.14513751621781784 | validation: 0.11047329865671339]
	TIME [epoch: 8.54 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14565224306849636		[learning rate: 0.0021805]
	Learning Rate: 0.00218054
	LOSS [training: 0.14565224306849636 | validation: 0.06904780104525204]
	TIME [epoch: 8.53 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16817293231722957		[learning rate: 0.0021754]
	Learning Rate: 0.0021754
	LOSS [training: 0.16817293231722957 | validation: 0.0901451476654652]
	TIME [epoch: 8.53 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1224532799062309		[learning rate: 0.0021703]
	Learning Rate: 0.00217027
	LOSS [training: 0.1224532799062309 | validation: 0.15179472734752292]
	TIME [epoch: 8.53 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1446779038638962		[learning rate: 0.0021651]
	Learning Rate: 0.00216515
	LOSS [training: 0.1446779038638962 | validation: 0.10629232412361066]
	TIME [epoch: 8.54 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14671046485959466		[learning rate: 0.00216]
	Learning Rate: 0.00216004
	LOSS [training: 0.14671046485959466 | validation: 0.11534877609845386]
	TIME [epoch: 8.53 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1348607594778664		[learning rate: 0.0021549]
	Learning Rate: 0.00215494
	LOSS [training: 0.1348607594778664 | validation: 0.14225529887508215]
	TIME [epoch: 8.53 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14751477595358709		[learning rate: 0.0021499]
	Learning Rate: 0.00214986
	LOSS [training: 0.14751477595358709 | validation: 0.13772439741334763]
	TIME [epoch: 8.53 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12427665907282717		[learning rate: 0.0021448]
	Learning Rate: 0.00214479
	LOSS [training: 0.12427665907282717 | validation: 0.08520043273013389]
	TIME [epoch: 8.55 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10269344279011679		[learning rate: 0.0021397]
	Learning Rate: 0.00213973
	LOSS [training: 0.10269344279011679 | validation: 0.09629565509334168]
	TIME [epoch: 8.53 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271139380170791		[learning rate: 0.0021347]
	Learning Rate: 0.00213468
	LOSS [training: 0.1271139380170791 | validation: 0.10216432832825784]
	TIME [epoch: 8.52 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12449009314364907		[learning rate: 0.0021296]
	Learning Rate: 0.00212965
	LOSS [training: 0.12449009314364907 | validation: 0.12778432058559122]
	TIME [epoch: 8.52 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11048659681768566		[learning rate: 0.0021246]
	Learning Rate: 0.00212462
	LOSS [training: 0.11048659681768566 | validation: 0.07382471096275472]
	TIME [epoch: 8.55 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15605996918544726		[learning rate: 0.0021196]
	Learning Rate: 0.00211961
	LOSS [training: 0.15605996918544726 | validation: 0.21057190236341855]
	TIME [epoch: 8.52 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15499600708431704		[learning rate: 0.0021146]
	Learning Rate: 0.00211461
	LOSS [training: 0.15499600708431704 | validation: 0.0758017284482316]
	TIME [epoch: 8.52 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13620232374212135		[learning rate: 0.0021096]
	Learning Rate: 0.00210962
	LOSS [training: 0.13620232374212135 | validation: 0.06461973951300495]
	TIME [epoch: 8.52 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20935152909448296		[learning rate: 0.0021046]
	Learning Rate: 0.00210465
	LOSS [training: 0.20935152909448296 | validation: 0.24897183641736176]
	TIME [epoch: 8.54 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1328599550316924		[learning rate: 0.0020997]
	Learning Rate: 0.00209968
	LOSS [training: 0.1328599550316924 | validation: 0.12140355880931233]
	TIME [epoch: 8.52 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12494659646108304		[learning rate: 0.0020947]
	Learning Rate: 0.00209473
	LOSS [training: 0.12494659646108304 | validation: 0.09959384818186517]
	TIME [epoch: 8.52 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10544598028548866		[learning rate: 0.0020898]
	Learning Rate: 0.00208979
	LOSS [training: 0.10544598028548866 | validation: 0.07352567497214915]
	TIME [epoch: 8.52 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12311032031028361		[learning rate: 0.0020849]
	Learning Rate: 0.00208486
	LOSS [training: 0.12311032031028361 | validation: 0.11826479219100024]
	TIME [epoch: 8.55 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16060761524730116		[learning rate: 0.0020799]
	Learning Rate: 0.00207994
	LOSS [training: 0.16060761524730116 | validation: 0.11235574032985449]
	TIME [epoch: 8.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1545675569155258		[learning rate: 0.002075]
	Learning Rate: 0.00207504
	LOSS [training: 0.1545675569155258 | validation: 0.08212677509026163]
	TIME [epoch: 8.52 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12777800307373272		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.12777800307373272 | validation: 0.30268168396569306]
	TIME [epoch: 8.53 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17405342869096424		[learning rate: 0.0020653]
	Learning Rate: 0.00206526
	LOSS [training: 0.17405342869096424 | validation: 0.09847877316728412]
	TIME [epoch: 8.54 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.108725904613778		[learning rate: 0.0020604]
	Learning Rate: 0.00206039
	LOSS [training: 0.108725904613778 | validation: 0.07987509272266743]
	TIME [epoch: 8.52 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13941465813107232		[learning rate: 0.0020555]
	Learning Rate: 0.00205553
	LOSS [training: 0.13941465813107232 | validation: 0.06980759911544795]
	TIME [epoch: 8.52 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11627672956894945		[learning rate: 0.0020507]
	Learning Rate: 0.00205068
	LOSS [training: 0.11627672956894945 | validation: 0.10315862691174597]
	TIME [epoch: 8.53 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.140421923073339		[learning rate: 0.0020458]
	Learning Rate: 0.00204584
	LOSS [training: 0.140421923073339 | validation: 0.1143082402721671]
	TIME [epoch: 8.53 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14594045672603062		[learning rate: 0.002041]
	Learning Rate: 0.00204101
	LOSS [training: 0.14594045672603062 | validation: 0.0784658935725122]
	TIME [epoch: 8.52 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15975059412726797		[learning rate: 0.0020362]
	Learning Rate: 0.0020362
	LOSS [training: 0.15975059412726797 | validation: 0.12744412021219553]
	TIME [epoch: 8.53 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14142928310171182		[learning rate: 0.0020314]
	Learning Rate: 0.0020314
	LOSS [training: 0.14142928310171182 | validation: 0.08152227445527058]
	TIME [epoch: 8.53 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13755893331756844		[learning rate: 0.0020266]
	Learning Rate: 0.00202661
	LOSS [training: 0.13755893331756844 | validation: 0.33566994898802616]
	TIME [epoch: 8.54 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18190862338111882		[learning rate: 0.0020218]
	Learning Rate: 0.00202182
	LOSS [training: 0.18190862338111882 | validation: 0.1300946383825453]
	TIME [epoch: 8.52 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17177576330954855		[learning rate: 0.0020171]
	Learning Rate: 0.00201706
	LOSS [training: 0.17177576330954855 | validation: 0.265644099846153]
	TIME [epoch: 8.53 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2269787762126334		[learning rate: 0.0020123]
	Learning Rate: 0.0020123
	LOSS [training: 0.2269787762126334 | validation: 0.07389224392644536]
	TIME [epoch: 8.54 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12080452004731286		[learning rate: 0.0020076]
	Learning Rate: 0.00200755
	LOSS [training: 0.12080452004731286 | validation: 0.16646180921103382]
	TIME [epoch: 8.52 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13666496803027414		[learning rate: 0.0020028]
	Learning Rate: 0.00200282
	LOSS [training: 0.13666496803027414 | validation: 0.1593193825271479]
	TIME [epoch: 8.53 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10549008044767569		[learning rate: 0.0019981]
	Learning Rate: 0.00199809
	LOSS [training: 0.10549008044767569 | validation: 0.09632331974341367]
	TIME [epoch: 8.53 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15065873990137107		[learning rate: 0.0019934]
	Learning Rate: 0.00199338
	LOSS [training: 0.15065873990137107 | validation: 0.14454305648652438]
	TIME [epoch: 8.55 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12578856308659608		[learning rate: 0.0019887]
	Learning Rate: 0.00198868
	LOSS [training: 0.12578856308659608 | validation: 0.13566288928134385]
	TIME [epoch: 8.53 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15185627042367572		[learning rate: 0.001984]
	Learning Rate: 0.00198399
	LOSS [training: 0.15185627042367572 | validation: 0.11924682634586853]
	TIME [epoch: 8.53 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255840623006154		[learning rate: 0.0019793]
	Learning Rate: 0.00197931
	LOSS [training: 0.1255840623006154 | validation: 0.10146269362785976]
	TIME [epoch: 8.52 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11928040147461075		[learning rate: 0.0019746]
	Learning Rate: 0.00197464
	LOSS [training: 0.11928040147461075 | validation: 0.09523629022276772]
	TIME [epoch: 8.55 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15518655995440042		[learning rate: 0.00197]
	Learning Rate: 0.00196998
	LOSS [training: 0.15518655995440042 | validation: 0.24645324323618956]
	TIME [epoch: 8.53 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1435590527376918		[learning rate: 0.0019653]
	Learning Rate: 0.00196533
	LOSS [training: 0.1435590527376918 | validation: 0.12481558656714466]
	TIME [epoch: 8.52 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10940806215231955		[learning rate: 0.0019607]
	Learning Rate: 0.0019607
	LOSS [training: 0.10940806215231955 | validation: 0.20339827821785342]
	TIME [epoch: 8.53 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14848635833684093		[learning rate: 0.0019561]
	Learning Rate: 0.00195607
	LOSS [training: 0.14848635833684093 | validation: 0.21838288555989555]
	TIME [epoch: 8.55 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1416980472792547		[learning rate: 0.0019515]
	Learning Rate: 0.00195146
	LOSS [training: 0.1416980472792547 | validation: 0.11576453977815779]
	TIME [epoch: 8.52 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12000492814222316		[learning rate: 0.0019469]
	Learning Rate: 0.00194685
	LOSS [training: 0.12000492814222316 | validation: 0.18716660378198707]
	TIME [epoch: 8.52 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12354859420914296		[learning rate: 0.0019423]
	Learning Rate: 0.00194226
	LOSS [training: 0.12354859420914296 | validation: 0.10785109630231224]
	TIME [epoch: 8.52 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15572169144816672		[learning rate: 0.0019377]
	Learning Rate: 0.00193768
	LOSS [training: 0.15572169144816672 | validation: 0.15367572357184545]
	TIME [epoch: 8.55 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14530579333350113		[learning rate: 0.0019331]
	Learning Rate: 0.00193311
	LOSS [training: 0.14530579333350113 | validation: 0.13390646609021992]
	TIME [epoch: 8.53 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15492223369076186		[learning rate: 0.0019285]
	Learning Rate: 0.00192855
	LOSS [training: 0.15492223369076186 | validation: 0.07871806103501802]
	TIME [epoch: 8.53 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12014366802867837		[learning rate: 0.001924]
	Learning Rate: 0.001924
	LOSS [training: 0.12014366802867837 | validation: 0.06926001514178966]
	TIME [epoch: 8.53 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09906667326612259		[learning rate: 0.0019195]
	Learning Rate: 0.00191946
	LOSS [training: 0.09906667326612259 | validation: 0.11659958900510968]
	TIME [epoch: 8.54 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2471011411151712		[learning rate: 0.0019149]
	Learning Rate: 0.00191493
	LOSS [training: 0.2471011411151712 | validation: 0.10816893519856766]
	TIME [epoch: 8.53 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17876000015363838		[learning rate: 0.0019104]
	Learning Rate: 0.00191042
	LOSS [training: 0.17876000015363838 | validation: 0.10782790386659433]
	TIME [epoch: 8.52 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14711006250202563		[learning rate: 0.0019059]
	Learning Rate: 0.00190591
	LOSS [training: 0.14711006250202563 | validation: 0.13023871738444648]
	TIME [epoch: 8.53 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14095012241775737		[learning rate: 0.0019014]
	Learning Rate: 0.00190141
	LOSS [training: 0.14095012241775737 | validation: 0.2174529941076785]
	TIME [epoch: 8.55 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11872319132056768		[learning rate: 0.0018969]
	Learning Rate: 0.00189693
	LOSS [training: 0.11872319132056768 | validation: 0.18515162735023535]
	TIME [epoch: 8.52 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373946726064907		[learning rate: 0.0018925]
	Learning Rate: 0.00189246
	LOSS [training: 0.1373946726064907 | validation: 0.0892461555456016]
	TIME [epoch: 8.52 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11499474752445568		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.11499474752445568 | validation: 0.13912493810068688]
	TIME [epoch: 8.53 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12560377296362174		[learning rate: 0.0018835]
	Learning Rate: 0.00188354
	LOSS [training: 0.12560377296362174 | validation: 0.3872033547853808]
	TIME [epoch: 8.53 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15608610888836028		[learning rate: 0.0018791]
	Learning Rate: 0.00187909
	LOSS [training: 0.15608610888836028 | validation: 0.4134798687756538]
	TIME [epoch: 8.51 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17628924826596115		[learning rate: 0.0018747]
	Learning Rate: 0.00187466
	LOSS [training: 0.17628924826596115 | validation: 0.06359150125271268]
	TIME [epoch: 8.52 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13180023674087618		[learning rate: 0.0018702]
	Learning Rate: 0.00187024
	LOSS [training: 0.13180023674087618 | validation: 0.11652352175732254]
	TIME [epoch: 8.53 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14075871025894598		[learning rate: 0.0018658]
	Learning Rate: 0.00186583
	LOSS [training: 0.14075871025894598 | validation: 0.11290567235681608]
	TIME [epoch: 8.53 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16350098659643694		[learning rate: 0.0018614]
	Learning Rate: 0.00186143
	LOSS [training: 0.16350098659643694 | validation: 0.09698990906957111]
	TIME [epoch: 8.52 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13297695955444547		[learning rate: 0.001857]
	Learning Rate: 0.00185704
	LOSS [training: 0.13297695955444547 | validation: 0.10523739555167692]
	TIME [epoch: 8.52 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13043927996524268		[learning rate: 0.0018527]
	Learning Rate: 0.00185266
	LOSS [training: 0.13043927996524268 | validation: 0.1908152727827029]
	TIME [epoch: 8.55 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1511225279084044		[learning rate: 0.0018483]
	Learning Rate: 0.00184829
	LOSS [training: 0.1511225279084044 | validation: 0.06845250967741494]
	TIME [epoch: 8.53 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1282324941065123		[learning rate: 0.0018439]
	Learning Rate: 0.00184393
	LOSS [training: 0.1282324941065123 | validation: 0.07203840667933033]
	TIME [epoch: 8.52 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1119067030417101		[learning rate: 0.0018396]
	Learning Rate: 0.00183958
	LOSS [training: 0.1119067030417101 | validation: 0.08914375271914035]
	TIME [epoch: 8.89 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12037320005126526		[learning rate: 0.0018352]
	Learning Rate: 0.00183524
	LOSS [training: 0.12037320005126526 | validation: 0.1389005694480236]
	TIME [epoch: 8.54 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17008665451724947		[learning rate: 0.0018309]
	Learning Rate: 0.00183091
	LOSS [training: 0.17008665451724947 | validation: 0.1281684334821522]
	TIME [epoch: 8.51 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12393138198373481		[learning rate: 0.0018266]
	Learning Rate: 0.00182659
	LOSS [training: 0.12393138198373481 | validation: 0.08502755526172878]
	TIME [epoch: 8.52 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12741430070334606		[learning rate: 0.0018223]
	Learning Rate: 0.00182228
	LOSS [training: 0.12741430070334606 | validation: 0.08596517536293516]
	TIME [epoch: 8.52 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1079915539014992		[learning rate: 0.001818]
	Learning Rate: 0.00181798
	LOSS [training: 0.1079915539014992 | validation: 0.18738974053004814]
	TIME [epoch: 8.54 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15727279459478613		[learning rate: 0.0018137]
	Learning Rate: 0.00181369
	LOSS [training: 0.15727279459478613 | validation: 0.09239985422223432]
	TIME [epoch: 8.52 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12862084511947494		[learning rate: 0.0018094]
	Learning Rate: 0.00180942
	LOSS [training: 0.12862084511947494 | validation: 0.1314365502677647]
	TIME [epoch: 8.53 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11723844966253147		[learning rate: 0.0018051]
	Learning Rate: 0.00180515
	LOSS [training: 0.11723844966253147 | validation: 0.06040027907932588]
	TIME [epoch: 8.53 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09532314122791569		[learning rate: 0.0018009]
	Learning Rate: 0.00180089
	LOSS [training: 0.09532314122791569 | validation: 0.11515662038644006]
	TIME [epoch: 8.55 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13395091991928976		[learning rate: 0.0017966]
	Learning Rate: 0.00179664
	LOSS [training: 0.13395091991928976 | validation: 0.15656579025907957]
	TIME [epoch: 8.53 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11615800699903048		[learning rate: 0.0017924]
	Learning Rate: 0.0017924
	LOSS [training: 0.11615800699903048 | validation: 0.13259499406626515]
	TIME [epoch: 8.53 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13119486115358714		[learning rate: 0.0017882]
	Learning Rate: 0.00178818
	LOSS [training: 0.13119486115358714 | validation: 0.16303146550746853]
	TIME [epoch: 8.53 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16155828361611843		[learning rate: 0.001784]
	Learning Rate: 0.00178396
	LOSS [training: 0.16155828361611843 | validation: 0.159837583513981]
	TIME [epoch: 8.55 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12907131518936138		[learning rate: 0.0017797]
	Learning Rate: 0.00177975
	LOSS [training: 0.12907131518936138 | validation: 0.1904546428662015]
	TIME [epoch: 8.52 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11344790318541036		[learning rate: 0.0017756]
	Learning Rate: 0.00177555
	LOSS [training: 0.11344790318541036 | validation: 0.09684954377877904]
	TIME [epoch: 8.53 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.159983355003907		[learning rate: 0.0017714]
	Learning Rate: 0.00177136
	LOSS [training: 0.159983355003907 | validation: 0.31426741978941763]
	TIME [epoch: 8.53 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1763490868333358		[learning rate: 0.0017672]
	Learning Rate: 0.00176719
	LOSS [training: 0.1763490868333358 | validation: 0.06776738092595576]
	TIME [epoch: 8.55 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10853228314445595		[learning rate: 0.001763]
	Learning Rate: 0.00176302
	LOSS [training: 0.10853228314445595 | validation: 0.09862047065389815]
	TIME [epoch: 8.52 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10609083817042242		[learning rate: 0.0017589]
	Learning Rate: 0.00175886
	LOSS [training: 0.10609083817042242 | validation: 0.060707730671705096]
	TIME [epoch: 8.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10207317708102323		[learning rate: 0.0017547]
	Learning Rate: 0.00175471
	LOSS [training: 0.10207317708102323 | validation: 0.14652114048453763]
	TIME [epoch: 8.54 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11606580744180386		[learning rate: 0.0017506]
	Learning Rate: 0.00175057
	LOSS [training: 0.11606580744180386 | validation: 0.07921753112570232]
	TIME [epoch: 8.53 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11926793280774317		[learning rate: 0.0017464]
	Learning Rate: 0.00174644
	LOSS [training: 0.11926793280774317 | validation: 0.06422949484465174]
	TIME [epoch: 8.53 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1716621149918584		[learning rate: 0.0017423]
	Learning Rate: 0.00174232
	LOSS [training: 0.1716621149918584 | validation: 0.09465947367536956]
	TIME [epoch: 8.53 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11234652344656726		[learning rate: 0.0017382]
	Learning Rate: 0.00173821
	LOSS [training: 0.11234652344656726 | validation: 0.1496452516098552]
	TIME [epoch: 8.53 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10472337380643089		[learning rate: 0.0017341]
	Learning Rate: 0.00173411
	LOSS [training: 0.10472337380643089 | validation: 0.07695708215291497]
	TIME [epoch: 8.52 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14597903574198456		[learning rate: 0.00173]
	Learning Rate: 0.00173002
	LOSS [training: 0.14597903574198456 | validation: 0.08692254771961402]
	TIME [epoch: 8.52 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11726243738550786		[learning rate: 0.0017259]
	Learning Rate: 0.00172594
	LOSS [training: 0.11726243738550786 | validation: 0.1814077230438909]
	TIME [epoch: 8.52 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15767651841845456		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.15767651841845456 | validation: 0.08209982248673511]
	TIME [epoch: 8.55 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1312034946956287		[learning rate: 0.0017178]
	Learning Rate: 0.00171781
	LOSS [training: 0.1312034946956287 | validation: 0.06229878917733679]
	TIME [epoch: 8.52 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10839157531760468		[learning rate: 0.0017138]
	Learning Rate: 0.00171375
	LOSS [training: 0.10839157531760468 | validation: 0.05537978887335816]
	TIME [epoch: 8.53 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12061450291101464		[learning rate: 0.0017097]
	Learning Rate: 0.00170971
	LOSS [training: 0.12061450291101464 | validation: 0.06806723962021458]
	TIME [epoch: 8.52 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12424940661658393		[learning rate: 0.0017057]
	Learning Rate: 0.00170568
	LOSS [training: 0.12424940661658393 | validation: 0.08158156254119411]
	TIME [epoch: 8.55 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12033221283017947		[learning rate: 0.0017017]
	Learning Rate: 0.00170166
	LOSS [training: 0.12033221283017947 | validation: 0.059697000028992815]
	TIME [epoch: 8.52 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267818569919025		[learning rate: 0.0016976]
	Learning Rate: 0.00169764
	LOSS [training: 0.1267818569919025 | validation: 0.12841421561556837]
	TIME [epoch: 8.51 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15484628643724893		[learning rate: 0.0016936]
	Learning Rate: 0.00169364
	LOSS [training: 0.15484628643724893 | validation: 0.0735350224998222]
	TIME [epoch: 8.51 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1246567358401687		[learning rate: 0.0016896]
	Learning Rate: 0.00168964
	LOSS [training: 0.1246567358401687 | validation: 0.11667889434404416]
	TIME [epoch: 8.54 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1437804798712589		[learning rate: 0.0016857]
	Learning Rate: 0.00168566
	LOSS [training: 0.1437804798712589 | validation: 0.0640838416041559]
	TIME [epoch: 8.52 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11971655453160868		[learning rate: 0.0016817]
	Learning Rate: 0.00168168
	LOSS [training: 0.11971655453160868 | validation: 0.10897679333045637]
	TIME [epoch: 8.51 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11958012167534679		[learning rate: 0.0016777]
	Learning Rate: 0.00167771
	LOSS [training: 0.11958012167534679 | validation: 0.1663478426402377]
	TIME [epoch: 8.51 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11491136030075225		[learning rate: 0.0016738]
	Learning Rate: 0.00167376
	LOSS [training: 0.11491136030075225 | validation: 0.0746612588806892]
	TIME [epoch: 8.54 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10978049163756332		[learning rate: 0.0016698]
	Learning Rate: 0.00166981
	LOSS [training: 0.10978049163756332 | validation: 0.08866164030961796]
	TIME [epoch: 8.51 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09318881357539108		[learning rate: 0.0016659]
	Learning Rate: 0.00166587
	LOSS [training: 0.09318881357539108 | validation: 0.06175657645098995]
	TIME [epoch: 8.51 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12108414775320046		[learning rate: 0.0016619]
	Learning Rate: 0.00166194
	LOSS [training: 0.12108414775320046 | validation: 0.04500768561348313]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08235505149683825		[learning rate: 0.001658]
	Learning Rate: 0.00165802
	LOSS [training: 0.08235505149683825 | validation: 0.12443690138899516]
	TIME [epoch: 8.56 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12845977483425555		[learning rate: 0.0016541]
	Learning Rate: 0.00165411
	LOSS [training: 0.12845977483425555 | validation: 0.0626278719665937]
	TIME [epoch: 8.53 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1218773666914501		[learning rate: 0.0016502]
	Learning Rate: 0.00165021
	LOSS [training: 0.1218773666914501 | validation: 0.05488230986817229]
	TIME [epoch: 8.53 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11527426412293625		[learning rate: 0.0016463]
	Learning Rate: 0.00164631
	LOSS [training: 0.11527426412293625 | validation: 0.07634661733637081]
	TIME [epoch: 8.53 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08967411833521496		[learning rate: 0.0016424]
	Learning Rate: 0.00164243
	LOSS [training: 0.08967411833521496 | validation: 0.076115004299702]
	TIME [epoch: 8.55 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.085685953794035		[learning rate: 0.0016386]
	Learning Rate: 0.00163856
	LOSS [training: 0.085685953794035 | validation: 0.07124232926516907]
	TIME [epoch: 8.53 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09301206563085873		[learning rate: 0.0016347]
	Learning Rate: 0.00163469
	LOSS [training: 0.09301206563085873 | validation: 0.06435148672079188]
	TIME [epoch: 8.53 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08307299868007975		[learning rate: 0.0016308]
	Learning Rate: 0.00163084
	LOSS [training: 0.08307299868007975 | validation: 0.0841772871753686]
	TIME [epoch: 8.53 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12024629815085312		[learning rate: 0.001627]
	Learning Rate: 0.00162699
	LOSS [training: 0.12024629815085312 | validation: 0.0681084156987768]
	TIME [epoch: 8.55 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09412580325111305		[learning rate: 0.0016232]
	Learning Rate: 0.00162315
	LOSS [training: 0.09412580325111305 | validation: 0.05247520563003172]
	TIME [epoch: 8.53 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1135143292931926		[learning rate: 0.0016193]
	Learning Rate: 0.00161932
	LOSS [training: 0.1135143292931926 | validation: 0.08019485456149711]
	TIME [epoch: 8.52 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11455456635881		[learning rate: 0.0016155]
	Learning Rate: 0.0016155
	LOSS [training: 0.11455456635881 | validation: 0.12135317176457505]
	TIME [epoch: 8.53 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16279601716724285		[learning rate: 0.0016117]
	Learning Rate: 0.00161169
	LOSS [training: 0.16279601716724285 | validation: 0.07680388668510285]
	TIME [epoch: 8.55 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08696450496276277		[learning rate: 0.0016079]
	Learning Rate: 0.00160789
	LOSS [training: 0.08696450496276277 | validation: 0.07938923023612397]
	TIME [epoch: 8.53 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12663969066120714		[learning rate: 0.0016041]
	Learning Rate: 0.0016041
	LOSS [training: 0.12663969066120714 | validation: 0.14505035929680085]
	TIME [epoch: 8.53 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13635657413428962		[learning rate: 0.0016003]
	Learning Rate: 0.00160031
	LOSS [training: 0.13635657413428962 | validation: 0.07293884897499199]
	TIME [epoch: 8.53 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15171757152051107		[learning rate: 0.0015965]
	Learning Rate: 0.00159654
	LOSS [training: 0.15171757152051107 | validation: 0.09171543630584841]
	TIME [epoch: 8.55 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11189032697417314		[learning rate: 0.0015928]
	Learning Rate: 0.00159277
	LOSS [training: 0.11189032697417314 | validation: 0.08465855617453669]
	TIME [epoch: 8.53 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10373709583565108		[learning rate: 0.001589]
	Learning Rate: 0.00158902
	LOSS [training: 0.10373709583565108 | validation: 0.08764296018754882]
	TIME [epoch: 8.53 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10535794566241619		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.10535794566241619 | validation: 0.11418621602827589]
	TIME [epoch: 8.54 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09079351165039673		[learning rate: 0.0015815]
	Learning Rate: 0.00158153
	LOSS [training: 0.09079351165039673 | validation: 0.21492164230703298]
	TIME [epoch: 8.54 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12868909975221765		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.12868909975221765 | validation: 0.08335782402461228]
	TIME [epoch: 8.53 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1079203497576104		[learning rate: 0.0015741]
	Learning Rate: 0.00157408
	LOSS [training: 0.1079203497576104 | validation: 0.11379387151792894]
	TIME [epoch: 8.53 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10808541676660825		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.10808541676660825 | validation: 0.07753094633958277]
	TIME [epoch: 8.54 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1243279918480433		[learning rate: 0.0015667]
	Learning Rate: 0.00156666
	LOSS [training: 0.1243279918480433 | validation: 0.11316244874735888]
	TIME [epoch: 8.54 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1065099481663651		[learning rate: 0.001563]
	Learning Rate: 0.00156296
	LOSS [training: 0.1065099481663651 | validation: 0.08213753774506516]
	TIME [epoch: 8.53 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1064493174660276		[learning rate: 0.0015593]
	Learning Rate: 0.00155928
	LOSS [training: 0.1064493174660276 | validation: 0.23679670069553993]
	TIME [epoch: 8.53 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13926358208100903		[learning rate: 0.0015556]
	Learning Rate: 0.0015556
	LOSS [training: 0.13926358208100903 | validation: 0.11679711942248014]
	TIME [epoch: 8.55 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13921018764081872		[learning rate: 0.0015519]
	Learning Rate: 0.00155193
	LOSS [training: 0.13921018764081872 | validation: 0.07765658773227857]
	TIME [epoch: 8.54 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10199124776905762		[learning rate: 0.0015483]
	Learning Rate: 0.00154827
	LOSS [training: 0.10199124776905762 | validation: 0.08672719263818472]
	TIME [epoch: 8.53 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1375739941457915		[learning rate: 0.0015446]
	Learning Rate: 0.00154462
	LOSS [training: 0.1375739941457915 | validation: 0.11583001426896278]
	TIME [epoch: 8.53 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11557506301897127		[learning rate: 0.001541]
	Learning Rate: 0.00154097
	LOSS [training: 0.11557506301897127 | validation: 0.0585487826904878]
	TIME [epoch: 8.55 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08659217114209067		[learning rate: 0.0015373]
	Learning Rate: 0.00153734
	LOSS [training: 0.08659217114209067 | validation: 0.19743980971498987]
	TIME [epoch: 8.53 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12025716918504048		[learning rate: 0.0015337]
	Learning Rate: 0.00153371
	LOSS [training: 0.12025716918504048 | validation: 0.08907859728069528]
	TIME [epoch: 8.53 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0989260073106403		[learning rate: 0.0015301]
	Learning Rate: 0.00153009
	LOSS [training: 0.0989260073106403 | validation: 0.10787254905447577]
	TIME [epoch: 8.52 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13109432434370422		[learning rate: 0.0015265]
	Learning Rate: 0.00152648
	LOSS [training: 0.13109432434370422 | validation: 0.25916601172759135]
	TIME [epoch: 8.55 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17393483152543923		[learning rate: 0.0015229]
	Learning Rate: 0.00152288
	LOSS [training: 0.17393483152543923 | validation: 0.0649864259778371]
	TIME [epoch: 8.53 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11032897383041493		[learning rate: 0.0015193]
	Learning Rate: 0.00151929
	LOSS [training: 0.11032897383041493 | validation: 0.07992545938756426]
	TIME [epoch: 8.52 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12056007538228333		[learning rate: 0.0015157]
	Learning Rate: 0.00151571
	LOSS [training: 0.12056007538228333 | validation: 0.17265286395558027]
	TIME [epoch: 8.52 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11792162845038823		[learning rate: 0.0015121]
	Learning Rate: 0.00151213
	LOSS [training: 0.11792162845038823 | validation: 0.08087456893072247]
	TIME [epoch: 8.55 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09953460009103551		[learning rate: 0.0015086]
	Learning Rate: 0.00150857
	LOSS [training: 0.09953460009103551 | validation: 0.08161701557834238]
	TIME [epoch: 8.53 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13304969745249598		[learning rate: 0.001505]
	Learning Rate: 0.00150501
	LOSS [training: 0.13304969745249598 | validation: 0.1950680874080895]
	TIME [epoch: 8.53 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11618193729166429		[learning rate: 0.0015015]
	Learning Rate: 0.00150146
	LOSS [training: 0.11618193729166429 | validation: 0.11015937474634667]
	TIME [epoch: 8.53 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10263070279789747		[learning rate: 0.0014979]
	Learning Rate: 0.00149791
	LOSS [training: 0.10263070279789747 | validation: 0.06573869728793308]
	TIME [epoch: 8.55 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10747521680821175		[learning rate: 0.0014944]
	Learning Rate: 0.00149438
	LOSS [training: 0.10747521680821175 | validation: 0.07574393514301055]
	TIME [epoch: 8.52 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09002416900638296		[learning rate: 0.0014909]
	Learning Rate: 0.00149086
	LOSS [training: 0.09002416900638296 | validation: 0.053487028550961456]
	TIME [epoch: 8.52 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10834023491270842		[learning rate: 0.0014873]
	Learning Rate: 0.00148734
	LOSS [training: 0.10834023491270842 | validation: 0.07319425268268864]
	TIME [epoch: 8.52 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09927634483633914		[learning rate: 0.0014838]
	Learning Rate: 0.00148383
	LOSS [training: 0.09927634483633914 | validation: 0.07595195508232563]
	TIME [epoch: 8.55 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12424428889790948		[learning rate: 0.0014803]
	Learning Rate: 0.00148033
	LOSS [training: 0.12424428889790948 | validation: 0.4935131374451217]
	TIME [epoch: 8.53 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20263902527893696		[learning rate: 0.0014768]
	Learning Rate: 0.00147684
	LOSS [training: 0.20263902527893696 | validation: 0.09997673504783772]
	TIME [epoch: 8.53 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1174712612355154		[learning rate: 0.0014734]
	Learning Rate: 0.00147336
	LOSS [training: 0.1174712612355154 | validation: 0.06979391652001773]
	TIME [epoch: 8.53 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13460274397915684		[learning rate: 0.0014699]
	Learning Rate: 0.00146988
	LOSS [training: 0.13460274397915684 | validation: 0.24108692571492557]
	TIME [epoch: 8.55 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11736043384445756		[learning rate: 0.0014664]
	Learning Rate: 0.00146641
	LOSS [training: 0.11736043384445756 | validation: 0.06146365437441563]
	TIME [epoch: 8.53 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10594808615710591		[learning rate: 0.001463]
	Learning Rate: 0.00146295
	LOSS [training: 0.10594808615710591 | validation: 0.10080791653101498]
	TIME [epoch: 8.53 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10448080351782418		[learning rate: 0.0014595]
	Learning Rate: 0.0014595
	LOSS [training: 0.10448080351782418 | validation: 0.0777765118081824]
	TIME [epoch: 8.53 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11228090750625053		[learning rate: 0.0014561]
	Learning Rate: 0.00145606
	LOSS [training: 0.11228090750625053 | validation: 0.12032046398683628]
	TIME [epoch: 8.53 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11568458610538437		[learning rate: 0.0014526]
	Learning Rate: 0.00145263
	LOSS [training: 0.11568458610538437 | validation: 0.2325516583673281]
	TIME [epoch: 8.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11947528409791577		[learning rate: 0.0014492]
	Learning Rate: 0.0014492
	LOSS [training: 0.11947528409791577 | validation: 0.1329867712043509]
	TIME [epoch: 8.52 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12792335109584707		[learning rate: 0.0014458]
	Learning Rate: 0.00144578
	LOSS [training: 0.12792335109584707 | validation: 0.15995607549690183]
	TIME [epoch: 8.54 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11381902108904465		[learning rate: 0.0014424]
	Learning Rate: 0.00144237
	LOSS [training: 0.11381902108904465 | validation: 0.10001677835480807]
	TIME [epoch: 8.54 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09463719026954928		[learning rate: 0.001439]
	Learning Rate: 0.00143897
	LOSS [training: 0.09463719026954928 | validation: 0.18954033659160044]
	TIME [epoch: 8.52 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15244402869444107		[learning rate: 0.0014356]
	Learning Rate: 0.00143557
	LOSS [training: 0.15244402869444107 | validation: 0.1424997059280254]
	TIME [epoch: 8.53 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1332548790753751		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.1332548790753751 | validation: 0.08622346620197452]
	TIME [epoch: 8.55 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11006942310907353		[learning rate: 0.0014288]
	Learning Rate: 0.00142881
	LOSS [training: 0.11006942310907353 | validation: 0.12520813581785584]
	TIME [epoch: 8.53 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10811933987407726		[learning rate: 0.0014254]
	Learning Rate: 0.00142544
	LOSS [training: 0.10811933987407726 | validation: 0.14429378510878665]
	TIME [epoch: 8.52 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11494977172733101		[learning rate: 0.0014221]
	Learning Rate: 0.00142208
	LOSS [training: 0.11494977172733101 | validation: 0.12787856339075285]
	TIME [epoch: 8.53 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1275926993148838		[learning rate: 0.0014187]
	Learning Rate: 0.00141872
	LOSS [training: 0.1275926993148838 | validation: 0.05670110259062181]
	TIME [epoch: 8.55 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09254351809317544		[learning rate: 0.0014154]
	Learning Rate: 0.00141538
	LOSS [training: 0.09254351809317544 | validation: 0.060176576498098294]
	TIME [epoch: 8.53 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09763498078298519		[learning rate: 0.001412]
	Learning Rate: 0.00141204
	LOSS [training: 0.09763498078298519 | validation: 0.04945040357242797]
	TIME [epoch: 8.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09556989754215628		[learning rate: 0.0014087]
	Learning Rate: 0.00140871
	LOSS [training: 0.09556989754215628 | validation: 0.14064814876498205]
	TIME [epoch: 8.53 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09172352221422447		[learning rate: 0.0014054]
	Learning Rate: 0.00140538
	LOSS [training: 0.09172352221422447 | validation: 0.14311056259248855]
	TIME [epoch: 8.55 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10816653098467073		[learning rate: 0.0014021]
	Learning Rate: 0.00140207
	LOSS [training: 0.10816653098467073 | validation: 0.06410666676134902]
	TIME [epoch: 8.53 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09244707094790895		[learning rate: 0.0013988]
	Learning Rate: 0.00139876
	LOSS [training: 0.09244707094790895 | validation: 0.11295511558207619]
	TIME [epoch: 8.53 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10682523964485427		[learning rate: 0.0013955]
	Learning Rate: 0.00139546
	LOSS [training: 0.10682523964485427 | validation: 0.11355419612896889]
	TIME [epoch: 8.53 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10027252041601287		[learning rate: 0.0013922]
	Learning Rate: 0.00139217
	LOSS [training: 0.10027252041601287 | validation: 0.08858646742613036]
	TIME [epoch: 8.56 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09968901416797264		[learning rate: 0.0013889]
	Learning Rate: 0.00138889
	LOSS [training: 0.09968901416797264 | validation: 0.08650134920279981]
	TIME [epoch: 8.53 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1059052098779953		[learning rate: 0.0013856]
	Learning Rate: 0.00138561
	LOSS [training: 0.1059052098779953 | validation: 0.12461262470996776]
	TIME [epoch: 8.53 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1098318850223289		[learning rate: 0.0013823]
	Learning Rate: 0.00138234
	LOSS [training: 0.1098318850223289 | validation: 0.08123181991667713]
	TIME [epoch: 8.53 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09946264454927764		[learning rate: 0.0013791]
	Learning Rate: 0.00137908
	LOSS [training: 0.09946264454927764 | validation: 0.05342729951750595]
	TIME [epoch: 8.55 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09756470480760912		[learning rate: 0.0013758]
	Learning Rate: 0.00137583
	LOSS [training: 0.09756470480760912 | validation: 0.06897373725154021]
	TIME [epoch: 8.53 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11373212547464087		[learning rate: 0.0013726]
	Learning Rate: 0.00137258
	LOSS [training: 0.11373212547464087 | validation: 0.08867012623536911]
	TIME [epoch: 8.53 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12028790218627947		[learning rate: 0.0013693]
	Learning Rate: 0.00136934
	LOSS [training: 0.12028790218627947 | validation: 0.05534544499240372]
	TIME [epoch: 8.53 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08785200827898952		[learning rate: 0.0013661]
	Learning Rate: 0.00136611
	LOSS [training: 0.08785200827898952 | validation: 0.12460684420880316]
	TIME [epoch: 8.54 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13465593348817337		[learning rate: 0.0013629]
	Learning Rate: 0.00136289
	LOSS [training: 0.13465593348817337 | validation: 0.08629350622074194]
	TIME [epoch: 8.52 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1474491066364026		[learning rate: 0.0013597]
	Learning Rate: 0.00135968
	LOSS [training: 0.1474491066364026 | validation: 0.15500488740967466]
	TIME [epoch: 8.53 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1312317036366833		[learning rate: 0.0013565]
	Learning Rate: 0.00135647
	LOSS [training: 0.1312317036366833 | validation: 0.17649098295350116]
	TIME [epoch: 8.55 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.133164514010831		[learning rate: 0.0013533]
	Learning Rate: 0.00135327
	LOSS [training: 0.133164514010831 | validation: 0.16921637918408167]
	TIME [epoch: 8.53 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.115523015336413		[learning rate: 0.0013501]
	Learning Rate: 0.00135008
	LOSS [training: 0.115523015336413 | validation: 0.08328651045452376]
	TIME [epoch: 8.52 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14001225673198395		[learning rate: 0.0013469]
	Learning Rate: 0.00134689
	LOSS [training: 0.14001225673198395 | validation: 0.08572657374670664]
	TIME [epoch: 8.52 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09278235878988055		[learning rate: 0.0013437]
	Learning Rate: 0.00134372
	LOSS [training: 0.09278235878988055 | validation: 0.06600328299343299]
	TIME [epoch: 8.54 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1175259809891446		[learning rate: 0.0013405]
	Learning Rate: 0.00134055
	LOSS [training: 0.1175259809891446 | validation: 0.07224093897464845]
	TIME [epoch: 8.54 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1029903648201265		[learning rate: 0.0013374]
	Learning Rate: 0.00133738
	LOSS [training: 0.1029903648201265 | validation: 0.05945831586856776]
	TIME [epoch: 8.52 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11872671045952252		[learning rate: 0.0013342]
	Learning Rate: 0.00133423
	LOSS [training: 0.11872671045952252 | validation: 0.09455776606146071]
	TIME [epoch: 8.53 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12232361192191905		[learning rate: 0.0013311]
	Learning Rate: 0.00133108
	LOSS [training: 0.12232361192191905 | validation: 0.08709521690690081]
	TIME [epoch: 8.55 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0923889039305376		[learning rate: 0.0013279]
	Learning Rate: 0.00132794
	LOSS [training: 0.0923889039305376 | validation: 0.0711931729365021]
	TIME [epoch: 8.53 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.126484924784813		[learning rate: 0.0013248]
	Learning Rate: 0.00132481
	LOSS [training: 0.126484924784813 | validation: 0.06441691251643124]
	TIME [epoch: 8.52 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08408090934071046		[learning rate: 0.0013217]
	Learning Rate: 0.00132169
	LOSS [training: 0.08408090934071046 | validation: 0.12254712253939673]
	TIME [epoch: 8.52 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0973847911250166		[learning rate: 0.0013186]
	Learning Rate: 0.00131857
	LOSS [training: 0.0973847911250166 | validation: 0.08859190965641642]
	TIME [epoch: 8.55 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09098793764542212		[learning rate: 0.0013155]
	Learning Rate: 0.00131546
	LOSS [training: 0.09098793764542212 | validation: 0.06992853208865996]
	TIME [epoch: 8.53 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12071630293887661		[learning rate: 0.0013124]
	Learning Rate: 0.00131235
	LOSS [training: 0.12071630293887661 | validation: 0.08205602374801652]
	TIME [epoch: 8.52 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11621390964057195		[learning rate: 0.0013093]
	Learning Rate: 0.00130926
	LOSS [training: 0.11621390964057195 | validation: 0.14696236537782448]
	TIME [epoch: 8.52 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11570035102660312		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.11570035102660312 | validation: 0.115445016067437]
	TIME [epoch: 8.54 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12183922157214608		[learning rate: 0.0013031]
	Learning Rate: 0.00130309
	LOSS [training: 0.12183922157214608 | validation: 0.10835580194684405]
	TIME [epoch: 8.53 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11847571146063016		[learning rate: 0.0013]
	Learning Rate: 0.00130002
	LOSS [training: 0.11847571146063016 | validation: 0.09995591747925922]
	TIME [epoch: 8.52 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11137980433043715		[learning rate: 0.0012969]
	Learning Rate: 0.00129695
	LOSS [training: 0.11137980433043715 | validation: 0.09880572679184314]
	TIME [epoch: 8.52 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12844447514585905		[learning rate: 0.0012939]
	Learning Rate: 0.00129389
	LOSS [training: 0.12844447514585905 | validation: 0.06610131244677328]
	TIME [epoch: 8.55 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10698789226540147		[learning rate: 0.0012908]
	Learning Rate: 0.00129084
	LOSS [training: 0.10698789226540147 | validation: 0.05595660311151376]
	TIME [epoch: 8.53 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0864788746882014		[learning rate: 0.0012878]
	Learning Rate: 0.00128779
	LOSS [training: 0.0864788746882014 | validation: 0.14466641280660697]
	TIME [epoch: 8.52 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1679617402320509		[learning rate: 0.0012848]
	Learning Rate: 0.00128476
	LOSS [training: 0.1679617402320509 | validation: 0.04155198607305413]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_919.pth
	Model improved!!!
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07756528665717781		[learning rate: 0.0012817]
	Learning Rate: 0.00128173
	LOSS [training: 0.07756528665717781 | validation: 0.06974881473271634]
	TIME [epoch: 8.55 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09563920805459103		[learning rate: 0.0012787]
	Learning Rate: 0.0012787
	LOSS [training: 0.09563920805459103 | validation: 0.040154591704058815]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09925343121261927		[learning rate: 0.0012757]
	Learning Rate: 0.00127569
	LOSS [training: 0.09925343121261927 | validation: 0.08470103553672803]
	TIME [epoch: 8.52 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08498584888421011		[learning rate: 0.0012727]
	Learning Rate: 0.00127268
	LOSS [training: 0.08498584888421011 | validation: 0.14782584804584403]
	TIME [epoch: 8.53 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10351988734918902		[learning rate: 0.0012697]
	Learning Rate: 0.00126967
	LOSS [training: 0.10351988734918902 | validation: 0.04198898749465507]
	TIME [epoch: 8.54 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11749125112123579		[learning rate: 0.0012667]
	Learning Rate: 0.00126668
	LOSS [training: 0.11749125112123579 | validation: 0.06335488679807347]
	TIME [epoch: 8.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08005377956811315		[learning rate: 0.0012637]
	Learning Rate: 0.00126369
	LOSS [training: 0.08005377956811315 | validation: 0.11198319917670681]
	TIME [epoch: 8.52 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07722566502282638		[learning rate: 0.0012607]
	Learning Rate: 0.00126071
	LOSS [training: 0.07722566502282638 | validation: 0.08151950808510712]
	TIME [epoch: 8.54 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11869334469338622		[learning rate: 0.0012577]
	Learning Rate: 0.00125774
	LOSS [training: 0.11869334469338622 | validation: 0.12930118323196144]
	TIME [epoch: 8.54 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11879789323847283		[learning rate: 0.0012548]
	Learning Rate: 0.00125477
	LOSS [training: 0.11879789323847283 | validation: 0.2093147507282071]
	TIME [epoch: 8.52 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18522909970222465		[learning rate: 0.0012518]
	Learning Rate: 0.00125181
	LOSS [training: 0.18522909970222465 | validation: 0.08252557315116132]
	TIME [epoch: 8.52 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10130734838143321		[learning rate: 0.0012489]
	Learning Rate: 0.00124886
	LOSS [training: 0.10130734838143321 | validation: 0.0540205827284433]
	TIME [epoch: 8.53 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10300538160026522		[learning rate: 0.0012459]
	Learning Rate: 0.00124591
	LOSS [training: 0.10300538160026522 | validation: 0.06665551347663122]
	TIME [epoch: 8.53 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10574699517769037		[learning rate: 0.001243]
	Learning Rate: 0.00124297
	LOSS [training: 0.10574699517769037 | validation: 0.04905715696852471]
	TIME [epoch: 8.51 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09124111096624392		[learning rate: 0.00124]
	Learning Rate: 0.00124004
	LOSS [training: 0.09124111096624392 | validation: 0.07338817165010175]
	TIME [epoch: 8.52 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11226130281484656		[learning rate: 0.0012371]
	Learning Rate: 0.00123712
	LOSS [training: 0.11226130281484656 | validation: 0.07137537516825758]
	TIME [epoch: 8.54 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09323484038579131		[learning rate: 0.0012342]
	Learning Rate: 0.0012342
	LOSS [training: 0.09323484038579131 | validation: 0.07935160736898965]
	TIME [epoch: 8.52 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16270067302482843		[learning rate: 0.0012313]
	Learning Rate: 0.00123129
	LOSS [training: 0.16270067302482843 | validation: 0.041026534840576945]
	TIME [epoch: 8.52 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0908552527001269		[learning rate: 0.0012284]
	Learning Rate: 0.00122838
	LOSS [training: 0.0908552527001269 | validation: 0.08497079891629189]
	TIME [epoch: 8.52 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1449157381340955		[learning rate: 0.0012255]
	Learning Rate: 0.00122548
	LOSS [training: 0.1449157381340955 | validation: 0.047798598710536]
	TIME [epoch: 8.54 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06680838060095926		[learning rate: 0.0012226]
	Learning Rate: 0.00122259
	LOSS [training: 0.06680838060095926 | validation: 0.03905938538742075]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_940.pth
	Model improved!!!
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0883437044597701		[learning rate: 0.0012197]
	Learning Rate: 0.00121971
	LOSS [training: 0.0883437044597701 | validation: 0.05889934991758107]
	TIME [epoch: 8.52 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09427333275383537		[learning rate: 0.0012168]
	Learning Rate: 0.00121683
	LOSS [training: 0.09427333275383537 | validation: 0.08294301800371458]
	TIME [epoch: 8.52 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013472360241457		[learning rate: 0.001214]
	Learning Rate: 0.00121396
	LOSS [training: 0.1013472360241457 | validation: 0.0908459464451885]
	TIME [epoch: 8.55 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08319981584389993		[learning rate: 0.0012111]
	Learning Rate: 0.0012111
	LOSS [training: 0.08319981584389993 | validation: 0.07948089218641874]
	TIME [epoch: 8.52 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08999268785435056		[learning rate: 0.0012082]
	Learning Rate: 0.00120824
	LOSS [training: 0.08999268785435056 | validation: 0.10462716129350264]
	TIME [epoch: 8.52 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10041007422239707		[learning rate: 0.0012054]
	Learning Rate: 0.00120539
	LOSS [training: 0.10041007422239707 | validation: 0.05117971137642402]
	TIME [epoch: 8.52 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08519755881120697		[learning rate: 0.0012025]
	Learning Rate: 0.00120255
	LOSS [training: 0.08519755881120697 | validation: 0.03298376284858506]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07435312211521802		[learning rate: 0.0011997]
	Learning Rate: 0.00119971
	LOSS [training: 0.07435312211521802 | validation: 0.06633549003126638]
	TIME [epoch: 8.52 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0749030627955011		[learning rate: 0.0011969]
	Learning Rate: 0.00119688
	LOSS [training: 0.0749030627955011 | validation: 0.08358972926064259]
	TIME [epoch: 8.52 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08545264462979765		[learning rate: 0.0011941]
	Learning Rate: 0.00119406
	LOSS [training: 0.08545264462979765 | validation: 0.08918740686548199]
	TIME [epoch: 8.53 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10875062821557771		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.10875062821557771 | validation: 0.13277102483003672]
	TIME [epoch: 8.54 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.088482739175662		[learning rate: 0.0011884]
	Learning Rate: 0.00118843
	LOSS [training: 0.088482739175662 | validation: 0.10145874469924437]
	TIME [epoch: 8.52 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1057445441493919		[learning rate: 0.0011856]
	Learning Rate: 0.00118563
	LOSS [training: 0.1057445441493919 | validation: 0.19548033641275286]
	TIME [epoch: 8.52 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10578377699124686		[learning rate: 0.0011828]
	Learning Rate: 0.00118283
	LOSS [training: 0.10578377699124686 | validation: 0.04008424701323246]
	TIME [epoch: 8.54 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09261898682045626		[learning rate: 0.00118]
	Learning Rate: 0.00118004
	LOSS [training: 0.09261898682045626 | validation: 0.04150025934494324]
	TIME [epoch: 8.53 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08939029905503149		[learning rate: 0.0011773]
	Learning Rate: 0.00117726
	LOSS [training: 0.08939029905503149 | validation: 0.22955422066015319]
	TIME [epoch: 8.52 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10917651865077707		[learning rate: 0.0011745]
	Learning Rate: 0.00117448
	LOSS [training: 0.10917651865077707 | validation: 0.03728904436129312]
	TIME [epoch: 8.52 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07595043928785974		[learning rate: 0.0011717]
	Learning Rate: 0.00117171
	LOSS [training: 0.07595043928785974 | validation: 0.05199186245833037]
	TIME [epoch: 8.53 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158627874287687		[learning rate: 0.0011689]
	Learning Rate: 0.00116895
	LOSS [training: 0.08158627874287687 | validation: 0.07371449178079208]
	TIME [epoch: 8.53 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07287913503153218		[learning rate: 0.0011662]
	Learning Rate: 0.00116619
	LOSS [training: 0.07287913503153218 | validation: 0.07155800586980304]
	TIME [epoch: 8.52 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0816438819796938		[learning rate: 0.0011634]
	Learning Rate: 0.00116344
	LOSS [training: 0.0816438819796938 | validation: 0.09868806046718599]
	TIME [epoch: 8.52 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10413337659327337		[learning rate: 0.0011607]
	Learning Rate: 0.00116069
	LOSS [training: 0.10413337659327337 | validation: 0.06544014576131445]
	TIME [epoch: 8.54 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09285303374637419		[learning rate: 0.001158]
	Learning Rate: 0.00115796
	LOSS [training: 0.09285303374637419 | validation: 0.112858131704875]
	TIME [epoch: 8.53 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09189437064437098		[learning rate: 0.0011552]
	Learning Rate: 0.00115523
	LOSS [training: 0.09189437064437098 | validation: 0.08463244568081066]
	TIME [epoch: 8.52 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0902959068973772		[learning rate: 0.0011525]
	Learning Rate: 0.0011525
	LOSS [training: 0.0902959068973772 | validation: 0.05577651775549061]
	TIME [epoch: 8.52 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07924311587542791		[learning rate: 0.0011498]
	Learning Rate: 0.00114978
	LOSS [training: 0.07924311587542791 | validation: 0.10890759703022622]
	TIME [epoch: 8.54 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08434324141762538		[learning rate: 0.0011471]
	Learning Rate: 0.00114707
	LOSS [training: 0.08434324141762538 | validation: 0.045465360025340615]
	TIME [epoch: 8.52 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1035611788419386		[learning rate: 0.0011444]
	Learning Rate: 0.00114436
	LOSS [training: 0.1035611788419386 | validation: 0.07965824176319025]
	TIME [epoch: 8.52 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10148382149199556		[learning rate: 0.0011417]
	Learning Rate: 0.00114166
	LOSS [training: 0.10148382149199556 | validation: 0.10324659434871312]
	TIME [epoch: 8.52 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11101248850344972		[learning rate: 0.001139]
	Learning Rate: 0.00113897
	LOSS [training: 0.11101248850344972 | validation: 0.04822735972970263]
	TIME [epoch: 8.54 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15904002575948267		[learning rate: 0.0011363]
	Learning Rate: 0.00113628
	LOSS [training: 0.15904002575948267 | validation: 0.14361742752772383]
	TIME [epoch: 8.52 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08735523189905961		[learning rate: 0.0011336]
	Learning Rate: 0.0011336
	LOSS [training: 0.08735523189905961 | validation: 0.09736655298917744]
	TIME [epoch: 8.52 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08977010512981512		[learning rate: 0.0011309]
	Learning Rate: 0.00113093
	LOSS [training: 0.08977010512981512 | validation: 0.06811749514565005]
	TIME [epoch: 8.52 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06560692472261255		[learning rate: 0.0011283]
	Learning Rate: 0.00112826
	LOSS [training: 0.06560692472261255 | validation: 0.059855045034164084]
	TIME [epoch: 8.54 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0732020368236069		[learning rate: 0.0011256]
	Learning Rate: 0.0011256
	LOSS [training: 0.0732020368236069 | validation: 0.040039255415015185]
	TIME [epoch: 8.52 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10675234726964608		[learning rate: 0.0011229]
	Learning Rate: 0.00112295
	LOSS [training: 0.10675234726964608 | validation: 0.06961175127780528]
	TIME [epoch: 8.52 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09886533540648018		[learning rate: 0.0011203]
	Learning Rate: 0.0011203
	LOSS [training: 0.09886533540648018 | validation: 0.1315384191448255]
	TIME [epoch: 8.52 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12065261805450075		[learning rate: 0.0011177]
	Learning Rate: 0.00111765
	LOSS [training: 0.12065261805450075 | validation: 0.06854787748373965]
	TIME [epoch: 8.55 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08340285207226962		[learning rate: 0.001115]
	Learning Rate: 0.00111502
	LOSS [training: 0.08340285207226962 | validation: 0.04502472873451059]
	TIME [epoch: 8.52 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0713017008462999		[learning rate: 0.0011124]
	Learning Rate: 0.00111239
	LOSS [training: 0.0713017008462999 | validation: 0.07414954046958232]
	TIME [epoch: 8.52 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06506621276782858		[learning rate: 0.0011098]
	Learning Rate: 0.00110976
	LOSS [training: 0.06506621276782858 | validation: 0.04066830299707405]
	TIME [epoch: 8.52 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06546403216631962		[learning rate: 0.0011071]
	Learning Rate: 0.00110715
	LOSS [training: 0.06546403216631962 | validation: 0.050751049977657864]
	TIME [epoch: 8.54 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0935394273710291		[learning rate: 0.0011045]
	Learning Rate: 0.00110453
	LOSS [training: 0.0935394273710291 | validation: 0.060722823312123794]
	TIME [epoch: 8.52 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07964651695861971		[learning rate: 0.0011019]
	Learning Rate: 0.00110193
	LOSS [training: 0.07964651695861971 | validation: 0.047466988003903296]
	TIME [epoch: 8.52 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08799094671258993		[learning rate: 0.0010993]
	Learning Rate: 0.00109933
	LOSS [training: 0.08799094671258993 | validation: 0.03776422815900916]
	TIME [epoch: 8.52 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08791649766176395		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.08791649766176395 | validation: 0.04090157363674783]
	TIME [epoch: 8.54 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07676271447257729		[learning rate: 0.0010942]
	Learning Rate: 0.00109415
	LOSS [training: 0.07676271447257729 | validation: 0.04866968906149215]
	TIME [epoch: 8.52 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07140825205486288		[learning rate: 0.0010916]
	Learning Rate: 0.00109157
	LOSS [training: 0.07140825205486288 | validation: 0.11289934143012913]
	TIME [epoch: 8.52 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09454869371997829		[learning rate: 0.001089]
	Learning Rate: 0.00108899
	LOSS [training: 0.09454869371997829 | validation: 0.059371113251170046]
	TIME [epoch: 8.54 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066570209475417		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.07066570209475417 | validation: 0.08381106273485936]
	TIME [epoch: 8.53 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12356752297436438		[learning rate: 0.0010839]
	Learning Rate: 0.00108386
	LOSS [training: 0.12356752297436438 | validation: 0.06567939139652867]
	TIME [epoch: 8.52 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0976080469638446		[learning rate: 0.0010813]
	Learning Rate: 0.00108131
	LOSS [training: 0.0976080469638446 | validation: 0.05471099896617692]
	TIME [epoch: 8.52 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06911060844417025		[learning rate: 0.0010788]
	Learning Rate: 0.00107876
	LOSS [training: 0.06911060844417025 | validation: 0.10277044913546182]
	TIME [epoch: 8.53 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12865405986443423		[learning rate: 0.0010762]
	Learning Rate: 0.00107621
	LOSS [training: 0.12865405986443423 | validation: 0.054774598743562324]
	TIME [epoch: 8.53 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07258162943644306		[learning rate: 0.0010737]
	Learning Rate: 0.00107367
	LOSS [training: 0.07258162943644306 | validation: 0.04595339684475461]
	TIME [epoch: 8.52 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08714529916586586		[learning rate: 0.0010711]
	Learning Rate: 0.00107114
	LOSS [training: 0.08714529916586586 | validation: 0.06750571868527072]
	TIME [epoch: 8.52 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09133511488477462		[learning rate: 0.0010686]
	Learning Rate: 0.00106861
	LOSS [training: 0.09133511488477462 | validation: 0.10824909174886853]
	TIME [epoch: 8.54 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10482035876678109		[learning rate: 0.0010661]
	Learning Rate: 0.00106609
	LOSS [training: 0.10482035876678109 | validation: 0.06896385958367127]
	TIME [epoch: 8.52 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08778245905737726		[learning rate: 0.0010636]
	Learning Rate: 0.00106358
	LOSS [training: 0.08778245905737726 | validation: 0.11216775089918929]
	TIME [epoch: 8.51 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09544024227410568		[learning rate: 0.0010611]
	Learning Rate: 0.00106107
	LOSS [training: 0.09544024227410568 | validation: 0.09997452166466206]
	TIME [epoch: 8.52 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09111958744201717		[learning rate: 0.0010586]
	Learning Rate: 0.00105857
	LOSS [training: 0.09111958744201717 | validation: 0.05412092474503838]
	TIME [epoch: 8.54 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08121780995031501		[learning rate: 0.0010561]
	Learning Rate: 0.00105607
	LOSS [training: 0.08121780995031501 | validation: 0.06968171912133236]
	TIME [epoch: 8.52 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10686094355336598		[learning rate: 0.0010536]
	Learning Rate: 0.00105358
	LOSS [training: 0.10686094355336598 | validation: 0.07651468486659492]
	TIME [epoch: 8.52 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08758228542049097		[learning rate: 0.0010511]
	Learning Rate: 0.00105109
	LOSS [training: 0.08758228542049097 | validation: 0.06002903312434239]
	TIME [epoch: 8.52 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09614487395214115		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.09614487395214115 | validation: 0.0692449665230199]
	TIME [epoch: 8.54 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0767951299795719		[learning rate: 0.0010461]
	Learning Rate: 0.00104614
	LOSS [training: 0.0767951299795719 | validation: 0.08614403240419627]
	TIME [epoch: 8.52 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158513854155489		[learning rate: 0.0010437]
	Learning Rate: 0.00104367
	LOSS [training: 0.08158513854155489 | validation: 0.07789758838456276]
	TIME [epoch: 8.52 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247916458732439		[learning rate: 0.0010412]
	Learning Rate: 0.00104121
	LOSS [training: 0.08247916458732439 | validation: 0.06464104891138814]
	TIME [epoch: 8.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07263129868005161		[learning rate: 0.0010388]
	Learning Rate: 0.00103875
	LOSS [training: 0.07263129868005161 | validation: 0.04624619150843529]
	TIME [epoch: 8.54 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096561455672838		[learning rate: 0.0010363]
	Learning Rate: 0.0010363
	LOSS [training: 0.096561455672838 | validation: 0.0402086724451244]
	TIME [epoch: 8.51 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10191996842273639		[learning rate: 0.0010339]
	Learning Rate: 0.00103386
	LOSS [training: 0.10191996842273639 | validation: 0.049964482531514656]
	TIME [epoch: 8.51 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09415432684042487		[learning rate: 0.0010314]
	Learning Rate: 0.00103142
	LOSS [training: 0.09415432684042487 | validation: 0.14094397217829108]
	TIME [epoch: 8.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08203792878072794		[learning rate: 0.001029]
	Learning Rate: 0.00102899
	LOSS [training: 0.08203792878072794 | validation: 0.18231593097988086]
	TIME [epoch: 8.54 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14505693857438096		[learning rate: 0.0010266]
	Learning Rate: 0.00102656
	LOSS [training: 0.14505693857438096 | validation: 0.05160043004277917]
	TIME [epoch: 8.52 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09503173949020834		[learning rate: 0.0010241]
	Learning Rate: 0.00102414
	LOSS [training: 0.09503173949020834 | validation: 0.13628645333700007]
	TIME [epoch: 8.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07587490103197786		[learning rate: 0.0010217]
	Learning Rate: 0.00102172
	LOSS [training: 0.07587490103197786 | validation: 0.09999361726210641]
	TIME [epoch: 8.52 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07929610175743443		[learning rate: 0.0010193]
	Learning Rate: 0.00101931
	LOSS [training: 0.07929610175743443 | validation: 0.09870692409757029]
	TIME [epoch: 8.54 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766253342385533		[learning rate: 0.0010169]
	Learning Rate: 0.00101691
	LOSS [training: 0.0766253342385533 | validation: 0.0707271399023199]
	TIME [epoch: 8.52 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09104762833928734		[learning rate: 0.0010145]
	Learning Rate: 0.00101451
	LOSS [training: 0.09104762833928734 | validation: 0.07631941439063275]
	TIME [epoch: 8.52 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461391010546653		[learning rate: 0.0010121]
	Learning Rate: 0.00101212
	LOSS [training: 0.10461391010546653 | validation: 0.07600789908137473]
	TIME [epoch: 8.52 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10212373582432469		[learning rate: 0.0010097]
	Learning Rate: 0.00100973
	LOSS [training: 0.10212373582432469 | validation: 0.13877436826657308]
	TIME [epoch: 8.53 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07826644595514168		[learning rate: 0.0010073]
	Learning Rate: 0.00100735
	LOSS [training: 0.07826644595514168 | validation: 0.05729932900207229]
	TIME [epoch: 8.51 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07475220283543385		[learning rate: 0.001005]
	Learning Rate: 0.00100497
	LOSS [training: 0.07475220283543385 | validation: 0.054567663493109105]
	TIME [epoch: 8.52 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09942356946297651		[learning rate: 0.0010026]
	Learning Rate: 0.0010026
	LOSS [training: 0.09942356946297651 | validation: 0.11342777291535347]
	TIME [epoch: 8.53 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07683050434847025		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.07683050434847025 | validation: 0.1157983733212633]
	TIME [epoch: 8.53 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10486939129397521		[learning rate: 0.00099788]
	Learning Rate: 0.000997877
	LOSS [training: 0.10486939129397521 | validation: 0.06861941500777483]
	TIME [epoch: 8.52 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09527485963249975		[learning rate: 0.00099552]
	Learning Rate: 0.000995523
	LOSS [training: 0.09527485963249975 | validation: 0.05780673464056964]
	TIME [epoch: 8.51 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09165064896127453		[learning rate: 0.00099317]
	Learning Rate: 0.000993175
	LOSS [training: 0.09165064896127453 | validation: 0.1362560463938227]
	TIME [epoch: 8.53 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09954478797582707		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.09954478797582707 | validation: 0.06511378547158714]
	TIME [epoch: 8.53 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11578202879768185		[learning rate: 0.00098849]
	Learning Rate: 0.000988495
	LOSS [training: 0.11578202879768185 | validation: 0.07482788841660735]
	TIME [epoch: 8.52 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0973133899360322		[learning rate: 0.00098616]
	Learning Rate: 0.000986163
	LOSS [training: 0.0973133899360322 | validation: 0.05559610131794228]
	TIME [epoch: 8.52 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094213326013858		[learning rate: 0.00098384]
	Learning Rate: 0.000983837
	LOSS [training: 0.07094213326013858 | validation: 0.11639015085422563]
	TIME [epoch: 8.54 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1058094353726364		[learning rate: 0.00098152]
	Learning Rate: 0.000981516
	LOSS [training: 0.1058094353726364 | validation: 0.06767062497135723]
	TIME [epoch: 8.53 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0926597491442296		[learning rate: 0.0009792]
	Learning Rate: 0.000979201
	LOSS [training: 0.0926597491442296 | validation: 0.06421276632693158]
	TIME [epoch: 8.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09157836435635427		[learning rate: 0.00097689]
	Learning Rate: 0.000976891
	LOSS [training: 0.09157836435635427 | validation: 0.05907919876418696]
	TIME [epoch: 8.51 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07782169147749722		[learning rate: 0.00097459]
	Learning Rate: 0.000974587
	LOSS [training: 0.07782169147749722 | validation: 0.09852007712549354]
	TIME [epoch: 8.54 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08270768486111915		[learning rate: 0.00097229]
	Learning Rate: 0.000972288
	LOSS [training: 0.08270768486111915 | validation: 0.04457632746986637]
	TIME [epoch: 8.52 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08133289023507972		[learning rate: 0.00096999]
	Learning Rate: 0.000969994
	LOSS [training: 0.08133289023507972 | validation: 0.05918915226439747]
	TIME [epoch: 8.52 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07849365894216262		[learning rate: 0.00096771]
	Learning Rate: 0.000967706
	LOSS [training: 0.07849365894216262 | validation: 0.05613200357073983]
	TIME [epoch: 8.52 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06895695845852436		[learning rate: 0.00096542]
	Learning Rate: 0.000965424
	LOSS [training: 0.06895695845852436 | validation: 0.10739180222251299]
	TIME [epoch: 8.54 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0804838688042929		[learning rate: 0.00096315]
	Learning Rate: 0.000963146
	LOSS [training: 0.0804838688042929 | validation: 0.10142124490763915]
	TIME [epoch: 8.52 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09950266974777465		[learning rate: 0.00096087]
	Learning Rate: 0.000960874
	LOSS [training: 0.09950266974777465 | validation: 0.06996463443616815]
	TIME [epoch: 8.52 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07610059275388288		[learning rate: 0.00095861]
	Learning Rate: 0.000958608
	LOSS [training: 0.07610059275388288 | validation: 0.09605800157394968]
	TIME [epoch: 8.52 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0815413324094379		[learning rate: 0.00095635]
	Learning Rate: 0.000956347
	LOSS [training: 0.0815413324094379 | validation: 0.034934948228743115]
	TIME [epoch: 8.54 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05741366492710791		[learning rate: 0.00095409]
	Learning Rate: 0.000954091
	LOSS [training: 0.05741366492710791 | validation: 0.06550627529009181]
	TIME [epoch: 8.52 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07896151689977501		[learning rate: 0.00095184]
	Learning Rate: 0.00095184
	LOSS [training: 0.07896151689977501 | validation: 0.04367023888957852]
	TIME [epoch: 8.51 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06477306893822342		[learning rate: 0.0009496]
	Learning Rate: 0.000949595
	LOSS [training: 0.06477306893822342 | validation: 0.1165384609970318]
	TIME [epoch: 8.51 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08293855814629536		[learning rate: 0.00094736]
	Learning Rate: 0.000947355
	LOSS [training: 0.08293855814629536 | validation: 0.07090269531495767]
	TIME [epoch: 8.54 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08367722641943112		[learning rate: 0.00094512]
	Learning Rate: 0.000945121
	LOSS [training: 0.08367722641943112 | validation: 0.05254159034241285]
	TIME [epoch: 8.51 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07760214974364905		[learning rate: 0.00094289]
	Learning Rate: 0.000942891
	LOSS [training: 0.07760214974364905 | validation: 0.054321153083759774]
	TIME [epoch: 8.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06306214532302343		[learning rate: 0.00094067]
	Learning Rate: 0.000940667
	LOSS [training: 0.06306214532302343 | validation: 0.0573437208210693]
	TIME [epoch: 8.51 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08077455876656697		[learning rate: 0.00093845]
	Learning Rate: 0.000938448
	LOSS [training: 0.08077455876656697 | validation: 0.07038210837698519]
	TIME [epoch: 8.54 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08382955324034012		[learning rate: 0.00093623]
	Learning Rate: 0.000936234
	LOSS [training: 0.08382955324034012 | validation: 0.095653829391034]
	TIME [epoch: 8.52 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09815424868496742		[learning rate: 0.00093403]
	Learning Rate: 0.000934026
	LOSS [training: 0.09815424868496742 | validation: 0.05856899164667805]
	TIME [epoch: 8.51 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09329589999742698		[learning rate: 0.00093182]
	Learning Rate: 0.000931823
	LOSS [training: 0.09329589999742698 | validation: 0.051606707311980665]
	TIME [epoch: 8.51 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10499765244766286		[learning rate: 0.00092962]
	Learning Rate: 0.000929625
	LOSS [training: 0.10499765244766286 | validation: 0.08061689534505156]
	TIME [epoch: 8.54 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790015643981814		[learning rate: 0.00092743]
	Learning Rate: 0.000927432
	LOSS [training: 0.0790015643981814 | validation: 0.06600134606772046]
	TIME [epoch: 8.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06590339884809598		[learning rate: 0.00092524]
	Learning Rate: 0.000925244
	LOSS [training: 0.06590339884809598 | validation: 0.05974260140731012]
	TIME [epoch: 8.51 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10147846388758083		[learning rate: 0.00092306]
	Learning Rate: 0.000923062
	LOSS [training: 0.10147846388758083 | validation: 0.128350721228437]
	TIME [epoch: 8.52 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08082261971399382		[learning rate: 0.00092088]
	Learning Rate: 0.000920884
	LOSS [training: 0.08082261971399382 | validation: 0.04394950269227898]
	TIME [epoch: 8.52 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06390929254957495		[learning rate: 0.00091871]
	Learning Rate: 0.000918712
	LOSS [training: 0.06390929254957495 | validation: 0.07544027758226914]
	TIME [epoch: 8.52 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0699108160485226		[learning rate: 0.00091654]
	Learning Rate: 0.000916545
	LOSS [training: 0.0699108160485226 | validation: 0.08102322958692254]
	TIME [epoch: 8.51 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07888468451333304		[learning rate: 0.00091438]
	Learning Rate: 0.000914383
	LOSS [training: 0.07888468451333304 | validation: 0.0678246902710678]
	TIME [epoch: 8.53 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07245779045034398		[learning rate: 0.00091223]
	Learning Rate: 0.000912226
	LOSS [training: 0.07245779045034398 | validation: 0.03837120904292077]
	TIME [epoch: 8.53 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07033463962157394		[learning rate: 0.00091007]
	Learning Rate: 0.000910074
	LOSS [training: 0.07033463962157394 | validation: 0.09246873983688181]
	TIME [epoch: 8.52 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10955291408794068		[learning rate: 0.00090793]
	Learning Rate: 0.000907928
	LOSS [training: 0.10955291408794068 | validation: 0.21786136370809722]
	TIME [epoch: 8.52 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1394407870828067		[learning rate: 0.00090579]
	Learning Rate: 0.000905786
	LOSS [training: 0.1394407870828067 | validation: 0.14248480639109148]
	TIME [epoch: 8.54 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09893002639139493		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.09893002639139493 | validation: 0.05376579397233387]
	TIME [epoch: 8.52 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06272213383834346		[learning rate: 0.00090152]
	Learning Rate: 0.000901518
	LOSS [training: 0.06272213383834346 | validation: 0.03544538320154412]
	TIME [epoch: 8.52 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06573781292114078		[learning rate: 0.00089939]
	Learning Rate: 0.000899391
	LOSS [training: 0.06573781292114078 | validation: 0.05452372383541973]
	TIME [epoch: 8.51 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0827913602919906		[learning rate: 0.00089727]
	Learning Rate: 0.00089727
	LOSS [training: 0.0827913602919906 | validation: 0.06268738764298291]
	TIME [epoch: 8.53 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07873520418348887		[learning rate: 0.00089515]
	Learning Rate: 0.000895153
	LOSS [training: 0.07873520418348887 | validation: 0.23819702120631628]
	TIME [epoch: 8.51 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10113858123521721		[learning rate: 0.00089304]
	Learning Rate: 0.000893042
	LOSS [training: 0.10113858123521721 | validation: 0.0408063397911267]
	TIME [epoch: 8.51 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739098739350074		[learning rate: 0.00089094]
	Learning Rate: 0.000890935
	LOSS [training: 0.08739098739350074 | validation: 0.11818620238804256]
	TIME [epoch: 8.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.114159007506013		[learning rate: 0.00088883]
	Learning Rate: 0.000888834
	LOSS [training: 0.114159007506013 | validation: 0.19636761016169357]
	TIME [epoch: 8.53 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11549810893272523		[learning rate: 0.00088674]
	Learning Rate: 0.000886737
	LOSS [training: 0.11549810893272523 | validation: 0.04516284464680757]
	TIME [epoch: 8.52 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07483815402783277		[learning rate: 0.00088465]
	Learning Rate: 0.000884645
	LOSS [training: 0.07483815402783277 | validation: 0.055589822731100955]
	TIME [epoch: 8.52 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07871805991470303		[learning rate: 0.00088256]
	Learning Rate: 0.000882559
	LOSS [training: 0.07871805991470303 | validation: 0.059683299863336384]
	TIME [epoch: 8.52 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06652941544536353		[learning rate: 0.00088048]
	Learning Rate: 0.000880477
	LOSS [training: 0.06652941544536353 | validation: 0.11819119353177976]
	TIME [epoch: 8.55 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07252042228096056		[learning rate: 0.0008784]
	Learning Rate: 0.0008784
	LOSS [training: 0.07252042228096056 | validation: 0.04798681072752749]
	TIME [epoch: 8.52 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06144669729360393		[learning rate: 0.00087633]
	Learning Rate: 0.000876328
	LOSS [training: 0.06144669729360393 | validation: 0.04169188737368668]
	TIME [epoch: 8.51 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158078179300365		[learning rate: 0.00087426]
	Learning Rate: 0.000874261
	LOSS [training: 0.08158078179300365 | validation: 0.030095668903866533]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06163014414956795		[learning rate: 0.0008722]
	Learning Rate: 0.000872199
	LOSS [training: 0.06163014414956795 | validation: 0.039045290904448055]
	TIME [epoch: 8.55 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08468227814635124		[learning rate: 0.00087014]
	Learning Rate: 0.000870141
	LOSS [training: 0.08468227814635124 | validation: 0.062197204457301064]
	TIME [epoch: 8.51 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08202366854767652		[learning rate: 0.00086809]
	Learning Rate: 0.000868089
	LOSS [training: 0.08202366854767652 | validation: 0.060589218696415564]
	TIME [epoch: 8.51 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0762685224892949		[learning rate: 0.00086604]
	Learning Rate: 0.000866041
	LOSS [training: 0.0762685224892949 | validation: 0.08919369284085832]
	TIME [epoch: 8.52 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09401687293155295		[learning rate: 0.000864]
	Learning Rate: 0.000863998
	LOSS [training: 0.09401687293155295 | validation: 0.06547384597039405]
	TIME [epoch: 8.53 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07481530451222228		[learning rate: 0.00086196]
	Learning Rate: 0.00086196
	LOSS [training: 0.07481530451222228 | validation: 0.1466429618245102]
	TIME [epoch: 8.51 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07041100406541646		[learning rate: 0.00085993]
	Learning Rate: 0.000859927
	LOSS [training: 0.07041100406541646 | validation: 0.026202012171903162]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1089.pth
	Model improved!!!
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0533960560795804		[learning rate: 0.0008579]
	Learning Rate: 0.000857898
	LOSS [training: 0.0533960560795804 | validation: 0.08427956159998812]
	TIME [epoch: 8.53 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08825350721754653		[learning rate: 0.00085587]
	Learning Rate: 0.000855875
	LOSS [training: 0.08825350721754653 | validation: 0.03592797409215539]
	TIME [epoch: 8.54 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06451372955621493		[learning rate: 0.00085386]
	Learning Rate: 0.000853856
	LOSS [training: 0.06451372955621493 | validation: 0.044174249122856696]
	TIME [epoch: 8.52 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07434028403232874		[learning rate: 0.00085184]
	Learning Rate: 0.000851842
	LOSS [training: 0.07434028403232874 | validation: 0.05033232110658696]
	TIME [epoch: 8.52 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08861893811886017		[learning rate: 0.00084983]
	Learning Rate: 0.000849832
	LOSS [training: 0.08861893811886017 | validation: 0.10719899114351356]
	TIME [epoch: 8.54 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07356541414525665		[learning rate: 0.00084783]
	Learning Rate: 0.000847828
	LOSS [training: 0.07356541414525665 | validation: 0.04764414993224965]
	TIME [epoch: 8.53 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08176137984029594		[learning rate: 0.00084583]
	Learning Rate: 0.000845828
	LOSS [training: 0.08176137984029594 | validation: 0.03771543859038613]
	TIME [epoch: 8.52 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07056591865098905		[learning rate: 0.00084383]
	Learning Rate: 0.000843833
	LOSS [training: 0.07056591865098905 | validation: 0.06591907983067438]
	TIME [epoch: 8.53 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07192290765853232		[learning rate: 0.00084184]
	Learning Rate: 0.000841842
	LOSS [training: 0.07192290765853232 | validation: 0.13980541844533803]
	TIME [epoch: 8.55 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08184074102189656		[learning rate: 0.00083986]
	Learning Rate: 0.000839856
	LOSS [training: 0.08184074102189656 | validation: 0.04556318974057273]
	TIME [epoch: 8.53 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0704110474138161		[learning rate: 0.00083788]
	Learning Rate: 0.000837876
	LOSS [training: 0.0704110474138161 | validation: 0.09454718106521429]
	TIME [epoch: 8.53 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221675356489195		[learning rate: 0.0008359]
	Learning Rate: 0.000835899
	LOSS [training: 0.07221675356489195 | validation: 0.04845102283951758]
	TIME [epoch: 8.52 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08099648161306436		[learning rate: 0.00083393]
	Learning Rate: 0.000833927
	LOSS [training: 0.08099648161306436 | validation: 0.06711810619982625]
	TIME [epoch: 8.55 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07093464863946083		[learning rate: 0.00083196]
	Learning Rate: 0.00083196
	LOSS [training: 0.07093464863946083 | validation: 0.04290422070055046]
	TIME [epoch: 8.52 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.083786397184599		[learning rate: 0.00083]
	Learning Rate: 0.000829998
	LOSS [training: 0.083786397184599 | validation: 0.0415170189691702]
	TIME [epoch: 8.52 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08124356299639884		[learning rate: 0.00082804]
	Learning Rate: 0.00082804
	LOSS [training: 0.08124356299639884 | validation: 0.041600629111820525]
	TIME [epoch: 8.53 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10357353138086471		[learning rate: 0.00082609]
	Learning Rate: 0.000826087
	LOSS [training: 0.10357353138086471 | validation: 0.06516044592252486]
	TIME [epoch: 8.55 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07833368250133407		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.07833368250133407 | validation: 0.06842468857769571]
	TIME [epoch: 8.53 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06962484013724168		[learning rate: 0.00082219]
	Learning Rate: 0.000822194
	LOSS [training: 0.06962484013724168 | validation: 0.03687610330433765]
	TIME [epoch: 8.53 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08661980862736976		[learning rate: 0.00082025]
	Learning Rate: 0.000820254
	LOSS [training: 0.08661980862736976 | validation: 0.060973730858605274]
	TIME [epoch: 8.51 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07345871746661262		[learning rate: 0.00081832]
	Learning Rate: 0.00081832
	LOSS [training: 0.07345871746661262 | validation: 0.093956516296577]
	TIME [epoch: 8.55 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07831479167164515		[learning rate: 0.00081639]
	Learning Rate: 0.000816389
	LOSS [training: 0.07831479167164515 | validation: 0.023191029700940915]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1111.pth
	Model improved!!!
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060476491136418786		[learning rate: 0.00081446]
	Learning Rate: 0.000814464
	LOSS [training: 0.060476491136418786 | validation: 0.04844705144317192]
	TIME [epoch: 8.52 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07708474246824253		[learning rate: 0.00081254]
	Learning Rate: 0.000812543
	LOSS [training: 0.07708474246824253 | validation: 0.04090566003988977]
	TIME [epoch: 8.52 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05788967340925545		[learning rate: 0.00081063]
	Learning Rate: 0.000810626
	LOSS [training: 0.05788967340925545 | validation: 0.04844373315834795]
	TIME [epoch: 8.53 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08006423573617835		[learning rate: 0.00080871]
	Learning Rate: 0.000808714
	LOSS [training: 0.08006423573617835 | validation: 0.06483247500451113]
	TIME [epoch: 8.51 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07722942030044454		[learning rate: 0.00080681]
	Learning Rate: 0.000806806
	LOSS [training: 0.07722942030044454 | validation: 0.04299442097949925]
	TIME [epoch: 8.51 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059525376386499906		[learning rate: 0.0008049]
	Learning Rate: 0.000804903
	LOSS [training: 0.059525376386499906 | validation: 0.10190975799548332]
	TIME [epoch: 8.51 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07195735046184248		[learning rate: 0.000803]
	Learning Rate: 0.000803004
	LOSS [training: 0.07195735046184248 | validation: 0.17451440688805134]
	TIME [epoch: 8.53 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11796533342637863		[learning rate: 0.00080111]
	Learning Rate: 0.00080111
	LOSS [training: 0.11796533342637863 | validation: 0.03640244286281765]
	TIME [epoch: 8.51 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06337611463849127		[learning rate: 0.00079922]
	Learning Rate: 0.000799221
	LOSS [training: 0.06337611463849127 | validation: 0.059855639462818806]
	TIME [epoch: 8.51 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10296174921626053		[learning rate: 0.00079734]
	Learning Rate: 0.000797335
	LOSS [training: 0.10296174921626053 | validation: 0.03800031507497957]
	TIME [epoch: 8.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06074347600754171		[learning rate: 0.00079545]
	Learning Rate: 0.000795454
	LOSS [training: 0.06074347600754171 | validation: 0.061240574304056675]
	TIME [epoch: 8.52 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08409488561072632		[learning rate: 0.00079358]
	Learning Rate: 0.000793578
	LOSS [training: 0.08409488561072632 | validation: 0.13594331930673242]
	TIME [epoch: 8.51 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09082582681566538		[learning rate: 0.00079171]
	Learning Rate: 0.000791706
	LOSS [training: 0.09082582681566538 | validation: 0.10437162640706321]
	TIME [epoch: 8.51 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07627911785065826		[learning rate: 0.00078984]
	Learning Rate: 0.000789839
	LOSS [training: 0.07627911785065826 | validation: 0.03948927581083676]
	TIME [epoch: 8.53 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06786447590788347		[learning rate: 0.00078798]
	Learning Rate: 0.000787976
	LOSS [training: 0.06786447590788347 | validation: 0.03571319915470392]
	TIME [epoch: 8.52 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06035549975080109		[learning rate: 0.00078612]
	Learning Rate: 0.000786117
	LOSS [training: 0.06035549975080109 | validation: 0.04928733590206933]
	TIME [epoch: 8.52 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10206615787003892		[learning rate: 0.00078426]
	Learning Rate: 0.000784263
	LOSS [training: 0.10206615787003892 | validation: 0.05019173780574336]
	TIME [epoch: 8.52 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0813399334962829		[learning rate: 0.00078241]
	Learning Rate: 0.000782413
	LOSS [training: 0.0813399334962829 | validation: 0.04615092015739154]
	TIME [epoch: 8.54 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06839441465085225		[learning rate: 0.00078057]
	Learning Rate: 0.000780567
	LOSS [training: 0.06839441465085225 | validation: 0.04370734653395146]
	TIME [epoch: 8.52 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10122569109927593		[learning rate: 0.00077873]
	Learning Rate: 0.000778726
	LOSS [training: 0.10122569109927593 | validation: 0.06109288406213542]
	TIME [epoch: 8.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678692098996018		[learning rate: 0.00077689]
	Learning Rate: 0.000776889
	LOSS [training: 0.07678692098996018 | validation: 0.06780429117047324]
	TIME [epoch: 8.51 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06789126436282587		[learning rate: 0.00077506]
	Learning Rate: 0.000775056
	LOSS [training: 0.06789126436282587 | validation: 0.05977735040375873]
	TIME [epoch: 8.54 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07277988064452955		[learning rate: 0.00077323]
	Learning Rate: 0.000773228
	LOSS [training: 0.07277988064452955 | validation: 0.06867729601482872]
	TIME [epoch: 8.52 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07026242902064414		[learning rate: 0.0007714]
	Learning Rate: 0.000771404
	LOSS [training: 0.07026242902064414 | validation: 0.041223408379969725]
	TIME [epoch: 8.52 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07675325641015632		[learning rate: 0.00076958]
	Learning Rate: 0.000769585
	LOSS [training: 0.07675325641015632 | validation: 0.028216797853216236]
	TIME [epoch: 8.52 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676642738116721		[learning rate: 0.00076777]
	Learning Rate: 0.000767769
	LOSS [training: 0.0676642738116721 | validation: 0.15433493595737444]
	TIME [epoch: 8.54 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07778134686162609		[learning rate: 0.00076596]
	Learning Rate: 0.000765958
	LOSS [training: 0.07778134686162609 | validation: 0.05488018633281816]
	TIME [epoch: 8.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06247559174744505		[learning rate: 0.00076415]
	Learning Rate: 0.000764151
	LOSS [training: 0.06247559174744505 | validation: 0.04691383740461892]
	TIME [epoch: 8.51 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05018209844568232		[learning rate: 0.00076235]
	Learning Rate: 0.000762349
	LOSS [training: 0.05018209844568232 | validation: 0.07907725544576036]
	TIME [epoch: 8.52 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1032469972525587		[learning rate: 0.00076055]
	Learning Rate: 0.000760551
	LOSS [training: 0.1032469972525587 | validation: 0.11653379761229693]
	TIME [epoch: 8.54 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.114023274010481		[learning rate: 0.00075876]
	Learning Rate: 0.000758757
	LOSS [training: 0.114023274010481 | validation: 0.07825744854701146]
	TIME [epoch: 8.52 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07736601216941816		[learning rate: 0.00075697]
	Learning Rate: 0.000756967
	LOSS [training: 0.07736601216941816 | validation: 0.06736087958892159]
	TIME [epoch: 8.52 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07338571182147635		[learning rate: 0.00075518]
	Learning Rate: 0.000755181
	LOSS [training: 0.07338571182147635 | validation: 0.03231134867309667]
	TIME [epoch: 8.52 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06966120633598882		[learning rate: 0.0007534]
	Learning Rate: 0.0007534
	LOSS [training: 0.06966120633598882 | validation: 0.05580875370469769]
	TIME [epoch: 8.54 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06950604779922051		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.06950604779922051 | validation: 0.032913127573126116]
	TIME [epoch: 8.52 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07047288372880804		[learning rate: 0.00074985]
	Learning Rate: 0.00074985
	LOSS [training: 0.07047288372880804 | validation: 0.05255773769837255]
	TIME [epoch: 8.52 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07526998867829092		[learning rate: 0.00074808]
	Learning Rate: 0.000748081
	LOSS [training: 0.07526998867829092 | validation: 0.0855158055246036]
	TIME [epoch: 8.53 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08438007340448146		[learning rate: 0.00074632]
	Learning Rate: 0.000746316
	LOSS [training: 0.08438007340448146 | validation: 0.09919148100550038]
	TIME [epoch: 8.53 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06211317880437032		[learning rate: 0.00074456]
	Learning Rate: 0.000744556
	LOSS [training: 0.06211317880437032 | validation: 0.07972036421808823]
	TIME [epoch: 8.52 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08297730856051475		[learning rate: 0.0007428]
	Learning Rate: 0.0007428
	LOSS [training: 0.08297730856051475 | validation: 0.056617848032826865]
	TIME [epoch: 8.52 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1085732701950479		[learning rate: 0.00074105]
	Learning Rate: 0.000741048
	LOSS [training: 0.1085732701950479 | validation: 0.15551044625222116]
	TIME [epoch: 8.53 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08212785838847528		[learning rate: 0.0007393]
	Learning Rate: 0.0007393
	LOSS [training: 0.08212785838847528 | validation: 0.08961600465816297]
	TIME [epoch: 8.53 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08985704629321864		[learning rate: 0.00073756]
	Learning Rate: 0.000737556
	LOSS [training: 0.08985704629321864 | validation: 0.02853238749315358]
	TIME [epoch: 8.52 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06805818057904828		[learning rate: 0.00073582]
	Learning Rate: 0.000735816
	LOSS [training: 0.06805818057904828 | validation: 0.09676968111173687]
	TIME [epoch: 8.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11430086587547592		[learning rate: 0.00073408]
	Learning Rate: 0.00073408
	LOSS [training: 0.11430086587547592 | validation: 0.09331643679748827]
	TIME [epoch: 8.53 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07587078706665999		[learning rate: 0.00073235]
	Learning Rate: 0.000732349
	LOSS [training: 0.07587078706665999 | validation: 0.06205597262980173]
	TIME [epoch: 8.53 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08430262305018256		[learning rate: 0.00073062]
	Learning Rate: 0.000730621
	LOSS [training: 0.08430262305018256 | validation: 0.03644854303349951]
	TIME [epoch: 8.52 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0590573444643767		[learning rate: 0.0007289]
	Learning Rate: 0.000728898
	LOSS [training: 0.0590573444643767 | validation: 0.060378219176402584]
	TIME [epoch: 8.52 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09251628259419989		[learning rate: 0.00072718]
	Learning Rate: 0.000727178
	LOSS [training: 0.09251628259419989 | validation: 0.07484980914782885]
	TIME [epoch: 8.54 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07446404482381894		[learning rate: 0.00072546]
	Learning Rate: 0.000725463
	LOSS [training: 0.07446404482381894 | validation: 0.04802248037885182]
	TIME [epoch: 8.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06545324883464554		[learning rate: 0.00072375]
	Learning Rate: 0.000723752
	LOSS [training: 0.06545324883464554 | validation: 0.06537386914278728]
	TIME [epoch: 8.51 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08300982126302073		[learning rate: 0.00072204]
	Learning Rate: 0.000722045
	LOSS [training: 0.08300982126302073 | validation: 0.03809405491816052]
	TIME [epoch: 8.51 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06818318787385863		[learning rate: 0.00072034]
	Learning Rate: 0.000720342
	LOSS [training: 0.06818318787385863 | validation: 0.04871201116218976]
	TIME [epoch: 8.54 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0647463280203683		[learning rate: 0.00071864]
	Learning Rate: 0.000718642
	LOSS [training: 0.0647463280203683 | validation: 0.03866393499534895]
	TIME [epoch: 8.52 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06536296211882531		[learning rate: 0.00071695]
	Learning Rate: 0.000716947
	LOSS [training: 0.06536296211882531 | validation: 0.05652973612442705]
	TIME [epoch: 8.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10631288947492037		[learning rate: 0.00071526]
	Learning Rate: 0.000715256
	LOSS [training: 0.10631288947492037 | validation: 0.039442065013425974]
	TIME [epoch: 8.52 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0692959486340227		[learning rate: 0.00071357]
	Learning Rate: 0.000713569
	LOSS [training: 0.0692959486340227 | validation: 0.09176463855450007]
	TIME [epoch: 8.54 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06669332807419931		[learning rate: 0.00071189]
	Learning Rate: 0.000711886
	LOSS [training: 0.06669332807419931 | validation: 0.028064661433074505]
	TIME [epoch: 8.52 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06196971519782681		[learning rate: 0.00071021]
	Learning Rate: 0.000710206
	LOSS [training: 0.06196971519782681 | validation: 0.13274447150777047]
	TIME [epoch: 8.52 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07153062416232198		[learning rate: 0.00070853]
	Learning Rate: 0.000708531
	LOSS [training: 0.07153062416232198 | validation: 0.0372810687147462]
	TIME [epoch: 8.52 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08660330070273244		[learning rate: 0.00070686]
	Learning Rate: 0.00070686
	LOSS [training: 0.08660330070273244 | validation: 0.034989448526826394]
	TIME [epoch: 8.54 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05579316271027659		[learning rate: 0.00070519]
	Learning Rate: 0.000705193
	LOSS [training: 0.05579316271027659 | validation: 0.05234474668101716]
	TIME [epoch: 8.52 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.086113820982073		[learning rate: 0.00070353]
	Learning Rate: 0.000703529
	LOSS [training: 0.086113820982073 | validation: 0.10655744350501109]
	TIME [epoch: 8.51 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.084463224347047		[learning rate: 0.00070187]
	Learning Rate: 0.000701869
	LOSS [training: 0.084463224347047 | validation: 0.06726887650622251]
	TIME [epoch: 8.52 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0931673818023238		[learning rate: 0.00070021]
	Learning Rate: 0.000700214
	LOSS [training: 0.0931673818023238 | validation: 0.046361903672739214]
	TIME [epoch: 8.53 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06395356386576272		[learning rate: 0.00069856]
	Learning Rate: 0.000698562
	LOSS [training: 0.06395356386576272 | validation: 0.06975274705336262]
	TIME [epoch: 8.51 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08072930321356109		[learning rate: 0.00069691]
	Learning Rate: 0.000696914
	LOSS [training: 0.08072930321356109 | validation: 0.059981236899803184]
	TIME [epoch: 8.52 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07445169097496424		[learning rate: 0.00069527]
	Learning Rate: 0.00069527
	LOSS [training: 0.07445169097496424 | validation: 0.0920591315269422]
	TIME [epoch: 8.52 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06660126832092472		[learning rate: 0.00069363]
	Learning Rate: 0.000693631
	LOSS [training: 0.06660126832092472 | validation: 0.04695924038267124]
	TIME [epoch: 8.54 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058168252223791		[learning rate: 0.00069199]
	Learning Rate: 0.000691994
	LOSS [training: 0.058168252223791 | validation: 0.06374469650537845]
	TIME [epoch: 8.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05146313754953038		[learning rate: 0.00069036]
	Learning Rate: 0.000690362
	LOSS [training: 0.05146313754953038 | validation: 0.03644809628237418]
	TIME [epoch: 8.52 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06631966034105329		[learning rate: 0.00068873]
	Learning Rate: 0.000688734
	LOSS [training: 0.06631966034105329 | validation: 0.04534060405340505]
	TIME [epoch: 8.53 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04914190102315775		[learning rate: 0.00068711]
	Learning Rate: 0.000687109
	LOSS [training: 0.04914190102315775 | validation: 0.03433895330810034]
	TIME [epoch: 8.54 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05684640896642314		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.05684640896642314 | validation: 0.05206477034252356]
	TIME [epoch: 8.51 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0805314291138247		[learning rate: 0.00068387]
	Learning Rate: 0.000683871
	LOSS [training: 0.0805314291138247 | validation: 0.03640311030827684]
	TIME [epoch: 8.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06049838134546888		[learning rate: 0.00068226]
	Learning Rate: 0.000682258
	LOSS [training: 0.06049838134546888 | validation: 0.03383029968679553]
	TIME [epoch: 8.53 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060748663751981014		[learning rate: 0.00068065]
	Learning Rate: 0.000680649
	LOSS [training: 0.060748663751981014 | validation: 0.03674331042487546]
	TIME [epoch: 8.53 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07208152973710166		[learning rate: 0.00067904]
	Learning Rate: 0.000679043
	LOSS [training: 0.07208152973710166 | validation: 0.042361121291986305]
	TIME [epoch: 8.52 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06996535169836535		[learning rate: 0.00067744]
	Learning Rate: 0.000677442
	LOSS [training: 0.06996535169836535 | validation: 0.10896256234561746]
	TIME [epoch: 8.52 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07239622900087067		[learning rate: 0.00067584]
	Learning Rate: 0.000675844
	LOSS [training: 0.07239622900087067 | validation: 0.05331715932479936]
	TIME [epoch: 8.54 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0507268722041714		[learning rate: 0.00067425]
	Learning Rate: 0.000674249
	LOSS [training: 0.0507268722041714 | validation: 0.03730093933857329]
	TIME [epoch: 8.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05738350749705355		[learning rate: 0.00067266]
	Learning Rate: 0.000672659
	LOSS [training: 0.05738350749705355 | validation: 0.04175729028383838]
	TIME [epoch: 8.51 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10592893585407744		[learning rate: 0.00067107]
	Learning Rate: 0.000671072
	LOSS [training: 0.10592893585407744 | validation: 0.03769576342725134]
	TIME [epoch: 8.52 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06593031445299995		[learning rate: 0.00066949]
	Learning Rate: 0.000669489
	LOSS [training: 0.06593031445299995 | validation: 0.03967432672486197]
	TIME [epoch: 8.53 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06425648556667751		[learning rate: 0.00066791]
	Learning Rate: 0.00066791
	LOSS [training: 0.06425648556667751 | validation: 0.03147456604369309]
	TIME [epoch: 8.53 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659811463635392		[learning rate: 0.00066633]
	Learning Rate: 0.000666335
	LOSS [training: 0.0659811463635392 | validation: 0.06073064231940799]
	TIME [epoch: 8.52 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0652220414478617		[learning rate: 0.00066476]
	Learning Rate: 0.000664763
	LOSS [training: 0.0652220414478617 | validation: 0.02567748585012962]
	TIME [epoch: 8.52 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04939198241310063		[learning rate: 0.00066319]
	Learning Rate: 0.000663195
	LOSS [training: 0.04939198241310063 | validation: 0.04519667208975671]
	TIME [epoch: 8.53 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059720093860652204		[learning rate: 0.00066163]
	Learning Rate: 0.00066163
	LOSS [training: 0.059720093860652204 | validation: 0.08733609694638998]
	TIME [epoch: 8.51 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09583977512852472		[learning rate: 0.00066007]
	Learning Rate: 0.00066007
	LOSS [training: 0.09583977512852472 | validation: 0.03704590132922456]
	TIME [epoch: 8.51 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716272008364878		[learning rate: 0.00065851]
	Learning Rate: 0.000658513
	LOSS [training: 0.0716272008364878 | validation: 0.056150707121617516]
	TIME [epoch: 8.52 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06780955553289138		[learning rate: 0.00065696]
	Learning Rate: 0.000656959
	LOSS [training: 0.06780955553289138 | validation: 0.03358777436011444]
	TIME [epoch: 8.53 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0752137834925427		[learning rate: 0.00065541]
	Learning Rate: 0.00065541
	LOSS [training: 0.0752137834925427 | validation: 0.05454478026503159]
	TIME [epoch: 8.52 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06411420462796001		[learning rate: 0.00065386]
	Learning Rate: 0.000653864
	LOSS [training: 0.06411420462796001 | validation: 0.06288527441807705]
	TIME [epoch: 8.52 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07916296509599229		[learning rate: 0.00065232]
	Learning Rate: 0.000652321
	LOSS [training: 0.07916296509599229 | validation: 0.038214262709679994]
	TIME [epoch: 8.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05950393521419965		[learning rate: 0.00065078]
	Learning Rate: 0.000650783
	LOSS [training: 0.05950393521419965 | validation: 0.02784706683010554]
	TIME [epoch: 8.54 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06327813160660316		[learning rate: 0.00064925]
	Learning Rate: 0.000649247
	LOSS [training: 0.06327813160660316 | validation: 0.02834901556570034]
	TIME [epoch: 8.51 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06303657947976028		[learning rate: 0.00064772]
	Learning Rate: 0.000647716
	LOSS [training: 0.06303657947976028 | validation: 0.0753966768209195]
	TIME [epoch: 8.52 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05486187784903936		[learning rate: 0.00064619]
	Learning Rate: 0.000646188
	LOSS [training: 0.05486187784903936 | validation: 0.036151785746504364]
	TIME [epoch: 8.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07260029799302		[learning rate: 0.00064466]
	Learning Rate: 0.000644664
	LOSS [training: 0.07260029799302 | validation: 0.0525178799868157]
	TIME [epoch: 8.54 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405352290487846		[learning rate: 0.00064314]
	Learning Rate: 0.000643143
	LOSS [training: 0.07405352290487846 | validation: 0.06260012201073491]
	TIME [epoch: 8.52 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04947409447008212		[learning rate: 0.00064163]
	Learning Rate: 0.000641626
	LOSS [training: 0.04947409447008212 | validation: 0.035100720600944414]
	TIME [epoch: 8.52 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0674432941835997		[learning rate: 0.00064011]
	Learning Rate: 0.000640113
	LOSS [training: 0.0674432941835997 | validation: 0.08018630138134537]
	TIME [epoch: 8.51 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07350086771663329		[learning rate: 0.0006386]
	Learning Rate: 0.000638603
	LOSS [training: 0.07350086771663329 | validation: 0.11342307597057984]
	TIME [epoch: 8.55 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06988646850224763		[learning rate: 0.0006371]
	Learning Rate: 0.000637096
	LOSS [training: 0.06988646850224763 | validation: 0.05851602480695606]
	TIME [epoch: 8.52 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936329474941344		[learning rate: 0.00063559]
	Learning Rate: 0.000635594
	LOSS [training: 0.06936329474941344 | validation: 0.08822120014180075]
	TIME [epoch: 8.52 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06769014224109668		[learning rate: 0.00063409]
	Learning Rate: 0.000634094
	LOSS [training: 0.06769014224109668 | validation: 0.044404917530512414]
	TIME [epoch: 8.52 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06052407852759869		[learning rate: 0.0006326]
	Learning Rate: 0.000632598
	LOSS [training: 0.06052407852759869 | validation: 0.026310706684730026]
	TIME [epoch: 8.53 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05676146010772533		[learning rate: 0.00063111]
	Learning Rate: 0.000631106
	LOSS [training: 0.05676146010772533 | validation: 0.059378308731735746]
	TIME [epoch: 8.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12224739358290951		[learning rate: 0.00062962]
	Learning Rate: 0.000629618
	LOSS [training: 0.12224739358290951 | validation: 0.03545980541572317]
	TIME [epoch: 8.51 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0683367289965474		[learning rate: 0.00062813]
	Learning Rate: 0.000628132
	LOSS [training: 0.0683367289965474 | validation: 0.036177399021527695]
	TIME [epoch: 8.53 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06637427274637778		[learning rate: 0.00062665]
	Learning Rate: 0.000626651
	LOSS [training: 0.06637427274637778 | validation: 0.06371307520690282]
	TIME [epoch: 8.53 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07641859312378767		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.07641859312378767 | validation: 0.06520302780802653]
	TIME [epoch: 8.52 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06390178778298894		[learning rate: 0.0006237]
	Learning Rate: 0.000623698
	LOSS [training: 0.06390178778298894 | validation: 0.08180134295854037]
	TIME [epoch: 8.51 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632700045945335		[learning rate: 0.00062223]
	Learning Rate: 0.000622227
	LOSS [training: 0.06632700045945335 | validation: 0.04728771216984648]
	TIME [epoch: 8.53 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08107302681875868		[learning rate: 0.00062076]
	Learning Rate: 0.000620759
	LOSS [training: 0.08107302681875868 | validation: 0.027696305373190122]
	TIME [epoch: 8.52 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053313626559361706		[learning rate: 0.00061929]
	Learning Rate: 0.000619295
	LOSS [training: 0.053313626559361706 | validation: 0.0815036096504607]
	TIME [epoch: 8.52 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05735347385649252		[learning rate: 0.00061783]
	Learning Rate: 0.000617834
	LOSS [training: 0.05735347385649252 | validation: 0.04844325701035164]
	TIME [epoch: 8.51 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06225619307644894		[learning rate: 0.00061638]
	Learning Rate: 0.000616377
	LOSS [training: 0.06225619307644894 | validation: 0.03897561881581513]
	TIME [epoch: 8.53 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05973047845708771		[learning rate: 0.00061492]
	Learning Rate: 0.000614923
	LOSS [training: 0.05973047845708771 | validation: 0.043867641540816765]
	TIME [epoch: 8.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06168840965075721		[learning rate: 0.00061347]
	Learning Rate: 0.000613472
	LOSS [training: 0.06168840965075721 | validation: 0.05507499497886789]
	TIME [epoch: 8.52 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07250459681925438		[learning rate: 0.00061203]
	Learning Rate: 0.000612025
	LOSS [training: 0.07250459681925438 | validation: 0.0547199033107984]
	TIME [epoch: 8.52 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07090788473339057		[learning rate: 0.00061058]
	Learning Rate: 0.000610581
	LOSS [training: 0.07090788473339057 | validation: 0.04933946601904715]
	TIME [epoch: 8.54 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07286602833928493		[learning rate: 0.00060914]
	Learning Rate: 0.000609141
	LOSS [training: 0.07286602833928493 | validation: 0.06477377689141442]
	TIME [epoch: 8.52 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06896186470983105		[learning rate: 0.0006077]
	Learning Rate: 0.000607704
	LOSS [training: 0.06896186470983105 | validation: 0.058631844243964094]
	TIME [epoch: 8.51 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018301415009229		[learning rate: 0.00060627]
	Learning Rate: 0.000606271
	LOSS [training: 0.07018301415009229 | validation: 0.08610787050211022]
	TIME [epoch: 8.52 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06982186088745057		[learning rate: 0.00060484]
	Learning Rate: 0.000604841
	LOSS [training: 0.06982186088745057 | validation: 0.08689737213990117]
	TIME [epoch: 8.53 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06520363029309315		[learning rate: 0.00060341]
	Learning Rate: 0.000603414
	LOSS [training: 0.06520363029309315 | validation: 0.06317600151794105]
	TIME [epoch: 8.52 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0652824126172111		[learning rate: 0.00060199]
	Learning Rate: 0.000601991
	LOSS [training: 0.0652824126172111 | validation: 0.056843908874681735]
	TIME [epoch: 8.52 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06502609789279701		[learning rate: 0.00060057]
	Learning Rate: 0.000600571
	LOSS [training: 0.06502609789279701 | validation: 0.06516224930003404]
	TIME [epoch: 8.51 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06415117949008425		[learning rate: 0.00059915]
	Learning Rate: 0.000599154
	LOSS [training: 0.06415117949008425 | validation: 0.0755784086240999]
	TIME [epoch: 8.53 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06251210946305222		[learning rate: 0.00059774]
	Learning Rate: 0.000597741
	LOSS [training: 0.06251210946305222 | validation: 0.03550064996169212]
	TIME [epoch: 8.52 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053000591900339566		[learning rate: 0.00059633]
	Learning Rate: 0.000596331
	LOSS [training: 0.053000591900339566 | validation: 0.021740521082398184]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1244.pth
	Model improved!!!
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06065243356570885		[learning rate: 0.00059492]
	Learning Rate: 0.000594924
	LOSS [training: 0.06065243356570885 | validation: 0.040857965213032324]
	TIME [epoch: 8.52 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0726042067560188		[learning rate: 0.00059352]
	Learning Rate: 0.000593521
	LOSS [training: 0.0726042067560188 | validation: 0.0906333793797977]
	TIME [epoch: 8.54 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05380219156980216		[learning rate: 0.00059212]
	Learning Rate: 0.000592121
	LOSS [training: 0.05380219156980216 | validation: 0.02460161970965883]
	TIME [epoch: 8.53 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0468597610463698		[learning rate: 0.00059072]
	Learning Rate: 0.000590724
	LOSS [training: 0.0468597610463698 | validation: 0.02673941528912302]
	TIME [epoch: 8.52 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05929859077048234		[learning rate: 0.00058933]
	Learning Rate: 0.000589331
	LOSS [training: 0.05929859077048234 | validation: 0.06379254606729916]
	TIME [epoch: 8.52 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052488219219209306		[learning rate: 0.00058794]
	Learning Rate: 0.00058794
	LOSS [training: 0.052488219219209306 | validation: 0.028092039935702858]
	TIME [epoch: 8.55 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06414321591991176		[learning rate: 0.00058655]
	Learning Rate: 0.000586554
	LOSS [training: 0.06414321591991176 | validation: 0.08104471380048145]
	TIME [epoch: 8.52 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07322658981470302		[learning rate: 0.00058517]
	Learning Rate: 0.00058517
	LOSS [training: 0.07322658981470302 | validation: 0.04374671769204509]
	TIME [epoch: 8.52 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05157669571307714		[learning rate: 0.00058379]
	Learning Rate: 0.00058379
	LOSS [training: 0.05157669571307714 | validation: 0.019900551301659155]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1253.pth
	Model improved!!!
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05301852338355937		[learning rate: 0.00058241]
	Learning Rate: 0.000582413
	LOSS [training: 0.05301852338355937 | validation: 0.05765977452618624]
	TIME [epoch: 8.53 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061526160863822066		[learning rate: 0.00058104]
	Learning Rate: 0.000581039
	LOSS [training: 0.061526160863822066 | validation: 0.06130051363022941]
	TIME [epoch: 8.52 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061086031619480716		[learning rate: 0.00057967]
	Learning Rate: 0.000579668
	LOSS [training: 0.061086031619480716 | validation: 0.05377826856150652]
	TIME [epoch: 8.51 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06049593172257471		[learning rate: 0.0005783]
	Learning Rate: 0.000578301
	LOSS [training: 0.06049593172257471 | validation: 0.055456644161837404]
	TIME [epoch: 8.54 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05805363947152946		[learning rate: 0.00057694]
	Learning Rate: 0.000576937
	LOSS [training: 0.05805363947152946 | validation: 0.050478126543764594]
	TIME [epoch: 8.53 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06173947780636241		[learning rate: 0.00057558]
	Learning Rate: 0.000575576
	LOSS [training: 0.06173947780636241 | validation: 0.03245135124901431]
	TIME [epoch: 8.52 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06584521035231927		[learning rate: 0.00057422]
	Learning Rate: 0.000574218
	LOSS [training: 0.06584521035231927 | validation: 0.05401633093815801]
	TIME [epoch: 8.51 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05985899920918639		[learning rate: 0.00057286]
	Learning Rate: 0.000572864
	LOSS [training: 0.05985899920918639 | validation: 0.0502770277893873]
	TIME [epoch: 8.54 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05212854897454713		[learning rate: 0.00057151]
	Learning Rate: 0.000571512
	LOSS [training: 0.05212854897454713 | validation: 0.05051342925774341]
	TIME [epoch: 8.53 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06780215017458466		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.06780215017458466 | validation: 0.03490050855871923]
	TIME [epoch: 8.52 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04792147492433276		[learning rate: 0.00056882]
	Learning Rate: 0.000568819
	LOSS [training: 0.04792147492433276 | validation: 0.036173411069543124]
	TIME [epoch: 8.52 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053143174905507504		[learning rate: 0.00056748]
	Learning Rate: 0.000567478
	LOSS [training: 0.053143174905507504 | validation: 0.03479017601540435]
	TIME [epoch: 8.55 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05740229164764151		[learning rate: 0.00056614]
	Learning Rate: 0.000566139
	LOSS [training: 0.05740229164764151 | validation: 0.046550255286182105]
	TIME [epoch: 8.52 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06081707576608356		[learning rate: 0.0005648]
	Learning Rate: 0.000564804
	LOSS [training: 0.06081707576608356 | validation: 0.02341737663315416]
	TIME [epoch: 8.52 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05905046002332549		[learning rate: 0.00056347]
	Learning Rate: 0.000563471
	LOSS [training: 0.05905046002332549 | validation: 0.036512831900436]
	TIME [epoch: 8.52 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04875757287310852		[learning rate: 0.00056214]
	Learning Rate: 0.000562142
	LOSS [training: 0.04875757287310852 | validation: 0.04022156344872988]
	TIME [epoch: 8.55 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05246246960849328		[learning rate: 0.00056082]
	Learning Rate: 0.000560816
	LOSS [training: 0.05246246960849328 | validation: 0.05508132256944645]
	TIME [epoch: 8.52 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059987777972737945		[learning rate: 0.00055949]
	Learning Rate: 0.000559493
	LOSS [training: 0.059987777972737945 | validation: 0.04019944364740685]
	TIME [epoch: 8.52 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06413223486474283		[learning rate: 0.00055817]
	Learning Rate: 0.000558173
	LOSS [training: 0.06413223486474283 | validation: 0.045367732520963856]
	TIME [epoch: 8.53 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07465917576827266		[learning rate: 0.00055686]
	Learning Rate: 0.000556857
	LOSS [training: 0.07465917576827266 | validation: 0.07098977531652857]
	TIME [epoch: 8.55 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06828213412857505		[learning rate: 0.00055554]
	Learning Rate: 0.000555543
	LOSS [training: 0.06828213412857505 | validation: 0.05542164405841438]
	TIME [epoch: 8.53 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052423110074954524		[learning rate: 0.00055423]
	Learning Rate: 0.000554233
	LOSS [training: 0.052423110074954524 | validation: 0.034672216739349705]
	TIME [epoch: 8.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062478429956254175		[learning rate: 0.00055293]
	Learning Rate: 0.000552925
	LOSS [training: 0.062478429956254175 | validation: 0.09197056901605849]
	TIME [epoch: 8.52 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07414395277980121		[learning rate: 0.00055162]
	Learning Rate: 0.000551621
	LOSS [training: 0.07414395277980121 | validation: 0.04836410337572067]
	TIME [epoch: 8.55 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0585589900324068		[learning rate: 0.00055032]
	Learning Rate: 0.00055032
	LOSS [training: 0.0585589900324068 | validation: 0.04022107631314695]
	TIME [epoch: 8.52 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06810483325224825		[learning rate: 0.00054902]
	Learning Rate: 0.000549022
	LOSS [training: 0.06810483325224825 | validation: 0.038441026666648816]
	TIME [epoch: 8.53 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0751668365652573		[learning rate: 0.00054773]
	Learning Rate: 0.000547727
	LOSS [training: 0.0751668365652573 | validation: 0.038336667103040525]
	TIME [epoch: 8.53 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07806918365022017		[learning rate: 0.00054643]
	Learning Rate: 0.000546435
	LOSS [training: 0.07806918365022017 | validation: 0.08878893961812959]
	TIME [epoch: 8.54 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0762941138326652		[learning rate: 0.00054515]
	Learning Rate: 0.000545146
	LOSS [training: 0.0762941138326652 | validation: 0.058911096957927594]
	TIME [epoch: 8.52 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645630768578477		[learning rate: 0.00054386]
	Learning Rate: 0.00054386
	LOSS [training: 0.0645630768578477 | validation: 0.04308875290406436]
	TIME [epoch: 8.52 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06472731606207735		[learning rate: 0.00054258]
	Learning Rate: 0.000542577
	LOSS [training: 0.06472731606207735 | validation: 0.047007500372863574]
	TIME [epoch: 8.53 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06902535125075715		[learning rate: 0.0005413]
	Learning Rate: 0.000541297
	LOSS [training: 0.06902535125075715 | validation: 0.05464468851075817]
	TIME [epoch: 8.53 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07164081226424425		[learning rate: 0.00054002]
	Learning Rate: 0.00054002
	LOSS [training: 0.07164081226424425 | validation: 0.05766705083087477]
	TIME [epoch: 8.52 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0652921275365856		[learning rate: 0.00053875]
	Learning Rate: 0.000538747
	LOSS [training: 0.0652921275365856 | validation: 0.04076262125347874]
	TIME [epoch: 8.52 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09764762120315112		[learning rate: 0.00053748]
	Learning Rate: 0.000537476
	LOSS [training: 0.09764762120315112 | validation: 0.06049255197119009]
	TIME [epoch: 8.54 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06392359740114735		[learning rate: 0.00053621]
	Learning Rate: 0.000536208
	LOSS [training: 0.06392359740114735 | validation: 0.05897238023892051]
	TIME [epoch: 8.53 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08311713651264498		[learning rate: 0.00053494]
	Learning Rate: 0.000534943
	LOSS [training: 0.08311713651264498 | validation: 0.04272094974115543]
	TIME [epoch: 8.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054731085657909795		[learning rate: 0.00053368]
	Learning Rate: 0.000533681
	LOSS [training: 0.054731085657909795 | validation: 0.0337018849134126]
	TIME [epoch: 8.52 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05885762147361866		[learning rate: 0.00053242]
	Learning Rate: 0.000532422
	LOSS [training: 0.05885762147361866 | validation: 0.04034618804083126]
	TIME [epoch: 8.54 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06157677494768676		[learning rate: 0.00053117]
	Learning Rate: 0.000531167
	LOSS [training: 0.06157677494768676 | validation: 0.05688921345469143]
	TIME [epoch: 8.52 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08063225040815807		[learning rate: 0.00052991]
	Learning Rate: 0.000529914
	LOSS [training: 0.08063225040815807 | validation: 0.07557622245395001]
	TIME [epoch: 8.52 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05688421876375237		[learning rate: 0.00052866]
	Learning Rate: 0.000528664
	LOSS [training: 0.05688421876375237 | validation: 0.03829021650098021]
	TIME [epoch: 8.51 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043378856291464214		[learning rate: 0.00052742]
	Learning Rate: 0.000527417
	LOSS [training: 0.043378856291464214 | validation: 0.022397402108989904]
	TIME [epoch: 8.54 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06052540097911537		[learning rate: 0.00052617]
	Learning Rate: 0.000526173
	LOSS [training: 0.06052540097911537 | validation: 0.13424541058246914]
	TIME [epoch: 8.52 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07491929970135888		[learning rate: 0.00052493]
	Learning Rate: 0.000524931
	LOSS [training: 0.07491929970135888 | validation: 0.04527808998048655]
	TIME [epoch: 8.52 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05038375915875889		[learning rate: 0.00052369]
	Learning Rate: 0.000523693
	LOSS [training: 0.05038375915875889 | validation: 0.051487460955522556]
	TIME [epoch: 8.51 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04971533295038707		[learning rate: 0.00052246]
	Learning Rate: 0.000522458
	LOSS [training: 0.04971533295038707 | validation: 0.021537292623566767]
	TIME [epoch: 8.55 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05199593392955669		[learning rate: 0.00052123]
	Learning Rate: 0.000521225
	LOSS [training: 0.05199593392955669 | validation: 0.0290551109823233]
	TIME [epoch: 8.53 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053982012494587284		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.053982012494587284 | validation: 0.04266881224466865]
	TIME [epoch: 8.51 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059399919083557406		[learning rate: 0.00051877]
	Learning Rate: 0.000518769
	LOSS [training: 0.059399919083557406 | validation: 0.03003043983760717]
	TIME [epoch: 8.52 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05028550276039424		[learning rate: 0.00051755]
	Learning Rate: 0.000517546
	LOSS [training: 0.05028550276039424 | validation: 0.07889087546044342]
	TIME [epoch: 8.54 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05773891451581355		[learning rate: 0.00051632]
	Learning Rate: 0.000516325
	LOSS [training: 0.05773891451581355 | validation: 0.07782105205604323]
	TIME [epoch: 8.52 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058210436647092		[learning rate: 0.00051511]
	Learning Rate: 0.000515107
	LOSS [training: 0.058210436647092 | validation: 0.041066836809488486]
	TIME [epoch: 8.52 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632612798179761		[learning rate: 0.00051389]
	Learning Rate: 0.000513892
	LOSS [training: 0.06632612798179761 | validation: 0.03997461358570431]
	TIME [epoch: 8.53 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06979900888315961		[learning rate: 0.00051268]
	Learning Rate: 0.00051268
	LOSS [training: 0.06979900888315961 | validation: 0.07009685098372759]
	TIME [epoch: 8.54 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059304470340275875		[learning rate: 0.00051147]
	Learning Rate: 0.00051147
	LOSS [training: 0.059304470340275875 | validation: 0.0285976338424523]
	TIME [epoch: 8.53 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04938657933883621		[learning rate: 0.00051026]
	Learning Rate: 0.000510264
	LOSS [training: 0.04938657933883621 | validation: 0.03270321614579193]
	TIME [epoch: 8.52 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054968593988742064		[learning rate: 0.00050906]
	Learning Rate: 0.00050906
	LOSS [training: 0.054968593988742064 | validation: 0.04454979833223035]
	TIME [epoch: 8.53 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05069375216395459		[learning rate: 0.00050786]
	Learning Rate: 0.000507859
	LOSS [training: 0.05069375216395459 | validation: 0.03752563258373072]
	TIME [epoch: 8.54 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05551712421495616		[learning rate: 0.00050666]
	Learning Rate: 0.000506662
	LOSS [training: 0.05551712421495616 | validation: 0.10904146667391337]
	TIME [epoch: 8.52 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05668137246280351		[learning rate: 0.00050547]
	Learning Rate: 0.000505466
	LOSS [training: 0.05668137246280351 | validation: 0.043913063176006795]
	TIME [epoch: 8.52 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058916878989762334		[learning rate: 0.00050427]
	Learning Rate: 0.000504274
	LOSS [training: 0.058916878989762334 | validation: 0.03325752529717931]
	TIME [epoch: 8.53 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046891703396913474		[learning rate: 0.00050308]
	Learning Rate: 0.000503085
	LOSS [training: 0.046891703396913474 | validation: 0.040006551776279486]
	TIME [epoch: 8.53 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05808112454494633		[learning rate: 0.0005019]
	Learning Rate: 0.000501898
	LOSS [training: 0.05808112454494633 | validation: 0.036131324800893164]
	TIME [epoch: 8.52 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05032482558832654		[learning rate: 0.00050071]
	Learning Rate: 0.000500714
	LOSS [training: 0.05032482558832654 | validation: 0.03590680548808568]
	TIME [epoch: 8.52 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0605045272487781		[learning rate: 0.00049953]
	Learning Rate: 0.000499533
	LOSS [training: 0.0605045272487781 | validation: 0.04096233788671255]
	TIME [epoch: 8.54 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05809376309544564		[learning rate: 0.00049835]
	Learning Rate: 0.000498355
	LOSS [training: 0.05809376309544564 | validation: 0.0556489661547486]
	TIME [epoch: 8.53 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05390769708074204		[learning rate: 0.00049718]
	Learning Rate: 0.000497179
	LOSS [training: 0.05390769708074204 | validation: 0.033772643265095374]
	TIME [epoch: 8.52 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05821183476993347		[learning rate: 0.00049601]
	Learning Rate: 0.000496006
	LOSS [training: 0.05821183476993347 | validation: 0.046098053693437835]
	TIME [epoch: 8.52 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07258718316564704		[learning rate: 0.00049484]
	Learning Rate: 0.000494836
	LOSS [training: 0.07258718316564704 | validation: 0.03788467421108801]
	TIME [epoch: 8.54 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05568314386667082		[learning rate: 0.00049367]
	Learning Rate: 0.000493669
	LOSS [training: 0.05568314386667082 | validation: 0.04058305102275277]
	TIME [epoch: 8.53 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06822151109671118		[learning rate: 0.0004925]
	Learning Rate: 0.000492505
	LOSS [training: 0.06822151109671118 | validation: 0.04238360190488785]
	TIME [epoch: 8.52 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05232868122781585		[learning rate: 0.00049134]
	Learning Rate: 0.000491343
	LOSS [training: 0.05232868122781585 | validation: 0.047317505423593136]
	TIME [epoch: 8.52 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056692667410601846		[learning rate: 0.00049018]
	Learning Rate: 0.000490184
	LOSS [training: 0.056692667410601846 | validation: 0.03796660117414972]
	TIME [epoch: 8.55 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05446017775328105		[learning rate: 0.00048903]
	Learning Rate: 0.000489027
	LOSS [training: 0.05446017775328105 | validation: 0.05569961015285048]
	TIME [epoch: 8.53 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05576882351431441		[learning rate: 0.00048787]
	Learning Rate: 0.000487874
	LOSS [training: 0.05576882351431441 | validation: 0.028887188970757698]
	TIME [epoch: 8.53 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046238970481209576		[learning rate: 0.00048672]
	Learning Rate: 0.000486723
	LOSS [training: 0.046238970481209576 | validation: 0.06829347364011133]
	TIME [epoch: 8.53 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059396319815613996		[learning rate: 0.00048558]
	Learning Rate: 0.000485575
	LOSS [training: 0.059396319815613996 | validation: 0.03230930549666042]
	TIME [epoch: 8.54 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05840317238852415		[learning rate: 0.00048443]
	Learning Rate: 0.00048443
	LOSS [training: 0.05840317238852415 | validation: 0.07229294323846189]
	TIME [epoch: 8.53 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07132006289125756		[learning rate: 0.00048329]
	Learning Rate: 0.000483287
	LOSS [training: 0.07132006289125756 | validation: 0.04916829649082923]
	TIME [epoch: 8.52 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05558932292206716		[learning rate: 0.00048215]
	Learning Rate: 0.000482147
	LOSS [training: 0.05558932292206716 | validation: 0.04076893090068058]
	TIME [epoch: 8.52 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05718537941081421		[learning rate: 0.00048101]
	Learning Rate: 0.00048101
	LOSS [training: 0.05718537941081421 | validation: 0.04616381090942075]
	TIME [epoch: 8.56 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06066962996073973		[learning rate: 0.00047988]
	Learning Rate: 0.000479875
	LOSS [training: 0.06066962996073973 | validation: 0.03282459883528424]
	TIME [epoch: 8.52 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04607761680736608		[learning rate: 0.00047874]
	Learning Rate: 0.000478743
	LOSS [training: 0.04607761680736608 | validation: 0.03363463107478461]
	TIME [epoch: 8.52 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055164663421576235		[learning rate: 0.00047761]
	Learning Rate: 0.000477614
	LOSS [training: 0.055164663421576235 | validation: 0.02596551801280067]
	TIME [epoch: 8.52 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04595464589441756		[learning rate: 0.00047649]
	Learning Rate: 0.000476487
	LOSS [training: 0.04595464589441756 | validation: 0.020060905065952827]
	TIME [epoch: 8.55 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060841678583352155		[learning rate: 0.00047536]
	Learning Rate: 0.000475363
	LOSS [training: 0.060841678583352155 | validation: 0.08967459029905547]
	TIME [epoch: 8.53 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07019180587530047		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.07019180587530047 | validation: 0.05078535340379572]
	TIME [epoch: 8.52 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07317160187428752		[learning rate: 0.00047312]
	Learning Rate: 0.000473123
	LOSS [training: 0.07317160187428752 | validation: 0.08786431626514452]
	TIME [epoch: 8.52 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05611208059188518		[learning rate: 0.00047201]
	Learning Rate: 0.000472007
	LOSS [training: 0.05611208059188518 | validation: 0.02715913799228027]
	TIME [epoch: 8.55 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05533424946922283		[learning rate: 0.00047089]
	Learning Rate: 0.000470894
	LOSS [training: 0.05533424946922283 | validation: 0.03213850487072702]
	TIME [epoch: 8.53 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05577285571223599		[learning rate: 0.00046978]
	Learning Rate: 0.000469783
	LOSS [training: 0.05577285571223599 | validation: 0.044099767883841484]
	TIME [epoch: 8.52 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055372464491063124		[learning rate: 0.00046867]
	Learning Rate: 0.000468675
	LOSS [training: 0.055372464491063124 | validation: 0.06333686992190249]
	TIME [epoch: 8.53 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07342451995288807		[learning rate: 0.00046757]
	Learning Rate: 0.000467569
	LOSS [training: 0.07342451995288807 | validation: 0.047076024828230756]
	TIME [epoch: 8.54 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07371462513147267		[learning rate: 0.00046647]
	Learning Rate: 0.000466467
	LOSS [training: 0.07371462513147267 | validation: 0.02830210618206375]
	TIME [epoch: 8.52 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05102454405917774		[learning rate: 0.00046537]
	Learning Rate: 0.000465366
	LOSS [training: 0.05102454405917774 | validation: 0.03704959008250397]
	TIME [epoch: 8.53 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04636363422452473		[learning rate: 0.00046427]
	Learning Rate: 0.000464269
	LOSS [training: 0.04636363422452473 | validation: 0.026863303826517165]
	TIME [epoch: 8.54 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06525052445659987		[learning rate: 0.00046317]
	Learning Rate: 0.000463173
	LOSS [training: 0.06525052445659987 | validation: 0.02586885432992181]
	TIME [epoch: 8.54 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0583061347765362		[learning rate: 0.00046208]
	Learning Rate: 0.000462081
	LOSS [training: 0.0583061347765362 | validation: 0.0678427288093168]
	TIME [epoch: 8.52 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05778947636944777		[learning rate: 0.00046099]
	Learning Rate: 0.000460991
	LOSS [training: 0.05778947636944777 | validation: 0.037679696340029115]
	TIME [epoch: 8.53 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05853449832596545		[learning rate: 0.0004599]
	Learning Rate: 0.000459903
	LOSS [training: 0.05853449832596545 | validation: 0.05493021197987391]
	TIME [epoch: 8.54 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060072678271364054		[learning rate: 0.00045882]
	Learning Rate: 0.000458819
	LOSS [training: 0.060072678271364054 | validation: 0.056657237550498576]
	TIME [epoch: 8.52 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06666460735574267		[learning rate: 0.00045774]
	Learning Rate: 0.000457736
	LOSS [training: 0.06666460735574267 | validation: 0.049310061820350845]
	TIME [epoch: 8.53 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05056534811998574		[learning rate: 0.00045666]
	Learning Rate: 0.000456657
	LOSS [training: 0.05056534811998574 | validation: 0.05658296251295945]
	TIME [epoch: 8.52 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06303240094237736		[learning rate: 0.00045558]
	Learning Rate: 0.000455579
	LOSS [training: 0.06303240094237736 | validation: 0.026185595072951727]
	TIME [epoch: 8.55 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05079715955311894		[learning rate: 0.0004545]
	Learning Rate: 0.000454505
	LOSS [training: 0.05079715955311894 | validation: 0.04144786038668273]
	TIME [epoch: 8.53 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0502972308118939		[learning rate: 0.00045343]
	Learning Rate: 0.000453433
	LOSS [training: 0.0502972308118939 | validation: 0.04122912121581358]
	TIME [epoch: 8.51 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0694114393667373		[learning rate: 0.00045236]
	Learning Rate: 0.000452363
	LOSS [training: 0.0694114393667373 | validation: 0.06837612472909038]
	TIME [epoch: 8.52 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05470430920129441		[learning rate: 0.0004513]
	Learning Rate: 0.000451296
	LOSS [training: 0.05470430920129441 | validation: 0.04728024552861869]
	TIME [epoch: 8.54 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055849486746630636		[learning rate: 0.00045023]
	Learning Rate: 0.000450232
	LOSS [training: 0.055849486746630636 | validation: 0.035931657656374315]
	TIME [epoch: 8.52 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047973067189340926		[learning rate: 0.00044917]
	Learning Rate: 0.000449169
	LOSS [training: 0.047973067189340926 | validation: 0.04034056073196546]
	TIME [epoch: 8.52 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050404688554472075		[learning rate: 0.00044811]
	Learning Rate: 0.00044811
	LOSS [training: 0.050404688554472075 | validation: 0.01612046786624116]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1365.pth
	Model improved!!!
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03876327112768508		[learning rate: 0.00044705]
	Learning Rate: 0.000447053
	LOSS [training: 0.03876327112768508 | validation: 0.033042075549068184]
	TIME [epoch: 8.55 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06730176734510054		[learning rate: 0.000446]
	Learning Rate: 0.000445998
	LOSS [training: 0.06730176734510054 | validation: 0.03333206252729962]
	TIME [epoch: 8.52 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04672073723174527		[learning rate: 0.00044495]
	Learning Rate: 0.000444946
	LOSS [training: 0.04672073723174527 | validation: 0.03182966954736873]
	TIME [epoch: 8.53 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05072179481573389		[learning rate: 0.0004439]
	Learning Rate: 0.000443897
	LOSS [training: 0.05072179481573389 | validation: 0.036904879242918215]
	TIME [epoch: 8.52 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04573732637939167		[learning rate: 0.00044285]
	Learning Rate: 0.00044285
	LOSS [training: 0.04573732637939167 | validation: 0.061147610168758394]
	TIME [epoch: 8.54 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06495734667576071		[learning rate: 0.00044181]
	Learning Rate: 0.000441805
	LOSS [training: 0.06495734667576071 | validation: 0.03616055586275617]
	TIME [epoch: 8.52 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05600649321996602		[learning rate: 0.00044076]
	Learning Rate: 0.000440763
	LOSS [training: 0.05600649321996602 | validation: 0.07276936174404022]
	TIME [epoch: 8.52 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07963230823781545		[learning rate: 0.00043972]
	Learning Rate: 0.000439723
	LOSS [training: 0.07963230823781545 | validation: 0.042051776914993955]
	TIME [epoch: 8.52 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04722312516703911		[learning rate: 0.00043869]
	Learning Rate: 0.000438686
	LOSS [training: 0.04722312516703911 | validation: 0.042182082964972265]
	TIME [epoch: 8.54 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04960376370410229		[learning rate: 0.00043765]
	Learning Rate: 0.000437651
	LOSS [training: 0.04960376370410229 | validation: 0.03955303537723284]
	TIME [epoch: 8.52 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057929671012489595		[learning rate: 0.00043662]
	Learning Rate: 0.000436619
	LOSS [training: 0.057929671012489595 | validation: 0.06699203089600654]
	TIME [epoch: 8.52 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05595115073635513		[learning rate: 0.00043559]
	Learning Rate: 0.000435589
	LOSS [training: 0.05595115073635513 | validation: 0.07647002738334241]
	TIME [epoch: 8.53 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05267636555704349		[learning rate: 0.00043456]
	Learning Rate: 0.000434562
	LOSS [training: 0.05267636555704349 | validation: 0.03963765959345565]
	TIME [epoch: 8.53 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270541559987348		[learning rate: 0.00043354]
	Learning Rate: 0.000433536
	LOSS [training: 0.05270541559987348 | validation: 0.03985526551336784]
	TIME [epoch: 8.52 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06737900829498653		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.06737900829498653 | validation: 0.039867977597559744]
	TIME [epoch: 8.52 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05373562846078188		[learning rate: 0.00043149]
	Learning Rate: 0.000431494
	LOSS [training: 0.05373562846078188 | validation: 0.027497110324418164]
	TIME [epoch: 8.53 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04825170870603419		[learning rate: 0.00043048]
	Learning Rate: 0.000430476
	LOSS [training: 0.04825170870603419 | validation: 0.029704929602710817]
	TIME [epoch: 8.53 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042193957517677835		[learning rate: 0.00042946]
	Learning Rate: 0.00042946
	LOSS [training: 0.042193957517677835 | validation: 0.03650150373376829]
	TIME [epoch: 8.52 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05006398838516711		[learning rate: 0.00042845]
	Learning Rate: 0.000428447
	LOSS [training: 0.05006398838516711 | validation: 0.0306416064979046]
	TIME [epoch: 8.53 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06321830310034368		[learning rate: 0.00042744]
	Learning Rate: 0.000427437
	LOSS [training: 0.06321830310034368 | validation: 0.08308848749351572]
	TIME [epoch: 8.54 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0551637895156785		[learning rate: 0.00042643]
	Learning Rate: 0.000426428
	LOSS [training: 0.0551637895156785 | validation: 0.0373837006957372]
	TIME [epoch: 8.53 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0596591507737825		[learning rate: 0.00042542]
	Learning Rate: 0.000425423
	LOSS [training: 0.0596591507737825 | validation: 0.05333658430084753]
	TIME [epoch: 8.52 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04873083025642071		[learning rate: 0.00042442]
	Learning Rate: 0.000424419
	LOSS [training: 0.04873083025642071 | validation: 0.03570068764055896]
	TIME [epoch: 8.52 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05078245951622118		[learning rate: 0.00042342]
	Learning Rate: 0.000423418
	LOSS [training: 0.05078245951622118 | validation: 0.04621162501591905]
	TIME [epoch: 8.54 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05830703319749404		[learning rate: 0.00042242]
	Learning Rate: 0.000422419
	LOSS [training: 0.05830703319749404 | validation: 0.03737326920806444]
	TIME [epoch: 8.52 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05543835311035585		[learning rate: 0.00042142]
	Learning Rate: 0.000421423
	LOSS [training: 0.05543835311035585 | validation: 0.03924386174488686]
	TIME [epoch: 8.52 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050657661481762206		[learning rate: 0.00042043]
	Learning Rate: 0.000420429
	LOSS [training: 0.050657661481762206 | validation: 0.0275753754338727]
	TIME [epoch: 8.52 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06016960008644451		[learning rate: 0.00041944]
	Learning Rate: 0.000419437
	LOSS [training: 0.06016960008644451 | validation: 0.05465376903113903]
	TIME [epoch: 8.54 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057319920840715		[learning rate: 0.00041845]
	Learning Rate: 0.000418448
	LOSS [training: 0.057319920840715 | validation: 0.034813337158405705]
	TIME [epoch: 8.52 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052397898478304596		[learning rate: 0.00041746]
	Learning Rate: 0.00041746
	LOSS [training: 0.052397898478304596 | validation: 0.027918361595173222]
	TIME [epoch: 8.52 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05187172046206947		[learning rate: 0.00041648]
	Learning Rate: 0.000416476
	LOSS [training: 0.05187172046206947 | validation: 0.03817445895403537]
	TIME [epoch: 8.52 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05116424432550885		[learning rate: 0.00041549]
	Learning Rate: 0.000415493
	LOSS [training: 0.05116424432550885 | validation: 0.026548478431786513]
	TIME [epoch: 8.54 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05927137153562858		[learning rate: 0.00041451]
	Learning Rate: 0.000414513
	LOSS [training: 0.05927137153562858 | validation: 0.08935951732423716]
	TIME [epoch: 8.52 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664757044351916		[learning rate: 0.00041354]
	Learning Rate: 0.000413535
	LOSS [training: 0.05664757044351916 | validation: 0.026853498070261425]
	TIME [epoch: 8.52 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04827516396949597		[learning rate: 0.00041256]
	Learning Rate: 0.00041256
	LOSS [training: 0.04827516396949597 | validation: 0.057832381705220835]
	TIME [epoch: 8.52 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05656468444845593		[learning rate: 0.00041159]
	Learning Rate: 0.000411587
	LOSS [training: 0.05656468444845593 | validation: 0.02627375821249823]
	TIME [epoch: 8.54 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04455514373056176		[learning rate: 0.00041062]
	Learning Rate: 0.000410616
	LOSS [training: 0.04455514373056176 | validation: 0.016038297328130457]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1402.pth
	Model improved!!!
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04714682709478246		[learning rate: 0.00040965]
	Learning Rate: 0.000409647
	LOSS [training: 0.04714682709478246 | validation: 0.035038311000955974]
	TIME [epoch: 8.53 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05101471204099589		[learning rate: 0.00040868]
	Learning Rate: 0.000408681
	LOSS [training: 0.05101471204099589 | validation: 0.03846329095414434]
	TIME [epoch: 8.54 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053214456752478614		[learning rate: 0.00040772]
	Learning Rate: 0.000407717
	LOSS [training: 0.053214456752478614 | validation: 0.043290058133977426]
	TIME [epoch: 8.56 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0771568456924407		[learning rate: 0.00040676]
	Learning Rate: 0.000406755
	LOSS [training: 0.0771568456924407 | validation: 0.05400651823159641]
	TIME [epoch: 8.54 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07238555749498385		[learning rate: 0.0004058]
	Learning Rate: 0.000405796
	LOSS [training: 0.07238555749498385 | validation: 0.05819567225185282]
	TIME [epoch: 8.54 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06340005907814708		[learning rate: 0.00040484]
	Learning Rate: 0.000404839
	LOSS [training: 0.06340005907814708 | validation: 0.036382101295791294]
	TIME [epoch: 8.54 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049756528134335676		[learning rate: 0.00040388]
	Learning Rate: 0.000403884
	LOSS [training: 0.049756528134335676 | validation: 0.0299953769674889]
	TIME [epoch: 8.56 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05091975477904851		[learning rate: 0.00040293]
	Learning Rate: 0.000402931
	LOSS [training: 0.05091975477904851 | validation: 0.033164934218521055]
	TIME [epoch: 8.54 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04930583453086832		[learning rate: 0.00040198]
	Learning Rate: 0.000401981
	LOSS [training: 0.04930583453086832 | validation: 0.028118029669721586]
	TIME [epoch: 8.53 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04964377020293086		[learning rate: 0.00040103]
	Learning Rate: 0.000401032
	LOSS [training: 0.04964377020293086 | validation: 0.03392032137732649]
	TIME [epoch: 8.54 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04618329031316876		[learning rate: 0.00040009]
	Learning Rate: 0.000400086
	LOSS [training: 0.04618329031316876 | validation: 0.045145117276171175]
	TIME [epoch: 8.56 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049849322983641135		[learning rate: 0.00039914]
	Learning Rate: 0.000399143
	LOSS [training: 0.049849322983641135 | validation: 0.03160936644787508]
	TIME [epoch: 8.54 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06878748705679338		[learning rate: 0.0003982]
	Learning Rate: 0.000398201
	LOSS [training: 0.06878748705679338 | validation: 0.0362474368527915]
	TIME [epoch: 8.53 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046922265082894495		[learning rate: 0.00039726]
	Learning Rate: 0.000397262
	LOSS [training: 0.046922265082894495 | validation: 0.04728241658093919]
	TIME [epoch: 8.54 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05522426242109731		[learning rate: 0.00039632]
	Learning Rate: 0.000396325
	LOSS [training: 0.05522426242109731 | validation: 0.043198200386581634]
	TIME [epoch: 8.55 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041970409354720156		[learning rate: 0.00039539]
	Learning Rate: 0.00039539
	LOSS [training: 0.041970409354720156 | validation: 0.03665221705745621]
	TIME [epoch: 8.53 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04353176809093552		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.04353176809093552 | validation: 0.024774712021201645]
	TIME [epoch: 8.54 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04775705162726649		[learning rate: 0.00039353]
	Learning Rate: 0.000393527
	LOSS [training: 0.04775705162726649 | validation: 0.031050171648619868]
	TIME [epoch: 8.55 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04493123821208743		[learning rate: 0.0003926]
	Learning Rate: 0.000392599
	LOSS [training: 0.04493123821208743 | validation: 0.032036349301914686]
	TIME [epoch: 8.55 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042074308117667374		[learning rate: 0.00039167]
	Learning Rate: 0.000391672
	LOSS [training: 0.042074308117667374 | validation: 0.036491296464862155]
	TIME [epoch: 8.54 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04457252327678928		[learning rate: 0.00039075]
	Learning Rate: 0.000390748
	LOSS [training: 0.04457252327678928 | validation: 0.04083546248930629]
	TIME [epoch: 8.53 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04842343421986498		[learning rate: 0.00038983]
	Learning Rate: 0.000389827
	LOSS [training: 0.04842343421986498 | validation: 0.03864019779260984]
	TIME [epoch: 8.55 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050393498333650776		[learning rate: 0.00038891]
	Learning Rate: 0.000388907
	LOSS [training: 0.050393498333650776 | validation: 0.023823590441230984]
	TIME [epoch: 8.54 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054318363344373365		[learning rate: 0.00038799]
	Learning Rate: 0.00038799
	LOSS [training: 0.054318363344373365 | validation: 0.040662218132388864]
	TIME [epoch: 8.54 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0712906404741106		[learning rate: 0.00038707]
	Learning Rate: 0.000387075
	LOSS [training: 0.0712906404741106 | validation: 0.03344895074930222]
	TIME [epoch: 8.54 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05539963402786839		[learning rate: 0.00038616]
	Learning Rate: 0.000386162
	LOSS [training: 0.05539963402786839 | validation: 0.0706082162371685]
	TIME [epoch: 8.56 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049794009748208204		[learning rate: 0.00038525]
	Learning Rate: 0.000385251
	LOSS [training: 0.049794009748208204 | validation: 0.03419157336149864]
	TIME [epoch: 8.54 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04722926411527219		[learning rate: 0.00038434]
	Learning Rate: 0.000384342
	LOSS [training: 0.04722926411527219 | validation: 0.030602282068048936]
	TIME [epoch: 8.53 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050806158912471956		[learning rate: 0.00038344]
	Learning Rate: 0.000383435
	LOSS [training: 0.050806158912471956 | validation: 0.029985814281002967]
	TIME [epoch: 8.54 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05335694821912316		[learning rate: 0.00038253]
	Learning Rate: 0.000382531
	LOSS [training: 0.05335694821912316 | validation: 0.03986195437924799]
	TIME [epoch: 8.55 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04729793533526736		[learning rate: 0.00038163]
	Learning Rate: 0.000381629
	LOSS [training: 0.04729793533526736 | validation: 0.04291758916956605]
	TIME [epoch: 8.53 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04439551924762787		[learning rate: 0.00038073]
	Learning Rate: 0.000380729
	LOSS [training: 0.04439551924762787 | validation: 0.029057317581559952]
	TIME [epoch: 8.54 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044211076249366967		[learning rate: 0.00037983]
	Learning Rate: 0.00037983
	LOSS [training: 0.044211076249366967 | validation: 0.026094855934242316]
	TIME [epoch: 8.53 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04370570472989901		[learning rate: 0.00037893]
	Learning Rate: 0.000378934
	LOSS [training: 0.04370570472989901 | validation: 0.030627907680821027]
	TIME [epoch: 8.56 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04725925467905119		[learning rate: 0.00037804]
	Learning Rate: 0.000378041
	LOSS [training: 0.04725925467905119 | validation: 0.021959409898484536]
	TIME [epoch: 8.54 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052373423407742724		[learning rate: 0.00037715]
	Learning Rate: 0.000377149
	LOSS [training: 0.052373423407742724 | validation: 0.043830592529311235]
	TIME [epoch: 8.54 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0492543955554751		[learning rate: 0.00037626]
	Learning Rate: 0.000376259
	LOSS [training: 0.0492543955554751 | validation: 0.018055331984696096]
	TIME [epoch: 8.53 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039565609912216346		[learning rate: 0.00037537]
	Learning Rate: 0.000375372
	LOSS [training: 0.039565609912216346 | validation: 0.020983854507660736]
	TIME [epoch: 8.56 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05056357012621746		[learning rate: 0.00037449]
	Learning Rate: 0.000374486
	LOSS [training: 0.05056357012621746 | validation: 0.012310602817006657]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1441.pth
	Model improved!!!
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05685602403308452		[learning rate: 0.0003736]
	Learning Rate: 0.000373603
	LOSS [training: 0.05685602403308452 | validation: 0.023949441707235196]
	TIME [epoch: 8.53 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549801006474388		[learning rate: 0.00037272]
	Learning Rate: 0.000372722
	LOSS [training: 0.0549801006474388 | validation: 0.03695058885449788]
	TIME [epoch: 8.54 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046563525761744815		[learning rate: 0.00037184]
	Learning Rate: 0.000371842
	LOSS [training: 0.046563525761744815 | validation: 0.03097898520925043]
	TIME [epoch: 8.55 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04589093601647049		[learning rate: 0.00037097]
	Learning Rate: 0.000370965
	LOSS [training: 0.04589093601647049 | validation: 0.03544359700341158]
	TIME [epoch: 8.53 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04831335214356641		[learning rate: 0.00037009]
	Learning Rate: 0.00037009
	LOSS [training: 0.04831335214356641 | validation: 0.02571762445030658]
	TIME [epoch: 8.53 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05768085783285589		[learning rate: 0.00036922]
	Learning Rate: 0.000369217
	LOSS [training: 0.05768085783285589 | validation: 0.036389300276124394]
	TIME [epoch: 8.54 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054520324156686194		[learning rate: 0.00036835]
	Learning Rate: 0.000368346
	LOSS [training: 0.054520324156686194 | validation: 0.053819357081465236]
	TIME [epoch: 8.54 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054262543017990904		[learning rate: 0.00036748]
	Learning Rate: 0.000367477
	LOSS [training: 0.054262543017990904 | validation: 0.030364371706766743]
	TIME [epoch: 8.53 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04766109384172952		[learning rate: 0.00036661]
	Learning Rate: 0.000366611
	LOSS [training: 0.04766109384172952 | validation: 0.028442900606522912]
	TIME [epoch: 8.53 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054481451095321334		[learning rate: 0.00036575]
	Learning Rate: 0.000365746
	LOSS [training: 0.054481451095321334 | validation: 0.04192912929928708]
	TIME [epoch: 8.54 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048756371757829105		[learning rate: 0.00036488]
	Learning Rate: 0.000364883
	LOSS [training: 0.048756371757829105 | validation: 0.04257761324255033]
	TIME [epoch: 8.54 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047413781492497545		[learning rate: 0.00036402]
	Learning Rate: 0.000364022
	LOSS [training: 0.047413781492497545 | validation: 0.0323418112750771]
	TIME [epoch: 8.53 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04912400162034843		[learning rate: 0.00036316]
	Learning Rate: 0.000363164
	LOSS [training: 0.04912400162034843 | validation: 0.03649430433309932]
	TIME [epoch: 8.53 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05085616696693175		[learning rate: 0.00036231]
	Learning Rate: 0.000362307
	LOSS [training: 0.05085616696693175 | validation: 0.026200606678875672]
	TIME [epoch: 8.55 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04573133046455282		[learning rate: 0.00036145]
	Learning Rate: 0.000361452
	LOSS [training: 0.04573133046455282 | validation: 0.027483828098353133]
	TIME [epoch: 8.53 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04843349803018328		[learning rate: 0.0003606]
	Learning Rate: 0.0003606
	LOSS [training: 0.04843349803018328 | validation: 0.037097584217692714]
	TIME [epoch: 8.53 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05624156042232662		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.05624156042232662 | validation: 0.03690310908706103]
	TIME [epoch: 8.53 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05072946834806667		[learning rate: 0.0003589]
	Learning Rate: 0.000358901
	LOSS [training: 0.05072946834806667 | validation: 0.03128452060837607]
	TIME [epoch: 8.55 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04088785457633925		[learning rate: 0.00035805]
	Learning Rate: 0.000358054
	LOSS [training: 0.04088785457633925 | validation: 0.027896998469974593]
	TIME [epoch: 8.53 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04036399840190032		[learning rate: 0.00035721]
	Learning Rate: 0.00035721
	LOSS [training: 0.04036399840190032 | validation: 0.02319513732191302]
	TIME [epoch: 8.53 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05253701329310871		[learning rate: 0.00035637]
	Learning Rate: 0.000356367
	LOSS [training: 0.05253701329310871 | validation: 0.09531669653060133]
	TIME [epoch: 8.53 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07203244405889642		[learning rate: 0.00035553]
	Learning Rate: 0.000355526
	LOSS [training: 0.07203244405889642 | validation: 0.035775074229656555]
	TIME [epoch: 8.56 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0520163839650631		[learning rate: 0.00035469]
	Learning Rate: 0.000354688
	LOSS [training: 0.0520163839650631 | validation: 0.04310925084706699]
	TIME [epoch: 8.53 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05421078483161561		[learning rate: 0.00035385]
	Learning Rate: 0.000353851
	LOSS [training: 0.05421078483161561 | validation: 0.022643145583084348]
	TIME [epoch: 8.53 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0523459636529766		[learning rate: 0.00035302]
	Learning Rate: 0.000353016
	LOSS [training: 0.0523459636529766 | validation: 0.031640359590846004]
	TIME [epoch: 8.53 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05049851764638945		[learning rate: 0.00035218]
	Learning Rate: 0.000352184
	LOSS [training: 0.05049851764638945 | validation: 0.028410386009278858]
	TIME [epoch: 8.55 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045076094985104884		[learning rate: 0.00035135]
	Learning Rate: 0.000351353
	LOSS [training: 0.045076094985104884 | validation: 0.03917619596995651]
	TIME [epoch: 8.54 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04950122121586381		[learning rate: 0.00035052]
	Learning Rate: 0.000350524
	LOSS [training: 0.04950122121586381 | validation: 0.01622922484773935]
	TIME [epoch: 8.53 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05303403307479056		[learning rate: 0.0003497]
	Learning Rate: 0.000349697
	LOSS [training: 0.05303403307479056 | validation: 0.04485570974095618]
	TIME [epoch: 8.53 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06193956858641362		[learning rate: 0.00034887]
	Learning Rate: 0.000348872
	LOSS [training: 0.06193956858641362 | validation: 0.043891882022615916]
	TIME [epoch: 8.55 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041692504938900574		[learning rate: 0.00034805]
	Learning Rate: 0.000348049
	LOSS [training: 0.041692504938900574 | validation: 0.0289754471577046]
	TIME [epoch: 8.53 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04760859141683003		[learning rate: 0.00034723]
	Learning Rate: 0.000347228
	LOSS [training: 0.04760859141683003 | validation: 0.03803814643602036]
	TIME [epoch: 8.53 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04752456018528624		[learning rate: 0.00034641]
	Learning Rate: 0.000346409
	LOSS [training: 0.04752456018528624 | validation: 0.07161187023526697]
	TIME [epoch: 8.53 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0476429891251502		[learning rate: 0.00034559]
	Learning Rate: 0.000345592
	LOSS [training: 0.0476429891251502 | validation: 0.043147063392750144]
	TIME [epoch: 8.55 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04889732581891675		[learning rate: 0.00034478]
	Learning Rate: 0.000344777
	LOSS [training: 0.04889732581891675 | validation: 0.061578060962969604]
	TIME [epoch: 8.53 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05254228652332012		[learning rate: 0.00034396]
	Learning Rate: 0.000343964
	LOSS [training: 0.05254228652332012 | validation: 0.037991466760893086]
	TIME [epoch: 8.53 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043537593723328445		[learning rate: 0.00034315]
	Learning Rate: 0.000343152
	LOSS [training: 0.043537593723328445 | validation: 0.05063344020332499]
	TIME [epoch: 8.54 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044142447767564236		[learning rate: 0.00034234]
	Learning Rate: 0.000342343
	LOSS [training: 0.044142447767564236 | validation: 0.02464961822469714]
	TIME [epoch: 8.54 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04572823593226016		[learning rate: 0.00034154]
	Learning Rate: 0.000341536
	LOSS [training: 0.04572823593226016 | validation: 0.03787967749851284]
	TIME [epoch: 8.53 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045868349457969075		[learning rate: 0.00034073]
	Learning Rate: 0.00034073
	LOSS [training: 0.045868349457969075 | validation: 0.04080476341699146]
	TIME [epoch: 8.53 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06915645854901324		[learning rate: 0.00033993]
	Learning Rate: 0.000339926
	LOSS [training: 0.06915645854901324 | validation: 0.057946474427798156]
	TIME [epoch: 8.54 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04742187376158273		[learning rate: 0.00033912]
	Learning Rate: 0.000339124
	LOSS [training: 0.04742187376158273 | validation: 0.02460976599756754]
	TIME [epoch: 8.53 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05493292785892091		[learning rate: 0.00033832]
	Learning Rate: 0.000338324
	LOSS [training: 0.05493292785892091 | validation: 0.039515788772782716]
	TIME [epoch: 8.53 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04418165249364235		[learning rate: 0.00033753]
	Learning Rate: 0.000337526
	LOSS [training: 0.04418165249364235 | validation: 0.03008859699665267]
	TIME [epoch: 8.52 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047988700005736275		[learning rate: 0.00033673]
	Learning Rate: 0.00033673
	LOSS [training: 0.047988700005736275 | validation: 0.036051229758324185]
	TIME [epoch: 8.54 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05070020439325203		[learning rate: 0.00033594]
	Learning Rate: 0.000335936
	LOSS [training: 0.05070020439325203 | validation: 0.02941474454686833]
	TIME [epoch: 8.53 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056480538574630236		[learning rate: 0.00033514]
	Learning Rate: 0.000335143
	LOSS [training: 0.056480538574630236 | validation: 0.03495311303954023]
	TIME [epoch: 8.52 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0499383383570557		[learning rate: 0.00033435]
	Learning Rate: 0.000334353
	LOSS [training: 0.0499383383570557 | validation: 0.036119160006567806]
	TIME [epoch: 8.53 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059315098209904285		[learning rate: 0.00033356]
	Learning Rate: 0.000333564
	LOSS [training: 0.059315098209904285 | validation: 0.029264220814352558]
	TIME [epoch: 8.55 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054945363387264565		[learning rate: 0.00033278]
	Learning Rate: 0.000332777
	LOSS [training: 0.054945363387264565 | validation: 0.057084230477406905]
	TIME [epoch: 8.53 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052755730192342545		[learning rate: 0.00033199]
	Learning Rate: 0.000331992
	LOSS [training: 0.052755730192342545 | validation: 0.06020240358029169]
	TIME [epoch: 8.52 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05479278528702882		[learning rate: 0.00033121]
	Learning Rate: 0.000331209
	LOSS [training: 0.05479278528702882 | validation: 0.04843033979283785]
	TIME [epoch: 8.53 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056439590067630455		[learning rate: 0.00033043]
	Learning Rate: 0.000330428
	LOSS [training: 0.056439590067630455 | validation: 0.0478680857514467]
	TIME [epoch: 8.54 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04373042938009986		[learning rate: 0.00032965]
	Learning Rate: 0.000329649
	LOSS [training: 0.04373042938009986 | validation: 0.026620950852364166]
	TIME [epoch: 8.52 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06589969091058268		[learning rate: 0.00032887]
	Learning Rate: 0.000328871
	LOSS [training: 0.06589969091058268 | validation: 0.022115066900017483]
	TIME [epoch: 8.53 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04857356847576488		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.04857356847576488 | validation: 0.025591302811726085]
	TIME [epoch: 8.52 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05051665582993996		[learning rate: 0.00032732]
	Learning Rate: 0.000327321
	LOSS [training: 0.05051665582993996 | validation: 0.05527681234446906]
	TIME [epoch: 8.56 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051031354465837266		[learning rate: 0.00032655]
	Learning Rate: 0.000326549
	LOSS [training: 0.051031354465837266 | validation: 0.04615461287922207]
	TIME [epoch: 8.53 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04379638071103491		[learning rate: 0.00032578]
	Learning Rate: 0.000325779
	LOSS [training: 0.04379638071103491 | validation: 0.027175207022995043]
	TIME [epoch: 8.52 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05690329532599855		[learning rate: 0.00032501]
	Learning Rate: 0.000325011
	LOSS [training: 0.05690329532599855 | validation: 0.06981246243417505]
	TIME [epoch: 8.52 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05794516642037016		[learning rate: 0.00032424]
	Learning Rate: 0.000324244
	LOSS [training: 0.05794516642037016 | validation: 0.04891656812683102]
	TIME [epoch: 8.54 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05024027504066059		[learning rate: 0.00032348]
	Learning Rate: 0.000323479
	LOSS [training: 0.05024027504066059 | validation: 0.025217664718668376]
	TIME [epoch: 8.52 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0576449055331963		[learning rate: 0.00032272]
	Learning Rate: 0.000322716
	LOSS [training: 0.0576449055331963 | validation: 0.046461287724579095]
	TIME [epoch: 8.51 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04938592343916738		[learning rate: 0.00032195]
	Learning Rate: 0.000321955
	LOSS [training: 0.04938592343916738 | validation: 0.025161934748629093]
	TIME [epoch: 8.52 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043396446624271036		[learning rate: 0.0003212]
	Learning Rate: 0.000321195
	LOSS [training: 0.043396446624271036 | validation: 0.030316697241518295]
	TIME [epoch: 8.53 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04899650991548376		[learning rate: 0.00032044]
	Learning Rate: 0.000320438
	LOSS [training: 0.04899650991548376 | validation: 0.024718878613501655]
	TIME [epoch: 8.52 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04241978257043189		[learning rate: 0.00031968]
	Learning Rate: 0.000319682
	LOSS [training: 0.04241978257043189 | validation: 0.025070292969832063]
	TIME [epoch: 8.52 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03894229938301085		[learning rate: 0.00031893]
	Learning Rate: 0.000318928
	LOSS [training: 0.03894229938301085 | validation: 0.028404513805943468]
	TIME [epoch: 8.54 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04705091678550269		[learning rate: 0.00031818]
	Learning Rate: 0.000318175
	LOSS [training: 0.04705091678550269 | validation: 0.03893971198309708]
	TIME [epoch: 8.53 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0589269897719877		[learning rate: 0.00031742]
	Learning Rate: 0.000317425
	LOSS [training: 0.0589269897719877 | validation: 0.038933573353777146]
	TIME [epoch: 8.52 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046088237363174175		[learning rate: 0.00031668]
	Learning Rate: 0.000316676
	LOSS [training: 0.046088237363174175 | validation: 0.025852089387385542]
	TIME [epoch: 8.52 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041180394901420274		[learning rate: 0.00031593]
	Learning Rate: 0.000315929
	LOSS [training: 0.041180394901420274 | validation: 0.050966155381871256]
	TIME [epoch: 8.54 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05734494026382432		[learning rate: 0.00031518]
	Learning Rate: 0.000315184
	LOSS [training: 0.05734494026382432 | validation: 0.033179718442955385]
	TIME [epoch: 8.53 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05765279665529566		[learning rate: 0.00031444]
	Learning Rate: 0.00031444
	LOSS [training: 0.05765279665529566 | validation: 0.04395222978601801]
	TIME [epoch: 8.52 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04164036204931676		[learning rate: 0.0003137]
	Learning Rate: 0.000313699
	LOSS [training: 0.04164036204931676 | validation: 0.05101938741360462]
	TIME [epoch: 8.51 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043450188671589826		[learning rate: 0.00031296]
	Learning Rate: 0.000312959
	LOSS [training: 0.043450188671589826 | validation: 0.028755056283554393]
	TIME [epoch: 8.54 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047801161757572055		[learning rate: 0.00031222]
	Learning Rate: 0.000312221
	LOSS [training: 0.047801161757572055 | validation: 0.0375505976792879]
	TIME [epoch: 8.52 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044847689744333126		[learning rate: 0.00031148]
	Learning Rate: 0.000311484
	LOSS [training: 0.044847689744333126 | validation: 0.03127932107123909]
	TIME [epoch: 8.53 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041191227717310354		[learning rate: 0.00031075]
	Learning Rate: 0.000310749
	LOSS [training: 0.041191227717310354 | validation: 0.04843534020842972]
	TIME [epoch: 8.52 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05645594869317037		[learning rate: 0.00031002]
	Learning Rate: 0.000310016
	LOSS [training: 0.05645594869317037 | validation: 0.057276414705164744]
	TIME [epoch: 8.55 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050837044175400345		[learning rate: 0.00030929]
	Learning Rate: 0.000309285
	LOSS [training: 0.050837044175400345 | validation: 0.022284803702997576]
	TIME [epoch: 8.52 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047062029848299616		[learning rate: 0.00030856]
	Learning Rate: 0.000308555
	LOSS [training: 0.047062029848299616 | validation: 0.025235883221023568]
	TIME [epoch: 8.52 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04247968312505542		[learning rate: 0.00030783]
	Learning Rate: 0.000307828
	LOSS [training: 0.04247968312505542 | validation: 0.027410628265461298]
	TIME [epoch: 8.52 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03951083968499146		[learning rate: 0.0003071]
	Learning Rate: 0.000307102
	LOSS [training: 0.03951083968499146 | validation: 0.03740731605887254]
	TIME [epoch: 8.55 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05979919113234653		[learning rate: 0.00030638]
	Learning Rate: 0.000306377
	LOSS [training: 0.05979919113234653 | validation: 0.041286267364014036]
	TIME [epoch: 8.53 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041868390098980905		[learning rate: 0.00030565]
	Learning Rate: 0.000305654
	LOSS [training: 0.041868390098980905 | validation: 0.030074218006692372]
	TIME [epoch: 8.52 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06792069379596719		[learning rate: 0.00030493]
	Learning Rate: 0.000304933
	LOSS [training: 0.06792069379596719 | validation: 0.03010189302550648]
	TIME [epoch: 8.52 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05612502953676549		[learning rate: 0.00030421]
	Learning Rate: 0.000304214
	LOSS [training: 0.05612502953676549 | validation: 0.019312940926146934]
	TIME [epoch: 8.54 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04306768792470966		[learning rate: 0.0003035]
	Learning Rate: 0.000303497
	LOSS [training: 0.04306768792470966 | validation: 0.06413192401914808]
	TIME [epoch: 8.52 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05631440384229984		[learning rate: 0.00030278]
	Learning Rate: 0.000302781
	LOSS [training: 0.05631440384229984 | validation: 0.03754106695692293]
	TIME [epoch: 8.52 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054043210655888595		[learning rate: 0.00030207]
	Learning Rate: 0.000302066
	LOSS [training: 0.054043210655888595 | validation: 0.02701064557930081]
	TIME [epoch: 8.53 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04954201702436341		[learning rate: 0.00030135]
	Learning Rate: 0.000301354
	LOSS [training: 0.04954201702436341 | validation: 0.022632650164714198]
	TIME [epoch: 8.54 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043431312470627016		[learning rate: 0.00030064]
	Learning Rate: 0.000300643
	LOSS [training: 0.043431312470627016 | validation: 0.03387844576934974]
	TIME [epoch: 8.53 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04305293759766645		[learning rate: 0.00029993]
	Learning Rate: 0.000299934
	LOSS [training: 0.04305293759766645 | validation: 0.028366855081415815]
	TIME [epoch: 8.52 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04321773809329889		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.04321773809329889 | validation: 0.05237728702379473]
	TIME [epoch: 8.52 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05476740865176647		[learning rate: 0.00029852]
	Learning Rate: 0.000298521
	LOSS [training: 0.05476740865176647 | validation: 0.03555732740811075]
	TIME [epoch: 8.54 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054402788071175864		[learning rate: 0.00029782]
	Learning Rate: 0.000297816
	LOSS [training: 0.054402788071175864 | validation: 0.0461539530289769]
	TIME [epoch: 8.53 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045668933721767356		[learning rate: 0.00029711]
	Learning Rate: 0.000297114
	LOSS [training: 0.045668933721767356 | validation: 0.045171735625661555]
	TIME [epoch: 8.52 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05580932846775766		[learning rate: 0.00029641]
	Learning Rate: 0.000296413
	LOSS [training: 0.05580932846775766 | validation: 0.04223631684417527]
	TIME [epoch: 8.53 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05343176647534951		[learning rate: 0.00029571]
	Learning Rate: 0.000295714
	LOSS [training: 0.05343176647534951 | validation: 0.03337626896521301]
	TIME [epoch: 8.55 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049118179651442564		[learning rate: 0.00029502]
	Learning Rate: 0.000295016
	LOSS [training: 0.049118179651442564 | validation: 0.04123933697310325]
	TIME [epoch: 8.52 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03838711654283539		[learning rate: 0.00029432]
	Learning Rate: 0.00029432
	LOSS [training: 0.03838711654283539 | validation: 0.021343592814714714]
	TIME [epoch: 8.52 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04056296620426318		[learning rate: 0.00029363]
	Learning Rate: 0.000293626
	LOSS [training: 0.04056296620426318 | validation: 0.03836688277008874]
	TIME [epoch: 8.54 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06149054265837728		[learning rate: 0.00029293]
	Learning Rate: 0.000292934
	LOSS [training: 0.06149054265837728 | validation: 0.04556461366327606]
	TIME [epoch: 8.54 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04718146112903972		[learning rate: 0.00029224]
	Learning Rate: 0.000292243
	LOSS [training: 0.04718146112903972 | validation: 0.04254982611934053]
	TIME [epoch: 8.52 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05213916815140794		[learning rate: 0.00029155]
	Learning Rate: 0.000291553
	LOSS [training: 0.05213916815140794 | validation: 0.0279987223274652]
	TIME [epoch: 8.52 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05175203873702918		[learning rate: 0.00029087]
	Learning Rate: 0.000290866
	LOSS [training: 0.05175203873702918 | validation: 0.021336427294629846]
	TIME [epoch: 8.54 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04918384699200744		[learning rate: 0.00029018]
	Learning Rate: 0.000290179
	LOSS [training: 0.04918384699200744 | validation: 0.03897824606407894]
	TIME [epoch: 8.53 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04050763077876347		[learning rate: 0.00028949]
	Learning Rate: 0.000289495
	LOSS [training: 0.04050763077876347 | validation: 0.02835125696931308]
	TIME [epoch: 8.53 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04278835527345573		[learning rate: 0.00028881]
	Learning Rate: 0.000288812
	LOSS [training: 0.04278835527345573 | validation: 0.036672919563299655]
	TIME [epoch: 8.52 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04907684056796492		[learning rate: 0.00028813]
	Learning Rate: 0.000288131
	LOSS [training: 0.04907684056796492 | validation: 0.03131271843069483]
	TIME [epoch: 8.53 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0494362142841118		[learning rate: 0.00028745]
	Learning Rate: 0.000287451
	LOSS [training: 0.0494362142841118 | validation: 0.03956197131299362]
	TIME [epoch: 8.51 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054137826613574705		[learning rate: 0.00028677]
	Learning Rate: 0.000286773
	LOSS [training: 0.054137826613574705 | validation: 0.02990300662617923]
	TIME [epoch: 8.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05178828348602667		[learning rate: 0.0002861]
	Learning Rate: 0.000286097
	LOSS [training: 0.05178828348602667 | validation: 0.0390957160886784]
	TIME [epoch: 8.51 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04670461078829498		[learning rate: 0.00028542]
	Learning Rate: 0.000285422
	LOSS [training: 0.04670461078829498 | validation: 0.026267149274118835]
	TIME [epoch: 8.54 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0507992049732055		[learning rate: 0.00028475]
	Learning Rate: 0.000284749
	LOSS [training: 0.0507992049732055 | validation: 0.02365526165871339]
	TIME [epoch: 8.52 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04414746770814438		[learning rate: 0.00028408]
	Learning Rate: 0.000284077
	LOSS [training: 0.04414746770814438 | validation: 0.03668191719156044]
	TIME [epoch: 8.52 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06435868362038648		[learning rate: 0.00028341]
	Learning Rate: 0.000283407
	LOSS [training: 0.06435868362038648 | validation: 0.034856818190769426]
	TIME [epoch: 8.53 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054849556889121756		[learning rate: 0.00028274]
	Learning Rate: 0.000282738
	LOSS [training: 0.054849556889121756 | validation: 0.023906286935999853]
	TIME [epoch: 8.54 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03797128531739569		[learning rate: 0.00028207]
	Learning Rate: 0.000282071
	LOSS [training: 0.03797128531739569 | validation: 0.03146329487388468]
	TIME [epoch: 8.52 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049901115601576264		[learning rate: 0.00028141]
	Learning Rate: 0.000281406
	LOSS [training: 0.049901115601576264 | validation: 0.03650594756560486]
	TIME [epoch: 8.52 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04276046964580866		[learning rate: 0.00028074]
	Learning Rate: 0.000280742
	LOSS [training: 0.04276046964580866 | validation: 0.021484122974317413]
	TIME [epoch: 8.51 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0418594390741104		[learning rate: 0.00028008]
	Learning Rate: 0.00028008
	LOSS [training: 0.0418594390741104 | validation: 0.021107154150610784]
	TIME [epoch: 8.55 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04225727910703127		[learning rate: 0.00027942]
	Learning Rate: 0.000279419
	LOSS [training: 0.04225727910703127 | validation: 0.029259446496698094]
	TIME [epoch: 8.51 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04526776291282105		[learning rate: 0.00027876]
	Learning Rate: 0.00027876
	LOSS [training: 0.04526776291282105 | validation: 0.030838255326450167]
	TIME [epoch: 8.52 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041238019251807784		[learning rate: 0.0002781]
	Learning Rate: 0.000278103
	LOSS [training: 0.041238019251807784 | validation: 0.020874488385770835]
	TIME [epoch: 8.52 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042236484337953455		[learning rate: 0.00027745]
	Learning Rate: 0.000277447
	LOSS [training: 0.042236484337953455 | validation: 0.03814022097359541]
	TIME [epoch: 8.54 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040419882690346715		[learning rate: 0.00027679]
	Learning Rate: 0.000276792
	LOSS [training: 0.040419882690346715 | validation: 0.038882859323776484]
	TIME [epoch: 8.52 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04367403934555941		[learning rate: 0.00027614]
	Learning Rate: 0.000276139
	LOSS [training: 0.04367403934555941 | validation: 0.031612967580644774]
	TIME [epoch: 8.51 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06177413189836554		[learning rate: 0.00027549]
	Learning Rate: 0.000275488
	LOSS [training: 0.06177413189836554 | validation: 0.039404422368979695]
	TIME [epoch: 8.52 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043352666047133025		[learning rate: 0.00027484]
	Learning Rate: 0.000274838
	LOSS [training: 0.043352666047133025 | validation: 0.023207368999310814]
	TIME [epoch: 8.53 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04818130714532286		[learning rate: 0.00027419]
	Learning Rate: 0.00027419
	LOSS [training: 0.04818130714532286 | validation: 0.03632519336587667]
	TIME [epoch: 8.52 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04753947453508345		[learning rate: 0.00027354]
	Learning Rate: 0.000273543
	LOSS [training: 0.04753947453508345 | validation: 0.024916431514831243]
	TIME [epoch: 8.51 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04255229484953503		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.04255229484953503 | validation: 0.030282955184153068]
	TIME [epoch: 8.53 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04617632536322312		[learning rate: 0.00027225]
	Learning Rate: 0.000272254
	LOSS [training: 0.04617632536322312 | validation: 0.049043171730053674]
	TIME [epoch: 8.53 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058438545037827715		[learning rate: 0.00027161]
	Learning Rate: 0.000271612
	LOSS [training: 0.058438545037827715 | validation: 0.043990937369100695]
	TIME [epoch: 8.52 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052505676413637827		[learning rate: 0.00027097]
	Learning Rate: 0.000270971
	LOSS [training: 0.052505676413637827 | validation: 0.04779798988334916]
	TIME [epoch: 8.52 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050321742469780294		[learning rate: 0.00027033]
	Learning Rate: 0.000270332
	LOSS [training: 0.050321742469780294 | validation: 0.032079544516110337]
	TIME [epoch: 8.53 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04284288605566099		[learning rate: 0.00026969]
	Learning Rate: 0.000269694
	LOSS [training: 0.04284288605566099 | validation: 0.031918504768517264]
	TIME [epoch: 8.53 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04871348767652189		[learning rate: 0.00026906]
	Learning Rate: 0.000269058
	LOSS [training: 0.04871348767652189 | validation: 0.043892988633056323]
	TIME [epoch: 8.51 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04353628804631258		[learning rate: 0.00026842]
	Learning Rate: 0.000268423
	LOSS [training: 0.04353628804631258 | validation: 0.023359834076613493]
	TIME [epoch: 8.51 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046171331676142645		[learning rate: 0.00026779]
	Learning Rate: 0.00026779
	LOSS [training: 0.046171331676142645 | validation: 0.03231420975569213]
	TIME [epoch: 8.54 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046138671694983244		[learning rate: 0.00026716]
	Learning Rate: 0.000267159
	LOSS [training: 0.046138671694983244 | validation: 0.0278649086940836]
	TIME [epoch: 8.52 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05704341446623644		[learning rate: 0.00026653]
	Learning Rate: 0.000266528
	LOSS [training: 0.05704341446623644 | validation: 0.04771367473192487]
	TIME [epoch: 8.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0457103155598315		[learning rate: 0.0002659]
	Learning Rate: 0.0002659
	LOSS [training: 0.0457103155598315 | validation: 0.028563366064895526]
	TIME [epoch: 8.51 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04608469161120613		[learning rate: 0.00026527]
	Learning Rate: 0.000265273
	LOSS [training: 0.04608469161120613 | validation: 0.02707510700924365]
	TIME [epoch: 8.54 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04416740144663746		[learning rate: 0.00026465]
	Learning Rate: 0.000264647
	LOSS [training: 0.04416740144663746 | validation: 0.017064429532023914]
	TIME [epoch: 8.52 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049350684214574995		[learning rate: 0.00026402]
	Learning Rate: 0.000264022
	LOSS [training: 0.049350684214574995 | validation: 0.059118026854883175]
	TIME [epoch: 8.52 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062348176184952406		[learning rate: 0.0002634]
	Learning Rate: 0.0002634
	LOSS [training: 0.062348176184952406 | validation: 0.040193562666936265]
	TIME [epoch: 8.52 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04280675236437414		[learning rate: 0.00026278]
	Learning Rate: 0.000262778
	LOSS [training: 0.04280675236437414 | validation: 0.027923836910162765]
	TIME [epoch: 8.54 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0416882043260256		[learning rate: 0.00026216]
	Learning Rate: 0.000262159
	LOSS [training: 0.0416882043260256 | validation: 0.019379565706089775]
	TIME [epoch: 8.52 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050839257537421786		[learning rate: 0.00026154]
	Learning Rate: 0.00026154
	LOSS [training: 0.050839257537421786 | validation: 0.026055445211744285]
	TIME [epoch: 8.53 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06193675136144435		[learning rate: 0.00026092]
	Learning Rate: 0.000260923
	LOSS [training: 0.06193675136144435 | validation: 0.03761314966059205]
	TIME [epoch: 8.52 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04169470418594223		[learning rate: 0.00026031]
	Learning Rate: 0.000260308
	LOSS [training: 0.04169470418594223 | validation: 0.04210357886108629]
	TIME [epoch: 8.54 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054604511626703545		[learning rate: 0.00025969]
	Learning Rate: 0.000259694
	LOSS [training: 0.054604511626703545 | validation: 0.030697849795140564]
	TIME [epoch: 8.51 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04124538793034362		[learning rate: 0.00025908]
	Learning Rate: 0.000259081
	LOSS [training: 0.04124538793034362 | validation: 0.027713767898267367]
	TIME [epoch: 8.51 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05266110357102376		[learning rate: 0.00025847]
	Learning Rate: 0.00025847
	LOSS [training: 0.05266110357102376 | validation: 0.028210285384888255]
	TIME [epoch: 8.52 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04099414027108807		[learning rate: 0.00025786]
	Learning Rate: 0.00025786
	LOSS [training: 0.04099414027108807 | validation: 0.025763837233419885]
	TIME [epoch: 8.53 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04273060984816731		[learning rate: 0.00025725]
	Learning Rate: 0.000257252
	LOSS [training: 0.04273060984816731 | validation: 0.027683167658838145]
	TIME [epoch: 8.52 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03783198809602796		[learning rate: 0.00025665]
	Learning Rate: 0.000256645
	LOSS [training: 0.03783198809602796 | validation: 0.04234042494833369]
	TIME [epoch: 8.52 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05052867687951938		[learning rate: 0.00025604]
	Learning Rate: 0.00025604
	LOSS [training: 0.05052867687951938 | validation: 0.023113407998807872]
	TIME [epoch: 8.52 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04202968828935677		[learning rate: 0.00025544]
	Learning Rate: 0.000255436
	LOSS [training: 0.04202968828935677 | validation: 0.03888713197196447]
	TIME [epoch: 8.54 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043417719385437016		[learning rate: 0.00025483]
	Learning Rate: 0.000254833
	LOSS [training: 0.043417719385437016 | validation: 0.01872191814846292]
	TIME [epoch: 8.51 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047191287463766544		[learning rate: 0.00025423]
	Learning Rate: 0.000254232
	LOSS [training: 0.047191287463766544 | validation: 0.04921923463141173]
	TIME [epoch: 8.52 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054371640836271454		[learning rate: 0.00025363]
	Learning Rate: 0.000253633
	LOSS [training: 0.054371640836271454 | validation: 0.029016021517502003]
	TIME [epoch: 8.55 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04182526001786539		[learning rate: 0.00025303]
	Learning Rate: 0.000253034
	LOSS [training: 0.04182526001786539 | validation: 0.03136397586944648]
	TIME [epoch: 8.53 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04509875654839538		[learning rate: 0.00025244]
	Learning Rate: 0.000252437
	LOSS [training: 0.04509875654839538 | validation: 0.03508041949106152]
	TIME [epoch: 8.52 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035080269034648934		[learning rate: 0.00025184]
	Learning Rate: 0.000251842
	LOSS [training: 0.035080269034648934 | validation: 0.0359564009853475]
	TIME [epoch: 8.51 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04011374597044471		[learning rate: 0.00025125]
	Learning Rate: 0.000251248
	LOSS [training: 0.04011374597044471 | validation: 0.024876303303865838]
	TIME [epoch: 8.53 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04992845056442732		[learning rate: 0.00025066]
	Learning Rate: 0.000250655
	LOSS [training: 0.04992845056442732 | validation: 0.024256912125445028]
	TIME [epoch: 8.54 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03676001777534123		[learning rate: 0.00025006]
	Learning Rate: 0.000250064
	LOSS [training: 0.03676001777534123 | validation: 0.034838644825597634]
	TIME [epoch: 8.53 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038934396010553096		[learning rate: 0.00024947]
	Learning Rate: 0.000249474
	LOSS [training: 0.038934396010553096 | validation: 0.05082225443380459]
	TIME [epoch: 8.52 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04776630210389477		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.04776630210389477 | validation: 0.03588460353564635]
	TIME [epoch: 8.54 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04957653498579808		[learning rate: 0.0002483]
	Learning Rate: 0.000248299
	LOSS [training: 0.04957653498579808 | validation: 0.06003252731498275]
	TIME [epoch: 8.53 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056511664923668214		[learning rate: 0.00024771]
	Learning Rate: 0.000247713
	LOSS [training: 0.056511664923668214 | validation: 0.056972736237436136]
	TIME [epoch: 8.52 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047429661231185125		[learning rate: 0.00024713]
	Learning Rate: 0.000247129
	LOSS [training: 0.047429661231185125 | validation: 0.04308598762279753]
	TIME [epoch: 8.53 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04606811986369932		[learning rate: 0.00024655]
	Learning Rate: 0.000246546
	LOSS [training: 0.04606811986369932 | validation: 0.025385528871766976]
	TIME [epoch: 8.54 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05025204759128164		[learning rate: 0.00024596]
	Learning Rate: 0.000245964
	LOSS [training: 0.05025204759128164 | validation: 0.025621506452533298]
	TIME [epoch: 8.53 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04516372643227679		[learning rate: 0.00024538]
	Learning Rate: 0.000245384
	LOSS [training: 0.04516372643227679 | validation: 0.021362691868192896]
	TIME [epoch: 8.52 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04555714628766853		[learning rate: 0.00024481]
	Learning Rate: 0.000244805
	LOSS [training: 0.04555714628766853 | validation: 0.037785192909630075]
	TIME [epoch: 8.51 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05383779489844467		[learning rate: 0.00024423]
	Learning Rate: 0.000244228
	LOSS [training: 0.05383779489844467 | validation: 0.04533261281780718]
	TIME [epoch: 8.54 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044219038560844755		[learning rate: 0.00024365]
	Learning Rate: 0.000243652
	LOSS [training: 0.044219038560844755 | validation: 0.024890505999001226]
	TIME [epoch: 8.52 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041308724056682664		[learning rate: 0.00024308]
	Learning Rate: 0.000243077
	LOSS [training: 0.041308724056682664 | validation: 0.018979665721736073]
	TIME [epoch: 8.52 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0446083690818296		[learning rate: 0.0002425]
	Learning Rate: 0.000242503
	LOSS [training: 0.0446083690818296 | validation: 0.03789111689638873]
	TIME [epoch: 8.52 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04857737755877605		[learning rate: 0.00024193]
	Learning Rate: 0.000241931
	LOSS [training: 0.04857737755877605 | validation: 0.043476059389373455]
	TIME [epoch: 8.54 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04324919842662605		[learning rate: 0.00024136]
	Learning Rate: 0.000241361
	LOSS [training: 0.04324919842662605 | validation: 0.030491840698611744]
	TIME [epoch: 8.52 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04055563192463117		[learning rate: 0.00024079]
	Learning Rate: 0.000240791
	LOSS [training: 0.04055563192463117 | validation: 0.027758553736424364]
	TIME [epoch: 8.52 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04372532727736036		[learning rate: 0.00024022]
	Learning Rate: 0.000240223
	LOSS [training: 0.04372532727736036 | validation: 0.023332330541977402]
	TIME [epoch: 8.52 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04224966370480501		[learning rate: 0.00023966]
	Learning Rate: 0.000239657
	LOSS [training: 0.04224966370480501 | validation: 0.027922061729218364]
	TIME [epoch: 8.54 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047328803160702905		[learning rate: 0.00023909]
	Learning Rate: 0.000239091
	LOSS [training: 0.047328803160702905 | validation: 0.04473117643407053]
	TIME [epoch: 8.52 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04192951066011358		[learning rate: 0.00023853]
	Learning Rate: 0.000238527
	LOSS [training: 0.04192951066011358 | validation: 0.034383407563124586]
	TIME [epoch: 8.52 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040998430472392405		[learning rate: 0.00023796]
	Learning Rate: 0.000237965
	LOSS [training: 0.040998430472392405 | validation: 0.04900039067458242]
	TIME [epoch: 8.51 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04989167545632507		[learning rate: 0.0002374]
	Learning Rate: 0.000237404
	LOSS [training: 0.04989167545632507 | validation: 0.048523070792173446]
	TIME [epoch: 8.54 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05281368089719015		[learning rate: 0.00023684]
	Learning Rate: 0.000236844
	LOSS [training: 0.05281368089719015 | validation: 0.022918802846266018]
	TIME [epoch: 8.51 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04084046766759951		[learning rate: 0.00023628]
	Learning Rate: 0.000236285
	LOSS [training: 0.04084046766759951 | validation: 0.0154696553263027]
	TIME [epoch: 8.51 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0416260715435423		[learning rate: 0.00023573]
	Learning Rate: 0.000235728
	LOSS [training: 0.0416260715435423 | validation: 0.0217312157265118]
	TIME [epoch: 8.51 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05082380252435638		[learning rate: 0.00023517]
	Learning Rate: 0.000235171
	LOSS [training: 0.05082380252435638 | validation: 0.03277336633788342]
	TIME [epoch: 8.54 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05761412405144376		[learning rate: 0.00023462]
	Learning Rate: 0.000234617
	LOSS [training: 0.05761412405144376 | validation: 0.0906448079035084]
	TIME [epoch: 8.51 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05100140857106626		[learning rate: 0.00023406]
	Learning Rate: 0.000234063
	LOSS [training: 0.05100140857106626 | validation: 0.045272845493054215]
	TIME [epoch: 8.51 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051714586914403025		[learning rate: 0.00023351]
	Learning Rate: 0.000233511
	LOSS [training: 0.051714586914403025 | validation: 0.0279584926036249]
	TIME [epoch: 8.54 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04454030297741373		[learning rate: 0.00023296]
	Learning Rate: 0.00023296
	LOSS [training: 0.04454030297741373 | validation: 0.023929552327616697]
	TIME [epoch: 8.53 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05947802723532129		[learning rate: 0.00023241]
	Learning Rate: 0.000232411
	LOSS [training: 0.05947802723532129 | validation: 0.03126434080904114]
	TIME [epoch: 8.52 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05041192120154573		[learning rate: 0.00023186]
	Learning Rate: 0.000231863
	LOSS [training: 0.05041192120154573 | validation: 0.03202903985804896]
	TIME [epoch: 8.51 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03713246390451522		[learning rate: 0.00023132]
	Learning Rate: 0.000231316
	LOSS [training: 0.03713246390451522 | validation: 0.029221600131682866]
	TIME [epoch: 8.54 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04445064447449819		[learning rate: 0.00023077]
	Learning Rate: 0.00023077
	LOSS [training: 0.04445064447449819 | validation: 0.05084637718492235]
	TIME [epoch: 8.52 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055409250206316076		[learning rate: 0.00023023]
	Learning Rate: 0.000230226
	LOSS [training: 0.055409250206316076 | validation: 0.03560082465756824]
	TIME [epoch: 8.52 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04010379297923168		[learning rate: 0.00022968]
	Learning Rate: 0.000229683
	LOSS [training: 0.04010379297923168 | validation: 0.02990920182986663]
	TIME [epoch: 8.51 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04999166390563414		[learning rate: 0.00022914]
	Learning Rate: 0.000229141
	LOSS [training: 0.04999166390563414 | validation: 0.03710720662088599]
	TIME [epoch: 8.54 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04517518409614542		[learning rate: 0.0002286]
	Learning Rate: 0.0002286
	LOSS [training: 0.04517518409614542 | validation: 0.03600791511150764]
	TIME [epoch: 8.53 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052047751494494546		[learning rate: 0.00022806]
	Learning Rate: 0.000228061
	LOSS [training: 0.052047751494494546 | validation: 0.03527531212275581]
	TIME [epoch: 8.51 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039266154632997076		[learning rate: 0.00022752]
	Learning Rate: 0.000227523
	LOSS [training: 0.039266154632997076 | validation: 0.02244321951945466]
	TIME [epoch: 8.51 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03964010004879766		[learning rate: 0.00022699]
	Learning Rate: 0.000226986
	LOSS [training: 0.03964010004879766 | validation: 0.047605771315238105]
	TIME [epoch: 8.54 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051788363416148564		[learning rate: 0.00022645]
	Learning Rate: 0.000226451
	LOSS [training: 0.051788363416148564 | validation: 0.0413723637181785]
	TIME [epoch: 8.52 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04488583643138398		[learning rate: 0.00022592]
	Learning Rate: 0.000225917
	LOSS [training: 0.04488583643138398 | validation: 0.019021493616235424]
	TIME [epoch: 8.52 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036964888255250024		[learning rate: 0.00022538]
	Learning Rate: 0.000225384
	LOSS [training: 0.036964888255250024 | validation: 0.029947321623150003]
	TIME [epoch: 8.52 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03583108649776654		[learning rate: 0.00022485]
	Learning Rate: 0.000224852
	LOSS [training: 0.03583108649776654 | validation: 0.032072865652881574]
	TIME [epoch: 8.54 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03524702107398224		[learning rate: 0.00022432]
	Learning Rate: 0.000224322
	LOSS [training: 0.03524702107398224 | validation: 0.033355593855958744]
	TIME [epoch: 8.52 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04006226102422134		[learning rate: 0.00022379]
	Learning Rate: 0.000223793
	LOSS [training: 0.04006226102422134 | validation: 0.031138567869577437]
	TIME [epoch: 8.52 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04096711485285713		[learning rate: 0.00022326]
	Learning Rate: 0.000223265
	LOSS [training: 0.04096711485285713 | validation: 0.061349850575327304]
	TIME [epoch: 8.52 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06728600862959772		[learning rate: 0.00022274]
	Learning Rate: 0.000222738
	LOSS [training: 0.06728600862959772 | validation: 0.026520242839713038]
	TIME [epoch: 8.54 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04244612200995611		[learning rate: 0.00022221]
	Learning Rate: 0.000222213
	LOSS [training: 0.04244612200995611 | validation: 0.029375132662877952]
	TIME [epoch: 8.52 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055140645059572876		[learning rate: 0.00022169]
	Learning Rate: 0.000221689
	LOSS [training: 0.055140645059572876 | validation: 0.04243870932040399]
	TIME [epoch: 8.51 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03551575174180098		[learning rate: 0.00022117]
	Learning Rate: 0.000221166
	LOSS [training: 0.03551575174180098 | validation: 0.024456001325237328]
	TIME [epoch: 8.51 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04328364792392184		[learning rate: 0.00022064]
	Learning Rate: 0.000220644
	LOSS [training: 0.04328364792392184 | validation: 0.027628687238675412]
	TIME [epoch: 8.53 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043538811778914326		[learning rate: 0.00022012]
	Learning Rate: 0.000220124
	LOSS [training: 0.043538811778914326 | validation: 0.028305570792554382]
	TIME [epoch: 8.51 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04557268771411728		[learning rate: 0.0002196]
	Learning Rate: 0.000219604
	LOSS [training: 0.04557268771411728 | validation: 0.06569664414690077]
	TIME [epoch: 8.52 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05098928587012118		[learning rate: 0.00021909]
	Learning Rate: 0.000219086
	LOSS [training: 0.05098928587012118 | validation: 0.028367611262766976]
	TIME [epoch: 8.52 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04008809694881583		[learning rate: 0.00021857]
	Learning Rate: 0.00021857
	LOSS [training: 0.04008809694881583 | validation: 0.03448389755650505]
	TIME [epoch: 8.54 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04929197258977409		[learning rate: 0.00021805]
	Learning Rate: 0.000218054
	LOSS [training: 0.04929197258977409 | validation: 0.03001333556515473]
	TIME [epoch: 8.52 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04143563296164272		[learning rate: 0.00021754]
	Learning Rate: 0.00021754
	LOSS [training: 0.04143563296164272 | validation: 0.041175362862944154]
	TIME [epoch: 8.52 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05239182889591537		[learning rate: 0.00021703]
	Learning Rate: 0.000217027
	LOSS [training: 0.05239182889591537 | validation: 0.036686130451754694]
	TIME [epoch: 8.54 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03990538493725928		[learning rate: 0.00021651]
	Learning Rate: 0.000216515
	LOSS [training: 0.03990538493725928 | validation: 0.022146236499555046]
	TIME [epoch: 8.53 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04251736052334805		[learning rate: 0.000216]
	Learning Rate: 0.000216004
	LOSS [training: 0.04251736052334805 | validation: 0.022227974041473003]
	TIME [epoch: 8.51 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03976724866106138		[learning rate: 0.00021549]
	Learning Rate: 0.000215494
	LOSS [training: 0.03976724866106138 | validation: 0.0295949476435496]
	TIME [epoch: 8.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04075148494753914		[learning rate: 0.00021499]
	Learning Rate: 0.000214986
	LOSS [training: 0.04075148494753914 | validation: 0.02750371604869136]
	TIME [epoch: 8.53 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044077224810304697		[learning rate: 0.00021448]
	Learning Rate: 0.000214479
	LOSS [training: 0.044077224810304697 | validation: 0.03372515349539953]
	TIME [epoch: 8.53 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039772708575656866		[learning rate: 0.00021397]
	Learning Rate: 0.000213973
	LOSS [training: 0.039772708575656866 | validation: 0.021749046706165398]
	TIME [epoch: 8.52 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04986502653534024		[learning rate: 0.00021347]
	Learning Rate: 0.000213468
	LOSS [training: 0.04986502653534024 | validation: 0.047159634954253044]
	TIME [epoch: 8.51 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04308853326238897		[learning rate: 0.00021296]
	Learning Rate: 0.000212965
	LOSS [training: 0.04308853326238897 | validation: 0.07677418813523568]
	TIME [epoch: 8.53 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05441689342567783		[learning rate: 0.00021246]
	Learning Rate: 0.000212462
	LOSS [training: 0.05441689342567783 | validation: 0.019644739610595797]
	TIME [epoch: 8.51 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057160524095113074		[learning rate: 0.00021196]
	Learning Rate: 0.000211961
	LOSS [training: 0.057160524095113074 | validation: 0.042615071178773715]
	TIME [epoch: 8.51 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03801011380350735		[learning rate: 0.00021146]
	Learning Rate: 0.000211461
	LOSS [training: 0.03801011380350735 | validation: 0.023336974194654227]
	TIME [epoch: 8.51 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03809788257988867		[learning rate: 0.00021096]
	Learning Rate: 0.000210962
	LOSS [training: 0.03809788257988867 | validation: 0.021673003735159846]
	TIME [epoch: 8.54 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040702774901820074		[learning rate: 0.00021046]
	Learning Rate: 0.000210465
	LOSS [training: 0.040702774901820074 | validation: 0.062172685095094424]
	TIME [epoch: 8.52 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052217744111840644		[learning rate: 0.00020997]
	Learning Rate: 0.000209968
	LOSS [training: 0.052217744111840644 | validation: 0.024072545055597028]
	TIME [epoch: 8.52 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05089686977770188		[learning rate: 0.00020947]
	Learning Rate: 0.000209473
	LOSS [training: 0.05089686977770188 | validation: 0.047243355283775476]
	TIME [epoch: 8.52 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058809933868470624		[learning rate: 0.00020898]
	Learning Rate: 0.000208979
	LOSS [training: 0.058809933868470624 | validation: 0.03421934386834188]
	TIME [epoch: 8.55 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046785271412209804		[learning rate: 0.00020849]
	Learning Rate: 0.000208486
	LOSS [training: 0.046785271412209804 | validation: 0.02801131139536952]
	TIME [epoch: 8.52 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872021347783518		[learning rate: 0.00020799]
	Learning Rate: 0.000207994
	LOSS [training: 0.03872021347783518 | validation: 0.03975762663454965]
	TIME [epoch: 8.52 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042427593050269885		[learning rate: 0.0002075]
	Learning Rate: 0.000207504
	LOSS [training: 0.042427593050269885 | validation: 0.040666702050057936]
	TIME [epoch: 8.52 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04431661825051117		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.04431661825051117 | validation: 0.02139795394319257]
	TIME [epoch: 8.55 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044431235764535205		[learning rate: 0.00020653]
	Learning Rate: 0.000206526
	LOSS [training: 0.044431235764535205 | validation: 0.029889549075713267]
	TIME [epoch: 8.52 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043622099902442306		[learning rate: 0.00020604]
	Learning Rate: 0.000206039
	LOSS [training: 0.043622099902442306 | validation: 0.03522576004183219]
	TIME [epoch: 8.51 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03561747254842206		[learning rate: 0.00020555]
	Learning Rate: 0.000205553
	LOSS [training: 0.03561747254842206 | validation: 0.03318694550574739]
	TIME [epoch: 8.52 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047244436772212794		[learning rate: 0.00020507]
	Learning Rate: 0.000205068
	LOSS [training: 0.047244436772212794 | validation: 0.04572429853177702]
	TIME [epoch: 8.54 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04281995179192564		[learning rate: 0.00020458]
	Learning Rate: 0.000204584
	LOSS [training: 0.04281995179192564 | validation: 0.025333257800356432]
	TIME [epoch: 8.52 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046914798639157776		[learning rate: 0.0002041]
	Learning Rate: 0.000204101
	LOSS [training: 0.046914798639157776 | validation: 0.03023384398409888]
	TIME [epoch: 8.51 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040072827189790966		[learning rate: 0.00020362]
	Learning Rate: 0.00020362
	LOSS [training: 0.040072827189790966 | validation: 0.018607525013536505]
	TIME [epoch: 8.52 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04152150636300611		[learning rate: 0.00020314]
	Learning Rate: 0.00020314
	LOSS [training: 0.04152150636300611 | validation: 0.02434938929957539]
	TIME [epoch: 8.54 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054255677007269576		[learning rate: 0.00020266]
	Learning Rate: 0.000202661
	LOSS [training: 0.054255677007269576 | validation: 0.033253214862978143]
	TIME [epoch: 8.52 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03853748918002266		[learning rate: 0.00020218]
	Learning Rate: 0.000202182
	LOSS [training: 0.03853748918002266 | validation: 0.024117065106104195]
	TIME [epoch: 8.52 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038361735033559795		[learning rate: 0.00020171]
	Learning Rate: 0.000201706
	LOSS [training: 0.038361735033559795 | validation: 0.028999921521095734]
	TIME [epoch: 8.53 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040385285229851645		[learning rate: 0.00020123]
	Learning Rate: 0.00020123
	LOSS [training: 0.040385285229851645 | validation: 0.021149598243035066]
	TIME [epoch: 8.53 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04041857569365516		[learning rate: 0.00020076]
	Learning Rate: 0.000200755
	LOSS [training: 0.04041857569365516 | validation: 0.021629347551895207]
	TIME [epoch: 8.52 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03916469075545479		[learning rate: 0.00020028]
	Learning Rate: 0.000200282
	LOSS [training: 0.03916469075545479 | validation: 0.041179895704814354]
	TIME [epoch: 8.53 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03862001312822639		[learning rate: 0.00019981]
	Learning Rate: 0.000199809
	LOSS [training: 0.03862001312822639 | validation: 0.03573586033743312]
	TIME [epoch: 8.54 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03892382018616981		[learning rate: 0.00019934]
	Learning Rate: 0.000199338
	LOSS [training: 0.03892382018616981 | validation: 0.02031554747487237]
	TIME [epoch: 8.54 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047921769108332554		[learning rate: 0.00019887]
	Learning Rate: 0.000198868
	LOSS [training: 0.047921769108332554 | validation: 0.027397512538720543]
	TIME [epoch: 8.52 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04131321773318268		[learning rate: 0.0001984]
	Learning Rate: 0.000198398
	LOSS [training: 0.04131321773318268 | validation: 0.02842953407071111]
	TIME [epoch: 8.52 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04644722809077148		[learning rate: 0.00019793]
	Learning Rate: 0.000197931
	LOSS [training: 0.04644722809077148 | validation: 0.024467069699713954]
	TIME [epoch: 8.54 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039118903945157595		[learning rate: 0.00019746]
	Learning Rate: 0.000197464
	LOSS [training: 0.039118903945157595 | validation: 0.025171047865230403]
	TIME [epoch: 8.52 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04520782610167163		[learning rate: 0.000197]
	Learning Rate: 0.000196998
	LOSS [training: 0.04520782610167163 | validation: 0.04164641152345624]
	TIME [epoch: 8.53 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039839455202158175		[learning rate: 0.00019653]
	Learning Rate: 0.000196533
	LOSS [training: 0.039839455202158175 | validation: 0.025984959368657086]
	TIME [epoch: 8.52 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03650459368257945		[learning rate: 0.00019607]
	Learning Rate: 0.00019607
	LOSS [training: 0.03650459368257945 | validation: 0.037961062244583635]
	TIME [epoch: 8.54 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04157235087846959		[learning rate: 0.00019561]
	Learning Rate: 0.000195607
	LOSS [training: 0.04157235087846959 | validation: 0.026148458123864255]
	TIME [epoch: 8.52 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039480799900394214		[learning rate: 0.00019515]
	Learning Rate: 0.000195146
	LOSS [training: 0.039480799900394214 | validation: 0.02286882784948341]
	TIME [epoch: 8.52 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038826183557214344		[learning rate: 0.00019469]
	Learning Rate: 0.000194685
	LOSS [training: 0.038826183557214344 | validation: 0.03434733360114701]
	TIME [epoch: 8.53 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07204123103848509		[learning rate: 0.00019423]
	Learning Rate: 0.000194226
	LOSS [training: 0.07204123103848509 | validation: 0.04837977460508053]
	TIME [epoch: 8.55 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04517031152074301		[learning rate: 0.00019377]
	Learning Rate: 0.000193768
	LOSS [training: 0.04517031152074301 | validation: 0.019073591939231943]
	TIME [epoch: 8.53 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04141971031949924		[learning rate: 0.00019331]
	Learning Rate: 0.000193311
	LOSS [training: 0.04141971031949924 | validation: 0.033214409887842244]
	TIME [epoch: 8.51 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05438595332271791		[learning rate: 0.00019285]
	Learning Rate: 0.000192855
	LOSS [training: 0.05438595332271791 | validation: 0.03464099176431886]
	TIME [epoch: 8.52 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044658151788470254		[learning rate: 0.0001924]
	Learning Rate: 0.0001924
	LOSS [training: 0.044658151788470254 | validation: 0.025184549844578588]
	TIME [epoch: 8.55 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04922522511163545		[learning rate: 0.00019195]
	Learning Rate: 0.000191946
	LOSS [training: 0.04922522511163545 | validation: 0.019930833724162326]
	TIME [epoch: 8.52 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04471398157917039		[learning rate: 0.00019149]
	Learning Rate: 0.000191493
	LOSS [training: 0.04471398157917039 | validation: 0.03476930239540045]
	TIME [epoch: 8.52 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050598855722294014		[learning rate: 0.00019104]
	Learning Rate: 0.000191042
	LOSS [training: 0.050598855722294014 | validation: 0.03949103442379519]
	TIME [epoch: 8.52 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0481400671043928		[learning rate: 0.00019059]
	Learning Rate: 0.000190591
	LOSS [training: 0.0481400671043928 | validation: 0.03501997154093713]
	TIME [epoch: 8.54 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047435752578605786		[learning rate: 0.00019014]
	Learning Rate: 0.000190141
	LOSS [training: 0.047435752578605786 | validation: 0.027224165055658278]
	TIME [epoch: 8.52 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03829371505746245		[learning rate: 0.00018969]
	Learning Rate: 0.000189693
	LOSS [training: 0.03829371505746245 | validation: 0.028681618272006888]
	TIME [epoch: 8.52 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04351067677029245		[learning rate: 0.00018925]
	Learning Rate: 0.000189245
	LOSS [training: 0.04351067677029245 | validation: 0.024719749311582467]
	TIME [epoch: 8.53 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044775277110055675		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.044775277110055675 | validation: 0.026326443142530152]
	TIME [epoch: 8.54 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04626774428187598		[learning rate: 0.00018835]
	Learning Rate: 0.000188354
	LOSS [training: 0.04626774428187598 | validation: 0.04572737990758999]
	TIME [epoch: 8.52 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04320493208936667		[learning rate: 0.00018791]
	Learning Rate: 0.000187909
	LOSS [training: 0.04320493208936667 | validation: 0.035353918677862764]
	TIME [epoch: 8.52 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04557679214604627		[learning rate: 0.00018747]
	Learning Rate: 0.000187466
	LOSS [training: 0.04557679214604627 | validation: 0.03216463155347844]
	TIME [epoch: 8.53 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05246324330966262		[learning rate: 0.00018702]
	Learning Rate: 0.000187024
	LOSS [training: 0.05246324330966262 | validation: 0.019015813183653273]
	TIME [epoch: 8.53 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04071430823104164		[learning rate: 0.00018658]
	Learning Rate: 0.000186583
	LOSS [training: 0.04071430823104164 | validation: 0.04518931881600137]
	TIME [epoch: 8.52 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04726541243880159		[learning rate: 0.00018614]
	Learning Rate: 0.000186143
	LOSS [training: 0.04726541243880159 | validation: 0.04056947708280979]
	TIME [epoch: 8.51 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04347409856470663		[learning rate: 0.0001857]
	Learning Rate: 0.000185704
	LOSS [training: 0.04347409856470663 | validation: 0.030010027040612515]
	TIME [epoch: 8.52 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04411552252271887		[learning rate: 0.00018527]
	Learning Rate: 0.000185266
	LOSS [training: 0.04411552252271887 | validation: 0.0183351709558282]
	TIME [epoch: 8.53 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044926108038872474		[learning rate: 0.00018483]
	Learning Rate: 0.000184829
	LOSS [training: 0.044926108038872474 | validation: 0.02600856537274148]
	TIME [epoch: 8.52 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04297003818141673		[learning rate: 0.00018439]
	Learning Rate: 0.000184393
	LOSS [training: 0.04297003818141673 | validation: 0.025437726048186865]
	TIME [epoch: 8.52 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039734863304105306		[learning rate: 0.00018396]
	Learning Rate: 0.000183958
	LOSS [training: 0.039734863304105306 | validation: 0.029556257454200943]
	TIME [epoch: 8.54 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04091379004585959		[learning rate: 0.00018352]
	Learning Rate: 0.000183524
	LOSS [training: 0.04091379004585959 | validation: 0.0282276687786606]
	TIME [epoch: 8.53 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04117592417573875		[learning rate: 0.00018309]
	Learning Rate: 0.000183091
	LOSS [training: 0.04117592417573875 | validation: 0.030469470000198565]
	TIME [epoch: 8.52 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053462958032207256		[learning rate: 0.00018266]
	Learning Rate: 0.000182659
	LOSS [training: 0.053462958032207256 | validation: 0.05292761594720395]
	TIME [epoch: 8.53 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04121689178696049		[learning rate: 0.00018223]
	Learning Rate: 0.000182228
	LOSS [training: 0.04121689178696049 | validation: 0.027504720868969545]
	TIME [epoch: 8.54 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04609134987156983		[learning rate: 0.0001818]
	Learning Rate: 0.000181798
	LOSS [training: 0.04609134987156983 | validation: 0.023333488097621535]
	TIME [epoch: 8.52 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0384618208545839		[learning rate: 0.00018137]
	Learning Rate: 0.000181369
	LOSS [training: 0.0384618208545839 | validation: 0.029255189561670177]
	TIME [epoch: 8.51 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034572831411108416		[learning rate: 0.00018094]
	Learning Rate: 0.000180942
	LOSS [training: 0.034572831411108416 | validation: 0.02968292593940694]
	TIME [epoch: 8.52 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03820004553860248		[learning rate: 0.00018051]
	Learning Rate: 0.000180515
	LOSS [training: 0.03820004553860248 | validation: 0.023020503198317055]
	TIME [epoch: 8.54 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04300500024174954		[learning rate: 0.00018009]
	Learning Rate: 0.000180089
	LOSS [training: 0.04300500024174954 | validation: 0.02585313235401658]
	TIME [epoch: 8.52 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0398362729859139		[learning rate: 0.00017966]
	Learning Rate: 0.000179664
	LOSS [training: 0.0398362729859139 | validation: 0.028681860158544764]
	TIME [epoch: 8.52 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04480885702994891		[learning rate: 0.00017924]
	Learning Rate: 0.00017924
	LOSS [training: 0.04480885702994891 | validation: 0.03610519711401208]
	TIME [epoch: 8.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04201296358506397		[learning rate: 0.00017882]
	Learning Rate: 0.000178818
	LOSS [training: 0.04201296358506397 | validation: 0.02766837458658023]
	TIME [epoch: 8.54 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035098347688425804		[learning rate: 0.0001784]
	Learning Rate: 0.000178396
	LOSS [training: 0.035098347688425804 | validation: 0.04611851136194417]
	TIME [epoch: 8.52 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04297044676655752		[learning rate: 0.00017797]
	Learning Rate: 0.000177975
	LOSS [training: 0.04297044676655752 | validation: 0.03245963396020218]
	TIME [epoch: 8.52 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045126128417845426		[learning rate: 0.00017756]
	Learning Rate: 0.000177555
	LOSS [training: 0.045126128417845426 | validation: 0.03424999181808252]
	TIME [epoch: 8.53 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0472275045070923		[learning rate: 0.00017714]
	Learning Rate: 0.000177136
	LOSS [training: 0.0472275045070923 | validation: 0.033574140925176625]
	TIME [epoch: 8.55 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872512050541302		[learning rate: 0.00017672]
	Learning Rate: 0.000176718
	LOSS [training: 0.03872512050541302 | validation: 0.02443337212393503]
	TIME [epoch: 8.52 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036922371515296946		[learning rate: 0.0001763]
	Learning Rate: 0.000176302
	LOSS [training: 0.036922371515296946 | validation: 0.02780701260676025]
	TIME [epoch: 8.52 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039593462389485384		[learning rate: 0.00017589]
	Learning Rate: 0.000175886
	LOSS [training: 0.039593462389485384 | validation: 0.029551670288081498]
	TIME [epoch: 8.52 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03567641746260315		[learning rate: 0.00017547]
	Learning Rate: 0.000175471
	LOSS [training: 0.03567641746260315 | validation: 0.018060263432103728]
	TIME [epoch: 8.54 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039568034374121555		[learning rate: 0.00017506]
	Learning Rate: 0.000175057
	LOSS [training: 0.039568034374121555 | validation: 0.03504349882268244]
	TIME [epoch: 8.52 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039905318853612856		[learning rate: 0.00017464]
	Learning Rate: 0.000174644
	LOSS [training: 0.039905318853612856 | validation: 0.031310304812203454]
	TIME [epoch: 8.52 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0429426582219541		[learning rate: 0.00017423]
	Learning Rate: 0.000174232
	LOSS [training: 0.0429426582219541 | validation: 0.03870096270974738]
	TIME [epoch: 8.53 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03881610825559719		[learning rate: 0.00017382]
	Learning Rate: 0.000173821
	LOSS [training: 0.03881610825559719 | validation: 0.025432353917866437]
	TIME [epoch: 8.55 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04160933149199957		[learning rate: 0.00017341]
	Learning Rate: 0.000173411
	LOSS [training: 0.04160933149199957 | validation: 0.03162048532143016]
	TIME [epoch: 8.52 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038059986368175446		[learning rate: 0.000173]
	Learning Rate: 0.000173002
	LOSS [training: 0.038059986368175446 | validation: 0.027930586292238477]
	TIME [epoch: 8.51 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04106307963551131		[learning rate: 0.00017259]
	Learning Rate: 0.000172594
	LOSS [training: 0.04106307963551131 | validation: 0.05113512528160977]
	TIME [epoch: 8.53 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055383015769808655		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.055383015769808655 | validation: 0.030941807485214898]
	TIME [epoch: 8.53 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04198375919080859		[learning rate: 0.00017178]
	Learning Rate: 0.000171781
	LOSS [training: 0.04198375919080859 | validation: 0.030910750605645985]
	TIME [epoch: 8.53 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04814613921966567		[learning rate: 0.00017138]
	Learning Rate: 0.000171375
	LOSS [training: 0.04814613921966567 | validation: 0.033112948804487105]
	TIME [epoch: 8.51 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04144887711989449		[learning rate: 0.00017097]
	Learning Rate: 0.000170971
	LOSS [training: 0.04144887711989449 | validation: 0.027157820593191995]
	TIME [epoch: 8.52 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040852714661846756		[learning rate: 0.00017057]
	Learning Rate: 0.000170568
	LOSS [training: 0.040852714661846756 | validation: 0.035007667440958415]
	TIME [epoch: 8.53 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04232244961329418		[learning rate: 0.00017017]
	Learning Rate: 0.000170166
	LOSS [training: 0.04232244961329418 | validation: 0.017606991375964533]
	TIME [epoch: 8.51 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0412972495220057		[learning rate: 0.00016976]
	Learning Rate: 0.000169764
	LOSS [training: 0.0412972495220057 | validation: 0.03091080292610275]
	TIME [epoch: 8.52 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052254948128964016		[learning rate: 0.00016936]
	Learning Rate: 0.000169364
	LOSS [training: 0.052254948128964016 | validation: 0.03186492134523625]
	TIME [epoch: 8.53 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0420704495545022		[learning rate: 0.00016896]
	Learning Rate: 0.000168964
	LOSS [training: 0.0420704495545022 | validation: 0.025408191669178997]
	TIME [epoch: 8.52 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038102070102084336		[learning rate: 0.00016857]
	Learning Rate: 0.000168566
	LOSS [training: 0.038102070102084336 | validation: 0.023954936895687767]
	TIME [epoch: 8.53 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03804724960494947		[learning rate: 0.00016817]
	Learning Rate: 0.000168168
	LOSS [training: 0.03804724960494947 | validation: 0.017808673498638274]
	TIME [epoch: 8.52 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03930244669231224		[learning rate: 0.00016777]
	Learning Rate: 0.000167771
	LOSS [training: 0.03930244669231224 | validation: 0.024613210188195164]
	TIME [epoch: 8.55 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03750289873974594		[learning rate: 0.00016738]
	Learning Rate: 0.000167376
	LOSS [training: 0.03750289873974594 | validation: 0.02799179849994582]
	TIME [epoch: 8.52 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04722464032701962		[learning rate: 0.00016698]
	Learning Rate: 0.000166981
	LOSS [training: 0.04722464032701962 | validation: 0.04911621795789928]
	TIME [epoch: 8.52 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049364958782204614		[learning rate: 0.00016659]
	Learning Rate: 0.000166587
	LOSS [training: 0.049364958782204614 | validation: 0.025549308468692085]
	TIME [epoch: 8.52 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038126310461393316		[learning rate: 0.00016619]
	Learning Rate: 0.000166194
	LOSS [training: 0.038126310461393316 | validation: 0.02018873552257383]
	TIME [epoch: 8.55 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03931675832659025		[learning rate: 0.0001658]
	Learning Rate: 0.000165802
	LOSS [training: 0.03931675832659025 | validation: 0.019670550708691382]
	TIME [epoch: 8.52 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03428891312577232		[learning rate: 0.00016541]
	Learning Rate: 0.000165411
	LOSS [training: 0.03428891312577232 | validation: 0.02588823883877408]
	TIME [epoch: 8.53 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038698721206309766		[learning rate: 0.00016502]
	Learning Rate: 0.000165021
	LOSS [training: 0.038698721206309766 | validation: 0.016161472787993104]
	TIME [epoch: 8.52 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03907988399810099		[learning rate: 0.00016463]
	Learning Rate: 0.000164631
	LOSS [training: 0.03907988399810099 | validation: 0.025676150374932358]
	TIME [epoch: 8.55 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05589351601406241		[learning rate: 0.00016424]
	Learning Rate: 0.000164243
	LOSS [training: 0.05589351601406241 | validation: 0.03196426815672701]
	TIME [epoch: 8.53 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04270263107777947		[learning rate: 0.00016386]
	Learning Rate: 0.000163856
	LOSS [training: 0.04270263107777947 | validation: 0.035885970557210566]
	TIME [epoch: 8.52 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044458270094860114		[learning rate: 0.00016347]
	Learning Rate: 0.000163469
	LOSS [training: 0.044458270094860114 | validation: 0.031163382547808847]
	TIME [epoch: 8.52 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04360530383955106		[learning rate: 0.00016308]
	Learning Rate: 0.000163084
	LOSS [training: 0.04360530383955106 | validation: 0.0333838652182694]
	TIME [epoch: 8.55 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038325127449394564		[learning rate: 0.0001627]
	Learning Rate: 0.000162699
	LOSS [training: 0.038325127449394564 | validation: 0.025229317574267246]
	TIME [epoch: 8.52 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042847122330227486		[learning rate: 0.00016232]
	Learning Rate: 0.000162315
	LOSS [training: 0.042847122330227486 | validation: 0.020318992026178918]
	TIME [epoch: 8.52 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042923925087948574		[learning rate: 0.00016193]
	Learning Rate: 0.000161932
	LOSS [training: 0.042923925087948574 | validation: 0.021469109196430917]
	TIME [epoch: 8.53 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03813738731905675		[learning rate: 0.00016155]
	Learning Rate: 0.00016155
	LOSS [training: 0.03813738731905675 | validation: 0.03253084619782791]
	TIME [epoch: 8.55 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03849692058360939		[learning rate: 0.00016117]
	Learning Rate: 0.000161169
	LOSS [training: 0.03849692058360939 | validation: 0.021961994295822778]
	TIME [epoch: 8.52 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03680860334220604		[learning rate: 0.00016079]
	Learning Rate: 0.000160789
	LOSS [training: 0.03680860334220604 | validation: 0.030882182526977713]
	TIME [epoch: 8.52 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04100283144543181		[learning rate: 0.00016041]
	Learning Rate: 0.00016041
	LOSS [training: 0.04100283144543181 | validation: 0.028283671130283426]
	TIME [epoch: 8.53 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0340041704637778		[learning rate: 0.00016003]
	Learning Rate: 0.000160031
	LOSS [training: 0.0340041704637778 | validation: 0.015840545787131524]
	TIME [epoch: 8.53 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040691965098972445		[learning rate: 0.00015965]
	Learning Rate: 0.000159654
	LOSS [training: 0.040691965098972445 | validation: 0.041360958038065804]
	TIME [epoch: 8.52 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04346213823426033		[learning rate: 0.00015928]
	Learning Rate: 0.000159277
	LOSS [training: 0.04346213823426033 | validation: 0.029016871048185757]
	TIME [epoch: 8.52 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04452846803769261		[learning rate: 0.0001589]
	Learning Rate: 0.000158902
	LOSS [training: 0.04452846803769261 | validation: 0.026577737963338302]
	TIME [epoch: 8.53 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04022305811650031		[learning rate: 0.00015853]
	Learning Rate: 0.000158527
	LOSS [training: 0.04022305811650031 | validation: 0.02778810068249122]
	TIME [epoch: 8.53 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043479155485790275		[learning rate: 0.00015815]
	Learning Rate: 0.000158153
	LOSS [training: 0.043479155485790275 | validation: 0.020690097743362855]
	TIME [epoch: 8.51 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046509500229711044		[learning rate: 0.00015778]
	Learning Rate: 0.00015778
	LOSS [training: 0.046509500229711044 | validation: 0.027294303951061666]
	TIME [epoch: 8.52 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04218848919683216		[learning rate: 0.00015741]
	Learning Rate: 0.000157408
	LOSS [training: 0.04218848919683216 | validation: 0.030816708281333108]
	TIME [epoch: 8.54 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04512472128467728		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.04512472128467728 | validation: 0.019742972759920527]
	TIME [epoch: 8.52 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054185639202632294		[learning rate: 0.00015667]
	Learning Rate: 0.000156666
	LOSS [training: 0.054185639202632294 | validation: 0.028988906229143022]
	TIME [epoch: 8.51 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0437929769384746		[learning rate: 0.0001563]
	Learning Rate: 0.000156296
	LOSS [training: 0.0437929769384746 | validation: 0.021634137968226663]
	TIME [epoch: 8.52 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03494092118085575		[learning rate: 0.00015593]
	Learning Rate: 0.000155928
	LOSS [training: 0.03494092118085575 | validation: 0.03685006811949036]
	TIME [epoch: 8.53 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04140754776593271		[learning rate: 0.00015556]
	Learning Rate: 0.00015556
	LOSS [training: 0.04140754776593271 | validation: 0.022734682946061034]
	TIME [epoch: 8.52 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04484560865869945		[learning rate: 0.00015519]
	Learning Rate: 0.000155193
	LOSS [training: 0.04484560865869945 | validation: 0.03516020339914899]
	TIME [epoch: 8.52 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0414276255297646		[learning rate: 0.00015483]
	Learning Rate: 0.000154827
	LOSS [training: 0.0414276255297646 | validation: 0.03244525918866297]
	TIME [epoch: 8.52 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03912206000649602		[learning rate: 0.00015446]
	Learning Rate: 0.000154462
	LOSS [training: 0.03912206000649602 | validation: 0.03228876253509577]
	TIME [epoch: 8.54 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039050716702667125		[learning rate: 0.0001541]
	Learning Rate: 0.000154097
	LOSS [training: 0.039050716702667125 | validation: 0.02380217043106745]
	TIME [epoch: 8.51 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282276907024547		[learning rate: 0.00015373]
	Learning Rate: 0.000153734
	LOSS [training: 0.04282276907024547 | validation: 0.022428499133322788]
	TIME [epoch: 8.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03777090909330853		[learning rate: 0.00015337]
	Learning Rate: 0.000153371
	LOSS [training: 0.03777090909330853 | validation: 0.015273218226919488]
	TIME [epoch: 8.51 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03573074988028682		[learning rate: 0.00015301]
	Learning Rate: 0.000153009
	LOSS [training: 0.03573074988028682 | validation: 0.018176100853105115]
	TIME [epoch: 8.54 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03704237280639858		[learning rate: 0.00015265]
	Learning Rate: 0.000152648
	LOSS [training: 0.03704237280639858 | validation: 0.01991252746948704]
	TIME [epoch: 8.52 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03604991807019216		[learning rate: 0.00015229]
	Learning Rate: 0.000152288
	LOSS [training: 0.03604991807019216 | validation: 0.022135795985095515]
	TIME [epoch: 8.52 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04166538565841529		[learning rate: 0.00015193]
	Learning Rate: 0.000151929
	LOSS [training: 0.04166538565841529 | validation: 0.03995291517809046]
	TIME [epoch: 8.52 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03538430850331442		[learning rate: 0.00015157]
	Learning Rate: 0.000151571
	LOSS [training: 0.03538430850331442 | validation: 0.028433964297086563]
	TIME [epoch: 8.54 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03925800347592098		[learning rate: 0.00015121]
	Learning Rate: 0.000151213
	LOSS [training: 0.03925800347592098 | validation: 0.027940050737231513]
	TIME [epoch: 8.53 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0472592758830433		[learning rate: 0.00015086]
	Learning Rate: 0.000150857
	LOSS [training: 0.0472592758830433 | validation: 0.02463783201810964]
	TIME [epoch: 8.52 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04011841007824814		[learning rate: 0.0001505]
	Learning Rate: 0.000150501
	LOSS [training: 0.04011841007824814 | validation: 0.02670064827954367]
	TIME [epoch: 8.52 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03793029807896822		[learning rate: 0.00015015]
	Learning Rate: 0.000150146
	LOSS [training: 0.03793029807896822 | validation: 0.04668495475034602]
	TIME [epoch: 8.53 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038249726841399004		[learning rate: 0.00014979]
	Learning Rate: 0.000149791
	LOSS [training: 0.038249726841399004 | validation: 0.020645582821466536]
	TIME [epoch: 8.52 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03561421268718542		[learning rate: 0.00014944]
	Learning Rate: 0.000149438
	LOSS [training: 0.03561421268718542 | validation: 0.018963039114094936]
	TIME [epoch: 8.53 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04236329894371922		[learning rate: 0.00014909]
	Learning Rate: 0.000149086
	LOSS [training: 0.04236329894371922 | validation: 0.03979646786633098]
	TIME [epoch: 8.54 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038834321701407236		[learning rate: 0.00014873]
	Learning Rate: 0.000148734
	LOSS [training: 0.038834321701407236 | validation: 0.010061039902412538]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study4/model_tr_study4_r2_20240219_184940/states/model_tr_study4_1832.pth
	Model improved!!!
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03623376658601433		[learning rate: 0.00014838]
	Learning Rate: 0.000148383
	LOSS [training: 0.03623376658601433 | validation: 0.024267229676147653]
	TIME [epoch: 8.51 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03844565335941916		[learning rate: 0.00014803]
	Learning Rate: 0.000148033
	LOSS [training: 0.03844565335941916 | validation: 0.021724255201171085]
	TIME [epoch: 8.52 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04116617870026263		[learning rate: 0.00014768]
	Learning Rate: 0.000147684
	LOSS [training: 0.04116617870026263 | validation: 0.025558780280105168]
	TIME [epoch: 8.53 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042489489005067785		[learning rate: 0.00014734]
	Learning Rate: 0.000147336
	LOSS [training: 0.042489489005067785 | validation: 0.026314888363253484]
	TIME [epoch: 8.52 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03716347222276284		[learning rate: 0.00014699]
	Learning Rate: 0.000146988
	LOSS [training: 0.03716347222276284 | validation: 0.018867406920458865]
	TIME [epoch: 8.52 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0406430202315087		[learning rate: 0.00014664]
	Learning Rate: 0.000146641
	LOSS [training: 0.0406430202315087 | validation: 0.03582954350060451]
	TIME [epoch: 8.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04534987869619444		[learning rate: 0.0001463]
	Learning Rate: 0.000146295
	LOSS [training: 0.04534987869619444 | validation: 0.027651083257037225]
	TIME [epoch: 8.54 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0484194247753461		[learning rate: 0.00014595]
	Learning Rate: 0.00014595
	LOSS [training: 0.0484194247753461 | validation: 0.03595564649443542]
	TIME [epoch: 8.52 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03784243254517575		[learning rate: 0.00014561]
	Learning Rate: 0.000145606
	LOSS [training: 0.03784243254517575 | validation: 0.026906128693272986]
	TIME [epoch: 8.53 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04184650702249358		[learning rate: 0.00014526]
	Learning Rate: 0.000145263
	LOSS [training: 0.04184650702249358 | validation: 0.025792436909289583]
	TIME [epoch: 8.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04248559567767402		[learning rate: 0.00014492]
	Learning Rate: 0.00014492
	LOSS [training: 0.04248559567767402 | validation: 0.03130813551549484]
	TIME [epoch: 8.54 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04722907940958112		[learning rate: 0.00014458]
	Learning Rate: 0.000144578
	LOSS [training: 0.04722907940958112 | validation: 0.03277867892964727]
	TIME [epoch: 8.52 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046278384975678426		[learning rate: 0.00014424]
	Learning Rate: 0.000144237
	LOSS [training: 0.046278384975678426 | validation: 0.019250407725337433]
	TIME [epoch: 8.51 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036699446970699115		[learning rate: 0.0001439]
	Learning Rate: 0.000143897
	LOSS [training: 0.036699446970699115 | validation: 0.025489279939997757]
	TIME [epoch: 8.51 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03605311844687134		[learning rate: 0.00014356]
	Learning Rate: 0.000143557
	LOSS [training: 0.03605311844687134 | validation: 0.019582689550747993]
	TIME [epoch: 8.54 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03597939354442927		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.03597939354442927 | validation: 0.027364377925182662]
	TIME [epoch: 8.52 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038370329652056626		[learning rate: 0.00014288]
	Learning Rate: 0.000142881
	LOSS [training: 0.038370329652056626 | validation: 0.025778529153576334]
	TIME [epoch: 8.52 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03962468128930586		[learning rate: 0.00014254]
	Learning Rate: 0.000142544
	LOSS [training: 0.03962468128930586 | validation: 0.02114702702257379]
	TIME [epoch: 8.51 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03765534170338504		[learning rate: 0.00014221]
	Learning Rate: 0.000142208
	LOSS [training: 0.03765534170338504 | validation: 0.012527791808931429]
	TIME [epoch: 8.54 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03433391599969718		[learning rate: 0.00014187]
	Learning Rate: 0.000141872
	LOSS [training: 0.03433391599969718 | validation: 0.023914252536448806]
	TIME [epoch: 8.51 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04184441699315299		[learning rate: 0.00014154]
	Learning Rate: 0.000141538
	LOSS [training: 0.04184441699315299 | validation: 0.027217355638464724]
	TIME [epoch: 8.51 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042815097354477125		[learning rate: 0.0001412]
	Learning Rate: 0.000141204
	LOSS [training: 0.042815097354477125 | validation: 0.026306699635555646]
	TIME [epoch: 8.52 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03852044605434818		[learning rate: 0.00014087]
	Learning Rate: 0.000140871
	LOSS [training: 0.03852044605434818 | validation: 0.018907475632482403]
	TIME [epoch: 8.54 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035949575327275975		[learning rate: 0.00014054]
	Learning Rate: 0.000140538
	LOSS [training: 0.035949575327275975 | validation: 0.022643263836864918]
	TIME [epoch: 8.51 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03817131256770179		[learning rate: 0.00014021]
	Learning Rate: 0.000140207
	LOSS [training: 0.03817131256770179 | validation: 0.03308394898242288]
	TIME [epoch: 8.52 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042600162486586914		[learning rate: 0.00013988]
	Learning Rate: 0.000139876
	LOSS [training: 0.042600162486586914 | validation: 0.016306602447997573]
	TIME [epoch: 8.52 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03671035772620377		[learning rate: 0.00013955]
	Learning Rate: 0.000139546
	LOSS [training: 0.03671035772620377 | validation: 0.029775045961659835]
	TIME [epoch: 8.54 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041710122359613265		[learning rate: 0.00013922]
	Learning Rate: 0.000139217
	LOSS [training: 0.041710122359613265 | validation: 0.04084420505496928]
	TIME [epoch: 8.52 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03758786581315005		[learning rate: 0.00013889]
	Learning Rate: 0.000138889
	LOSS [training: 0.03758786581315005 | validation: 0.02261948093475138]
	TIME [epoch: 8.51 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04291630406707299		[learning rate: 0.00013856]
	Learning Rate: 0.000138561
	LOSS [training: 0.04291630406707299 | validation: 0.026802084851366113]
	TIME [epoch: 8.53 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03707624869092018		[learning rate: 0.00013823]
	Learning Rate: 0.000138234
	LOSS [training: 0.03707624869092018 | validation: 0.03183333547618279]
	TIME [epoch: 8.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036740837956637316		[learning rate: 0.00013791]
	Learning Rate: 0.000137908
	LOSS [training: 0.036740837956637316 | validation: 0.026302442004619432]
	TIME [epoch: 8.51 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04194050794094463		[learning rate: 0.00013758]
	Learning Rate: 0.000137583
	LOSS [training: 0.04194050794094463 | validation: 0.02504159423777974]
	TIME [epoch: 8.51 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04247793094655681		[learning rate: 0.00013726]
	Learning Rate: 0.000137258
	LOSS [training: 0.04247793094655681 | validation: 0.028150255232909698]
	TIME [epoch: 8.53 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03722144518486432		[learning rate: 0.00013693]
	Learning Rate: 0.000136934
	LOSS [training: 0.03722144518486432 | validation: 0.02891588096610662]
	TIME [epoch: 8.53 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04058846670826486		[learning rate: 0.00013661]
	Learning Rate: 0.000136611
	LOSS [training: 0.04058846670826486 | validation: 0.02757496830523528]
	TIME [epoch: 8.51 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03879475534803998		[learning rate: 0.00013629]
	Learning Rate: 0.000136289
	LOSS [training: 0.03879475534803998 | validation: 0.016583924749583725]
	TIME [epoch: 8.52 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032538720591810275		[learning rate: 0.00013597]
	Learning Rate: 0.000135968
	LOSS [training: 0.032538720591810275 | validation: 0.033249512606558645]
	TIME [epoch: 8.53 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037454344002618385		[learning rate: 0.00013565]
	Learning Rate: 0.000135647
	LOSS [training: 0.037454344002618385 | validation: 0.024415094442949044]
	TIME [epoch: 8.52 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043568998428488534		[learning rate: 0.00013533]
	Learning Rate: 0.000135327
	LOSS [training: 0.043568998428488534 | validation: 0.027634538790753206]
	TIME [epoch: 8.51 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039461893238462144		[learning rate: 0.00013501]
	Learning Rate: 0.000135008
	LOSS [training: 0.039461893238462144 | validation: 0.04069708607933782]
	TIME [epoch: 8.51 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04800424755683888		[learning rate: 0.00013469]
	Learning Rate: 0.000134689
	LOSS [training: 0.04800424755683888 | validation: 0.03595743475459181]
	TIME [epoch: 8.53 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048494690820118744		[learning rate: 0.00013437]
	Learning Rate: 0.000134372
	LOSS [training: 0.048494690820118744 | validation: 0.03946328415934317]
	TIME [epoch: 8.52 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03948259001884571		[learning rate: 0.00013405]
	Learning Rate: 0.000134055
	LOSS [training: 0.03948259001884571 | validation: 0.024874843180078727]
	TIME [epoch: 8.51 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046856215948802675		[learning rate: 0.00013374]
	Learning Rate: 0.000133738
	LOSS [training: 0.046856215948802675 | validation: 0.028125519955726]
	TIME [epoch: 8.52 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05552146893792985		[learning rate: 0.00013342]
	Learning Rate: 0.000133423
	LOSS [training: 0.05552146893792985 | validation: 0.05397582542008876]
	TIME [epoch: 8.55 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04229510908326771		[learning rate: 0.00013311]
	Learning Rate: 0.000133108
	LOSS [training: 0.04229510908326771 | validation: 0.020375198855040653]
	TIME [epoch: 8.52 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03661082097102173		[learning rate: 0.00013279]
	Learning Rate: 0.000132794
	LOSS [training: 0.03661082097102173 | validation: 0.02481030552586887]
	TIME [epoch: 8.53 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04739098316944791		[learning rate: 0.00013248]
	Learning Rate: 0.000132481
	LOSS [training: 0.04739098316944791 | validation: 0.02184065312690317]
	TIME [epoch: 8.52 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040912219323363204		[learning rate: 0.00013217]
	Learning Rate: 0.000132169
	LOSS [training: 0.040912219323363204 | validation: 0.020835817078378022]
	TIME [epoch: 8.54 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042172084698330434		[learning rate: 0.00013186]
	Learning Rate: 0.000131857
	LOSS [training: 0.042172084698330434 | validation: 0.031865103836246265]
	TIME [epoch: 8.52 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03977689922937524		[learning rate: 0.00013155]
	Learning Rate: 0.000131546
	LOSS [training: 0.03977689922937524 | validation: 0.02224356875841003]
	TIME [epoch: 8.52 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03806799216886741		[learning rate: 0.00013124]
	Learning Rate: 0.000131235
	LOSS [training: 0.03806799216886741 | validation: 0.022325778583806948]
	TIME [epoch: 8.52 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03469122977221523		[learning rate: 0.00013093]
	Learning Rate: 0.000130926
	LOSS [training: 0.03469122977221523 | validation: 0.01748267644572743]
	TIME [epoch: 8.54 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03762892866007881		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.03762892866007881 | validation: 0.02393510156213128]
	TIME [epoch: 8.52 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040525178750552705		[learning rate: 0.00013031]
	Learning Rate: 0.000130309
	LOSS [training: 0.040525178750552705 | validation: 0.017184941849284405]
	TIME [epoch: 8.52 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03713157562553746		[learning rate: 0.00013]
	Learning Rate: 0.000130002
	LOSS [training: 0.03713157562553746 | validation: 0.02954317893042055]
	TIME [epoch: 8.53 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03902653318675494		[learning rate: 0.00012969]
	Learning Rate: 0.000129695
	LOSS [training: 0.03902653318675494 | validation: 0.029980785307229238]
	TIME [epoch: 8.54 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03948687537308988		[learning rate: 0.00012939]
	Learning Rate: 0.000129389
	LOSS [training: 0.03948687537308988 | validation: 0.03147180237199443]
	TIME [epoch: 8.53 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03838695965669482		[learning rate: 0.00012908]
	Learning Rate: 0.000129084
	LOSS [training: 0.03838695965669482 | validation: 0.04861777345440259]
	TIME [epoch: 8.51 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0559492538194577		[learning rate: 0.00012878]
	Learning Rate: 0.000128779
	LOSS [training: 0.0559492538194577 | validation: 0.02349209932994953]
	TIME [epoch: 8.53 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0401424280076977		[learning rate: 0.00012848]
	Learning Rate: 0.000128476
	LOSS [training: 0.0401424280076977 | validation: 0.013992087344515706]
	TIME [epoch: 8.53 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037821665657944294		[learning rate: 0.00012817]
	Learning Rate: 0.000128172
	LOSS [training: 0.037821665657944294 | validation: 0.031784809905168784]
	TIME [epoch: 8.51 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039209723643101616		[learning rate: 0.00012787]
	Learning Rate: 0.00012787
	LOSS [training: 0.039209723643101616 | validation: 0.031122997589377303]
	TIME [epoch: 8.52 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034920929028984395		[learning rate: 0.00012757]
	Learning Rate: 0.000127569
	LOSS [training: 0.034920929028984395 | validation: 0.02391102813265579]
	TIME [epoch: 8.54 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049276461682846315		[learning rate: 0.00012727]
	Learning Rate: 0.000127268
	LOSS [training: 0.049276461682846315 | validation: 0.05793140786236188]
	TIME [epoch: 8.53 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04466932059347173		[learning rate: 0.00012697]
	Learning Rate: 0.000126967
	LOSS [training: 0.04466932059347173 | validation: 0.03445576597949361]
	TIME [epoch: 8.52 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04171059098504621		[learning rate: 0.00012667]
	Learning Rate: 0.000126668
	LOSS [training: 0.04171059098504621 | validation: 0.025412219615319226]
	TIME [epoch: 8.52 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03672608107950063		[learning rate: 0.00012637]
	Learning Rate: 0.000126369
	LOSS [training: 0.03672608107950063 | validation: 0.023655326522582322]
	TIME [epoch: 8.54 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03671923830958537		[learning rate: 0.00012607]
	Learning Rate: 0.000126071
	LOSS [training: 0.03671923830958537 | validation: 0.02306393702183132]
	TIME [epoch: 8.52 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0374332662034836		[learning rate: 0.00012577]
	Learning Rate: 0.000125774
	LOSS [training: 0.0374332662034836 | validation: 0.02791883158529461]
	TIME [epoch: 8.53 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043078745779933675		[learning rate: 0.00012548]
	Learning Rate: 0.000125477
	LOSS [training: 0.043078745779933675 | validation: 0.03022744527849628]
	TIME [epoch: 8.52 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04635745287190397		[learning rate: 0.00012518]
	Learning Rate: 0.000125181
	LOSS [training: 0.04635745287190397 | validation: 0.03072645615499892]
	TIME [epoch: 8.54 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03952757683838521		[learning rate: 0.00012489]
	Learning Rate: 0.000124886
	LOSS [training: 0.03952757683838521 | validation: 0.020668025893292596]
	TIME [epoch: 8.51 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041419485871165215		[learning rate: 0.00012459]
	Learning Rate: 0.000124591
	LOSS [training: 0.041419485871165215 | validation: 0.026133635398426596]
	TIME [epoch: 8.51 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037817315620508024		[learning rate: 0.0001243]
	Learning Rate: 0.000124297
	LOSS [training: 0.037817315620508024 | validation: 0.019870600667358684]
	TIME [epoch: 8.52 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03323834235256844		[learning rate: 0.000124]
	Learning Rate: 0.000124004
	LOSS [training: 0.03323834235256844 | validation: 0.02365468012221969]
	TIME [epoch: 8.54 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03228270365635881		[learning rate: 0.00012371]
	Learning Rate: 0.000123712
	LOSS [training: 0.03228270365635881 | validation: 0.034250786062939007]
	TIME [epoch: 8.53 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03940190062040499		[learning rate: 0.00012342]
	Learning Rate: 0.00012342
	LOSS [training: 0.03940190062040499 | validation: 0.028961900820813735]
	TIME [epoch: 8.52 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03932701398443359		[learning rate: 0.00012313]
	Learning Rate: 0.000123129
	LOSS [training: 0.03932701398443359 | validation: 0.02648757761614635]
	TIME [epoch: 8.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035044468600547087		[learning rate: 0.00012284]
	Learning Rate: 0.000122838
	LOSS [training: 0.035044468600547087 | validation: 0.02731821772940793]
	TIME [epoch: 8.54 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039364152975865194		[learning rate: 0.00012255]
	Learning Rate: 0.000122548
	LOSS [training: 0.039364152975865194 | validation: 0.027181081796183372]
	TIME [epoch: 8.52 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04063092211990897		[learning rate: 0.00012226]
	Learning Rate: 0.000122259
	LOSS [training: 0.04063092211990897 | validation: 0.03432621547242787]
	TIME [epoch: 8.52 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04378673032711261		[learning rate: 0.00012197]
	Learning Rate: 0.000121971
	LOSS [training: 0.04378673032711261 | validation: 0.03758991676667197]
	TIME [epoch: 8.52 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039375066002075895		[learning rate: 0.00012168]
	Learning Rate: 0.000121683
	LOSS [training: 0.039375066002075895 | validation: 0.030029161234692688]
	TIME [epoch: 8.54 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044909802354979864		[learning rate: 0.0001214]
	Learning Rate: 0.000121396
	LOSS [training: 0.044909802354979864 | validation: 0.028827340098243524]
	TIME [epoch: 8.52 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05064881618575047		[learning rate: 0.00012111]
	Learning Rate: 0.00012111
	LOSS [training: 0.05064881618575047 | validation: 0.023783568995955778]
	TIME [epoch: 8.51 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037797762804851115		[learning rate: 0.00012082]
	Learning Rate: 0.000120824
	LOSS [training: 0.037797762804851115 | validation: 0.035585358302109495]
	TIME [epoch: 8.51 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04045570553686171		[learning rate: 0.00012054]
	Learning Rate: 0.000120539
	LOSS [training: 0.04045570553686171 | validation: 0.01716633172516491]
	TIME [epoch: 8.53 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03186759690619969		[learning rate: 0.00012025]
	Learning Rate: 0.000120255
	LOSS [training: 0.03186759690619969 | validation: 0.019426175861380165]
	TIME [epoch: 8.51 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03824490648988323		[learning rate: 0.00011997]
	Learning Rate: 0.000119971
	LOSS [training: 0.03824490648988323 | validation: 0.020722691749400207]
	TIME [epoch: 8.51 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04252812667711582		[learning rate: 0.00011969]
	Learning Rate: 0.000119688
	LOSS [training: 0.04252812667711582 | validation: 0.046721874913867034]
	TIME [epoch: 8.53 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039638978558657625		[learning rate: 0.00011941]
	Learning Rate: 0.000119406
	LOSS [training: 0.039638978558657625 | validation: 0.03016201259245816]
	TIME [epoch: 8.52 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045914958164969745		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.045914958164969745 | validation: 0.026607546442813317]
	TIME [epoch: 8.51 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046156251228322884		[learning rate: 0.00011884]
	Learning Rate: 0.000118843
	LOSS [training: 0.046156251228322884 | validation: 0.03675050887680888]
	TIME [epoch: 8.52 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040709400248961726		[learning rate: 0.00011856]
	Learning Rate: 0.000118563
	LOSS [training: 0.040709400248961726 | validation: 0.026313130717956178]
	TIME [epoch: 8.54 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03780967198201072		[learning rate: 0.00011828]
	Learning Rate: 0.000118283
	LOSS [training: 0.03780967198201072 | validation: 0.02753869678723019]
	TIME [epoch: 8.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03614202429035276		[learning rate: 0.000118]
	Learning Rate: 0.000118004
	LOSS [training: 0.03614202429035276 | validation: 0.034086902395080665]
	TIME [epoch: 8.52 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037033230843445314		[learning rate: 0.00011773]
	Learning Rate: 0.000117726
	LOSS [training: 0.037033230843445314 | validation: 0.028733910697417535]
	TIME [epoch: 8.51 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041473033842769805		[learning rate: 0.00011745]
	Learning Rate: 0.000117448
	LOSS [training: 0.041473033842769805 | validation: 0.027534366442433726]
	TIME [epoch: 8.54 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037330158728935074		[learning rate: 0.00011717]
	Learning Rate: 0.000117171
	LOSS [training: 0.037330158728935074 | validation: 0.029065948678165456]
	TIME [epoch: 8.52 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033002989534163356		[learning rate: 0.00011689]
	Learning Rate: 0.000116895
	LOSS [training: 0.033002989534163356 | validation: 0.02005822918099949]
	TIME [epoch: 8.52 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033970664153056815		[learning rate: 0.00011662]
	Learning Rate: 0.000116619
	LOSS [training: 0.033970664153056815 | validation: 0.016395568108142484]
	TIME [epoch: 8.52 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038166522213107915		[learning rate: 0.00011634]
	Learning Rate: 0.000116344
	LOSS [training: 0.038166522213107915 | validation: 0.020731629811647192]
	TIME [epoch: 8.54 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04268718599288948		[learning rate: 0.00011607]
	Learning Rate: 0.000116069
	LOSS [training: 0.04268718599288948 | validation: 0.01955900744427371]
	TIME [epoch: 8.52 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03473721985077202		[learning rate: 0.0001158]
	Learning Rate: 0.000115796
	LOSS [training: 0.03473721985077202 | validation: 0.03019085861823652]
	TIME [epoch: 8.51 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0380506958472933		[learning rate: 0.00011552]
	Learning Rate: 0.000115523
	LOSS [training: 0.0380506958472933 | validation: 0.035088729727844666]
	TIME [epoch: 8.52 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041494209759131026		[learning rate: 0.00011525]
	Learning Rate: 0.00011525
	LOSS [training: 0.041494209759131026 | validation: 0.02320903595693636]
	TIME [epoch: 8.54 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03943384613781124		[learning rate: 0.00011498]
	Learning Rate: 0.000114978
	LOSS [training: 0.03943384613781124 | validation: 0.026820519984517704]
	TIME [epoch: 8.52 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03710770047992174		[learning rate: 0.00011471]
	Learning Rate: 0.000114707
	LOSS [training: 0.03710770047992174 | validation: 0.02237729701514951]
	TIME [epoch: 8.52 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035400277288463115		[learning rate: 0.00011444]
	Learning Rate: 0.000114436
	LOSS [training: 0.035400277288463115 | validation: 0.025601472535722123]
	TIME [epoch: 8.51 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03706327135582407		[learning rate: 0.00011417]
	Learning Rate: 0.000114166
	LOSS [training: 0.03706327135582407 | validation: 0.016543493947799248]
	TIME [epoch: 8.54 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038291335352336385		[learning rate: 0.0001139]
	Learning Rate: 0.000113897
	LOSS [training: 0.038291335352336385 | validation: 0.021285425818547525]
	TIME [epoch: 8.51 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0325132173877396		[learning rate: 0.00011363]
	Learning Rate: 0.000113628
	LOSS [training: 0.0325132173877396 | validation: 0.03150436905361566]
	TIME [epoch: 8.51 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0349035248740954		[learning rate: 0.00011336]
	Learning Rate: 0.00011336
	LOSS [training: 0.0349035248740954 | validation: 0.031210952003951804]
	TIME [epoch: 8.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04490546397236686		[learning rate: 0.00011309]
	Learning Rate: 0.000113093
	LOSS [training: 0.04490546397236686 | validation: 0.020943137885326785]
	TIME [epoch: 8.54 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038137565861407055		[learning rate: 0.00011283]
	Learning Rate: 0.000112826
	LOSS [training: 0.038137565861407055 | validation: 0.03398636008822155]
	TIME [epoch: 8.53 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04967750052898788		[learning rate: 0.00011256]
	Learning Rate: 0.00011256
	LOSS [training: 0.04967750052898788 | validation: 0.0259865930534977]
	TIME [epoch: 8.54 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04077164718187302		[learning rate: 0.00011229]
	Learning Rate: 0.000112295
	LOSS [training: 0.04077164718187302 | validation: 0.017531872627877695]
	TIME [epoch: 8.53 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0345545908445278		[learning rate: 0.00011203]
	Learning Rate: 0.00011203
	LOSS [training: 0.0345545908445278 | validation: 0.02954769161825155]
	TIME [epoch: 8.56 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037309145415103204		[learning rate: 0.00011177]
	Learning Rate: 0.000111765
	LOSS [training: 0.037309145415103204 | validation: 0.022959014293286964]
	TIME [epoch: 8.54 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040750248621982045		[learning rate: 0.0001115]
	Learning Rate: 0.000111502
	LOSS [training: 0.040750248621982045 | validation: 0.01869268830324605]
	TIME [epoch: 8.54 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03672874825153258		[learning rate: 0.00011124]
	Learning Rate: 0.000111239
	LOSS [training: 0.03672874825153258 | validation: 0.01974452144293521]
	TIME [epoch: 8.55 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0347410257116858		[learning rate: 0.00011098]
	Learning Rate: 0.000110976
	LOSS [training: 0.0347410257116858 | validation: 0.020962971065332958]
	TIME [epoch: 8.54 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043467500682162985		[learning rate: 0.00011071]
	Learning Rate: 0.000110715
	LOSS [training: 0.043467500682162985 | validation: 0.017969469777235864]
	TIME [epoch: 8.54 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03723383036307997		[learning rate: 0.00011045]
	Learning Rate: 0.000110453
	LOSS [training: 0.03723383036307997 | validation: 0.037132156200241274]
	TIME [epoch: 8.55 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0461253513543927		[learning rate: 0.00011019]
	Learning Rate: 0.000110193
	LOSS [training: 0.0461253513543927 | validation: 0.0531833632580799]
	TIME [epoch: 8.57 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05293431379095166		[learning rate: 0.00010993]
	Learning Rate: 0.000109933
	LOSS [training: 0.05293431379095166 | validation: 0.031430125890475454]
	TIME [epoch: 8.55 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0396317320382139		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.0396317320382139 | validation: 0.029197434173818603]
	TIME [epoch: 8.54 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04976741928715555		[learning rate: 0.00010942]
	Learning Rate: 0.000109415
	LOSS [training: 0.04976741928715555 | validation: 0.03783212414770391]
	TIME [epoch: 8.54 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04590583187239694		[learning rate: 0.00010916]
	Learning Rate: 0.000109157
	LOSS [training: 0.04590583187239694 | validation: 0.02175065986998773]
	TIME [epoch: 8.56 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040658623814052844		[learning rate: 0.0001089]
	Learning Rate: 0.000108899
	LOSS [training: 0.040658623814052844 | validation: 0.020642271974220604]
	TIME [epoch: 8.54 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04018365134736082		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.04018365134736082 | validation: 0.0357973769635633]
	TIME [epoch: 8.54 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04090579142314397		[learning rate: 0.00010839]
	Learning Rate: 0.000108386
	LOSS [training: 0.04090579142314397 | validation: 0.02473247040362423]
	TIME [epoch: 8.54 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04012963683783839		[learning rate: 0.00010813]
	Learning Rate: 0.000108131
	LOSS [training: 0.04012963683783839 | validation: 0.02329755527333159]
	TIME [epoch: 8.56 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0332440935385652		[learning rate: 0.00010788]
	Learning Rate: 0.000107876
	LOSS [training: 0.0332440935385652 | validation: 0.019867668190041876]
	TIME [epoch: 8.55 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03581696516058207		[learning rate: 0.00010762]
	Learning Rate: 0.000107621
	LOSS [training: 0.03581696516058207 | validation: 0.030411589740629297]
	TIME [epoch: 8.54 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04564762222032673		[learning rate: 0.00010737]
	Learning Rate: 0.000107367
	LOSS [training: 0.04564762222032673 | validation: 0.02617397905746001]
	TIME [epoch: 8.55 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0370156815138118		[learning rate: 0.00010711]
	Learning Rate: 0.000107114
	LOSS [training: 0.0370156815138118 | validation: 0.02075068233686647]
	TIME [epoch: 8.56 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036116097158959984		[learning rate: 0.00010686]
	Learning Rate: 0.000106861
	LOSS [training: 0.036116097158959984 | validation: 0.02615486974206107]
	TIME [epoch: 8.55 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03595151158309101		[learning rate: 0.00010661]
	Learning Rate: 0.000106609
	LOSS [training: 0.03595151158309101 | validation: 0.032166905902798776]
	TIME [epoch: 8.54 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046164986460734726		[learning rate: 0.00010636]
	Learning Rate: 0.000106358
	LOSS [training: 0.046164986460734726 | validation: 0.03182023923239588]
	TIME [epoch: 8.55 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03540406988895976		[learning rate: 0.00010611]
	Learning Rate: 0.000106107
	LOSS [training: 0.03540406988895976 | validation: 0.016376040237585564]
	TIME [epoch: 8.57 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038962925707799495		[learning rate: 0.00010586]
	Learning Rate: 0.000105857
	LOSS [training: 0.038962925707799495 | validation: 0.02845834333996334]
	TIME [epoch: 8.54 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03458079643280752		[learning rate: 0.00010561]
	Learning Rate: 0.000105607
	LOSS [training: 0.03458079643280752 | validation: 0.024044831102866367]
	TIME [epoch: 8.55 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0385052653282276		[learning rate: 0.00010536]
	Learning Rate: 0.000105358
	LOSS [training: 0.0385052653282276 | validation: 0.025754858079986814]
	TIME [epoch: 8.55 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04160356032216368		[learning rate: 0.00010511]
	Learning Rate: 0.000105109
	LOSS [training: 0.04160356032216368 | validation: 0.03696883180054859]
	TIME [epoch: 8.57 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03930774372153037		[learning rate: 0.00010486]
	Learning Rate: 0.000104861
	LOSS [training: 0.03930774372153037 | validation: 0.02516294649438696]
	TIME [epoch: 8.54 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042333176703062456		[learning rate: 0.00010461]
	Learning Rate: 0.000104614
	LOSS [training: 0.042333176703062456 | validation: 0.030118657822326554]
	TIME [epoch: 8.54 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039721088201493816		[learning rate: 0.00010437]
	Learning Rate: 0.000104367
	LOSS [training: 0.039721088201493816 | validation: 0.020841708471506737]
	TIME [epoch: 8.55 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040372479283696375		[learning rate: 0.00010412]
	Learning Rate: 0.000104121
	LOSS [training: 0.040372479283696375 | validation: 0.01720730235595427]
	TIME [epoch: 8.56 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0320814623064117		[learning rate: 0.00010388]
	Learning Rate: 0.000103875
	LOSS [training: 0.0320814623064117 | validation: 0.02385700268129088]
	TIME [epoch: 8.53 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03989198977529153		[learning rate: 0.00010363]
	Learning Rate: 0.00010363
	LOSS [training: 0.03989198977529153 | validation: 0.020596474794617223]
	TIME [epoch: 8.54 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03191739802780068		[learning rate: 0.00010339]
	Learning Rate: 0.000103386
	LOSS [training: 0.03191739802780068 | validation: 0.018478525447245025]
	TIME [epoch: 8.56 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04070052448920295		[learning rate: 0.00010314]
	Learning Rate: 0.000103142
	LOSS [training: 0.04070052448920295 | validation: 0.020797244386068656]
	TIME [epoch: 8.55 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036382097464673926		[learning rate: 0.0001029]
	Learning Rate: 0.000102899
	LOSS [training: 0.036382097464673926 | validation: 0.013665711649472521]
	TIME [epoch: 8.54 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03417252616006887		[learning rate: 0.00010266]
	Learning Rate: 0.000102656
	LOSS [training: 0.03417252616006887 | validation: 0.01570080926409162]
	TIME [epoch: 8.54 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03352859886090638		[learning rate: 0.00010241]
	Learning Rate: 0.000102414
	LOSS [training: 0.03352859886090638 | validation: 0.021714427383332218]
	TIME [epoch: 8.56 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03413996368640676		[learning rate: 0.00010217]
	Learning Rate: 0.000102172
	LOSS [training: 0.03413996368640676 | validation: 0.028426771422296354]
	TIME [epoch: 8.55 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050156318905046716		[learning rate: 0.00010193]
	Learning Rate: 0.000101931
	LOSS [training: 0.050156318905046716 | validation: 0.051716501741817016]
	TIME [epoch: 8.55 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04443374736160428		[learning rate: 0.00010169]
	Learning Rate: 0.000101691
	LOSS [training: 0.04443374736160428 | validation: 0.024747660835473806]
	TIME [epoch: 8.55 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03787919826827905		[learning rate: 0.00010145]
	Learning Rate: 0.000101451
	LOSS [training: 0.03787919826827905 | validation: 0.0200524914312718]
	TIME [epoch: 8.56 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038967269073609784		[learning rate: 0.00010121]
	Learning Rate: 0.000101212
	LOSS [training: 0.038967269073609784 | validation: 0.02435833754650763]
	TIME [epoch: 8.54 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0343439444367313		[learning rate: 0.00010097]
	Learning Rate: 0.000100973
	LOSS [training: 0.0343439444367313 | validation: 0.04815262430840685]
	TIME [epoch: 8.53 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0439393206919862		[learning rate: 0.00010073]
	Learning Rate: 0.000100735
	LOSS [training: 0.0439393206919862 | validation: 0.027726627214602693]
	TIME [epoch: 8.53 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03718409974150949		[learning rate: 0.0001005]
	Learning Rate: 0.000100497
	LOSS [training: 0.03718409974150949 | validation: 0.02723217226561147]
	TIME [epoch: 8.51 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03972719389867475		[learning rate: 0.00010026]
	Learning Rate: 0.00010026
	LOSS [training: 0.03972719389867475 | validation: 0.037097671560724174]
	TIME [epoch: 8.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036692412649693376		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.036692412649693376 | validation: 0.027999139148398113]
	TIME [epoch: 8.54 sec]
Finished training in 17218.345 seconds.
