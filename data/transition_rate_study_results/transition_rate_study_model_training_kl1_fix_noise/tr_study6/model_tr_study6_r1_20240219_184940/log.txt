Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2017049228

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.011087383695289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.011087383695289 | validation: 9.773125266169407]
	TIME [epoch: 80.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.973328201199735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.973328201199735 | validation: 7.385600103525555]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.020622595076733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.020622595076733 | validation: 6.958030720465943]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.741066708357375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.741066708357375 | validation: 6.611147352363367]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.551356996661487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.551356996661487 | validation: 6.423000117964525]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.967808837955703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.967808837955703 | validation: 6.36344707131564]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.183080956455666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.183080956455666 | validation: 6.8442026724686595]
	TIME [epoch: 9.77 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.097672070601114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.097672070601114 | validation: 6.785435125681634]
	TIME [epoch: 9.76 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.220628264521583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.220628264521583 | validation: 6.371800468549428]
	TIME [epoch: 9.77 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.090884282976491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.090884282976491 | validation: 5.1629157032050115]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.071829760957908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.071829760957908 | validation: 10.286816135140016]
	TIME [epoch: 9.77 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.052622808187701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.052622808187701 | validation: 10.174173050219395]
	TIME [epoch: 9.78 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.208195199009278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.208195199009278 | validation: 8.23797681682586]
	TIME [epoch: 9.77 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.642182533599048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.642182533599048 | validation: 6.699867751497853]
	TIME [epoch: 9.76 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.209901314419122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.209901314419122 | validation: 6.789741414229061]
	TIME [epoch: 9.77 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.320194564916585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.320194564916585 | validation: 6.596783324621324]
	TIME [epoch: 9.79 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.98716514967712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.98716514967712 | validation: 6.640955396637722]
	TIME [epoch: 9.76 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.854369056158447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.854369056158447 | validation: 6.355221628232666]
	TIME [epoch: 9.77 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4843609029758715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4843609029758715 | validation: 5.055254667467034]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.213364350145149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.213364350145149 | validation: 5.14197331458474]
	TIME [epoch: 9.78 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2120575862003005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2120575862003005 | validation: 4.858348333036747]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8893313579061175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8893313579061175 | validation: 4.985963969677704]
	TIME [epoch: 9.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.188667374837516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.188667374837516 | validation: 6.229665754310571]
	TIME [epoch: 9.77 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.353330160636753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.353330160636753 | validation: 4.473717948922188]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.044822687685551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.044822687685551 | validation: 6.281979059745993]
	TIME [epoch: 9.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.652237252823554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.652237252823554 | validation: 6.607402265043121]
	TIME [epoch: 9.77 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.515490092097086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.515490092097086 | validation: 4.6573725042212395]
	TIME [epoch: 9.77 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.656883723053584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.656883723053584 | validation: 5.651447090866932]
	TIME [epoch: 9.79 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.617347972116148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.617347972116148 | validation: 4.521443386632962]
	TIME [epoch: 9.77 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.154729427938219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.154729427938219 | validation: 4.861667453128018]
	TIME [epoch: 9.77 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.004409978633754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.004409978633754 | validation: 6.103918241584729]
	TIME [epoch: 9.79 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.069576153606005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.069576153606005 | validation: 6.153127902690417]
	TIME [epoch: 9.77 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.066857090816507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.066857090816507 | validation: 5.911708848825643]
	TIME [epoch: 9.77 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.077167945838551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.077167945838551 | validation: 4.218630333743667]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.790488701964768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.790488701964768 | validation: 4.939980143271663]
	TIME [epoch: 9.77 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.20265140206205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.20265140206205 | validation: 5.009075703386734]
	TIME [epoch: 9.77 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.940761986102495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.940761986102495 | validation: 4.923558085803547]
	TIME [epoch: 9.79 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.101676003314027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.101676003314027 | validation: 4.4183235983323605]
	TIME [epoch: 9.76 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.750489730802141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.750489730802141 | validation: 4.93059606863094]
	TIME [epoch: 9.77 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.937838600982714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.937838600982714 | validation: 4.745894730846964]
	TIME [epoch: 9.78 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.761167901013062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.761167901013062 | validation: 5.332021643263483]
	TIME [epoch: 9.77 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.340049556707624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.340049556707624 | validation: 5.401221214378896]
	TIME [epoch: 9.77 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.030021421786654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.030021421786654 | validation: 4.552398030127162]
	TIME [epoch: 9.78 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.892267902929663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.892267902929663 | validation: 5.199134913585453]
	TIME [epoch: 9.77 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.821271529020977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.821271529020977 | validation: 4.498029483456618]
	TIME [epoch: 9.76 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.035503817163682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.035503817163682 | validation: 5.359424134493759]
	TIME [epoch: 9.77 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.017423166196035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.017423166196035 | validation: 4.743503718215392]
	TIME [epoch: 9.77 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.653492505835025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.653492505835025 | validation: 4.3460307330650885]
	TIME [epoch: 9.76 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.817369609131077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.817369609131077 | validation: 5.34710334161628]
	TIME [epoch: 9.78 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.392125200218638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.392125200218638 | validation: 4.692471568709358]
	TIME [epoch: 9.77 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.579046603762643		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 4.579046603762643 | validation: 4.310406644707495]
	TIME [epoch: 9.76 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.563939039229496		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 4.563939039229496 | validation: 4.399941621478381]
	TIME [epoch: 9.77 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.446797360951368		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 4.446797360951368 | validation: 4.678188367423894]
	TIME [epoch: 9.78 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.374405146886221		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 4.374405146886221 | validation: 4.180308171718198]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.304795967801323		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 4.304795967801323 | validation: 5.141407560541679]
	TIME [epoch: 9.78 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.714963110069673		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 5.714963110069673 | validation: 7.371361100152749]
	TIME [epoch: 9.78 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.417079642090068		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 8.417079642090068 | validation: 9.161749999357978]
	TIME [epoch: 9.77 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.482471176967856		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 7.482471176967856 | validation: 6.062033922193187]
	TIME [epoch: 9.78 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.255053077149329		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 5.255053077149329 | validation: 4.303106890222958]
	TIME [epoch: 9.78 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7964009923529725		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 4.7964009923529725 | validation: 4.242922075017237]
	TIME [epoch: 9.77 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.691201955114048		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 4.691201955114048 | validation: 4.294002843061267]
	TIME [epoch: 9.77 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.954430961443469		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 4.954430961443469 | validation: 7.049685305435847]
	TIME [epoch: 9.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.238681836586473		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 7.238681836586473 | validation: 6.417028091989676]
	TIME [epoch: 9.76 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0453013585594615		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 5.0453013585594615 | validation: 4.267596857721357]
	TIME [epoch: 9.76 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.541874689093963		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 4.541874689093963 | validation: 5.588119673738756]
	TIME [epoch: 9.79 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.01176779623645		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 5.01176779623645 | validation: 5.15169245088398]
	TIME [epoch: 9.76 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.346082306874692		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 4.346082306874692 | validation: 4.19903037642927]
	TIME [epoch: 9.77 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.514866603075076		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 4.514866603075076 | validation: 4.423818038227668]
	TIME [epoch: 9.79 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.262934617548583		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 4.262934617548583 | validation: 5.863340372293954]
	TIME [epoch: 9.77 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.931897746042507		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 4.931897746042507 | validation: 4.109587625941008]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4211950044299755		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 4.4211950044299755 | validation: 5.564232282296827]
	TIME [epoch: 9.79 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.892232593334393		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 4.892232593334393 | validation: 4.113738622566028]
	TIME [epoch: 9.76 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.421188013917463		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 4.421188013917463 | validation: 4.393391215753745]
	TIME [epoch: 9.77 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.552719290682674		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 4.552719290682674 | validation: 4.50611014756586]
	TIME [epoch: 9.78 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.500262158007507		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 5.500262158007507 | validation: 4.390282048591929]
	TIME [epoch: 9.76 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4997366069160964		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 5.4997366069160964 | validation: 6.448213631873982]
	TIME [epoch: 9.75 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.367377330917785		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 7.367377330917785 | validation: 8.110506662360363]
	TIME [epoch: 9.78 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.942876971395958		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 7.942876971395958 | validation: 7.343260783923559]
	TIME [epoch: 9.76 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.842547124018037		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 6.842547124018037 | validation: 6.871045955092163]
	TIME [epoch: 9.76 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.083589659351395		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 6.083589659351395 | validation: 5.714712496611091]
	TIME [epoch: 9.77 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.223591222563238		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 5.223591222563238 | validation: 6.639014100568486]
	TIME [epoch: 9.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.996116437201086		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 6.996116437201086 | validation: 4.458032407581729]
	TIME [epoch: 9.74 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.148223754303094		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 4.148223754303094 | validation: 3.3302209264945897]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.526873680093242		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 4.526873680093242 | validation: 4.620076357572322]
	TIME [epoch: 9.76 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.758107471611015		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 4.758107471611015 | validation: 4.316305383403507]
	TIME [epoch: 9.75 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.482418523763235		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 5.482418523763235 | validation: 5.172182860859876]
	TIME [epoch: 9.77 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.686898629319819		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 5.686898629319819 | validation: 4.635796547157712]
	TIME [epoch: 9.75 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.116584827022157		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 5.116584827022157 | validation: 3.82975480240068]
	TIME [epoch: 9.75 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5293486179924205		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 4.5293486179924205 | validation: 5.20607504712408]
	TIME [epoch: 9.77 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.872894757760363		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 4.872894757760363 | validation: 4.045205930110165]
	TIME [epoch: 9.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.077837940152279		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 4.077837940152279 | validation: 3.97550000478376]
	TIME [epoch: 9.74 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9247274693677925		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 3.9247274693677925 | validation: 3.4170225493897806]
	TIME [epoch: 9.77 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.013690610867652		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 4.013690610867652 | validation: 3.2311860169529223]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7161591168321584		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 3.7161591168321584 | validation: 3.005700284743438]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.628587718688035		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 3.628587718688035 | validation: 3.1317934761218353]
	TIME [epoch: 9.78 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6822556360239758		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 3.6822556360239758 | validation: 2.845112301733548]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.407525063807417		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 4.407525063807417 | validation: 3.3515244167722513]
	TIME [epoch: 9.74 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4972387651807066		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 3.4972387651807066 | validation: 2.6436477422169764]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4445392140553963		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 3.4445392140553963 | validation: 3.3033215374181806]
	TIME [epoch: 9.77 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.994372593225389		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 3.994372593225389 | validation: 4.1790685923208875]
	TIME [epoch: 9.75 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6486148636148195		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 3.6486148636148195 | validation: 2.69332313281799]
	TIME [epoch: 9.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.072730183237909		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 3.072730183237909 | validation: 2.6431817801923274]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9962181770949696		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 2.9962181770949696 | validation: 3.9065531876295414]
	TIME [epoch: 9.77 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.867535342996395		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 3.867535342996395 | validation: 2.997692541279658]
	TIME [epoch: 9.77 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3319026361784574		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 3.3319026361784574 | validation: 3.2263139141158015]
	TIME [epoch: 9.78 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.838851285492388		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 3.838851285492388 | validation: 3.8442712468363847]
	TIME [epoch: 9.77 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9024364412329247		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 3.9024364412329247 | validation: 4.009456460607953]
	TIME [epoch: 9.76 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.203922690851566		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 4.203922690851566 | validation: 4.967240455957493]
	TIME [epoch: 9.76 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.354195094503512		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 5.354195094503512 | validation: 3.1293034375688764]
	TIME [epoch: 9.79 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3616049491567943		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 3.3616049491567943 | validation: 4.184220745877687]
	TIME [epoch: 9.76 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.56456022913803		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 5.56456022913803 | validation: 4.736685357975375]
	TIME [epoch: 9.76 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.994885128605268		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 4.994885128605268 | validation: 3.8558714122649507]
	TIME [epoch: 9.78 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.645780758055361		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 4.645780758055361 | validation: 3.1723712053022894]
	TIME [epoch: 9.77 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.553444525503785		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 3.553444525503785 | validation: 2.5024392439421566]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.831791798259326		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 2.831791798259326 | validation: 2.4103431759135168]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.442082043220472		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 3.442082043220472 | validation: 2.815710127916676]
	TIME [epoch: 9.78 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0377892029425366		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 3.0377892029425366 | validation: 2.714045706305861]
	TIME [epoch: 9.75 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.928866418626229		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 3.928866418626229 | validation: 4.087158991861176]
	TIME [epoch: 9.75 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.581100354609062		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 3.581100354609062 | validation: 3.130186420540164]
	TIME [epoch: 9.78 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1523744409085106		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 3.1523744409085106 | validation: 2.34173924405427]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.054509324923548		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 3.054509324923548 | validation: 2.891611840699352]
	TIME [epoch: 9.76 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0141328901604902		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 3.0141328901604902 | validation: 2.5494508245899627]
	TIME [epoch: 9.78 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0075928981165023		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 3.0075928981165023 | validation: 2.642997291714863]
	TIME [epoch: 9.77 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0708908277575855		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 3.0708908277575855 | validation: 2.8382426383660686]
	TIME [epoch: 9.76 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0676375674318512		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 3.0676375674318512 | validation: 2.371622454337038]
	TIME [epoch: 9.77 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.917939099784346		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 2.917939099784346 | validation: 2.386263075821048]
	TIME [epoch: 9.78 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0385720156125537		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 3.0385720156125537 | validation: 2.4210308399926923]
	TIME [epoch: 9.76 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7429663812167933		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 2.7429663812167933 | validation: 2.251858584343892]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6971589565878014		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 2.6971589565878014 | validation: 2.258127125831521]
	TIME [epoch: 9.79 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.173344134376569		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 3.173344134376569 | validation: 2.315126483443379]
	TIME [epoch: 9.76 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0258142297002832		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 3.0258142297002832 | validation: 2.35816760640591]
	TIME [epoch: 9.76 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.020158096450542		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 3.020158096450542 | validation: 3.2726063168740755]
	TIME [epoch: 9.77 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9184316504040737		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 2.9184316504040737 | validation: 2.4516096561673364]
	TIME [epoch: 9.76 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0651452837990507		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 3.0651452837990507 | validation: 2.7700199895873845]
	TIME [epoch: 9.76 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9138930128923035		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 2.9138930128923035 | validation: 2.1798052113534183]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7039623557562793		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 2.7039623557562793 | validation: 2.2727735748013327]
	TIME [epoch: 9.78 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0744350495119397		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 3.0744350495119397 | validation: 3.9125350687041123]
	TIME [epoch: 9.76 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.331852197117199		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 4.331852197117199 | validation: 3.565442735038552]
	TIME [epoch: 9.76 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7209897404456433		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 3.7209897404456433 | validation: 2.5799311579112554]
	TIME [epoch: 9.78 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6581228869458884		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 3.6581228869458884 | validation: 4.38399768876719]
	TIME [epoch: 9.76 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.196050491219452		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 4.196050491219452 | validation: 2.682741585693217]
	TIME [epoch: 9.76 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.138320184479229		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 3.138320184479229 | validation: 3.3614196464217274]
	TIME [epoch: 9.76 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9950299344680005		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 2.9950299344680005 | validation: 2.573929896937953]
	TIME [epoch: 9.78 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.673792286907522		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 2.673792286907522 | validation: 2.6201200365379607]
	TIME [epoch: 9.76 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.119987240713049		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 3.119987240713049 | validation: 2.6441357678147233]
	TIME [epoch: 9.76 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.407079817927781		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 3.407079817927781 | validation: 2.711319854322925]
	TIME [epoch: 9.78 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5516404847695817		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 3.5516404847695817 | validation: 2.2928675722544423]
	TIME [epoch: 9.77 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.125955202969741		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 3.125955202969741 | validation: 2.8946852933191587]
	TIME [epoch: 9.76 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0362067278227105		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 4.0362067278227105 | validation: 3.611963345931693]
	TIME [epoch: 9.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.67326659885335		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 3.67326659885335 | validation: 2.6941493620461974]
	TIME [epoch: 9.76 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2663985857885174		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 3.2663985857885174 | validation: 2.90169388078392]
	TIME [epoch: 9.75 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1237875479921646		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 3.1237875479921646 | validation: 2.5336133028652954]
	TIME [epoch: 9.76 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9736592344043524		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 2.9736592344043524 | validation: 3.045870177396848]
	TIME [epoch: 9.78 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.970285252850875		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 5.970285252850875 | validation: 5.442453161559492]
	TIME [epoch: 9.76 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.731269729621661		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 6.731269729621661 | validation: 7.550819743433838]
	TIME [epoch: 9.76 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.743238629511003		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 5.743238629511003 | validation: 3.6555809828236683]
	TIME [epoch: 9.78 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.510641966583878		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 4.510641966583878 | validation: 3.945894721687224]
	TIME [epoch: 9.76 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6619051602079224		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 3.6619051602079224 | validation: 2.375030307708339]
	TIME [epoch: 9.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.013837242023207		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 3.013837242023207 | validation: 2.206782282764819]
	TIME [epoch: 9.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7695445998346035		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 2.7695445998346035 | validation: 4.230934069416827]
	TIME [epoch: 9.77 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.893744510309973		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 4.893744510309973 | validation: 2.982664130604224]
	TIME [epoch: 9.75 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.496926469883358		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 3.496926469883358 | validation: 3.111151540741427]
	TIME [epoch: 9.75 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.148671399355085		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 3.148671399355085 | validation: 2.2742671955866194]
	TIME [epoch: 9.77 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.095178005949443		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 3.095178005949443 | validation: 2.928514002479958]
	TIME [epoch: 9.75 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.327226884388206		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 3.327226884388206 | validation: 3.192449772785966]
	TIME [epoch: 9.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7302709434758214		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 3.7302709434758214 | validation: 3.17212280362412]
	TIME [epoch: 9.78 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.890665534600642		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 3.890665534600642 | validation: 5.487072821348277]
	TIME [epoch: 9.76 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.155915083305133		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 4.155915083305133 | validation: 2.5648850211188825]
	TIME [epoch: 9.75 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.471289476389549		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 4.471289476389549 | validation: 4.2254633168984395]
	TIME [epoch: 9.76 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.438164563782131		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 4.438164563782131 | validation: 4.326598046348038]
	TIME [epoch: 9.77 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.420826125740054		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 4.420826125740054 | validation: 3.4219870506523855]
	TIME [epoch: 9.76 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8472958283607896		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 3.8472958283607896 | validation: 3.539936296252725]
	TIME [epoch: 9.75 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.481540958864034		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 4.481540958864034 | validation: 4.414418310206716]
	TIME [epoch: 9.78 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.372459689652933		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 4.372459689652933 | validation: 3.2732195641872774]
	TIME [epoch: 9.75 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.721863552824525		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 3.721863552824525 | validation: 4.122482061007155]
	TIME [epoch: 9.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7995952960668418		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 3.7995952960668418 | validation: 2.7774904951101327]
	TIME [epoch: 9.77 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3964861710612966		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 3.3964861710612966 | validation: 3.1892362303712156]
	TIME [epoch: 9.77 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3536595546058465		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 3.3536595546058465 | validation: 2.4865829544914284]
	TIME [epoch: 9.75 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.131122870081205		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 3.131122870081205 | validation: 2.6124474686173076]
	TIME [epoch: 9.75 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5119097366006935		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 3.5119097366006935 | validation: 2.950374895880426]
	TIME [epoch: 9.78 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1691111487008943		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 3.1691111487008943 | validation: 2.9757272381025404]
	TIME [epoch: 9.75 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.476991418791741		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 3.476991418791741 | validation: 2.7556568980281635]
	TIME [epoch: 9.77 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1468958768914517		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 3.1468958768914517 | validation: 3.247642614366937]
	TIME [epoch: 9.77 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.109381023177249		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 3.109381023177249 | validation: 2.398642475183523]
	TIME [epoch: 9.76 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3909827340762604		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 3.3909827340762604 | validation: 2.4182362811910156]
	TIME [epoch: 9.75 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0255105269198173		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 3.0255105269198173 | validation: 2.498014938155086]
	TIME [epoch: 9.76 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9912702728428684		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 2.9912702728428684 | validation: 2.4622703443933567]
	TIME [epoch: 9.77 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.197218616646243		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 3.197218616646243 | validation: 2.943762567753173]
	TIME [epoch: 9.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0562172353721366		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 3.0562172353721366 | validation: 2.5158620018144693]
	TIME [epoch: 9.75 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.157641699054902		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 3.157641699054902 | validation: 2.8639358438561238]
	TIME [epoch: 9.78 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.799037788504544		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 3.799037788504544 | validation: 4.63222705898674]
	TIME [epoch: 9.75 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.897000960220048		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 4.897000960220048 | validation: 3.138991077169127]
	TIME [epoch: 9.75 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.627871865444971		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 3.627871865444971 | validation: 3.5320198898220783]
	TIME [epoch: 9.77 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.505829599306815		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 3.505829599306815 | validation: 2.406311080085284]
	TIME [epoch: 9.76 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.583654271282757		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 2.583654271282757 | validation: 2.4312325881018486]
	TIME [epoch: 9.76 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7240561310460603		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 2.7240561310460603 | validation: 2.0942205147777373]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.584715840158356		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 2.584715840158356 | validation: 2.0622271512085475]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.524004664946349		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 2.524004664946349 | validation: 2.114025449162696]
	TIME [epoch: 9.75 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.520843057090296		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 2.520843057090296 | validation: 2.045312768870585]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.440379849710782		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 2.440379849710782 | validation: 1.9408748962292472]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.324920588573094		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 2.324920588573094 | validation: 2.1601300436606277]
	TIME [epoch: 9.76 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5379457683048887		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 2.5379457683048887 | validation: 1.9317962498679158]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4194939169840373		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 2.4194939169840373 | validation: 2.3677162681056543]
	TIME [epoch: 9.78 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.849177798447017		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 2.849177798447017 | validation: 2.5008211748406457]
	TIME [epoch: 9.76 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7145839728116066		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 2.7145839728116066 | validation: 1.9802381018149067]
	TIME [epoch: 9.75 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.389303048136246		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 2.389303048136246 | validation: 1.9205140593464358]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.250460670041464		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 2.250460670041464 | validation: 2.3329713261687077]
	TIME [epoch: 9.78 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.716529513192517		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 2.716529513192517 | validation: 2.2221816444585984]
	TIME [epoch: 9.76 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5112819834018247		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 2.5112819834018247 | validation: 2.17669022934006]
	TIME [epoch: 9.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.605892471765408		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 2.605892471765408 | validation: 2.191285643226481]
	TIME [epoch: 9.79 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4312345628333496		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 2.4312345628333496 | validation: 2.2209255684699474]
	TIME [epoch: 9.76 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5006243014436706		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 2.5006243014436706 | validation: 1.8437248496248972]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2301513210729835		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 2.2301513210729835 | validation: 2.1180203950067273]
	TIME [epoch: 9.79 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1501908783105685		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.1501908783105685 | validation: 2.0801954494247026]
	TIME [epoch: 9.78 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.156595855020183		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 2.156595855020183 | validation: 1.7941247577503134]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0690060746218513		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 2.0690060746218513 | validation: 1.6943789604794177]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.038081423757384		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 2.038081423757384 | validation: 1.931312985329525]
	TIME [epoch: 9.79 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1111038169990084		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 2.1111038169990084 | validation: 2.2689386439315764]
	TIME [epoch: 9.76 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.46486863269988		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 2.46486863269988 | validation: 1.7329324381394065]
	TIME [epoch: 9.76 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8999254872243		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 1.8999254872243 | validation: 1.4860024922043988]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8345632986562226		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 1.8345632986562226 | validation: 1.8305970408386296]
	TIME [epoch: 9.76 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.361684519448917		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 2.361684519448917 | validation: 2.403764495285147]
	TIME [epoch: 9.76 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.21360494883542		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 2.21360494883542 | validation: 2.1495857088615073]
	TIME [epoch: 9.77 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0967314301923023		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 2.0967314301923023 | validation: 1.4547496591883782]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8555485842485335		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 1.8555485842485335 | validation: 1.795157389150877]
	TIME [epoch: 9.77 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3863498485924675		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 2.3863498485924675 | validation: 1.684811259221935]
	TIME [epoch: 9.77 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0271649096831443		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 2.0271649096831443 | validation: 1.4488241946617777]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6618871453464048		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 1.6618871453464048 | validation: 1.3622344143014633]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8065330342376977		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 1.8065330342376977 | validation: 1.3608563634951725]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4342960343479647		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 1.4342960343479647 | validation: 1.339001202096996]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.463185707275739		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 1.463185707275739 | validation: 1.400423232890371]
	TIME [epoch: 9.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4469839684670882		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 1.4469839684670882 | validation: 0.9582862845107262]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.293005401054608		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 1.293005401054608 | validation: 1.7235572476186263]
	TIME [epoch: 9.78 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1546428892188896		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 1.1546428892188896 | validation: 0.8447216780203352]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4630052116460532		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 1.4630052116460532 | validation: 1.3202715433774177]
	TIME [epoch: 9.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0870009470057984		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 1.0870009470057984 | validation: 1.2110305821450373]
	TIME [epoch: 9.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1993098440963679		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 1.1993098440963679 | validation: 0.8910047503956172]
	TIME [epoch: 9.78 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1775040704741784		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 1.1775040704741784 | validation: 1.3964172942206476]
	TIME [epoch: 9.76 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2277679743904732		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.2277679743904732 | validation: 0.8440897310967629]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0430749354616373		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 1.0430749354616373 | validation: 0.871348776002279]
	TIME [epoch: 9.78 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8951484352853394		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 0.8951484352853394 | validation: 0.9822238143425936]
	TIME [epoch: 9.77 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1832318579425425		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.1832318579425425 | validation: 0.777638025833492]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9313620274100304		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 0.9313620274100304 | validation: 0.828155140366172]
	TIME [epoch: 9.79 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9277640574609128		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 0.9277640574609128 | validation: 4.7611779643490815]
	TIME [epoch: 9.76 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7264557499480842		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 1.7264557499480842 | validation: 0.9076054048133242]
	TIME [epoch: 9.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.969298596150491		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 0.969298596150491 | validation: 0.8285283565322462]
	TIME [epoch: 9.77 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8909586092133839		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 0.8909586092133839 | validation: 1.0700890543895774]
	TIME [epoch: 9.78 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4334699686014187		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 1.4334699686014187 | validation: 1.011932864691468]
	TIME [epoch: 9.75 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0583065174667288		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 1.0583065174667288 | validation: 1.076834572705272]
	TIME [epoch: 9.75 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1379446463116565		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 1.1379446463116565 | validation: 1.8544839712992434]
	TIME [epoch: 9.77 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4427538992704254		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 1.4427538992704254 | validation: 0.9669882519750752]
	TIME [epoch: 9.76 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9818000243925908		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 0.9818000243925908 | validation: 0.7379464967256257]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8453136608304689		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 0.8453136608304689 | validation: 0.7864055626141871]
	TIME [epoch: 9.77 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9825019718385419		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 0.9825019718385419 | validation: 0.7911539961631633]
	TIME [epoch: 9.77 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9066441132904984		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 0.9066441132904984 | validation: 0.9343125555919545]
	TIME [epoch: 9.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.847895295238731		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 0.847895295238731 | validation: 1.0984995760338507]
	TIME [epoch: 9.75 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8907451958064595		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 0.8907451958064595 | validation: 0.8040318630154218]
	TIME [epoch: 9.78 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0514811949642988		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 1.0514811949642988 | validation: 1.0697517616194165]
	TIME [epoch: 9.74 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9911994373490195		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 0.9911994373490195 | validation: 0.8586455550660447]
	TIME [epoch: 9.75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.125301464324949		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 1.125301464324949 | validation: 1.405377477305739]
	TIME [epoch: 9.77 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9655752005562901		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 0.9655752005562901 | validation: 1.1674033526346383]
	TIME [epoch: 9.75 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9199216787654256		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 0.9199216787654256 | validation: 0.9410267974448846]
	TIME [epoch: 9.75 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9067042125363001		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 0.9067042125363001 | validation: 0.9035112699316471]
	TIME [epoch: 9.75 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.131151947059028		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.131151947059028 | validation: 0.8831030990477772]
	TIME [epoch: 10.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9411425645300943		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 0.9411425645300943 | validation: 0.7392463861416271]
	TIME [epoch: 9.76 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9730151588077828		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 0.9730151588077828 | validation: 0.8838026893179339]
	TIME [epoch: 9.76 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8152610791219643		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 0.8152610791219643 | validation: 0.623768460692435]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.809287775881014		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 0.809287775881014 | validation: 1.1664946554742783]
	TIME [epoch: 9.76 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8826247385458427		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 0.8826247385458427 | validation: 0.5988620570743646]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.717717966332826		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 0.717717966332826 | validation: 0.7951901187077022]
	TIME [epoch: 9.79 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9018802649423444		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 0.9018802649423444 | validation: 1.184362784301197]
	TIME [epoch: 9.77 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8044585562240736		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 0.8044585562240736 | validation: 0.7660332505507103]
	TIME [epoch: 9.75 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9253800083250632		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 0.9253800083250632 | validation: 0.882248916896973]
	TIME [epoch: 9.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9203322931562422		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 0.9203322931562422 | validation: 0.7058638963938358]
	TIME [epoch: 9.77 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9051325414267355		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 0.9051325414267355 | validation: 0.6848536669984836]
	TIME [epoch: 9.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8604835801829568		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 0.8604835801829568 | validation: 0.8432915196559817]
	TIME [epoch: 9.76 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6819654864481139		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 0.6819654864481139 | validation: 0.6945134323806067]
	TIME [epoch: 9.78 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7554682520399357		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 0.7554682520399357 | validation: 0.708345914787871]
	TIME [epoch: 9.75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7067460317495551		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 0.7067460317495551 | validation: 0.6821279171704816]
	TIME [epoch: 9.75 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6869394059705036		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 0.6869394059705036 | validation: 0.8011560618820672]
	TIME [epoch: 9.77 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9034104161238835		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 0.9034104161238835 | validation: 0.6900795742006023]
	TIME [epoch: 9.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556924466946746		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 0.6556924466946746 | validation: 1.4229426966503314]
	TIME [epoch: 9.76 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2180058387558925		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 1.2180058387558925 | validation: 0.8056668564817944]
	TIME [epoch: 9.76 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7702771730119751		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 0.7702771730119751 | validation: 0.6552661640585485]
	TIME [epoch: 9.78 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7494469115423662		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 0.7494469115423662 | validation: 2.2859252404265464]
	TIME [epoch: 9.76 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0766065625266026		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 1.0766065625266026 | validation: 0.7875129482732918]
	TIME [epoch: 9.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6449723753322629		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 0.6449723753322629 | validation: 0.7966138704037735]
	TIME [epoch: 9.77 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7871009325065212		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 0.7871009325065212 | validation: 0.8727720464204218]
	TIME [epoch: 9.77 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.034891828999497		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 1.034891828999497 | validation: 0.6308882991139328]
	TIME [epoch: 9.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7110614361340909		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 0.7110614361340909 | validation: 0.6002113081698293]
	TIME [epoch: 9.77 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6616245978086635		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 0.6616245978086635 | validation: 0.5608881931858077]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6899758445115188		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 0.6899758445115188 | validation: 0.7359494422228718]
	TIME [epoch: 9.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8217699553397797		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 0.8217699553397797 | validation: 0.7708137389013956]
	TIME [epoch: 9.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7010785086288267		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 0.7010785086288267 | validation: 0.6030150896406963]
	TIME [epoch: 9.79 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0377965275967669		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 1.0377965275967669 | validation: 0.8644316098918122]
	TIME [epoch: 9.77 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7302073366404993		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.7302073366404993 | validation: 0.6484530899775729]
	TIME [epoch: 9.77 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8208768309423913		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 0.8208768309423913 | validation: 1.9301722939944757]
	TIME [epoch: 9.78 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.057352977457175		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 1.057352977457175 | validation: 0.7347433124117461]
	TIME [epoch: 9.77 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7155394194313558		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 0.7155394194313558 | validation: 0.6252691701253168]
	TIME [epoch: 9.75 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7552665773855791		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 0.7552665773855791 | validation: 0.7980098430984385]
	TIME [epoch: 9.75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7934334161819407		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 1.7934334161819407 | validation: 1.1632227351338984]
	TIME [epoch: 9.77 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9566611023245443		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 0.9566611023245443 | validation: 0.7738218755879476]
	TIME [epoch: 9.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7856889922641938		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 0.7856889922641938 | validation: 0.9386656409442498]
	TIME [epoch: 9.75 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9703901446424716		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 0.9703901446424716 | validation: 0.709743909366251]
	TIME [epoch: 9.77 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8580788255494737		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 0.8580788255494737 | validation: 1.3932949940093142]
	TIME [epoch: 9.75 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.853275815729382		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.853275815729382 | validation: 0.7766869996565001]
	TIME [epoch: 9.75 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7018357420152822		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 0.7018357420152822 | validation: 1.2543980083808233]
	TIME [epoch: 9.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0189036905343474		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 1.0189036905343474 | validation: 0.9862078192395806]
	TIME [epoch: 9.77 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0354624744917658		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 1.0354624744917658 | validation: 0.9514724067996372]
	TIME [epoch: 9.75 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8872474344534336		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.8872474344534336 | validation: 1.3899059559660578]
	TIME [epoch: 9.75 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9033696041637403		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 0.9033696041637403 | validation: 0.7384681386134951]
	TIME [epoch: 9.77 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7978068456002461		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 0.7978068456002461 | validation: 0.6910439366041802]
	TIME [epoch: 9.75 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1986716532618134		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 1.1986716532618134 | validation: 1.1562302584044355]
	TIME [epoch: 9.75 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0537192831827173		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 1.0537192831827173 | validation: 0.9473922976333347]
	TIME [epoch: 9.77 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7421497273219841		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.7421497273219841 | validation: 0.704985297347545]
	TIME [epoch: 9.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5884833549723789		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.5884833549723789 | validation: 1.229452483717476]
	TIME [epoch: 9.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9601387736744439		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.9601387736744439 | validation: 2.0533556437226315]
	TIME [epoch: 9.76 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.854542322060798		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 1.854542322060798 | validation: 1.683067691765625]
	TIME [epoch: 9.77 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8341766648740887		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.8341766648740887 | validation: 0.9031624634072997]
	TIME [epoch: 9.75 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7561941101970583		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 0.7561941101970583 | validation: 1.0638251131224206]
	TIME [epoch: 9.75 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7489276644930631		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.7489276644930631 | validation: 0.8689656881378709]
	TIME [epoch: 9.77 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7854004308103272		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 0.7854004308103272 | validation: 0.7824435180818584]
	TIME [epoch: 9.75 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5248413877947398		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 1.5248413877947398 | validation: 0.8728434958611103]
	TIME [epoch: 9.75 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0733612168171622		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 1.0733612168171622 | validation: 1.0044102921397926]
	TIME [epoch: 9.76 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8945554889459014		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 0.8945554889459014 | validation: 1.2476341358968512]
	TIME [epoch: 9.76 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0140513726280478		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 1.0140513726280478 | validation: 0.6017565473975198]
	TIME [epoch: 9.75 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8979034090808087		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 0.8979034090808087 | validation: 0.9709336951126676]
	TIME [epoch: 9.75 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.919538227439126		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 0.919538227439126 | validation: 0.7338209757296985]
	TIME [epoch: 9.78 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8066708873431253		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 0.8066708873431253 | validation: 1.0297383854760584]
	TIME [epoch: 9.75 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7785810557248573		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 0.7785810557248573 | validation: 0.711222263050837]
	TIME [epoch: 9.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7741885115575563		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 0.7741885115575563 | validation: 0.8654771804339515]
	TIME [epoch: 9.76 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7853389773257942		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 0.7853389773257942 | validation: 0.830534638686134]
	TIME [epoch: 9.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8239024427938697		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.8239024427938697 | validation: 0.8083097246836863]
	TIME [epoch: 9.76 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9389687460638425		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 0.9389687460638425 | validation: 1.7013429692081448]
	TIME [epoch: 9.77 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8917115973285256		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 0.8917115973285256 | validation: 0.8338220415139047]
	TIME [epoch: 9.77 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7489115187074982		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 0.7489115187074982 | validation: 0.8261319722365781]
	TIME [epoch: 9.76 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8138460049908908		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 0.8138460049908908 | validation: 0.7733448227782955]
	TIME [epoch: 9.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7481972442639331		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 0.7481972442639331 | validation: 1.2592447548879522]
	TIME [epoch: 9.78 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7934371171957619		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 0.7934371171957619 | validation: 0.8571345012012052]
	TIME [epoch: 9.76 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7696773805024113		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 0.7696773805024113 | validation: 0.8061268271157874]
	TIME [epoch: 9.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7726974979930867		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 0.7726974979930867 | validation: 0.8582655363838714]
	TIME [epoch: 9.77 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7584267793538076		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 0.7584267793538076 | validation: 0.8216013194114351]
	TIME [epoch: 9.76 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8180512858213834		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 0.8180512858213834 | validation: 0.7238387496451777]
	TIME [epoch: 9.75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7732279263402855		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 0.7732279263402855 | validation: 1.062466843754025]
	TIME [epoch: 9.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8755333330997954		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 0.8755333330997954 | validation: 0.809470710202934]
	TIME [epoch: 9.77 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.700331620605783		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 0.700331620605783 | validation: 0.6993032492697117]
	TIME [epoch: 9.75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9222026901137351		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 0.9222026901137351 | validation: 0.8320798756804854]
	TIME [epoch: 9.75 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.798288444821184		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 0.798288444821184 | validation: 0.7449492577563203]
	TIME [epoch: 9.77 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8081244858593382		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 0.8081244858593382 | validation: 1.1014928202018976]
	TIME [epoch: 9.75 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.847051835727021		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 0.847051835727021 | validation: 1.035000600547986]
	TIME [epoch: 9.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8062264025041224		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 0.8062264025041224 | validation: 1.3558071996299543]
	TIME [epoch: 9.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9143000353093456		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 0.9143000353093456 | validation: 0.6312693062544137]
	TIME [epoch: 9.77 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8272431952279335		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 0.8272431952279335 | validation: 0.7265254341798166]
	TIME [epoch: 9.75 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7264471906908933		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 0.7264471906908933 | validation: 1.0871918321220642]
	TIME [epoch: 9.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8260199603250916		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 0.8260199603250916 | validation: 0.7493527880608661]
	TIME [epoch: 9.78 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6719677590763447		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 0.6719677590763447 | validation: 0.8087000578510883]
	TIME [epoch: 9.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7059536157530298		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 0.7059536157530298 | validation: 0.703873111561679]
	TIME [epoch: 9.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7066036551579078		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 0.7066036551579078 | validation: 0.7512265338341071]
	TIME [epoch: 9.77 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2847391309532128		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 1.2847391309532128 | validation: 0.845077639059376]
	TIME [epoch: 9.75 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7480199006327849		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 0.7480199006327849 | validation: 0.7297437436731363]
	TIME [epoch: 9.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.681995384983599		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 0.681995384983599 | validation: 0.7244176006484598]
	TIME [epoch: 9.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7543074162730729		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 0.7543074162730729 | validation: 0.683443951744939]
	TIME [epoch: 9.77 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.786626485566314		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 0.786626485566314 | validation: 0.8791718788428884]
	TIME [epoch: 9.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7330628878181041		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 0.7330628878181041 | validation: 0.6758410414299906]
	TIME [epoch: 9.75 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6849600692146691		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 0.6849600692146691 | validation: 0.8419259599335587]
	TIME [epoch: 9.77 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7442975395073849		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 0.7442975395073849 | validation: 0.6976031496746186]
	TIME [epoch: 9.76 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6647799563142631		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 0.6647799563142631 | validation: 0.804464171547731]
	TIME [epoch: 9.75 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7047090205036733		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 0.7047090205036733 | validation: 0.827496657421797]
	TIME [epoch: 9.76 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.803777805615573		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 0.803777805615573 | validation: 0.7432890867607218]
	TIME [epoch: 9.78 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8250794563318695		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 0.8250794563318695 | validation: 0.9496275270526207]
	TIME [epoch: 9.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1268750890289259		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 1.1268750890289259 | validation: 0.7395567872799435]
	TIME [epoch: 9.75 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7348419524855059		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 0.7348419524855059 | validation: 0.6732187985485116]
	TIME [epoch: 9.78 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.730529918132399		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 0.730529918132399 | validation: 0.8955631159256329]
	TIME [epoch: 9.76 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7527369053325819		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 0.7527369053325819 | validation: 0.7037397486108727]
	TIME [epoch: 9.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6595470037896101		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 0.6595470037896101 | validation: 0.8299670800786069]
	TIME [epoch: 9.78 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6401998381659932		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 0.6401998381659932 | validation: 0.8426578688269933]
	TIME [epoch: 9.75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8400631283327679		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 0.8400631283327679 | validation: 0.9661194682381684]
	TIME [epoch: 9.75 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8344987965247072		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 0.8344987965247072 | validation: 0.9301708709514048]
	TIME [epoch: 9.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7707983927640688		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 0.7707983927640688 | validation: 0.7183715593019815]
	TIME [epoch: 9.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7546287668833447		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 0.7546287668833447 | validation: 0.7874493346347995]
	TIME [epoch: 9.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.763305440109229		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.763305440109229 | validation: 0.7120663313104402]
	TIME [epoch: 9.76 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.659837140011222		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.659837140011222 | validation: 0.7174517785653015]
	TIME [epoch: 9.77 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.759795763751807		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.759795763751807 | validation: 0.8092172447496373]
	TIME [epoch: 9.75 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6603280208070754		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 0.6603280208070754 | validation: 0.7915436143442783]
	TIME [epoch: 9.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6567750988913001		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.6567750988913001 | validation: 0.9072821608697401]
	TIME [epoch: 9.75 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9598576753146053		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.9598576753146053 | validation: 0.6983874438487926]
	TIME [epoch: 9.77 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8247688058176722		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.8247688058176722 | validation: 0.5921564272717972]
	TIME [epoch: 9.76 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8204256824334927		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 0.8204256824334927 | validation: 1.407975368020787]
	TIME [epoch: 9.75 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0620194677602697		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 1.0620194677602697 | validation: 0.8827316081348434]
	TIME [epoch: 9.78 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8729709114691794		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.8729709114691794 | validation: 0.5817623598527407]
	TIME [epoch: 9.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.759592826593798		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.759592826593798 | validation: 0.775172803176067]
	TIME [epoch: 9.76 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7474789272041031		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.7474789272041031 | validation: 0.6882356499412723]
	TIME [epoch: 9.78 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6675579934036474		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.6675579934036474 | validation: 0.6014693723853598]
	TIME [epoch: 9.76 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7154975411150298		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 0.7154975411150298 | validation: 0.6651527305043302]
	TIME [epoch: 9.75 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7315737351682077		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 0.7315737351682077 | validation: 0.6988317251337764]
	TIME [epoch: 9.75 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6945670041617131		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.6945670041617131 | validation: 0.7391030760498046]
	TIME [epoch: 9.77 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9757944017916215		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.9757944017916215 | validation: 1.2690253046914215]
	TIME [epoch: 9.74 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.761756723444192		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 0.761756723444192 | validation: 0.7217880935639766]
	TIME [epoch: 9.75 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6946170021622555		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.6946170021622555 | validation: 0.710470334937861]
	TIME [epoch: 9.78 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.753149872803012		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.753149872803012 | validation: 1.2756427416669867]
	TIME [epoch: 9.75 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7942850776583532		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.7942850776583532 | validation: 0.6402329473037688]
	TIME [epoch: 9.75 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6871067894233672		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 0.6871067894233672 | validation: 0.7075480178562079]
	TIME [epoch: 9.76 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6698609504682501		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.6698609504682501 | validation: 0.699941473196221]
	TIME [epoch: 9.77 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6254920955917775		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.6254920955917775 | validation: 0.62745937137365]
	TIME [epoch: 9.75 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9767169390474812		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.9767169390474812 | validation: 1.6080170577954918]
	TIME [epoch: 9.75 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8479937092531866		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 0.8479937092531866 | validation: 0.6710907923901729]
	TIME [epoch: 9.78 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6523506968926365		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.6523506968926365 | validation: 0.7027339057001427]
	TIME [epoch: 9.75 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6928863008503428		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.6928863008503428 | validation: 0.6391037174507078]
	TIME [epoch: 9.74 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7802469279320737		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.7802469279320737 | validation: 1.2129569802769953]
	TIME [epoch: 9.78 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8951863315087557		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.8951863315087557 | validation: 0.6077080889530498]
	TIME [epoch: 9.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.757171322022374		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.757171322022374 | validation: 0.711573504043609]
	TIME [epoch: 9.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6693553655422882		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 0.6693553655422882 | validation: 0.5894260665249114]
	TIME [epoch: 9.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5753907828543239		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.5753907828543239 | validation: 0.6304053055953726]
	TIME [epoch: 9.77 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6675031127092735		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 0.6675031127092735 | validation: 0.5777863799447588]
	TIME [epoch: 9.75 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6788056719978479		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 0.6788056719978479 | validation: 0.5733023915969937]
	TIME [epoch: 9.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.741956770268399		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.741956770268399 | validation: 0.5913476676723535]
	TIME [epoch: 9.77 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7876378794050634		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.7876378794050634 | validation: 0.5390690445688273]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7129167699434183		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.7129167699434183 | validation: 0.6080249634544205]
	TIME [epoch: 9.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6003680776154787		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.6003680776154787 | validation: 0.5850708294144089]
	TIME [epoch: 9.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2567830695473188		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 1.2567830695473188 | validation: 0.7571184364250533]
	TIME [epoch: 9.76 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284787652469311		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 0.6284787652469311 | validation: 0.5527596797911327]
	TIME [epoch: 9.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6160723639601315		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.6160723639601315 | validation: 0.620014729990111]
	TIME [epoch: 9.74 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5815834167258069		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 0.5815834167258069 | validation: 0.6723719077678507]
	TIME [epoch: 9.77 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6196472185971085		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.6196472185971085 | validation: 0.5380855654513889]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440190399744311		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.5440190399744311 | validation: 0.7515353843296118]
	TIME [epoch: 9.76 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6644834459245115		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.6644834459245115 | validation: 0.5348905498027803]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6280691677151012		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.6280691677151012 | validation: 0.828100393041089]
	TIME [epoch: 9.76 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6227365021878271		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.6227365021878271 | validation: 0.6169023253373113]
	TIME [epoch: 9.75 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5801503900335208		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.5801503900335208 | validation: 0.6226876303343388]
	TIME [epoch: 9.77 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6323037229682824		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 0.6323037229682824 | validation: 0.6999519383317415]
	TIME [epoch: 9.76 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6466425845749597		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.6466425845749597 | validation: 0.6207815970089695]
	TIME [epoch: 9.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6426774412479372		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.6426774412479372 | validation: 0.7140123584206498]
	TIME [epoch: 9.75 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6529524103103166		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.6529524103103166 | validation: 0.9162223146783484]
	TIME [epoch: 9.78 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7631901116274099		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.7631901116274099 | validation: 0.7349472894018513]
	TIME [epoch: 9.75 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6387518635241017		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.6387518635241017 | validation: 0.7735042862025466]
	TIME [epoch: 9.75 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7075266682671464		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.7075266682671464 | validation: 0.7022743259678639]
	TIME [epoch: 9.76 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7390334018528228		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.7390334018528228 | validation: 0.7064660988739253]
	TIME [epoch: 9.75 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7220158731454049		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.7220158731454049 | validation: 0.6427929365787636]
	TIME [epoch: 9.75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6844075309464386		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.6844075309464386 | validation: 0.7164748446768888]
	TIME [epoch: 9.75 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6561080653585026		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.6561080653585026 | validation: 0.6457553188919418]
	TIME [epoch: 9.76 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6787750701419102		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 0.6787750701419102 | validation: 0.7718730798176671]
	TIME [epoch: 9.75 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5927007078007207		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.5927007078007207 | validation: 1.0668736756190664]
	TIME [epoch: 9.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7902687302709093		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.7902687302709093 | validation: 0.6287737546957315]
	TIME [epoch: 9.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6205667517769656		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.6205667517769656 | validation: 0.6167807439059423]
	TIME [epoch: 9.75 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6258505491904951		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.6258505491904951 | validation: 0.7520086627435117]
	TIME [epoch: 9.75 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6423645584628657		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.6423645584628657 | validation: 0.6173736082310647]
	TIME [epoch: 9.77 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6812122465642364		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.6812122465642364 | validation: 0.7185924954669679]
	TIME [epoch: 9.76 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6566503215053615		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.6566503215053615 | validation: 0.709136803196908]
	TIME [epoch: 9.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7413301951193638		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.7413301951193638 | validation: 0.8497470546155205]
	TIME [epoch: 9.75 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6927574303271157		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 0.6927574303271157 | validation: 0.5626794304981755]
	TIME [epoch: 9.77 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6003201984874759		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.6003201984874759 | validation: 0.8452602772731046]
	TIME [epoch: 9.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6199402086998622		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.6199402086998622 | validation: 0.5352177331070254]
	TIME [epoch: 9.76 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389891395511633		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.6389891395511633 | validation: 0.6993842100492126]
	TIME [epoch: 9.77 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6165177226013678		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.6165177226013678 | validation: 0.6933791418827399]
	TIME [epoch: 9.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7067711474871209		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 0.7067711474871209 | validation: 1.0019359556056282]
	TIME [epoch: 9.75 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6663981956628205		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.6663981956628205 | validation: 0.6308021963711307]
	TIME [epoch: 9.76 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6030204625499695		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.6030204625499695 | validation: 0.8154690832628332]
	TIME [epoch: 9.77 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6978928983890735		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.6978928983890735 | validation: 0.555668090659839]
	TIME [epoch: 9.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5868119152395244		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.5868119152395244 | validation: 0.8625086313840743]
	TIME [epoch: 9.75 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6332156748660075		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.6332156748660075 | validation: 0.741024957018848]
	TIME [epoch: 9.77 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676422299791668		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.5676422299791668 | validation: 0.9248467788423773]
	TIME [epoch: 9.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6575536547773084		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.6575536547773084 | validation: 0.592445441262869]
	TIME [epoch: 9.75 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6947263675503995		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.6947263675503995 | validation: 0.5626783049385468]
	TIME [epoch: 9.77 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.613317777246149		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.613317777246149 | validation: 0.5380286981836647]
	TIME [epoch: 9.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5759157904167547		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.5759157904167547 | validation: 0.5889180596842063]
	TIME [epoch: 9.75 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5879791217477399		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.5879791217477399 | validation: 0.5242373000898444]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5238447987713442		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.5238447987713442 | validation: 0.6673803476486725]
	TIME [epoch: 9.77 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.530302347649126		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.530302347649126 | validation: 0.6032337712473219]
	TIME [epoch: 9.74 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6756035387084437		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.6756035387084437 | validation: 0.5667740105000583]
	TIME [epoch: 9.74 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5034343680539196		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.5034343680539196 | validation: 0.6521306029373528]
	TIME [epoch: 9.77 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6975857596228685		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.6975857596228685 | validation: 0.6027015194587088]
	TIME [epoch: 9.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5290384099293495		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.5290384099293495 | validation: 0.8181606773548843]
	TIME [epoch: 9.74 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5793937804591318		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.5793937804591318 | validation: 0.6375409951793912]
	TIME [epoch: 9.75 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5788650703220635		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.5788650703220635 | validation: 0.5389920464561994]
	TIME [epoch: 9.76 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4642270247571256		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.4642270247571256 | validation: 0.5206440371607257]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4755029357692517		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.4755029357692517 | validation: 0.5193500128260857]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5012562696464102		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.5012562696464102 | validation: 0.5676714943526878]
	TIME [epoch: 9.78 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5638768458182574		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.5638768458182574 | validation: 1.1362441017243048]
	TIME [epoch: 9.76 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6428558478004052		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.6428558478004052 | validation: 0.4778645615168419]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610434128199099		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.5610434128199099 | validation: 0.5041578677822084]
	TIME [epoch: 9.78 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7150618521347673		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.7150618521347673 | validation: 0.5164353813291149]
	TIME [epoch: 9.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5579174518701508		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.5579174518701508 | validation: 0.45766165110540913]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4627320477899916		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.4627320477899916 | validation: 0.7532205022285514]
	TIME [epoch: 9.76 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807971647000938		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.5807971647000938 | validation: 0.43995517105276305]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6766870463480996		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.6766870463480996 | validation: 0.5606635401681507]
	TIME [epoch: 9.77 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6899404509393339		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.6899404509393339 | validation: 0.8369707800262959]
	TIME [epoch: 9.75 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6799831162550438		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.6799831162550438 | validation: 0.46294793420899566]
	TIME [epoch: 9.78 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5071407161869832		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.5071407161869832 | validation: 0.4110018694439392]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6228472757044683		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.6228472757044683 | validation: 0.4558643400250006]
	TIME [epoch: 9.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5045503800218432		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.5045503800218432 | validation: 0.3976227164954922]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45856273663165475		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.45856273663165475 | validation: 0.49429889285339385]
	TIME [epoch: 9.76 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180980012433187		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.5180980012433187 | validation: 0.4429673582218184]
	TIME [epoch: 9.76 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965083297756837		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.5965083297756837 | validation: 0.46736449298755434]
	TIME [epoch: 9.77 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7229834707650751		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.7229834707650751 | validation: 0.47948466148825986]
	TIME [epoch: 9.77 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6219238820064662		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.6219238820064662 | validation: 0.48279679145234483]
	TIME [epoch: 9.76 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4949107004615598		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.4949107004615598 | validation: 0.745336806511066]
	TIME [epoch: 9.76 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6842496760041066		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.6842496760041066 | validation: 0.4038016677815369]
	TIME [epoch: 9.78 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300191776765973		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.5300191776765973 | validation: 0.48761087965284255]
	TIME [epoch: 9.76 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5683016437688113		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.5683016437688113 | validation: 0.8451062012051535]
	TIME [epoch: 9.76 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5729257897301622		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.5729257897301622 | validation: 0.6973819093104373]
	TIME [epoch: 9.78 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5009903044209929		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.5009903044209929 | validation: 0.3850576757144748]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651161381690477		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.6651161381690477 | validation: 0.5723308775601923]
	TIME [epoch: 9.77 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4995040368904943		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.4995040368904943 | validation: 0.4165955235629403]
	TIME [epoch: 9.77 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48055596344137497		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.48055596344137497 | validation: 0.5343781808150068]
	TIME [epoch: 9.78 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49704443897316963		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.49704443897316963 | validation: 0.4499106468933972]
	TIME [epoch: 9.76 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5623774834608427		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.5623774834608427 | validation: 0.4851765275586433]
	TIME [epoch: 9.77 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5028321642314392		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.5028321642314392 | validation: 0.5544475921755756]
	TIME [epoch: 9.79 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5479236798045737		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.5479236798045737 | validation: 0.4666867322849686]
	TIME [epoch: 9.77 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.652036349067602		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.652036349067602 | validation: 0.6205213699691827]
	TIME [epoch: 9.76 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.722557896475623		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.722557896475623 | validation: 0.6238591167162371]
	TIME [epoch: 9.78 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254378141102151		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.5254378141102151 | validation: 0.450341617287855]
	TIME [epoch: 9.76 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4866280673208907		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.4866280673208907 | validation: 0.403977194146526]
	TIME [epoch: 9.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48795976516277284		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.48795976516277284 | validation: 0.45587288931633224]
	TIME [epoch: 9.76 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7095086758395525		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.7095086758395525 | validation: 0.4236653731799846]
	TIME [epoch: 9.78 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4733400639253656		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.4733400639253656 | validation: 0.45493697708070213]
	TIME [epoch: 9.76 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4894428562012683		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.4894428562012683 | validation: 0.49783891994096535]
	TIME [epoch: 9.76 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41727351678141333		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.41727351678141333 | validation: 0.38922304703209776]
	TIME [epoch: 9.79 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6131084784557856		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.6131084784557856 | validation: 0.4166850291802425]
	TIME [epoch: 9.77 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086344549087454		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.5086344549087454 | validation: 0.682938357214178]
	TIME [epoch: 9.76 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5066914283921184		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.5066914283921184 | validation: 0.4577549128017656]
	TIME [epoch: 9.77 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811292037671166		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.6811292037671166 | validation: 0.5210094375724994]
	TIME [epoch: 9.78 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4464326062927402		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.4464326062927402 | validation: 0.37798129810732817]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_522.pth
	Model improved!!!
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4555885791666422		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.4555885791666422 | validation: 0.42323328015536077]
	TIME [epoch: 9.76 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5531900266015956		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.5531900266015956 | validation: 0.4228755295865257]
	TIME [epoch: 9.78 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39132993347049466		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.39132993347049466 | validation: 0.5975619068583012]
	TIME [epoch: 9.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259642822401525		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.5259642822401525 | validation: 0.5028110138636888]
	TIME [epoch: 9.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45596328837015737		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.45596328837015737 | validation: 0.39840864068429843]
	TIME [epoch: 9.77 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47458128834445634		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.47458128834445634 | validation: 0.43069884732405683]
	TIME [epoch: 9.76 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46747697172355923		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.46747697172355923 | validation: 0.46234563603124]
	TIME [epoch: 9.76 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4424193651064187		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.4424193651064187 | validation: 0.5232975960647501]
	TIME [epoch: 9.77 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.506654083263426		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.506654083263426 | validation: 0.44884527020306475]
	TIME [epoch: 9.77 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40159870427766087		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.40159870427766087 | validation: 0.6012853664933683]
	TIME [epoch: 9.76 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6161096460553315		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.6161096460553315 | validation: 0.7840220061580814]
	TIME [epoch: 9.75 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4918024315083421		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.4918024315083421 | validation: 0.5971336664353765]
	TIME [epoch: 9.78 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576491526133368		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.4576491526133368 | validation: 0.33432362675888655]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4239205657885619		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.4239205657885619 | validation: 0.32087721483859305]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4099843159220817		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.4099843159220817 | validation: 0.5734249609252363]
	TIME [epoch: 9.78 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.496258870043072		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.496258870043072 | validation: 0.5161371132197599]
	TIME [epoch: 9.77 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43688556724107297		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.43688556724107297 | validation: 0.39346063872241716]
	TIME [epoch: 9.76 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4492553228180296		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.4492553228180296 | validation: 0.42007215510895857]
	TIME [epoch: 9.76 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4316467039410815		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.4316467039410815 | validation: 0.47077621956801524]
	TIME [epoch: 9.78 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6540181232105231		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.6540181232105231 | validation: 0.8480036733273764]
	TIME [epoch: 9.76 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.546717406259599		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.546717406259599 | validation: 0.35575928940631485]
	TIME [epoch: 9.76 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46027499555916024		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.46027499555916024 | validation: 0.7393570845817261]
	TIME [epoch: 9.78 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518663101774062		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.518663101774062 | validation: 0.3782153150549239]
	TIME [epoch: 9.77 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4797998717146365		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.4797998717146365 | validation: 0.37793281270236984]
	TIME [epoch: 9.76 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44394397720537676		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.44394397720537676 | validation: 0.38090949397565765]
	TIME [epoch: 9.77 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36350781289486805		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.36350781289486805 | validation: 0.36887879417290925]
	TIME [epoch: 9.78 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3855088401981078		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.3855088401981078 | validation: 0.29882151880929025]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4032898095346097		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.4032898095346097 | validation: 0.4174980166496996]
	TIME [epoch: 9.77 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5068806456751572		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.5068806456751572 | validation: 0.47361024460349244]
	TIME [epoch: 9.78 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.443229598157734		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.443229598157734 | validation: 0.3715013549069029]
	TIME [epoch: 9.76 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3724867412638558		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.3724867412638558 | validation: 0.3634043837645131]
	TIME [epoch: 9.75 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6663682194225994		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.6663682194225994 | validation: 0.39380506923897807]
	TIME [epoch: 9.78 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909514099124779		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.3909514099124779 | validation: 0.3693733826805564]
	TIME [epoch: 9.76 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5222314815360816		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.5222314815360816 | validation: 0.39937382955882456]
	TIME [epoch: 9.75 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43277165850302		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.43277165850302 | validation: 0.3047745508351975]
	TIME [epoch: 9.77 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40676817836336676		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.40676817836336676 | validation: 0.290763871751836]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576308843887621		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.4576308843887621 | validation: 0.34469228463097634]
	TIME [epoch: 9.76 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3493979397307734		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.3493979397307734 | validation: 0.4849677261296993]
	TIME [epoch: 9.74 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5126604884281096		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.5126604884281096 | validation: 0.3864672854571573]
	TIME [epoch: 9.78 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37482962951168297		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.37482962951168297 | validation: 0.5679105721545133]
	TIME [epoch: 9.75 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.633278991144451		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.633278991144451 | validation: 0.4006768817774797]
	TIME [epoch: 9.76 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3764525652409677		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.3764525652409677 | validation: 0.3557070330895698]
	TIME [epoch: 9.78 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38644052395694867		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.38644052395694867 | validation: 0.5119333479486076]
	TIME [epoch: 9.77 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34879656776121637		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.34879656776121637 | validation: 0.4683241851266503]
	TIME [epoch: 9.75 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.418019500882688		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.418019500882688 | validation: 0.3741383299634525]
	TIME [epoch: 9.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4902387080517582		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.4902387080517582 | validation: 0.7062196990575771]
	TIME [epoch: 9.77 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4983578772704506		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.4983578772704506 | validation: 0.40279298137115055]
	TIME [epoch: 9.76 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6210874626826245		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.6210874626826245 | validation: 0.5440978570963978]
	TIME [epoch: 9.75 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5730865120212115		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.5730865120212115 | validation: 0.34708402440818853]
	TIME [epoch: 9.77 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44235623540894153		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 0.44235623540894153 | validation: 0.2886816932604531]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6898591537765674		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.6898591537765674 | validation: 1.1720331879514665]
	TIME [epoch: 9.75 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6307138180492302		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.6307138180492302 | validation: 0.46785201229467893]
	TIME [epoch: 9.77 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3854556498972036		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.3854556498972036 | validation: 0.4084401125916095]
	TIME [epoch: 9.76 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3722819247328546		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.3722819247328546 | validation: 0.32167050879112297]
	TIME [epoch: 9.75 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40883500122072547		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.40883500122072547 | validation: 0.36928341336685727]
	TIME [epoch: 9.75 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6490574521761682		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.6490574521761682 | validation: 0.37438493537494877]
	TIME [epoch: 9.76 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4129921083677665		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.4129921083677665 | validation: 0.42774834246801846]
	TIME [epoch: 9.74 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42618758953422586		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.42618758953422586 | validation: 0.4045825820565482]
	TIME [epoch: 9.75 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34450745611615624		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.34450745611615624 | validation: 0.4158367336427299]
	TIME [epoch: 9.77 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43347255718966504		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.43347255718966504 | validation: 0.2978154291955441]
	TIME [epoch: 9.76 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3722679811111178		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.3722679811111178 | validation: 0.3706597435242331]
	TIME [epoch: 9.75 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3618753382795824		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.3618753382795824 | validation: 0.43452733240398717]
	TIME [epoch: 9.76 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4513613041431433		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.4513613041431433 | validation: 0.3017139689578766]
	TIME [epoch: 9.77 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38841827296116305		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.38841827296116305 | validation: 0.4774474054405178]
	TIME [epoch: 9.75 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35857897120028603		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.35857897120028603 | validation: 0.3246515343943615]
	TIME [epoch: 9.75 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5690004131077908		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.5690004131077908 | validation: 0.32897243449300606]
	TIME [epoch: 9.77 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3471321260543417		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.3471321260543417 | validation: 0.44442201609506776]
	TIME [epoch: 9.75 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47028267981505917		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.47028267981505917 | validation: 0.5465014342717244]
	TIME [epoch: 9.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3583196002738275		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.3583196002738275 | validation: 0.3347897557233763]
	TIME [epoch: 9.77 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4411241468589745		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.4411241468589745 | validation: 0.470565681938631]
	TIME [epoch: 9.74 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6772311865466507		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.6772311865466507 | validation: 0.4545375842713084]
	TIME [epoch: 9.75 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38552856156482773		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.38552856156482773 | validation: 0.43253997985852594]
	TIME [epoch: 9.75 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3761196363972467		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.3761196363972467 | validation: 0.3961836101007266]
	TIME [epoch: 9.76 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5356277880344137		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.5356277880344137 | validation: 1.0577300414789244]
	TIME [epoch: 9.74 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6211595479787047		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.6211595479787047 | validation: 0.4019053255048266]
	TIME [epoch: 9.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41334541211277565		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.41334541211277565 | validation: 0.2835456476173287]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43460367359704966		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.43460367359704966 | validation: 0.39593630064083074]
	TIME [epoch: 9.77 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4244833235869125		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.4244833235869125 | validation: 0.5807400215085272]
	TIME [epoch: 9.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4427503266107082		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.4427503266107082 | validation: 0.35886425770332225]
	TIME [epoch: 9.76 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3218005755145174		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.3218005755145174 | validation: 0.3672731285164395]
	TIME [epoch: 9.77 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35512966204382745		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.35512966204382745 | validation: 0.7834215242269404]
	TIME [epoch: 9.76 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47941008924954		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.47941008924954 | validation: 0.2932948005733508]
	TIME [epoch: 9.75 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3989476102452051		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.3989476102452051 | validation: 0.35441750071337524]
	TIME [epoch: 9.78 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4192122049467157		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.4192122049467157 | validation: 0.29155362948961433]
	TIME [epoch: 9.76 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3692862992730383		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.3692862992730383 | validation: 0.4529005729662673]
	TIME [epoch: 9.77 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43360812944301763		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.43360812944301763 | validation: 0.30912720126827525]
	TIME [epoch: 9.76 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3305872177032755		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.3305872177032755 | validation: 0.31336291691326734]
	TIME [epoch: 9.75 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3727679220826173		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.3727679220826173 | validation: 0.4834881286245]
	TIME [epoch: 9.75 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4065634252464719		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.4065634252464719 | validation: 0.33993167335336466]
	TIME [epoch: 9.75 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34216495957148396		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.34216495957148396 | validation: 0.3704862077052622]
	TIME [epoch: 9.78 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155433175008513		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.4155433175008513 | validation: 0.4293021690784313]
	TIME [epoch: 9.75 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3380433384183574		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.3380433384183574 | validation: 0.24734625168978264]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3376282807607357		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.3376282807607357 | validation: 0.3364770253599585]
	TIME [epoch: 9.78 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3635280208533183		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.3635280208533183 | validation: 0.32386546945465866]
	TIME [epoch: 9.75 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35607258529777075		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.35607258529777075 | validation: 0.45177105044175975]
	TIME [epoch: 9.75 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3634290781673423		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.3634290781673423 | validation: 0.4289095133675634]
	TIME [epoch: 9.76 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3523420319889229		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.3523420319889229 | validation: 0.22998197307423604]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_619.pth
	Model improved!!!
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977474711827306		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.3977474711827306 | validation: 0.32655888643272507]
	TIME [epoch: 9.75 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4760345174620732		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.4760345174620732 | validation: 0.38387683450399585]
	TIME [epoch: 9.75 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45249510621060224		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.45249510621060224 | validation: 0.3219353554056501]
	TIME [epoch: 9.77 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41244854287574945		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.41244854287574945 | validation: 0.5508462981101366]
	TIME [epoch: 9.75 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39099291411629933		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.39099291411629933 | validation: 0.3098789725989376]
	TIME [epoch: 9.75 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34917386900445757		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.34917386900445757 | validation: 0.42522253750432376]
	TIME [epoch: 9.78 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41590324064624956		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.41590324064624956 | validation: 0.32792179149514944]
	TIME [epoch: 9.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32807964678695994		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.32807964678695994 | validation: 0.37464485983875295]
	TIME [epoch: 9.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177065444032504		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.4177065444032504 | validation: 0.2691274705823089]
	TIME [epoch: 9.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3501976450462722		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.3501976450462722 | validation: 0.372886128826763]
	TIME [epoch: 9.77 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4892375112026596		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.4892375112026596 | validation: 0.3548434404137123]
	TIME [epoch: 9.75 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3535623226439423		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.3535623226439423 | validation: 0.29243315053506425]
	TIME [epoch: 9.75 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3701113570594834		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.3701113570594834 | validation: 0.2822060007358244]
	TIME [epoch: 9.78 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28838496185582463		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.28838496185582463 | validation: 0.2711771076880136]
	TIME [epoch: 9.75 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3345790413337337		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.3345790413337337 | validation: 0.42903577529254067]
	TIME [epoch: 9.74 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37083776159807147		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.37083776159807147 | validation: 0.26233248143358134]
	TIME [epoch: 9.77 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3055944013601415		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.3055944013601415 | validation: 0.3708178160082094]
	TIME [epoch: 9.75 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33400636857144417		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.33400636857144417 | validation: 0.2801430563345755]
	TIME [epoch: 9.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068027065186465		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.3068027065186465 | validation: 0.2919259594236292]
	TIME [epoch: 9.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31010588684572216		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.31010588684572216 | validation: 0.4549295748460315]
	TIME [epoch: 9.78 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3512315078143239		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.3512315078143239 | validation: 0.29789211337770216]
	TIME [epoch: 9.74 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35705447404277113		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.35705447404277113 | validation: 0.23056439240664658]
	TIME [epoch: 9.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142869623217061		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.3142869623217061 | validation: 0.28640187454387706]
	TIME [epoch: 9.77 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38052191086849807		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.38052191086849807 | validation: 0.3847434398291024]
	TIME [epoch: 9.75 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38915095459861054		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.38915095459861054 | validation: 0.4743045972005338]
	TIME [epoch: 9.75 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34372187227747386		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.34372187227747386 | validation: 0.27773098965708864]
	TIME [epoch: 9.75 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.434204708108909		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.434204708108909 | validation: 0.37522918172276143]
	TIME [epoch: 9.76 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32296501172402914		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.32296501172402914 | validation: 0.33970305865765127]
	TIME [epoch: 9.75 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31862278389290044		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.31862278389290044 | validation: 0.26074091719208964]
	TIME [epoch: 9.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3293674366452987		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.3293674366452987 | validation: 0.27156717164378197]
	TIME [epoch: 9.77 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29158977297977434		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.29158977297977434 | validation: 0.45511040569324607]
	TIME [epoch: 9.75 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5697654836855126		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.5697654836855126 | validation: 0.24844813992467724]
	TIME [epoch: 9.75 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30211759351217915		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.30211759351217915 | validation: 0.34749051563167926]
	TIME [epoch: 9.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37159912850052657		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.37159912850052657 | validation: 0.31093058153338193]
	TIME [epoch: 9.75 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076181381735876		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.3076181381735876 | validation: 0.3790763745683576]
	TIME [epoch: 9.76 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32197805419448244		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.32197805419448244 | validation: 0.22758802573469475]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30001334859142254		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.30001334859142254 | validation: 0.3237518434063371]
	TIME [epoch: 9.79 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30301244613244843		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.30301244613244843 | validation: 0.3363126873034372]
	TIME [epoch: 9.76 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3489891088232533		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.3489891088232533 | validation: 0.2898698172931386]
	TIME [epoch: 9.75 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42281713359309		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.42281713359309 | validation: 0.34049294623344833]
	TIME [epoch: 9.78 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4176560774638691		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.4176560774638691 | validation: 0.44156517034898757]
	TIME [epoch: 9.75 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39043391268274785		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.39043391268274785 | validation: 0.2733362602233699]
	TIME [epoch: 9.76 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3205129127413082		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.3205129127413082 | validation: 0.29377676559227484]
	TIME [epoch: 9.76 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305231785415912		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.305231785415912 | validation: 0.22854807064258467]
	TIME [epoch: 9.77 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2828310587923634		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.2828310587923634 | validation: 0.24193377730548846]
	TIME [epoch: 9.75 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26952755812978635		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.26952755812978635 | validation: 0.2869371087177202]
	TIME [epoch: 9.75 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3416085251814889		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.3416085251814889 | validation: 0.294995047804083]
	TIME [epoch: 9.77 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615777584268024		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.3615777584268024 | validation: 0.2223497109138882]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4078216027833089		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.4078216027833089 | validation: 0.27741416845175687]
	TIME [epoch: 9.78 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32626655303204444		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.32626655303204444 | validation: 0.4900866895313047]
	TIME [epoch: 9.77 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4669568398810099		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.4669568398810099 | validation: 0.19085412686178552]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23436412187266079		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.23436412187266079 | validation: 0.2642011129080393]
	TIME [epoch: 9.75 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.268240674384079		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.268240674384079 | validation: 0.2824178503312092]
	TIME [epoch: 9.76 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.456502120197188		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.456502120197188 | validation: 0.44045665586161664]
	TIME [epoch: 9.76 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34569658855636687		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.34569658855636687 | validation: 0.37450501871812436]
	TIME [epoch: 9.78 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33889186311347663		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.33889186311347663 | validation: 0.2927841093266487]
	TIME [epoch: 9.75 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27686462233692627		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.27686462233692627 | validation: 0.4141447396819818]
	TIME [epoch: 9.77 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34199095875251395		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.34199095875251395 | validation: 0.26084840597674946]
	TIME [epoch: 9.75 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28987835354150276		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.28987835354150276 | validation: 0.407340904996307]
	TIME [epoch: 9.75 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147436626356277		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.3147436626356277 | validation: 0.26201744403747723]
	TIME [epoch: 9.77 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623152355765672		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.2623152355765672 | validation: 0.6050957996845593]
	TIME [epoch: 9.75 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4461279505888781		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.4461279505888781 | validation: 0.41556838043384126]
	TIME [epoch: 9.75 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44570165441584564		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.44570165441584564 | validation: 0.3214830252786575]
	TIME [epoch: 9.75 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3656160823156055		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.3656160823156055 | validation: 0.36998732333706713]
	TIME [epoch: 9.77 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35008921064631215		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.35008921064631215 | validation: 0.3328405354333205]
	TIME [epoch: 9.75 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27073181782358324		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.27073181782358324 | validation: 0.6624783619314664]
	TIME [epoch: 9.76 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4508547443295754		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.4508547443295754 | validation: 0.26421322038964973]
	TIME [epoch: 9.77 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31863089429241487		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.31863089429241487 | validation: 0.30044820794823074]
	TIME [epoch: 9.75 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2822319329210222		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.2822319329210222 | validation: 0.4520368253685205]
	TIME [epoch: 9.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31788386092670906		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.31788386092670906 | validation: 0.21886383476697618]
	TIME [epoch: 9.76 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25946716402560865		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.25946716402560865 | validation: 0.387562734749678]
	TIME [epoch: 9.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2923939597765141		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.2923939597765141 | validation: 0.5693656447983745]
	TIME [epoch: 9.76 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32446451498286194		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.32446451498286194 | validation: 0.280970708120775]
	TIME [epoch: 9.75 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3132695730131763		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.3132695730131763 | validation: 0.317455933717119]
	TIME [epoch: 9.78 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3938921923975854		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.3938921923975854 | validation: 0.2422249338307803]
	TIME [epoch: 9.76 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3396325440255076		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.3396325440255076 | validation: 0.3067429507973427]
	TIME [epoch: 9.76 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2916041397150913		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.2916041397150913 | validation: 0.2934714184345091]
	TIME [epoch: 9.78 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2966647686178117		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.2966647686178117 | validation: 0.2821331281333875]
	TIME [epoch: 9.76 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38992456442812795		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.38992456442812795 | validation: 0.4507932750223175]
	TIME [epoch: 9.75 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3165766142904472		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.3165766142904472 | validation: 0.28507499007963644]
	TIME [epoch: 9.77 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2571749250862005		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.2571749250862005 | validation: 0.25920521629647925]
	TIME [epoch: 9.78 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2658162158466216		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.2658162158466216 | validation: 0.37578016080534843]
	TIME [epoch: 9.76 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3516617510360391		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.3516617510360391 | validation: 0.3208707183071771]
	TIME [epoch: 9.76 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31754543167108246		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.31754543167108246 | validation: 0.35836724886746224]
	TIME [epoch: 9.78 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3111994894691481		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.3111994894691481 | validation: 0.2541333511195944]
	TIME [epoch: 9.76 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28837621319944057		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.28837621319944057 | validation: 0.3684214064687042]
	TIME [epoch: 9.76 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3389549314810274		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.3389549314810274 | validation: 0.4623912372378237]
	TIME [epoch: 9.77 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3516934955008632		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.3516934955008632 | validation: 0.27478839681983536]
	TIME [epoch: 9.76 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3322723557912194		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.3322723557912194 | validation: 0.43649535129187556]
	TIME [epoch: 9.76 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795112481848329		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.3795112481848329 | validation: 0.34122998096652796]
	TIME [epoch: 9.76 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32544192292976626		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.32544192292976626 | validation: 0.35784355489754016]
	TIME [epoch: 9.78 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38428139477516365		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.38428139477516365 | validation: 0.3968529934412983]
	TIME [epoch: 9.76 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3410971938324351		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.3410971938324351 | validation: 0.30672358880366674]
	TIME [epoch: 9.75 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4101686628497364		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.4101686628497364 | validation: 0.39898941187506504]
	TIME [epoch: 9.78 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2866263412908892		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.2866263412908892 | validation: 0.4324806076776521]
	TIME [epoch: 9.76 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3605483888492964		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.3605483888492964 | validation: 0.23596659828867744]
	TIME [epoch: 9.76 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623813806559975		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.2623813806559975 | validation: 0.24690328636229367]
	TIME [epoch: 9.76 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27787833456761946		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.27787833456761946 | validation: 0.23072540414021717]
	TIME [epoch: 9.77 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25085492387699226		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.25085492387699226 | validation: 0.2407536526146894]
	TIME [epoch: 9.75 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2695222854957315		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.2695222854957315 | validation: 0.2401221051922773]
	TIME [epoch: 9.75 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3548044319033612		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.3548044319033612 | validation: 0.5445129539040375]
	TIME [epoch: 9.78 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36049708549151943		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.36049708549151943 | validation: 0.23075175883873017]
	TIME [epoch: 9.75 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.260809468351705		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.260809468351705 | validation: 0.23113588750448386]
	TIME [epoch: 9.76 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36032329681080444		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.36032329681080444 | validation: 0.24552078983589512]
	TIME [epoch: 9.78 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27316929007218377		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.27316929007218377 | validation: 0.20078222029338297]
	TIME [epoch: 9.76 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710550641588687		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.2710550641588687 | validation: 0.2832033488869069]
	TIME [epoch: 9.76 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3437973240843997		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.3437973240843997 | validation: 0.32899578658537854]
	TIME [epoch: 9.76 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42006150269749354		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.42006150269749354 | validation: 0.3252997007177241]
	TIME [epoch: 9.79 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2809763339691527		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.2809763339691527 | validation: 0.2456842932897712]
	TIME [epoch: 9.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3990507510532105		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.3990507510532105 | validation: 0.25592903704343933]
	TIME [epoch: 9.76 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29742183138094264		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.29742183138094264 | validation: 0.22323538927422745]
	TIME [epoch: 9.78 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2760538011490178		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.2760538011490178 | validation: 0.33026034535170595]
	TIME [epoch: 9.76 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29470807668056825		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.29470807668056825 | validation: 0.32980659593583583]
	TIME [epoch: 9.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27790683292789725		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.27790683292789725 | validation: 0.23884965656602106]
	TIME [epoch: 9.76 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2647087486013537		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.2647087486013537 | validation: 0.4903652011431159]
	TIME [epoch: 9.75 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3962591890711858		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.3962591890711858 | validation: 0.28382594194924715]
	TIME [epoch: 9.75 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2788588622650049		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.2788588622650049 | validation: 0.3391728547555355]
	TIME [epoch: 9.74 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27255414504271036		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.27255414504271036 | validation: 0.24855724518851208]
	TIME [epoch: 9.78 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22839747814069583		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.22839747814069583 | validation: 0.4402838412260897]
	TIME [epoch: 9.75 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35505343912961035		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.35505343912961035 | validation: 0.22884925648470694]
	TIME [epoch: 9.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30260525871577026		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.30260525871577026 | validation: 0.18826966631361494]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24645826867763826		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.24645826867763826 | validation: 0.23573661629713005]
	TIME [epoch: 9.76 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22226529268541456		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.22226529268541456 | validation: 0.3959872136269072]
	TIME [epoch: 9.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3515047073231103		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.3515047073231103 | validation: 0.35434141757774773]
	TIME [epoch: 9.75 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2843007489801725		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.2843007489801725 | validation: 0.2698367257952261]
	TIME [epoch: 9.77 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2327771018188593		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.2327771018188593 | validation: 0.22154543822926087]
	TIME [epoch: 9.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26874108287580645		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.26874108287580645 | validation: 0.6958878789333599]
	TIME [epoch: 9.74 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181158003481492		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.4181158003481492 | validation: 0.43224196030194373]
	TIME [epoch: 9.77 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34857127605982224		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.34857127605982224 | validation: 0.20338083650928454]
	TIME [epoch: 9.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25514602139980586		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.25514602139980586 | validation: 0.3636888958951633]
	TIME [epoch: 9.74 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29056470386164535		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.29056470386164535 | validation: 0.22320412987623378]
	TIME [epoch: 9.76 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25472790618519814		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.25472790618519814 | validation: 0.30190153140097775]
	TIME [epoch: 9.76 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24770808731184452		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.24770808731184452 | validation: 0.40415581514314014]
	TIME [epoch: 9.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3133710633865422		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.3133710633865422 | validation: 0.364759722537063]
	TIME [epoch: 9.75 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28728030427886286		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.28728030427886286 | validation: 0.4879194855175807]
	TIME [epoch: 9.76 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4014916905019349		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.4014916905019349 | validation: 0.23509689054437266]
	TIME [epoch: 9.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4042594230747074		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.4042594230747074 | validation: 0.4125416696491728]
	TIME [epoch: 9.74 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36436747871342473		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.36436747871342473 | validation: 0.26510885385051247]
	TIME [epoch: 9.77 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26233396628699973		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.26233396628699973 | validation: 0.23205313795207544]
	TIME [epoch: 9.74 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2231602769811109		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.2231602769811109 | validation: 0.21480190754038966]
	TIME [epoch: 9.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33167587543296423		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.33167587543296423 | validation: 0.37478111895993904]
	TIME [epoch: 9.75 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33182088325690945		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.33182088325690945 | validation: 0.30121636837932747]
	TIME [epoch: 9.77 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36212283804477824		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.36212283804477824 | validation: 0.20834425902127943]
	TIME [epoch: 9.74 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30348946541158217		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.30348946541158217 | validation: 0.24701753581766767]
	TIME [epoch: 9.75 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3492826477751782		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.3492826477751782 | validation: 0.2703183727812912]
	TIME [epoch: 9.77 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30326294695397904		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.30326294695397904 | validation: 0.26565791760426916]
	TIME [epoch: 9.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22049642108282952		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.22049642108282952 | validation: 0.22677051850183794]
	TIME [epoch: 9.74 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512618615406071		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.2512618615406071 | validation: 0.2884678209455749]
	TIME [epoch: 9.77 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3109265321195962		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.3109265321195962 | validation: 0.30798236893805075]
	TIME [epoch: 9.74 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3087512176651024		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.3087512176651024 | validation: 0.23935144724662824]
	TIME [epoch: 9.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3573387941270184		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.3573387941270184 | validation: 0.22833058862681274]
	TIME [epoch: 9.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3496748948803712		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.3496748948803712 | validation: 0.3003240010751316]
	TIME [epoch: 9.77 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925215899924673		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.2925215899924673 | validation: 0.23041438492949085]
	TIME [epoch: 9.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26007666349846137		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.26007666349846137 | validation: 0.26777302936435576]
	TIME [epoch: 9.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059175160079065		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.3059175160079065 | validation: 0.3091047831760372]
	TIME [epoch: 9.76 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2933600366648402		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.2933600366648402 | validation: 0.29523238815678143]
	TIME [epoch: 9.74 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28680999481327873		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.28680999481327873 | validation: 0.2046317631351242]
	TIME [epoch: 9.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22672670415659227		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.22672670415659227 | validation: 0.34952109483013405]
	TIME [epoch: 9.74 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2616234001330384		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.2616234001330384 | validation: 0.2993243074594979]
	TIME [epoch: 9.76 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29672887675659665		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.29672887675659665 | validation: 0.25172090348012555]
	TIME [epoch: 9.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2335246542879012		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.2335246542879012 | validation: 0.22212740718381374]
	TIME [epoch: 9.74 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26580569671240917		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.26580569671240917 | validation: 0.19517015752384542]
	TIME [epoch: 9.76 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2389464773428942		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.2389464773428942 | validation: 0.3314263011965564]
	TIME [epoch: 9.74 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26481323686686103		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.26481323686686103 | validation: 0.25947163644851023]
	TIME [epoch: 9.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29692409411328163		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.29692409411328163 | validation: 0.2976487961574878]
	TIME [epoch: 9.76 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3715333712092081		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.3715333712092081 | validation: 0.20654269772946074]
	TIME [epoch: 9.75 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2423348327986221		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.2423348327986221 | validation: 0.3109494520002571]
	TIME [epoch: 9.74 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3908224647744172		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.3908224647744172 | validation: 0.3252605441328004]
	TIME [epoch: 9.74 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2797421770310442		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.2797421770310442 | validation: 0.24890452384174133]
	TIME [epoch: 9.76 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26305228406157005		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.26305228406157005 | validation: 0.2780303020601515]
	TIME [epoch: 9.74 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2633131683681747		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.2633131683681747 | validation: 0.2810206697509123]
	TIME [epoch: 9.74 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2469737029074533		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.2469737029074533 | validation: 0.2266503573372516]
	TIME [epoch: 9.77 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36972890028992333		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.36972890028992333 | validation: 0.30285638415397614]
	TIME [epoch: 9.74 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23419746763184915		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.23419746763184915 | validation: 0.20468436296807324]
	TIME [epoch: 9.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30004910220423947		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.30004910220423947 | validation: 0.31563402500433596]
	TIME [epoch: 9.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767210445493639		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.2767210445493639 | validation: 0.3340780619943769]
	TIME [epoch: 9.76 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2971913988950344		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.2971913988950344 | validation: 0.17472474202111957]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21416138178109567		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.21416138178109567 | validation: 0.19786911039508792]
	TIME [epoch: 9.75 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24713382735556017		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.24713382735556017 | validation: 0.19728085901008363]
	TIME [epoch: 9.76 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.257002272505103		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.257002272505103 | validation: 0.2135051428953545]
	TIME [epoch: 9.75 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23770097077216673		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.23770097077216673 | validation: 0.3371471177784598]
	TIME [epoch: 9.75 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.264479404474235		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.264479404474235 | validation: 0.3709094865422466]
	TIME [epoch: 9.76 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3109071048943012		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.3109071048943012 | validation: 0.35056960562799716]
	TIME [epoch: 9.75 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2872972900536688		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.2872972900536688 | validation: 0.263373547986469]
	TIME [epoch: 9.75 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2877864111894794		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.2877864111894794 | validation: 0.2878274429037716]
	TIME [epoch: 9.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27152804812220094		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.27152804812220094 | validation: 0.17666700886326986]
	TIME [epoch: 9.76 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2403862187734819		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.2403862187734819 | validation: 0.23368195481011342]
	TIME [epoch: 9.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3659172385337154		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.3659172385337154 | validation: 0.31672188777264376]
	TIME [epoch: 9.75 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4102404249988246		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.4102404249988246 | validation: 0.24007119302143004]
	TIME [epoch: 9.76 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27893533875604787		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.27893533875604787 | validation: 0.2402806505331325]
	TIME [epoch: 9.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2478268692014259		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.2478268692014259 | validation: 0.22312712558877765]
	TIME [epoch: 9.74 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24434261891533077		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.24434261891533077 | validation: 0.30508524080515337]
	TIME [epoch: 9.76 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24886592947727398		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.24886592947727398 | validation: 0.4394966126794797]
	TIME [epoch: 9.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35222983229371885		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.35222983229371885 | validation: 0.34584249152722807]
	TIME [epoch: 9.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748065479653149		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.2748065479653149 | validation: 0.3189845750130781]
	TIME [epoch: 9.75 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2930503232845657		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.2930503232845657 | validation: 0.5019381815079601]
	TIME [epoch: 9.77 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42150700365088667		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.42150700365088667 | validation: 0.22794835124977167]
	TIME [epoch: 9.74 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34333613933503776		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.34333613933503776 | validation: 0.21657588835111186]
	TIME [epoch: 9.74 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2542231567805072		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.2542231567805072 | validation: 0.22054738225621737]
	TIME [epoch: 9.76 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25906110445441566		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.25906110445441566 | validation: 0.2744944055889695]
	TIME [epoch: 9.75 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2379100809129143		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.2379100809129143 | validation: 0.2646431219735285]
	TIME [epoch: 9.74 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26018812133712704		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.26018812133712704 | validation: 0.17616261132920258]
	TIME [epoch: 9.75 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2566143626147209		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.2566143626147209 | validation: 0.21529084549222685]
	TIME [epoch: 9.76 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3218511614158804		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.3218511614158804 | validation: 0.214572125591404]
	TIME [epoch: 9.74 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29531312140808547		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.29531312140808547 | validation: 0.19951870317701054]
	TIME [epoch: 9.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.442551806668048		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.442551806668048 | validation: 0.36075015887686634]
	TIME [epoch: 9.77 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31671253489508727		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.31671253489508727 | validation: 0.287017246928916]
	TIME [epoch: 9.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3322716548731279		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.3322716548731279 | validation: 0.3228191319749557]
	TIME [epoch: 9.74 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28965020989218954		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.28965020989218954 | validation: 0.44800915379952233]
	TIME [epoch: 9.76 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7105556924676885		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.7105556924676885 | validation: 0.2821383106280485]
	TIME [epoch: 9.74 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2855469438119885		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.2855469438119885 | validation: 0.3706007264986789]
	TIME [epoch: 9.74 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29117193491349597		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.29117193491349597 | validation: 0.3610722990854021]
	TIME [epoch: 9.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2453796912699219		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.2453796912699219 | validation: 0.23113491679096088]
	TIME [epoch: 9.77 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2363896977410617		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.2363896977410617 | validation: 0.23699292309524356]
	TIME [epoch: 9.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19395159845888843		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.19395159845888843 | validation: 0.21906677641652814]
	TIME [epoch: 9.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22793261021856007		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.22793261021856007 | validation: 0.18933262245193994]
	TIME [epoch: 9.76 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24463358791701867		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.24463358791701867 | validation: 0.39433796347019934]
	TIME [epoch: 9.75 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2973404648465584		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.2973404648465584 | validation: 0.21744609712089477]
	TIME [epoch: 9.74 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2422037436988258		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.2422037436988258 | validation: 0.20096148288848306]
	TIME [epoch: 9.75 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23448271111186583		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.23448271111186583 | validation: 0.3064009030556134]
	TIME [epoch: 9.76 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2851038620618987		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.2851038620618987 | validation: 0.1721814669811811]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_840.pth
	Model improved!!!
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2567772362512995		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.2567772362512995 | validation: 0.27783819524572434]
	TIME [epoch: 9.75 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2498667599325363		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.2498667599325363 | validation: 0.38399492847942684]
	TIME [epoch: 9.77 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807006929861071		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.2807006929861071 | validation: 0.3115126034653518]
	TIME [epoch: 9.75 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28510083577019907		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.28510083577019907 | validation: 0.18303961288450268]
	TIME [epoch: 9.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3479211649145256		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.3479211649145256 | validation: 0.2796608659125785]
	TIME [epoch: 9.77 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2500256097211166		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.2500256097211166 | validation: 0.24986635748993358]
	TIME [epoch: 9.75 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.218370334776569		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.218370334776569 | validation: 0.2060803579069964]
	TIME [epoch: 9.75 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30230026030706536		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.30230026030706536 | validation: 0.23800161956546714]
	TIME [epoch: 9.76 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23479981375543163		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.23479981375543163 | validation: 0.2517725856897503]
	TIME [epoch: 9.76 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22658918565546796		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.22658918565546796 | validation: 0.20287106484060785]
	TIME [epoch: 9.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23524392479693682		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.23524392479693682 | validation: 0.3795026464700401]
	TIME [epoch: 9.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27232583365104485		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.27232583365104485 | validation: 0.21404006317312657]
	TIME [epoch: 9.77 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49614427475316036		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.49614427475316036 | validation: 0.2963821764108822]
	TIME [epoch: 9.74 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3859148073651556		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.3859148073651556 | validation: 0.2747221233867622]
	TIME [epoch: 9.75 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3070345178281807		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.3070345178281807 | validation: 0.2914173623559995]
	TIME [epoch: 9.76 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27446816169048716		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.27446816169048716 | validation: 0.20907640844154976]
	TIME [epoch: 9.76 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24037342089264557		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.24037342089264557 | validation: 0.2099924619781752]
	TIME [epoch: 9.74 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20003272442485737		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.20003272442485737 | validation: 0.3117506679516696]
	TIME [epoch: 9.74 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24982724357683467		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.24982724357683467 | validation: 0.16423106386709718]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_859.pth
	Model improved!!!
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20741577933784727		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.20741577933784727 | validation: 0.1914704651274204]
	TIME [epoch: 9.75 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20047654650601304		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.20047654650601304 | validation: 0.4104262835286944]
	TIME [epoch: 9.75 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44713086956536596		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.44713086956536596 | validation: 0.21769786429362065]
	TIME [epoch: 9.76 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24668291087241562		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.24668291087241562 | validation: 0.21353247866857253]
	TIME [epoch: 9.74 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20002099369165877		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.20002099369165877 | validation: 0.45917253838178357]
	TIME [epoch: 9.74 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.352919613028588		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.352919613028588 | validation: 0.33612245658227063]
	TIME [epoch: 9.75 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2365551526858412		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.2365551526858412 | validation: 0.20398863450375437]
	TIME [epoch: 9.77 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24840590598416856		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.24840590598416856 | validation: 0.22338294822023358]
	TIME [epoch: 9.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28237698207374007		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.28237698207374007 | validation: 0.3140985403336149]
	TIME [epoch: 9.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24394190994770742		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.24394190994770742 | validation: 0.23130568641309257]
	TIME [epoch: 9.76 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20360316096296102		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.20360316096296102 | validation: 0.254837438368246]
	TIME [epoch: 9.74 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22022846118765105		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.22022846118765105 | validation: 0.17347052753793296]
	TIME [epoch: 9.74 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18081377167770413		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.18081377167770413 | validation: 0.18325721853345686]
	TIME [epoch: 9.76 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651087664016996		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.2651087664016996 | validation: 0.3113447171382749]
	TIME [epoch: 9.75 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2662768540385552		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.2662768540385552 | validation: 0.32266341288987593]
	TIME [epoch: 9.75 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625466440782541		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.2625466440782541 | validation: 0.25741963746806845]
	TIME [epoch: 9.74 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24039013473390813		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.24039013473390813 | validation: 0.1786220580896579]
	TIME [epoch: 9.77 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2617319302522578		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.2617319302522578 | validation: 0.3163438126086188]
	TIME [epoch: 9.74 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25144477795332787		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.25144477795332787 | validation: 0.21242442101313416]
	TIME [epoch: 9.75 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.195245228043451		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.195245228043451 | validation: 0.15051630308180594]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16643655537750948		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.16643655537750948 | validation: 0.27058902745045266]
	TIME [epoch: 9.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3014396833404551		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.3014396833404551 | validation: 0.46300803859319184]
	TIME [epoch: 9.76 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3925371052482147		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.3925371052482147 | validation: 0.20877980498224133]
	TIME [epoch: 9.77 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2991329501100801		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.2991329501100801 | validation: 0.40497764213711135]
	TIME [epoch: 9.76 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3210298133402279		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.3210298133402279 | validation: 0.22040871081718924]
	TIME [epoch: 9.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24094484066776953		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.24094484066776953 | validation: 0.16783707892572583]
	TIME [epoch: 9.74 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20249067888362188		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.20249067888362188 | validation: 0.19881871034036366]
	TIME [epoch: 9.77 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531851996167684		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.2531851996167684 | validation: 0.31111424753317013]
	TIME [epoch: 9.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28117926401417864		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.28117926401417864 | validation: 0.24642385427255953]
	TIME [epoch: 9.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23766617674719734		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.23766617674719734 | validation: 0.17269825031998934]
	TIME [epoch: 9.76 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33515007146163034		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.33515007146163034 | validation: 0.22592685119948125]
	TIME [epoch: 9.76 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25000532055352587		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.25000532055352587 | validation: 0.34925586613796555]
	TIME [epoch: 9.75 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302396501631216		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.3302396501631216 | validation: 0.2516519115328275]
	TIME [epoch: 9.75 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33896097225942523		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.33896097225942523 | validation: 0.3391712125247428]
	TIME [epoch: 9.77 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.351757417589926		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.351757417589926 | validation: 0.23685088033322005]
	TIME [epoch: 9.74 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2258201986208533		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.2258201986208533 | validation: 0.22282037740321006]
	TIME [epoch: 9.75 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3560156041422352		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.3560156041422352 | validation: 0.1863598167239475]
	TIME [epoch: 9.77 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22508138873812453		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.22508138873812453 | validation: 0.15845151283157916]
	TIME [epoch: 9.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2589745661889775		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.2589745661889775 | validation: 0.33094538551877195]
	TIME [epoch: 9.74 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2282613279984873		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.2282613279984873 | validation: 0.3064556852818643]
	TIME [epoch: 9.76 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25249571935019965		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.25249571935019965 | validation: 0.2520255384882078]
	TIME [epoch: 9.77 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2365342560675494		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.2365342560675494 | validation: 0.2036281434354619]
	TIME [epoch: 9.74 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20171238685309228		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.20171238685309228 | validation: 0.19546438492929555]
	TIME [epoch: 9.75 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968804949047365		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.2968804949047365 | validation: 0.31115172635364136]
	TIME [epoch: 9.76 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.275824825637266		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.275824825637266 | validation: 0.22500109186711192]
	TIME [epoch: 9.75 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4548486752942873		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.4548486752942873 | validation: 0.5228299619837895]
	TIME [epoch: 9.75 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42780652468375735		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.42780652468375735 | validation: 0.2790986363771045]
	TIME [epoch: 9.77 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21583144390403972		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.21583144390403972 | validation: 0.24330936987489502]
	TIME [epoch: 9.74 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25061097912894004		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.25061097912894004 | validation: 0.22646086810728341]
	TIME [epoch: 9.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20955292376575269		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.20955292376575269 | validation: 0.18881583372125285]
	TIME [epoch: 9.75 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17962012840252736		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.17962012840252736 | validation: 0.19509032615479693]
	TIME [epoch: 9.76 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26605892147186616		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.26605892147186616 | validation: 0.2707932541932837]
	TIME [epoch: 9.75 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33180325774984604		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.33180325774984604 | validation: 0.21657844283953068]
	TIME [epoch: 9.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22345403248946175		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.22345403248946175 | validation: 0.20004935705125612]
	TIME [epoch: 9.76 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19428472379607528		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.19428472379607528 | validation: 0.2279073788941195]
	TIME [epoch: 9.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749140944412663		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.2749140944412663 | validation: 0.2729500829826396]
	TIME [epoch: 9.75 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30559291305784575		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.30559291305784575 | validation: 0.16991857145955375]
	TIME [epoch: 9.76 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22546584853208856		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.22546584853208856 | validation: 0.21899615470600964]
	TIME [epoch: 9.76 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25199664639103647		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.25199664639103647 | validation: 0.180961307658636]
	TIME [epoch: 9.75 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2127162470966987		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.2127162470966987 | validation: 0.1962678440125499]
	TIME [epoch: 9.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2868298377939501		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.2868298377939501 | validation: 0.251299562328965]
	TIME [epoch: 9.78 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.255925893601744		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.255925893601744 | validation: 0.23493683557637382]
	TIME [epoch: 9.75 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21937513968976557		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.21937513968976557 | validation: 0.2359683778060554]
	TIME [epoch: 9.75 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19341611254956687		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.19341611254956687 | validation: 0.17767701854337958]
	TIME [epoch: 9.77 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30565247664404527		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.30565247664404527 | validation: 0.2881787086562178]
	TIME [epoch: 9.75 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3525236618688602		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.3525236618688602 | validation: 0.25120052828793576]
	TIME [epoch: 9.75 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3599912176894283		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.3599912176894283 | validation: 0.30365370981425127]
	TIME [epoch: 9.76 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2812149516556286		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.2812149516556286 | validation: 0.22440420932595204]
	TIME [epoch: 9.77 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27327047116821546		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.27327047116821546 | validation: 0.43718855887504393]
	TIME [epoch: 9.75 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4072297585284475		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.4072297585284475 | validation: 0.44508585427832825]
	TIME [epoch: 9.76 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5102889620625212		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.5102889620625212 | validation: 0.29518773526451597]
	TIME [epoch: 9.78 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2857321144052277		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.2857321144052277 | validation: 0.27078548594787577]
	TIME [epoch: 9.75 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20048356761357877		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.20048356761357877 | validation: 0.18996221278550457]
	TIME [epoch: 9.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20814806184230966		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.20814806184230966 | validation: 0.18265976612046322]
	TIME [epoch: 9.77 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1871378807181856		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.1871378807181856 | validation: 0.1452699327690628]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_934.pth
	Model improved!!!
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1744113652648939		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.1744113652648939 | validation: 0.18129330991434223]
	TIME [epoch: 9.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275634651165898		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.15275634651165898 | validation: 0.14893911615893665]
	TIME [epoch: 9.75 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20831863965410652		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.20831863965410652 | validation: 0.19590377329616335]
	TIME [epoch: 9.76 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14735712252682398		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.14735712252682398 | validation: 0.14753174680521794]
	TIME [epoch: 9.75 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17803384555044094		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.17803384555044094 | validation: 0.1749470413349279]
	TIME [epoch: 9.74 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18019033684546457		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.18019033684546457 | validation: 0.18445695300005482]
	TIME [epoch: 9.77 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20323525856947305		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.20323525856947305 | validation: 0.2469681183855515]
	TIME [epoch: 9.75 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21644888881692464		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.21644888881692464 | validation: 0.1863439216226944]
	TIME [epoch: 9.73 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23964533145721928		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.23964533145721928 | validation: 0.27079190254760455]
	TIME [epoch: 9.76 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613819203440494		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.2613819203440494 | validation: 0.25488166268141105]
	TIME [epoch: 9.75 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2277069526842745		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.2277069526842745 | validation: 0.36756823812214534]
	TIME [epoch: 9.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28675686785277776		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.28675686785277776 | validation: 0.19375629626517893]
	TIME [epoch: 9.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18902597260711315		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.18902597260711315 | validation: 0.13827761525429322]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_947.pth
	Model improved!!!
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642223486456543		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.1642223486456543 | validation: 0.2394239233115053]
	TIME [epoch: 9.75 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22319607159873858		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.22319607159873858 | validation: 0.32455637805035653]
	TIME [epoch: 9.74 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3536617626229299		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.3536617626229299 | validation: 0.3331191214223679]
	TIME [epoch: 9.77 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31318317351383707		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.31318317351383707 | validation: 0.37501410753069]
	TIME [epoch: 9.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38467973904628666		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.38467973904628666 | validation: 0.27739375701953456]
	TIME [epoch: 9.75 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2446784165672416		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.2446784165672416 | validation: 0.22868389304069198]
	TIME [epoch: 9.74 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28792502037359496		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.28792502037359496 | validation: 0.43131844998792757]
	TIME [epoch: 9.76 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573940856337304		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.2573940856337304 | validation: 0.18013205058170978]
	TIME [epoch: 9.75 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23721159833443065		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.23721159833443065 | validation: 0.3020197302638754]
	TIME [epoch: 9.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2384819071263647		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.2384819071263647 | validation: 0.17740630929633688]
	TIME [epoch: 9.76 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19910699060867956		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.19910699060867956 | validation: 0.1559426124556542]
	TIME [epoch: 9.75 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20050860348368804		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.20050860348368804 | validation: 0.13334882814547963]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_959.pth
	Model improved!!!
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720311370229266		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.1720311370229266 | validation: 0.1828298750872888]
	TIME [epoch: 9.77 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19244749965301605		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.19244749965301605 | validation: 0.20711762741614897]
	TIME [epoch: 9.76 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17637973987546934		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.17637973987546934 | validation: 0.12813889640801673]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2904154509423565		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.2904154509423565 | validation: 0.3473528257677198]
	TIME [epoch: 9.76 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3023943994200435		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.3023943994200435 | validation: 0.1956345501706751]
	TIME [epoch: 9.76 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2278898152033361		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.2278898152033361 | validation: 0.1460887082935335]
	TIME [epoch: 9.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18915750628834693		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.18915750628834693 | validation: 0.13202450827486747]
	TIME [epoch: 9.74 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17947421566515637		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.17947421566515637 | validation: 0.21092049529943385]
	TIME [epoch: 9.77 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20851816372008286		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.20851816372008286 | validation: 0.22226444040701812]
	TIME [epoch: 9.75 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2154087072680991		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.2154087072680991 | validation: 0.15474171069154186]
	TIME [epoch: 9.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21576900806274493		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.21576900806274493 | validation: 0.17565180676747427]
	TIME [epoch: 9.76 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637605741379942		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.1637605741379942 | validation: 0.1824391582264502]
	TIME [epoch: 9.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2969242368735503		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.2969242368735503 | validation: 0.34462544845076565]
	TIME [epoch: 9.74 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27783503376635615		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.27783503376635615 | validation: 0.19574759758521412]
	TIME [epoch: 9.75 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2041574646545473		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.2041574646545473 | validation: 0.15259734746663928]
	TIME [epoch: 9.76 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17567871457485665		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.17567871457485665 | validation: 0.1291308681823624]
	TIME [epoch: 9.74 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23304681627501062		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.23304681627501062 | validation: 0.18349785396658347]
	TIME [epoch: 10 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1893643185250233		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.1893643185250233 | validation: 0.18072772354212618]
	TIME [epoch: 9.77 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18314448725872198		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.18314448725872198 | validation: 0.3433219215603141]
	TIME [epoch: 9.76 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27406365166154456		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.27406365166154456 | validation: 0.342794672444888]
	TIME [epoch: 9.76 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30885777573792333		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.30885777573792333 | validation: 0.16050750084878007]
	TIME [epoch: 9.76 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17881818667562577		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.17881818667562577 | validation: 0.14767383603123085]
	TIME [epoch: 9.77 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16618135835206055		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.16618135835206055 | validation: 0.1625858904685599]
	TIME [epoch: 9.75 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14682534764368466		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.14682534764368466 | validation: 0.24494439617249672]
	TIME [epoch: 9.75 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2097644442391212		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.2097644442391212 | validation: 0.12783306349173615]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_984.pth
	Model improved!!!
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2056369687012935		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.2056369687012935 | validation: 0.24912320497984725]
	TIME [epoch: 9.76 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22364987932924088		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.22364987932924088 | validation: 0.2853709794799352]
	TIME [epoch: 9.76 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23938759438999163		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.23938759438999163 | validation: 0.1802185057756971]
	TIME [epoch: 9.78 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15958061341386662		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.15958061341386662 | validation: 0.22751072522146168]
	TIME [epoch: 9.77 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.187073516155603		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.187073516155603 | validation: 0.14832526715127567]
	TIME [epoch: 9.76 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17483648357230597		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.17483648357230597 | validation: 0.14397186595993106]
	TIME [epoch: 9.77 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18033403844423992		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.18033403844423992 | validation: 0.18758819963061948]
	TIME [epoch: 9.78 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312237396896958		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.3312237396896958 | validation: 0.25185592755342134]
	TIME [epoch: 9.76 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1855735122467886		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.1855735122467886 | validation: 0.17046669699654346]
	TIME [epoch: 9.76 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2232958125449204		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.2232958125449204 | validation: 0.26757841223676315]
	TIME [epoch: 9.78 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22605378249122796		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.22605378249122796 | validation: 0.17824616494879705]
	TIME [epoch: 9.76 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19856556405672315		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.19856556405672315 | validation: 0.19370885722923198]
	TIME [epoch: 9.75 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15052033440973692		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.15052033440973692 | validation: 0.31084191168007147]
	TIME [epoch: 9.77 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2933629887486411		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.2933629887486411 | validation: 0.2766814257910086]
	TIME [epoch: 9.77 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21020559211949347		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.21020559211949347 | validation: 0.18672806221046329]
	TIME [epoch: 9.76 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22533252689167144		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.22533252689167144 | validation: 0.24088632404490198]
	TIME [epoch: 9.76 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19936553112103975		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.19936553112103975 | validation: 0.18047552226978833]
	TIME [epoch: 9.78 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2048381799841715		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.2048381799841715 | validation: 0.326759552933534]
	TIME [epoch: 9.76 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.236434888294729		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.236434888294729 | validation: 0.20566468810090877]
	TIME [epoch: 9.76 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19694101289030463		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.19694101289030463 | validation: 0.18760169827130269]
	TIME [epoch: 9.78 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18419505386763949		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.18419505386763949 | validation: 0.23041258282103969]
	TIME [epoch: 9.76 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19430436997993278		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.19430436997993278 | validation: 0.20072608866042388]
	TIME [epoch: 9.76 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1557583208852414		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.1557583208852414 | validation: 0.3294772120312573]
	TIME [epoch: 9.76 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24545069948147144		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.24545069948147144 | validation: 0.24576209310347324]
	TIME [epoch: 9.78 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1961330314688836		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.1961330314688836 | validation: 0.23021427448217224]
	TIME [epoch: 9.76 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21165308796499374		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.21165308796499374 | validation: 0.24377259812405025]
	TIME [epoch: 9.76 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21131638031083075		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.21131638031083075 | validation: 0.17611896832721394]
	TIME [epoch: 9.78 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157603121545386		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.157603121545386 | validation: 0.13666990134120055]
	TIME [epoch: 9.75 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15420875250313298		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.15420875250313298 | validation: 0.14030701562587053]
	TIME [epoch: 9.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14673895413705065		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.14673895413705065 | validation: 0.15336066137353846]
	TIME [epoch: 9.77 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205607501305419		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.205607501305419 | validation: 0.21658462804661735]
	TIME [epoch: 9.75 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18928116500380765		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.18928116500380765 | validation: 0.13601880621218343]
	TIME [epoch: 9.76 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18845889654474748		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.18845889654474748 | validation: 0.16939211455590936]
	TIME [epoch: 9.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18879312818738908		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.18879312818738908 | validation: 0.14507729491428045]
	TIME [epoch: 9.78 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15627060787607822		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.15627060787607822 | validation: 0.13214678982172962]
	TIME [epoch: 9.76 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20415467233381518		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.20415467233381518 | validation: 0.2044863127282975]
	TIME [epoch: 9.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23090272970219705		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.23090272970219705 | validation: 0.15924229988491143]
	TIME [epoch: 9.77 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14162659498026237		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.14162659498026237 | validation: 0.13100139646825193]
	TIME [epoch: 9.76 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21023563793094127		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.21023563793094127 | validation: 0.12055303105511214]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1023.pth
	Model improved!!!
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13367931215988707		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.13367931215988707 | validation: 0.1432684078481808]
	TIME [epoch: 9.77 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16655611573253198		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.16655611573253198 | validation: 0.12573403971054564]
	TIME [epoch: 9.77 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15214416709870648		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.15214416709870648 | validation: 0.1738967441602749]
	TIME [epoch: 9.76 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2696896779695609		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.2696896779695609 | validation: 0.22039843515562965]
	TIME [epoch: 9.75 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14961618388081463		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.14961618388081463 | validation: 0.17026988492910242]
	TIME [epoch: 9.78 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1690301925039679		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.1690301925039679 | validation: 0.1463419821277404]
	TIME [epoch: 9.75 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20648235621007038		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.20648235621007038 | validation: 0.19591830221677373]
	TIME [epoch: 9.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797948079288843		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.1797948079288843 | validation: 0.17505305867574678]
	TIME [epoch: 9.77 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16712492738035234		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.16712492738035234 | validation: 0.14676177491515355]
	TIME [epoch: 9.76 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15082094398168816		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.15082094398168816 | validation: 0.18442849055227917]
	TIME [epoch: 9.75 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18712685417969244		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.18712685417969244 | validation: 0.21732243963167386]
	TIME [epoch: 9.76 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16055055752210715		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.16055055752210715 | validation: 0.14021280118358279]
	TIME [epoch: 9.77 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17006870586029643		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.17006870586029643 | validation: 0.15252990358047652]
	TIME [epoch: 9.76 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17764385149619646		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.17764385149619646 | validation: 0.165018566817919]
	TIME [epoch: 9.76 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636327967590796		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.1636327967590796 | validation: 0.18014373284158425]
	TIME [epoch: 9.77 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18032376416038093		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.18032376416038093 | validation: 0.12645328378674114]
	TIME [epoch: 9.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645172712807208		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.1645172712807208 | validation: 0.18789739896428348]
	TIME [epoch: 9.75 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19030429709896102		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.19030429709896102 | validation: 0.23012324896812453]
	TIME [epoch: 9.77 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22089039522523807		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.22089039522523807 | validation: 0.1221364866336382]
	TIME [epoch: 9.77 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15090265252364418		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.15090265252364418 | validation: 0.24789418003790978]
	TIME [epoch: 9.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2117592061938815		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.2117592061938815 | validation: 0.1653210461626668]
	TIME [epoch: 9.76 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21507726264089566		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.21507726264089566 | validation: 0.19383824592430268]
	TIME [epoch: 9.78 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1935394285762994		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.1935394285762994 | validation: 0.2094149729948814]
	TIME [epoch: 9.76 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18072961030184329		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.18072961030184329 | validation: 0.1431122006337126]
	TIME [epoch: 9.75 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16204571425019323		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.16204571425019323 | validation: 0.23620789666246056]
	TIME [epoch: 9.77 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2003752949771851		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.2003752949771851 | validation: 0.1547638018611462]
	TIME [epoch: 9.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1928286625557563		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.1928286625557563 | validation: 0.15432094117138156]
	TIME [epoch: 9.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16266049633701146		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.16266049633701146 | validation: 0.14029789232308867]
	TIME [epoch: 9.75 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19377038058481333		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.19377038058481333 | validation: 0.12261037427730369]
	TIME [epoch: 9.77 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657769157370733		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.1657769157370733 | validation: 0.15538223052380512]
	TIME [epoch: 9.75 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16190758662632238		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.16190758662632238 | validation: 0.14336171711058382]
	TIME [epoch: 9.76 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1726459894405124		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.1726459894405124 | validation: 0.14594696787486916]
	TIME [epoch: 9.78 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19954757657329414		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.19954757657329414 | validation: 0.23574889208494199]
	TIME [epoch: 9.75 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17865811186944178		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.17865811186944178 | validation: 0.11245823568082601]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1057.pth
	Model improved!!!
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21581085903672098		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.21581085903672098 | validation: 0.17599061896479457]
	TIME [epoch: 9.78 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2046727910774949		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.2046727910774949 | validation: 0.12952906131772524]
	TIME [epoch: 9.76 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15181216209309464		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.15181216209309464 | validation: 0.1645054402658179]
	TIME [epoch: 9.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16412732455943577		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.16412732455943577 | validation: 0.12390718544399315]
	TIME [epoch: 9.75 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14764652397924927		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.14764652397924927 | validation: 0.1501581963544667]
	TIME [epoch: 9.78 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16247023909157185		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.16247023909157185 | validation: 0.1069058672725181]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17703850569782806		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.17703850569782806 | validation: 0.166372186706444]
	TIME [epoch: 9.75 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19793911593156663		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.19793911593156663 | validation: 0.1328294678943375]
	TIME [epoch: 9.77 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15160162346314773		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.15160162346314773 | validation: 0.12364678339049309]
	TIME [epoch: 9.75 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19267535617771506		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.19267535617771506 | validation: 0.1589583016982588]
	TIME [epoch: 9.74 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16718457351442884		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.16718457351442884 | validation: 0.149927060279695]
	TIME [epoch: 9.77 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2301411474373604		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.2301411474373604 | validation: 0.27110366271909153]
	TIME [epoch: 9.76 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604880436782551		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.1604880436782551 | validation: 0.16893929123361823]
	TIME [epoch: 9.76 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21717162271898363		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.21717162271898363 | validation: 0.16650786328242487]
	TIME [epoch: 9.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503032475541845		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.1503032475541845 | validation: 0.12261113502086629]
	TIME [epoch: 9.77 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16305852977243435		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.16305852977243435 | validation: 0.13751658808046588]
	TIME [epoch: 9.75 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14281317349789321		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.14281317349789321 | validation: 0.14326264438033853]
	TIME [epoch: 9.75 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16526515843902273		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.16526515843902273 | validation: 0.1386862498669435]
	TIME [epoch: 9.77 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14793432842328272		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.14793432842328272 | validation: 0.11839511109055142]
	TIME [epoch: 9.75 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17783633446195873		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.17783633446195873 | validation: 0.24129149609961317]
	TIME [epoch: 9.75 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2331077188416964		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.2331077188416964 | validation: 0.14164463844304243]
	TIME [epoch: 9.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15148910004885155		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.15148910004885155 | validation: 0.12855872697121717]
	TIME [epoch: 9.77 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1423820931406097		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.1423820931406097 | validation: 0.1743462672830483]
	TIME [epoch: 9.75 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18604250794393176		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.18604250794393176 | validation: 0.1710776796710036]
	TIME [epoch: 9.75 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636085304455951		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.1636085304455951 | validation: 0.1383786316440397]
	TIME [epoch: 9.77 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19215608775000126		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.19215608775000126 | validation: 0.2402723541576359]
	TIME [epoch: 9.75 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24246901786667516		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.24246901786667516 | validation: 0.14946525095763055]
	TIME [epoch: 9.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15021019338490388		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.15021019338490388 | validation: 0.12440554244752541]
	TIME [epoch: 9.77 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15504476122479618		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.15504476122479618 | validation: 0.12580503873395465]
	TIME [epoch: 9.75 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13786807061445852		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.13786807061445852 | validation: 0.1259340314368039]
	TIME [epoch: 9.75 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1238096064005132		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.1238096064005132 | validation: 0.10113061027391959]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1088.pth
	Model improved!!!
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1935818135292083		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.1935818135292083 | validation: 0.22330989243864707]
	TIME [epoch: 9.78 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22725109836679963		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.22725109836679963 | validation: 0.17341787137176348]
	TIME [epoch: 9.76 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17126120993606805		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.17126120993606805 | validation: 0.11532664906612011]
	TIME [epoch: 9.74 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535421168167228		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.1535421168167228 | validation: 0.11488722071151031]
	TIME [epoch: 9.77 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14129668115035315		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.14129668115035315 | validation: 0.11916993160378542]
	TIME [epoch: 9.76 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1463623362386946		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.1463623362386946 | validation: 0.19086256931585904]
	TIME [epoch: 9.75 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16949218560947316		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.16949218560947316 | validation: 0.1984468896120886]
	TIME [epoch: 9.77 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17642271563933884		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.17642271563933884 | validation: 0.16515878101936923]
	TIME [epoch: 9.77 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14987907675853024		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.14987907675853024 | validation: 0.09717027260052405]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1097.pth
	Model improved!!!
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14668909281161882		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.14668909281161882 | validation: 0.1459339176379799]
	TIME [epoch: 9.76 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16232902024310558		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.16232902024310558 | validation: 0.12283110697130305]
	TIME [epoch: 9.77 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14108642051237258		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.14108642051237258 | validation: 0.14851077662984322]
	TIME [epoch: 9.74 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21708837910321882		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.21708837910321882 | validation: 0.12365777234322156]
	TIME [epoch: 9.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17868130919485342		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.17868130919485342 | validation: 0.15077163001038826]
	TIME [epoch: 9.77 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16185156595700775		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.16185156595700775 | validation: 0.1768480784058266]
	TIME [epoch: 9.75 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21766682667164292		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.21766682667164292 | validation: 0.30612950432388636]
	TIME [epoch: 9.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27603787268131014		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.27603787268131014 | validation: 0.14980496591073209]
	TIME [epoch: 9.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14174197445988262		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.14174197445988262 | validation: 0.13369853694824907]
	TIME [epoch: 9.77 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14304876606605538		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.14304876606605538 | validation: 0.13483109571677743]
	TIME [epoch: 9.75 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1368897462529678		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.1368897462529678 | validation: 0.1689015399635877]
	TIME [epoch: 9.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19376076230985784		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.19376076230985784 | validation: 0.1502962988483931]
	TIME [epoch: 9.76 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14999382719523596		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.14999382719523596 | validation: 0.1658919705028101]
	TIME [epoch: 9.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17306098102949227		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.17306098102949227 | validation: 0.1408722321184317]
	TIME [epoch: 9.75 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788297532397158		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.15788297532397158 | validation: 0.1949914602607758]
	TIME [epoch: 9.77 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762577225693489		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.1762577225693489 | validation: 0.10975488904198262]
	TIME [epoch: 9.75 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15264174961938154		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.15264174961938154 | validation: 0.13039031168086648]
	TIME [epoch: 9.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1206284791114967		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.1206284791114967 | validation: 0.15023919920735754]
	TIME [epoch: 9.75 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1469678104945535		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.1469678104945535 | validation: 0.13248023462842853]
	TIME [epoch: 9.78 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15352006891790182		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.15352006891790182 | validation: 0.16340533816219996]
	TIME [epoch: 9.75 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14738811193620643		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.14738811193620643 | validation: 0.15015954248217975]
	TIME [epoch: 9.75 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15236231581368362		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.15236231581368362 | validation: 0.13656243132688206]
	TIME [epoch: 9.77 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14038379985641566		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.14038379985641566 | validation: 0.1331253804502412]
	TIME [epoch: 9.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2376236282021889		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.2376236282021889 | validation: 0.14384162497368777]
	TIME [epoch: 9.76 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15398560780048037		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.15398560780048037 | validation: 0.16334521683757228]
	TIME [epoch: 9.75 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1509856213582868		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.1509856213582868 | validation: 0.20195286413916003]
	TIME [epoch: 9.76 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1713008518213238		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.1713008518213238 | validation: 0.17887556651022113]
	TIME [epoch: 9.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15440812502126008		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.15440812502126008 | validation: 0.18770323472955086]
	TIME [epoch: 9.74 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14442525995806327		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.14442525995806327 | validation: 0.13474676292397378]
	TIME [epoch: 9.77 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1273113646460499		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.1273113646460499 | validation: 0.16590629680534666]
	TIME [epoch: 9.75 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13493939410802522		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.13493939410802522 | validation: 0.11059018757794929]
	TIME [epoch: 9.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12621400187028747		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.12621400187028747 | validation: 0.11924875488702938]
	TIME [epoch: 9.76 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13688408505536623		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.13688408505536623 | validation: 0.13571673714472035]
	TIME [epoch: 9.75 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13425735800051974		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.13425735800051974 | validation: 0.1434988193839373]
	TIME [epoch: 9.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13832651082961742		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.13832651082961742 | validation: 0.12946123492128706]
	TIME [epoch: 9.75 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708209948819334		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.1708209948819334 | validation: 0.1544929780489829]
	TIME [epoch: 9.77 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13968090850603612		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.13968090850603612 | validation: 0.12625117110089407]
	TIME [epoch: 9.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15804832484507286		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.15804832484507286 | validation: 0.12215166807608538]
	TIME [epoch: 9.73 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14208081905889375		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.14208081905889375 | validation: 0.203383445751502]
	TIME [epoch: 9.75 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16357371223137723		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.16357371223137723 | validation: 0.14031421527586052]
	TIME [epoch: 9.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556827929242436		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.1556827929242436 | validation: 0.12135087081754631]
	TIME [epoch: 9.74 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15403845747836015		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.15403845747836015 | validation: 0.13917414345382131]
	TIME [epoch: 9.76 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15321510054765408		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.15321510054765408 | validation: 0.15382181361005612]
	TIME [epoch: 9.74 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21345240889554118		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.21345240889554118 | validation: 0.20419126564608328]
	TIME [epoch: 9.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27291883803439443		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.27291883803439443 | validation: 0.2680906767320406]
	TIME [epoch: 9.74 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2294363713750045		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.2294363713750045 | validation: 0.20984857347385194]
	TIME [epoch: 9.77 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19199456102857593		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.19199456102857593 | validation: 0.13805443439210927]
	TIME [epoch: 9.75 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13687597182159442		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.13687597182159442 | validation: 0.10229741023936197]
	TIME [epoch: 9.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17603136708130968		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.17603136708130968 | validation: 0.14632683305741295]
	TIME [epoch: 9.77 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1806043334165918		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.1806043334165918 | validation: 0.16434242026241183]
	TIME [epoch: 9.75 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1410336070887362		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.1410336070887362 | validation: 0.11416568192924716]
	TIME [epoch: 9.75 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15618970816384997		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.15618970816384997 | validation: 0.15278262860084457]
	TIME [epoch: 9.75 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638440156956598		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.1638440156956598 | validation: 0.10540021375904444]
	TIME [epoch: 9.76 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12202869998896795		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.12202869998896795 | validation: 0.12639764370643453]
	TIME [epoch: 9.73 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14726765325834845		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.14726765325834845 | validation: 0.10614365460265864]
	TIME [epoch: 9.75 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1301333959664479		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.1301333959664479 | validation: 0.11575939126419046]
	TIME [epoch: 9.78 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13992025412028847		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.13992025412028847 | validation: 0.14234341981512927]
	TIME [epoch: 9.75 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18339389058032457		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.18339389058032457 | validation: 0.13832069175297754]
	TIME [epoch: 9.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14629673305250934		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.14629673305250934 | validation: 0.17975807858789566]
	TIME [epoch: 9.76 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16570076005850692		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.16570076005850692 | validation: 0.12722804415980965]
	TIME [epoch: 9.75 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12336485660044431		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.12336485660044431 | validation: 0.1216451808558743]
	TIME [epoch: 9.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12938017579266523		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.12938017579266523 | validation: 0.16702604873501856]
	TIME [epoch: 9.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15691488125323866		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.15691488125323866 | validation: 0.2085945271835467]
	TIME [epoch: 9.77 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17858628464362541		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.17858628464362541 | validation: 0.15281050502125879]
	TIME [epoch: 9.75 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14959134830562293		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.14959134830562293 | validation: 0.12941628137635874]
	TIME [epoch: 9.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1384607577769807		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.1384607577769807 | validation: 0.14022090341805254]
	TIME [epoch: 9.75 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1360926670971056		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.1360926670971056 | validation: 0.13999078771643814]
	TIME [epoch: 9.75 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14733408284962843		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.14733408284962843 | validation: 0.18708287744039923]
	TIME [epoch: 9.74 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544820789220581		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.1544820789220581 | validation: 0.10602729113155526]
	TIME [epoch: 9.75 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11628901787073784		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.11628901787073784 | validation: 0.12010931566554886]
	TIME [epoch: 9.77 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1904319705258694		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.1904319705258694 | validation: 0.12136552848772496]
	TIME [epoch: 9.75 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12325427175314918		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.12325427175314918 | validation: 0.11675876447433925]
	TIME [epoch: 9.74 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1220728406494795		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.1220728406494795 | validation: 0.10941385104574115]
	TIME [epoch: 9.77 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12371164363484163		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.12371164363484163 | validation: 0.15011837745138273]
	TIME [epoch: 9.75 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16263809153870779		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.16263809153870779 | validation: 0.12392930374277239]
	TIME [epoch: 9.75 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14053417846853722		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.14053417846853722 | validation: 0.14914817657835588]
	TIME [epoch: 9.77 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14745343279551748		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.14745343279551748 | validation: 0.12957346945346448]
	TIME [epoch: 9.75 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558406583929226		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.1558406583929226 | validation: 0.14770590175418624]
	TIME [epoch: 9.75 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304457888383624		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.1304457888383624 | validation: 0.14413824547246104]
	TIME [epoch: 9.75 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1255814602909997		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.1255814602909997 | validation: 0.1359569271680876]
	TIME [epoch: 9.76 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15138593676446144		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.15138593676446144 | validation: 0.1145447180670197]
	TIME [epoch: 9.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16025835120519336		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.16025835120519336 | validation: 0.12237711540803677]
	TIME [epoch: 9.74 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12210848053606176		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.12210848053606176 | validation: 0.13545461314135232]
	TIME [epoch: 9.75 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18889679180284968		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.18889679180284968 | validation: 0.1436531424374709]
	TIME [epoch: 9.74 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14068630313158495		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.14068630313158495 | validation: 0.19770076841790624]
	TIME [epoch: 9.75 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2149757142819409		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.2149757142819409 | validation: 0.19117339040689188]
	TIME [epoch: 9.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18493912411629274		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.18493912411629274 | validation: 0.1475839098408183]
	TIME [epoch: 9.75 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14404746641165417		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.14404746641165417 | validation: 0.12730888618483857]
	TIME [epoch: 9.73 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15483909911487648		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.15483909911487648 | validation: 0.12033976816964026]
	TIME [epoch: 9.73 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155421149116696		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.155421149116696 | validation: 0.15726996205327023]
	TIME [epoch: 9.77 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27722385032141		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.27722385032141 | validation: 0.3078339227999487]
	TIME [epoch: 9.74 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2782890826664614		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.2782890826664614 | validation: 0.13398003803539604]
	TIME [epoch: 9.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11435852727986395		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.11435852727986395 | validation: 0.11719703961078182]
	TIME [epoch: 9.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14958959036597447		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.14958959036597447 | validation: 0.1978297463310732]
	TIME [epoch: 9.74 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2149373129120376		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.2149373129120376 | validation: 0.14775512376238215]
	TIME [epoch: 9.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16894166641022662		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.16894166641022662 | validation: 0.2306458111844515]
	TIME [epoch: 9.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17790185982173226		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.17790185982173226 | validation: 0.14158606310184604]
	TIME [epoch: 9.76 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13823243852306036		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.13823243852306036 | validation: 0.12187294734331414]
	TIME [epoch: 9.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13015736519928384		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.13015736519928384 | validation: 0.1127731245464915]
	TIME [epoch: 9.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14808828002989544		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.14808828002989544 | validation: 0.10488237563944523]
	TIME [epoch: 9.77 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13858881220345654		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.13858881220345654 | validation: 0.1687290962041985]
	TIME [epoch: 9.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16303043681710427		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.16303043681710427 | validation: 0.15975359303449863]
	TIME [epoch: 9.73 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1960293622858162		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.1960293622858162 | validation: 0.14622521930059304]
	TIME [epoch: 9.73 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11586556570128533		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.11586556570128533 | validation: 0.11509535359109982]
	TIME [epoch: 9.75 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14275346394742527		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.14275346394742527 | validation: 0.11389384903517431]
	TIME [epoch: 9.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1332962338641464		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.1332962338641464 | validation: 0.13229414957196892]
	TIME [epoch: 9.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16011011615744736		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.16011011615744736 | validation: 0.31338861647433286]
	TIME [epoch: 9.77 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2028350316529334		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.2028350316529334 | validation: 0.13795470217107905]
	TIME [epoch: 9.74 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14550166931495828		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.14550166931495828 | validation: 0.10795395407679986]
	TIME [epoch: 9.73 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12515682339053635		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.12515682339053635 | validation: 0.12284287812381445]
	TIME [epoch: 9.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492482644604194		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.1492482644604194 | validation: 0.11457377449983305]
	TIME [epoch: 9.73 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13548227736798815		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.13548227736798815 | validation: 0.18444171273190985]
	TIME [epoch: 9.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17523799529321973		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.17523799529321973 | validation: 0.15206777691923123]
	TIME [epoch: 9.75 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15083398939035245		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.15083398939035245 | validation: 0.1433961634146168]
	TIME [epoch: 9.76 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17329601275755702		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.17329601275755702 | validation: 0.24147507636612006]
	TIME [epoch: 9.75 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22280085586767298		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.22280085586767298 | validation: 0.1499782998259348]
	TIME [epoch: 9.75 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15676221716192182		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.15676221716192182 | validation: 0.122813204773936]
	TIME [epoch: 9.75 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14997524894791076		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.14997524894791076 | validation: 0.1279907219763536]
	TIME [epoch: 9.74 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14145909616661378		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.14145909616661378 | validation: 0.09157255378243705]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1216.pth
	Model improved!!!
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304667189204584		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.1304667189204584 | validation: 0.11568203793537166]
	TIME [epoch: 9.76 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16233715543447994		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.16233715543447994 | validation: 0.1489867424830157]
	TIME [epoch: 9.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14808603736657275		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.14808603736657275 | validation: 0.14470381888737247]
	TIME [epoch: 9.73 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14783938236520777		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.14783938236520777 | validation: 0.11900862030707984]
	TIME [epoch: 9.73 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304050619004002		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.1304050619004002 | validation: 0.13082450129869116]
	TIME [epoch: 9.75 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209612256281915		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.15209612256281915 | validation: 0.18470889635118176]
	TIME [epoch: 9.74 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24275735959425265		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.24275735959425265 | validation: 0.21045065027011348]
	TIME [epoch: 9.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16966744568797393		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.16966744568797393 | validation: 0.1513599214043163]
	TIME [epoch: 9.75 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759990657891875		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.1759990657891875 | validation: 0.1434369754922165]
	TIME [epoch: 9.74 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1345709658603184		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.1345709658603184 | validation: 0.13168141583759746]
	TIME [epoch: 9.74 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13107026818204184		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.13107026818204184 | validation: 0.13836170586536808]
	TIME [epoch: 9.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13684538176029623		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.13684538176029623 | validation: 0.17420023929880227]
	TIME [epoch: 9.75 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14998513219111287		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.14998513219111287 | validation: 0.10036498048930009]
	TIME [epoch: 9.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12823775923892372		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.12823775923892372 | validation: 0.11381691584147792]
	TIME [epoch: 9.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15453114346660454		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.15453114346660454 | validation: 0.10107179759067886]
	TIME [epoch: 9.78 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12842491477117624		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.12842491477117624 | validation: 0.14541455197098135]
	TIME [epoch: 9.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276443496935045		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.1276443496935045 | validation: 0.1487175342609158]
	TIME [epoch: 9.75 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14359568721844002		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.14359568721844002 | validation: 0.10402835054579558]
	TIME [epoch: 9.76 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1344929455212096		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.1344929455212096 | validation: 0.10653677666594606]
	TIME [epoch: 9.76 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12274155480223754		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.12274155480223754 | validation: 0.13341901248265517]
	TIME [epoch: 9.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590295063975599		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.1590295063975599 | validation: 0.21659250664614216]
	TIME [epoch: 9.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15645703293816854		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.15645703293816854 | validation: 0.14536017973742157]
	TIME [epoch: 9.78 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15915925023745794		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.15915925023745794 | validation: 0.20229087315185004]
	TIME [epoch: 9.74 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16187723158028655		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.16187723158028655 | validation: 0.09985268309212654]
	TIME [epoch: 9.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.136868058949745		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.136868058949745 | validation: 0.10600677192952628]
	TIME [epoch: 9.77 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14468047896715933		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.14468047896715933 | validation: 0.10709276639308492]
	TIME [epoch: 9.75 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15059873570425936		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.15059873570425936 | validation: 0.20639324061316536]
	TIME [epoch: 9.75 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19798157783929562		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.19798157783929562 | validation: 0.11082654906922432]
	TIME [epoch: 9.75 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1305205768083364		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.1305205768083364 | validation: 0.20440285623252222]
	TIME [epoch: 9.76 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20624936963978283		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.20624936963978283 | validation: 0.1584337882009752]
	TIME [epoch: 9.75 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15957351067885092		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.15957351067885092 | validation: 0.10965492441986197]
	TIME [epoch: 9.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14585736868429455		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.14585736868429455 | validation: 0.13858378937920882]
	TIME [epoch: 9.77 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11920565063164823		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.11920565063164823 | validation: 0.11307249307777091]
	TIME [epoch: 9.73 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11691921885594432		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.11691921885594432 | validation: 0.12167685091131163]
	TIME [epoch: 9.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1338291475369348		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.1338291475369348 | validation: 0.15787257792926235]
	TIME [epoch: 9.76 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20515440695768938		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.20515440695768938 | validation: 0.11871404728259301]
	TIME [epoch: 9.73 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.168634695420082		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.168634695420082 | validation: 0.10947413833048827]
	TIME [epoch: 9.73 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14984914906250388		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.14984914906250388 | validation: 0.13193714142152566]
	TIME [epoch: 9.75 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458455287579754		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.1458455287579754 | validation: 0.10910772823078312]
	TIME [epoch: 9.76 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1416338144100817		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.1416338144100817 | validation: 0.13857958664413508]
	TIME [epoch: 9.75 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1409319956879782		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.1409319956879782 | validation: 0.1259038233565829]
	TIME [epoch: 9.75 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14535075207599968		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.14535075207599968 | validation: 0.11618421833927874]
	TIME [epoch: 9.77 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11596366109123624		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.11596366109123624 | validation: 0.1375074782892708]
	TIME [epoch: 9.75 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12830731414697977		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.12830731414697977 | validation: 0.15140044154141274]
	TIME [epoch: 9.75 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14797235625941013		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.14797235625941013 | validation: 0.16528797496988545]
	TIME [epoch: 9.75 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1336376640253981		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.1336376640253981 | validation: 0.11983588998512261]
	TIME [epoch: 9.76 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13987547471391745		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.13987547471391745 | validation: 0.10441746709775716]
	TIME [epoch: 9.75 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14659588844743046		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.14659588844743046 | validation: 0.15219125656151877]
	TIME [epoch: 9.75 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1774804302466452		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.1774804302466452 | validation: 0.1195552583569004]
	TIME [epoch: 9.78 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1339789597844774		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.1339789597844774 | validation: 0.12045547652618263]
	TIME [epoch: 9.75 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11734191178265097		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.11734191178265097 | validation: 0.12165297577652939]
	TIME [epoch: 9.75 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14326410136130954		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.14326410136130954 | validation: 0.16047013562953993]
	TIME [epoch: 9.76 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20042738218075956		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.20042738218075956 | validation: 0.1211178399559465]
	TIME [epoch: 9.75 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12801902948427843		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.12801902948427843 | validation: 0.11285556187202973]
	TIME [epoch: 9.75 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16488932929462097		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.16488932929462097 | validation: 0.14668110118041097]
	TIME [epoch: 9.76 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17579992308685552		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.17579992308685552 | validation: 0.1149799110988225]
	TIME [epoch: 9.78 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12543385134812368		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.12543385134812368 | validation: 0.15857864032191632]
	TIME [epoch: 9.75 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16025507649621068		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.16025507649621068 | validation: 0.14083266818286572]
	TIME [epoch: 9.75 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1268058883344398		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.1268058883344398 | validation: 0.10673512306541341]
	TIME [epoch: 9.76 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1256127478448107		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.1256127478448107 | validation: 0.11420053438026902]
	TIME [epoch: 9.74 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13946139747919273		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.13946139747919273 | validation: 0.18624420635784333]
	TIME [epoch: 9.74 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28830139120683523		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.28830139120683523 | validation: 0.2772296351443585]
	TIME [epoch: 9.75 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1891906540309321		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.1891906540309321 | validation: 0.12504584195759436]
	TIME [epoch: 9.76 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11845550307620789		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.11845550307620789 | validation: 0.09673234063077576]
	TIME [epoch: 9.76 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11790234016918681		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.11790234016918681 | validation: 0.14363010166708873]
	TIME [epoch: 9.75 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14334840581108824		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.14334840581108824 | validation: 0.10874770907788907]
	TIME [epoch: 9.76 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1270184965811732		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.1270184965811732 | validation: 0.11348762156242465]
	TIME [epoch: 9.75 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13686765766935133		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.13686765766935133 | validation: 0.16391348245578527]
	TIME [epoch: 9.75 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562031060826633		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.1562031060826633 | validation: 0.13410925421923078]
	TIME [epoch: 9.76 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1385852895738294		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.1385852895738294 | validation: 0.12533686466523541]
	TIME [epoch: 9.74 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14298127525970478		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.14298127525970478 | validation: 0.11956990465367484]
	TIME [epoch: 9.74 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11851348088108875		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.11851348088108875 | validation: 0.11599899400709404]
	TIME [epoch: 9.74 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1197342768217714		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.1197342768217714 | validation: 0.17305148642761345]
	TIME [epoch: 9.76 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618604966032725		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.1618604966032725 | validation: 0.0881011455536763]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1290.pth
	Model improved!!!
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11955277508742615		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.11955277508742615 | validation: 0.12224322376272508]
	TIME [epoch: 9.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1180123872047865		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.1180123872047865 | validation: 0.16433287304872718]
	TIME [epoch: 9.77 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575341992796768		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.1575341992796768 | validation: 0.12096193330891926]
	TIME [epoch: 9.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12519804408973573		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.12519804408973573 | validation: 0.11950938790560472]
	TIME [epoch: 9.73 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12918947238680528		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.12918947238680528 | validation: 0.11355098493594555]
	TIME [epoch: 9.76 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10707602870790818		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.10707602870790818 | validation: 0.1174319489772512]
	TIME [epoch: 9.75 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11663126238138413		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.11663126238138413 | validation: 0.1109703798913101]
	TIME [epoch: 9.75 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12142191085623173		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.12142191085623173 | validation: 0.1266470818225134]
	TIME [epoch: 9.75 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13142354456561328		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.13142354456561328 | validation: 0.12328523522036505]
	TIME [epoch: 9.76 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14164974824594906		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.14164974824594906 | validation: 0.11921796682510027]
	TIME [epoch: 9.75 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1158116635197836		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.1158116635197836 | validation: 0.09432073620656237]
	TIME [epoch: 9.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11522546803476719		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.11522546803476719 | validation: 0.12367700135396159]
	TIME [epoch: 9.77 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12777002220379735		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.12777002220379735 | validation: 0.14950677897973505]
	TIME [epoch: 9.75 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12745355715633783		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.12745355715633783 | validation: 0.13139194488229636]
	TIME [epoch: 9.76 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1331357350810022		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.1331357350810022 | validation: 0.09963995185608358]
	TIME [epoch: 9.76 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13227477359868933		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.13227477359868933 | validation: 0.10422708224599392]
	TIME [epoch: 9.77 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11105942412094852		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.11105942412094852 | validation: 0.12021258921335985]
	TIME [epoch: 9.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14523275825323542		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.14523275825323542 | validation: 0.1376583571544738]
	TIME [epoch: 9.75 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13009790063695753		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.13009790063695753 | validation: 0.10724333668363993]
	TIME [epoch: 9.77 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11725962979939561		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.11725962979939561 | validation: 0.1695492784372665]
	TIME [epoch: 9.75 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11568627469528328		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.11568627469528328 | validation: 0.09011491940034824]
	TIME [epoch: 9.75 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11763379941629568		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.11763379941629568 | validation: 0.10463501519919767]
	TIME [epoch: 9.77 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12006929488683422		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.12006929488683422 | validation: 0.105778403093948]
	TIME [epoch: 9.75 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12240535101796528		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.12240535101796528 | validation: 0.09655735145008557]
	TIME [epoch: 9.75 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12141559701051732		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.12141559701051732 | validation: 0.11445630634486662]
	TIME [epoch: 9.75 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1299038599690066		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.1299038599690066 | validation: 0.12325714582007521]
	TIME [epoch: 9.76 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14514788495958525		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.14514788495958525 | validation: 0.12042402597775022]
	TIME [epoch: 9.75 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128376042831101		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.128376042831101 | validation: 0.10147851773212116]
	TIME [epoch: 9.75 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11177448459493906		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.11177448459493906 | validation: 0.09682733426218407]
	TIME [epoch: 9.77 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11285209849472762		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.11285209849472762 | validation: 0.1175600370401838]
	TIME [epoch: 9.75 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12896054260951856		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.12896054260951856 | validation: 0.10881533397962319]
	TIME [epoch: 9.74 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14336652317619575		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.14336652317619575 | validation: 0.1312812946251138]
	TIME [epoch: 9.76 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1947935365462302		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.1947935365462302 | validation: 0.1717011473096987]
	TIME [epoch: 9.75 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17340605437239648		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.17340605437239648 | validation: 0.1389563157104923]
	TIME [epoch: 9.75 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12403522703862835		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.12403522703862835 | validation: 0.1089434104563064]
	TIME [epoch: 9.74 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12598305010731892		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.12598305010731892 | validation: 0.11043723598535488]
	TIME [epoch: 9.77 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1262375198664588		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.1262375198664588 | validation: 0.09125843682478686]
	TIME [epoch: 9.75 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12523950275010834		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.12523950275010834 | validation: 0.1260320985900197]
	TIME [epoch: 9.75 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19127044228749046		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.19127044228749046 | validation: 0.151140960238699]
	TIME [epoch: 9.76 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1311573934291621		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.1311573934291621 | validation: 0.12918002955627006]
	TIME [epoch: 9.75 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15667155994419707		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.15667155994419707 | validation: 0.20000765751775987]
	TIME [epoch: 9.75 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639696910613845		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.1639696910613845 | validation: 0.102280686260709]
	TIME [epoch: 9.75 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1126671356670608		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.1126671356670608 | validation: 0.136376453070264]
	TIME [epoch: 9.77 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18216555130648657		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.18216555130648657 | validation: 0.1051897275315152]
	TIME [epoch: 9.75 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253850026208316		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.1253850026208316 | validation: 0.14120812821104425]
	TIME [epoch: 9.75 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13367835825263807		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.13367835825263807 | validation: 0.10989052191620609]
	TIME [epoch: 9.77 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12309975453205205		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.12309975453205205 | validation: 0.16864201687095104]
	TIME [epoch: 9.75 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1734085253946515		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.1734085253946515 | validation: 0.14471549585551224]
	TIME [epoch: 9.75 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14311795227019625		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.14311795227019625 | validation: 0.14279400663970743]
	TIME [epoch: 9.77 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1297210339432111		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.1297210339432111 | validation: 0.10894895704358344]
	TIME [epoch: 9.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12995166898388305		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.12995166898388305 | validation: 0.1091038105481424]
	TIME [epoch: 9.75 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14013861071475475		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.14013861071475475 | validation: 0.13517321347746922]
	TIME [epoch: 9.75 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1148518746571181		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.1148518746571181 | validation: 0.08756654546056022]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1343.pth
	Model improved!!!
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11208929155784889		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.11208929155784889 | validation: 0.11113043074116483]
	TIME [epoch: 9.76 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11666585971317955		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.11666585971317955 | validation: 0.09855536987008097]
	TIME [epoch: 9.76 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13001598583601076		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.13001598583601076 | validation: 0.12603334822181492]
	TIME [epoch: 9.78 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12188458438962584		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.12188458438962584 | validation: 0.10623611086526297]
	TIME [epoch: 9.76 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11519460468103282		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.11519460468103282 | validation: 0.08736534751022791]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1348.pth
	Model improved!!!
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11190769020301343		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.11190769020301343 | validation: 0.10659061496661192]
	TIME [epoch: 9.77 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1269466984885953		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.1269466984885953 | validation: 0.11562727927626934]
	TIME [epoch: 9.76 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1350605906427507		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.1350605906427507 | validation: 0.098419514730716]
	TIME [epoch: 9.75 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11558981254028444		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.11558981254028444 | validation: 0.11091768169211036]
	TIME [epoch: 9.75 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14291942964270335		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.14291942964270335 | validation: 0.1302296571538341]
	TIME [epoch: 9.77 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1409487467898673		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.1409487467898673 | validation: 0.14024752557727213]
	TIME [epoch: 9.75 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12751682163877356		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.12751682163877356 | validation: 0.10379170200004648]
	TIME [epoch: 9.74 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11234881225255515		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.11234881225255515 | validation: 0.11192626421546031]
	TIME [epoch: 9.76 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13526936354885405		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.13526936354885405 | validation: 0.13355388060779777]
	TIME [epoch: 9.76 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13271035535872513		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.13271035535872513 | validation: 0.11695671338409042]
	TIME [epoch: 9.74 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11587615418897076		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.11587615418897076 | validation: 0.11586400795097301]
	TIME [epoch: 9.75 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11924257503986002		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.11924257503986002 | validation: 0.14584071708561144]
	TIME [epoch: 9.76 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16212076677166928		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.16212076677166928 | validation: 0.1529907302894492]
	TIME [epoch: 9.75 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1208549855649212		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.1208549855649212 | validation: 0.13664678912024286]
	TIME [epoch: 9.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11945827349290343		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.11945827349290343 | validation: 0.11925467961231713]
	TIME [epoch: 9.77 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11526110391324662		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.11526110391324662 | validation: 0.11195677366073098]
	TIME [epoch: 9.74 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12341162538078738		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.12341162538078738 | validation: 0.12865238051440764]
	TIME [epoch: 9.75 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572413624061749		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.1572413624061749 | validation: 0.11109602728940925]
	TIME [epoch: 9.76 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11103032021755951		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.11103032021755951 | validation: 0.1155490447273303]
	TIME [epoch: 9.75 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11609147488672558		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.11609147488672558 | validation: 0.10560628074504798]
	TIME [epoch: 9.75 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11471709627297891		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.11471709627297891 | validation: 0.09894050545646742]
	TIME [epoch: 9.75 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1099439548901123		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.1099439548901123 | validation: 0.11286483744555877]
	TIME [epoch: 9.77 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11382779969314125		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.11382779969314125 | validation: 0.11575574968348469]
	TIME [epoch: 9.76 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12467623451574697		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.12467623451574697 | validation: 0.14446855232029646]
	TIME [epoch: 9.75 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13677441484043126		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.13677441484043126 | validation: 0.11489090646013121]
	TIME [epoch: 9.78 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14437132692031407		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.14437132692031407 | validation: 0.1696440471923586]
	TIME [epoch: 9.75 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1585237204474314		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.1585237204474314 | validation: 0.10754403569481122]
	TIME [epoch: 9.75 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11281886274192494		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.11281886274192494 | validation: 0.08546855727674416]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1376.pth
	Model improved!!!
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11524549282100542		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.11524549282100542 | validation: 0.11655977441036598]
	TIME [epoch: 9.77 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12239859619322777		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.12239859619322777 | validation: 0.11447490149291412]
	TIME [epoch: 9.76 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11973092224396202		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.11973092224396202 | validation: 0.1106577070208509]
	TIME [epoch: 9.76 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128368087497918		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.128368087497918 | validation: 0.09945432601085599]
	TIME [epoch: 9.79 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11445919197562895		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.11445919197562895 | validation: 0.12674284119071483]
	TIME [epoch: 9.76 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13382360693427447		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.13382360693427447 | validation: 0.12669213643418442]
	TIME [epoch: 9.77 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16219918474513315		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.16219918474513315 | validation: 0.15832713914970015]
	TIME [epoch: 9.78 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18137232184055288		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.18137232184055288 | validation: 0.13792058628207168]
	TIME [epoch: 9.77 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1262676166046229		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.1262676166046229 | validation: 0.09896253218466292]
	TIME [epoch: 9.76 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1223380658251838		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.1223380658251838 | validation: 0.09163688994265759]
	TIME [epoch: 9.78 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13847801730657555		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.13847801730657555 | validation: 0.2261279634091533]
	TIME [epoch: 9.78 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21422194413910126		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.21422194413910126 | validation: 0.11985874412004677]
	TIME [epoch: 9.78 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12039992856953305		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.12039992856953305 | validation: 0.09626824552507848]
	TIME [epoch: 9.76 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10549495903047088		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.10549495903047088 | validation: 0.08414706975236498]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1390.pth
	Model improved!!!
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10783998413217392		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.10783998413217392 | validation: 0.12071670286014406]
	TIME [epoch: 9.77 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1070182288703325		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.1070182288703325 | validation: 0.10370150899302853]
	TIME [epoch: 9.76 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11043385821087645		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.11043385821087645 | validation: 0.11219692802826162]
	TIME [epoch: 9.77 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12035886361375248		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.12035886361375248 | validation: 0.11360926701066434]
	TIME [epoch: 9.77 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12274875979022722		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.12274875979022722 | validation: 0.13177831328505313]
	TIME [epoch: 9.76 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1316704627514042		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.1316704627514042 | validation: 0.12277979167273985]
	TIME [epoch: 9.77 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14534512735036248		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.14534512735036248 | validation: 0.12525551587559985]
	TIME [epoch: 9.78 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11960258340303476		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.11960258340303476 | validation: 0.13028907868221684]
	TIME [epoch: 9.76 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15257378391058118		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.15257378391058118 | validation: 0.15090033722595977]
	TIME [epoch: 9.76 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13084515007201192		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.13084515007201192 | validation: 0.1017749097806106]
	TIME [epoch: 9.79 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11403270666185336		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.11403270666185336 | validation: 0.13061187769720295]
	TIME [epoch: 9.76 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14560127058402467		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.14560127058402467 | validation: 0.16132601863782867]
	TIME [epoch: 9.76 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12716354330978308		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.12716354330978308 | validation: 0.10670939730471694]
	TIME [epoch: 9.77 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1335364010868924		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.1335364010868924 | validation: 0.1436966312307278]
	TIME [epoch: 9.77 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661207361480969		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.1661207361480969 | validation: 0.11213354326198241]
	TIME [epoch: 9.76 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12272516337531987		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.12272516337531987 | validation: 0.14766278880674652]
	TIME [epoch: 9.76 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15258914175915408		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.15258914175915408 | validation: 0.1260839211431367]
	TIME [epoch: 9.78 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12345752136262614		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.12345752136262614 | validation: 0.10664433480468778]
	TIME [epoch: 9.76 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.109951600399075		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.109951600399075 | validation: 0.100217751678711]
	TIME [epoch: 9.76 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11913951277951758		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.11913951277951758 | validation: 0.117977388170555]
	TIME [epoch: 9.78 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1368049125387561		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.1368049125387561 | validation: 0.10346922436889956]
	TIME [epoch: 9.76 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.119203561808876		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.119203561808876 | validation: 0.12535076799948075]
	TIME [epoch: 9.77 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12855018839900295		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.12855018839900295 | validation: 0.11396401046917594]
	TIME [epoch: 9.77 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11425880213043853		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.11425880213043853 | validation: 0.10525763482125192]
	TIME [epoch: 9.78 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11347324296468145		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.11347324296468145 | validation: 0.12967649868287914]
	TIME [epoch: 9.77 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13312218841806672		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.13312218841806672 | validation: 0.1110032789791362]
	TIME [epoch: 9.76 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1037905881700288		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.1037905881700288 | validation: 0.09639295812232558]
	TIME [epoch: 9.78 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10434764634881008		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.10434764634881008 | validation: 0.10036209103589393]
	TIME [epoch: 9.76 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13483922786170316		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.13483922786170316 | validation: 0.10644816433497724]
	TIME [epoch: 9.76 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15894559955055593		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.15894559955055593 | validation: 0.12015899611841087]
	TIME [epoch: 9.78 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1392376200045917		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.1392376200045917 | validation: 0.10596205765664488]
	TIME [epoch: 9.76 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276354797715349		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.1276354797715349 | validation: 0.11602362710912777]
	TIME [epoch: 9.76 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166117977405114		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.1166117977405114 | validation: 0.09779240017131528]
	TIME [epoch: 9.76 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11545720772401946		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.11545720772401946 | validation: 0.10303516498683045]
	TIME [epoch: 9.78 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12015313938943543		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.12015313938943543 | validation: 0.10738928474206465]
	TIME [epoch: 9.76 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09646855933087006		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.09646855933087006 | validation: 0.09539396534562364]
	TIME [epoch: 9.76 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11163752126080943		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.11163752126080943 | validation: 0.10306146553241803]
	TIME [epoch: 9.78 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10234634727270046		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.10234634727270046 | validation: 0.10476108936244341]
	TIME [epoch: 9.76 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10631537424464337		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.10631537424464337 | validation: 0.09117395786892164]
	TIME [epoch: 9.75 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1364558523747621		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.1364558523747621 | validation: 0.11904174487385866]
	TIME [epoch: 9.77 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10748743865174962		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.10748743865174962 | validation: 0.11691749661719239]
	TIME [epoch: 9.77 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11155119639529691		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.11155119639529691 | validation: 0.08703114949399014]
	TIME [epoch: 9.76 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11139884084965468		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.11139884084965468 | validation: 0.11594235734748226]
	TIME [epoch: 9.75 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12923239788641683		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.12923239788641683 | validation: 0.10498581596839443]
	TIME [epoch: 9.78 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11171115879860816		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.11171115879860816 | validation: 0.08174256707318481]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1435.pth
	Model improved!!!
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11177793226795736		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.11177793226795736 | validation: 0.11829906900560225]
	TIME [epoch: 9.76 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11942666274117686		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.11942666274117686 | validation: 0.1008457502682556]
	TIME [epoch: 9.78 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11624427796432042		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.11624427796432042 | validation: 0.09448674628853511]
	TIME [epoch: 9.76 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11860857283461801		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.11860857283461801 | validation: 0.08440560713499767]
	TIME [epoch: 9.76 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10645341726144193		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.10645341726144193 | validation: 0.0796787010817109]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1440.pth
	Model improved!!!
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1128736941646932		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.1128736941646932 | validation: 0.17071273050971641]
	TIME [epoch: 9.77 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11670833889197677		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.11670833889197677 | validation: 0.10730340284826309]
	TIME [epoch: 9.75 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10743990538669838		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.10743990538669838 | validation: 0.1029770329428172]
	TIME [epoch: 9.75 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1077194406262469		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.1077194406262469 | validation: 0.12336502340391409]
	TIME [epoch: 9.77 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12493681099892359		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.12493681099892359 | validation: 0.11188443537167508]
	TIME [epoch: 9.75 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12061740000414278		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.12061740000414278 | validation: 0.11514201816239869]
	TIME [epoch: 9.75 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11460483271822439		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.11460483271822439 | validation: 0.099466000955519]
	TIME [epoch: 9.77 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1083127101624706		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.1083127101624706 | validation: 0.10502538234832848]
	TIME [epoch: 9.76 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10981600811439643		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.10981600811439643 | validation: 0.10526041697127544]
	TIME [epoch: 9.75 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11355291437166046		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.11355291437166046 | validation: 0.08625769894605263]
	TIME [epoch: 9.76 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10749798743291308		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.10749798743291308 | validation: 0.15411229317752667]
	TIME [epoch: 9.76 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19139474735207243		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.19139474735207243 | validation: 0.16377620842497403]
	TIME [epoch: 9.75 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14566295579789737		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.14566295579789737 | validation: 0.0929871528634688]
	TIME [epoch: 9.75 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10364036327167414		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.10364036327167414 | validation: 0.09654965498124103]
	TIME [epoch: 9.77 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15218218874639597		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.15218218874639597 | validation: 0.11622451848326235]
	TIME [epoch: 9.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10847531835165672		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.10847531835165672 | validation: 0.1034698818883237]
	TIME [epoch: 9.75 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10714391129685144		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.10714391129685144 | validation: 0.09886914461691441]
	TIME [epoch: 9.76 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11278752169176202		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.11278752169176202 | validation: 0.092749690503285]
	TIME [epoch: 9.76 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11421125992102923		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.11421125992102923 | validation: 0.1103995466323184]
	TIME [epoch: 9.75 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12825348038354528		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.12825348038354528 | validation: 0.12208261361494083]
	TIME [epoch: 9.75 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11419385861517461		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.11419385861517461 | validation: 0.10302898254751285]
	TIME [epoch: 9.77 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11794539772230146		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.11794539772230146 | validation: 0.12993883638066403]
	TIME [epoch: 9.75 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12638601959158396		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.12638601959158396 | validation: 0.10333981770552056]
	TIME [epoch: 9.76 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11901367389454334		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.11901367389454334 | validation: 0.11132083201413168]
	TIME [epoch: 9.77 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12636784439105841		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.12636784439105841 | validation: 0.10707899851032078]
	TIME [epoch: 9.75 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12112947953474469		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.12112947953474469 | validation: 0.09556810480623075]
	TIME [epoch: 9.75 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10446929908419171		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.10446929908419171 | validation: 0.08572575285052061]
	TIME [epoch: 9.76 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10576203010626957		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.10576203010626957 | validation: 0.12244327927006607]
	TIME [epoch: 9.77 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11410846014761038		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.11410846014761038 | validation: 0.10833851666986549]
	TIME [epoch: 9.75 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11689047881941025		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.11689047881941025 | validation: 0.09484366748408495]
	TIME [epoch: 9.75 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11275349766945675		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.11275349766945675 | validation: 0.09342399563303538]
	TIME [epoch: 9.77 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10492626366005545		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.10492626366005545 | validation: 0.09105780673642766]
	TIME [epoch: 9.75 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10745913938354387		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.10745913938354387 | validation: 0.09049641510235229]
	TIME [epoch: 9.75 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11359459485303373		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.11359459485303373 | validation: 0.09175817135150008]
	TIME [epoch: 9.77 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11017615526353344		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.11017615526353344 | validation: 0.08378113290685217]
	TIME [epoch: 9.75 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10547022304158053		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.10547022304158053 | validation: 0.09864077157710507]
	TIME [epoch: 9.75 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12006010770497995		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.12006010770497995 | validation: 0.12210126454517069]
	TIME [epoch: 9.75 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1620877134642601		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.1620877134642601 | validation: 0.10657525949924368]
	TIME [epoch: 9.77 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1176152442194874		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.1176152442194874 | validation: 0.10947406726365184]
	TIME [epoch: 9.75 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.110736251197872		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.110736251197872 | validation: 0.13243109032282846]
	TIME [epoch: 9.75 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785165451214879		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.1785165451214879 | validation: 0.1538484252868205]
	TIME [epoch: 9.76 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1305760467367308		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.1305760467367308 | validation: 0.11152775526472355]
	TIME [epoch: 9.75 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11050494177431584		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.11050494177431584 | validation: 0.08903665378929924]
	TIME [epoch: 9.75 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.095337772415456		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.095337772415456 | validation: 0.09871785340873848]
	TIME [epoch: 9.75 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10229268372015014		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.10229268372015014 | validation: 0.09093915118257441]
	TIME [epoch: 9.76 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10646545205620854		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.10646545205620854 | validation: 0.08960492475614429]
	TIME [epoch: 9.74 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12057289006443579		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.12057289006443579 | validation: 0.11254884385227072]
	TIME [epoch: 9.75 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1135867613288311		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.1135867613288311 | validation: 0.1387113325689753]
	TIME [epoch: 9.77 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13523387217783842		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.13523387217783842 | validation: 0.09575871738788623]
	TIME [epoch: 9.75 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12065321493466237		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.12065321493466237 | validation: 0.0976027802273761]
	TIME [epoch: 9.74 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11405597520560155		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.11405597520560155 | validation: 0.09867610688457029]
	TIME [epoch: 9.76 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1100156723850219		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.1100156723850219 | validation: 0.09312928091378728]
	TIME [epoch: 9.75 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10710516698710167		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.10710516698710167 | validation: 0.0909610132539672]
	TIME [epoch: 9.75 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1184692587352992		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.1184692587352992 | validation: 0.10837123077450198]
	TIME [epoch: 9.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11406651135776384		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.11406651135776384 | validation: 0.09905192944306687]
	TIME [epoch: 9.77 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1119196885953559		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.1119196885953559 | validation: 0.13099815929181075]
	TIME [epoch: 9.74 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12638162438501954		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.12638162438501954 | validation: 0.1177906617932965]
	TIME [epoch: 9.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11655322049081893		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.11655322049081893 | validation: 0.10984749594352115]
	TIME [epoch: 9.77 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12233505735272909		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.12233505735272909 | validation: 0.1033603449844685]
	TIME [epoch: 9.74 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166956909036038		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.1166956909036038 | validation: 0.11592906809750934]
	TIME [epoch: 9.74 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10768393873736051		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.10768393873736051 | validation: 0.10145615605864819]
	TIME [epoch: 9.76 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11311691704185112		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.11311691704185112 | validation: 0.08940245364322504]
	TIME [epoch: 9.76 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11072494169119255		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.11072494169119255 | validation: 0.10895521943335049]
	TIME [epoch: 9.75 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12080180027949698		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.12080180027949698 | validation: 0.11939729389604083]
	TIME [epoch: 9.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11259839375396334		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.11259839375396334 | validation: 0.1049513767494008]
	TIME [epoch: 9.77 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12022267276311376		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.12022267276311376 | validation: 0.10190887283798873]
	TIME [epoch: 9.75 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11013252316819686		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.11013252316819686 | validation: 0.1106478177989014]
	TIME [epoch: 9.75 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10686104163529216		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.10686104163529216 | validation: 0.08306358538378864]
	TIME [epoch: 9.76 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12171900617093438		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.12171900617093438 | validation: 0.10465864633417679]
	TIME [epoch: 9.75 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11308923535862714		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.11308923535862714 | validation: 0.10390853596381544]
	TIME [epoch: 9.75 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034844866398739		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.1034844866398739 | validation: 0.10123490240732679]
	TIME [epoch: 9.75 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10354988226021367		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.10354988226021367 | validation: 0.0856210760855778]
	TIME [epoch: 9.77 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10746175728444433		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.10746175728444433 | validation: 0.12705856412366454]
	TIME [epoch: 9.75 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16822061151996517		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.16822061151996517 | validation: 0.18241112792206102]
	TIME [epoch: 9.75 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16665713070224747		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.16665713070224747 | validation: 0.12112123456164443]
	TIME [epoch: 9.77 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12682907288742562		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.12682907288742562 | validation: 0.11525748448422242]
	TIME [epoch: 9.75 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11653208465769342		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.11653208465769342 | validation: 0.10569197835292922]
	TIME [epoch: 9.75 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11152473282817124		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.11152473282817124 | validation: 0.09892614734369602]
	TIME [epoch: 9.76 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10085126128310859		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.10085126128310859 | validation: 0.09074794732446784]
	TIME [epoch: 9.75 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10566072358613621		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.10566072358613621 | validation: 0.08987487539139594]
	TIME [epoch: 9.75 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10364148177445527		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.10364148177445527 | validation: 0.11163831982748662]
	TIME [epoch: 9.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11115524021099628		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.11115524021099628 | validation: 0.10628258212895872]
	TIME [epoch: 9.77 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12435995734828571		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.12435995734828571 | validation: 0.1248699351776521]
	TIME [epoch: 9.75 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14311261385975715		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.14311261385975715 | validation: 0.13175164081125446]
	TIME [epoch: 9.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15514001909615743		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.15514001909615743 | validation: 0.14817442544274706]
	TIME [epoch: 9.76 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14944700075037137		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.14944700075037137 | validation: 0.1321384186859516]
	TIME [epoch: 9.75 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14882257120538736		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.14882257120538736 | validation: 0.1284834862727561]
	TIME [epoch: 9.75 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11494849117018573		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.11494849117018573 | validation: 0.10365367888999334]
	TIME [epoch: 9.75 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.136890221353757		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.136890221353757 | validation: 0.15392762004797855]
	TIME [epoch: 9.77 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13210495910944686		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.13210495910944686 | validation: 0.11325102882614757]
	TIME [epoch: 9.74 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13426260854079208		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.13426260854079208 | validation: 0.13179646279914234]
	TIME [epoch: 9.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14273290947391026		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.14273290947391026 | validation: 0.1467557080030983]
	TIME [epoch: 9.77 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15244947474580725		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.15244947474580725 | validation: 0.10376437294227893]
	TIME [epoch: 9.75 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10695198141734015		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.10695198141734015 | validation: 0.0980393679198665]
	TIME [epoch: 9.75 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0998396677638768		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.0998396677638768 | validation: 0.08824090241918606]
	TIME [epoch: 9.76 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1331934002176014		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.1331934002176014 | validation: 0.1100032915344939]
	TIME [epoch: 9.74 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11346601589895622		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.11346601589895622 | validation: 0.0979791936506789]
	TIME [epoch: 9.74 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1196151809769284		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.1196151809769284 | validation: 0.10895541908688436]
	TIME [epoch: 9.75 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144157311654506		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.1144157311654506 | validation: 0.1184836750218296]
	TIME [epoch: 9.77 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11145386659583707		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.11145386659583707 | validation: 0.0948795257417261]
	TIME [epoch: 9.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10249015197522023		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.10249015197522023 | validation: 0.09139460559749452]
	TIME [epoch: 9.75 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09770193118438641		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.09770193118438641 | validation: 0.10546946837187973]
	TIME [epoch: 9.78 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10553226119388817		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.10553226119388817 | validation: 0.08564570782688082]
	TIME [epoch: 9.75 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10125578723387929		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.10125578723387929 | validation: 0.09235661943742476]
	TIME [epoch: 9.75 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.109723191104977		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.109723191104977 | validation: 0.10717497123996783]
	TIME [epoch: 9.75 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11058469134471345		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.11058469134471345 | validation: 0.10831942985852394]
	TIME [epoch: 9.76 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10212433161985406		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.10212433161985406 | validation: 0.08792274107926586]
	TIME [epoch: 9.75 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11133470656387781		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.11133470656387781 | validation: 0.09511300294565697]
	TIME [epoch: 9.75 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13287216895012155		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.13287216895012155 | validation: 0.12551075532190079]
	TIME [epoch: 9.77 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1437950657166765		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.1437950657166765 | validation: 0.11576443468214162]
	TIME [epoch: 9.75 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.127414621627128		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.127414621627128 | validation: 0.09522713249363753]
	TIME [epoch: 9.75 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10973637398198972		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.10973637398198972 | validation: 0.10239698824035273]
	TIME [epoch: 9.77 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10868607226600543		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.10868607226600543 | validation: 0.09117503938818217]
	TIME [epoch: 9.76 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10687136150842616		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.10687136150842616 | validation: 0.10115620206436632]
	TIME [epoch: 9.75 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10465710181985607		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.10465710181985607 | validation: 0.09003577878808225]
	TIME [epoch: 9.76 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10230083598755654		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.10230083598755654 | validation: 0.10725124306597117]
	TIME [epoch: 9.77 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10022071060702512		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.10022071060702512 | validation: 0.09978336395588713]
	TIME [epoch: 9.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1269238773353441		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.1269238773353441 | validation: 0.09244940224533103]
	TIME [epoch: 9.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11731674167012092		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.11731674167012092 | validation: 0.111855973557346]
	TIME [epoch: 9.77 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11449695664011521		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.11449695664011521 | validation: 0.11714906156515884]
	TIME [epoch: 9.76 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12269501159992627		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.12269501159992627 | validation: 0.10188595714580728]
	TIME [epoch: 9.75 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10374620587856065		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.10374620587856065 | validation: 0.09517067390636605]
	TIME [epoch: 9.77 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11033031870791146		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.11033031870791146 | validation: 0.10412517560484771]
	TIME [epoch: 9.75 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1035488496426759		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.1035488496426759 | validation: 0.08328060678304589]
	TIME [epoch: 9.76 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10551891617022044		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.10551891617022044 | validation: 0.12065132694118827]
	TIME [epoch: 9.75 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11603924607848111		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.11603924607848111 | validation: 0.10421939517094224]
	TIME [epoch: 9.78 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09657592146850094		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.09657592146850094 | validation: 0.0858077183494586]
	TIME [epoch: 9.75 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12035216005771088		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.12035216005771088 | validation: 0.09668648261435386]
	TIME [epoch: 9.75 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10538906478850552		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.10538906478850552 | validation: 0.09679170806834878]
	TIME [epoch: 9.77 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10903498012964334		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.10903498012964334 | validation: 0.10589540243664444]
	TIME [epoch: 9.75 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11115758538006952		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.11115758538006952 | validation: 0.09211573608000684]
	TIME [epoch: 9.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1060438527591118		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.1060438527591118 | validation: 0.08907150978644005]
	TIME [epoch: 9.76 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1261571041917636		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.1261571041917636 | validation: 0.11785203168652231]
	TIME [epoch: 9.77 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12813519485231445		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.12813519485231445 | validation: 0.1027333290984004]
	TIME [epoch: 9.75 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.132079052473339		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.132079052473339 | validation: 0.0952269622365671]
	TIME [epoch: 9.75 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10841628961856471		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.10841628961856471 | validation: 0.11272465679738977]
	TIME [epoch: 9.77 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1186795316465212		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.1186795316465212 | validation: 0.10663619926486888]
	TIME [epoch: 9.75 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13648631078078804		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.13648631078078804 | validation: 0.10812276813064511]
	TIME [epoch: 9.75 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12031849160323005		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.12031849160323005 | validation: 0.09615448805861888]
	TIME [epoch: 9.76 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11692672389371742		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.11692672389371742 | validation: 0.08454815968519132]
	TIME [epoch: 9.75 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1130394726618806		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.1130394726618806 | validation: 0.111254533397309]
	TIME [epoch: 9.75 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11975923295921102		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.11975923295921102 | validation: 0.11975898948475226]
	TIME [epoch: 9.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11401738976293836		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.11401738976293836 | validation: 0.10343631765234065]
	TIME [epoch: 9.77 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1099717915508884		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.1099717915508884 | validation: 0.10253035763464219]
	TIME [epoch: 9.75 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10810231847050085		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.10810231847050085 | validation: 0.09718334365933753]
	TIME [epoch: 9.75 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11629261371054948		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.11629261371054948 | validation: 0.09775205630327514]
	TIME [epoch: 9.76 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12525530227801346		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.12525530227801346 | validation: 0.10109820976909237]
	TIME [epoch: 9.75 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1117876261333679		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.1117876261333679 | validation: 0.09826548385887166]
	TIME [epoch: 9.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12087917384092028		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.12087917384092028 | validation: 0.13798389104187267]
	TIME [epoch: 9.74 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11866758684548884		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.11866758684548884 | validation: 0.09528892141338764]
	TIME [epoch: 9.76 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11202001835180268		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.11202001835180268 | validation: 0.10383039524997031]
	TIME [epoch: 9.75 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1187197593894422		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.1187197593894422 | validation: 0.09665419466709617]
	TIME [epoch: 9.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11561246719216903		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.11561246719216903 | validation: 0.09654188039710132]
	TIME [epoch: 9.77 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11796822843200472		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.11796822843200472 | validation: 0.10256091181985781]
	TIME [epoch: 9.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12119728799397052		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.12119728799397052 | validation: 0.1193342154991792]
	TIME [epoch: 9.74 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11723041668074856		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.11723041668074856 | validation: 0.11309570710523367]
	TIME [epoch: 9.76 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11278446535760156		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.11278446535760156 | validation: 0.09661961003494508]
	TIME [epoch: 9.75 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12615733227974135		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.12615733227974135 | validation: 0.13915122381297276]
	TIME [epoch: 9.75 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11571595094200479		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.11571595094200479 | validation: 0.09405184075326316]
	TIME [epoch: 9.75 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10986872327139677		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.10986872327139677 | validation: 0.09689914127562149]
	TIME [epoch: 9.76 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11698024955187454		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.11698024955187454 | validation: 0.07756992214750438]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1601.pth
	Model improved!!!
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10369819593324325		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.10369819593324325 | validation: 0.08770017407071226]
	TIME [epoch: 9.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10583267164800594		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.10583267164800594 | validation: 0.10147107624545398]
	TIME [epoch: 9.77 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11201673136241755		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.11201673136241755 | validation: 0.09425843497083598]
	TIME [epoch: 9.75 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166509717539815		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.1166509717539815 | validation: 0.10510868354541973]
	TIME [epoch: 9.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10921665129842228		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.10921665129842228 | validation: 0.08702345766868805]
	TIME [epoch: 9.76 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0970825665700764		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.0970825665700764 | validation: 0.08516926445368149]
	TIME [epoch: 9.76 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10303404396959655		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.10303404396959655 | validation: 0.08183145400032243]
	TIME [epoch: 9.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09535315859418185		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.09535315859418185 | validation: 0.07783136272935738]
	TIME [epoch: 9.74 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09883117161734772		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.09883117161734772 | validation: 0.08518361746490846]
	TIME [epoch: 9.77 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10070584478497926		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.10070584478497926 | validation: 0.08724385095367389]
	TIME [epoch: 9.75 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10504811892370676		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.10504811892370676 | validation: 0.08673758658650227]
	TIME [epoch: 9.74 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11205955535849206		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.11205955535849206 | validation: 0.11284197975928954]
	TIME [epoch: 9.77 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1392317093703372		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.1392317093703372 | validation: 0.12461979895241461]
	TIME [epoch: 9.75 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14146160566509808		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.14146160566509808 | validation: 0.10974603912275976]
	TIME [epoch: 9.75 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12398872631817164		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.12398872631817164 | validation: 0.07552875457184749]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1616.pth
	Model improved!!!
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10756611320727716		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.10756611320727716 | validation: 0.08638810986581472]
	TIME [epoch: 9.77 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10759597184587937		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.10759597184587937 | validation: 0.11153857041262122]
	TIME [epoch: 9.75 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10902568489280504		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.10902568489280504 | validation: 0.08488978890966205]
	TIME [epoch: 9.75 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946985768062545		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.10946985768062545 | validation: 0.07691395415474282]
	TIME [epoch: 9.77 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10132513335752402		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.10132513335752402 | validation: 0.08839599538730099]
	TIME [epoch: 9.76 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10662315187371148		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.10662315187371148 | validation: 0.08833015476762186]
	TIME [epoch: 9.75 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034889548697292		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.1034889548697292 | validation: 0.08731496789863984]
	TIME [epoch: 9.77 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09457534690109429		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.09457534690109429 | validation: 0.09186789900037645]
	TIME [epoch: 9.75 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09714593778467215		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.09714593778467215 | validation: 0.08890431785777639]
	TIME [epoch: 9.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1080101698991267		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.1080101698991267 | validation: 0.07163228399355888]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1626.pth
	Model improved!!!
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1036017290839043		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.1036017290839043 | validation: 0.09551239886748096]
	TIME [epoch: 9.76 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10173857103468278		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.10173857103468278 | validation: 0.10238599415639449]
	TIME [epoch: 9.75 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11743128804803224		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.11743128804803224 | validation: 0.09275399506364934]
	TIME [epoch: 9.75 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11158813291885732		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.11158813291885732 | validation: 0.09932362026781241]
	TIME [epoch: 9.76 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11945117594048527		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.11945117594048527 | validation: 0.09602926124270278]
	TIME [epoch: 9.75 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11457243217472908		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.11457243217472908 | validation: 0.09388097011262157]
	TIME [epoch: 9.74 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10415295596738776		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.10415295596738776 | validation: 0.10704331601915865]
	TIME [epoch: 9.77 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11863584801579888		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.11863584801579888 | validation: 0.10352194916836059]
	TIME [epoch: 9.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11030056767126531		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.11030056767126531 | validation: 0.08395946628468708]
	TIME [epoch: 9.74 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10144001644274951		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.10144001644274951 | validation: 0.09649730341694135]
	TIME [epoch: 9.75 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10829595240036675		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.10829595240036675 | validation: 0.10002977616173274]
	TIME [epoch: 9.78 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10164326642216599		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.10164326642216599 | validation: 0.09014647680153731]
	TIME [epoch: 9.75 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10489977068485383		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.10489977068485383 | validation: 0.08676298438732648]
	TIME [epoch: 9.75 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11117343024932735		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.11117343024932735 | validation: 0.11423062405677965]
	TIME [epoch: 9.76 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10570159619308331		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.10570159619308331 | validation: 0.10005934823148563]
	TIME [epoch: 9.75 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1118984403781322		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.1118984403781322 | validation: 0.101542730583172]
	TIME [epoch: 9.75 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1381238534900916		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.1381238534900916 | validation: 0.12290049763981431]
	TIME [epoch: 9.75 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11620147593534069		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.11620147593534069 | validation: 0.10022110827317014]
	TIME [epoch: 9.76 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10163117102882455		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.10163117102882455 | validation: 0.09590136385197007]
	TIME [epoch: 9.75 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11864364807005526		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.11864364807005526 | validation: 0.10917902735732565]
	TIME [epoch: 9.75 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379698150112304		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.1379698150112304 | validation: 0.15069333713151042]
	TIME [epoch: 9.77 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1473504583759539		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.1473504583759539 | validation: 0.12683170746235306]
	TIME [epoch: 9.75 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1153641631772486		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.1153641631772486 | validation: 0.09874143641420263]
	TIME [epoch: 9.75 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10608373311197199		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.10608373311197199 | validation: 0.10526808941886316]
	TIME [epoch: 9.76 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10243993813116443		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.10243993813116443 | validation: 0.08145037117234921]
	TIME [epoch: 9.75 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09849340942766614		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.09849340942766614 | validation: 0.1114875204049233]
	TIME [epoch: 9.75 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1033154021608075		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.1033154021608075 | validation: 0.10189481178024883]
	TIME [epoch: 9.76 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10408471717501322		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.10408471717501322 | validation: 0.07492297635889635]
	TIME [epoch: 9.76 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09485963649927659		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.09485963649927659 | validation: 0.09959581692081944]
	TIME [epoch: 9.75 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1122022837080104		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.1122022837080104 | validation: 0.1054780992915697]
	TIME [epoch: 9.75 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11733988055190103		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.11733988055190103 | validation: 0.09287221872282991]
	TIME [epoch: 9.77 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11443899582481029		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.11443899582481029 | validation: 0.08851560811427263]
	TIME [epoch: 9.75 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10234234808722695		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.10234234808722695 | validation: 0.07688125884688275]
	TIME [epoch: 9.75 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09985066612854532		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.09985066612854532 | validation: 0.0950287249782926]
	TIME [epoch: 9.76 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11008063936847128		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.11008063936847128 | validation: 0.09388279129454574]
	TIME [epoch: 9.75 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1090033736228978		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.1090033736228978 | validation: 0.098052484474398]
	TIME [epoch: 9.75 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09881050540487461		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.09881050540487461 | validation: 0.08501256604620633]
	TIME [epoch: 9.74 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10016118667729897		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.10016118667729897 | validation: 0.11947005503842893]
	TIME [epoch: 9.77 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09702882195626603		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.09702882195626603 | validation: 0.09479104609566247]
	TIME [epoch: 9.75 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1027955573452295		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.1027955573452295 | validation: 0.09442352669540548]
	TIME [epoch: 9.75 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10226961254428905		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.10226961254428905 | validation: 0.08681773185650314]
	TIME [epoch: 9.76 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11193748497620544		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.11193748497620544 | validation: 0.0927360489477305]
	TIME [epoch: 9.76 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10780536498429191		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.10780536498429191 | validation: 0.09775702470879408]
	TIME [epoch: 9.75 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10871020743571273		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.10871020743571273 | validation: 0.09020896611046826]
	TIME [epoch: 9.75 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11033220888230252		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.11033220888230252 | validation: 0.06873826644351932]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1671.pth
	Model improved!!!
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09558162449135842		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.09558162449135842 | validation: 0.0992246215550097]
	TIME [epoch: 9.76 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10363827219247082		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.10363827219247082 | validation: 0.09595214967204344]
	TIME [epoch: 9.75 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10689687438016685		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.10689687438016685 | validation: 0.08477440793808633]
	TIME [epoch: 9.78 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09568907495392587		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.09568907495392587 | validation: 0.09936272414962347]
	TIME [epoch: 9.76 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09699602591658767		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.09699602591658767 | validation: 0.09418529156356746]
	TIME [epoch: 9.76 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11461520174616684		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.11461520174616684 | validation: 0.11714484039190824]
	TIME [epoch: 9.78 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11846977714099652		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.11846977714099652 | validation: 0.1679033226575396]
	TIME [epoch: 9.76 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379141276402159		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.1379141276402159 | validation: 0.11841191220644408]
	TIME [epoch: 9.75 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1181672711240773		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.1181672711240773 | validation: 0.12109866688684456]
	TIME [epoch: 9.75 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12734359176977758		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.12734359176977758 | validation: 0.11903107776264861]
	TIME [epoch: 9.78 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342553755243211		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.1342553755243211 | validation: 0.11384527222309371]
	TIME [epoch: 9.75 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12629258930481224		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.12629258930481224 | validation: 0.12083570717192746]
	TIME [epoch: 9.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12868009081345022		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.12868009081345022 | validation: 0.10856333889464076]
	TIME [epoch: 9.77 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11361960686423471		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.11361960686423471 | validation: 0.11118312122081613]
	TIME [epoch: 9.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1113669036415454		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.1113669036415454 | validation: 0.07996934358226201]
	TIME [epoch: 9.75 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09618661175922445		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.09618661175922445 | validation: 0.07520569333868388]
	TIME [epoch: 9.75 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09839929675107764		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.09839929675107764 | validation: 0.09508196677253974]
	TIME [epoch: 9.76 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09304416036335347		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.09304416036335347 | validation: 0.09908407756030592]
	TIME [epoch: 9.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09368159713061205		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.09368159713061205 | validation: 0.08359365567842857]
	TIME [epoch: 9.75 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10330894661551708		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.10330894661551708 | validation: 0.09795019012893529]
	TIME [epoch: 9.76 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0991110665340794		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.0991110665340794 | validation: 0.07928228736216031]
	TIME [epoch: 9.75 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10109478452051317		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.10109478452051317 | validation: 0.11205873353838774]
	TIME [epoch: 9.75 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10054575719239116		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.10054575719239116 | validation: 0.07763843970503376]
	TIME [epoch: 9.77 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09801972827510111		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.09801972827510111 | validation: 0.09115407785004585]
	TIME [epoch: 9.76 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09819180934643475		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.09819180934643475 | validation: 0.08455791565878769]
	TIME [epoch: 9.75 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09508295900357613		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.09508295900357613 | validation: 0.07944555346117499]
	TIME [epoch: 9.75 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09495405919086511		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.09495405919086511 | validation: 0.08861037030851904]
	TIME [epoch: 9.76 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10877973278986297		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.10877973278986297 | validation: 0.11029018229426456]
	TIME [epoch: 9.75 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10791368389566132		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.10791368389566132 | validation: 0.08664888421519137]
	TIME [epoch: 9.75 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1008619782790156		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.1008619782790156 | validation: 0.08807696201066229]
	TIME [epoch: 9.77 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09428408984587797		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.09428408984587797 | validation: 0.0750777308606404]
	TIME [epoch: 9.75 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09854285022848153		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.09854285022848153 | validation: 0.06955985921092563]
	TIME [epoch: 9.75 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10254322222936425		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.10254322222936425 | validation: 0.0840603723234829]
	TIME [epoch: 9.76 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10047535434511423		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.10047535434511423 | validation: 0.09123691127944022]
	TIME [epoch: 9.76 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09443668778272918		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.09443668778272918 | validation: 0.09491725496447995]
	TIME [epoch: 9.75 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287045482919727		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.09287045482919727 | validation: 0.08154749333060954]
	TIME [epoch: 9.75 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1004687118141904		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.1004687118141904 | validation: 0.09165789244450213]
	TIME [epoch: 9.77 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10039612263548439		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.10039612263548439 | validation: 0.09518360947151752]
	TIME [epoch: 9.75 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10624140722840947		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.10624140722840947 | validation: 0.08822349305520888]
	TIME [epoch: 9.75 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1012802179572185		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.1012802179572185 | validation: 0.07953418213516636]
	TIME [epoch: 9.78 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09357987657871776		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.09357987657871776 | validation: 0.09989466016666264]
	TIME [epoch: 9.75 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10992603343655243		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.10992603343655243 | validation: 0.11158492130041485]
	TIME [epoch: 9.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.117465588365034		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.117465588365034 | validation: 0.08266941164174568]
	TIME [epoch: 9.76 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09670991346992411		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.09670991346992411 | validation: 0.07720133781768732]
	TIME [epoch: 9.77 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793367109112463		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.08793367109112463 | validation: 0.09440958399507132]
	TIME [epoch: 9.76 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11848113366930202		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.11848113366930202 | validation: 0.10589773530591956]
	TIME [epoch: 9.75 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12304864982857681		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.12304864982857681 | validation: 0.0996778261325848]
	TIME [epoch: 9.77 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10199628831702001		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.10199628831702001 | validation: 0.07963973748827019]
	TIME [epoch: 9.75 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10502613992934248		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.10502613992934248 | validation: 0.0978567957791534]
	TIME [epoch: 9.75 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10576336594216869		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.10576336594216869 | validation: 0.07906714594829332]
	TIME [epoch: 9.77 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09004942843782686		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.09004942843782686 | validation: 0.09193926446576364]
	TIME [epoch: 9.76 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09291088471145703		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.09291088471145703 | validation: 0.08037452137426901]
	TIME [epoch: 9.75 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09396807619199177		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.09396807619199177 | validation: 0.09162088862496788]
	TIME [epoch: 9.75 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09673338553080295		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.09673338553080295 | validation: 0.09298973793214767]
	TIME [epoch: 9.77 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09714978177103217		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.09714978177103217 | validation: 0.08684432628911687]
	TIME [epoch: 9.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09426246114798312		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.09426246114798312 | validation: 0.07875374553885413]
	TIME [epoch: 9.75 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10030584297482652		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.10030584297482652 | validation: 0.08883424904846379]
	TIME [epoch: 9.77 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0985860828033193		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.0985860828033193 | validation: 0.08721940339790914]
	TIME [epoch: 9.75 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.093099965260216		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.093099965260216 | validation: 0.08783410721943924]
	TIME [epoch: 9.76 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09305352395533018		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.09305352395533018 | validation: 0.09019575678217655]
	TIME [epoch: 9.77 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09612158223722285		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.09612158223722285 | validation: 0.0823161835577799]
	TIME [epoch: 9.75 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09149726271729243		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.09149726271729243 | validation: 0.08450477929925099]
	TIME [epoch: 9.75 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09507068502512017		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.09507068502512017 | validation: 0.08766128570790777]
	TIME [epoch: 9.75 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09560265833402562		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.09560265833402562 | validation: 0.08446234649214353]
	TIME [epoch: 9.78 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10030574477228624		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.10030574477228624 | validation: 0.08800154287838438]
	TIME [epoch: 9.75 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0990505416898536		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.0990505416898536 | validation: 0.08894409005389196]
	TIME [epoch: 9.76 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09706876629907181		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.09706876629907181 | validation: 0.08233871247336659]
	TIME [epoch: 9.76 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09633252784769471		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.09633252784769471 | validation: 0.08202371202950869]
	TIME [epoch: 9.76 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11155611367304186		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.11155611367304186 | validation: 0.09529957001151111]
	TIME [epoch: 9.75 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11498504020045294		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.11498504020045294 | validation: 0.08245878116194547]
	TIME [epoch: 9.75 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10797993473258352		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.10797993473258352 | validation: 0.09874753880728537]
	TIME [epoch: 9.77 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09370587508905089		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.09370587508905089 | validation: 0.08346970246423574]
	TIME [epoch: 9.76 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09960957471334973		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.09960957471334973 | validation: 0.0907143483097062]
	TIME [epoch: 9.75 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09246917693036412		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.09246917693036412 | validation: 0.07153314391392696]
	TIME [epoch: 9.77 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09411989772437791		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.09411989772437791 | validation: 0.09482412568969731]
	TIME [epoch: 9.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10203626294741056		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.10203626294741056 | validation: 0.08383279902541772]
	TIME [epoch: 9.75 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11432166880996633		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.11432166880996633 | validation: 0.09683638278078917]
	TIME [epoch: 9.76 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946728731467378		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.10946728731467378 | validation: 0.0720281065260364]
	TIME [epoch: 9.76 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09684731522298244		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.09684731522298244 | validation: 0.0787121827223344]
	TIME [epoch: 9.75 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09383628302146525		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.09383628302146525 | validation: 0.08783356917125612]
	TIME [epoch: 9.75 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1003723473522059		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.1003723473522059 | validation: 0.09063207518220537]
	TIME [epoch: 9.77 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11443021787366503		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.11443021787366503 | validation: 0.1013812785164237]
	TIME [epoch: 9.75 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1091669560870346		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.1091669560870346 | validation: 0.09733417529709097]
	TIME [epoch: 9.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11603149448929925		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.11603149448929925 | validation: 0.13302064312305686]
	TIME [epoch: 9.77 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.127810414388625		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.127810414388625 | validation: 0.12365654069880443]
	TIME [epoch: 9.75 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11289389718902372		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.11289389718902372 | validation: 0.1003602279118106]
	TIME [epoch: 9.75 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10823337257249241		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.10823337257249241 | validation: 0.09934492426682164]
	TIME [epoch: 9.75 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10406490183832026		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.10406490183832026 | validation: 0.09916466167006593]
	TIME [epoch: 9.78 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11411928235712628		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.11411928235712628 | validation: 0.08691819616141036]
	TIME [epoch: 9.75 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09924140653580249		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.09924140653580249 | validation: 0.0999730982156932]
	TIME [epoch: 9.75 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09546859150034848		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.09546859150034848 | validation: 0.10253769404483908]
	TIME [epoch: 9.78 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10079048080132606		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.10079048080132606 | validation: 0.10301398254732362]
	TIME [epoch: 9.76 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1035060471355922		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.1035060471355922 | validation: 0.0984596993915126]
	TIME [epoch: 9.75 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08910077612901197		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.08910077612901197 | validation: 0.09481346861125779]
	TIME [epoch: 9.77 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09576310499721256		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.09576310499721256 | validation: 0.0876221845394928]
	TIME [epoch: 9.75 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09260068474483839		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.09260068474483839 | validation: 0.10394824129467481]
	TIME [epoch: 9.75 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10816686215307818		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.10816686215307818 | validation: 0.10925553100331982]
	TIME [epoch: 9.75 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10144737737001892		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.10144737737001892 | validation: 0.09885051033381032]
	TIME [epoch: 9.77 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09761396513959102		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.09761396513959102 | validation: 0.09354264674599196]
	TIME [epoch: 9.75 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0951996485014587		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.0951996485014587 | validation: 0.08580355510897629]
	TIME [epoch: 9.75 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09571939486451418		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.09571939486451418 | validation: 0.08866298972952817]
	TIME [epoch: 9.77 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1003805599419862		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.1003805599419862 | validation: 0.08701697927031608]
	TIME [epoch: 9.75 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09288524020786763		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.09288524020786763 | validation: 0.07645866382041269]
	TIME [epoch: 9.75 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09360739153827893		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.09360739153827893 | validation: 0.07609771726441412]
	TIME [epoch: 9.77 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08995944336624843		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.08995944336624843 | validation: 0.07830114433111589]
	TIME [epoch: 9.79 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09515683212372594		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.09515683212372594 | validation: 0.08684638109947253]
	TIME [epoch: 9.75 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09453263463238545		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.09453263463238545 | validation: 0.07908481720849324]
	TIME [epoch: 9.75 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08506072480207207		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.08506072480207207 | validation: 0.06555697736471322]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240219_184940/states/model_tr_study6_1779.pth
	Model improved!!!
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09039035263930344		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.09039035263930344 | validation: 0.0818556079726038]
	TIME [epoch: 9.76 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08478793792185632		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.08478793792185632 | validation: 0.0992382655624978]
	TIME [epoch: 9.75 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09536063197091622		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.09536063197091622 | validation: 0.0699707271729819]
	TIME [epoch: 9.77 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09638866800263199		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.09638866800263199 | validation: 0.0901332717669417]
	TIME [epoch: 9.76 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10275130568413784		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.10275130568413784 | validation: 0.09840377052223538]
	TIME [epoch: 9.75 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1134225322830136		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.1134225322830136 | validation: 0.10272720338642882]
	TIME [epoch: 9.76 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10518201980667281		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.10518201980667281 | validation: 0.08248785104898543]
	TIME [epoch: 9.76 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08935111035624801		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.08935111035624801 | validation: 0.08272116485072943]
	TIME [epoch: 9.75 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09353016694872196		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.09353016694872196 | validation: 0.08498784676273534]
	TIME [epoch: 9.75 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09532466026253492		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.09532466026253492 | validation: 0.07419839714087335]
	TIME [epoch: 9.78 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09107841732305522		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.09107841732305522 | validation: 0.09172003647209107]
	TIME [epoch: 9.75 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08953702894330633		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.08953702894330633 | validation: 0.07893198949492687]
	TIME [epoch: 9.75 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092020361391812		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.092020361391812 | validation: 0.07893320862136813]
	TIME [epoch: 9.77 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09404039231290802		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.09404039231290802 | validation: 0.10444541887328748]
	TIME [epoch: 9.75 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09854548390713028		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.09854548390713028 | validation: 0.09282264935441806]
	TIME [epoch: 9.75 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09655565668693802		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.09655565668693802 | validation: 0.09570702909544382]
	TIME [epoch: 9.75 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08954099090282239		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.08954099090282239 | validation: 0.08088629377040539]
	TIME [epoch: 9.77 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10910263198319274		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.10910263198319274 | validation: 0.12227721745885294]
	TIME [epoch: 9.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10429411250708878		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.10429411250708878 | validation: 0.0874729472816241]
	TIME [epoch: 9.75 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09757203779787402		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.09757203779787402 | validation: 0.08346592401432633]
	TIME [epoch: 9.76 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09849126201862564		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.09849126201862564 | validation: 0.09422062026120355]
	TIME [epoch: 9.75 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10581106691658508		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.10581106691658508 | validation: 0.12357706362261314]
	TIME [epoch: 9.75 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10819260518942045		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.10819260518942045 | validation: 0.08253319738522669]
	TIME [epoch: 9.76 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0957197258159245		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.0957197258159245 | validation: 0.10236778151413428]
	TIME [epoch: 9.75 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10194321423814087		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.10194321423814087 | validation: 0.10613575070895312]
	TIME [epoch: 9.75 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10059259763475455		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.10059259763475455 | validation: 0.11013243472841232]
	TIME [epoch: 9.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11001221626315413		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.11001221626315413 | validation: 0.10923296646316305]
	TIME [epoch: 9.76 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10654509451496075		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.10654509451496075 | validation: 0.10121494475160954]
	TIME [epoch: 9.75 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11191133212751578		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.11191133212751578 | validation: 0.09280447830282249]
	TIME [epoch: 9.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09580369341760797		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.09580369341760797 | validation: 0.09546062291093291]
	TIME [epoch: 9.76 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09758915721234832		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.09758915721234832 | validation: 0.08182747724794466]
	TIME [epoch: 9.74 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.087592883728872		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.087592883728872 | validation: 0.08940621139877865]
	TIME [epoch: 9.75 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0990824498235765		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.0990824498235765 | validation: 0.09152214020711157]
	TIME [epoch: 9.76 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0933878277756803		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.0933878277756803 | validation: 0.09387711515534183]
	TIME [epoch: 9.76 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09962590283498685		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.09962590283498685 | validation: 0.09449938323141009]
	TIME [epoch: 9.74 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09616774799486524		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.09616774799486524 | validation: 0.07239957789587863]
	TIME [epoch: 9.74 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08988658633839808		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.08988658633839808 | validation: 0.08395311924366898]
	TIME [epoch: 9.76 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09629357538818815		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.09629357538818815 | validation: 0.09059825061479476]
	TIME [epoch: 9.75 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09659657385390719		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.09659657385390719 | validation: 0.100351596374393]
	TIME [epoch: 9.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09923220035046583		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.09923220035046583 | validation: 0.09472588463595912]
	TIME [epoch: 9.75 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09536130060759651		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.09536130060759651 | validation: 0.10610966886176712]
	TIME [epoch: 9.75 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08958874395329723		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.08958874395329723 | validation: 0.09424255737873725]
	TIME [epoch: 9.74 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10383795024351379		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.10383795024351379 | validation: 0.07767804871397777]
	TIME [epoch: 9.75 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09718665102452785		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.09718665102452785 | validation: 0.08528691200756948]
	TIME [epoch: 9.77 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0908744316355497		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.0908744316355497 | validation: 0.07664621097558554]
	TIME [epoch: 9.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09483595708517115		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.09483595708517115 | validation: 0.08336533133133892]
	TIME [epoch: 9.75 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09505847564368217		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.09505847564368217 | validation: 0.08731716200361245]
	TIME [epoch: 9.77 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09234755708118055		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.09234755708118055 | validation: 0.08630985826695634]
	TIME [epoch: 9.75 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09420907977732518		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.09420907977732518 | validation: 0.07840237360299496]
	TIME [epoch: 9.75 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09193324964149825		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.09193324964149825 | validation: 0.06892155664958281]
	TIME [epoch: 9.75 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09116964975400424		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.09116964975400424 | validation: 0.07754402996705288]
	TIME [epoch: 9.76 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09463370845467221		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.09463370845467221 | validation: 0.09190919697552602]
	TIME [epoch: 9.74 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09384141179374647		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.09384141179374647 | validation: 0.0867296497201182]
	TIME [epoch: 9.74 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870589503705684		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.0870589503705684 | validation: 0.08095903161073208]
	TIME [epoch: 9.76 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09281783538524771		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.09281783538524771 | validation: 0.09157770777944674]
	TIME [epoch: 9.75 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0928239822668179		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.0928239822668179 | validation: 0.08024688486567826]
	TIME [epoch: 9.74 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09514819434151128		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.09514819434151128 | validation: 0.0935793198172733]
	TIME [epoch: 9.76 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0997518162477024		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.0997518162477024 | validation: 0.08816913380896614]
	TIME [epoch: 9.75 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11602303637337301		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.11602303637337301 | validation: 0.09404329944129508]
	TIME [epoch: 9.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10358669115040076		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.10358669115040076 | validation: 0.08308303088201054]
	TIME [epoch: 9.75 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09179665599710377		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.09179665599710377 | validation: 0.08480254281113585]
	TIME [epoch: 9.76 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09504137090638712		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.09504137090638712 | validation: 0.06720458405840098]
	TIME [epoch: 9.75 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09430722700239083		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.09430722700239083 | validation: 0.08894458161388254]
	TIME [epoch: 9.75 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09932012759717788		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.09932012759717788 | validation: 0.09548074544573996]
	TIME [epoch: 9.77 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09763856658140624		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.09763856658140624 | validation: 0.08544359444326606]
	TIME [epoch: 9.75 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09050493655262877		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.09050493655262877 | validation: 0.0923749065602899]
	TIME [epoch: 9.75 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08865902558646745		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.08865902558646745 | validation: 0.08105378868904616]
	TIME [epoch: 9.75 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10630260727408262		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.10630260727408262 | validation: 0.09393637940836999]
	TIME [epoch: 9.76 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11592423576350283		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.11592423576350283 | validation: 0.10732948839262925]
	TIME [epoch: 9.75 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10447680090402296		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.10447680090402296 | validation: 0.08004287009630436]
	TIME [epoch: 9.75 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09208297931711248		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.09208297931711248 | validation: 0.07922278013973956]
	TIME [epoch: 9.77 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11038712457863076		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.11038712457863076 | validation: 0.09836461922254712]
	TIME [epoch: 9.75 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1319588385253812		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.1319588385253812 | validation: 0.10222331286859591]
	TIME [epoch: 9.76 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11625180968309927		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.11625180968309927 | validation: 0.0976354687305051]
	TIME [epoch: 9.77 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1161796494015307		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.1161796494015307 | validation: 0.08935468707007488]
	TIME [epoch: 9.76 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12080058873251198		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.12080058873251198 | validation: 0.10477537576623165]
	TIME [epoch: 9.76 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12757474316242376		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.12757474316242376 | validation: 0.13959890600276262]
	TIME [epoch: 9.76 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15535251074103223		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.15535251074103223 | validation: 0.13152624249776987]
	TIME [epoch: 9.77 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14384751125490394		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.14384751125490394 | validation: 0.10692521320075471]
	TIME [epoch: 9.75 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1176003206134261		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.1176003206134261 | validation: 0.09266074442159818]
	TIME [epoch: 9.75 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102044119396006		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.102044119396006 | validation: 0.09830297019869942]
	TIME [epoch: 9.77 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12128802789901987		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.12128802789901987 | validation: 0.09378699380275198]
	TIME [epoch: 9.75 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13792117253658082		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.13792117253658082 | validation: 0.10125690921445812]
	TIME [epoch: 9.75 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12159421041628407		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.12159421041628407 | validation: 0.09791498313096149]
	TIME [epoch: 9.78 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12109903019116805		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.12109903019116805 | validation: 0.09331433911114864]
	TIME [epoch: 9.76 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10786299133481787		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.10786299133481787 | validation: 0.08798200436797736]
	TIME [epoch: 9.76 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09864286378513701		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.09864286378513701 | validation: 0.09130028238095453]
	TIME [epoch: 9.75 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10510332961168427		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.10510332961168427 | validation: 0.07888198827848075]
	TIME [epoch: 9.79 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10109044244062577		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.10109044244062577 | validation: 0.10165440540026607]
	TIME [epoch: 9.75 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09821396690731403		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.09821396690731403 | validation: 0.08949624404862998]
	TIME [epoch: 9.76 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10059294111048003		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.10059294111048003 | validation: 0.09501894392252011]
	TIME [epoch: 9.77 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10772074847190734		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.10772074847190734 | validation: 0.10869549121947375]
	TIME [epoch: 9.75 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12292999664514859		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.12292999664514859 | validation: 0.09829920213992843]
	TIME [epoch: 9.75 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09953101210284086		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.09953101210284086 | validation: 0.08596412220302951]
	TIME [epoch: 9.76 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09118582947434321		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.09118582947434321 | validation: 0.09494228669297265]
	TIME [epoch: 9.77 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10525607969188981		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.10525607969188981 | validation: 0.09495888982368142]
	TIME [epoch: 9.75 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1123422210056235		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.1123422210056235 | validation: 0.09261540738838565]
	TIME [epoch: 9.74 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11539388731204643		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.11539388731204643 | validation: 0.10738063300612848]
	TIME [epoch: 9.78 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10858965625692858		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.10858965625692858 | validation: 0.08789926461029816]
	TIME [epoch: 9.75 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09352056614404883		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.09352056614404883 | validation: 0.08062655596445747]
	TIME [epoch: 9.75 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105374758012981		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.09105374758012981 | validation: 0.0676094344817194]
	TIME [epoch: 9.76 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09328976035526029		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.09328976035526029 | validation: 0.09347624526097478]
	TIME [epoch: 9.75 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09750518412969951		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.09750518412969951 | validation: 0.08039520696805934]
	TIME [epoch: 9.74 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10182188457075798		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.10182188457075798 | validation: 0.09378088143118184]
	TIME [epoch: 9.75 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.099147829626133		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.099147829626133 | validation: 0.09210224270417061]
	TIME [epoch: 9.76 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0906332057807101		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.0906332057807101 | validation: 0.08294852787819793]
	TIME [epoch: 9.75 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08774721364053706		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.08774721364053706 | validation: 0.07138617643182413]
	TIME [epoch: 9.74 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09167602543393441		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.09167602543393441 | validation: 0.09615697240347953]
	TIME [epoch: 9.77 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08959360157020217		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.08959360157020217 | validation: 0.0911533432759938]
	TIME [epoch: 9.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1021209332602766		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.1021209332602766 | validation: 0.08256800331942611]
	TIME [epoch: 9.75 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.111743808542288		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.111743808542288 | validation: 0.08547409494933968]
	TIME [epoch: 9.76 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12426326124683502		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.12426326124683502 | validation: 0.10995690636631845]
	TIME [epoch: 9.75 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1090944041001947		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.1090944041001947 | validation: 0.07604514224811044]
	TIME [epoch: 9.75 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09637941445012853		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.09637941445012853 | validation: 0.08213176830893079]
	TIME [epoch: 9.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0956299865202997		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.0956299865202997 | validation: 0.09992879690838923]
	TIME [epoch: 9.77 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09699838449579619		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.09699838449579619 | validation: 0.08338348183405896]
	TIME [epoch: 9.74 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09543261809919948		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.09543261809919948 | validation: 0.09211341094639142]
	TIME [epoch: 9.75 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09160831533270325		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.09160831533270325 | validation: 0.09632876026736024]
	TIME [epoch: 9.77 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09662155184858853		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.09662155184858853 | validation: 0.09258688347959507]
	TIME [epoch: 9.75 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10858740315629953		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.10858740315629953 | validation: 0.11265138147386468]
	TIME [epoch: 9.75 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12490556043879135		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.12490556043879135 | validation: 0.0929833246388329]
	TIME [epoch: 9.75 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10318747412690674		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.10318747412690674 | validation: 0.08751654548278745]
	TIME [epoch: 9.76 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09508399199230384		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.09508399199230384 | validation: 0.09454362408308811]
	TIME [epoch: 9.75 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09878278672913277		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.09878278672913277 | validation: 0.07742400630332967]
	TIME [epoch: 9.75 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09225577272066791		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.09225577272066791 | validation: 0.0761554158097214]
	TIME [epoch: 9.77 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09101185643577758		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.09101185643577758 | validation: 0.08383730267189878]
	TIME [epoch: 9.75 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08864914072521171		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.08864914072521171 | validation: 0.09039457792697451]
	TIME [epoch: 9.74 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.085847934413395		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.085847934413395 | validation: 0.09017468007252843]
	TIME [epoch: 9.76 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09468412108780115		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.09468412108780115 | validation: 0.11100394432012571]
	TIME [epoch: 9.75 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10094384835149847		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.10094384835149847 | validation: 0.08128671036911093]
	TIME [epoch: 9.75 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10051695929433872		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.10051695929433872 | validation: 0.08682723125461403]
	TIME [epoch: 9.74 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08880504695124261		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.08880504695124261 | validation: 0.09220812092669936]
	TIME [epoch: 9.77 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092954343111324		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.092954343111324 | validation: 0.07947278909305779]
	TIME [epoch: 9.74 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09071813268983613		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.09071813268983613 | validation: 0.09310666150750863]
	TIME [epoch: 9.75 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898189866006254		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.08898189866006254 | validation: 0.06939290980340283]
	TIME [epoch: 9.78 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08845493205703311		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.08845493205703311 | validation: 0.07092167421774706]
	TIME [epoch: 9.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09492589839448963		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.09492589839448963 | validation: 0.0682088368418639]
	TIME [epoch: 9.75 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08927235820159501		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.08927235820159501 | validation: 0.08728773171684236]
	TIME [epoch: 9.75 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08642665617180509		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.08642665617180509 | validation: 0.06824385216086677]
	TIME [epoch: 9.77 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09802114279110505		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.09802114279110505 | validation: 0.09261752289169309]
	TIME [epoch: 9.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10169952126428106		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.10169952126428106 | validation: 0.07790359829670719]
	TIME [epoch: 9.75 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09455596893571729		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.09455596893571729 | validation: 0.0841468053746954]
	TIME [epoch: 9.76 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09738910428779904		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.09738910428779904 | validation: 0.08712263263599358]
	TIME [epoch: 9.76 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09269812748961669		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.09269812748961669 | validation: 0.09714708230452629]
	TIME [epoch: 9.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10149937699353984		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.10149937699353984 | validation: 0.09757027363450999]
	TIME [epoch: 9.77 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10051285723312069		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.10051285723312069 | validation: 0.07876374443963781]
	TIME [epoch: 9.75 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09590277523144894		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.09590277523144894 | validation: 0.07640989712499824]
	TIME [epoch: 9.76 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09062553594883833		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.09062553594883833 | validation: 0.08014772077607855]
	TIME [epoch: 9.76 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08890930854164451		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.08890930854164451 | validation: 0.08080099484591005]
	TIME [epoch: 9.77 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09645142385527118		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.09645142385527118 | validation: 0.08101568244356194]
	TIME [epoch: 9.75 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09085458977809503		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.09085458977809503 | validation: 0.0767010455875486]
	TIME [epoch: 9.75 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08666580240459772		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.08666580240459772 | validation: 0.08272325247931839]
	TIME [epoch: 9.77 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0934691023501116		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.0934691023501116 | validation: 0.09184698060763992]
	TIME [epoch: 9.76 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.085055566475886		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.085055566475886 | validation: 0.08227153580821832]
	TIME [epoch: 9.76 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09369740395826441		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.09369740395826441 | validation: 0.07995680878123741]
	TIME [epoch: 9.78 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0966933489607801		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.0966933489607801 | validation: 0.08722019829020598]
	TIME [epoch: 9.75 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09366412192108405		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.09366412192108405 | validation: 0.06961916175120975]
	TIME [epoch: 9.75 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09251787345074144		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.09251787345074144 | validation: 0.07289311338345597]
	TIME [epoch: 9.75 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.099191130086042		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.099191130086042 | validation: 0.07816528150344691]
	TIME [epoch: 9.78 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08714218757169119		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.08714218757169119 | validation: 0.08093431005409746]
	TIME [epoch: 9.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08866500630701521		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.08866500630701521 | validation: 0.07830196290719296]
	TIME [epoch: 9.76 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0912599218309826		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.0912599218309826 | validation: 0.07305063293483384]
	TIME [epoch: 9.78 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08780806691053424		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.08780806691053424 | validation: 0.08109220758306464]
	TIME [epoch: 9.76 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09468643758492842		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.09468643758492842 | validation: 0.06700742478168893]
	TIME [epoch: 9.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09049820524751159		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.09049820524751159 | validation: 0.0905553537940718]
	TIME [epoch: 9.76 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09258045530357288		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.09258045530357288 | validation: 0.07252088873199161]
	TIME [epoch: 9.77 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09136310623002544		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.09136310623002544 | validation: 0.08262569162572468]
	TIME [epoch: 9.76 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09136780462517761		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.09136780462517761 | validation: 0.08175311031008616]
	TIME [epoch: 9.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09017789088998793		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.09017789088998793 | validation: 0.08408267663958569]
	TIME [epoch: 9.78 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09151451598236456		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.09151451598236456 | validation: 0.08241581240539926]
	TIME [epoch: 9.75 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09381538800347909		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.09381538800347909 | validation: 0.0905578868908714]
	TIME [epoch: 9.76 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0970198631752292		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.0970198631752292 | validation: 0.07464306014439932]
	TIME [epoch: 9.77 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10075599349006972		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.10075599349006972 | validation: 0.09393350776400156]
	TIME [epoch: 9.76 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0959212225906575		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.0959212225906575 | validation: 0.09704540051514543]
	TIME [epoch: 9.75 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851302350190817		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.09851302350190817 | validation: 0.07351565929502117]
	TIME [epoch: 9.76 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09612717608531879		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.09612717608531879 | validation: 0.06984904533224329]
	TIME [epoch: 9.78 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08697935006448057		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.08697935006448057 | validation: 0.07095321204015971]
	TIME [epoch: 9.75 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08803199150542126		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.08803199150542126 | validation: 0.0816035915724223]
	TIME [epoch: 9.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08758271901936607		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.08758271901936607 | validation: 0.07169757584866777]
	TIME [epoch: 9.77 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09034130549160199		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.09034130549160199 | validation: 0.07708517137781003]
	TIME [epoch: 9.75 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09402687976811375		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.09402687976811375 | validation: 0.08074093303961194]
	TIME [epoch: 9.76 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09541215857153328		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.09541215857153328 | validation: 0.08150527433101433]
	TIME [epoch: 9.76 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09277149500456941		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.09277149500456941 | validation: 0.08699989790954181]
	TIME [epoch: 9.77 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08540612197298382		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.08540612197298382 | validation: 0.07961750228541119]
	TIME [epoch: 9.75 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390253264441974		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.08390253264441974 | validation: 0.07375381444279]
	TIME [epoch: 9.76 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08797806362548086		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.08797806362548086 | validation: 0.08024445076187345]
	TIME [epoch: 9.78 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08871676145261946		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.08871676145261946 | validation: 0.07144610556095769]
	TIME [epoch: 9.75 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10209297931640855		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.10209297931640855 | validation: 0.0873513802667959]
	TIME [epoch: 9.75 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10349312161440152		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.10349312161440152 | validation: 0.08710684893375849]
	TIME [epoch: 9.77 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0985289190153038		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.0985289190153038 | validation: 0.06713526245678783]
	TIME [epoch: 9.76 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08954142777960368		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.08954142777960368 | validation: 0.07843790385623162]
	TIME [epoch: 9.75 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0860510974284562		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.0860510974284562 | validation: 0.07507232886290488]
	TIME [epoch: 9.76 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08804257497407156		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.08804257497407156 | validation: 0.06785281764972322]
	TIME [epoch: 9.77 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09673527828140102		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.09673527828140102 | validation: 0.09059147214214955]
	TIME [epoch: 9.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09904507097387877		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.09904507097387877 | validation: 0.08327255310397716]
	TIME [epoch: 9.76 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09162459277901475		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.09162459277901475 | validation: 0.08138662620375474]
	TIME [epoch: 9.77 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08183903889576814		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.08183903889576814 | validation: 0.07631039216123503]
	TIME [epoch: 9.76 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09022338266363453		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.09022338266363453 | validation: 0.0809392692350503]
	TIME [epoch: 9.75 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08230461482268861		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.08230461482268861 | validation: 0.08671072048458214]
	TIME [epoch: 9.77 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09210963359909358		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.09210963359909358 | validation: 0.08014886976150183]
	TIME [epoch: 9.76 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0929546841573313		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.0929546841573313 | validation: 0.08209362968135019]
	TIME [epoch: 9.75 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08938704959399775		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.08938704959399775 | validation: 0.09488823798456134]
	TIME [epoch: 9.75 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09564080157871134		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.09564080157871134 | validation: 0.0783806598402516]
	TIME [epoch: 9.78 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752594106774925		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.08752594106774925 | validation: 0.08764189941695971]
	TIME [epoch: 9.75 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09066650568629261		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.09066650568629261 | validation: 0.07361869860761809]
	TIME [epoch: 9.75 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08383347574238523		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.08383347574238523 | validation: 0.07037248227526606]
	TIME [epoch: 9.77 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08928209659733718		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.08928209659733718 | validation: 0.07110290586663946]
	TIME [epoch: 9.76 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262342009030844		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.09262342009030844 | validation: 0.08537858460367737]
	TIME [epoch: 9.75 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09280920690332267		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.09280920690332267 | validation: 0.09290585171549523]
	TIME [epoch: 9.76 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09289726540515181		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.09289726540515181 | validation: 0.08201398917361624]
	TIME [epoch: 9.76 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0983489750671486		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.0983489750671486 | validation: 0.0792204180424382]
	TIME [epoch: 9.76 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09047071363529395		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.09047071363529395 | validation: 0.09584742328702264]
	TIME [epoch: 9.74 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08596684498658824		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.08596684498658824 | validation: 0.07896612140840674]
	TIME [epoch: 9.77 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827516100708338		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.08827516100708338 | validation: 0.07468052924986304]
	TIME [epoch: 9.75 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09673682631403123		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.09673682631403123 | validation: 0.08892017366040637]
	TIME [epoch: 9.75 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09637425428514805		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.09637425428514805 | validation: 0.07605444213300029]
	TIME [epoch: 9.75 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08884528432385677		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.08884528432385677 | validation: 0.07044126590335713]
	TIME [epoch: 9.75 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08470442992994717		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.08470442992994717 | validation: 0.07084609339754094]
	TIME [epoch: 9.74 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09786281302286004		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.09786281302286004 | validation: 0.08078982536234394]
	TIME [epoch: 9.76 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09240230908538731		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.09240230908538731 | validation: 0.07613755762332959]
	TIME [epoch: 9.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08828636473234966		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.08828636473234966 | validation: 0.08424348901633426]
	TIME [epoch: 9.75 sec]
Finished training in 19694.548 seconds.
