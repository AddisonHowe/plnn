Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3090891341

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.680942117570238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.680942117570238 | validation: 8.394183535537742]
	TIME [epoch: 72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.256075689687982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.256075689687982 | validation: 7.684675632607129]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.147727341462538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.147727341462538 | validation: 7.702796345582779]
	TIME [epoch: 10.3 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.707801851932513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.707801851932513 | validation: 6.26363583489384]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.215774688099939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.215774688099939 | validation: 6.245985036978323]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.991193802225057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.991193802225057 | validation: 5.862282391884306]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.550708639856543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.550708639856543 | validation: 4.95223996680479]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.5872939688760725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5872939688760725 | validation: 6.827960839177434]
	TIME [epoch: 10.3 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.70991697817942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.70991697817942 | validation: 7.342302253226201]
	TIME [epoch: 10.3 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.905714022816423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.905714022816423 | validation: 6.793577978385823]
	TIME [epoch: 10.3 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.531558941127107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.531558941127107 | validation: 4.755090282496766]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.098776645718376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.098776645718376 | validation: 4.863857490362665]
	TIME [epoch: 10.3 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.997206019203783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.997206019203783 | validation: 4.587572969745776]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.789392704578445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.789392704578445 | validation: 4.4403463440605195]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.855538770044266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.855538770044266 | validation: 4.016965992708216]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.449265429573249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.449265429573249 | validation: 4.812254866868686]
	TIME [epoch: 10.3 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.824770746566253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.824770746566253 | validation: 4.624618484500162]
	TIME [epoch: 10.3 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.907323022659339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.907323022659339 | validation: 5.265606560558661]
	TIME [epoch: 10.3 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9074756094932015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9074756094932015 | validation: 5.228097684292927]
	TIME [epoch: 10.3 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.351003947509054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.351003947509054 | validation: 4.928841526265588]
	TIME [epoch: 10.3 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.793086912970873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.793086912970873 | validation: 3.9162409378081326]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.101819796270799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.101819796270799 | validation: 3.9350048225467265]
	TIME [epoch: 10.3 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.465454869251138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.465454869251138 | validation: 4.185597640023725]
	TIME [epoch: 10.3 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.071944367955091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.071944367955091 | validation: 3.771694394303962]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.530882723271923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.530882723271923 | validation: 3.654686298381953]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7992409365214215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7992409365214215 | validation: 4.261305810247639]
	TIME [epoch: 10.3 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.580631769531408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.580631769531408 | validation: 3.5128178852791225]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6209544471181423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6209544471181423 | validation: 3.168498556607399]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.398838732932313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.398838732932313 | validation: 3.368920790312046]
	TIME [epoch: 10.3 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2651760864447086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2651760864447086 | validation: 2.9843166952367755]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8505001545653954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8505001545653954 | validation: 3.0282266424630775]
	TIME [epoch: 10.3 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8669756872524674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8669756872524674 | validation: 3.1439068930509366]
	TIME [epoch: 10.3 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9942364431886253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9942364431886253 | validation: 3.736627399285423]
	TIME [epoch: 10.3 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.120864687080117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.120864687080117 | validation: 2.8599987935632556]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7604140353139948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7604140353139948 | validation: 2.9270918545456484]
	TIME [epoch: 10.3 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7878654348207017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7878654348207017 | validation: 2.8093525663181924]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.747983113966943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.747983113966943 | validation: 2.9769529333229623]
	TIME [epoch: 10.3 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7815676129183684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7815676129183684 | validation: 3.0773082040984114]
	TIME [epoch: 10.3 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8043340085949415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8043340085949415 | validation: 3.0445379717905316]
	TIME [epoch: 10.3 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7744781465928208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7744781465928208 | validation: 3.34170387811747]
	TIME [epoch: 10.3 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.961764267610153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.961764267610153 | validation: 2.8665615588080158]
	TIME [epoch: 10.3 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4793909581347977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4793909581347977 | validation: 3.6698029199000324]
	TIME [epoch: 10.3 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.087182567718808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.087182567718808 | validation: 2.9979333062962716]
	TIME [epoch: 10.3 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7808607200204762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7808607200204762 | validation: 2.994327079309977]
	TIME [epoch: 10.3 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1046378286191185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1046378286191185 | validation: 4.455007984732112]
	TIME [epoch: 10.3 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2591190892777844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2591190892777844 | validation: 2.931353718323417]
	TIME [epoch: 10.3 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.929895171029436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.929895171029436 | validation: 2.900958657351974]
	TIME [epoch: 10.3 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9339143230639695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9339143230639695 | validation: 4.586831871815469]
	TIME [epoch: 10.3 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.485316417634672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.485316417634672 | validation: 2.9144034449304743]
	TIME [epoch: 10.3 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1393284116995916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1393284116995916 | validation: 3.996440778408388]
	TIME [epoch: 10.3 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.55295998528685		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 3.55295998528685 | validation: 4.212913815761563]
	TIME [epoch: 10.3 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.324694885326513		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 3.324694885326513 | validation: 3.005816763325427]
	TIME [epoch: 10.3 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.899687374512418		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 2.899687374512418 | validation: 2.9545903053671423]
	TIME [epoch: 10.3 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.870642549354873		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 2.870642549354873 | validation: 2.9127644013808043]
	TIME [epoch: 10.3 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.728273490084706		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 2.728273490084706 | validation: 3.3326418866176666]
	TIME [epoch: 10.3 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4764198489277214		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 3.4764198489277214 | validation: 3.0386895921412953]
	TIME [epoch: 10.3 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.842902550872498		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 2.842902550872498 | validation: 2.924559610804991]
	TIME [epoch: 10.3 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7686301857665336		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 2.7686301857665336 | validation: 3.860164775746645]
	TIME [epoch: 10.3 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.101525593598108		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 3.101525593598108 | validation: 2.884107457863704]
	TIME [epoch: 10.3 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8857881206057354		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 2.8857881206057354 | validation: 2.854624804530396]
	TIME [epoch: 10.3 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7469844342785654		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 2.7469844342785654 | validation: 3.407769330478891]
	TIME [epoch: 10.3 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.807814779425226		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 2.807814779425226 | validation: 2.9538242531080527]
	TIME [epoch: 10.3 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.87849337531679		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 2.87849337531679 | validation: 2.8632383490625064]
	TIME [epoch: 10.3 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.742832004162185		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 2.742832004162185 | validation: 2.8435187808802063]
	TIME [epoch: 10.3 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7399249386124227		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 2.7399249386124227 | validation: 2.884070979669864]
	TIME [epoch: 10.3 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.696537145781759		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 2.696537145781759 | validation: 2.861721492165764]
	TIME [epoch: 10.3 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.212983458068004		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 3.212983458068004 | validation: 2.9900297754696012]
	TIME [epoch: 10.3 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8783491523426177		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 2.8783491523426177 | validation: 2.931286781210608]
	TIME [epoch: 10.3 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7696998229797307		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 2.7696998229797307 | validation: 2.849508435017855]
	TIME [epoch: 10.3 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.702438295137758		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 2.702438295137758 | validation: 2.9031383379517166]
	TIME [epoch: 10.3 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6997718956266565		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 2.6997718956266565 | validation: 2.8764418973120143]
	TIME [epoch: 10.3 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.853125680925646		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 2.853125680925646 | validation: 3.179014367157811]
	TIME [epoch: 10.3 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7412007339748636		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 2.7412007339748636 | validation: 2.955551907593996]
	TIME [epoch: 10.3 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8370939871736516		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 2.8370939871736516 | validation: 2.9863724155386433]
	TIME [epoch: 10.3 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.713965871347706		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 2.713965871347706 | validation: 2.9448975696394912]
	TIME [epoch: 10.3 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0668412878611684		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 3.0668412878611684 | validation: 4.162192032483565]
	TIME [epoch: 10.3 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1328889371615234		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 3.1328889371615234 | validation: 2.8710869438630393]
	TIME [epoch: 10.3 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8504205148461383		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 2.8504205148461383 | validation: 2.977206506664476]
	TIME [epoch: 10.3 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9360592565364434		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 2.9360592565364434 | validation: 3.3658755478746203]
	TIME [epoch: 10.3 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.04921329693154		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 3.04921329693154 | validation: 3.42565022949793]
	TIME [epoch: 10.3 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.931455950969774		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 2.931455950969774 | validation: 2.8390473852250806]
	TIME [epoch: 10.3 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.686108544365731		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 2.686108544365731 | validation: 2.835401418278865]
	TIME [epoch: 10.3 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6555688785316476		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 2.6555688785316476 | validation: 3.248738646387354]
	TIME [epoch: 10.3 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8420083176777786		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 2.8420083176777786 | validation: 2.833551759395799]
	TIME [epoch: 10.3 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8421669303201424		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 2.8421669303201424 | validation: 2.998679578549542]
	TIME [epoch: 10.3 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8558451873342117		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 2.8558451873342117 | validation: 3.048626029048875]
	TIME [epoch: 10.3 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7924647689727027		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 2.7924647689727027 | validation: 2.929123907150419]
	TIME [epoch: 10.3 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9352145329967967		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 2.9352145329967967 | validation: 2.8529952091140873]
	TIME [epoch: 10.3 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6976389959586204		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 2.6976389959586204 | validation: 3.081126301816238]
	TIME [epoch: 10.3 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.712439749428213		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 2.712439749428213 | validation: 2.8525033544515606]
	TIME [epoch: 10.3 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7776786439959418		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 2.7776786439959418 | validation: 2.9711031251067483]
	TIME [epoch: 10.3 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6734989695707165		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 2.6734989695707165 | validation: 2.893063182427567]
	TIME [epoch: 10.3 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7951222176744057		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 2.7951222176744057 | validation: 2.9159363453867466]
	TIME [epoch: 10.3 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8274429807024486		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 2.8274429807024486 | validation: 2.784231620553159]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.637561269369751		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 2.637561269369751 | validation: 2.817414666220475]
	TIME [epoch: 10.3 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6311139872585643		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 2.6311139872585643 | validation: 2.9593095938415686]
	TIME [epoch: 10.3 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7176825240970155		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 2.7176825240970155 | validation: 2.851688027057114]
	TIME [epoch: 10.3 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4245243845141955		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 3.4245243845141955 | validation: 3.1059750355773166]
	TIME [epoch: 10.3 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8561787038223025		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 2.8561787038223025 | validation: 2.7845490295616573]
	TIME [epoch: 10.3 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8803678644761073		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 2.8803678644761073 | validation: 2.872703564624773]
	TIME [epoch: 10.3 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.773131167606628		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 2.773131167606628 | validation: 2.883172915952013]
	TIME [epoch: 10.3 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7242607119121027		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 2.7242607119121027 | validation: 3.039108287840747]
	TIME [epoch: 10.3 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7075788226430935		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 2.7075788226430935 | validation: 2.8507151120983214]
	TIME [epoch: 10.3 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.650219986217039		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 2.650219986217039 | validation: 2.782071895622685]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6563740368583644		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 2.6563740368583644 | validation: 2.828772502762813]
	TIME [epoch: 10.3 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.683868285782131		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 2.683868285782131 | validation: 3.1543261739729633]
	TIME [epoch: 10.3 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7342047217435406		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 2.7342047217435406 | validation: 3.0338913838649626]
	TIME [epoch: 10.3 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.714161653005122		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 2.714161653005122 | validation: 2.9177674425619085]
	TIME [epoch: 10.3 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.652237707561914		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 2.652237707561914 | validation: 2.822495935483464]
	TIME [epoch: 10.3 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6597004243278417		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 2.6597004243278417 | validation: 2.811194815987461]
	TIME [epoch: 10.3 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.647346464861122		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 2.647346464861122 | validation: 2.8560008378697717]
	TIME [epoch: 10.3 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.776635883778348		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 2.776635883778348 | validation: 3.03172255772294]
	TIME [epoch: 10.3 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2552444559263605		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 3.2552444559263605 | validation: 4.800232603994429]
	TIME [epoch: 10.3 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.649079445349291		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 4.649079445349291 | validation: 4.213921141213192]
	TIME [epoch: 10.3 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2167744437766776		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 3.2167744437766776 | validation: 2.8364328972776383]
	TIME [epoch: 10.3 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.692408555437163		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 2.692408555437163 | validation: 2.914838263921549]
	TIME [epoch: 10.3 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6720759678583597		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 2.6720759678583597 | validation: 2.964869057416117]
	TIME [epoch: 10.3 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7076107760040844		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 2.7076107760040844 | validation: 2.891993327890593]
	TIME [epoch: 10.3 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8117383615869556		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 2.8117383615869556 | validation: 2.9916339795656097]
	TIME [epoch: 10.3 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.068682356745029		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 3.068682356745029 | validation: 2.916544833073918]
	TIME [epoch: 10.3 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.875093358498776		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 2.875093358498776 | validation: 3.3593945484857173]
	TIME [epoch: 10.3 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.019786162447816		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 3.019786162447816 | validation: 3.0430757758311913]
	TIME [epoch: 10.3 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.830710355931974		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 2.830710355931974 | validation: 2.8815465596676164]
	TIME [epoch: 10.3 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8500250845042405		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 2.8500250845042405 | validation: 3.1929021805488187]
	TIME [epoch: 10.3 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.771403961187996		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 2.771403961187996 | validation: 2.7984379775747716]
	TIME [epoch: 10.3 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.728380020347408		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 2.728380020347408 | validation: 3.7349655094143492]
	TIME [epoch: 10.3 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1230016508580194		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 3.1230016508580194 | validation: 2.89217782741431]
	TIME [epoch: 10.3 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.623047664333008		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 2.623047664333008 | validation: 2.833848747850792]
	TIME [epoch: 10.3 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.954278650456639		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 2.954278650456639 | validation: 3.1611757672360126]
	TIME [epoch: 10.3 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8866568135224666		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.8866568135224666 | validation: 3.0206843893865223]
	TIME [epoch: 10.3 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.773215377613954		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 2.773215377613954 | validation: 3.585247430173838]
	TIME [epoch: 10.3 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0790871967406956		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 3.0790871967406956 | validation: 2.907865138320162]
	TIME [epoch: 10.3 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7130245923468483		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 2.7130245923468483 | validation: 2.8939815101043793]
	TIME [epoch: 10.3 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.060059681317367		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 3.060059681317367 | validation: 2.948129940144809]
	TIME [epoch: 10.3 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.924329986874354		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 2.924329986874354 | validation: 2.9461475208044443]
	TIME [epoch: 10.3 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8673733614535037		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 2.8673733614535037 | validation: 3.055486409434361]
	TIME [epoch: 10.3 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7682057624732836		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 2.7682057624732836 | validation: 3.6745978209719694]
	TIME [epoch: 10.3 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.812900337369311		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 5.812900337369311 | validation: 5.923499531471812]
	TIME [epoch: 10.3 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3565246748275355		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 6.3565246748275355 | validation: 5.862511929055752]
	TIME [epoch: 10.3 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.321479245142798		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 6.321479245142798 | validation: 5.7594859035237915]
	TIME [epoch: 10.3 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.043713949467037		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 5.043713949467037 | validation: 5.364495574957998]
	TIME [epoch: 10.3 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.566030204574194		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 5.566030204574194 | validation: 5.129954981563754]
	TIME [epoch: 10.3 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.813132200252332		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 4.813132200252332 | validation: 4.068308123066613]
	TIME [epoch: 10.3 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.183495437674496		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 4.183495437674496 | validation: 5.3428932040848665]
	TIME [epoch: 10.3 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8379836909103426		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 3.8379836909103426 | validation: 3.6936631601650163]
	TIME [epoch: 10.3 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7200814093367933		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 3.7200814093367933 | validation: 3.3545091185667015]
	TIME [epoch: 10.3 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.149017209259539		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 3.149017209259539 | validation: 3.0132940453281605]
	TIME [epoch: 10.3 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.214010924519756		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 3.214010924519756 | validation: 3.1443932510116386]
	TIME [epoch: 10.3 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.326727094981494		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 3.326727094981494 | validation: 4.405474176645555]
	TIME [epoch: 10.3 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.266982208010958		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 5.266982208010958 | validation: 5.209610140717035]
	TIME [epoch: 10.3 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.517837254358662		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 5.517837254358662 | validation: 5.155023237258269]
	TIME [epoch: 10.3 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.936245773275781		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 4.936245773275781 | validation: 5.029735196040495]
	TIME [epoch: 10.3 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.021242245685721		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 4.021242245685721 | validation: 3.227397503620206]
	TIME [epoch: 10.3 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9594657046872244		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 3.9594657046872244 | validation: 4.875472035095422]
	TIME [epoch: 10.3 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.162247027846343		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 4.162247027846343 | validation: 4.078049622003559]
	TIME [epoch: 10.3 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3677792309478107		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 3.3677792309478107 | validation: 3.3363277972836642]
	TIME [epoch: 10.3 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.514761017937464		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 3.514761017937464 | validation: 3.0796207150377826]
	TIME [epoch: 10.3 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.975996895201599		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 2.975996895201599 | validation: 2.8775495501761648]
	TIME [epoch: 10.3 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9988547001155346		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 2.9988547001155346 | validation: 3.2045100656887193]
	TIME [epoch: 10.3 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.026034615375563		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 3.026034615375563 | validation: 2.962701895011451]
	TIME [epoch: 10.3 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8117791479673335		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 2.8117791479673335 | validation: 2.9861943914439517]
	TIME [epoch: 10.3 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.751844168649749		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 2.751844168649749 | validation: 2.7891481956822872]
	TIME [epoch: 10.3 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7280474581789664		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 2.7280474581789664 | validation: 3.0426829741123447]
	TIME [epoch: 10.3 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9474385740694777		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 2.9474385740694777 | validation: 2.87799378093578]
	TIME [epoch: 10.3 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7609974547217946		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 2.7609974547217946 | validation: 2.877318157395289]
	TIME [epoch: 10.3 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.711527355793659		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 2.711527355793659 | validation: 2.722100904154765]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_166.pth
	Model improved!!!
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1104755802532713		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 3.1104755802532713 | validation: 2.915016627419123]
	TIME [epoch: 10.3 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8740538728165603		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 2.8740538728165603 | validation: 3.1324460961893776]
	TIME [epoch: 10.3 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.775550935067188		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 2.775550935067188 | validation: 3.1065340966561226]
	TIME [epoch: 10.3 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.535404844120334		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 4.535404844120334 | validation: 5.335517875926986]
	TIME [epoch: 10.3 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.58677533474786		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 4.58677533474786 | validation: 3.403234445043527]
	TIME [epoch: 10.3 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4268974525559672		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 3.4268974525559672 | validation: 4.298102337679094]
	TIME [epoch: 10.3 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.790603107914727		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 3.790603107914727 | validation: 2.924885101509616]
	TIME [epoch: 10.3 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6501086046395965		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 2.6501086046395965 | validation: 3.070079824971017]
	TIME [epoch: 10.3 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.092632565368042		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 4.092632565368042 | validation: 4.802739190489765]
	TIME [epoch: 10.3 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.419709354055955		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 4.419709354055955 | validation: 3.6883473454001363]
	TIME [epoch: 10.3 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.654209238207988		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 3.654209238207988 | validation: 3.4107477135140853]
	TIME [epoch: 10.3 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2678027231977325		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 3.2678027231977325 | validation: 3.019735761214667]
	TIME [epoch: 10.3 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.799562687708585		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 2.799562687708585 | validation: 2.9665859214200605]
	TIME [epoch: 10.3 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.450757043351838		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 3.450757043351838 | validation: 3.3290657829740726]
	TIME [epoch: 10.3 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1101072234414264		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 3.1101072234414264 | validation: 3.7396030956890156]
	TIME [epoch: 10.3 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1967782891428875		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 4.1967782891428875 | validation: 3.3583246785125067]
	TIME [epoch: 10.3 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5022160129740216		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 3.5022160129740216 | validation: 5.10055404546986]
	TIME [epoch: 10.3 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.316141428677012		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 4.316141428677012 | validation: 3.023333070043524]
	TIME [epoch: 10.3 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2358113082038273		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 3.2358113082038273 | validation: 2.7473858921017933]
	TIME [epoch: 10.3 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0646526316990887		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 3.0646526316990887 | validation: 3.143092624164912]
	TIME [epoch: 10.3 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.832886360033727		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 2.832886360033727 | validation: 2.8520527256301023]
	TIME [epoch: 10.3 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6730111798492824		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 2.6730111798492824 | validation: 2.6279222515832354]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.640120289758424		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 2.640120289758424 | validation: 3.549046249656054]
	TIME [epoch: 10.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0295346305568915		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 3.0295346305568915 | validation: 2.895603266244809]
	TIME [epoch: 10.3 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7056745571400596		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 2.7056745571400596 | validation: 2.7415379167448624]
	TIME [epoch: 10.3 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5736894929098755		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 2.5736894929098755 | validation: 2.739619051831164]
	TIME [epoch: 10.3 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7077992402406714		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 2.7077992402406714 | validation: 3.266625533361769]
	TIME [epoch: 10.3 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.980591793110675		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 3.980591793110675 | validation: 3.4535277466834144]
	TIME [epoch: 10.3 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3222425577357853		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 3.3222425577357853 | validation: 3.0952051123857554]
	TIME [epoch: 10.3 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.067682133672819		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 3.067682133672819 | validation: 3.446357104411946]
	TIME [epoch: 10.3 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.224305451898927		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 3.224305451898927 | validation: 3.0450624328562856]
	TIME [epoch: 10.3 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0099250595033267		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 3.0099250595033267 | validation: 4.23646201761756]
	TIME [epoch: 10.3 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9849559582952865		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 3.9849559582952865 | validation: 3.27770640458621]
	TIME [epoch: 10.3 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.031837053657294		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 3.031837053657294 | validation: 3.0582435878316563]
	TIME [epoch: 10.3 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.969032436527702		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 2.969032436527702 | validation: 3.030918338216556]
	TIME [epoch: 10.3 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5810581422205034		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 2.5810581422205034 | validation: 2.762966494460006]
	TIME [epoch: 10.3 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.685146630052304		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 2.685146630052304 | validation: 2.7632005167960916]
	TIME [epoch: 10.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5535848370095677		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 2.5535848370095677 | validation: 2.76543955559122]
	TIME [epoch: 10.3 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8474922278892048		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 2.8474922278892048 | validation: 4.043394746091498]
	TIME [epoch: 10.3 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.666800190859176		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 4.666800190859176 | validation: 4.286089316234119]
	TIME [epoch: 10.3 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.342698558518422		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 3.342698558518422 | validation: 3.1946718103880847]
	TIME [epoch: 10.3 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.350390885748569		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 3.350390885748569 | validation: 3.0290888290845226]
	TIME [epoch: 10.3 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8487535032879743		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 2.8487535032879743 | validation: 2.9333985301341774]
	TIME [epoch: 10.3 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2871326601855655		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 3.2871326601855655 | validation: 3.6875331261925637]
	TIME [epoch: 10.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.345369174279265		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 3.345369174279265 | validation: 3.040690274313182]
	TIME [epoch: 10.3 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.269959737509699		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 3.269959737509699 | validation: 2.765150963085961]
	TIME [epoch: 10.3 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8767282598595063		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 2.8767282598595063 | validation: 2.932631371090171]
	TIME [epoch: 10.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6081724009822134		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 2.6081724009822134 | validation: 3.0428250377680257]
	TIME [epoch: 10.3 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.072909291390082		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 3.072909291390082 | validation: 2.6363667636458326]
	TIME [epoch: 10.3 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2611969196668564		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 2.2611969196668564 | validation: 2.412035072349508]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.163878979545559		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 2.163878979545559 | validation: 2.308856022235131]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_217.pth
	Model improved!!!
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1345732177813295		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 2.1345732177813295 | validation: 2.3969120139702613]
	TIME [epoch: 10.3 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.453630252757022		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 2.453630252757022 | validation: 2.346175140949315]
	TIME [epoch: 10.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1862261962283425		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 2.1862261962283425 | validation: 2.5438423655888536]
	TIME [epoch: 10.3 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2475843840357794		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 2.2475843840357794 | validation: 2.278511910174947]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_221.pth
	Model improved!!!
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.176112505667041		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 2.176112505667041 | validation: 2.788519079820143]
	TIME [epoch: 10.3 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.362846606264135		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 2.362846606264135 | validation: 2.5493942473241504]
	TIME [epoch: 10.3 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.708646394454875		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 2.708646394454875 | validation: 3.2731889366862665]
	TIME [epoch: 10.3 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.803387701018484		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 2.803387701018484 | validation: 3.0908379668187322]
	TIME [epoch: 10.3 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.550270716946488		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 2.550270716946488 | validation: 2.4106218492994094]
	TIME [epoch: 10.3 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1003289380729004		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 2.1003289380729004 | validation: 2.606155653180002]
	TIME [epoch: 10.3 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.291865892075817		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 2.291865892075817 | validation: 2.598099629562887]
	TIME [epoch: 10.3 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3401541023434214		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 2.3401541023434214 | validation: 2.3418264337332197]
	TIME [epoch: 10.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9668498734094968		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.9668498734094968 | validation: 2.179382072239294]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_230.pth
	Model improved!!!
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8496886538481556		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 2.8496886538481556 | validation: 3.3740004730424538]
	TIME [epoch: 10.3 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6734345117097886		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 2.6734345117097886 | validation: 2.496673976335788]
	TIME [epoch: 10.3 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.309478747627595		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 2.309478747627595 | validation: 1.9369767650586693]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_233.pth
	Model improved!!!
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.832528724538373		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 1.832528724538373 | validation: 1.8375229136297282]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_234.pth
	Model improved!!!
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8357146811523601		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.8357146811523601 | validation: 2.6242895561260475]
	TIME [epoch: 10.3 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1896687010462004		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 2.1896687010462004 | validation: 2.078983107350245]
	TIME [epoch: 10.3 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8818518563367843		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 1.8818518563367843 | validation: 1.9227219807728009]
	TIME [epoch: 10.2 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6937057502275152		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 1.6937057502275152 | validation: 1.8492836130529466]
	TIME [epoch: 10.3 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7945961841688436		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 1.7945961841688436 | validation: 1.875171776886967]
	TIME [epoch: 10.3 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9024978858727448		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 1.9024978858727448 | validation: 2.0664496611817396]
	TIME [epoch: 10.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0089933281121937		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 2.0089933281121937 | validation: 2.150073311718703]
	TIME [epoch: 10.3 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.007719711639358		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 2.007719711639358 | validation: 2.0285033673423767]
	TIME [epoch: 10.2 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9487397637795296		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 1.9487397637795296 | validation: 2.001305082212487]
	TIME [epoch: 10.3 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8575805441536943		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.8575805441536943 | validation: 2.652210221869979]
	TIME [epoch: 10.3 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6016448225799267		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 2.6016448225799267 | validation: 2.548374026778669]
	TIME [epoch: 10.3 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.871650147602792		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 2.871650147602792 | validation: 2.947613309947187]
	TIME [epoch: 10.3 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5418266652491885		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 2.5418266652491885 | validation: 2.067023589763717]
	TIME [epoch: 10.3 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8850435134918313		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 1.8850435134918313 | validation: 2.0171202728231656]
	TIME [epoch: 10.3 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0755284139073047		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 2.0755284139073047 | validation: 1.9397697021731959]
	TIME [epoch: 10.3 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0991653048224435		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 2.0991653048224435 | validation: 2.3614566360265847]
	TIME [epoch: 10.3 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9542263086118392		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 1.9542263086118392 | validation: 2.2246210629122705]
	TIME [epoch: 10.3 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8957080026789666		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.8957080026789666 | validation: 2.433501174739512]
	TIME [epoch: 10.3 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1093374242520033		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 2.1093374242520033 | validation: 1.9983267696460802]
	TIME [epoch: 10.3 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0303073804167986		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 2.0303073804167986 | validation: 2.3497378728382836]
	TIME [epoch: 10.3 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8829079129492972		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 1.8829079129492972 | validation: 2.0360897279513965]
	TIME [epoch: 10.3 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0693420961295006		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 2.0693420961295006 | validation: 2.395429387487992]
	TIME [epoch: 10.3 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.086219368039787		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 2.086219368039787 | validation: 2.044125866185752]
	TIME [epoch: 10.3 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7390800654709022		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 1.7390800654709022 | validation: 1.7561500690736882]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_258.pth
	Model improved!!!
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6573621670699032		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 1.6573621670699032 | validation: 2.0834490338095866]
	TIME [epoch: 10.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6826297440545102		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 1.6826297440545102 | validation: 1.7480641427826646]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_260.pth
	Model improved!!!
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5058319166147034		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 1.5058319166147034 | validation: 1.5328747010078154]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_261.pth
	Model improved!!!
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3841237420286068		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 1.3841237420286068 | validation: 1.6828836503635467]
	TIME [epoch: 10.3 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.427552598744292		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.427552598744292 | validation: 1.5519786729830782]
	TIME [epoch: 10.3 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.570168134786306		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 1.570168134786306 | validation: 1.631877737415087]
	TIME [epoch: 10.3 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4114102854040398		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 1.4114102854040398 | validation: 1.6191395318251638]
	TIME [epoch: 10.3 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4266279708425347		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 1.4266279708425347 | validation: 1.3671029012795506]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_266.pth
	Model improved!!!
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3976501833898776		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 1.3976501833898776 | validation: 1.4108299639706394]
	TIME [epoch: 10.3 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.595852668884013		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 1.595852668884013 | validation: 2.0567729124374843]
	TIME [epoch: 10.3 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.652423060226186		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.652423060226186 | validation: 1.7422928539677596]
	TIME [epoch: 10.3 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4226948918314222		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 1.4226948918314222 | validation: 1.383133993255763]
	TIME [epoch: 10.3 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3969981321608393		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.3969981321608393 | validation: 1.8608584171112728]
	TIME [epoch: 10.3 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6844790677564139		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 1.6844790677564139 | validation: 1.8382139560399122]
	TIME [epoch: 10.3 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4290302447376333		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 1.4290302447376333 | validation: 1.3093950743442315]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_273.pth
	Model improved!!!
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2472311254323056		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 1.2472311254323056 | validation: 1.1166620618829939]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_274.pth
	Model improved!!!
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.13603172152289		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.13603172152289 | validation: 1.1378121088541866]
	TIME [epoch: 10.3 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2555825466650503		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 1.2555825466650503 | validation: 1.5288146218563377]
	TIME [epoch: 10.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.216600177584958		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 1.216600177584958 | validation: 1.0571529554180639]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_277.pth
	Model improved!!!
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0614590503370833		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 1.0614590503370833 | validation: 1.0759754682945513]
	TIME [epoch: 10.3 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2028444475679114		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 1.2028444475679114 | validation: 0.9778708360626865]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9602063770539029		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 0.9602063770539029 | validation: 1.0248853166010616]
	TIME [epoch: 10.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0438744307656853		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 1.0438744307656853 | validation: 1.0055434681118174]
	TIME [epoch: 10.3 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0394277967928423		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 1.0394277967928423 | validation: 0.9780445439178379]
	TIME [epoch: 10.3 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.081028675951147		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 1.081028675951147 | validation: 1.1188041247364853]
	TIME [epoch: 10.3 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1918359432031478		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 1.1918359432031478 | validation: 1.390334160836161]
	TIME [epoch: 10.3 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.040046885740658		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 1.040046885740658 | validation: 1.0432067506005884]
	TIME [epoch: 10.3 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9532188250639957		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 0.9532188250639957 | validation: 0.9388463740124577]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_286.pth
	Model improved!!!
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9276198523362431		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 0.9276198523362431 | validation: 0.8736620725664119]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0129346077620975		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 1.0129346077620975 | validation: 0.882225894379003]
	TIME [epoch: 10.3 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9823517707870323		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 0.9823517707870323 | validation: 1.1774013343418057]
	TIME [epoch: 10.3 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9618723022785639		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 0.9618723022785639 | validation: 1.3604249872905936]
	TIME [epoch: 10.3 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9506457094815302		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 0.9506457094815302 | validation: 1.13128912145689]
	TIME [epoch: 10.3 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9156156361173109		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 0.9156156361173109 | validation: 0.7837066045342465]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_292.pth
	Model improved!!!
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.875666308494542		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 0.875666308494542 | validation: 0.8957674145284173]
	TIME [epoch: 10.3 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1868250348853941		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 1.1868250348853941 | validation: 1.0074400606084937]
	TIME [epoch: 10.3 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8707173985786889		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 0.8707173985786889 | validation: 0.8406922731313209]
	TIME [epoch: 10.3 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8744446854046053		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 0.8744446854046053 | validation: 0.9440831550703115]
	TIME [epoch: 10.3 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.977719117071412		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 0.977719117071412 | validation: 0.8134790238810643]
	TIME [epoch: 10.3 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8967882147859472		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 0.8967882147859472 | validation: 0.9492645004225865]
	TIME [epoch: 10.3 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.874533220621103		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 0.874533220621103 | validation: 0.7869138135449927]
	TIME [epoch: 10.3 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7722090668733786		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 0.7722090668733786 | validation: 0.8549696724338823]
	TIME [epoch: 10.3 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.755817583037475		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.755817583037475 | validation: 0.766831905116877]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_301.pth
	Model improved!!!
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8007718086739211		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 0.8007718086739211 | validation: 0.8959262480919705]
	TIME [epoch: 10.3 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8426116357644622		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 0.8426116357644622 | validation: 0.8287194875249467]
	TIME [epoch: 10.3 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135027347898142		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 0.8135027347898142 | validation: 0.8184421323773546]
	TIME [epoch: 10.3 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8044251642827694		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 0.8044251642827694 | validation: 0.7297541434808713]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7085721695718142		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 0.7085721695718142 | validation: 0.8358864281294766]
	TIME [epoch: 10.3 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7687123851237515		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 0.7687123851237515 | validation: 1.2142605462773297]
	TIME [epoch: 10.3 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.042689835303537		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 1.042689835303537 | validation: 1.0449277509819879]
	TIME [epoch: 10.3 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9106578510983876		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 0.9106578510983876 | validation: 0.7756612692895766]
	TIME [epoch: 10.3 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7481085796507287		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 0.7481085796507287 | validation: 0.7712615176342529]
	TIME [epoch: 10.3 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7056627887659179		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 0.7056627887659179 | validation: 0.7919739054387763]
	TIME [epoch: 10.3 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7460968413637156		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.7460968413637156 | validation: 0.5962126683648827]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_312.pth
	Model improved!!!
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7024789565936375		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 0.7024789565936375 | validation: 0.770800131991793]
	TIME [epoch: 10.3 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7134141222231977		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 0.7134141222231977 | validation: 1.1147063367108865]
	TIME [epoch: 10.3 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9648252865193078		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 0.9648252865193078 | validation: 0.671971701112401]
	TIME [epoch: 10.3 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7830101790737765		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 0.7830101790737765 | validation: 0.8157727975262327]
	TIME [epoch: 10.3 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7374008413845357		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.7374008413845357 | validation: 1.1697207361848372]
	TIME [epoch: 10.3 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7690715854664913		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 0.7690715854664913 | validation: 0.7861762369482196]
	TIME [epoch: 10.3 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.795405647627818		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.795405647627818 | validation: 0.7914367366337203]
	TIME [epoch: 10.3 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7513968147941441		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.7513968147941441 | validation: 0.7937615047531474]
	TIME [epoch: 10.3 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7361852897719503		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 0.7361852897719503 | validation: 0.7665789641363242]
	TIME [epoch: 10.3 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8015255306824521		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 0.8015255306824521 | validation: 0.884132428264939]
	TIME [epoch: 10.3 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8478120609808668		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.8478120609808668 | validation: 0.6688207014086478]
	TIME [epoch: 10.3 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7159026561760512		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.7159026561760512 | validation: 0.7039138061579894]
	TIME [epoch: 10.3 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6855113063214174		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.6855113063214174 | validation: 0.6458850059573794]
	TIME [epoch: 10.3 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6483412442285232		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 0.6483412442285232 | validation: 0.678805953057546]
	TIME [epoch: 10.3 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6806784341431177		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 0.6806784341431177 | validation: 0.7180622655253079]
	TIME [epoch: 10.3 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7007931914580171		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.7007931914580171 | validation: 0.6711641446121365]
	TIME [epoch: 10.3 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6702099537982563		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 0.6702099537982563 | validation: 0.8845156195007904]
	TIME [epoch: 10.3 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7243979059352343		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 0.7243979059352343 | validation: 0.9331400787832509]
	TIME [epoch: 10.3 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7143721604279356		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.7143721604279356 | validation: 0.5711105314676277]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_331.pth
	Model improved!!!
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.629768507111027		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 0.629768507111027 | validation: 0.7127469895980629]
	TIME [epoch: 10.3 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6573229280135191		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 0.6573229280135191 | validation: 0.6520888267275706]
	TIME [epoch: 10.3 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6091151186522696		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.6091151186522696 | validation: 1.2671118448538294]
	TIME [epoch: 10.3 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.724239835686552		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 0.724239835686552 | validation: 0.6585760186691992]
	TIME [epoch: 10.3 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6652620055431604		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.6652620055431604 | validation: 0.821298005311051]
	TIME [epoch: 10.3 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6327809230158639		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.6327809230158639 | validation: 0.5253970583056419]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_337.pth
	Model improved!!!
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7050293388299081		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.7050293388299081 | validation: 1.0685415281950237]
	TIME [epoch: 10.3 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7597910013906346		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.7597910013906346 | validation: 1.3998246186038659]
	TIME [epoch: 10.3 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9464758237442947		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.9464758237442947 | validation: 0.9909967481250778]
	TIME [epoch: 10.3 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544603822527949		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.6544603822527949 | validation: 0.5332886360732002]
	TIME [epoch: 10.3 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6008120747632276		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.6008120747632276 | validation: 0.8467359757339028]
	TIME [epoch: 10.3 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6548749815338756		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.6548749815338756 | validation: 0.7687894110169791]
	TIME [epoch: 10.3 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5575581958025737		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.5575581958025737 | validation: 0.5051926374092498]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_344.pth
	Model improved!!!
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945969155626832		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.5945969155626832 | validation: 0.6947756918127511]
	TIME [epoch: 10.3 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6492478394325114		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 0.6492478394325114 | validation: 0.46965224360789565]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_346.pth
	Model improved!!!
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5099261816639297		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.5099261816639297 | validation: 0.5397069502306802]
	TIME [epoch: 10.3 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602564753873465		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 0.5602564753873465 | validation: 0.5408054217738889]
	TIME [epoch: 10.3 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5655424479408322		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 0.5655424479408322 | validation: 0.9007824558813105]
	TIME [epoch: 10.3 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6973553003906964		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.6973553003906964 | validation: 0.5853064731030888]
	TIME [epoch: 10.3 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.522373644434932		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.522373644434932 | validation: 0.5784901634434865]
	TIME [epoch: 10.3 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5637966687732978		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.5637966687732978 | validation: 0.4837488762317472]
	TIME [epoch: 10.3 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49382290463729384		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 0.49382290463729384 | validation: 0.5198937556955661]
	TIME [epoch: 10.3 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48790724465773627		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.48790724465773627 | validation: 0.5223708807965406]
	TIME [epoch: 10.3 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245440268253638		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.6245440268253638 | validation: 0.5549929174528316]
	TIME [epoch: 10.3 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6815076282467026		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.6815076282467026 | validation: 0.5797586178396221]
	TIME [epoch: 10.3 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5084932231243837		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 0.5084932231243837 | validation: 0.4367179056193609]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_357.pth
	Model improved!!!
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5028346455322317		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.5028346455322317 | validation: 0.6483529625241985]
	TIME [epoch: 10.3 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231986611884029		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 0.5231986611884029 | validation: 0.4181212024479124]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_359.pth
	Model improved!!!
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45055936337753744		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.45055936337753744 | validation: 0.5016101526141118]
	TIME [epoch: 10.3 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.501653109623482		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.501653109623482 | validation: 0.543758503954789]
	TIME [epoch: 10.3 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44417864740431073		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.44417864740431073 | validation: 0.5407800015979978]
	TIME [epoch: 10.3 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142779432872957		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.4142779432872957 | validation: 0.42312274383608]
	TIME [epoch: 10.3 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49606433292108065		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.49606433292108065 | validation: 0.5646315714282488]
	TIME [epoch: 10.3 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124307664196802		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.5124307664196802 | validation: 0.5356394852978553]
	TIME [epoch: 10.3 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40637286256903254		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.40637286256903254 | validation: 0.42025343579005753]
	TIME [epoch: 10.3 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4484882786701948		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 0.4484882786701948 | validation: 0.42208944247536184]
	TIME [epoch: 10.3 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3799814876882558		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.3799814876882558 | validation: 0.4757418952194415]
	TIME [epoch: 10.3 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5425055287800633		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.5425055287800633 | validation: 0.5147538874418148]
	TIME [epoch: 10.3 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.541155324432175		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.541155324432175 | validation: 0.3415796411880497]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_370.pth
	Model improved!!!
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4406039062440882		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.4406039062440882 | validation: 0.32080631890821865]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_371.pth
	Model improved!!!
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45709071755910174		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.45709071755910174 | validation: 0.9262703653748642]
	TIME [epoch: 10.3 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46441788969236386		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.46441788969236386 | validation: 0.3781647608765969]
	TIME [epoch: 10.3 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3747801196106419		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.3747801196106419 | validation: 0.4439545075096015]
	TIME [epoch: 10.3 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44897640068536376		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.44897640068536376 | validation: 0.343157105073732]
	TIME [epoch: 10.3 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3885482229308056		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.3885482229308056 | validation: 0.34445365410564743]
	TIME [epoch: 10.3 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3869207728120164		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.3869207728120164 | validation: 0.48223493970895503]
	TIME [epoch: 10.3 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3713377218534902		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.3713377218534902 | validation: 0.3128336553430846]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_378.pth
	Model improved!!!
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4625404047499207		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.4625404047499207 | validation: 0.5115364720086687]
	TIME [epoch: 10.3 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39339824900003617		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.39339824900003617 | validation: 0.3395486746321039]
	TIME [epoch: 10.3 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.407264007588955		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.407264007588955 | validation: 0.34734539910049245]
	TIME [epoch: 10.3 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422394789707889		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.6422394789707889 | validation: 0.48131341036009917]
	TIME [epoch: 10.3 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626337144020332		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.3626337144020332 | validation: 0.4789768949051135]
	TIME [epoch: 10.3 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4351798534924384		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.4351798534924384 | validation: 0.34689074989796126]
	TIME [epoch: 10.3 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36003683898594646		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.36003683898594646 | validation: 0.3642438177271534]
	TIME [epoch: 10.3 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4145371719376798		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.4145371719376798 | validation: 0.5376556906294164]
	TIME [epoch: 10.3 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5019740258227142		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.5019740258227142 | validation: 0.30255176832310954]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_387.pth
	Model improved!!!
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32429023686268754		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.32429023686268754 | validation: 0.38067081534560687]
	TIME [epoch: 10.3 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4654695792664377		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.4654695792664377 | validation: 0.5694394386662147]
	TIME [epoch: 10.3 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36848844942454384		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.36848844942454384 | validation: 0.503384802737032]
	TIME [epoch: 10.3 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3572045805293071		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.3572045805293071 | validation: 0.40821166382140783]
	TIME [epoch: 10.3 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38530355668370575		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.38530355668370575 | validation: 0.35636336651986383]
	TIME [epoch: 10.3 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4052939500425049		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.4052939500425049 | validation: 0.5441069350022523]
	TIME [epoch: 10.3 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4283306915163997		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.4283306915163997 | validation: 0.4109428223432721]
	TIME [epoch: 10.3 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4603241721810093		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.4603241721810093 | validation: 0.44079647162824087]
	TIME [epoch: 10.3 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3178559220649542		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.3178559220649542 | validation: 0.3659207418254919]
	TIME [epoch: 10.3 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217248667560709		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.3217248667560709 | validation: 0.28011198744532406]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_397.pth
	Model improved!!!
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2987422957060299		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.2987422957060299 | validation: 0.2632866805739155]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_398.pth
	Model improved!!!
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35972545315817456		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.35972545315817456 | validation: 0.31666642492941494]
	TIME [epoch: 10.3 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.449953470290812		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.449953470290812 | validation: 0.7329452191220088]
	TIME [epoch: 10.3 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3964825882335145		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.3964825882335145 | validation: 0.3323339168944453]
	TIME [epoch: 10.3 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37732595256309603		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.37732595256309603 | validation: 0.3005103019276122]
	TIME [epoch: 10.3 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3427963696882611		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.3427963696882611 | validation: 0.24569785953886375]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_403.pth
	Model improved!!!
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3248263224762389		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.3248263224762389 | validation: 0.3045163860371768]
	TIME [epoch: 10.3 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3126593851324836		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.3126593851324836 | validation: 0.3846092029355118]
	TIME [epoch: 10.3 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36884958113417843		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.36884958113417843 | validation: 0.2688355919273675]
	TIME [epoch: 10.3 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488091284756125		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.4488091284756125 | validation: 0.5519765499569933]
	TIME [epoch: 10.3 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3561298727284967		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.3561298727284967 | validation: 0.39534680442450026]
	TIME [epoch: 10.3 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2888028251697917		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.2888028251697917 | validation: 0.24739899625741837]
	TIME [epoch: 10.3 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2921312680889825		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.2921312680889825 | validation: 0.5386996398966162]
	TIME [epoch: 10.3 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.492880661934526		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.492880661934526 | validation: 0.42162391450610265]
	TIME [epoch: 10.3 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3483655567110711		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.3483655567110711 | validation: 0.25663697975860195]
	TIME [epoch: 10.3 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3508725171997979		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.3508725171997979 | validation: 0.4094128111573197]
	TIME [epoch: 10.3 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34594823012693177		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.34594823012693177 | validation: 0.7146920920304668]
	TIME [epoch: 10.3 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.472247238451843		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.472247238451843 | validation: 0.4140054038520299]
	TIME [epoch: 10.3 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.307139539193026		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.307139539193026 | validation: 0.24281953180923413]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_416.pth
	Model improved!!!
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2514579886729127		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.2514579886729127 | validation: 0.3458366974854523]
	TIME [epoch: 10.3 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2607141395185475		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.2607141395185475 | validation: 0.4812204703434038]
	TIME [epoch: 10.3 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3731397195712938		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.3731397195712938 | validation: 0.3108552402051816]
	TIME [epoch: 10.3 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3602909424033667		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.3602909424033667 | validation: 0.24255574122480839]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_420.pth
	Model improved!!!
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3480361925246673		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.3480361925246673 | validation: 0.47467142520723543]
	TIME [epoch: 10.3 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3323677011518482		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.3323677011518482 | validation: 0.3734167426408007]
	TIME [epoch: 10.3 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.277008232624926		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.277008232624926 | validation: 0.2568509640173694]
	TIME [epoch: 10.3 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33652117233749584		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.33652117233749584 | validation: 0.2815781679614674]
	TIME [epoch: 10.3 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31468167843354083		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 0.31468167843354083 | validation: 0.2483422593547289]
	TIME [epoch: 10.3 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26219239025658314		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.26219239025658314 | validation: 0.22810227085227802]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_426.pth
	Model improved!!!
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4374350688004096		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.4374350688004096 | validation: 0.26443744576443373]
	TIME [epoch: 10.3 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30689506747568335		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.30689506747568335 | validation: 0.2830586643170298]
	TIME [epoch: 10.3 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261786428199937		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.3261786428199937 | validation: 0.7218819109022997]
	TIME [epoch: 10.3 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4126969021191247		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.4126969021191247 | validation: 0.25713244773169686]
	TIME [epoch: 10.3 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30405855572204105		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.30405855572204105 | validation: 0.33376214466348514]
	TIME [epoch: 10.3 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26564384360573173		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.26564384360573173 | validation: 0.35848897893518145]
	TIME [epoch: 10.3 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33027369892546665		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.33027369892546665 | validation: 0.4645456696491382]
	TIME [epoch: 10.3 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39832364385871705		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.39832364385871705 | validation: 0.4374951705457599]
	TIME [epoch: 10.3 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4415310193937375		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.4415310193937375 | validation: 0.28496706351723855]
	TIME [epoch: 10.3 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26795038876142385		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.26795038876142385 | validation: 0.3892133492144288]
	TIME [epoch: 10.3 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6037751006545938		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.6037751006545938 | validation: 0.27470452093300185]
	TIME [epoch: 10.3 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23773280761641785		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.23773280761641785 | validation: 0.4941370953451926]
	TIME [epoch: 10.3 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3579803886544758		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.3579803886544758 | validation: 0.4520836353007796]
	TIME [epoch: 10.3 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33727739830950537		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.33727739830950537 | validation: 0.23932975624499433]
	TIME [epoch: 10.3 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3900402323016273		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.3900402323016273 | validation: 0.32973165143703975]
	TIME [epoch: 10.3 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3540188976394406		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.3540188976394406 | validation: 0.24889977011055714]
	TIME [epoch: 10.3 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3643332124501429		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.3643332124501429 | validation: 0.3109533790326083]
	TIME [epoch: 10.3 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3227259993757065		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.3227259993757065 | validation: 1.1478538439724983]
	TIME [epoch: 10.3 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6417347267637685		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.6417347267637685 | validation: 0.29540918858106274]
	TIME [epoch: 10.3 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29458722174561647		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.29458722174561647 | validation: 0.2598354692537507]
	TIME [epoch: 10.3 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3591413137139983		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.3591413137139983 | validation: 0.51394701896705]
	TIME [epoch: 10.3 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4589827516424685		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.4589827516424685 | validation: 0.32127877519345077]
	TIME [epoch: 10.3 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30993811768449653		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.30993811768449653 | validation: 0.22917211030091839]
	TIME [epoch: 10.3 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23384258226126908		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.23384258226126908 | validation: 0.2381904235803681]
	TIME [epoch: 10.3 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.251996879880879		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.251996879880879 | validation: 0.3197802903613109]
	TIME [epoch: 10.3 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29400591974573825		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.29400591974573825 | validation: 0.27519488893867183]
	TIME [epoch: 10.3 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26399207388769713		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.26399207388769713 | validation: 0.5971597118640668]
	TIME [epoch: 10.3 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3280258986208728		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.3280258986208728 | validation: 0.4073040968876394]
	TIME [epoch: 10.3 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31527675123321397		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.31527675123321397 | validation: 0.371943765657809]
	TIME [epoch: 10.3 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2723794108508638		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.2723794108508638 | validation: 0.3328515670477625]
	TIME [epoch: 10.3 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3895196018527696		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.3895196018527696 | validation: 0.42057855081269735]
	TIME [epoch: 10.3 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26859545166693855		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.26859545166693855 | validation: 0.22410112543956182]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_458.pth
	Model improved!!!
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43315852275530425		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.43315852275530425 | validation: 0.637431880932366]
	TIME [epoch: 10.3 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.362032157233026		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.362032157233026 | validation: 0.39164333396733697]
	TIME [epoch: 10.3 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33621965765828715		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.33621965765828715 | validation: 0.3221033846195656]
	TIME [epoch: 10.3 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22874655773010089		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.22874655773010089 | validation: 0.3276314562292532]
	TIME [epoch: 10.3 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3140372973387079		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.3140372973387079 | validation: 0.3157384589834458]
	TIME [epoch: 10.3 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38915251157273845		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.38915251157273845 | validation: 0.5040729536530308]
	TIME [epoch: 10.3 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37837781266272075		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.37837781266272075 | validation: 0.3227114496272544]
	TIME [epoch: 10.3 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2867170450815716		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.2867170450815716 | validation: 0.23584538250598053]
	TIME [epoch: 10.3 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2820444726152926		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.2820444726152926 | validation: 0.2770274995538109]
	TIME [epoch: 10.3 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2787188864969051		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.2787188864969051 | validation: 0.30848193704604016]
	TIME [epoch: 10.3 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2503056956707508		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.2503056956707508 | validation: 0.25676190652045544]
	TIME [epoch: 10.3 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21662533080268917		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.21662533080268917 | validation: 0.2422452707042066]
	TIME [epoch: 10.3 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693490445259511		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.2693490445259511 | validation: 0.3130252979222344]
	TIME [epoch: 10.3 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24580695229697183		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.24580695229697183 | validation: 0.36012821848119364]
	TIME [epoch: 10.3 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43138270867429984		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.43138270867429984 | validation: 0.22144948785921637]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_473.pth
	Model improved!!!
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28829348520377013		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.28829348520377013 | validation: 0.3804570079930912]
	TIME [epoch: 10.3 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36817804978942265		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.36817804978942265 | validation: 0.2629683583100804]
	TIME [epoch: 10.3 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28744738325738023		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.28744738325738023 | validation: 0.23566852533499966]
	TIME [epoch: 10.3 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2343895987693883		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.2343895987693883 | validation: 0.21223704983976174]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_477.pth
	Model improved!!!
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25368869482761075		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.25368869482761075 | validation: 0.3756680908539529]
	TIME [epoch: 10.3 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2679590093667709		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.2679590093667709 | validation: 0.2575195527451758]
	TIME [epoch: 10.3 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27846136443693303		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.27846136443693303 | validation: 0.22629650871050763]
	TIME [epoch: 10.3 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25303912506381926		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.25303912506381926 | validation: 0.29830724155863453]
	TIME [epoch: 10.3 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25474147036384964		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.25474147036384964 | validation: 0.30077022260589054]
	TIME [epoch: 10.3 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29619777016544396		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.29619777016544396 | validation: 0.26461448863158465]
	TIME [epoch: 10.3 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4489044252511961		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.4489044252511961 | validation: 0.3048813589647009]
	TIME [epoch: 10.3 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24719570538785018		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.24719570538785018 | validation: 0.2635048583745184]
	TIME [epoch: 10.3 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2978273122955458		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.2978273122955458 | validation: 0.20653432580262995]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_486.pth
	Model improved!!!
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3268224368044314		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.3268224368044314 | validation: 0.32898737822044033]
	TIME [epoch: 10.3 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30782866152722643		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.30782866152722643 | validation: 0.21333596324107326]
	TIME [epoch: 10.3 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.308248885865264		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.308248885865264 | validation: 0.3153550748748936]
	TIME [epoch: 10.3 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24009202272494012		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.24009202272494012 | validation: 0.23212128313768943]
	TIME [epoch: 10.3 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26233393261743054		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.26233393261743054 | validation: 0.40417866998146124]
	TIME [epoch: 10.3 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3685715739939274		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.3685715739939274 | validation: 0.2930195410306441]
	TIME [epoch: 10.3 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2582256049157284		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.2582256049157284 | validation: 0.444774484371319]
	TIME [epoch: 10.3 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32669551575312766		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.32669551575312766 | validation: 0.29231292715225665]
	TIME [epoch: 10.3 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3191517297067364		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.3191517297067364 | validation: 0.48978976977751715]
	TIME [epoch: 10.3 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33042655346107075		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.33042655346107075 | validation: 0.2537161388745241]
	TIME [epoch: 10.3 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767027374068466		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.2767027374068466 | validation: 0.2267399874532574]
	TIME [epoch: 10.3 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22304253818764258		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.22304253818764258 | validation: 0.21330256947993842]
	TIME [epoch: 10.3 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3380926491241541		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.3380926491241541 | validation: 0.329451120323053]
	TIME [epoch: 10.3 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28784577944783607		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.28784577944783607 | validation: 0.20515884756847713]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_500.pth
	Model improved!!!
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23694719784546767		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.23694719784546767 | validation: 0.27932485284046515]
	TIME [epoch: 10.3 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2697301625017401		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.2697301625017401 | validation: 0.27820725005358427]
	TIME [epoch: 10.3 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2561182777981128		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.2561182777981128 | validation: 0.3876377233364057]
	TIME [epoch: 10.3 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33306915870496		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.33306915870496 | validation: 0.2916693277184678]
	TIME [epoch: 10.3 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3282120183035609		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.3282120183035609 | validation: 0.2961484466322146]
	TIME [epoch: 10.3 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2773016893544429		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.2773016893544429 | validation: 0.371955362557196]
	TIME [epoch: 10.3 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2558350825859315		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.2558350825859315 | validation: 0.24633904192684952]
	TIME [epoch: 10.3 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27612217417829676		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.27612217417829676 | validation: 0.2689511088991144]
	TIME [epoch: 10.6 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25244394184454777		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.25244394184454777 | validation: 0.26654152026601535]
	TIME [epoch: 10.3 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2739305875528665		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.2739305875528665 | validation: 0.2217559141477913]
	TIME [epoch: 10.3 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24146101682410545		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.24146101682410545 | validation: 0.2913200969979524]
	TIME [epoch: 10.3 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3213712050971083		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.3213712050971083 | validation: 0.2875197605595185]
	TIME [epoch: 10.3 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27586392912675406		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.27586392912675406 | validation: 0.3016995622696545]
	TIME [epoch: 10.3 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22177018449541192		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.22177018449541192 | validation: 0.3040655765187873]
	TIME [epoch: 10.3 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26259874654669596		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.26259874654669596 | validation: 0.30074870146156557]
	TIME [epoch: 10.3 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23568847648772992		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.23568847648772992 | validation: 0.18965463304315447]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_516.pth
	Model improved!!!
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20403419302719228		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.20403419302719228 | validation: 0.2625635918526064]
	TIME [epoch: 10.3 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24840798932453093		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.24840798932453093 | validation: 0.42356618537899127]
	TIME [epoch: 10.3 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26868676145226167		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.26868676145226167 | validation: 0.21579565416400692]
	TIME [epoch: 10.3 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22576456013264803		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.22576456013264803 | validation: 0.20179045937655093]
	TIME [epoch: 10.3 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2516469994214076		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.2516469994214076 | validation: 0.20820760431266433]
	TIME [epoch: 10.3 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30074351501033764		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.30074351501033764 | validation: 0.2298581109437773]
	TIME [epoch: 10.3 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22259205365775112		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.22259205365775112 | validation: 0.22481722624698008]
	TIME [epoch: 10.3 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21639820347510388		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.21639820347510388 | validation: 0.19594463523376834]
	TIME [epoch: 10.3 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22745609852264592		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.22745609852264592 | validation: 0.23763045799369906]
	TIME [epoch: 10.3 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2639614459519125		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.2639614459519125 | validation: 0.24565177583134187]
	TIME [epoch: 10.3 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24397352951033974		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.24397352951033974 | validation: 0.35396051677765344]
	TIME [epoch: 10.3 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3465305865033503		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.3465305865033503 | validation: 0.337488283240204]
	TIME [epoch: 10.3 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25200997013271115		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.25200997013271115 | validation: 0.22598621995573143]
	TIME [epoch: 10.3 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2527580437601619		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.2527580437601619 | validation: 0.2681925494600874]
	TIME [epoch: 10.3 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2678148333966489		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.2678148333966489 | validation: 0.23549173051329036]
	TIME [epoch: 10.3 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2242630161188112		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.2242630161188112 | validation: 0.29392760218924097]
	TIME [epoch: 10.3 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26836921216667975		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.26836921216667975 | validation: 0.2612505584796399]
	TIME [epoch: 10.3 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24609919038710376		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.24609919038710376 | validation: 0.21398425029781196]
	TIME [epoch: 10.3 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2511385334935195		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.2511385334935195 | validation: 0.22254476733465975]
	TIME [epoch: 10.3 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23834127380468323		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.23834127380468323 | validation: 0.30918153359478995]
	TIME [epoch: 10.3 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767230490268785		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.2767230490268785 | validation: 0.37824711622029356]
	TIME [epoch: 10.3 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2535162999960388		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.2535162999960388 | validation: 0.2842009471351378]
	TIME [epoch: 10.3 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21379851662721383		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.21379851662721383 | validation: 0.3049894496547153]
	TIME [epoch: 10.3 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22363375005329972		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.22363375005329972 | validation: 0.21401220610417834]
	TIME [epoch: 10.3 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2134166040799171		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.2134166040799171 | validation: 0.3662946154700502]
	TIME [epoch: 10.3 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2514885374422599		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.2514885374422599 | validation: 0.33546142283173425]
	TIME [epoch: 10.3 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651932559090761		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.2651932559090761 | validation: 0.29587366111910723]
	TIME [epoch: 10.3 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25364962018869647		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.25364962018869647 | validation: 0.17912564457647726]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_544.pth
	Model improved!!!
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19861692467930103		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.19861692467930103 | validation: 0.2765777918933622]
	TIME [epoch: 10.3 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32018671874602167		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.32018671874602167 | validation: 0.2680455421696579]
	TIME [epoch: 10.3 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22898478305303555		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.22898478305303555 | validation: 0.19729863919307913]
	TIME [epoch: 10.3 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015650243411188		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.2015650243411188 | validation: 0.3324745345904423]
	TIME [epoch: 10.3 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23603822745537223		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.23603822745537223 | validation: 0.25381326677492694]
	TIME [epoch: 10.3 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22106443243054202		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.22106443243054202 | validation: 0.20042821187601306]
	TIME [epoch: 10.3 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2223282207245343		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.2223282207245343 | validation: 0.34460516840945504]
	TIME [epoch: 10.3 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30829206361003175		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.30829206361003175 | validation: 0.3840103248724169]
	TIME [epoch: 10.3 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28217920804067903		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.28217920804067903 | validation: 0.3442454776819503]
	TIME [epoch: 10.3 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22905689669440837		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.22905689669440837 | validation: 0.21875019079658586]
	TIME [epoch: 10.3 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20406123431134224		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.20406123431134224 | validation: 0.2678436164625381]
	TIME [epoch: 10.3 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2315107991592967		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.2315107991592967 | validation: 0.2216711614779407]
	TIME [epoch: 10.3 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22260398677150312		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.22260398677150312 | validation: 0.19506768348023065]
	TIME [epoch: 10.3 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2251751928350673		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.2251751928350673 | validation: 0.20733873831481134]
	TIME [epoch: 10.3 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22130366604482132		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.22130366604482132 | validation: 0.21331891672752612]
	TIME [epoch: 10.3 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19486032737302733		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.19486032737302733 | validation: 0.24269199215559303]
	TIME [epoch: 10.3 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20550985477304035		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.20550985477304035 | validation: 0.2600163421807954]
	TIME [epoch: 10.3 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20016998632854138		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.20016998632854138 | validation: 0.17915521072427823]
	TIME [epoch: 10.3 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21624845609014254		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.21624845609014254 | validation: 0.24179158122106928]
	TIME [epoch: 10.3 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2656215910004576		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.2656215910004576 | validation: 0.23869826039282335]
	TIME [epoch: 10.3 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26470665435680785		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.26470665435680785 | validation: 0.20495115350474813]
	TIME [epoch: 10.3 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2966131346818215		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.2966131346818215 | validation: 0.18700381560710383]
	TIME [epoch: 10.3 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23230642517833539		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.23230642517833539 | validation: 0.32742954430173116]
	TIME [epoch: 10.3 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.258493838821577		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.258493838821577 | validation: 0.18529223156610392]
	TIME [epoch: 10.3 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23491197247363851		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.23491197247363851 | validation: 0.19847719783670273]
	TIME [epoch: 10.3 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20183618094265282		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.20183618094265282 | validation: 0.219630167378161]
	TIME [epoch: 10.3 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20461576117368807		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.20461576117368807 | validation: 0.18561948246326457]
	TIME [epoch: 10.3 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23003720819177617		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.23003720819177617 | validation: 0.3499366926578064]
	TIME [epoch: 10.3 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836570348907201		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.2836570348907201 | validation: 0.2627384004157539]
	TIME [epoch: 10.3 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2204148337686685		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.2204148337686685 | validation: 0.24138289026602344]
	TIME [epoch: 10.3 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27341477835543143		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.27341477835543143 | validation: 0.1914082064423105]
	TIME [epoch: 10.3 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2283915558558836		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.2283915558558836 | validation: 0.2596209402343136]
	TIME [epoch: 10.3 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21307806903772644		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.21307806903772644 | validation: 0.1691530059946316]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_577.pth
	Model improved!!!
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21976936806652544		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.21976936806652544 | validation: 0.22956289537925456]
	TIME [epoch: 10.3 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22338982037758098		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.22338982037758098 | validation: 0.3729927660957037]
	TIME [epoch: 10.3 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30284539010641764		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.30284539010641764 | validation: 0.21337577878684258]
	TIME [epoch: 10.3 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1869402529639407		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.1869402529639407 | validation: 0.20169856078308543]
	TIME [epoch: 10.3 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21771830619224047		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.21771830619224047 | validation: 0.300880959231728]
	TIME [epoch: 10.3 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2606343361807225		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.2606343361807225 | validation: 0.5005827478400436]
	TIME [epoch: 10.3 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836246459234255		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.2836246459234255 | validation: 0.19111871688872392]
	TIME [epoch: 10.3 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20514291226513856		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.20514291226513856 | validation: 0.3074919379458899]
	TIME [epoch: 10.3 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24941661554952937		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.24941661554952937 | validation: 0.2269007509500893]
	TIME [epoch: 10.3 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19293204400168418		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.19293204400168418 | validation: 0.2588611763610249]
	TIME [epoch: 10.3 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2192302083010876		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.2192302083010876 | validation: 0.2437680349639723]
	TIME [epoch: 10.3 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23225378652596723		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.23225378652596723 | validation: 0.31339032522034743]
	TIME [epoch: 10.3 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.287476814376347		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.287476814376347 | validation: 0.3759309836405689]
	TIME [epoch: 10.3 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394330465655555		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.2394330465655555 | validation: 0.1888288126099559]
	TIME [epoch: 10.3 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19805841719565706		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.19805841719565706 | validation: 0.18846803838016876]
	TIME [epoch: 10.3 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21962300722490954		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.21962300722490954 | validation: 0.38050531668786247]
	TIME [epoch: 10.3 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2880901065819471		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.2880901065819471 | validation: 0.17639417441793925]
	TIME [epoch: 10.3 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20459898003667232		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.20459898003667232 | validation: 0.21312406306393072]
	TIME [epoch: 10.3 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21578600586173008		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.21578600586173008 | validation: 0.20086608658652794]
	TIME [epoch: 10.3 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22686664099118853		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.22686664099118853 | validation: 0.292196961049144]
	TIME [epoch: 10.3 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22457629818524466		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.22457629818524466 | validation: 0.35962159218445633]
	TIME [epoch: 10.3 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3045175245711708		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.3045175245711708 | validation: 0.26325035902730703]
	TIME [epoch: 10.3 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29415693751359145		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.29415693751359145 | validation: 0.3054057588416372]
	TIME [epoch: 10.3 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2159798756025082		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.2159798756025082 | validation: 0.3497607291796791]
	TIME [epoch: 10.3 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28797711020782		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.28797711020782 | validation: 0.24127066960305144]
	TIME [epoch: 10.3 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18771579261419358		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.18771579261419358 | validation: 0.2520435384162397]
	TIME [epoch: 10.3 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21856247641172497		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.21856247641172497 | validation: 0.21281330282899746]
	TIME [epoch: 10.3 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21633892827518753		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.21633892827518753 | validation: 0.38709267491609456]
	TIME [epoch: 10.3 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2667998684274429		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.2667998684274429 | validation: 0.29124013463253723]
	TIME [epoch: 10.3 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237154265402193		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.2237154265402193 | validation: 0.25012292569708927]
	TIME [epoch: 10.3 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1999434100488574		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.1999434100488574 | validation: 0.20969143436884033]
	TIME [epoch: 10.3 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22893858675459197		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.22893858675459197 | validation: 0.23450484284844264]
	TIME [epoch: 10.3 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24398097236830876		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.24398097236830876 | validation: 0.1791915664593116]
	TIME [epoch: 10.3 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20124947921313993		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.20124947921313993 | validation: 0.24281071135803067]
	TIME [epoch: 10.3 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24990148054756384		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.24990148054756384 | validation: 0.32416691662910974]
	TIME [epoch: 10.3 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24667901591511016		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.24667901591511016 | validation: 0.1895929165409287]
	TIME [epoch: 10.3 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2087394207237198		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.2087394207237198 | validation: 0.2604905662773373]
	TIME [epoch: 10.3 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2059546445519842		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.2059546445519842 | validation: 0.23598799168101967]
	TIME [epoch: 10.3 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18197703620183436		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.18197703620183436 | validation: 0.3571708988006928]
	TIME [epoch: 10.3 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2865715220905842		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.2865715220905842 | validation: 0.22636382085858153]
	TIME [epoch: 10.3 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21396909578570167		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.21396909578570167 | validation: 0.2015029606079588]
	TIME [epoch: 10.3 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23530546884230724		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.23530546884230724 | validation: 0.2538793190985011]
	TIME [epoch: 10.3 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23565093487900057		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.23565093487900057 | validation: 0.22489619376577005]
	TIME [epoch: 10.3 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24126388799457743		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.24126388799457743 | validation: 0.22650067094887824]
	TIME [epoch: 10.3 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19714780445771626		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.19714780445771626 | validation: 0.19559115033937854]
	TIME [epoch: 10.3 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24040989342941352		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.24040989342941352 | validation: 0.41591228580480777]
	TIME [epoch: 10.3 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24438631745113953		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.24438631745113953 | validation: 0.19082271597397907]
	TIME [epoch: 10.3 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19736422440097154		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.19736422440097154 | validation: 0.20628214058646774]
	TIME [epoch: 10.3 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25512156174174655		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.25512156174174655 | validation: 0.23266570405008197]
	TIME [epoch: 10.3 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21361252629635033		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.21361252629635033 | validation: 0.20002188877618518]
	TIME [epoch: 10.3 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2133742483893534		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.2133742483893534 | validation: 0.22417411969492848]
	TIME [epoch: 10.3 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22010582851012472		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.22010582851012472 | validation: 0.21571746964275298]
	TIME [epoch: 10.3 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18666503992351524		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.18666503992351524 | validation: 0.18182715803117805]
	TIME [epoch: 10.3 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19042724441676356		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.19042724441676356 | validation: 0.1948342922307802]
	TIME [epoch: 10.3 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20081861454789798		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.20081861454789798 | validation: 0.20534045265827103]
	TIME [epoch: 10.3 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21221661435343817		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.21221661435343817 | validation: 0.22174649529004192]
	TIME [epoch: 10.3 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2181705297416971		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.2181705297416971 | validation: 0.25923200967538257]
	TIME [epoch: 10.3 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2147254887205769		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.2147254887205769 | validation: 0.19692949159540157]
	TIME [epoch: 10.3 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22086494152326006		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.22086494152326006 | validation: 0.1848892646163533]
	TIME [epoch: 10.3 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18851995798244664		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.18851995798244664 | validation: 0.23237099351765614]
	TIME [epoch: 10.3 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24640684563858165		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.24640684563858165 | validation: 0.2552395597767507]
	TIME [epoch: 10.3 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2300675694692856		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.2300675694692856 | validation: 0.22251872446556908]
	TIME [epoch: 10.3 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000041258723506		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.2000041258723506 | validation: 0.32467493135031916]
	TIME [epoch: 10.3 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2323060417355535		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.2323060417355535 | validation: 0.2060493703025123]
	TIME [epoch: 10.3 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24108969090644608		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.24108969090644608 | validation: 0.2472697862902681]
	TIME [epoch: 10.3 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23850643617438352		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.23850643617438352 | validation: 0.3671397397489042]
	TIME [epoch: 10.3 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020503036663299		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.3020503036663299 | validation: 0.24343744421237137]
	TIME [epoch: 10.3 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2137962478752291		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.2137962478752291 | validation: 0.2056504549513627]
	TIME [epoch: 10.3 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1959904374562783		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.1959904374562783 | validation: 0.19280959898513986]
	TIME [epoch: 10.3 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2189781039014893		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.2189781039014893 | validation: 0.19846364736674177]
	TIME [epoch: 10.3 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1826805095437778		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.1826805095437778 | validation: 0.1840067875614267]
	TIME [epoch: 10.3 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18505517305127736		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.18505517305127736 | validation: 0.1946379032932785]
	TIME [epoch: 10.3 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21179578336779667		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.21179578336779667 | validation: 0.21193903690812652]
	TIME [epoch: 10.3 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21595367942369847		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.21595367942369847 | validation: 0.2163593808242231]
	TIME [epoch: 10.3 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1961451741901318		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.1961451741901318 | validation: 0.2071559326566735]
	TIME [epoch: 10.3 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2044550315163817		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.2044550315163817 | validation: 0.23875382746097815]
	TIME [epoch: 10.3 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19354176914406648		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.19354176914406648 | validation: 0.18294570362754628]
	TIME [epoch: 10.3 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29387277038057774		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.29387277038057774 | validation: 0.35400509345918435]
	TIME [epoch: 10.3 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25064805722780453		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.25064805722780453 | validation: 0.20242163053972348]
	TIME [epoch: 10.3 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20263160466105865		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.20263160466105865 | validation: 0.20680069648777213]
	TIME [epoch: 10.3 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19313977153607037		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.19313977153607037 | validation: 0.23180171567411847]
	TIME [epoch: 10.3 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1989040976299933		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.1989040976299933 | validation: 0.17628265224236414]
	TIME [epoch: 10.3 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17267594559631888		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.17267594559631888 | validation: 0.19096959851084147]
	TIME [epoch: 10.3 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.193277337672282		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.193277337672282 | validation: 0.2698994565546294]
	TIME [epoch: 10.3 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18927728200249566		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.18927728200249566 | validation: 0.18454228625045005]
	TIME [epoch: 10.3 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2168670503659051		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.2168670503659051 | validation: 0.23421329033429245]
	TIME [epoch: 10.3 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2374827655202151		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.2374827655202151 | validation: 0.22226427661426593]
	TIME [epoch: 10.3 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853054637955927		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.1853054637955927 | validation: 0.17957597371827239]
	TIME [epoch: 10.3 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18910170077601066		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.18910170077601066 | validation: 0.22610110879420783]
	TIME [epoch: 10.3 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2122193186377562		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.2122193186377562 | validation: 0.19143369723873066]
	TIME [epoch: 10.3 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18776649985265026		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.18776649985265026 | validation: 0.18389034568704088]
	TIME [epoch: 10.3 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20035499714925215		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.20035499714925215 | validation: 0.2566121487652782]
	TIME [epoch: 10.3 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20630291163283623		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.20630291163283623 | validation: 0.20583111709924246]
	TIME [epoch: 10.3 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1860813138215795		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.1860813138215795 | validation: 0.18581460943576247]
	TIME [epoch: 10.3 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17567847085877736		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.17567847085877736 | validation: 0.22153678935918517]
	TIME [epoch: 10.3 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24765812082633648		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.24765812082633648 | validation: 0.1818590914089164]
	TIME [epoch: 10.3 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19454114580920062		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.19454114580920062 | validation: 0.21154759077693228]
	TIME [epoch: 10.3 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1915574484015225		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.1915574484015225 | validation: 0.18157642032416774]
	TIME [epoch: 10.3 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671541008791493		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.1671541008791493 | validation: 0.24234881050109536]
	TIME [epoch: 10.3 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2054568263449456		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.2054568263449456 | validation: 0.2886378058859749]
	TIME [epoch: 10.3 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19950558342731498		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.19950558342731498 | validation: 0.2308025507696777]
	TIME [epoch: 10.3 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19008403112773653		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.19008403112773653 | validation: 0.20936948311752482]
	TIME [epoch: 10.3 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20194204304856894		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.20194204304856894 | validation: 0.20997049147308702]
	TIME [epoch: 10.3 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1841023628757104		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.1841023628757104 | validation: 0.24767744711296466]
	TIME [epoch: 10.3 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20556459484823889		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.20556459484823889 | validation: 0.2164231347376327]
	TIME [epoch: 10.3 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18919161953479377		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.18919161953479377 | validation: 0.21827679248160498]
	TIME [epoch: 10.3 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183206812706079		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.2183206812706079 | validation: 0.2894167910967444]
	TIME [epoch: 10.3 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20228124648972998		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.20228124648972998 | validation: 0.17643801304420342]
	TIME [epoch: 10.3 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18159181656604728		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.18159181656604728 | validation: 0.21322159944268101]
	TIME [epoch: 10.3 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17750820967227637		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.17750820967227637 | validation: 0.24874474856841203]
	TIME [epoch: 10.3 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22459268002986757		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.22459268002986757 | validation: 0.22633630731162988]
	TIME [epoch: 10.3 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1908376143773078		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.1908376143773078 | validation: 0.2336239429248959]
	TIME [epoch: 10.3 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18205303170569803		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.18205303170569803 | validation: 0.2295422073881003]
	TIME [epoch: 10.3 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19641124594183812		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.19641124594183812 | validation: 0.22912304149390822]
	TIME [epoch: 10.3 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19157172340600914		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.19157172340600914 | validation: 0.1915895488705975]
	TIME [epoch: 10.3 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17640467270931473		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.17640467270931473 | validation: 0.16513190100884384]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_693.pth
	Model improved!!!
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17928254099257235		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.17928254099257235 | validation: 0.17489556361729747]
	TIME [epoch: 10.3 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18134556034240373		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.18134556034240373 | validation: 0.23331955117077585]
	TIME [epoch: 10.3 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19025312151643775		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.19025312151643775 | validation: 0.19518052328529098]
	TIME [epoch: 10.3 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17384296778853053		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.17384296778853053 | validation: 0.21098052598245837]
	TIME [epoch: 10.3 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17414686926615913		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.17414686926615913 | validation: 0.20010949447776458]
	TIME [epoch: 10.3 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1845150476426253		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.1845150476426253 | validation: 0.23141024398944168]
	TIME [epoch: 10.3 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18639868134376997		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.18639868134376997 | validation: 0.16520214865781696]
	TIME [epoch: 10.3 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24787939188693367		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.24787939188693367 | validation: 0.22142921905651888]
	TIME [epoch: 10.3 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24367780443301762		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.24367780443301762 | validation: 0.22523210080251801]
	TIME [epoch: 10.3 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19875819713195936		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.19875819713195936 | validation: 0.17232533588344773]
	TIME [epoch: 10.3 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18041024475709339		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.18041024475709339 | validation: 0.18171232696953488]
	TIME [epoch: 10.3 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18915342333182522		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.18915342333182522 | validation: 0.1887302143939738]
	TIME [epoch: 10.3 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16764799608979009		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.16764799608979009 | validation: 0.20913100213043045]
	TIME [epoch: 10.3 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17397550266811831		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.17397550266811831 | validation: 0.17921976005194096]
	TIME [epoch: 10.3 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17524955216568666		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.17524955216568666 | validation: 0.19028650678013975]
	TIME [epoch: 10.3 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767275583507345		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.1767275583507345 | validation: 0.20523038043158187]
	TIME [epoch: 10.3 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16974525430787105		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.16974525430787105 | validation: 0.1644819031989252]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_710.pth
	Model improved!!!
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17793984464986004		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.17793984464986004 | validation: 0.2054117336978631]
	TIME [epoch: 10.3 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770336316547252		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.1770336316547252 | validation: 0.23169916624939174]
	TIME [epoch: 10.3 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18495093611427124		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.18495093611427124 | validation: 0.20853831272646325]
	TIME [epoch: 10.3 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19198792144995133		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.19198792144995133 | validation: 0.24401507875550874]
	TIME [epoch: 10.3 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2108927992500627		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.2108927992500627 | validation: 0.22910033042398212]
	TIME [epoch: 10.3 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2115693539408928		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.2115693539408928 | validation: 0.18616784450276036]
	TIME [epoch: 10.3 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1660275835391813		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.1660275835391813 | validation: 0.1737419105292387]
	TIME [epoch: 10.3 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16918057471559003		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.16918057471559003 | validation: 0.2489522347182075]
	TIME [epoch: 10.3 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2111872549349559		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.2111872549349559 | validation: 0.1759830018936088]
	TIME [epoch: 10.3 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17184926499845737		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.17184926499845737 | validation: 0.2214735060908827]
	TIME [epoch: 10.3 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20313512071720435		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.20313512071720435 | validation: 0.1929807393949743]
	TIME [epoch: 10.3 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18164824372160582		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.18164824372160582 | validation: 0.19326862036273093]
	TIME [epoch: 10.3 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1965500760922545		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.1965500760922545 | validation: 0.17806086194348025]
	TIME [epoch: 10.3 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17660066666488244		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.17660066666488244 | validation: 0.16751865191826087]
	TIME [epoch: 10.3 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728676264466745		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.1728676264466745 | validation: 0.169881584536924]
	TIME [epoch: 10.3 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.179017901179509		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.179017901179509 | validation: 0.1760662714364875]
	TIME [epoch: 10.3 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16197498643594752		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.16197498643594752 | validation: 0.17341838449828018]
	TIME [epoch: 10.3 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19611328207657136		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.19611328207657136 | validation: 0.18123132736380007]
	TIME [epoch: 10.3 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16888931812974975		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.16888931812974975 | validation: 0.1983107682541722]
	TIME [epoch: 10.3 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19504051878917697		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.19504051878917697 | validation: 0.18307243526711303]
	TIME [epoch: 10.3 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18937633258124212		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.18937633258124212 | validation: 0.17721420899000598]
	TIME [epoch: 10.3 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16682302189640255		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.16682302189640255 | validation: 0.21018416370648002]
	TIME [epoch: 10.3 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21020131556986038		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.21020131556986038 | validation: 0.1761992472610712]
	TIME [epoch: 10.3 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18021395671774929		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.18021395671774929 | validation: 0.21534189623434433]
	TIME [epoch: 10.3 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1964877712013661		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.1964877712013661 | validation: 0.2224944170295726]
	TIME [epoch: 10.3 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17900151349172042		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.17900151349172042 | validation: 0.19983694197448237]
	TIME [epoch: 10.3 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1821344752790957		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.1821344752790957 | validation: 0.15359685623560318]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_737.pth
	Model improved!!!
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16931650765429623		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.16931650765429623 | validation: 0.17497029714434]
	TIME [epoch: 10.3 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21631575557711571		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.21631575557711571 | validation: 0.15812591454534317]
	TIME [epoch: 10.3 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17208314632044094		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.17208314632044094 | validation: 0.2194896596795415]
	TIME [epoch: 10.3 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19423506054142858		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.19423506054142858 | validation: 0.24170003797741893]
	TIME [epoch: 10.3 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934976935491429		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.1934976935491429 | validation: 0.17935522380219276]
	TIME [epoch: 10.3 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18664815750549207		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.18664815750549207 | validation: 0.18026499150368053]
	TIME [epoch: 10.3 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745242464851092		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.1745242464851092 | validation: 0.17466624229196023]
	TIME [epoch: 10.3 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17508117053370253		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.17508117053370253 | validation: 0.17700820240177736]
	TIME [epoch: 10.3 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20902030942090732		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.20902030942090732 | validation: 0.23053644660482564]
	TIME [epoch: 10.3 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18820579836239287		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.18820579836239287 | validation: 0.34930121922849316]
	TIME [epoch: 10.3 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.238051356764963		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.238051356764963 | validation: 0.19151528713359922]
	TIME [epoch: 10.3 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18084363358348907		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.18084363358348907 | validation: 0.19557282896288308]
	TIME [epoch: 10.3 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.178169749802868		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.178169749802868 | validation: 0.16214718682442336]
	TIME [epoch: 10.3 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17919915777160506		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.17919915777160506 | validation: 0.2704134967855729]
	TIME [epoch: 10.3 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20686059047248956		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.20686059047248956 | validation: 0.24084595678999168]
	TIME [epoch: 10.3 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21809229109455117		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.21809229109455117 | validation: 0.20175791636079937]
	TIME [epoch: 10.3 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745488113563083		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.1745488113563083 | validation: 0.2096456508034692]
	TIME [epoch: 10.3 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19444128918081352		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.19444128918081352 | validation: 0.18527959896601037]
	TIME [epoch: 10.3 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17247293070100467		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.17247293070100467 | validation: 0.19841581249086346]
	TIME [epoch: 10.3 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19377280982275188		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.19377280982275188 | validation: 0.1760759549546143]
	TIME [epoch: 10.3 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605479238853		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.1605479238853 | validation: 0.16323484272792727]
	TIME [epoch: 10.3 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17093402602112667		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.17093402602112667 | validation: 0.19840198377825535]
	TIME [epoch: 10.3 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16048386231772588		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.16048386231772588 | validation: 0.17903134645455807]
	TIME [epoch: 10.3 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582469901595274		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.1582469901595274 | validation: 0.17028971698242726]
	TIME [epoch: 10.3 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16558810039073754		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.16558810039073754 | validation: 0.18146849061249015]
	TIME [epoch: 10.3 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21158137293988802		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.21158137293988802 | validation: 0.18481365801079072]
	TIME [epoch: 10.3 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1830515042837754		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.1830515042837754 | validation: 0.20333664844058877]
	TIME [epoch: 10.3 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17695708446324976		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.17695708446324976 | validation: 0.17902640704832493]
	TIME [epoch: 10.3 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596168533954439		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.1596168533954439 | validation: 0.1581910465134502]
	TIME [epoch: 10.3 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20279016026797825		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.20279016026797825 | validation: 0.2612497826716242]
	TIME [epoch: 10.3 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2028532855771477		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.2028532855771477 | validation: 0.17897067430160932]
	TIME [epoch: 10.3 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21612120288134692		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.21612120288134692 | validation: 0.17389130765548128]
	TIME [epoch: 10.3 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18277956741780027		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.18277956741780027 | validation: 0.16974473343031712]
	TIME [epoch: 10.3 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698186244399152		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.1698186244399152 | validation: 0.1795144243195977]
	TIME [epoch: 10.3 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18540677031810723		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.18540677031810723 | validation: 0.1919161002975146]
	TIME [epoch: 10.3 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17472291830474745		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.17472291830474745 | validation: 0.1677424586972984]
	TIME [epoch: 10.3 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15968318906045584		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.15968318906045584 | validation: 0.1534305285581143]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_774.pth
	Model improved!!!
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16153195360159808		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.16153195360159808 | validation: 0.18516562878817286]
	TIME [epoch: 10.3 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18496689548887715		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.18496689548887715 | validation: 0.17195122445708996]
	TIME [epoch: 10.3 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035145267984866		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.16035145267984866 | validation: 0.19514649516299074]
	TIME [epoch: 10.3 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24242995400174316		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.24242995400174316 | validation: 0.18222329772532675]
	TIME [epoch: 10.3 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16083327191066324		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.16083327191066324 | validation: 0.20584390602149172]
	TIME [epoch: 10.3 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19664345341954811		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.19664345341954811 | validation: 0.17203868662779292]
	TIME [epoch: 10.3 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577049381939702		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.1577049381939702 | validation: 0.17287944263419372]
	TIME [epoch: 10.3 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.188138229097032		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.188138229097032 | validation: 0.27674210064446614]
	TIME [epoch: 10.3 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2607100644767151		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.2607100644767151 | validation: 0.21024333467044762]
	TIME [epoch: 10.3 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672514772828702		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.1672514772828702 | validation: 0.20052177016922998]
	TIME [epoch: 10.3 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20249662876581892		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.20249662876581892 | validation: 0.17595061955421162]
	TIME [epoch: 10.3 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17729110632329861		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.17729110632329861 | validation: 0.17000260434549908]
	TIME [epoch: 10.3 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16985377544806912		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.16985377544806912 | validation: 0.16280024909430946]
	TIME [epoch: 10.3 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16518892267651972		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.16518892267651972 | validation: 0.18396216118803538]
	TIME [epoch: 10.3 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16390233285217554		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.16390233285217554 | validation: 0.17202999312210818]
	TIME [epoch: 10.3 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18112548588295455		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.18112548588295455 | validation: 0.16725002817469087]
	TIME [epoch: 10.3 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18029559071123819		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.18029559071123819 | validation: 0.19361479978855817]
	TIME [epoch: 10.3 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16614147924659414		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.16614147924659414 | validation: 0.17095018468209147]
	TIME [epoch: 10.3 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18281325073952345		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.18281325073952345 | validation: 0.2271663719688244]
	TIME [epoch: 10.3 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16845136035657524		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.16845136035657524 | validation: 0.18624903620361455]
	TIME [epoch: 10.3 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611692400383681		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.1611692400383681 | validation: 0.21732984502717276]
	TIME [epoch: 10.3 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22187484832598048		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.22187484832598048 | validation: 0.18975679654068855]
	TIME [epoch: 10.3 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16158499272456725		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.16158499272456725 | validation: 0.1883183437275966]
	TIME [epoch: 10.3 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15777042753405482		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.15777042753405482 | validation: 0.16787992417022604]
	TIME [epoch: 10.3 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15717273031410617		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.15717273031410617 | validation: 0.18369674599088534]
	TIME [epoch: 10.3 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20235493526005927		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.20235493526005927 | validation: 0.1974730177872242]
	TIME [epoch: 10.3 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18171408495486507		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.18171408495486507 | validation: 0.16539451982697512]
	TIME [epoch: 10.3 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535298030971586		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.1535298030971586 | validation: 0.1827196021221695]
	TIME [epoch: 10.3 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19547940545379283		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.19547940545379283 | validation: 0.2213726783109646]
	TIME [epoch: 10.3 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1949959877873057		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.1949959877873057 | validation: 0.18592892836003366]
	TIME [epoch: 10.3 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17324216412197987		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.17324216412197987 | validation: 0.18435647462528856]
	TIME [epoch: 10.3 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.192006623212357		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.192006623212357 | validation: 0.19790211233650162]
	TIME [epoch: 10.3 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17781923249902665		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.17781923249902665 | validation: 0.16897467696413046]
	TIME [epoch: 10.3 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16979993786300318		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.16979993786300318 | validation: 0.19246472063835096]
	TIME [epoch: 10.3 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18629322653190847		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.18629322653190847 | validation: 0.1883265767637485]
	TIME [epoch: 10.3 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18173964401333104		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.18173964401333104 | validation: 0.1894460104712846]
	TIME [epoch: 10.3 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17521264274516474		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.17521264274516474 | validation: 0.17371263586116562]
	TIME [epoch: 10.3 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15333365479688657		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.15333365479688657 | validation: 0.16480158432458689]
	TIME [epoch: 10.3 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638958193579626		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.1638958193579626 | validation: 0.16063350075066515]
	TIME [epoch: 10.3 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16719613301822403		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.16719613301822403 | validation: 0.19229879008936948]
	TIME [epoch: 10.3 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17489398965449526		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.17489398965449526 | validation: 0.16554404695797156]
	TIME [epoch: 10.3 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1677129785517727		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.1677129785517727 | validation: 0.16258394554403377]
	TIME [epoch: 10.3 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1743163723748709		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.1743163723748709 | validation: 0.16065986321832285]
	TIME [epoch: 10.3 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16388624473458338		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.16388624473458338 | validation: 0.16421770001877817]
	TIME [epoch: 10.3 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17281933572535269		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.17281933572535269 | validation: 0.2504091633833629]
	TIME [epoch: 10.3 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24624416774496316		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.24624416774496316 | validation: 0.198678983216568]
	TIME [epoch: 10.3 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16654866552154304		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.16654866552154304 | validation: 0.18834908355634425]
	TIME [epoch: 10.3 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16841738003775966		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.16841738003775966 | validation: 0.15142679708905238]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_822.pth
	Model improved!!!
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15848167029144372		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.15848167029144372 | validation: 0.14715198555440076]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_823.pth
	Model improved!!!
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16997498135136582		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.16997498135136582 | validation: 0.16380674888946054]
	TIME [epoch: 10.3 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15200142832236763		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.15200142832236763 | validation: 0.1679871383173941]
	TIME [epoch: 10.3 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16892704406050663		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.16892704406050663 | validation: 0.18127796563247003]
	TIME [epoch: 10.3 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16166821393138736		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.16166821393138736 | validation: 0.16921105692099025]
	TIME [epoch: 10.3 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15824964187271634		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.15824964187271634 | validation: 0.1659741447335987]
	TIME [epoch: 10.3 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550169011089348		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.1550169011089348 | validation: 0.1661904635109844]
	TIME [epoch: 10.3 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16446603310723348		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.16446603310723348 | validation: 0.17135276790475906]
	TIME [epoch: 10.3 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598387835429163		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.1598387835429163 | validation: 0.1724642587870632]
	TIME [epoch: 10.3 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15728115733446993		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.15728115733446993 | validation: 0.17430186939830883]
	TIME [epoch: 10.3 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16125437618619046		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.16125437618619046 | validation: 0.17397916459392013]
	TIME [epoch: 10.3 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840202948393256		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.1840202948393256 | validation: 0.19240929475850088]
	TIME [epoch: 10.3 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1685689061385491		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.1685689061385491 | validation: 0.185289735918348]
	TIME [epoch: 10.3 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17699090394922562		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.17699090394922562 | validation: 0.16879923044902484]
	TIME [epoch: 10.3 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16263516691474372		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.16263516691474372 | validation: 0.17051312887174208]
	TIME [epoch: 10.3 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17464580374436367		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.17464580374436367 | validation: 0.18356533804363673]
	TIME [epoch: 10.3 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18279104209076427		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.18279104209076427 | validation: 0.16096315918699897]
	TIME [epoch: 10.3 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549112767375856		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.15549112767375856 | validation: 0.22005594188138625]
	TIME [epoch: 10.3 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19279735134816417		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.19279735134816417 | validation: 0.1707905407582192]
	TIME [epoch: 10.3 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16725579924663464		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.16725579924663464 | validation: 0.18769231647475557]
	TIME [epoch: 10.3 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16398646537142747		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.16398646537142747 | validation: 0.173486742310955]
	TIME [epoch: 10.3 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15937714427680966		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.15937714427680966 | validation: 0.22264144211681675]
	TIME [epoch: 10.3 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19119645795601		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.19119645795601 | validation: 0.19574795680093168]
	TIME [epoch: 10.3 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18037505300149168		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.18037505300149168 | validation: 0.19102310031006908]
	TIME [epoch: 10.3 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16303986817761987		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.16303986817761987 | validation: 0.18158232553496967]
	TIME [epoch: 10.3 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17247165007911597		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.17247165007911597 | validation: 0.18442570165833014]
	TIME [epoch: 10.3 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18767190525991437		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.18767190525991437 | validation: 0.23603290496461354]
	TIME [epoch: 10.3 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21992568901952397		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.21992568901952397 | validation: 0.17835467471571206]
	TIME [epoch: 10.3 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16008809636377072		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.16008809636377072 | validation: 0.1787684937365878]
	TIME [epoch: 10.3 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17677779084183157		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.17677779084183157 | validation: 0.1898810137583958]
	TIME [epoch: 10.3 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18035437652803982		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.18035437652803982 | validation: 0.1622889060371929]
	TIME [epoch: 10.3 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17422236715749218		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.17422236715749218 | validation: 0.19511705801481824]
	TIME [epoch: 10.3 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16472829315828433		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.16472829315828433 | validation: 0.17164559807640273]
	TIME [epoch: 10.3 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16168718934993942		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.16168718934993942 | validation: 0.2142272670294716]
	TIME [epoch: 10.3 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17514533018304346		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.17514533018304346 | validation: 0.16431782807619122]
	TIME [epoch: 10.3 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1631693618844281		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.1631693618844281 | validation: 0.19484512963273098]
	TIME [epoch: 10.3 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698212339829		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.1698212339829 | validation: 0.15849958755813165]
	TIME [epoch: 10.3 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16782153136581288		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.16782153136581288 | validation: 0.17997163071925734]
	TIME [epoch: 10.3 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16394845057006716		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.16394845057006716 | validation: 0.17052555372702358]
	TIME [epoch: 10.3 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15574925747704235		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.15574925747704235 | validation: 0.15469769341988124]
	TIME [epoch: 10.3 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17680459904560433		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.17680459904560433 | validation: 0.20596436276043562]
	TIME [epoch: 10.3 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742919135485169		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.1742919135485169 | validation: 0.1775857306713717]
	TIME [epoch: 10.3 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15479760824089356		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.15479760824089356 | validation: 0.1750846991917821]
	TIME [epoch: 10.3 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16820602402174872		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.16820602402174872 | validation: 0.16303746156006654]
	TIME [epoch: 10.3 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15003037484900394		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.15003037484900394 | validation: 0.18286739506782446]
	TIME [epoch: 10.3 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16854920771816712		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.16854920771816712 | validation: 0.1664998603191285]
	TIME [epoch: 10.3 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.171349405838804		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.171349405838804 | validation: 0.17642314789493363]
	TIME [epoch: 10.3 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15625765619077203		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.15625765619077203 | validation: 0.16500678957206372]
	TIME [epoch: 10.3 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16744481517685333		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.16744481517685333 | validation: 0.16595252626227347]
	TIME [epoch: 10.3 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15935921852801238		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.15935921852801238 | validation: 0.18670362367281648]
	TIME [epoch: 10.3 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.178435247349471		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.178435247349471 | validation: 0.1700577910261569]
	TIME [epoch: 10.3 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15826338779604227		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.15826338779604227 | validation: 0.1720689985823935]
	TIME [epoch: 10.3 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793236471509277		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.1793236471509277 | validation: 0.2264045563671263]
	TIME [epoch: 10.3 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17400806469996244		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.17400806469996244 | validation: 0.17848660895267707]
	TIME [epoch: 10.3 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553515894644055		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.1553515894644055 | validation: 0.16076736038272949]
	TIME [epoch: 10.3 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16335840634874893		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.16335840634874893 | validation: 0.1816130441498082]
	TIME [epoch: 10.3 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16419460812528236		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.16419460812528236 | validation: 0.17368274391935562]
	TIME [epoch: 10.2 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582127128344311		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.1582127128344311 | validation: 0.23140884350312427]
	TIME [epoch: 10.2 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20330446915850692		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.20330446915850692 | validation: 0.1971502014054571]
	TIME [epoch: 10.2 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17441747592441062		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.17441747592441062 | validation: 0.16404621409587222]
	TIME [epoch: 10.2 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15853526462845716		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.15853526462845716 | validation: 0.15690252244158664]
	TIME [epoch: 10.2 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15711180207009304		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.15711180207009304 | validation: 0.16795378753660126]
	TIME [epoch: 10.2 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1574357261716403		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.1574357261716403 | validation: 0.16795111531661655]
	TIME [epoch: 10.3 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.176078714189271		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.176078714189271 | validation: 0.2020989310202552]
	TIME [epoch: 10.2 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17794217954416114		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.17794217954416114 | validation: 0.18915091965286263]
	TIME [epoch: 10.2 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16325135108560876		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.16325135108560876 | validation: 0.14743737596414477]
	TIME [epoch: 10.2 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15155092036512072		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.15155092036512072 | validation: 0.1634276174810281]
	TIME [epoch: 10.2 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646798653354205		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.15646798653354205 | validation: 0.16463112201363686]
	TIME [epoch: 10.2 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15634817992856198		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.15634817992856198 | validation: 0.16906659866166274]
	TIME [epoch: 10.2 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532176829693728		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.1532176829693728 | validation: 0.16264326757194178]
	TIME [epoch: 10.2 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15083809160667563		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.15083809160667563 | validation: 0.15317776201947264]
	TIME [epoch: 10.2 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17129408413647151		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.17129408413647151 | validation: 0.19181103759219528]
	TIME [epoch: 10.2 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15458153327291227		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.15458153327291227 | validation: 0.15139329446526298]
	TIME [epoch: 10.2 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15783361139200627		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.15783361139200627 | validation: 0.16689774397248078]
	TIME [epoch: 10.2 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596435768256627		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.1596435768256627 | validation: 0.16944486119409824]
	TIME [epoch: 10.2 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15669442609464454		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.15669442609464454 | validation: 0.15152702026766818]
	TIME [epoch: 10.2 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15399486979615254		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.15399486979615254 | validation: 0.16671057587543367]
	TIME [epoch: 10.2 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15660897632002294		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.15660897632002294 | validation: 0.1617409241662595]
	TIME [epoch: 10.2 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549243702584167		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.1549243702584167 | validation: 0.20149225121200323]
	TIME [epoch: 10.2 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18395513960999085		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.18395513960999085 | validation: 0.19669581251604293]
	TIME [epoch: 10.2 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626177115083604		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.1626177115083604 | validation: 0.17082116685917542]
	TIME [epoch: 10.2 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15983648272081685		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.15983648272081685 | validation: 0.1981672722776663]
	TIME [epoch: 10.2 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1786230898105745		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.1786230898105745 | validation: 0.19135892447518862]
	TIME [epoch: 10.2 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17059958539737852		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.17059958539737852 | validation: 0.20746652943412136]
	TIME [epoch: 10.2 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18446283305726216		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.18446283305726216 | validation: 0.1718465925233579]
	TIME [epoch: 10.2 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15572343654485615		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.15572343654485615 | validation: 0.15165246493582973]
	TIME [epoch: 10.2 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.156207643125525		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.156207643125525 | validation: 0.16574263002535908]
	TIME [epoch: 10.2 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15854753783058004		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.15854753783058004 | validation: 0.15179297674723718]
	TIME [epoch: 10.2 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16153156298163474		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.16153156298163474 | validation: 0.1887681405440858]
	TIME [epoch: 10.2 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16491691915935697		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.16491691915935697 | validation: 0.14271953351391792]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_912.pth
	Model improved!!!
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604164070182764		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.1604164070182764 | validation: 0.18959168129031004]
	TIME [epoch: 10.2 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19062905656913792		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.19062905656913792 | validation: 0.1686237367751943]
	TIME [epoch: 10.2 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15318515407049285		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.15318515407049285 | validation: 0.16868797071800246]
	TIME [epoch: 10.2 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570066558460444		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.1570066558460444 | validation: 0.17683657728333843]
	TIME [epoch: 10.2 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15658984763907458		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.15658984763907458 | validation: 0.1731164570399163]
	TIME [epoch: 10.2 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16510908616529527		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.16510908616529527 | validation: 0.17622998955259506]
	TIME [epoch: 10.2 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17822873285023877		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.17822873285023877 | validation: 0.20062543693303553]
	TIME [epoch: 10.2 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16574324957625475		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.16574324957625475 | validation: 0.1668446683855612]
	TIME [epoch: 10.2 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14984410047313265		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.14984410047313265 | validation: 0.1659506743993692]
	TIME [epoch: 10.3 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1453394334658028		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.1453394334658028 | validation: 0.16281202804899828]
	TIME [epoch: 10.2 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16247902994918034		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.16247902994918034 | validation: 0.15597317921237355]
	TIME [epoch: 10.2 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17240306017107215		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.17240306017107215 | validation: 0.17172343238773352]
	TIME [epoch: 10.2 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15950050710596883		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.15950050710596883 | validation: 0.15464907608870823]
	TIME [epoch: 10.2 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17081021665514143		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.17081021665514143 | validation: 0.24335691806964854]
	TIME [epoch: 10.2 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20199859544404428		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.20199859544404428 | validation: 0.16781740723444144]
	TIME [epoch: 10.2 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15425575333024966		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.15425575333024966 | validation: 0.157001271862033]
	TIME [epoch: 10.2 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14972087815880442		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.14972087815880442 | validation: 0.16486956116366538]
	TIME [epoch: 10.2 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14893212520410418		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.14893212520410418 | validation: 0.15764870303318806]
	TIME [epoch: 10.2 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15105919144048136		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.15105919144048136 | validation: 0.2051248591022129]
	TIME [epoch: 10.2 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2141830575012568		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.2141830575012568 | validation: 0.22280029736716156]
	TIME [epoch: 10.2 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771800539099825		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.1771800539099825 | validation: 0.1641175155154577]
	TIME [epoch: 10.2 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15884903819676982		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.15884903819676982 | validation: 0.15448052217035177]
	TIME [epoch: 10.2 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17207932756385513		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.17207932756385513 | validation: 0.22625771697278554]
	TIME [epoch: 10.2 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1989839618501123		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.1989839618501123 | validation: 0.15311728870524874]
	TIME [epoch: 10.2 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15495485182429183		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.15495485182429183 | validation: 0.16651775710068215]
	TIME [epoch: 10.2 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16266630499802587		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.16266630499802587 | validation: 0.18142951574851707]
	TIME [epoch: 10.2 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14935577992391955		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.14935577992391955 | validation: 0.1639759941692562]
	TIME [epoch: 10.2 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886916502699546		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.14886916502699546 | validation: 0.1527515195169595]
	TIME [epoch: 10.2 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17573644783239634		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.17573644783239634 | validation: 0.19300687388698742]
	TIME [epoch: 10.2 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16497971513809975		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.16497971513809975 | validation: 0.16174174977482625]
	TIME [epoch: 10.2 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15148987074739856		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.15148987074739856 | validation: 0.1518628729026128]
	TIME [epoch: 10.2 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16416916956777888		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.16416916956777888 | validation: 0.1794352768248285]
	TIME [epoch: 10.2 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16456143021199515		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.16456143021199515 | validation: 0.15905467013241276]
	TIME [epoch: 10.2 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651269824219173		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.1651269824219173 | validation: 0.19153858775591162]
	TIME [epoch: 10.2 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17575237436178034		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.17575237436178034 | validation: 0.16231297773900227]
	TIME [epoch: 10.2 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492340494633802		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.1492340494633802 | validation: 0.15748313085900578]
	TIME [epoch: 10.2 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14807766707172373		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.14807766707172373 | validation: 0.17204971522589424]
	TIME [epoch: 10.2 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288103398223237		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.17288103398223237 | validation: 0.1609678232995628]
	TIME [epoch: 10.2 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1506091692308313		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.1506091692308313 | validation: 0.15447715242128482]
	TIME [epoch: 10.2 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14786881364601903		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.14786881364601903 | validation: 0.16311921053363532]
	TIME [epoch: 10.2 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530166487361237		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.1530166487361237 | validation: 0.1601657675150724]
	TIME [epoch: 10.2 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15817782824649568		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.15817782824649568 | validation: 0.169524856783108]
	TIME [epoch: 10.2 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15849760915962274		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.15849760915962274 | validation: 0.1763470229446331]
	TIME [epoch: 10.2 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16256431579729338		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.16256431579729338 | validation: 0.16360882911077518]
	TIME [epoch: 10.3 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554859477828779		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.1554859477828779 | validation: 0.15989138261329267]
	TIME [epoch: 10.2 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14793317013795387		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.14793317013795387 | validation: 0.15707241878438974]
	TIME [epoch: 10.2 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.154827956686369		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.154827956686369 | validation: 0.15813553276708484]
	TIME [epoch: 10.2 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560122441460483		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.1560122441460483 | validation: 0.17974433132627896]
	TIME [epoch: 10.2 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512491792176607		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.1512491792176607 | validation: 0.17669469497376702]
	TIME [epoch: 10.2 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15627581551631434		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.15627581551631434 | validation: 0.16606494040108277]
	TIME [epoch: 10.2 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15706970644926097		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.15706970644926097 | validation: 0.1753081690026447]
	TIME [epoch: 10.2 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16233248623825555		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.16233248623825555 | validation: 0.18346963266456592]
	TIME [epoch: 10.2 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16269418542222489		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.16269418542222489 | validation: 0.1792533829275474]
	TIME [epoch: 10.2 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626813576072075		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.1626813576072075 | validation: 0.1448689249006486]
	TIME [epoch: 10.2 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14766775484457137		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.14766775484457137 | validation: 0.1424603750001049]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240217_161441/states/model_tr_study6_967.pth
	Model improved!!!
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14694402590238087		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.14694402590238087 | validation: 0.15514906251475755]
	TIME [epoch: 10.2 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514416564541538		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.1514416564541538 | validation: 0.17233068234713952]
	TIME [epoch: 10.2 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14994551530889655		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.14994551530889655 | validation: 0.17493091017481313]
	TIME [epoch: 10.2 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1635175619714781		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.1635175619714781 | validation: 0.20521932700731113]
	TIME [epoch: 10.2 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1774242519574892		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.1774242519574892 | validation: 0.20964150798418502]
	TIME [epoch: 10.2 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18719019274298881		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.18719019274298881 | validation: 0.15910897847902333]
	TIME [epoch: 10.2 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15477342592875654		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.15477342592875654 | validation: 0.15815048981431865]
	TIME [epoch: 10.2 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580651453826552		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.1580651453826552 | validation: 0.1614123198761613]
	TIME [epoch: 10.2 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581778183630222		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.1581778183630222 | validation: 0.16787090716281866]
	TIME [epoch: 10.2 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563753559450603		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.1563753559450603 | validation: 0.16987349433983867]
	TIME [epoch: 10.2 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562959728724475		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.1562959728724475 | validation: 0.16333827869377646]
	TIME [epoch: 10.3 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1463615518682639		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.1463615518682639 | validation: 0.160283351673477]
	TIME [epoch: 10.2 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14388066920997067		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.14388066920997067 | validation: 0.1661028036609383]
	TIME [epoch: 10.2 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517423553296337		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.1517423553296337 | validation: 0.16593651539604978]
	TIME [epoch: 10.2 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528263229383205		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.1528263229383205 | validation: 0.15432212535183806]
	TIME [epoch: 10.2 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522842175685027		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.1522842175685027 | validation: 0.15428850471715083]
	TIME [epoch: 10.2 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15650816175059526		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.15650816175059526 | validation: 0.15802155861171593]
	TIME [epoch: 10.2 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16548782774505438		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.16548782774505438 | validation: 0.19091015334043743]
	TIME [epoch: 10.2 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16340568208207568		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.16340568208207568 | validation: 0.16639355701620936]
	TIME [epoch: 10.2 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594455953286865		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.1594455953286865 | validation: 0.1607877863361133]
	TIME [epoch: 10.2 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16385422561915133		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.16385422561915133 | validation: 0.16930653948203728]
	TIME [epoch: 10.2 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495214538693621		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.1495214538693621 | validation: 0.14541307869918402]
	TIME [epoch: 10.2 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14662530654464487		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.14662530654464487 | validation: 0.16692385378104746]
	TIME [epoch: 10.2 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15552876208983638		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.15552876208983638 | validation: 0.1642921617249653]
	TIME [epoch: 10.2 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549291103709345		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.15549291103709345 | validation: 0.1558583314690717]
	TIME [epoch: 10.2 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15268307868233238		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.15268307868233238 | validation: 0.1538495804369666]
	TIME [epoch: 10.2 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512032701971148		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.1512032701971148 | validation: 0.1511848257480154]
	TIME [epoch: 10.2 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15445395048940508		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.15445395048940508 | validation: 0.16416929366587632]
	TIME [epoch: 10.2 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14727488477209075		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.14727488477209075 | validation: 0.15728880900256972]
	TIME [epoch: 10.2 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495455840706663		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.1495455840706663 | validation: 0.14947995667315753]
	TIME [epoch: 10.2 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15125751453504108		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.15125751453504108 | validation: 0.15809214880539588]
	TIME [epoch: 10.2 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.14799388295763025		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.14799388295763025 | validation: 0.1742857651457186]
	TIME [epoch: 10.2 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609153525396409		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.1609153525396409 | validation: 0.15530132348456496]
	TIME [epoch: 10.2 sec]
Finished training in 10387.605 seconds.
