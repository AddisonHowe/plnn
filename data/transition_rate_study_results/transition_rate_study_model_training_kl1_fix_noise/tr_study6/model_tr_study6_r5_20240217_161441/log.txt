Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2379711698

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.2897390046092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.2897390046092 | validation: 9.344120842467445]
	TIME [epoch: 71.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.905466139027084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.905466139027084 | validation: 8.833318562667166]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.145090725783362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.145090725783362 | validation: 8.131510104958007]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.871043880910037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.871043880910037 | validation: 8.054052037789177]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.613310291819959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.613310291819959 | validation: 7.793580080691486]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.302151675089834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.302151675089834 | validation: 8.114958314644664]
	TIME [epoch: 10.3 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.351382840768809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.351382840768809 | validation: 7.870702365861969]
	TIME [epoch: 10.3 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.969593558145624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.969593558145624 | validation: 7.358688135195482]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.831847663946215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.831847663946215 | validation: 7.5848185515262685]
	TIME [epoch: 10.3 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.733770326796764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.733770326796764 | validation: 7.134427728280914]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.570074973043447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.570074973043447 | validation: 7.090045236326103]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6125195991528845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6125195991528845 | validation: 7.066535096578323]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.607449543882103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.607449543882103 | validation: 7.076820959558501]
	TIME [epoch: 10.3 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.528228499957666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.528228499957666 | validation: 7.061776814853052]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.473897434190571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.473897434190571 | validation: 6.608766158139968]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.590424282199628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.590424282199628 | validation: 7.08701308190077]
	TIME [epoch: 10.3 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.158058525417652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.158058525417652 | validation: 6.3906171652271535]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.024199775605361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.024199775605361 | validation: 6.4515946487467275]
	TIME [epoch: 10.3 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.017123623760073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.017123623760073 | validation: 6.88246368927652]
	TIME [epoch: 10.3 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.877541672558424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.877541672558424 | validation: 6.85513182308868]
	TIME [epoch: 10.3 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.807001125763616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.807001125763616 | validation: 6.564277290152416]
	TIME [epoch: 10.3 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.201344726080203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.201344726080203 | validation: 7.106352236875839]
	TIME [epoch: 10.3 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.940968901787482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.940968901787482 | validation: 10.084783427148663]
	TIME [epoch: 10.3 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.747007154336723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.747007154336723 | validation: 7.5483782829042]
	TIME [epoch: 10.3 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.0356696319318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0356696319318 | validation: 6.9397025959989875]
	TIME [epoch: 10.3 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.865558014188499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.865558014188499 | validation: 7.192276975299401]
	TIME [epoch: 10.3 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.654496626920018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.654496626920018 | validation: 7.6145823223923905]
	TIME [epoch: 10.3 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.285830378941325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.285830378941325 | validation: 7.273043589016279]
	TIME [epoch: 10.3 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.02745749040195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.02745749040195 | validation: 6.999620666978049]
	TIME [epoch: 10.3 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.50469508147957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.50469508147957 | validation: 6.69900012118113]
	TIME [epoch: 10.3 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.004538247719153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.004538247719153 | validation: 6.474088977811594]
	TIME [epoch: 10.3 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.719009399499216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.719009399499216 | validation: 6.494324817707401]
	TIME [epoch: 10.3 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.685039037959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.685039037959 | validation: 6.558676200985966]
	TIME [epoch: 10.3 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.325170973111602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.325170973111602 | validation: 7.239671749265372]
	TIME [epoch: 10.3 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.380535963062545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.380535963062545 | validation: 6.789404277207021]
	TIME [epoch: 10.3 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.202111981508902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.202111981508902 | validation: 6.504644201266753]
	TIME [epoch: 10.6 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.007417114023658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.007417114023658 | validation: 6.695179920980374]
	TIME [epoch: 10.3 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.804658553610686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.804658553610686 | validation: 6.427124537117315]
	TIME [epoch: 10.3 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.265732558994488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.265732558994488 | validation: 6.744217766060981]
	TIME [epoch: 10.3 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.738470848520895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.738470848520895 | validation: 6.746635062914603]
	TIME [epoch: 10.3 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.034944180053072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.034944180053072 | validation: 6.475717785820286]
	TIME [epoch: 10.3 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.8671697584418565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8671697584418565 | validation: 6.324961247344898]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.707483623825241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.707483623825241 | validation: 6.373107319562731]
	TIME [epoch: 10.3 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.7236277352737215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7236277352737215 | validation: 7.2606384959299275]
	TIME [epoch: 10.3 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.063068697417319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.063068697417319 | validation: 6.58037617434675]
	TIME [epoch: 10.3 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.6423024873441765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6423024873441765 | validation: 6.6187235615212]
	TIME [epoch: 10.3 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.409676566863398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.409676566863398 | validation: 6.924477243655042]
	TIME [epoch: 10.3 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.002075040860349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.002075040860349 | validation: 6.837821179397556]
	TIME [epoch: 10.3 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.124359672315734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.124359672315734 | validation: 6.640966488835268]
	TIME [epoch: 10.3 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.360850289517276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.360850289517276 | validation: 6.752172326871275]
	TIME [epoch: 10.3 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.838597955193348		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 5.838597955193348 | validation: 7.217625138026379]
	TIME [epoch: 10.3 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.788613357783956		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 5.788613357783956 | validation: 6.479326990002901]
	TIME [epoch: 10.3 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.710746382987143		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 5.710746382987143 | validation: 6.576215146270129]
	TIME [epoch: 10.3 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.6722177481482206		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 5.6722177481482206 | validation: 6.413952131399949]
	TIME [epoch: 10.3 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.576194754588143		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 5.576194754588143 | validation: 6.493808130362562]
	TIME [epoch: 10.3 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.808896312402268		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 5.808896312402268 | validation: 6.921562898977112]
	TIME [epoch: 10.3 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.888491723470771		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 5.888491723470771 | validation: 7.0627280574426345]
	TIME [epoch: 10.3 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.991764994163626		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 5.991764994163626 | validation: 7.867814853567804]
	TIME [epoch: 10.3 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.40354258501552		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 6.40354258501552 | validation: 6.583687189171934]
	TIME [epoch: 10.3 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.491773610154668		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 6.491773610154668 | validation: 6.499853902976749]
	TIME [epoch: 10.3 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.763097364199682		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 5.763097364199682 | validation: 6.506446635538167]
	TIME [epoch: 10.3 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.704398570201579		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 5.704398570201579 | validation: 6.270067702744789]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.526448152865161		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 5.526448152865161 | validation: 6.414299824956218]
	TIME [epoch: 10.3 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.443147427263308		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 6.443147427263308 | validation: 7.3462784339755345]
	TIME [epoch: 10.3 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.745895306047909		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 5.745895306047909 | validation: 6.330451126367337]
	TIME [epoch: 10.3 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.522035033524989		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 5.522035033524989 | validation: 7.395850857716783]
	TIME [epoch: 10.3 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.203543333777435		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 6.203543333777435 | validation: 6.368797440696585]
	TIME [epoch: 10.3 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.835318644752874		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 6.835318644752874 | validation: 6.9222664566683525]
	TIME [epoch: 10.3 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3399995506658815		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.3399995506658815 | validation: 6.406514000027711]
	TIME [epoch: 10.3 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.865042897748099		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 5.865042897748099 | validation: 6.794276386190543]
	TIME [epoch: 10.3 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.147347077804912		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 6.147347077804912 | validation: 6.451153417976851]
	TIME [epoch: 10.3 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.398212206362677		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 5.398212206362677 | validation: 6.946672427261854]
	TIME [epoch: 10.3 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.7684979244772965		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.7684979244772965 | validation: 6.580857485096667]
	TIME [epoch: 10.3 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.576116257656812		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 5.576116257656812 | validation: 6.387991410497098]
	TIME [epoch: 10.3 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.733546995415569		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 5.733546995415569 | validation: 6.525487847140487]
	TIME [epoch: 10.3 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.523482854351446		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 5.523482854351446 | validation: 6.648290544099711]
	TIME [epoch: 10.3 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.546374759123124		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 6.546374759123124 | validation: 6.306375438318039]
	TIME [epoch: 10.3 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.348922654634232		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 5.348922654634232 | validation: 6.442609356865999]
	TIME [epoch: 10.3 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.451039157016929		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 5.451039157016929 | validation: 6.518189801287747]
	TIME [epoch: 10.3 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.720482885834349		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 5.720482885834349 | validation: 6.798545121398546]
	TIME [epoch: 10.3 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.495418165257458		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 5.495418165257458 | validation: 7.565746482981986]
	TIME [epoch: 10.3 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.134436421892277		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 6.134436421892277 | validation: 6.350392526820382]
	TIME [epoch: 10.3 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.658019504472603		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 5.658019504472603 | validation: 6.418046153862725]
	TIME [epoch: 10.3 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.402212039637872		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 5.402212039637872 | validation: 6.264285412130605]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.592950860514093		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 5.592950860514093 | validation: 6.462043186272129]
	TIME [epoch: 10.3 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.0925558841424445		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 6.0925558841424445 | validation: 6.589017962427148]
	TIME [epoch: 10.3 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.6504443411209		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 5.6504443411209 | validation: 6.484701540103647]
	TIME [epoch: 10.3 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.448043749094862		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 5.448043749094862 | validation: 7.180885280189439]
	TIME [epoch: 10.3 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.020923610852632		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 6.020923610852632 | validation: 6.551841291497761]
	TIME [epoch: 10.3 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.56368487102602		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 6.56368487102602 | validation: 6.924483650516444]
	TIME [epoch: 10.3 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.940253956232257		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 5.940253956232257 | validation: 6.61811744947508]
	TIME [epoch: 10.3 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.463845516610722		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 5.463845516610722 | validation: 6.367134569347491]
	TIME [epoch: 10.3 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.317497865296794		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 5.317497865296794 | validation: 6.234345445888924]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.545124157940465		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 5.545124157940465 | validation: 6.411244927748929]
	TIME [epoch: 10.3 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.586308664158976		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 5.586308664158976 | validation: 6.398332697239924]
	TIME [epoch: 10.3 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.368324760003807		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 5.368324760003807 | validation: 6.631402145529444]
	TIME [epoch: 10.3 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.17837875195646		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 6.17837875195646 | validation: 6.450354738293763]
	TIME [epoch: 10.3 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.416216240982953		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 5.416216240982953 | validation: 6.424466038144114]
	TIME [epoch: 10.3 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.425065293932969		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 5.425065293932969 | validation: 6.38768361020394]
	TIME [epoch: 10.3 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.698625833153924		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 5.698625833153924 | validation: 7.069334813455752]
	TIME [epoch: 10.3 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.327887913409947		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 6.327887913409947 | validation: 6.869011368435497]
	TIME [epoch: 10.3 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.544919478710083		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 5.544919478710083 | validation: 6.361658288568899]
	TIME [epoch: 10.3 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.3715696069289125		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 5.3715696069289125 | validation: 6.320944093678628]
	TIME [epoch: 10.3 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.37248822584513		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 5.37248822584513 | validation: 6.269204371833446]
	TIME [epoch: 10.3 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.930885426231809		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 5.930885426231809 | validation: 6.982674287569004]
	TIME [epoch: 10.3 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.7380282206604045		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 5.7380282206604045 | validation: 6.87826875347914]
	TIME [epoch: 10.3 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.015208619300564		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 6.015208619300564 | validation: 6.945468167780653]
	TIME [epoch: 10.3 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.674326827606253		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 5.674326827606253 | validation: 6.807333528768127]
	TIME [epoch: 10.3 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.54785750593739		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 5.54785750593739 | validation: 6.404068520630313]
	TIME [epoch: 10.3 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.674709999345584		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 5.674709999345584 | validation: 6.772699382103299]
	TIME [epoch: 10.3 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.861380943113903		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 5.861380943113903 | validation: 8.579175519304009]
	TIME [epoch: 10.3 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.657712117029918		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 7.657712117029918 | validation: 6.75633048743484]
	TIME [epoch: 10.3 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.887101721364868		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 5.887101721364868 | validation: 6.654956331088226]
	TIME [epoch: 10.3 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.991043358116897		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 5.991043358116897 | validation: 6.6998552613882865]
	TIME [epoch: 10.3 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.8683066646048125		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 5.8683066646048125 | validation: 7.067113537245883]
	TIME [epoch: 10.3 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.895577223201775		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 7.895577223201775 | validation: 9.442774301874605]
	TIME [epoch: 10.3 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.576351989968861		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 7.576351989968861 | validation: 7.0377701418593235]
	TIME [epoch: 10.3 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.656779473362841		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 5.656779473362841 | validation: 6.878449216291476]
	TIME [epoch: 10.3 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.022167417687493		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 7.022167417687493 | validation: 6.504194649008894]
	TIME [epoch: 10.3 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.139284316305145		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 6.139284316305145 | validation: 6.848213160299736]
	TIME [epoch: 10.3 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.838602040967521		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 5.838602040967521 | validation: 6.314819666508929]
	TIME [epoch: 10.3 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.419301567666063		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 5.419301567666063 | validation: 6.865131549493717]
	TIME [epoch: 10.3 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.563005408205365		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 5.563005408205365 | validation: 6.517618263905217]
	TIME [epoch: 10.3 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.362760823077439		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 5.362760823077439 | validation: 6.475545677534736]
	TIME [epoch: 10.3 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.392402871027718		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 5.392402871027718 | validation: 6.551627311495738]
	TIME [epoch: 10.3 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.428152074259307		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 5.428152074259307 | validation: 7.229301764168398]
	TIME [epoch: 10.3 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.173968459729522		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 6.173968459729522 | validation: 6.450335806515923]
	TIME [epoch: 10.3 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.642816778829987		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 6.642816778829987 | validation: 6.4332662782536465]
	TIME [epoch: 10.3 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.3598094339647755		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 5.3598094339647755 | validation: 6.468528822839715]
	TIME [epoch: 10.3 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.555371271563718		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 5.555371271563718 | validation: 7.226170966516247]
	TIME [epoch: 10.3 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.769970261926053		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 5.769970261926053 | validation: 6.409358050292016]
	TIME [epoch: 10.3 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.5358485656888305		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 5.5358485656888305 | validation: 6.53965563829653]
	TIME [epoch: 10.3 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.668908609360452		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 5.668908609360452 | validation: 6.5954921021491515]
	TIME [epoch: 10.3 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.564198420089955		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 5.564198420089955 | validation: 6.737275453223342]
	TIME [epoch: 10.3 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.495296693779062		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 5.495296693779062 | validation: 6.53350419018564]
	TIME [epoch: 10.3 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9259359722779426		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 5.9259359722779426 | validation: 6.3950791926761825]
	TIME [epoch: 10.3 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.918474150469541		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 5.918474150469541 | validation: 6.348932677607117]
	TIME [epoch: 10.3 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.733000202683509		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 5.733000202683509 | validation: 6.420217059298121]
	TIME [epoch: 10.3 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.497990031524505		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 5.497990031524505 | validation: 7.584014589640419]
	TIME [epoch: 10.3 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.854218524751948		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 6.854218524751948 | validation: 6.713174257589712]
	TIME [epoch: 10.3 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.562974546000935		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 5.562974546000935 | validation: 6.159014594871185]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_141.pth
	Model improved!!!
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.3792552104011895		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 5.3792552104011895 | validation: 6.2823625237568805]
	TIME [epoch: 10.3 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.300947665364854		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 5.300947665364854 | validation: 6.178631584617729]
	TIME [epoch: 10.3 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.4980196045652		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 5.4980196045652 | validation: 6.226486092613343]
	TIME [epoch: 10.3 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.766467903843205		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 5.766467903843205 | validation: 6.549243007024229]
	TIME [epoch: 10.3 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.5452563557590375		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 5.5452563557590375 | validation: 6.651865904536617]
	TIME [epoch: 10.3 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.726716465535551		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 5.726716465535551 | validation: 6.872316170787383]
	TIME [epoch: 10.3 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.674681751253563		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 5.674681751253563 | validation: 6.564255109826964]
	TIME [epoch: 10.3 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.268732465917871		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 5.268732465917871 | validation: 6.16140920440906]
	TIME [epoch: 10.3 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.1938032787503		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 5.1938032787503 | validation: 6.155153348730934]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.168629399516264		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 5.168629399516264 | validation: 6.122067459800457]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_151.pth
	Model improved!!!
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.270658813375574		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 5.270658813375574 | validation: 6.0912584954914255]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_152.pth
	Model improved!!!
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.088113891393357		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 5.088113891393357 | validation: 6.088141951366993]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_153.pth
	Model improved!!!
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.951295321421951		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 4.951295321421951 | validation: 6.073773768896471]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_154.pth
	Model improved!!!
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.449666328047551		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 5.449666328047551 | validation: 7.024670685888764]
	TIME [epoch: 10.3 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.719961486158932		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 5.719961486158932 | validation: 6.227598546784774]
	TIME [epoch: 10.3 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.6805874061184465		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 5.6805874061184465 | validation: 5.868035678944234]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_157.pth
	Model improved!!!
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.1906210684978396		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 5.1906210684978396 | validation: 3.711861080909325]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_158.pth
	Model improved!!!
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.144513362274974		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 4.144513362274974 | validation: 3.8658527697417333]
	TIME [epoch: 10.3 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.200477404442383		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 4.200477404442383 | validation: 3.276788937009601]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_160.pth
	Model improved!!!
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7576475330512196		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 3.7576475330512196 | validation: 3.1438776454342543]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.45388531913288		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 4.45388531913288 | validation: 3.436785834287271]
	TIME [epoch: 10.3 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6726678993265454		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 3.6726678993265454 | validation: 2.8962937562312097]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.567057916290247		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 3.567057916290247 | validation: 2.8479701567404847]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_164.pth
	Model improved!!!
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6171520761876588		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 3.6171520761876588 | validation: 2.6773287678452347]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_165.pth
	Model improved!!!
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5138644186834944		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 3.5138644186834944 | validation: 2.886591953794069]
	TIME [epoch: 10.3 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8323409390951624		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 3.8323409390951624 | validation: 3.3428504237857215]
	TIME [epoch: 10.3 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6204564232720173		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 3.6204564232720173 | validation: 3.0466585144623166]
	TIME [epoch: 10.3 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.561728608048951		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 3.561728608048951 | validation: 2.7795293474300347]
	TIME [epoch: 10.3 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6394416008110326		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 3.6394416008110326 | validation: 3.6252008101030255]
	TIME [epoch: 10.3 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.750751728738929		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 3.750751728738929 | validation: 2.834971104311975]
	TIME [epoch: 10.3 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4987808642271228		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 3.4987808642271228 | validation: 2.677998236962725]
	TIME [epoch: 10.3 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.678467912403634		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 3.678467912403634 | validation: 2.6791952209835825]
	TIME [epoch: 10.3 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.941613628023249		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 3.941613628023249 | validation: 3.2604773334136783]
	TIME [epoch: 10.3 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.464855746740689		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 3.464855746740689 | validation: 2.9736475814908285]
	TIME [epoch: 10.3 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9060494094085385		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 3.9060494094085385 | validation: 3.6631652310142697]
	TIME [epoch: 10.3 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.516888995820745		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 6.516888995820745 | validation: 7.175964432122843]
	TIME [epoch: 10.3 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.219652542196361		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 6.219652542196361 | validation: 5.544501784281864]
	TIME [epoch: 10.3 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.722097593022367		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 4.722097593022367 | validation: 4.789922345640266]
	TIME [epoch: 10.3 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.721725849140638		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 4.721725849140638 | validation: 5.63852951716417]
	TIME [epoch: 10.3 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.593704424339978		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 4.593704424339978 | validation: 3.70020848699515]
	TIME [epoch: 10.3 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.053304614091849		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 4.053304614091849 | validation: 2.682745639175526]
	TIME [epoch: 10.3 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.689539463910814		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 2.689539463910814 | validation: 2.012346775992657]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.599675473107784		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 2.599675473107784 | validation: 2.048679584163329]
	TIME [epoch: 10.3 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5861681323603327		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 2.5861681323603327 | validation: 2.031258281049702]
	TIME [epoch: 10.3 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.043282794847758		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 3.043282794847758 | validation: 2.4944995489806243]
	TIME [epoch: 10.3 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6012616485499747		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 3.6012616485499747 | validation: 4.618950595464934]
	TIME [epoch: 10.3 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.214199696975405		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 3.214199696975405 | validation: 2.16039460566972]
	TIME [epoch: 10.3 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5790066071677646		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 2.5790066071677646 | validation: 2.1289408973676145]
	TIME [epoch: 10.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.384638233077097		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 2.384638233077097 | validation: 4.285717728955513]
	TIME [epoch: 10.3 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9135995606354372		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 3.9135995606354372 | validation: 2.4400706741495504]
	TIME [epoch: 10.3 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6460933039845025		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 2.6460933039845025 | validation: 2.7550041354911503]
	TIME [epoch: 10.3 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.378614405497029		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 2.378614405497029 | validation: 2.4108505861024456]
	TIME [epoch: 10.3 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.689819888965489		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 2.689819888965489 | validation: 2.85086930317388]
	TIME [epoch: 10.3 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2013048605777072		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 3.2013048605777072 | validation: 2.076394720134564]
	TIME [epoch: 10.3 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.302729150367564		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 2.302729150367564 | validation: 1.6989245822332748]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_196.pth
	Model improved!!!
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0686563608792916		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 2.0686563608792916 | validation: 2.3011139487032155]
	TIME [epoch: 10.3 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3039550922401153		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 2.3039550922401153 | validation: 1.7114435770306815]
	TIME [epoch: 10.3 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.997475143335712		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 1.997475143335712 | validation: 2.1296397614300635]
	TIME [epoch: 10.3 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.051104020576695		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 2.051104020576695 | validation: 1.667423698025996]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_200.pth
	Model improved!!!
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.996235360946255		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 1.996235360946255 | validation: 1.697960393913077]
	TIME [epoch: 10.3 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.160076916670382		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 2.160076916670382 | validation: 1.7670906052787327]
	TIME [epoch: 10.3 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1420844969532107		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 2.1420844969532107 | validation: 1.6803986128427295]
	TIME [epoch: 10.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0336169040845684		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 2.0336169040845684 | validation: 1.7759662824648836]
	TIME [epoch: 10.3 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5021113280451512		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 2.5021113280451512 | validation: 1.9391193711340338]
	TIME [epoch: 10.3 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.97039557271965		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.97039557271965 | validation: 1.7377960876387994]
	TIME [epoch: 10.3 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8908078557202632		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 1.8908078557202632 | validation: 1.5134498915938424]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_207.pth
	Model improved!!!
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8816866777346828		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 1.8816866777346828 | validation: 1.7424068171456248]
	TIME [epoch: 10.3 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8838118166351758		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 1.8838118166351758 | validation: 1.3945803279524231]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7574566822883053		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 1.7574566822883053 | validation: 1.4662582900154089]
	TIME [epoch: 10.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7817319824294386		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 1.7817319824294386 | validation: 1.3374510678667897]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.77625842819495		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 1.77625842819495 | validation: 1.5912951340606747]
	TIME [epoch: 10.3 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2638704043224247		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 2.2638704043224247 | validation: 2.0634012265496553]
	TIME [epoch: 10.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9210823128204733		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 1.9210823128204733 | validation: 1.4089877239828064]
	TIME [epoch: 10.3 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6848975719536852		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 1.6848975719536852 | validation: 1.7218088456918594]
	TIME [epoch: 10.3 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7337047703150674		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 1.7337047703150674 | validation: 1.2822066295360304]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.68017614763473		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 1.68017614763473 | validation: 1.3487717425086845]
	TIME [epoch: 10.3 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5524579692249045		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 1.5524579692249045 | validation: 1.3015903172223646]
	TIME [epoch: 10.3 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3080182064481223		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 1.3080182064481223 | validation: 1.7512595720356559]
	TIME [epoch: 10.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6479253805857923		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 1.6479253805857923 | validation: 1.3565107810931318]
	TIME [epoch: 10.3 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8350973715294203		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 1.8350973715294203 | validation: 1.291735222133013]
	TIME [epoch: 10.3 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5764625671502739		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 1.5764625671502739 | validation: 1.7122516539287176]
	TIME [epoch: 10.3 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7416984316040476		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 1.7416984316040476 | validation: 1.1618699214966888]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_223.pth
	Model improved!!!
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.51302294878545		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 1.51302294878545 | validation: 1.5908429688316137]
	TIME [epoch: 10.3 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4699505174698786		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 1.4699505174698786 | validation: 1.2867989985397765]
	TIME [epoch: 10.3 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.604964447121517		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 1.604964447121517 | validation: 1.0088649130033316]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_226.pth
	Model improved!!!
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2624435596295998		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 1.2624435596295998 | validation: 1.1899149531738882]
	TIME [epoch: 10.3 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5339434183291143		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 1.5339434183291143 | validation: 1.4811667995091882]
	TIME [epoch: 10.3 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5071516322134637		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 1.5071516322134637 | validation: 1.4188677473227376]
	TIME [epoch: 10.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4952271075898316		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.4952271075898316 | validation: 2.1444054688520433]
	TIME [epoch: 10.3 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.505564727586447		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 1.505564727586447 | validation: 1.3791715392769146]
	TIME [epoch: 10.3 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2953449457232558		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 1.2953449457232558 | validation: 1.2572598613066273]
	TIME [epoch: 10.3 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4194837517739212		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 1.4194837517739212 | validation: 1.1906272588142353]
	TIME [epoch: 10.3 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3779977354199404		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 1.3779977354199404 | validation: 1.2198512465875466]
	TIME [epoch: 10.3 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3941814477589087		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.3941814477589087 | validation: 1.4293141826809188]
	TIME [epoch: 10.3 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2041186855156343		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 1.2041186855156343 | validation: 1.8588349315639965]
	TIME [epoch: 10.3 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.38101324014402		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 1.38101324014402 | validation: 1.0443335116668329]
	TIME [epoch: 10.3 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4359633590828722		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 1.4359633590828722 | validation: 1.249401770385383]
	TIME [epoch: 10.3 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2347553347205178		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 1.2347553347205178 | validation: 1.0874596634938563]
	TIME [epoch: 10.3 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3341639640200023		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 1.3341639640200023 | validation: 1.5558041002382306]
	TIME [epoch: 10.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.290301066702368		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 1.290301066702368 | validation: 1.3974744770259104]
	TIME [epoch: 10.3 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3088996007006173		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 1.3088996007006173 | validation: 0.9575931308366029]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_242.pth
	Model improved!!!
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2779585969905518		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 1.2779585969905518 | validation: 1.7478576866610067]
	TIME [epoch: 10.3 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.274379095573868		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.274379095573868 | validation: 1.0475976091437462]
	TIME [epoch: 10.3 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.152780812607547		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 1.152780812607547 | validation: 1.014471679712384]
	TIME [epoch: 10.3 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1332705484190169		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 1.1332705484190169 | validation: 1.0415526757605074]
	TIME [epoch: 10.3 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1285199945371125		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 1.1285199945371125 | validation: 1.299203330601357]
	TIME [epoch: 10.3 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2510415828350432		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 1.2510415828350432 | validation: 1.0802927276138024]
	TIME [epoch: 10.3 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2133764512777983		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 1.2133764512777983 | validation: 1.0515595171839802]
	TIME [epoch: 10.3 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2680523552732033		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 1.2680523552732033 | validation: 1.1706833885385086]
	TIME [epoch: 10.3 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1098030221757031		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 1.1098030221757031 | validation: 1.3020636772308216]
	TIME [epoch: 10.3 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2911533491242673		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.2911533491242673 | validation: 1.1741046815023923]
	TIME [epoch: 10.3 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1618575943001308		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 1.1618575943001308 | validation: 1.2564847767326048]
	TIME [epoch: 10.3 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1528223928680874		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 1.1528223928680874 | validation: 1.2101436470539593]
	TIME [epoch: 10.3 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1284753128874245		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 1.1284753128874245 | validation: 1.040822542890557]
	TIME [epoch: 10.3 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0919286772447898		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 1.0919286772447898 | validation: 0.957377117958111]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_256.pth
	Model improved!!!
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2159508533323855		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 1.2159508533323855 | validation: 1.2413639575724222]
	TIME [epoch: 10.3 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0931554140751498		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 1.0931554140751498 | validation: 0.9326189508769537]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_258.pth
	Model improved!!!
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0653048000337733		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 1.0653048000337733 | validation: 1.1641500593351957]
	TIME [epoch: 10.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.087017240183655		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 1.087017240183655 | validation: 1.0422694195664208]
	TIME [epoch: 10.3 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0933441965997373		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 1.0933441965997373 | validation: 1.0812445670877815]
	TIME [epoch: 10.3 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2005849000696456		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 1.2005849000696456 | validation: 0.9007763532181153]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_262.pth
	Model improved!!!
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9992461442241771		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.9992461442241771 | validation: 0.9325168988300462]
	TIME [epoch: 10.3 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0922878065424821		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 1.0922878065424821 | validation: 0.8868339034497233]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_264.pth
	Model improved!!!
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9436418178042769		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 0.9436418178042769 | validation: 0.9838717301696669]
	TIME [epoch: 10.3 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.001574156849756		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 1.001574156849756 | validation: 1.380796496569277]
	TIME [epoch: 10.4 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1583317829405342		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 1.1583317829405342 | validation: 0.8653394803877281]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_267.pth
	Model improved!!!
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1842012855710249		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 1.1842012855710249 | validation: 1.117260730252699]
	TIME [epoch: 10.3 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0640543046261055		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.0640543046261055 | validation: 0.7926244341818004]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_269.pth
	Model improved!!!
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0469914364915567		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 1.0469914364915567 | validation: 1.120488540104191]
	TIME [epoch: 10.3 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1190770078841163		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.1190770078841163 | validation: 1.1102309637770016]
	TIME [epoch: 10.3 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.087447117950621		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 1.087447117950621 | validation: 1.0380266423377755]
	TIME [epoch: 10.3 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9413310740655503		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 0.9413310740655503 | validation: 1.2513771639601348]
	TIME [epoch: 10.3 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0912308547518408		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 1.0912308547518408 | validation: 0.9303435319975428]
	TIME [epoch: 10.3 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.018937103847793		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.018937103847793 | validation: 0.8751454801923594]
	TIME [epoch: 10.3 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.199074145832966		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 1.199074145832966 | validation: 0.8218952283869106]
	TIME [epoch: 10.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9687352289476339		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 0.9687352289476339 | validation: 0.8539469624545291]
	TIME [epoch: 10.3 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9944856686993961		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 0.9944856686993961 | validation: 1.0313943809978443]
	TIME [epoch: 10.3 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0006640232485353		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 1.0006640232485353 | validation: 1.0716632074491674]
	TIME [epoch: 10.3 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9438133889808302		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 0.9438133889808302 | validation: 0.9368688214290413]
	TIME [epoch: 10.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0460778058239746		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 1.0460778058239746 | validation: 0.9301968226598847]
	TIME [epoch: 10.3 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9361591122522406		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.9361591122522406 | validation: 1.0302317642143843]
	TIME [epoch: 10.3 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9599344138583528		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 0.9599344138583528 | validation: 0.9661520958016001]
	TIME [epoch: 10.3 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9427513166335008		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 0.9427513166335008 | validation: 0.8392116029648929]
	TIME [epoch: 10.3 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1546251802287821		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 1.1546251802287821 | validation: 0.9575115710243342]
	TIME [epoch: 10.3 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0868260992385472		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 1.0868260992385472 | validation: 0.823875785691649]
	TIME [epoch: 10.3 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8938958192242922		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 0.8938958192242922 | validation: 0.915001372197687]
	TIME [epoch: 10.3 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9627806295063011		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 0.9627806295063011 | validation: 0.9025576024188072]
	TIME [epoch: 10.3 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9032141539692307		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 0.9032141539692307 | validation: 1.134070922643603]
	TIME [epoch: 10.3 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9903525919230107		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 0.9903525919230107 | validation: 0.8731032514875119]
	TIME [epoch: 10.3 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9946284488974408		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 0.9946284488974408 | validation: 0.8921780757474038]
	TIME [epoch: 10.3 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0108557071273163		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 1.0108557071273163 | validation: 0.8395694763775297]
	TIME [epoch: 10.3 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9920370143433314		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 0.9920370143433314 | validation: 1.0248639767146035]
	TIME [epoch: 10.3 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2041547679940137		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 1.2041547679940137 | validation: 0.8461932651637207]
	TIME [epoch: 10.3 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9063039546076587		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 0.9063039546076587 | validation: 0.8722310466842352]
	TIME [epoch: 10.3 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.962109147795078		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 0.962109147795078 | validation: 0.8809687310135368]
	TIME [epoch: 10.3 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8973218118864317		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 0.8973218118864317 | validation: 0.7630662344409433]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_297.pth
	Model improved!!!
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8964888638728201		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 0.8964888638728201 | validation: 0.7691806835201485]
	TIME [epoch: 10.3 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9096726857848217		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 0.9096726857848217 | validation: 0.9434338391779702]
	TIME [epoch: 10.3 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9917204245960374		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 0.9917204245960374 | validation: 0.8314991115294714]
	TIME [epoch: 10.3 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9760548074621299		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.9760548074621299 | validation: 0.7955989128036752]
	TIME [epoch: 10.3 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9145689210440763		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 0.9145689210440763 | validation: 1.0259077123409857]
	TIME [epoch: 10.3 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0064763174331168		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 1.0064763174331168 | validation: 0.7580352386390823]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_303.pth
	Model improved!!!
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8888608564984686		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 0.8888608564984686 | validation: 0.8713404269652497]
	TIME [epoch: 10.3 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9270139218767545		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 0.9270139218767545 | validation: 1.0269846600796715]
	TIME [epoch: 10.3 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3341377020990914		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.3341377020990914 | validation: 1.566365785918818]
	TIME [epoch: 10.3 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1343273875932702		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 1.1343273875932702 | validation: 1.2552346726350867]
	TIME [epoch: 10.3 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9634037714777011		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 0.9634037714777011 | validation: 0.8892933588518909]
	TIME [epoch: 10.3 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0239033156669477		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 1.0239033156669477 | validation: 0.7799759420460304]
	TIME [epoch: 10.3 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8323483478073632		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 0.8323483478073632 | validation: 0.7300651219915593]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_310.pth
	Model improved!!!
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.876256862634629		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 0.876256862634629 | validation: 0.8159809321734579]
	TIME [epoch: 10.3 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9519773021460696		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.9519773021460696 | validation: 0.8000346729964521]
	TIME [epoch: 10.3 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9010134163061322		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 0.9010134163061322 | validation: 0.7797999806022116]
	TIME [epoch: 10.3 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1176802034938258		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 1.1176802034938258 | validation: 0.9186589884406332]
	TIME [epoch: 10.3 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9313969150022368		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 0.9313969150022368 | validation: 0.839359749244367]
	TIME [epoch: 10.3 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8597500485558847		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 0.8597500485558847 | validation: 0.9484090404174503]
	TIME [epoch: 10.3 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.910578533641902		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.910578533641902 | validation: 0.9616174735746743]
	TIME [epoch: 10.3 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0982392021507343		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 1.0982392021507343 | validation: 0.8527382907382993]
	TIME [epoch: 10.3 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.922110321869402		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.922110321869402 | validation: 0.7793531644392219]
	TIME [epoch: 10.3 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8464214564519816		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.8464214564519816 | validation: 0.8056303601411576]
	TIME [epoch: 10.3 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9796412216340553		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 0.9796412216340553 | validation: 0.787474180504112]
	TIME [epoch: 10.3 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8288928560666793		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 0.8288928560666793 | validation: 0.8287983342982557]
	TIME [epoch: 10.3 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8059331332121464		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.8059331332121464 | validation: 1.1169182391789287]
	TIME [epoch: 10.3 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8722883607142988		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.8722883607142988 | validation: 0.9451165617999125]
	TIME [epoch: 10.3 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9191764434214313		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.9191764434214313 | validation: 1.0801290427127537]
	TIME [epoch: 10.3 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8360546692125078		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 0.8360546692125078 | validation: 0.7506115527096614]
	TIME [epoch: 10.3 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7975998576310402		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 0.7975998576310402 | validation: 0.7867629820764793]
	TIME [epoch: 10.3 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8151603598968137		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.8151603598968137 | validation: 0.8288940826119219]
	TIME [epoch: 10.3 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8224672823691993		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 0.8224672823691993 | validation: 0.8475147155522014]
	TIME [epoch: 10.3 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.877700584796677		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 0.877700584796677 | validation: 0.739095798434578]
	TIME [epoch: 10.3 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8001036826260048		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.8001036826260048 | validation: 0.7341346175658433]
	TIME [epoch: 10.3 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.828622814666374		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 0.828622814666374 | validation: 0.7081308154636362]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_332.pth
	Model improved!!!
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9295416308916563		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 0.9295416308916563 | validation: 0.7642532201345119]
	TIME [epoch: 10.3 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8598819084166307		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.8598819084166307 | validation: 0.7292284267935472]
	TIME [epoch: 10.3 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7790289064444693		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 0.7790289064444693 | validation: 0.7348962911935667]
	TIME [epoch: 10.3 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7982774662408133		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.7982774662408133 | validation: 0.736996525398915]
	TIME [epoch: 10.3 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7803647165813589		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.7803647165813589 | validation: 0.773072924453324]
	TIME [epoch: 10.3 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8180163321373168		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.8180163321373168 | validation: 0.816210921185458]
	TIME [epoch: 10.3 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8941176822126332		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.8941176822126332 | validation: 0.6859563535031822]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_339.pth
	Model improved!!!
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7792500844744157		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.7792500844744157 | validation: 0.8645859831204333]
	TIME [epoch: 10.3 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7994988155759104		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.7994988155759104 | validation: 0.7393965152984739]
	TIME [epoch: 10.3 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8469795843862677		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.8469795843862677 | validation: 0.7622948040357334]
	TIME [epoch: 10.3 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8040508017206889		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.8040508017206889 | validation: 0.866018963857496]
	TIME [epoch: 10.3 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8154731291936764		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.8154731291936764 | validation: 0.8466617144594403]
	TIME [epoch: 10.3 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7784456749765511		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.7784456749765511 | validation: 1.1015813108905237]
	TIME [epoch: 10.3 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135925704731072		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 0.8135925704731072 | validation: 0.7435816620114905]
	TIME [epoch: 10.3 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8100729676663636		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.8100729676663636 | validation: 0.7201457687337657]
	TIME [epoch: 10.3 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7338771207523526		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 0.7338771207523526 | validation: 0.7547385641131277]
	TIME [epoch: 10.3 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7298120500389755		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 0.7298120500389755 | validation: 0.8387050032641681]
	TIME [epoch: 10.3 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7635468957156762		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.7635468957156762 | validation: 0.8976475505600056]
	TIME [epoch: 10.3 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7737496825567838		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.7737496825567838 | validation: 0.856901997233904]
	TIME [epoch: 10.3 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7624776733117187		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.7624776733117187 | validation: 0.7375620787921997]
	TIME [epoch: 10.3 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6679156694717181		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 0.6679156694717181 | validation: 0.6276801978348717]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_353.pth
	Model improved!!!
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926917474852059		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.6926917474852059 | validation: 0.7511283446566398]
	TIME [epoch: 10.3 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8521949633216126		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.8521949633216126 | validation: 0.9162249042117676]
	TIME [epoch: 10.3 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8049687462648578		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.8049687462648578 | validation: 0.7548212522683722]
	TIME [epoch: 10.3 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7765750594777047		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 0.7765750594777047 | validation: 0.6764516202225355]
	TIME [epoch: 10.3 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6891702461639891		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.6891702461639891 | validation: 0.8137567189667996]
	TIME [epoch: 10.3 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7465189626059658		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 0.7465189626059658 | validation: 0.6491481920132256]
	TIME [epoch: 10.3 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.795409680126524		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.795409680126524 | validation: 0.6950841128939353]
	TIME [epoch: 10.3 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6909053903451372		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.6909053903451372 | validation: 0.6340500145758656]
	TIME [epoch: 10.3 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.817048574755012		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.817048574755012 | validation: 0.6953309702615751]
	TIME [epoch: 10.3 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7109612733316644		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.7109612733316644 | validation: 0.7235432744231147]
	TIME [epoch: 10.3 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7301695211279371		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.7301695211279371 | validation: 0.7514952927183631]
	TIME [epoch: 10.3 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8574965004075835		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.8574965004075835 | validation: 1.174495814662576]
	TIME [epoch: 10.3 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7476265019595585		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.7476265019595585 | validation: 1.2379432873411613]
	TIME [epoch: 10.3 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7823851110288464		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 0.7823851110288464 | validation: 0.7628115557909169]
	TIME [epoch: 10.3 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6428529009466111		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.6428529009466111 | validation: 0.6004755621652839]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_368.pth
	Model improved!!!
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.65958679431339		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.65958679431339 | validation: 0.6416737918117416]
	TIME [epoch: 10.3 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6533591179929072		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.6533591179929072 | validation: 0.6359499898510448]
	TIME [epoch: 10.3 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6718797872618063		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.6718797872618063 | validation: 0.6690462505064673]
	TIME [epoch: 10.3 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6493796925507246		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.6493796925507246 | validation: 0.7492250212524194]
	TIME [epoch: 10.3 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103148904719248		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.7103148904719248 | validation: 0.8510671007259407]
	TIME [epoch: 10.3 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6384548704957002		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.6384548704957002 | validation: 0.7110666925635635]
	TIME [epoch: 10.3 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7497590222997244		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.7497590222997244 | validation: 0.6133721584346692]
	TIME [epoch: 10.3 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6785615792335903		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.6785615792335903 | validation: 0.6035134158148552]
	TIME [epoch: 10.3 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333767339674592		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.6333767339674592 | validation: 0.6928979027486843]
	TIME [epoch: 10.3 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5922911169274651		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.5922911169274651 | validation: 0.6017799563312374]
	TIME [epoch: 10.3 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5797460439892973		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.5797460439892973 | validation: 0.6852328897765316]
	TIME [epoch: 10.3 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284718440514567		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.6284718440514567 | validation: 0.5558682022986722]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_380.pth
	Model improved!!!
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245291436695231		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.6245291436695231 | validation: 0.6433660056713455]
	TIME [epoch: 10.3 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.624312406512941		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.624312406512941 | validation: 0.6427196096301452]
	TIME [epoch: 10.3 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5805935139311094		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.5805935139311094 | validation: 0.6444728390655962]
	TIME [epoch: 10.3 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7569800777235125		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.7569800777235125 | validation: 0.7309558461525323]
	TIME [epoch: 10.3 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787950752345808		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.5787950752345808 | validation: 0.520803341509755]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_385.pth
	Model improved!!!
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.565072983629159		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.565072983629159 | validation: 0.5617788503336281]
	TIME [epoch: 10.3 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5524872463970019		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.5524872463970019 | validation: 0.5963407879276162]
	TIME [epoch: 10.3 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5744161498746643		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.5744161498746643 | validation: 0.5309801940472076]
	TIME [epoch: 10.3 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322033867359586		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.5322033867359586 | validation: 0.5048777390661717]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_389.pth
	Model improved!!!
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5653952947305159		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.5653952947305159 | validation: 0.5580060417865598]
	TIME [epoch: 10.3 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242297733303188		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.5242297733303188 | validation: 0.6138425011661882]
	TIME [epoch: 10.3 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.796709854265169		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.796709854265169 | validation: 0.6647809101223459]
	TIME [epoch: 10.2 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5925665843934287		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.5925665843934287 | validation: 0.48990811898028996]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_393.pth
	Model improved!!!
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5444591894816229		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.5444591894816229 | validation: 0.5378575901112995]
	TIME [epoch: 10.3 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6000362067828527		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.6000362067828527 | validation: 0.5275201792272636]
	TIME [epoch: 10.3 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6330132095864979		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.6330132095864979 | validation: 0.6365787728506738]
	TIME [epoch: 10.3 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.592256586656453		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.592256586656453 | validation: 0.4903057587584263]
	TIME [epoch: 10.3 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220514146986754		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.5220514146986754 | validation: 0.6201709036378568]
	TIME [epoch: 10.3 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981809515328014		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.5981809515328014 | validation: 0.473713969738273]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_399.pth
	Model improved!!!
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5078591994607878		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.5078591994607878 | validation: 0.4737555530428061]
	TIME [epoch: 10.3 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5310480148022646		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.5310480148022646 | validation: 0.49676993468342645]
	TIME [epoch: 10.3 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5858573569042387		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.5858573569042387 | validation: 0.5074476994671084]
	TIME [epoch: 10.3 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4961760919526366		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.4961760919526366 | validation: 0.6063816041362938]
	TIME [epoch: 10.3 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5644622092655477		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.5644622092655477 | validation: 0.6647114034452335]
	TIME [epoch: 10.3 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.52632682218551		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.52632682218551 | validation: 0.6122674351208535]
	TIME [epoch: 10.3 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.579398535281887		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.579398535281887 | validation: 0.5311868736430116]
	TIME [epoch: 10.3 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5027863573738939		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.5027863573738939 | validation: 0.46644881519557785]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_407.pth
	Model improved!!!
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5330587414029634		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.5330587414029634 | validation: 0.510136838842584]
	TIME [epoch: 10.3 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062333878595711		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.5062333878595711 | validation: 0.561600269691699]
	TIME [epoch: 10.3 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4742785005468832		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.4742785005468832 | validation: 0.472372710819587]
	TIME [epoch: 10.3 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5207953767703226		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.5207953767703226 | validation: 0.6553582991867096]
	TIME [epoch: 10.3 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5528776762842436		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.5528776762842436 | validation: 0.664644804650795]
	TIME [epoch: 10.3 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.577025629110322		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.577025629110322 | validation: 0.6123543732496299]
	TIME [epoch: 10.3 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278354864714363		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.5278354864714363 | validation: 0.5019562762330823]
	TIME [epoch: 10.3 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.527973041409688		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.527973041409688 | validation: 0.4967570445315392]
	TIME [epoch: 10.3 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5140259221439168		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.5140259221439168 | validation: 0.5607691671748629]
	TIME [epoch: 10.3 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9034308888293359		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.9034308888293359 | validation: 0.48362114353821145]
	TIME [epoch: 10.3 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4630567022838644		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.4630567022838644 | validation: 0.5154085084390546]
	TIME [epoch: 10.3 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5740026561761644		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.5740026561761644 | validation: 0.51070345510746]
	TIME [epoch: 10.3 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48202730887887757		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.48202730887887757 | validation: 0.552749090514672]
	TIME [epoch: 10.3 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.514307120791732		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.514307120791732 | validation: 0.4543055501518205]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_421.pth
	Model improved!!!
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4953861622326444		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.4953861622326444 | validation: 0.4763818827318819]
	TIME [epoch: 10.3 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266980731916627		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.5266980731916627 | validation: 0.5839190624276018]
	TIME [epoch: 10.3 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48506552597989555		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.48506552597989555 | validation: 0.5252550846252869]
	TIME [epoch: 10.3 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46089338655164075		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 0.46089338655164075 | validation: 0.5596989995452127]
	TIME [epoch: 10.3 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5153224471799491		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.5153224471799491 | validation: 0.5291839245758709]
	TIME [epoch: 10.3 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6030506875661148		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.6030506875661148 | validation: 0.5139469880003839]
	TIME [epoch: 10.3 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057874348798788		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.5057874348798788 | validation: 0.5884753082684994]
	TIME [epoch: 10.3 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5096689407042122		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.5096689407042122 | validation: 0.7140557974215601]
	TIME [epoch: 10.3 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5688931662775939		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.5688931662775939 | validation: 0.644352789012583]
	TIME [epoch: 10.3 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5141352284436443		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.5141352284436443 | validation: 0.5732694276532341]
	TIME [epoch: 10.3 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4888105430705075		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.4888105430705075 | validation: 0.477605951549598]
	TIME [epoch: 10.3 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4584851434345986		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.4584851434345986 | validation: 0.4412063692896291]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_433.pth
	Model improved!!!
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4757248309498413		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.4757248309498413 | validation: 0.4505022093720217]
	TIME [epoch: 10.3 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47015301560166395		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.47015301560166395 | validation: 0.7484291826997611]
	TIME [epoch: 10.3 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6002725739558655		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.6002725739558655 | validation: 0.5546785721760886]
	TIME [epoch: 10.3 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8421244701833743		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.8421244701833743 | validation: 0.5124631348343572]
	TIME [epoch: 10.3 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46699239138473275		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.46699239138473275 | validation: 0.5695437750836153]
	TIME [epoch: 10.3 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46790284676076704		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.46790284676076704 | validation: 0.4917398122308947]
	TIME [epoch: 10.3 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43537484175601077		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.43537484175601077 | validation: 0.543044414734645]
	TIME [epoch: 10.3 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4668561326295581		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.4668561326295581 | validation: 0.4530492959729409]
	TIME [epoch: 10.3 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.482843183163782		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.482843183163782 | validation: 0.8865176717280419]
	TIME [epoch: 10.3 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185448051372979		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.6185448051372979 | validation: 0.5038675863216199]
	TIME [epoch: 10.3 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559910782619195		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.4559910782619195 | validation: 0.499833636182578]
	TIME [epoch: 10.3 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47175570169166364		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.47175570169166364 | validation: 0.5196386127139703]
	TIME [epoch: 10.3 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4397511557650242		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.4397511557650242 | validation: 0.6117132451369041]
	TIME [epoch: 10.3 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4853598747835893		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.4853598747835893 | validation: 0.586516597725097]
	TIME [epoch: 10.3 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48441185806778975		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.48441185806778975 | validation: 0.4857094597648869]
	TIME [epoch: 10.3 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197376596003827		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.5197376596003827 | validation: 0.557612366529571]
	TIME [epoch: 10.3 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47000073302112766		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.47000073302112766 | validation: 0.6657637479176145]
	TIME [epoch: 10.3 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49565200523836805		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.49565200523836805 | validation: 0.47511164589345684]
	TIME [epoch: 10.3 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407418171953748		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.5407418171953748 | validation: 0.5739669920833135]
	TIME [epoch: 10.3 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46764304745236807		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.46764304745236807 | validation: 0.7100156483712395]
	TIME [epoch: 10.3 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5106973308251266		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.5106973308251266 | validation: 0.5647912684209425]
	TIME [epoch: 10.3 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48329395952739834		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.48329395952739834 | validation: 0.5551958384626596]
	TIME [epoch: 10.3 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5151441240387624		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.5151441240387624 | validation: 0.4843968992857998]
	TIME [epoch: 10.3 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.472454303738376		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.472454303738376 | validation: 0.4400100112897216]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_457.pth
	Model improved!!!
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.422198956796018		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.422198956796018 | validation: 0.6236726448992728]
	TIME [epoch: 10.3 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.512108720081293		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.512108720081293 | validation: 0.5272099469056633]
	TIME [epoch: 10.3 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5834314457165368		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.5834314457165368 | validation: 0.6047369379593731]
	TIME [epoch: 10.3 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4843486503551195		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.4843486503551195 | validation: 0.6310794343681623]
	TIME [epoch: 10.3 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5668540799661396		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.5668540799661396 | validation: 0.5059502831533356]
	TIME [epoch: 10.3 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5130144782368768		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.5130144782368768 | validation: 0.47288310050212945]
	TIME [epoch: 10.3 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47531579589146505		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.47531579589146505 | validation: 0.48367870158297793]
	TIME [epoch: 10.3 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246268542695516		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.4246268542695516 | validation: 0.44014638049013727]
	TIME [epoch: 10.3 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5384398873485974		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.5384398873485974 | validation: 0.4166505605783003]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_466.pth
	Model improved!!!
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5839021490967654		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.5839021490967654 | validation: 0.4824530211668032]
	TIME [epoch: 10.3 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44709943784947936		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.44709943784947936 | validation: 0.43417825856818065]
	TIME [epoch: 10.3 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47565311292989393		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.47565311292989393 | validation: 0.4601598390663679]
	TIME [epoch: 10.3 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4370689921763578		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.4370689921763578 | validation: 0.4427415273256496]
	TIME [epoch: 10.3 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5110322508656766		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.5110322508656766 | validation: 0.5118910855344572]
	TIME [epoch: 10.3 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7324938761172738		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.7324938761172738 | validation: 0.5218668838623793]
	TIME [epoch: 10.3 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4309431375535442		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.4309431375535442 | validation: 0.47196092319231225]
	TIME [epoch: 10.3 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4189745507677111		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.4189745507677111 | validation: 0.4390122702033652]
	TIME [epoch: 10.6 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4627996627865897		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.4627996627865897 | validation: 0.4588372757349953]
	TIME [epoch: 10.3 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48460592141269787		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.48460592141269787 | validation: 0.6209382656669112]
	TIME [epoch: 10.3 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4614563396870305		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.4614563396870305 | validation: 0.46499593972861447]
	TIME [epoch: 10.3 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787139967049743		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.5787139967049743 | validation: 0.6221687368473507]
	TIME [epoch: 10.3 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391778531641862		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.5391778531641862 | validation: 0.507861635125456]
	TIME [epoch: 10.3 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4858731995070295		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.4858731995070295 | validation: 0.5653828471095369]
	TIME [epoch: 10.3 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4493108091117747		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.4493108091117747 | validation: 0.481029598561975]
	TIME [epoch: 10.3 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4203581030134054		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.4203581030134054 | validation: 0.4990247495512264]
	TIME [epoch: 10.3 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4646847102622219		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.4646847102622219 | validation: 0.426439743999157]
	TIME [epoch: 10.3 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6194415072428512		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.6194415072428512 | validation: 0.5159439647000632]
	TIME [epoch: 10.3 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47469544148386894		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.47469544148386894 | validation: 0.7667025921722137]
	TIME [epoch: 10.3 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5653927386053423		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.5653927386053423 | validation: 0.48336810681274933]
	TIME [epoch: 10.3 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43315527935490444		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.43315527935490444 | validation: 0.5016387722894204]
	TIME [epoch: 10.3 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4547652381345742		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.4547652381345742 | validation: 0.5986865945713132]
	TIME [epoch: 10.3 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4629962609641871		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.4629962609641871 | validation: 0.46463678198776825]
	TIME [epoch: 10.3 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4427039537690538		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.4427039537690538 | validation: 0.4411330265637765]
	TIME [epoch: 10.3 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4445236422750142		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.4445236422750142 | validation: 0.5706540120970063]
	TIME [epoch: 10.3 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44591586403340405		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.44591586403340405 | validation: 0.5592578435775334]
	TIME [epoch: 10.3 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217598735946247		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.5217598735946247 | validation: 0.46815913558538486]
	TIME [epoch: 10.3 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4545398688050538		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.4545398688050538 | validation: 0.4653981463952016]
	TIME [epoch: 10.3 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41190080394545425		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.41190080394545425 | validation: 0.4800930610044412]
	TIME [epoch: 10.3 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47541323823740883		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.47541323823740883 | validation: 0.49479723232872846]
	TIME [epoch: 10.3 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4644010789625571		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.4644010789625571 | validation: 0.5031481595028306]
	TIME [epoch: 10.3 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4306324623169708		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.4306324623169708 | validation: 0.5783045236193949]
	TIME [epoch: 10.3 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47531167137916286		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.47531167137916286 | validation: 0.4784686460218106]
	TIME [epoch: 10.3 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4438722689267899		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.4438722689267899 | validation: 0.6087583072029099]
	TIME [epoch: 10.3 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5114516011941287		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.5114516011941287 | validation: 0.44962215885624657]
	TIME [epoch: 10.3 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43228366511329924		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.43228366511329924 | validation: 0.5042826843894487]
	TIME [epoch: 10.3 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4537361818911866		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.4537361818911866 | validation: 0.4325961302709479]
	TIME [epoch: 10.3 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44364415619233977		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.44364415619233977 | validation: 0.4987239959990552]
	TIME [epoch: 10.3 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4816028045643422		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.4816028045643422 | validation: 0.5169804168490406]
	TIME [epoch: 10.3 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4611797133669574		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.4611797133669574 | validation: 0.4406564128572967]
	TIME [epoch: 10.3 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4063971348422647		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.4063971348422647 | validation: 0.4947780664616028]
	TIME [epoch: 10.3 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45117806804964483		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.45117806804964483 | validation: 0.4346903086080245]
	TIME [epoch: 10.3 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44169667644808125		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.44169667644808125 | validation: 0.41504368162203537]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_509.pth
	Model improved!!!
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4915305517157253		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.4915305517157253 | validation: 0.42517065927388514]
	TIME [epoch: 10.3 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4386284915626309		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.4386284915626309 | validation: 0.4692457315814379]
	TIME [epoch: 10.3 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4350276378429139		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.4350276378429139 | validation: 0.47101350371124723]
	TIME [epoch: 10.3 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45138659694771627		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.45138659694771627 | validation: 0.5606345368043752]
	TIME [epoch: 10.3 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4466370558599075		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.4466370558599075 | validation: 0.4714193227145886]
	TIME [epoch: 10.3 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4650403092467883		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.4650403092467883 | validation: 0.5341076485462127]
	TIME [epoch: 10.3 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45333013381614506		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.45333013381614506 | validation: 0.48358079606176535]
	TIME [epoch: 10.3 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4587788651943038		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.4587788651943038 | validation: 0.4735682839023585]
	TIME [epoch: 10.3 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.432474781884009		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.432474781884009 | validation: 0.4931833957376042]
	TIME [epoch: 10.3 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43203764073882106		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.43203764073882106 | validation: 0.5453262745805783]
	TIME [epoch: 10.3 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4373573665496896		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.4373573665496896 | validation: 0.4472982650827904]
	TIME [epoch: 10.3 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44179214738542416		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.44179214738542416 | validation: 0.4992841850951881]
	TIME [epoch: 10.3 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023114405417333		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.5023114405417333 | validation: 0.5079958185814405]
	TIME [epoch: 10.3 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5844551296353764		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.5844551296353764 | validation: 0.5779375206375167]
	TIME [epoch: 10.3 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4579199975652406		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.4579199975652406 | validation: 0.46413997583929173]
	TIME [epoch: 10.3 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4474542727540218		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.4474542727540218 | validation: 0.5290509177658632]
	TIME [epoch: 10.3 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4422777206194047		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.4422777206194047 | validation: 0.4863070374882316]
	TIME [epoch: 10.3 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45881969275154966		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.45881969275154966 | validation: 0.6190479597885655]
	TIME [epoch: 10.3 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4743816235975927		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.4743816235975927 | validation: 0.5659583651258375]
	TIME [epoch: 10.3 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4521772985991096		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.4521772985991096 | validation: 0.47606802790700575]
	TIME [epoch: 10.3 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44354649727254464		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.44354649727254464 | validation: 0.48682447220909875]
	TIME [epoch: 10.3 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44224405489021795		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.44224405489021795 | validation: 0.4310013782786581]
	TIME [epoch: 10.3 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40429957984254905		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.40429957984254905 | validation: 0.5919994762214025]
	TIME [epoch: 10.3 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4875840083424638		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.4875840083424638 | validation: 0.5238205489918031]
	TIME [epoch: 10.3 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4889412597852828		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.4889412597852828 | validation: 0.5749067902028745]
	TIME [epoch: 10.3 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45240522812618966		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.45240522812618966 | validation: 0.4217110378135003]
	TIME [epoch: 10.3 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41477717784341284		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.41477717784341284 | validation: 0.5013733812831]
	TIME [epoch: 10.3 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4749737080576851		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.4749737080576851 | validation: 0.4644550212720627]
	TIME [epoch: 10.3 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41765984456437427		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.41765984456437427 | validation: 0.4521292969272582]
	TIME [epoch: 10.3 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4313100260383405		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.4313100260383405 | validation: 0.5169481935779133]
	TIME [epoch: 10.3 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4386649425779791		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.4386649425779791 | validation: 0.5315509952256028]
	TIME [epoch: 10.3 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45699646088166423		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.45699646088166423 | validation: 0.5278804815687219]
	TIME [epoch: 10.3 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.417905075042337		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.417905075042337 | validation: 0.4483652428447]
	TIME [epoch: 10.3 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178652195777984		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.4178652195777984 | validation: 0.4439272770209135]
	TIME [epoch: 10.3 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44450935244360784		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.44450935244360784 | validation: 0.5393564613417278]
	TIME [epoch: 10.3 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44257511211634915		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.44257511211634915 | validation: 0.5397025476026351]
	TIME [epoch: 10.3 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576980838533027		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.4576980838533027 | validation: 0.47487248557830425]
	TIME [epoch: 10.3 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4340018328297317		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.4340018328297317 | validation: 0.42147367688840404]
	TIME [epoch: 10.3 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4099805301573169		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.4099805301573169 | validation: 0.4746000111810081]
	TIME [epoch: 10.3 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41985219261438295		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.41985219261438295 | validation: 0.48173998489741227]
	TIME [epoch: 10.3 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42522764689759585		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.42522764689759585 | validation: 0.5844526912447381]
	TIME [epoch: 10.3 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363567570723803		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.5363567570723803 | validation: 0.5854991440453244]
	TIME [epoch: 10.3 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4600932576681765		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.4600932576681765 | validation: 0.47712071979729265]
	TIME [epoch: 10.3 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41865756699490053		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.41865756699490053 | validation: 0.43572543978744405]
	TIME [epoch: 10.3 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42697058548891265		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.42697058548891265 | validation: 0.44755320420265354]
	TIME [epoch: 10.3 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42471301854589977		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.42471301854589977 | validation: 0.4368379931289914]
	TIME [epoch: 10.3 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42572361105532097		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.42572361105532097 | validation: 0.46215671483597404]
	TIME [epoch: 10.3 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42427073375994456		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.42427073375994456 | validation: 0.48197887071951434]
	TIME [epoch: 10.3 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6452134372736437		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.6452134372736437 | validation: 1.084464765280173]
	TIME [epoch: 10.3 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.583404493206456		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.583404493206456 | validation: 0.443231682492476]
	TIME [epoch: 10.3 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44554411548017897		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.44554411548017897 | validation: 0.46513618285460795]
	TIME [epoch: 10.3 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4452170388988973		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.4452170388988973 | validation: 0.46716884963928806]
	TIME [epoch: 10.3 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40911344782388326		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.40911344782388326 | validation: 0.48659220569723366]
	TIME [epoch: 10.3 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4390698288226604		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.4390698288226604 | validation: 0.4320148449992918]
	TIME [epoch: 10.3 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4166650900980212		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.4166650900980212 | validation: 0.5280732473204311]
	TIME [epoch: 10.3 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4597999179449353		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.4597999179449353 | validation: 0.47622139774341227]
	TIME [epoch: 10.3 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4291364788480404		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.4291364788480404 | validation: 0.46018781517701113]
	TIME [epoch: 10.3 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970325184088258		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.3970325184088258 | validation: 0.5117298068573575]
	TIME [epoch: 10.3 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4273090431994103		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.4273090431994103 | validation: 0.7364419850332362]
	TIME [epoch: 10.3 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5199945763487903		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.5199945763487903 | validation: 0.4083070016356991]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_569.pth
	Model improved!!!
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4575270603641684		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.4575270603641684 | validation: 0.4410581725832259]
	TIME [epoch: 10.3 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4461263054999862		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.4461263054999862 | validation: 0.4549206156128419]
	TIME [epoch: 10.3 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4597781946173697		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.4597781946173697 | validation: 0.5411445481676522]
	TIME [epoch: 10.3 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4751427163663268		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.4751427163663268 | validation: 0.6238959189867245]
	TIME [epoch: 10.3 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48398247476659007		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.48398247476659007 | validation: 0.5391948211734585]
	TIME [epoch: 10.3 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43989472077885255		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.43989472077885255 | validation: 0.4154671130020702]
	TIME [epoch: 10.3 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41170329079960927		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.41170329079960927 | validation: 0.4837772233177082]
	TIME [epoch: 10.3 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4289923144104524		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.4289923144104524 | validation: 0.4590670870587008]
	TIME [epoch: 10.3 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4052682597768157		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.4052682597768157 | validation: 0.4214776388217662]
	TIME [epoch: 10.3 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4197866391515839		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.4197866391515839 | validation: 0.47649351855182986]
	TIME [epoch: 10.3 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4778177504764427		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.4778177504764427 | validation: 0.48741617592252284]
	TIME [epoch: 10.3 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40531952882926897		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.40531952882926897 | validation: 0.46542723252514834]
	TIME [epoch: 10.3 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.423953060902104		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.423953060902104 | validation: 0.48952492796691505]
	TIME [epoch: 10.3 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4602839671044346		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.4602839671044346 | validation: 0.4199583238396747]
	TIME [epoch: 10.3 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40408687308922475		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.40408687308922475 | validation: 0.42754689173433635]
	TIME [epoch: 10.3 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124609011401586		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.4124609011401586 | validation: 0.5096969835291612]
	TIME [epoch: 10.3 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4373644390154962		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.4373644390154962 | validation: 0.4679441692786255]
	TIME [epoch: 10.3 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4385843047376644		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.4385843047376644 | validation: 0.4958117315702761]
	TIME [epoch: 10.3 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3994911788541862		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.3994911788541862 | validation: 0.4261241964555075]
	TIME [epoch: 10.3 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4105554819222532		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.4105554819222532 | validation: 0.6506258747622263]
	TIME [epoch: 10.3 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4648915110671329		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.4648915110671329 | validation: 0.5380993040636008]
	TIME [epoch: 10.3 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4680867797873541		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.4680867797873541 | validation: 0.5113401875565208]
	TIME [epoch: 10.3 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488209565462583		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.4488209565462583 | validation: 0.4982939669883517]
	TIME [epoch: 10.3 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46310659561811607		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.46310659561811607 | validation: 0.5806881299548023]
	TIME [epoch: 10.3 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.511434239228706		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.511434239228706 | validation: 0.4728554439754562]
	TIME [epoch: 10.3 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.404250754260176		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.404250754260176 | validation: 0.4580269686531175]
	TIME [epoch: 10.3 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4198329832244611		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.4198329832244611 | validation: 0.462782957590648]
	TIME [epoch: 10.3 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4304310706830437		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.4304310706830437 | validation: 0.5039871362243169]
	TIME [epoch: 10.3 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4355946019461642		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.4355946019461642 | validation: 0.44550594556480094]
	TIME [epoch: 10.3 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40989411850367363		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.40989411850367363 | validation: 0.47986347413301855]
	TIME [epoch: 10.3 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40142204071594334		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.40142204071594334 | validation: 0.4626988979603178]
	TIME [epoch: 10.3 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42431952235671744		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.42431952235671744 | validation: 0.4782609918382644]
	TIME [epoch: 10.3 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4607128318659225		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.4607128318659225 | validation: 0.4756507000092539]
	TIME [epoch: 10.3 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40775610436269866		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.40775610436269866 | validation: 0.4605936719500464]
	TIME [epoch: 10.3 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4447684154152321		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.4447684154152321 | validation: 0.49237620611742733]
	TIME [epoch: 10.3 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4029309448777272		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.4029309448777272 | validation: 0.4546779472508999]
	TIME [epoch: 10.3 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4030601415521641		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.4030601415521641 | validation: 0.45950028134265064]
	TIME [epoch: 10.3 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45497688121396374		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.45497688121396374 | validation: 0.44573979918841333]
	TIME [epoch: 10.3 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42005424798950897		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.42005424798950897 | validation: 0.48180289006973004]
	TIME [epoch: 10.3 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42633744902251713		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.42633744902251713 | validation: 0.4341178674017763]
	TIME [epoch: 10.3 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4002149143846502		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.4002149143846502 | validation: 0.5040601029206684]
	TIME [epoch: 10.3 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4051217384450566		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.4051217384450566 | validation: 0.4457109470457868]
	TIME [epoch: 10.3 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4032743275436624		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.4032743275436624 | validation: 0.5543839835052495]
	TIME [epoch: 10.3 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47341013484309097		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.47341013484309097 | validation: 0.46301113372449026]
	TIME [epoch: 10.3 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4453828145378916		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.4453828145378916 | validation: 0.5160107886812255]
	TIME [epoch: 10.3 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43440757468031643		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.43440757468031643 | validation: 0.435264945403921]
	TIME [epoch: 10.3 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41010614080195873		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.41010614080195873 | validation: 0.5044724392785767]
	TIME [epoch: 10.3 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39017644669722296		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.39017644669722296 | validation: 0.43617715607702406]
	TIME [epoch: 10.3 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42718058888486876		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.42718058888486876 | validation: 0.5081492456455236]
	TIME [epoch: 10.3 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42371581392821583		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.42371581392821583 | validation: 0.4359951269375968]
	TIME [epoch: 10.3 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41151600722448123		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.41151600722448123 | validation: 0.4555469303911413]
	TIME [epoch: 10.3 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42446380802406364		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.42446380802406364 | validation: 0.43939002350132145]
	TIME [epoch: 10.3 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4461287459143259		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.4461287459143259 | validation: 0.4267060170963744]
	TIME [epoch: 10.3 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40961317766601646		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.40961317766601646 | validation: 0.4548480538718793]
	TIME [epoch: 10.3 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41031951973183445		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.41031951973183445 | validation: 0.5007355385452162]
	TIME [epoch: 10.3 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4331269061377383		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.4331269061377383 | validation: 0.44971195526529373]
	TIME [epoch: 10.3 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40385908105364193		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.40385908105364193 | validation: 0.4655542988015431]
	TIME [epoch: 10.3 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4028237111029259		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.4028237111029259 | validation: 0.4706691985484166]
	TIME [epoch: 10.3 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4817248357574212		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.4817248357574212 | validation: 0.5144325601427306]
	TIME [epoch: 10.3 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4359612176870561		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.4359612176870561 | validation: 0.432585615608339]
	TIME [epoch: 10.3 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40296663576375413		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.40296663576375413 | validation: 0.4545430566950413]
	TIME [epoch: 10.3 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40490503520126764		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.40490503520126764 | validation: 0.4383003728699963]
	TIME [epoch: 10.3 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3836254397139845		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.3836254397139845 | validation: 0.44173042991248634]
	TIME [epoch: 10.3 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005214423874322		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.4005214423874322 | validation: 0.47138301010707223]
	TIME [epoch: 10.3 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38243752502243766		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.38243752502243766 | validation: 0.46604924379885293]
	TIME [epoch: 10.3 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.417694373987431		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.417694373987431 | validation: 0.43714527401560543]
	TIME [epoch: 10.3 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3936693212744468		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.3936693212744468 | validation: 0.43052569538874025]
	TIME [epoch: 10.3 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41361316309882534		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.41361316309882534 | validation: 0.41867920014668386]
	TIME [epoch: 10.3 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4377653814034037		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.4377653814034037 | validation: 0.43286461102584783]
	TIME [epoch: 10.3 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46133060247427504		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.46133060247427504 | validation: 0.4679473523315669]
	TIME [epoch: 10.3 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.426582567919816		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.426582567919816 | validation: 0.4595177569049174]
	TIME [epoch: 10.3 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42213291424617605		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.42213291424617605 | validation: 0.4336610886247844]
	TIME [epoch: 10.3 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44618339203659846		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.44618339203659846 | validation: 0.4631098648036979]
	TIME [epoch: 10.3 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38775282571285113		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.38775282571285113 | validation: 0.41429363114422246]
	TIME [epoch: 10.3 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4269296404363027		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.4269296404363027 | validation: 0.4316572883159554]
	TIME [epoch: 10.3 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4159284344835922		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.4159284344835922 | validation: 0.48746478539496396]
	TIME [epoch: 10.3 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4416072482007884		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.4416072482007884 | validation: 0.473870434243499]
	TIME [epoch: 10.3 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.452789431133921		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.452789431133921 | validation: 0.4883903249372766]
	TIME [epoch: 10.3 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45041121567554904		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.45041121567554904 | validation: 0.5174564909957046]
	TIME [epoch: 10.3 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4572313385164981		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.4572313385164981 | validation: 0.4659524126599224]
	TIME [epoch: 10.3 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.416760004640255		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.416760004640255 | validation: 0.4631893103767819]
	TIME [epoch: 10.3 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3888843538830239		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.3888843538830239 | validation: 0.388589593857713]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_651.pth
	Model improved!!!
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46709428035933154		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.46709428035933154 | validation: 0.433419614742528]
	TIME [epoch: 10.3 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43466011718954184		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.43466011718954184 | validation: 0.4752464633404923]
	TIME [epoch: 10.3 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.410023068359563		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.410023068359563 | validation: 0.45760672148270615]
	TIME [epoch: 10.3 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3834246307806476		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.3834246307806476 | validation: 0.43505778301498155]
	TIME [epoch: 10.3 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39329640432175483		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.39329640432175483 | validation: 0.406925579109333]
	TIME [epoch: 10.3 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4480940404357835		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.4480940404357835 | validation: 0.4662376465359865]
	TIME [epoch: 10.3 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4458750153709598		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.4458750153709598 | validation: 0.4590429392669133]
	TIME [epoch: 10.3 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246084440747464		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.4246084440747464 | validation: 0.5194353150736286]
	TIME [epoch: 10.3 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251079807143284		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.4251079807143284 | validation: 0.4505531988098781]
	TIME [epoch: 10.3 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4518600828522201		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.4518600828522201 | validation: 0.44100148449300647]
	TIME [epoch: 10.3 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3907637209649222		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.3907637209649222 | validation: 0.4448739675308099]
	TIME [epoch: 10.3 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40666946224706485		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.40666946224706485 | validation: 0.4590431054014472]
	TIME [epoch: 10.3 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3986122923565264		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.3986122923565264 | validation: 0.428767382879831]
	TIME [epoch: 10.3 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4090082447674163		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.4090082447674163 | validation: 0.4287102105622564]
	TIME [epoch: 10.3 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40389389009196536		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.40389389009196536 | validation: 0.4633136818970843]
	TIME [epoch: 10.3 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42834423701803426		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.42834423701803426 | validation: 0.504233838242397]
	TIME [epoch: 10.3 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41956512975957383		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.41956512975957383 | validation: 0.4214962756624317]
	TIME [epoch: 10.3 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4168816910251426		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.4168816910251426 | validation: 0.4437009536360254]
	TIME [epoch: 10.3 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005620517160258		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.4005620517160258 | validation: 0.44027632122289234]
	TIME [epoch: 10.3 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43932633043209224		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.43932633043209224 | validation: 0.5380999327344003]
	TIME [epoch: 10.3 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43575907131450914		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.43575907131450914 | validation: 0.4163104124157711]
	TIME [epoch: 10.3 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970974552735996		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.3970974552735996 | validation: 0.4610813909943922]
	TIME [epoch: 10.3 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4132611364162836		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.4132611364162836 | validation: 0.5887864811317058]
	TIME [epoch: 10.3 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4691958029227277		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.4691958029227277 | validation: 0.5136806594639983]
	TIME [epoch: 10.3 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.438907096559401		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.438907096559401 | validation: 0.41577536005868915]
	TIME [epoch: 10.3 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4512976821354636		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.4512976821354636 | validation: 0.43742910980070265]
	TIME [epoch: 10.3 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3906315823357038		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.3906315823357038 | validation: 0.41200923581526094]
	TIME [epoch: 10.3 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39345058458429044		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.39345058458429044 | validation: 0.42632280070144246]
	TIME [epoch: 10.3 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3828531144849996		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.3828531144849996 | validation: 0.42950064288886325]
	TIME [epoch: 10.3 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155920435003898		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.4155920435003898 | validation: 0.47794093897571116]
	TIME [epoch: 10.3 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4489687760756912		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.4489687760756912 | validation: 0.41800395767867643]
	TIME [epoch: 10.3 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39584147587342666		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.39584147587342666 | validation: 0.5024279743617488]
	TIME [epoch: 10.3 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4447304541996456		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.4447304541996456 | validation: 0.49221953159116993]
	TIME [epoch: 10.3 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4190406794018588		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.4190406794018588 | validation: 0.41580539132018085]
	TIME [epoch: 10.3 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3835723768919987		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.3835723768919987 | validation: 0.46416729565362574]
	TIME [epoch: 10.3 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38797169441582985		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.38797169441582985 | validation: 0.42038867656802403]
	TIME [epoch: 10.3 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3898594919067771		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.3898594919067771 | validation: 0.44081980813594823]
	TIME [epoch: 10.3 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.396023350067343		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.396023350067343 | validation: 0.4555599441733979]
	TIME [epoch: 10.3 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40733451807823784		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.40733451807823784 | validation: 0.4747515303654288]
	TIME [epoch: 10.3 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41475721631949136		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.41475721631949136 | validation: 0.4403809326455489]
	TIME [epoch: 10.3 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39068621688898086		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.39068621688898086 | validation: 0.4428178555748346]
	TIME [epoch: 10.3 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977167209896151		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.3977167209896151 | validation: 0.4719843417830049]
	TIME [epoch: 10.3 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4498864447742374		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.4498864447742374 | validation: 0.42856290370340233]
	TIME [epoch: 10.3 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3958929983873406		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.3958929983873406 | validation: 0.46212497864490304]
	TIME [epoch: 10.3 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3972274802685088		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.3972274802685088 | validation: 0.46890942814959313]
	TIME [epoch: 10.3 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38638984772015134		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.38638984772015134 | validation: 0.42284939082017836]
	TIME [epoch: 10.3 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38922377009333375		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.38922377009333375 | validation: 0.4443165782172516]
	TIME [epoch: 10.3 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43406172598602855		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.43406172598602855 | validation: 0.4567799415607158]
	TIME [epoch: 10.3 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3896650947519344		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.3896650947519344 | validation: 0.4387352143442746]
	TIME [epoch: 10.3 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142301043479534		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.4142301043479534 | validation: 0.4669836748294362]
	TIME [epoch: 10.3 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.401410910493779		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.401410910493779 | validation: 0.44073101151704]
	TIME [epoch: 10.3 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3837713774739472		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.3837713774739472 | validation: 0.408993300516249]
	TIME [epoch: 10.3 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3878587111012465		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.3878587111012465 | validation: 0.4873836435987204]
	TIME [epoch: 10.3 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41729209257977856		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.41729209257977856 | validation: 0.4858419035834775]
	TIME [epoch: 10.3 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39548326268279754		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.39548326268279754 | validation: 0.4676533279528217]
	TIME [epoch: 10.3 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38587066907044576		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.38587066907044576 | validation: 0.4566752933268292]
	TIME [epoch: 10.3 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4509869152903378		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.4509869152903378 | validation: 0.4797140114780096]
	TIME [epoch: 10.3 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4029809632565556		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.4029809632565556 | validation: 0.48262462193510913]
	TIME [epoch: 10.3 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39869173860851387		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.39869173860851387 | validation: 0.46303927034189574]
	TIME [epoch: 10.3 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3755705704639403		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.3755705704639403 | validation: 0.4554334232695725]
	TIME [epoch: 10.3 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39207158924504065		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.39207158924504065 | validation: 0.4544083200171204]
	TIME [epoch: 10.3 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4052842874168311		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.4052842874168311 | validation: 0.4248336409432369]
	TIME [epoch: 10.3 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39697006431358295		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.39697006431358295 | validation: 0.41674349748587913]
	TIME [epoch: 10.3 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.396185793545028		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.396185793545028 | validation: 0.39488439971953965]
	TIME [epoch: 10.3 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38036503850323		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.38036503850323 | validation: 0.4290880015355188]
	TIME [epoch: 10.3 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39728837203016387		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.39728837203016387 | validation: 0.4378013540057013]
	TIME [epoch: 10.3 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39261998956487065		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.39261998956487065 | validation: 0.4493387060436542]
	TIME [epoch: 10.3 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3875136744866245		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.3875136744866245 | validation: 0.43995260215327775]
	TIME [epoch: 10.3 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38805088744147376		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.38805088744147376 | validation: 0.43900422886700846]
	TIME [epoch: 10.3 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39156733772666014		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.39156733772666014 | validation: 0.4247054669679909]
	TIME [epoch: 10.3 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.380569256223095		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.380569256223095 | validation: 0.42554138451642815]
	TIME [epoch: 10.3 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40910477541305507		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.40910477541305507 | validation: 0.45913666093503575]
	TIME [epoch: 10.3 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38784318336801255		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.38784318336801255 | validation: 0.4055779261750348]
	TIME [epoch: 10.3 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3841000996369435		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.3841000996369435 | validation: 0.4554875500436032]
	TIME [epoch: 10.3 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38085999116115365		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.38085999116115365 | validation: 0.42207409961585274]
	TIME [epoch: 10.3 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37893224418421984		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.37893224418421984 | validation: 0.432986873565443]
	TIME [epoch: 10.3 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38994958730581264		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.38994958730581264 | validation: 0.44387360970117506]
	TIME [epoch: 10.3 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38369159238966577		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.38369159238966577 | validation: 0.4193215465552775]
	TIME [epoch: 10.3 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39516393840448477		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.39516393840448477 | validation: 0.48002119121311837]
	TIME [epoch: 10.3 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005672960308587		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.4005672960308587 | validation: 0.480251983935232]
	TIME [epoch: 10.3 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3926084745900171		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.3926084745900171 | validation: 0.42077569931783987]
	TIME [epoch: 10.3 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.378087316377936		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.378087316377936 | validation: 0.44477908236312647]
	TIME [epoch: 10.3 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950173515642722		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.3950173515642722 | validation: 0.44474533826350554]
	TIME [epoch: 10.3 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41801250919035643		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.41801250919035643 | validation: 0.5076146914582704]
	TIME [epoch: 10.3 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4279764648259919		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.4279764648259919 | validation: 0.4475990867260291]
	TIME [epoch: 10.3 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4511225677444967		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.4511225677444967 | validation: 0.5362242228529498]
	TIME [epoch: 10.3 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46562517683219945		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.46562517683219945 | validation: 0.5081471509437705]
	TIME [epoch: 10.3 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4158344496711063		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.4158344496711063 | validation: 0.4222161217875257]
	TIME [epoch: 10.3 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3844530772152738		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.3844530772152738 | validation: 0.42597240525028085]
	TIME [epoch: 10.3 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38667952004585665		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.38667952004585665 | validation: 0.4039914886258318]
	TIME [epoch: 10.3 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.385237462220316		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.385237462220316 | validation: 0.4468750228996713]
	TIME [epoch: 10.3 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46550165826310064		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.46550165826310064 | validation: 0.47502229698241677]
	TIME [epoch: 10.3 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4249978727049267		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.4249978727049267 | validation: 0.42903638941457745]
	TIME [epoch: 10.3 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38935869445103294		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.38935869445103294 | validation: 0.5639576960036802]
	TIME [epoch: 10.3 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4603142240306212		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.4603142240306212 | validation: 0.5062451037114919]
	TIME [epoch: 10.3 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40533738782980944		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.40533738782980944 | validation: 0.4120621968832454]
	TIME [epoch: 10.3 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3912871051343986		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.3912871051343986 | validation: 0.45384576468128573]
	TIME [epoch: 10.3 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39176564645420936		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.39176564645420936 | validation: 0.42915193727804396]
	TIME [epoch: 10.3 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3955972345202108		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.3955972345202108 | validation: 0.4259586997305702]
	TIME [epoch: 10.3 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38416266722471404		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.38416266722471404 | validation: 0.4013025824516901]
	TIME [epoch: 10.3 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4051620974035234		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.4051620974035234 | validation: 0.4302494339452942]
	TIME [epoch: 10.3 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43842054902686745		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.43842054902686745 | validation: 0.40863312392305956]
	TIME [epoch: 10.3 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36958967317106806		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.36958967317106806 | validation: 0.4179644881479234]
	TIME [epoch: 10.3 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37275162170962933		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.37275162170962933 | validation: 0.432781354125888]
	TIME [epoch: 10.3 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40029607497175074		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.40029607497175074 | validation: 0.43036994185745003]
	TIME [epoch: 10.3 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39181586565288284		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.39181586565288284 | validation: 0.4163229978802566]
	TIME [epoch: 10.3 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39393938695417324		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.39393938695417324 | validation: 0.45960995164473534]
	TIME [epoch: 10.3 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876000504477612		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.3876000504477612 | validation: 0.4494187768840737]
	TIME [epoch: 10.3 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38447373166227367		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.38447373166227367 | validation: 0.4345487559210861]
	TIME [epoch: 10.3 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37392035612268676		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.37392035612268676 | validation: 0.45933191291987174]
	TIME [epoch: 10.3 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4126217668424199		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.4126217668424199 | validation: 0.4279515097503825]
	TIME [epoch: 10.3 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40397881276166336		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.40397881276166336 | validation: 0.4065654417722147]
	TIME [epoch: 10.3 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38216212409981765		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.38216212409981765 | validation: 0.3923670575894485]
	TIME [epoch: 10.3 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4042052339054128		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.4042052339054128 | validation: 0.4703751293674374]
	TIME [epoch: 10.3 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4064968619226964		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.4064968619226964 | validation: 0.4133076310284595]
	TIME [epoch: 10.3 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.376712194168001		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.376712194168001 | validation: 0.4297897103317683]
	TIME [epoch: 10.3 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.418977794718137		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.418977794718137 | validation: 0.4928197440913468]
	TIME [epoch: 10.3 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42834740951537575		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.42834740951537575 | validation: 0.44986677182038487]
	TIME [epoch: 10.3 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37378957899359244		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.37378957899359244 | validation: 0.4442325879264098]
	TIME [epoch: 10.3 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4235815667543855		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.4235815667543855 | validation: 0.43025428381377095]
	TIME [epoch: 10.3 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.390686804203787		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.390686804203787 | validation: 0.41715794515367316]
	TIME [epoch: 10.3 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3786658610148695		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.3786658610148695 | validation: 0.46882955246381885]
	TIME [epoch: 10.3 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37746907708487676		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.37746907708487676 | validation: 0.40370537827306635]
	TIME [epoch: 10.3 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38297039937277255		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.38297039937277255 | validation: 0.42339842007941997]
	TIME [epoch: 10.3 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3998009215664517		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.3998009215664517 | validation: 0.4285109260870188]
	TIME [epoch: 10.3 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40353383171659135		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.40353383171659135 | validation: 0.4478116889516861]
	TIME [epoch: 10.3 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3973976726128323		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.3973976726128323 | validation: 0.4272896874515608]
	TIME [epoch: 10.3 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3790297781591365		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.3790297781591365 | validation: 0.44008423966386395]
	TIME [epoch: 10.3 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38013523611390454		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.38013523611390454 | validation: 0.40728263119701874]
	TIME [epoch: 10.3 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3802289439529427		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.3802289439529427 | validation: 0.42497683109290324]
	TIME [epoch: 10.3 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3721746325710217		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.3721746325710217 | validation: 0.4432721832044695]
	TIME [epoch: 10.3 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37791897083039144		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.37791897083039144 | validation: 0.3987083547676115]
	TIME [epoch: 10.3 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38163033231444354		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.38163033231444354 | validation: 0.411425926013994]
	TIME [epoch: 10.3 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3735108200115871		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.3735108200115871 | validation: 0.4430278109180361]
	TIME [epoch: 10.3 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41446613948074507		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.41446613948074507 | validation: 0.4595290950590548]
	TIME [epoch: 10.3 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4004244878203824		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.4004244878203824 | validation: 0.4932201565382805]
	TIME [epoch: 10.3 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4144551948134686		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.4144551948134686 | validation: 0.3892618639706923]
	TIME [epoch: 10.3 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3870225451179766		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.3870225451179766 | validation: 0.46897065639935664]
	TIME [epoch: 10.3 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3781521659422642		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.3781521659422642 | validation: 0.4218783204861937]
	TIME [epoch: 10.3 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3728739358311819		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.3728739358311819 | validation: 0.42087657331121736]
	TIME [epoch: 10.3 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3679899562217025		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.3679899562217025 | validation: 0.4431704580887885]
	TIME [epoch: 10.3 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3750013513645152		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.3750013513645152 | validation: 0.45161172184406057]
	TIME [epoch: 10.3 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39945182263058154		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.39945182263058154 | validation: 0.4106206018225391]
	TIME [epoch: 10.3 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3649809539567884		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.3649809539567884 | validation: 0.4288061866522612]
	TIME [epoch: 10.3 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38509286351179634		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.38509286351179634 | validation: 0.416574962636217]
	TIME [epoch: 10.3 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.371842305293972		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.371842305293972 | validation: 0.4253355121244462]
	TIME [epoch: 10.3 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38130452455404296		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.38130452455404296 | validation: 0.41635694410032487]
	TIME [epoch: 10.3 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3813073267572239		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.3813073267572239 | validation: 0.43992287514838097]
	TIME [epoch: 10.3 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3815981447641442		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.3815981447641442 | validation: 0.4288449996256938]
	TIME [epoch: 10.3 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3864611908965766		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.3864611908965766 | validation: 0.4332036221358574]
	TIME [epoch: 10.3 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38227059018612397		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.38227059018612397 | validation: 0.4540929121459672]
	TIME [epoch: 10.3 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36117185129770407		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.36117185129770407 | validation: 0.4140541090899786]
	TIME [epoch: 10.3 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3606662367248592		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.3606662367248592 | validation: 0.3835273752016683]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_804.pth
	Model improved!!!
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3744892366130313		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.3744892366130313 | validation: 0.4285824493414065]
	TIME [epoch: 10.3 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3764620880476911		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.3764620880476911 | validation: 0.44358151025591797]
	TIME [epoch: 10.3 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37506214566337454		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.37506214566337454 | validation: 0.43515089628387266]
	TIME [epoch: 10.3 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36478875983377734		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.36478875983377734 | validation: 0.4262166288366844]
	TIME [epoch: 10.3 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3791765421948967		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.3791765421948967 | validation: 0.38274308186244443]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_809.pth
	Model improved!!!
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36048175298894886		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.36048175298894886 | validation: 0.4424138435049887]
	TIME [epoch: 10.3 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38348462223027463		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.38348462223027463 | validation: 0.4051499934480438]
	TIME [epoch: 10.3 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3557225435906651		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.3557225435906651 | validation: 0.42780148596452516]
	TIME [epoch: 10.3 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3712099150125428		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.3712099150125428 | validation: 0.3994618546884321]
	TIME [epoch: 10.3 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3712138256788885		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.3712138256788885 | validation: 0.44396166203819837]
	TIME [epoch: 10.3 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38637038495824966		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.38637038495824966 | validation: 0.42831232602600394]
	TIME [epoch: 10.3 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36692768723498437		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.36692768723498437 | validation: 0.4225352478480017]
	TIME [epoch: 10.3 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37749956938668633		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.37749956938668633 | validation: 0.39410984240334324]
	TIME [epoch: 10.3 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3819588085381208		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.3819588085381208 | validation: 0.40755796878761713]
	TIME [epoch: 10.3 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3669706422779543		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.3669706422779543 | validation: 0.42091618500323125]
	TIME [epoch: 10.3 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3644802067127547		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.3644802067127547 | validation: 0.41706956121745964]
	TIME [epoch: 10.3 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37295718127616284		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.37295718127616284 | validation: 0.3876178694577132]
	TIME [epoch: 10.3 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3677049968777748		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.3677049968777748 | validation: 0.42541569466822493]
	TIME [epoch: 10.3 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36537853867177905		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.36537853867177905 | validation: 0.3706618295024067]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_823.pth
	Model improved!!!
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36775570441596994		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.36775570441596994 | validation: 0.3886214674627568]
	TIME [epoch: 10.3 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3660061315221893		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.3660061315221893 | validation: 0.446893550050857]
	TIME [epoch: 10.3 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37048171125789053		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.37048171125789053 | validation: 0.4307485489490459]
	TIME [epoch: 10.3 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3826572485981836		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.3826572485981836 | validation: 0.42359283178719703]
	TIME [epoch: 10.3 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3738952040007793		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.3738952040007793 | validation: 0.4308687428134498]
	TIME [epoch: 10.3 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37522173711239004		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.37522173711239004 | validation: 0.4054872944348412]
	TIME [epoch: 10.3 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3863245408523774		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.3863245408523774 | validation: 0.4262765262689494]
	TIME [epoch: 10.3 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3708006761582374		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.3708006761582374 | validation: 0.44719145825742546]
	TIME [epoch: 10.3 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3759555840977687		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.3759555840977687 | validation: 0.4262982507344502]
	TIME [epoch: 10.3 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795912885845637		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.3795912885845637 | validation: 0.43236365407916305]
	TIME [epoch: 10.3 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36830722418591766		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.36830722418591766 | validation: 0.4308020910300601]
	TIME [epoch: 10.3 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3836131639072171		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.3836131639072171 | validation: 0.3899886150534075]
	TIME [epoch: 10.3 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36046814014868556		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.36046814014868556 | validation: 0.4113805912539408]
	TIME [epoch: 10.3 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37251659896249273		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.37251659896249273 | validation: 0.42579165945383113]
	TIME [epoch: 10.3 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37745613325369465		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.37745613325369465 | validation: 0.4515699826161209]
	TIME [epoch: 10.3 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3745665608720456		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.3745665608720456 | validation: 0.4303423577702389]
	TIME [epoch: 10.3 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39357752367233106		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.39357752367233106 | validation: 0.41547227980536827]
	TIME [epoch: 10.3 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38392070577462684		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.38392070577462684 | validation: 0.3962802857169455]
	TIME [epoch: 10.3 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36663777430760075		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.36663777430760075 | validation: 0.4291058322108002]
	TIME [epoch: 10.3 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37948346075168865		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.37948346075168865 | validation: 0.45065615224350153]
	TIME [epoch: 10.3 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3689801565521559		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.3689801565521559 | validation: 0.4121676749729453]
	TIME [epoch: 10.3 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38022474272194373		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.38022474272194373 | validation: 0.3982086412427907]
	TIME [epoch: 10.3 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39585839925406796		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.39585839925406796 | validation: 0.42441492154995425]
	TIME [epoch: 10.3 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3862496433860097		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.3862496433860097 | validation: 0.41838993798419594]
	TIME [epoch: 10.3 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3725605656533048		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.3725605656533048 | validation: 0.4514225366008715]
	TIME [epoch: 10.3 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3862149630184112		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.3862149630184112 | validation: 0.387253874645173]
	TIME [epoch: 10.3 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3556857338805319		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.3556857338805319 | validation: 0.38416434431722657]
	TIME [epoch: 10.3 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36239422153452716		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.36239422153452716 | validation: 0.42408966813147714]
	TIME [epoch: 10.3 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37187953332353685		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.37187953332353685 | validation: 0.4236861120433575]
	TIME [epoch: 10.3 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615258892787711		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.3615258892787711 | validation: 0.4080445936816324]
	TIME [epoch: 10.3 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3572156310152932		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.3572156310152932 | validation: 0.3904475962352132]
	TIME [epoch: 10.3 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3719639614885762		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.3719639614885762 | validation: 0.4112517084000736]
	TIME [epoch: 10.3 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37221146918822506		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.37221146918822506 | validation: 0.4384788931555902]
	TIME [epoch: 10.3 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38095240031290095		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.38095240031290095 | validation: 0.43848274877168925]
	TIME [epoch: 10.3 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950982049695201		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.3950982049695201 | validation: 0.43828741076360206]
	TIME [epoch: 10.3 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3796563296839401		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.3796563296839401 | validation: 0.41478196586483734]
	TIME [epoch: 10.3 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35744829368947273		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.35744829368947273 | validation: 0.417529840104112]
	TIME [epoch: 10.3 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3687624312278307		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.3687624312278307 | validation: 0.4151508144748105]
	TIME [epoch: 10.3 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37265947856768866		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.37265947856768866 | validation: 0.4299290537274041]
	TIME [epoch: 10.3 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36148600699304356		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.36148600699304356 | validation: 0.39257864606907517]
	TIME [epoch: 10.3 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37129404598770366		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.37129404598770366 | validation: 0.4454742311005185]
	TIME [epoch: 10.3 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37794354242436146		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.37794354242436146 | validation: 0.417516136100524]
	TIME [epoch: 10.3 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3655485198145446		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.3655485198145446 | validation: 0.4247825061570154]
	TIME [epoch: 10.3 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36626359524972096		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.36626359524972096 | validation: 0.40552787445231664]
	TIME [epoch: 10.3 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3739397231411115		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.3739397231411115 | validation: 0.3861744464363355]
	TIME [epoch: 10.3 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36890311837214274		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.36890311837214274 | validation: 0.4215354628964606]
	TIME [epoch: 10.3 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36916888540127546		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.36916888540127546 | validation: 0.4323233533562994]
	TIME [epoch: 10.3 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.370369038656445		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.370369038656445 | validation: 0.4106295092103147]
	TIME [epoch: 10.3 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37844858796127456		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.37844858796127456 | validation: 0.43246779105667044]
	TIME [epoch: 10.3 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3649602142586551		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.3649602142586551 | validation: 0.4202767559157197]
	TIME [epoch: 10.3 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36697937948332304		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.36697937948332304 | validation: 0.39978481248903436]
	TIME [epoch: 10.3 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36808523537073984		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.36808523537073984 | validation: 0.4063520914877951]
	TIME [epoch: 10.3 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3635963428860252		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.3635963428860252 | validation: 0.3951859104153979]
	TIME [epoch: 10.3 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36256903383661		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.36256903383661 | validation: 0.4438700976942674]
	TIME [epoch: 10.3 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35899025610229474		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.35899025610229474 | validation: 0.4278752898387348]
	TIME [epoch: 10.3 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3717258841096839		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.3717258841096839 | validation: 0.38961117116261684]
	TIME [epoch: 10.3 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615600113875027		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.3615600113875027 | validation: 0.44449732384458485]
	TIME [epoch: 10.3 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3712051476020746		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.3712051476020746 | validation: 0.4268174255589433]
	TIME [epoch: 10.3 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3691751065581233		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.3691751065581233 | validation: 0.39308782448371615]
	TIME [epoch: 10.3 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3917307287642916		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.3917307287642916 | validation: 0.4408664935446797]
	TIME [epoch: 10.3 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4047222293033751		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.4047222293033751 | validation: 0.40233588682809535]
	TIME [epoch: 10.3 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3623944333501544		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.3623944333501544 | validation: 0.4176356252986554]
	TIME [epoch: 10.3 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38940275806195057		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.38940275806195057 | validation: 0.4174542935667451]
	TIME [epoch: 10.3 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37696027179051267		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.37696027179051267 | validation: 0.4362064858922487]
	TIME [epoch: 10.3 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3639679131501325		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.3639679131501325 | validation: 0.435248362882147]
	TIME [epoch: 10.3 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3718441684167057		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.3718441684167057 | validation: 0.4061859472389382]
	TIME [epoch: 10.3 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3662831722804977		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.3662831722804977 | validation: 0.3763721466589853]
	TIME [epoch: 10.3 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3712060831248133		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.3712060831248133 | validation: 0.396949460978796]
	TIME [epoch: 10.3 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3532398730987835		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.3532398730987835 | validation: 0.39308447079887954]
	TIME [epoch: 10.3 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.367849584015107		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.367849584015107 | validation: 0.4733874837891537]
	TIME [epoch: 10.3 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40334342402515677		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.40334342402515677 | validation: 0.47661557434021135]
	TIME [epoch: 10.3 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3978098247894369		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.3978098247894369 | validation: 0.41442132098761236]
	TIME [epoch: 10.3 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3651695322787599		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.3651695322787599 | validation: 0.4076204736223083]
	TIME [epoch: 10.3 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35544572236611505		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.35544572236611505 | validation: 0.40037759850445864]
	TIME [epoch: 10.3 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35920189061728647		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.35920189061728647 | validation: 0.4297893457172012]
	TIME [epoch: 10.3 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3555958202933943		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.3555958202933943 | validation: 0.41830122969649197]
	TIME [epoch: 10.3 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35765318045697353		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.35765318045697353 | validation: 0.37054980167612267]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_900.pth
	Model improved!!!
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3691582687813587		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.3691582687813587 | validation: 0.43001882010570297]
	TIME [epoch: 10.3 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36488212994864977		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.36488212994864977 | validation: 0.4144476375486616]
	TIME [epoch: 10.3 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35459131385270104		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.35459131385270104 | validation: 0.42743817779695936]
	TIME [epoch: 10.3 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3618256201936898		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.3618256201936898 | validation: 0.3887570692275044]
	TIME [epoch: 10.3 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3610841835004223		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.3610841835004223 | validation: 0.38932716092290237]
	TIME [epoch: 10.3 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3699330352826754		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.3699330352826754 | validation: 0.41450779230847573]
	TIME [epoch: 10.3 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36828779704937675		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.36828779704937675 | validation: 0.4044674296790568]
	TIME [epoch: 10.3 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35546851678531155		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.35546851678531155 | validation: 0.39583227530823656]
	TIME [epoch: 10.3 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38308022597547997		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.38308022597547997 | validation: 0.42921227011712393]
	TIME [epoch: 10.3 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37467812511665904		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.37467812511665904 | validation: 0.3719289942693456]
	TIME [epoch: 10.3 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35908202523535254		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.35908202523535254 | validation: 0.4393790325456362]
	TIME [epoch: 10.3 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3704561273844353		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.3704561273844353 | validation: 0.4486184599625331]
	TIME [epoch: 10.3 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3570439252446483		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.3570439252446483 | validation: 0.42411092959856794]
	TIME [epoch: 10.3 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3649692748145131		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.3649692748145131 | validation: 0.40647252122251176]
	TIME [epoch: 10.3 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3478304577159299		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.3478304577159299 | validation: 0.4213740417502556]
	TIME [epoch: 10.3 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3694790140619829		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.3694790140619829 | validation: 0.4135333001911328]
	TIME [epoch: 10.3 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3586733305512672		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.3586733305512672 | validation: 0.4041070808737042]
	TIME [epoch: 10.2 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35850363951245107		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.35850363951245107 | validation: 0.42530232457997985]
	TIME [epoch: 10.3 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37850054348588275		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.37850054348588275 | validation: 0.47592099838641183]
	TIME [epoch: 10.3 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41538299269124207		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.41538299269124207 | validation: 0.4549913618490066]
	TIME [epoch: 10.3 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37799146388142346		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.37799146388142346 | validation: 0.4272636788803347]
	TIME [epoch: 10.3 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3611291975111374		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.3611291975111374 | validation: 0.3915346667296]
	TIME [epoch: 10.3 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3612456782572325		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.3612456782572325 | validation: 0.41535848372983564]
	TIME [epoch: 10.3 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3780150040270738		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.3780150040270738 | validation: 0.42334046582251433]
	TIME [epoch: 10.3 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3648465353624819		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.3648465353624819 | validation: 0.40082186476298914]
	TIME [epoch: 10.3 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36427442149493927		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.36427442149493927 | validation: 0.40390102273229034]
	TIME [epoch: 10.3 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3537880505813455		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.3537880505813455 | validation: 0.4205364641671369]
	TIME [epoch: 10.3 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3642689773229861		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.3642689773229861 | validation: 0.42190288839697937]
	TIME [epoch: 10.3 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3620489178325978		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.3620489178325978 | validation: 0.4177261976001285]
	TIME [epoch: 10.3 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3624819032498098		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.3624819032498098 | validation: 0.40622860215159207]
	TIME [epoch: 10.3 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35893177810145827		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.35893177810145827 | validation: 0.4085770638083254]
	TIME [epoch: 10.3 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3618706719305277		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.3618706719305277 | validation: 0.395960722801711]
	TIME [epoch: 10.3 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3693331847422876		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.3693331847422876 | validation: 0.40687810124614265]
	TIME [epoch: 10.3 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35612528236429253		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.35612528236429253 | validation: 0.3892750612247042]
	TIME [epoch: 10.3 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3627235626536667		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.3627235626536667 | validation: 0.4067231704535182]
	TIME [epoch: 10.3 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3742274387427772		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.3742274387427772 | validation: 0.3964420855812874]
	TIME [epoch: 10.3 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3576856793420838		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.3576856793420838 | validation: 0.4173741295331277]
	TIME [epoch: 10.3 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3593230003463105		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.3593230003463105 | validation: 0.408985328303956]
	TIME [epoch: 10.3 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3754993907335661		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.3754993907335661 | validation: 0.40412076899661153]
	TIME [epoch: 10.3 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3600044941275793		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.3600044941275793 | validation: 0.4000331089754696]
	TIME [epoch: 10.3 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3548420572896488		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.3548420572896488 | validation: 0.3909554959473114]
	TIME [epoch: 10.3 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35481314699850075		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.35481314699850075 | validation: 0.38807446704626125]
	TIME [epoch: 10.3 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35479138505275887		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.35479138505275887 | validation: 0.4236719758665001]
	TIME [epoch: 10.3 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3640562366932102		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.3640562366932102 | validation: 0.3876109160598743]
	TIME [epoch: 10.3 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3549706415944973		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.3549706415944973 | validation: 0.4222837825664152]
	TIME [epoch: 10.3 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3691059413527932		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.3691059413527932 | validation: 0.4022511486859521]
	TIME [epoch: 10.3 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.356341347442788		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.356341347442788 | validation: 0.43541696739170943]
	TIME [epoch: 10.2 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3695842770643841		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.3695842770643841 | validation: 0.45630958415465367]
	TIME [epoch: 10.2 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3742162654526739		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.3742162654526739 | validation: 0.4287941379104845]
	TIME [epoch: 10.3 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3508069249377745		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.3508069249377745 | validation: 0.39336037972659704]
	TIME [epoch: 10.2 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3569201877795174		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.3569201877795174 | validation: 0.4292894973361925]
	TIME [epoch: 10.3 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3678418622167287		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.3678418622167287 | validation: 0.403832459197951]
	TIME [epoch: 10.3 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35608742924694814		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.35608742924694814 | validation: 0.37410252905717434]
	TIME [epoch: 10.3 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36458255129590594		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.36458255129590594 | validation: 0.430191234815665]
	TIME [epoch: 10.3 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3736178396224627		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.3736178396224627 | validation: 0.41317409171783404]
	TIME [epoch: 10.3 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3661423786840043		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.3661423786840043 | validation: 0.4065033202371446]
	TIME [epoch: 10.3 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3551639664695059		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.3551639664695059 | validation: 0.4122627732760629]
	TIME [epoch: 10.3 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3673233687930741		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.3673233687930741 | validation: 0.386044452385884]
	TIME [epoch: 10.3 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3581292786696529		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.3581292786696529 | validation: 0.39541667299066036]
	TIME [epoch: 10.3 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35326907398051904		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.35326907398051904 | validation: 0.4472598402469103]
	TIME [epoch: 10.3 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3596518916200122		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.3596518916200122 | validation: 0.40330716215616436]
	TIME [epoch: 10.2 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37414401173594813		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.37414401173594813 | validation: 0.4064365216148292]
	TIME [epoch: 10.3 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3613179337601435		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.3613179337601435 | validation: 0.42601944997991636]
	TIME [epoch: 10.3 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35728472004593337		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.35728472004593337 | validation: 0.40774344486775027]
	TIME [epoch: 10.3 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3531745600850615		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.3531745600850615 | validation: 0.40349069548144856]
	TIME [epoch: 10.3 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3552599937354345		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.3552599937354345 | validation: 0.43716475506496877]
	TIME [epoch: 10.3 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36532054637489264		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.36532054637489264 | validation: 0.3912917532051116]
	TIME [epoch: 10.3 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3591363982686622		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.3591363982686622 | validation: 0.3882668378133877]
	TIME [epoch: 10.3 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3636701876277731		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.3636701876277731 | validation: 0.3776853226389321]
	TIME [epoch: 10.3 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3672183762290756		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.3672183762290756 | validation: 0.38135722306316466]
	TIME [epoch: 10.3 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3517725094423063		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.3517725094423063 | validation: 0.4232986417605919]
	TIME [epoch: 10.3 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3625220239648538		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.3625220239648538 | validation: 0.41600146042007236]
	TIME [epoch: 10.3 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36083102869038997		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.36083102869038997 | validation: 0.3992662228104641]
	TIME [epoch: 10.3 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3616831731099351		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.3616831731099351 | validation: 0.4028365927203288]
	TIME [epoch: 10.3 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35650795748780595		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.35650795748780595 | validation: 0.40233655578804417]
	TIME [epoch: 10.3 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3678954993673202		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.3678954993673202 | validation: 0.38744143208269427]
	TIME [epoch: 10.3 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36520055305917476		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.36520055305917476 | validation: 0.36663919694211206]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240217_161441/states/model_tr_study6_977.pth
	Model improved!!!
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3600124497134131		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.3600124497134131 | validation: 0.3789226888517464]
	TIME [epoch: 10.3 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3559940123994802		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.3559940123994802 | validation: 0.4153681325956886]
	TIME [epoch: 10.3 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36169320867479554		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.36169320867479554 | validation: 0.42371205602035955]
	TIME [epoch: 10.3 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3575921876269669		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.3575921876269669 | validation: 0.39817751156335734]
	TIME [epoch: 10.3 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36892927111677065		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.36892927111677065 | validation: 0.38783143253451896]
	TIME [epoch: 10.2 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3562870950801219		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.3562870950801219 | validation: 0.38602485639135714]
	TIME [epoch: 10.3 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3613570349551997		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.3613570349551997 | validation: 0.41131457752352957]
	TIME [epoch: 10.3 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36072480072402935		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.36072480072402935 | validation: 0.41280935970776855]
	TIME [epoch: 10.3 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35325894227329435		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.35325894227329435 | validation: 0.37695981946531426]
	TIME [epoch: 10.3 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3547236845489512		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.3547236845489512 | validation: 0.3834538721984875]
	TIME [epoch: 10.3 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37020259969259084		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.37020259969259084 | validation: 0.46676899140039085]
	TIME [epoch: 10.2 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3653343881382126		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.3653343881382126 | validation: 0.39615527730160827]
	TIME [epoch: 10.3 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3737262481181761		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.3737262481181761 | validation: 0.42471221059680303]
	TIME [epoch: 10.3 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36191462830332477		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.36191462830332477 | validation: 0.3987480120879036]
	TIME [epoch: 10.3 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3673833856988577		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.3673833856988577 | validation: 0.3737108473523992]
	TIME [epoch: 10.3 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3645733127501121		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.3645733127501121 | validation: 0.42765963542976493]
	TIME [epoch: 10.3 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36342899416879326		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.36342899416879326 | validation: 0.4204113385779931]
	TIME [epoch: 10.3 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3566201164761143		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.3566201164761143 | validation: 0.3808522388912449]
	TIME [epoch: 10.3 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35883253205744114		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.35883253205744114 | validation: 0.3929526522886095]
	TIME [epoch: 10.2 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36073644185279424		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.36073644185279424 | validation: 0.3852929304385397]
	TIME [epoch: 10.3 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35274273994644056		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.35274273994644056 | validation: 0.42243718531166335]
	TIME [epoch: 10.3 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3464732544937203		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.3464732544937203 | validation: 0.4179731813763206]
	TIME [epoch: 10.2 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3585769178724482		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.3585769178724482 | validation: 0.4291148295698888]
	TIME [epoch: 10.2 sec]
Finished training in 10382.403 seconds.
