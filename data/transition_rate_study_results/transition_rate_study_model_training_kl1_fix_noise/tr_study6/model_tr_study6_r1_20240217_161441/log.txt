Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3369419183

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.383126054248581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.383126054248581 | validation: 8.091520174684518]
	TIME [epoch: 71.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.237826023337558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.237826023337558 | validation: 8.077445219073907]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.700699746196287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.700699746196287 | validation: 7.254181495793253]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8080724108318815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8080724108318815 | validation: 5.897614779635119]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.099220764083368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.099220764083368 | validation: 5.7783711591719715]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.10723422758262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.10723422758262 | validation: 6.2010657485146625]
	TIME [epoch: 10.2 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.7017845257296464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7017845257296464 | validation: 4.836675273643599]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.582790242464001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.582790242464001 | validation: 4.938760068969371]
	TIME [epoch: 10.2 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.196896467116196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.196896467116196 | validation: 4.874260118829852]
	TIME [epoch: 10.2 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.217016608996907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.217016608996907 | validation: 6.033195868033127]
	TIME [epoch: 10.2 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.921601761095087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.921601761095087 | validation: 5.284538635673855]
	TIME [epoch: 10.3 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.845935627605028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.845935627605028 | validation: 4.100027708950859]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.558046110831436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.558046110831436 | validation: 4.205882885515763]
	TIME [epoch: 10.2 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.451169181256368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.451169181256368 | validation: 4.1621387532171195]
	TIME [epoch: 10.2 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.205589491034016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.205589491034016 | validation: 3.62368846960101]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.561483334015745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.561483334015745 | validation: 3.4587306744607997]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9939303409256026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9939303409256026 | validation: 3.1872587897092854]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4746063507472984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4746063507472984 | validation: 3.3920154692549227]
	TIME [epoch: 10.2 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.458618196084494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.458618196084494 | validation: 2.5622825184796585]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0910272713401414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0910272713401414 | validation: 2.7487911357000394]
	TIME [epoch: 10.2 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1381834553041297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1381834553041297 | validation: 2.8896723606226113]
	TIME [epoch: 10.2 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9827774234553805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9827774234553805 | validation: 3.3370463781106463]
	TIME [epoch: 10.2 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.170499311192151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.170499311192151 | validation: 2.5961370265848336]
	TIME [epoch: 10.2 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9142250691021605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9142250691021605 | validation: 2.2588815097063093]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8097957928445068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8097957928445068 | validation: 2.2890707215318975]
	TIME [epoch: 10.2 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.789340752373961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.789340752373961 | validation: 2.4860422513747613]
	TIME [epoch: 10.2 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.787182861865343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.787182861865343 | validation: 2.4345882149641613]
	TIME [epoch: 10.2 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.838691065773889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.838691065773889 | validation: 2.1941528372607193]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.851905578879771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.851905578879771 | validation: 2.2901651230931863]
	TIME [epoch: 10.2 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.780707867764658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.780707867764658 | validation: 2.4111164268013483]
	TIME [epoch: 10.2 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.850735952580661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.850735952580661 | validation: 2.4627445781194606]
	TIME [epoch: 10.2 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7890933927885913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7890933927885913 | validation: 2.1355592724225567]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8308216501691223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8308216501691223 | validation: 2.1417998901523627]
	TIME [epoch: 10.2 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8002058885642582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8002058885642582 | validation: 2.1959712924046935]
	TIME [epoch: 10.2 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7285993999246463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7285993999246463 | validation: 2.405827089588766]
	TIME [epoch: 10.2 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7850550854816727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7850550854816727 | validation: 2.2273086481226]
	TIME [epoch: 10.2 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.678828986731233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.678828986731233 | validation: 2.285185598410888]
	TIME [epoch: 10.2 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6888525256013835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6888525256013835 | validation: 2.23986650637952]
	TIME [epoch: 10.2 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7835150623505824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7835150623505824 | validation: 2.2613289796290164]
	TIME [epoch: 10.2 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8131884298914875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8131884298914875 | validation: 2.12906551219038]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8018594860360273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8018594860360273 | validation: 2.391854856982788]
	TIME [epoch: 10.2 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.144458089046883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.144458089046883 | validation: 3.0413434232316945]
	TIME [epoch: 10.2 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.903365169580254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.903365169580254 | validation: 2.321155391357062]
	TIME [epoch: 10.2 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.692544479109716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.692544479109716 | validation: 2.232582941442941]
	TIME [epoch: 10.2 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7225149614697344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7225149614697344 | validation: 2.2042615047685934]
	TIME [epoch: 10.2 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6580886425610535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6580886425610535 | validation: 2.2149183726749975]
	TIME [epoch: 10.2 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7270721341720745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7270721341720745 | validation: 2.100843047942925]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7637403331864694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7637403331864694 | validation: 2.2873425652790806]
	TIME [epoch: 10.2 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6871999160933315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6871999160933315 | validation: 2.33056577413914]
	TIME [epoch: 10.2 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.717789009937614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.717789009937614 | validation: 2.4344101806197074]
	TIME [epoch: 10.2 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8947013134463733		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 2.8947013134463733 | validation: 2.655307771249826]
	TIME [epoch: 10.2 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.057560815651606		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 3.057560815651606 | validation: 2.616901442625018]
	TIME [epoch: 10.2 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8738061991059647		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 2.8738061991059647 | validation: 2.3268721386726496]
	TIME [epoch: 10.2 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.685897557902689		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 2.685897557902689 | validation: 2.11441112618883]
	TIME [epoch: 10.2 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.659444365604604		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 2.659444365604604 | validation: 2.287219837524255]
	TIME [epoch: 10.2 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.777677826046861		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 2.777677826046861 | validation: 2.2481764451545354]
	TIME [epoch: 10.2 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.119723011744696		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 3.119723011744696 | validation: 2.7616038108322765]
	TIME [epoch: 10.2 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.756589940951359		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 2.756589940951359 | validation: 2.293450517098341]
	TIME [epoch: 10.2 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6883028781866067		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 2.6883028781866067 | validation: 2.104573013509376]
	TIME [epoch: 10.2 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9396819388046818		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 2.9396819388046818 | validation: 2.202790976863161]
	TIME [epoch: 10.2 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7031849956324425		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 2.7031849956324425 | validation: 2.342545328122506]
	TIME [epoch: 10.2 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7970029409406987		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 2.7970029409406987 | validation: 2.2416781181518153]
	TIME [epoch: 10.2 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7251551273712664		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 2.7251551273712664 | validation: 2.346556027304055]
	TIME [epoch: 10.2 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.743330876492842		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 2.743330876492842 | validation: 2.185801049310338]
	TIME [epoch: 10.2 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.718760352735052		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 2.718760352735052 | validation: 2.467193852006105]
	TIME [epoch: 10.2 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.822198355774805		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 2.822198355774805 | validation: 2.1754300977775585]
	TIME [epoch: 10.2 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.665725176928898		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 2.665725176928898 | validation: 2.0976800816137775]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.636782928950622		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 2.636782928950622 | validation: 2.219160779088387]
	TIME [epoch: 10.2 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.65650509864461		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 2.65650509864461 | validation: 2.262108437952756]
	TIME [epoch: 10.2 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.669384492512934		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 2.669384492512934 | validation: 2.1412012075996274]
	TIME [epoch: 10.2 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.876427967913587		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 2.876427967913587 | validation: 2.53320299582922]
	TIME [epoch: 10.2 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.780601059507767		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 2.780601059507767 | validation: 2.2038208133612476]
	TIME [epoch: 10.2 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6394366677277583		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 2.6394366677277583 | validation: 2.141243324701731]
	TIME [epoch: 10.2 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6477745953041456		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 2.6477745953041456 | validation: 3.09540549052128]
	TIME [epoch: 10.2 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.013546141367592		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 3.013546141367592 | validation: 2.1040981170967497]
	TIME [epoch: 10.2 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8123388167351466		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 2.8123388167351466 | validation: 2.2947188765295885]
	TIME [epoch: 10.2 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6676098315528027		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 2.6676098315528027 | validation: 2.1665917683305627]
	TIME [epoch: 10.2 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6452382149566716		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 2.6452382149566716 | validation: 2.3266219283110625]
	TIME [epoch: 10.2 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.709130256867942		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 2.709130256867942 | validation: 2.085714423780128]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.656865769420442		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 2.656865769420442 | validation: 4.337216208489142]
	TIME [epoch: 10.2 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.245635629656696		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 5.245635629656696 | validation: 2.588399926619018]
	TIME [epoch: 10.2 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7814595699173497		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 2.7814595699173497 | validation: 2.08502398322919]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.654251468635656		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 2.654251468635656 | validation: 2.1827550614786566]
	TIME [epoch: 10.2 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.689083643066123		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 2.689083643066123 | validation: 2.3264349529855997]
	TIME [epoch: 10.2 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6736324793528503		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 2.6736324793528503 | validation: 2.153097752066164]
	TIME [epoch: 10.2 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.881637412396432		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 2.881637412396432 | validation: 3.20065166293626]
	TIME [epoch: 10.2 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8636188448106736		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 2.8636188448106736 | validation: 2.2326562802262084]
	TIME [epoch: 10.2 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6215761173062764		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 2.6215761173062764 | validation: 2.5160540962243783]
	TIME [epoch: 10.2 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8825043168894253		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 2.8825043168894253 | validation: 2.868159479621378]
	TIME [epoch: 10.2 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9710067557076636		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 2.9710067557076636 | validation: 2.1558055817982043]
	TIME [epoch: 10.2 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6330006007921503		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 2.6330006007921503 | validation: 2.1747758798753045]
	TIME [epoch: 10.2 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9209003744917434		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 2.9209003744917434 | validation: 2.2136125997317384]
	TIME [epoch: 10.2 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6578121510053565		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 2.6578121510053565 | validation: 2.17241456738312]
	TIME [epoch: 10.2 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.606448620383322		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 2.606448620383322 | validation: 2.1373211402030123]
	TIME [epoch: 10.2 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6301299347343225		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 2.6301299347343225 | validation: 3.1908649014608796]
	TIME [epoch: 10.2 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0305766078339893		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 3.0305766078339893 | validation: 2.210133324168282]
	TIME [epoch: 10.2 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6360348596991687		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 2.6360348596991687 | validation: 2.1683446257994823]
	TIME [epoch: 10.2 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.731624047758559		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 2.731624047758559 | validation: 2.189739522508252]
	TIME [epoch: 10.2 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.633625534370072		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 2.633625534370072 | validation: 2.1377011152753447]
	TIME [epoch: 10.2 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6595135859615313		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 2.6595135859615313 | validation: 2.1446899362912366]
	TIME [epoch: 10.2 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6451355946926247		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 2.6451355946926247 | validation: 2.0923197917005467]
	TIME [epoch: 10.2 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.681950816658822		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 2.681950816658822 | validation: 2.151332938346296]
	TIME [epoch: 10.2 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6150577991648776		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 2.6150577991648776 | validation: 2.2012437410412504]
	TIME [epoch: 10.2 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.687348519571574		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 2.687348519571574 | validation: 2.2533957634939465]
	TIME [epoch: 10.2 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.771024177048497		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 2.771024177048497 | validation: 2.1294114051894715]
	TIME [epoch: 10.2 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.694466635163931		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 2.694466635163931 | validation: 2.109445996309261]
	TIME [epoch: 10.2 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6519470820146562		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 2.6519470820146562 | validation: 2.194784947656898]
	TIME [epoch: 10.2 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7400253498364613		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 2.7400253498364613 | validation: 2.2278810199417722]
	TIME [epoch: 10.2 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.646704266322131		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 2.646704266322131 | validation: 2.1206474729902345]
	TIME [epoch: 10.2 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.749316034952277		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 2.749316034952277 | validation: 2.2144537907844546]
	TIME [epoch: 10.2 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.665440305343265		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 2.665440305343265 | validation: 2.2259615551630345]
	TIME [epoch: 10.2 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.343831327449604		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 3.343831327449604 | validation: 2.5242408623225443]
	TIME [epoch: 10.2 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7591510729831024		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 2.7591510729831024 | validation: 2.3013377280045284]
	TIME [epoch: 10.2 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.696608708462105		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 2.696608708462105 | validation: 2.1847862453221154]
	TIME [epoch: 10.2 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.734251686696229		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 2.734251686696229 | validation: 2.3108833600141767]
	TIME [epoch: 10.2 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6822563103766424		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 2.6822563103766424 | validation: 2.4018627595201116]
	TIME [epoch: 10.2 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7507250489142683		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 2.7507250489142683 | validation: 2.222667537439557]
	TIME [epoch: 10.2 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.681008495414066		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 2.681008495414066 | validation: 2.1389743486137243]
	TIME [epoch: 10.2 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7122746427061206		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 2.7122746427061206 | validation: 2.148592555846594]
	TIME [epoch: 10.2 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7170864153116177		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 2.7170864153116177 | validation: 2.1685608728485506]
	TIME [epoch: 10.2 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.350044976445246		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 3.350044976445246 | validation: 2.46942247405464]
	TIME [epoch: 10.2 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.851012964922207		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 2.851012964922207 | validation: 2.4548274335341627]
	TIME [epoch: 10.2 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6914655135315266		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 2.6914655135315266 | validation: 2.1622772532162595]
	TIME [epoch: 10.2 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6722226088252627		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 2.6722226088252627 | validation: 2.202682473092771]
	TIME [epoch: 10.2 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9397516141796074		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 2.9397516141796074 | validation: 2.494285606709385]
	TIME [epoch: 10.2 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.784062155342092		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 2.784062155342092 | validation: 2.2328256571144394]
	TIME [epoch: 10.2 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6694402362078713		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 2.6694402362078713 | validation: 2.234750489932675]
	TIME [epoch: 10.2 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.697511607212854		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 2.697511607212854 | validation: 2.1498399443233756]
	TIME [epoch: 10.2 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7681613156455365		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 2.7681613156455365 | validation: 2.4047690373543187]
	TIME [epoch: 10.2 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.685497898858343		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.685497898858343 | validation: 3.867437141158178]
	TIME [epoch: 10.2 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.497926532092702		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 3.497926532092702 | validation: 2.306345957706295]
	TIME [epoch: 10.2 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9507942345750076		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 2.9507942345750076 | validation: 2.435492485581307]
	TIME [epoch: 10.2 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8936915015699407		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 2.8936915015699407 | validation: 2.2080819699219525]
	TIME [epoch: 10.2 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.814382227088025		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 2.814382227088025 | validation: 2.494953523411191]
	TIME [epoch: 10.2 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7150717980925734		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 2.7150717980925734 | validation: 2.7773160629153173]
	TIME [epoch: 10.2 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.821694323640613		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 2.821694323640613 | validation: 2.3035379308652733]
	TIME [epoch: 10.2 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.603166089141012		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 2.603166089141012 | validation: 2.2954054582358614]
	TIME [epoch: 10.2 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6423882844472297		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 2.6423882844472297 | validation: 2.2924645616642905]
	TIME [epoch: 10.2 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7083612906374195		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 2.7083612906374195 | validation: 2.203400155893735]
	TIME [epoch: 10.2 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6025979787389497		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 2.6025979787389497 | validation: 2.7952710512685566]
	TIME [epoch: 10.2 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.380083021307955		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 3.380083021307955 | validation: 3.057786105611612]
	TIME [epoch: 10.2 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.748376495188351		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 2.748376495188351 | validation: 2.4610494712284963]
	TIME [epoch: 10.2 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.678902598607615		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 2.678902598607615 | validation: 2.2885332108175613]
	TIME [epoch: 10.2 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.608780250127988		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 2.608780250127988 | validation: 2.3134463937835865]
	TIME [epoch: 10.2 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.543529027841066		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 2.543529027841066 | validation: 1.9873505504224387]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.424939551481765		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 2.424939551481765 | validation: 3.8575375857789873]
	TIME [epoch: 10.2 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2026671016925916		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 3.2026671016925916 | validation: 2.1976789134028234]
	TIME [epoch: 10.2 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.519499760269519		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 2.519499760269519 | validation: 2.1132859617735718]
	TIME [epoch: 10.2 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6929140744417697		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.6929140744417697 | validation: 2.306974391530894]
	TIME [epoch: 10.2 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6854602394924343		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 2.6854602394924343 | validation: 2.124718611749376]
	TIME [epoch: 10.2 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.530606048299285		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 2.530606048299285 | validation: 2.4065964258396293]
	TIME [epoch: 10.2 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9444607472165085		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 2.9444607472165085 | validation: 2.836770314477164]
	TIME [epoch: 10.2 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.95065679454618		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 2.95065679454618 | validation: 2.2609566063102124]
	TIME [epoch: 10.2 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7953514251265394		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 2.7953514251265394 | validation: 2.326944630846096]
	TIME [epoch: 10.2 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8092029734777695		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 2.8092029734777695 | validation: 2.3256185879147937]
	TIME [epoch: 10.2 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7003741722648464		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 2.7003741722648464 | validation: 2.746217765748444]
	TIME [epoch: 10.2 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.963722799780053		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 2.963722799780053 | validation: 2.2429847379055965]
	TIME [epoch: 10.2 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.725122606287851		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 2.725122606287851 | validation: 2.2025463427133003]
	TIME [epoch: 10.2 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.70743162816297		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 2.70743162816297 | validation: 2.212149567153046]
	TIME [epoch: 10.2 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.686962498960065		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 2.686962498960065 | validation: 2.227095017863969]
	TIME [epoch: 10.2 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6801121729687885		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 2.6801121729687885 | validation: 2.2240668227378992]
	TIME [epoch: 10.2 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.689877026683398		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 2.689877026683398 | validation: 2.256343136107404]
	TIME [epoch: 10.2 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6951809706962324		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 2.6951809706962324 | validation: 2.23285804721545]
	TIME [epoch: 10.2 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.674038004071863		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 2.674038004071863 | validation: 3.221424474288322]
	TIME [epoch: 10.2 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0556329038485286		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 3.0556329038485286 | validation: 2.083437290148692]
	TIME [epoch: 10.2 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.549240851214151		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 2.549240851214151 | validation: 2.0844901228555313]
	TIME [epoch: 10.2 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.578605628713395		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 2.578605628713395 | validation: 2.1513638828380035]
	TIME [epoch: 10.2 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5511618841098356		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 2.5511618841098356 | validation: 2.0533772354403923]
	TIME [epoch: 10.2 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7799133951026533		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 2.7799133951026533 | validation: 2.1441059205320947]
	TIME [epoch: 10.2 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6852327708314974		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 2.6852327708314974 | validation: 2.294920919119132]
	TIME [epoch: 10.2 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.709937041872839		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 2.709937041872839 | validation: 2.115640803338419]
	TIME [epoch: 10.2 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.74075872270491		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 2.74075872270491 | validation: 2.23565184814881]
	TIME [epoch: 10.2 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7061317489065297		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 2.7061317489065297 | validation: 2.467437425625106]
	TIME [epoch: 10.2 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7299639412963317		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 2.7299639412963317 | validation: 2.1728690981181455]
	TIME [epoch: 10.2 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.664259446119339		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 2.664259446119339 | validation: 2.181334432604439]
	TIME [epoch: 10.2 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7115781999034105		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 2.7115781999034105 | validation: 2.2154094744920814]
	TIME [epoch: 10.2 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.688998886241309		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 2.688998886241309 | validation: 2.101283623732745]
	TIME [epoch: 10.2 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.023095124798193		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 3.023095124798193 | validation: 3.027899452999922]
	TIME [epoch: 10.2 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0811217943948135		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 3.0811217943948135 | validation: 2.5071562111561336]
	TIME [epoch: 10.2 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7070243447904048		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 2.7070243447904048 | validation: 2.2809457708846312]
	TIME [epoch: 10.2 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7406371332637782		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 2.7406371332637782 | validation: 2.128015379898218]
	TIME [epoch: 10.2 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6843519669758296		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 2.6843519669758296 | validation: 2.219667332417057]
	TIME [epoch: 10.2 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6912681534846508		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 2.6912681534846508 | validation: 2.2244128995305408]
	TIME [epoch: 10.2 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.645566142362746		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 2.645566142362746 | validation: 2.0919378259447283]
	TIME [epoch: 10.2 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6782245393183866		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 2.6782245393183866 | validation: 2.1186225617132077]
	TIME [epoch: 10.2 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.642615722083658		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 2.642615722083658 | validation: 2.1280959962074126]
	TIME [epoch: 10.2 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0380570576400854		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 3.0380570576400854 | validation: 2.6643886478414505]
	TIME [epoch: 10.2 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.757376898973367		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 2.757376898973367 | validation: 2.2343715579923593]
	TIME [epoch: 10.2 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.589882828618003		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 2.589882828618003 | validation: 1.9496569427336778]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.516022631026087		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 2.516022631026087 | validation: 2.274601173431409]
	TIME [epoch: 10.2 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.546202969641054		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 2.546202969641054 | validation: 2.663547266091398]
	TIME [epoch: 10.2 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.771068112728103		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 2.771068112728103 | validation: 3.371830335277707]
	TIME [epoch: 10.2 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8859083780643964		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 2.8859083780643964 | validation: 2.6257135673302527]
	TIME [epoch: 10.2 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.742719047885299		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 2.742719047885299 | validation: 1.8615066324746345]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.391168226357608		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 2.391168226357608 | validation: 2.8391521217884397]
	TIME [epoch: 10.2 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5340813986923174		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 2.5340813986923174 | validation: 1.7563568792941042]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_196.pth
	Model improved!!!
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2724832954925693		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 2.2724832954925693 | validation: 2.10674149626496]
	TIME [epoch: 10.2 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.573718940618847		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 2.573718940618847 | validation: 2.473745073912763]
	TIME [epoch: 10.2 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5212126568264104		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 2.5212126568264104 | validation: 2.5313853037314713]
	TIME [epoch: 10.2 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5001077455458733		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 2.5001077455458733 | validation: 2.765766059661893]
	TIME [epoch: 10.2 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0329778901770323		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 3.0329778901770323 | validation: 2.1084147873096892]
	TIME [epoch: 10.2 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0923246374029163		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 3.0923246374029163 | validation: 3.126371869252016]
	TIME [epoch: 10.2 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2099318997905817		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 3.2099318997905817 | validation: 2.233998238706349]
	TIME [epoch: 10.2 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.743701100888862		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 2.743701100888862 | validation: 2.6637660291344973]
	TIME [epoch: 10.2 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.722903026261583		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 2.722903026261583 | validation: 2.130684989971345]
	TIME [epoch: 10.2 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6487115954396727		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 2.6487115954396727 | validation: 2.170798575855974]
	TIME [epoch: 10.2 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9562335815193066		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 2.9562335815193066 | validation: 3.5158148439703267]
	TIME [epoch: 10.2 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4891215806418914		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 3.4891215806418914 | validation: 4.951931586401478]
	TIME [epoch: 10.2 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.868245354066647		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 4.868245354066647 | validation: 4.6409831582932695]
	TIME [epoch: 10.2 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.515291535899097		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 4.515291535899097 | validation: 4.8795026416609755]
	TIME [epoch: 10.2 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.072360473678419		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 4.072360473678419 | validation: 3.613723301302305]
	TIME [epoch: 10.2 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.238629391378789		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 3.238629391378789 | validation: 2.3761321324909326]
	TIME [epoch: 10.2 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5742934988779944		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 2.5742934988779944 | validation: 1.7779556159006404]
	TIME [epoch: 10.2 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0240416820223794		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 3.0240416820223794 | validation: 2.4679139144171587]
	TIME [epoch: 10.2 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.854325811523097		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 2.854325811523097 | validation: 2.321188526567787]
	TIME [epoch: 10.2 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.15002374343571		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 3.15002374343571 | validation: 2.2470476145722222]
	TIME [epoch: 10.2 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8504218675352404		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 2.8504218675352404 | validation: 3.855517154903531]
	TIME [epoch: 10.2 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.204955248192978		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 3.204955248192978 | validation: 2.100626816034217]
	TIME [epoch: 10.2 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8710943980128993		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 2.8710943980128993 | validation: 2.482423234309954]
	TIME [epoch: 10.2 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.831721521620537		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 2.831721521620537 | validation: 2.179778138677528]
	TIME [epoch: 10.2 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.71438455152872		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 2.71438455152872 | validation: 2.1077567035682914]
	TIME [epoch: 10.2 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.893764000308493		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 2.893764000308493 | validation: 2.3639975677407965]
	TIME [epoch: 10.2 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.711132666197524		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 2.711132666197524 | validation: 2.2849401078472313]
	TIME [epoch: 10.2 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.915720653053782		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 2.915720653053782 | validation: 2.017866067501124]
	TIME [epoch: 10.2 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6589589174180843		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 2.6589589174180843 | validation: 2.0429772759870146]
	TIME [epoch: 10.2 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5589352068081235		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 2.5589352068081235 | validation: 2.20208869750878]
	TIME [epoch: 10.2 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4373781131892827		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 2.4373781131892827 | validation: 2.0951798891441915]
	TIME [epoch: 10.2 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.354858830377045		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 2.354858830377045 | validation: 1.952116196330948]
	TIME [epoch: 10.2 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4185340382825604		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 2.4185340382825604 | validation: 1.910583322634563]
	TIME [epoch: 10.2 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.265433538755391		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 2.265433538755391 | validation: 2.3099470151532775]
	TIME [epoch: 10.2 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4347461774982535		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 2.4347461774982535 | validation: 1.869172575440677]
	TIME [epoch: 10.2 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4976448492628935		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 2.4976448492628935 | validation: 2.958655815223872]
	TIME [epoch: 10.2 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9908799759675855		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 2.9908799759675855 | validation: 2.317258467602915]
	TIME [epoch: 10.2 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.705735924787146		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 2.705735924787146 | validation: 2.0955788148028534]
	TIME [epoch: 10.2 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.365394677360329		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 2.365394677360329 | validation: 1.8171665934767396]
	TIME [epoch: 10.2 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2343751985753206		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 2.2343751985753206 | validation: 2.001844098187697]
	TIME [epoch: 10.2 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.514780390134444		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 2.514780390134444 | validation: 2.337356268770683]
	TIME [epoch: 10.2 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.345822890136593		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 2.345822890136593 | validation: 1.895319179580295]
	TIME [epoch: 10.2 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2338210592629446		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 2.2338210592629446 | validation: 2.103127936243677]
	TIME [epoch: 10.2 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.469401572713365		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 2.469401572713365 | validation: 1.961332495814068]
	TIME [epoch: 10.2 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4354010556879		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 2.4354010556879 | validation: 1.9489721003653966]
	TIME [epoch: 10.2 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3808398704322578		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 2.3808398704322578 | validation: 1.902135628216293]
	TIME [epoch: 10.2 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2004872450825244		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 2.2004872450825244 | validation: 1.7877028392461392]
	TIME [epoch: 10.2 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.132679768749961		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 2.132679768749961 | validation: 2.791364886125706]
	TIME [epoch: 10.2 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4569811700527375		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 3.4569811700527375 | validation: 2.995778632659775]
	TIME [epoch: 10.2 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.175733908939784		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 3.175733908939784 | validation: 2.5239999010180845]
	TIME [epoch: 10.2 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8189591256548647		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 2.8189591256548647 | validation: 2.4026781257379097]
	TIME [epoch: 10.2 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8191977486294233		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 2.8191977486294233 | validation: 2.2183305224241314]
	TIME [epoch: 10.2 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.565384316744578		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 2.565384316744578 | validation: 2.173332809609511]
	TIME [epoch: 10.2 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2995383599448145		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 3.2995383599448145 | validation: 2.891628008268405]
	TIME [epoch: 10.2 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9890565571239263		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 2.9890565571239263 | validation: 2.2676505905070226]
	TIME [epoch: 10.2 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9207382966661632		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 2.9207382966661632 | validation: 2.3909382882958194]
	TIME [epoch: 10.2 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8019852691511304		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 2.8019852691511304 | validation: 2.2281774162323926]
	TIME [epoch: 10.2 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.893397053526744		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 2.893397053526744 | validation: 2.670867029979675]
	TIME [epoch: 10.2 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8886175924133473		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 2.8886175924133473 | validation: 2.9151967203582974]
	TIME [epoch: 10.2 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.563819529069987		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 3.563819529069987 | validation: 4.253210591756135]
	TIME [epoch: 10.2 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.01990396252432		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 4.01990396252432 | validation: 3.731835513848348]
	TIME [epoch: 10.2 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.616665036802259		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 3.616665036802259 | validation: 3.379752705520176]
	TIME [epoch: 10.2 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1605324825153938		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 3.1605324825153938 | validation: 2.556762450811969]
	TIME [epoch: 10.2 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6870228886718355		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 2.6870228886718355 | validation: 2.1699969643800205]
	TIME [epoch: 10.2 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8146556422372724		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 2.8146556422372724 | validation: 2.533954003800214]
	TIME [epoch: 10.2 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9587080109815886		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 2.9587080109815886 | validation: 2.903371818554293]
	TIME [epoch: 10.2 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7480097780368333		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 3.7480097780368333 | validation: 2.474613224326494]
	TIME [epoch: 10.2 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.049543007939651		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 3.049543007939651 | validation: 2.308492153699626]
	TIME [epoch: 10.2 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.950168837227237		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 2.950168837227237 | validation: 2.44361684176161]
	TIME [epoch: 10.2 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.034088190878584		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 3.034088190878584 | validation: 2.4175956927557998]
	TIME [epoch: 10.2 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8009217183242305		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 2.8009217183242305 | validation: 2.387901633885826]
	TIME [epoch: 10.2 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7960001281116114		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 2.7960001281116114 | validation: 2.198056413249107]
	TIME [epoch: 10.2 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.083484916844003		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 3.083484916844003 | validation: 2.1990007236005393]
	TIME [epoch: 10.2 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.650711725296169		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 2.650711725296169 | validation: 2.4298996678590887]
	TIME [epoch: 10.2 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0187794678367568		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 3.0187794678367568 | validation: 4.815034334927085]
	TIME [epoch: 10.2 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.928577879011357		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 3.928577879011357 | validation: 2.10916361069777]
	TIME [epoch: 10.2 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.914111861899186		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 2.914111861899186 | validation: 2.4338340428375242]
	TIME [epoch: 10.2 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8853323860396904		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 2.8853323860396904 | validation: 2.2036066241998093]
	TIME [epoch: 10.2 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7946389258049664		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 2.7946389258049664 | validation: 2.512085924185502]
	TIME [epoch: 10.2 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5978818761133		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 2.5978818761133 | validation: 2.267600133586427]
	TIME [epoch: 10.2 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8656933252072347		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 2.8656933252072347 | validation: 2.400345801337536]
	TIME [epoch: 10.2 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.372872995436944		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 3.372872995436944 | validation: 3.9446166504300573]
	TIME [epoch: 10.2 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1067497815758043		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 3.1067497815758043 | validation: 2.290204710363949]
	TIME [epoch: 10.2 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.775950435227455		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 2.775950435227455 | validation: 2.2308994734733605]
	TIME [epoch: 10.2 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6508775924629013		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 2.6508775924629013 | validation: 2.2928161934763334]
	TIME [epoch: 10.2 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3486109040470478		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 2.3486109040470478 | validation: 1.8761571095749157]
	TIME [epoch: 10.2 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.23191291531712		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 2.23191291531712 | validation: 2.238976536047235]
	TIME [epoch: 10.2 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.554767694200388		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 2.554767694200388 | validation: 1.8546853037712128]
	TIME [epoch: 10.2 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1461024498470365		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 2.1461024498470365 | validation: 1.721680525667255]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_285.pth
	Model improved!!!
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1436827535544896		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 2.1436827535544896 | validation: 2.065100960460931]
	TIME [epoch: 10.2 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.212516804818108		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 2.212516804818108 | validation: 2.080153660704773]
	TIME [epoch: 10.2 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2213319263206315		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 2.2213319263206315 | validation: 1.6959630973094941]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_288.pth
	Model improved!!!
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.920007315883965		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 1.920007315883965 | validation: 1.475651891023041]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_289.pth
	Model improved!!!
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8195656327376786		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 1.8195656327376786 | validation: 1.5450234653697177]
	TIME [epoch: 10.2 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9234261363832772		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 1.9234261363832772 | validation: 1.3180711182772142]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_291.pth
	Model improved!!!
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.212449221182858		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 2.212449221182858 | validation: 2.554943752938528]
	TIME [epoch: 10.2 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.595816338004483		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 2.595816338004483 | validation: 1.7946377603853227]
	TIME [epoch: 10.2 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0136428690431982		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 2.0136428690431982 | validation: 1.6515139281766653]
	TIME [epoch: 10.2 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9225987692774322		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 1.9225987692774322 | validation: 1.5463450166093247]
	TIME [epoch: 10.2 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9872853570711904		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 1.9872853570711904 | validation: 1.6736540193440208]
	TIME [epoch: 10.2 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9390681009156054		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 1.9390681009156054 | validation: 1.6028125722783548]
	TIME [epoch: 10.2 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7714743196368072		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 1.7714743196368072 | validation: 1.419007554838995]
	TIME [epoch: 10.2 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.66898099231014		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 1.66898099231014 | validation: 1.380906110675603]
	TIME [epoch: 10.2 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.644193254717147		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 1.644193254717147 | validation: 1.296924424789653]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_300.pth
	Model improved!!!
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6971134243886439		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 1.6971134243886439 | validation: 1.1808143624344485]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_301.pth
	Model improved!!!
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6780927636934557		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 1.6780927636934557 | validation: 1.4482217041847094]
	TIME [epoch: 10.2 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6719971849121795		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 1.6719971849121795 | validation: 1.6670603321776742]
	TIME [epoch: 10.2 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8062453302441681		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 1.8062453302441681 | validation: 1.266596244352259]
	TIME [epoch: 10.2 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4921249616347156		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 1.4921249616347156 | validation: 1.104003049493226]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5039132172025813		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.5039132172025813 | validation: 1.216461307952714]
	TIME [epoch: 10.2 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4586012852724983		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 1.4586012852724983 | validation: 1.089740372842856]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_307.pth
	Model improved!!!
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4023468353505615		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 1.4023468353505615 | validation: 1.407330387843556]
	TIME [epoch: 10.2 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3292026798055112		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 1.3292026798055112 | validation: 0.947659957740361]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_309.pth
	Model improved!!!
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3688998634554015		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 1.3688998634554015 | validation: 1.23554902493674]
	TIME [epoch: 10.2 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1963762676255238		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 1.1963762676255238 | validation: 1.0010426424046042]
	TIME [epoch: 10.2 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9820567818456111		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.9820567818456111 | validation: 0.8334146244458579]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_312.pth
	Model improved!!!
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9707337871336789		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 0.9707337871336789 | validation: 0.8475124901307405]
	TIME [epoch: 10.2 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.797360749417053		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 0.797360749417053 | validation: 0.7398130003910975]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_314.pth
	Model improved!!!
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8878936245006619		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 0.8878936245006619 | validation: 0.7866233346676191]
	TIME [epoch: 10.2 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2312460537946561		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 1.2312460537946561 | validation: 0.6254315296102483]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_316.pth
	Model improved!!!
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8453291925428348		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.8453291925428348 | validation: 0.7484955636329506]
	TIME [epoch: 10.2 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1436140516027096		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 1.1436140516027096 | validation: 1.056535245310962]
	TIME [epoch: 10.2 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8054222370942231		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.8054222370942231 | validation: 0.7913004588476272]
	TIME [epoch: 10.2 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7600147209130903		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.7600147209130903 | validation: 0.8928879715798396]
	TIME [epoch: 10.2 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7383712399646235		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 0.7383712399646235 | validation: 0.7635939706349691]
	TIME [epoch: 10.2 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8614600312663623		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 0.8614600312663623 | validation: 1.00259129634494]
	TIME [epoch: 10.2 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8186896886020456		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.8186896886020456 | validation: 0.7108654676511011]
	TIME [epoch: 10.2 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7207230997318954		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.7207230997318954 | validation: 0.7525106414009379]
	TIME [epoch: 10.2 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7691094164583848		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.7691094164583848 | validation: 0.7148209517446767]
	TIME [epoch: 10.2 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9032019204620034		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 0.9032019204620034 | validation: 0.7631277133962232]
	TIME [epoch: 10.2 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7200781255705485		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 0.7200781255705485 | validation: 0.8924893634593315]
	TIME [epoch: 10.2 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0646964087942759		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 1.0646964087942759 | validation: 1.9938969432496931]
	TIME [epoch: 10.2 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2625225173177943		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 1.2625225173177943 | validation: 0.6129049340838789]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_329.pth
	Model improved!!!
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8559972552138806		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 0.8559972552138806 | validation: 0.4803967200749022]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_330.pth
	Model improved!!!
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0777495030881619		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 1.0777495030881619 | validation: 0.8888496417334695]
	TIME [epoch: 10.2 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6531990173186335		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 0.6531990173186335 | validation: 0.7235321100955358]
	TIME [epoch: 10.2 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6256503574715413		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 0.6256503574715413 | validation: 0.9647123667982053]
	TIME [epoch: 10.2 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8255901433268654		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.8255901433268654 | validation: 1.0223882252221266]
	TIME [epoch: 10.2 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7281573327967507		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 0.7281573327967507 | validation: 0.4411729207920773]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_335.pth
	Model improved!!!
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5135846849042646		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.5135846849042646 | validation: 0.5845584613991823]
	TIME [epoch: 10.2 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9831758147179185		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.9831758147179185 | validation: 0.6018911721522904]
	TIME [epoch: 10.2 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.645273849754384		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.645273849754384 | validation: 0.7748409306807804]
	TIME [epoch: 10.2 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5694406015610125		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.5694406015610125 | validation: 0.44146061011401794]
	TIME [epoch: 10.2 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5934907277372147		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.5934907277372147 | validation: 0.43093468388119915]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_340.pth
	Model improved!!!
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6597509036714927		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.6597509036714927 | validation: 0.42643249139611217]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_341.pth
	Model improved!!!
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6404476978428633		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.6404476978428633 | validation: 0.8561788328507355]
	TIME [epoch: 10.2 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.708035365049005		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.708035365049005 | validation: 0.5750533964495514]
	TIME [epoch: 10.2 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.58725733705379		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.58725733705379 | validation: 0.4628420828512491]
	TIME [epoch: 10.2 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5018820888228414		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.5018820888228414 | validation: 0.894657396539609]
	TIME [epoch: 10.2 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9267451179698003		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 0.9267451179698003 | validation: 0.34630692105014005]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_346.pth
	Model improved!!!
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0064853282839674		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 1.0064853282839674 | validation: 1.2472678774907298]
	TIME [epoch: 10.2 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0344085802732417		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 1.0344085802732417 | validation: 0.4621308489839339]
	TIME [epoch: 10.2 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5882997132264107		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 0.5882997132264107 | validation: 0.4926379316534633]
	TIME [epoch: 10.2 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5403603760634357		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.5403603760634357 | validation: 0.9656519657577612]
	TIME [epoch: 10.2 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6744809848537165		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.6744809848537165 | validation: 0.35966050767263946]
	TIME [epoch: 10.2 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.599975203856473		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.599975203856473 | validation: 0.39652013432855143]
	TIME [epoch: 10.2 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42475395174141095		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 0.42475395174141095 | validation: 0.7410066795110517]
	TIME [epoch: 10.2 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8318701610371797		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.8318701610371797 | validation: 0.9981519529626326]
	TIME [epoch: 10.2 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5527984891539575		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.5527984891539575 | validation: 0.7777175458947195]
	TIME [epoch: 10.2 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6789562371226646		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.6789562371226646 | validation: 0.6969121253743776]
	TIME [epoch: 10.2 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5906802291951515		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 0.5906802291951515 | validation: 0.5310137119829235]
	TIME [epoch: 10.2 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4767692573028657		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.4767692573028657 | validation: 0.4467484718703602]
	TIME [epoch: 10.2 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46650322144719103		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 0.46650322144719103 | validation: 1.1735921717064666]
	TIME [epoch: 10.2 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8210822353736329		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.8210822353736329 | validation: 0.649953147086471]
	TIME [epoch: 10.2 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502237393207013		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.6502237393207013 | validation: 0.6052623319382667]
	TIME [epoch: 10.2 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430506520627868		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.6430506520627868 | validation: 0.6603911040444777]
	TIME [epoch: 10.2 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45943031399285406		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.45943031399285406 | validation: 0.7294707796593133]
	TIME [epoch: 10.2 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5862646343176641		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.5862646343176641 | validation: 1.0755764402125505]
	TIME [epoch: 10.2 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426690964976162		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.5426690964976162 | validation: 0.3680048873660459]
	TIME [epoch: 10.2 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9172036280013552		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.9172036280013552 | validation: 1.345641701019387]
	TIME [epoch: 10.2 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6962162954156794		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 0.6962162954156794 | validation: 0.7061120873896007]
	TIME [epoch: 10.2 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5701004951183191		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.5701004951183191 | validation: 0.4636067006226629]
	TIME [epoch: 10.2 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4685873337183013		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.4685873337183013 | validation: 0.4824749496554994]
	TIME [epoch: 10.2 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5002298082031912		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.5002298082031912 | validation: 0.4358351615525547]
	TIME [epoch: 10.2 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.013260185477094		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 1.013260185477094 | validation: 0.4242226032620752]
	TIME [epoch: 10.2 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4989805973899026		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.4989805973899026 | validation: 0.35477609627388107]
	TIME [epoch: 10.2 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6557661481267999		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.6557661481267999 | validation: 0.8170097096074241]
	TIME [epoch: 10.2 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9103045427431983		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.9103045427431983 | validation: 0.44238318786034664]
	TIME [epoch: 10.2 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5728780059550479		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.5728780059550479 | validation: 0.4559374676220479]
	TIME [epoch: 10.2 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117949371357299		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.6117949371357299 | validation: 0.6424415487235641]
	TIME [epoch: 10.2 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6091885781510171		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.6091885781510171 | validation: 0.4885934642127451]
	TIME [epoch: 10.2 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5808608661568628		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.5808608661568628 | validation: 0.49720124080594197]
	TIME [epoch: 10.2 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622347409542693		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.6622347409542693 | validation: 1.1023048917550253]
	TIME [epoch: 10.2 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6662749265817898		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.6662749265817898 | validation: 1.14731976182257]
	TIME [epoch: 10.2 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9191963325435424		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.9191963325435424 | validation: 0.8421817687830171]
	TIME [epoch: 10.2 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7669752097384734		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.7669752097384734 | validation: 0.4671154645696794]
	TIME [epoch: 10.2 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5105598063170822		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.5105598063170822 | validation: 0.7800083061471302]
	TIME [epoch: 10.2 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5890798308330931		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.5890798308330931 | validation: 0.5810499695074218]
	TIME [epoch: 10.2 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.635343152159324		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.635343152159324 | validation: 0.4642555706208866]
	TIME [epoch: 10.2 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6595625727244221		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.6595625727244221 | validation: 0.3847761102108073]
	TIME [epoch: 10.2 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7079743266057992		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.7079743266057992 | validation: 0.36316521128663254]
	TIME [epoch: 10.2 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4395877363749433		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.4395877363749433 | validation: 0.3737202511347414]
	TIME [epoch: 10.2 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4726111252256738		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.4726111252256738 | validation: 0.5687923659608195]
	TIME [epoch: 10.2 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6148384147884187		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.6148384147884187 | validation: 0.4343198878836854]
	TIME [epoch: 10.2 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8424999785338565		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.8424999785338565 | validation: 0.6821219036679915]
	TIME [epoch: 10.2 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6774664714446036		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.6774664714446036 | validation: 0.41979381747327027]
	TIME [epoch: 10.2 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6716637054193292		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.6716637054193292 | validation: 0.33464858563721916]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_393.pth
	Model improved!!!
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246380067045953		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.4246380067045953 | validation: 0.8667451393511313]
	TIME [epoch: 10.2 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8457109632280477		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.8457109632280477 | validation: 0.35622536109166275]
	TIME [epoch: 10.2 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44372458832734535		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.44372458832734535 | validation: 0.7013291296580195]
	TIME [epoch: 10.2 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.557214556488932		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.557214556488932 | validation: 0.40642786605779424]
	TIME [epoch: 10.2 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0340943771057622		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 1.0340943771057622 | validation: 1.1008190617094855]
	TIME [epoch: 10.2 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8332428158419903		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.8332428158419903 | validation: 0.3349325110240892]
	TIME [epoch: 10.2 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7446840022620961		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.7446840022620961 | validation: 0.34666096143283354]
	TIME [epoch: 10.2 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5383785674146069		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.5383785674146069 | validation: 0.35085981957922413]
	TIME [epoch: 10.2 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5455939277633456		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.5455939277633456 | validation: 0.7944353598762672]
	TIME [epoch: 10.2 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5931879973253259		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.5931879973253259 | validation: 0.657794764814981]
	TIME [epoch: 10.2 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6642026515099456		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.6642026515099456 | validation: 0.44253966763039926]
	TIME [epoch: 10.2 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5871877656604597		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.5871877656604597 | validation: 0.38266132189386626]
	TIME [epoch: 10.2 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40338749753584774		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.40338749753584774 | validation: 0.6703798380066237]
	TIME [epoch: 10.2 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45500505825403736		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.45500505825403736 | validation: 0.6847481211275402]
	TIME [epoch: 10.2 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6885752134286778		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.6885752134286778 | validation: 1.0418326984013009]
	TIME [epoch: 10.2 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6692282383549373		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.6692282383549373 | validation: 0.28776247873981303]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_409.pth
	Model improved!!!
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5859836063757068		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.5859836063757068 | validation: 0.704973675304539]
	TIME [epoch: 10.2 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286486483488003		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.5286486483488003 | validation: 0.460383012660776]
	TIME [epoch: 10.2 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1101266998258734		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 1.1101266998258734 | validation: 0.4948567083154556]
	TIME [epoch: 10.2 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4426842853093092		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.4426842853093092 | validation: 0.7620771365852642]
	TIME [epoch: 10.2 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4926137136922038		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.4926137136922038 | validation: 0.665539939162388]
	TIME [epoch: 10.2 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.510428827901491		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.510428827901491 | validation: 0.3399568236766055]
	TIME [epoch: 10.2 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3877660417053465		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.3877660417053465 | validation: 0.6346889945265832]
	TIME [epoch: 10.2 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.683901968516031		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.683901968516031 | validation: 1.3196298716487247]
	TIME [epoch: 10.2 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8194489671775294		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.8194489671775294 | validation: 0.3615272415243293]
	TIME [epoch: 10.2 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49944702326456875		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.49944702326456875 | validation: 0.409063205620681]
	TIME [epoch: 10.2 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45659987146280845		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.45659987146280845 | validation: 1.3870150795342964]
	TIME [epoch: 10.2 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9471403712524437		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.9471403712524437 | validation: 0.4028767746071836]
	TIME [epoch: 10.2 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5973820377382191		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.5973820377382191 | validation: 0.5939864807827094]
	TIME [epoch: 10.2 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.574360494026941		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.574360494026941 | validation: 0.4346686638086803]
	TIME [epoch: 10.2 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4063693414494146		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.4063693414494146 | validation: 1.2312028271446047]
	TIME [epoch: 10.2 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8255613355278737		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 1.8255613355278737 | validation: 0.929884581853513]
	TIME [epoch: 10.2 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6202950377934296		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.6202950377934296 | validation: 0.44505662814842273]
	TIME [epoch: 10.2 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3833020944093019		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.3833020944093019 | validation: 1.1664833055388493]
	TIME [epoch: 10.2 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6385387285389776		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.6385387285389776 | validation: 0.34609472442356953]
	TIME [epoch: 10.2 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46081002477973854		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.46081002477973854 | validation: 0.35846686026476327]
	TIME [epoch: 10.2 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4684867288352946		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.4684867288352946 | validation: 0.37398631996976944]
	TIME [epoch: 10.2 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6247055634721214		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.6247055634721214 | validation: 0.5125666867807364]
	TIME [epoch: 10.2 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635308346392728		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.6635308346392728 | validation: 0.5430554156333729]
	TIME [epoch: 10.2 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459108951567927		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.6459108951567927 | validation: 0.4815074629696375]
	TIME [epoch: 10.2 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576698838895245		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.4576698838895245 | validation: 0.28768561305050744]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_434.pth
	Model improved!!!
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7943035824033112		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.7943035824033112 | validation: 0.4990204510483557]
	TIME [epoch: 10.2 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41196010348527096		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.41196010348527096 | validation: 0.8665922280911643]
	TIME [epoch: 10.2 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6734172460363181		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.6734172460363181 | validation: 0.3740966959500082]
	TIME [epoch: 10.2 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48169426581846625		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.48169426581846625 | validation: 0.40447149756874495]
	TIME [epoch: 10.2 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8557867271336115		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.8557867271336115 | validation: 0.3245989986897523]
	TIME [epoch: 10.2 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47834227941467206		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.47834227941467206 | validation: 0.885228396003267]
	TIME [epoch: 10.2 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5783965983560186		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.5783965983560186 | validation: 0.6996152588921015]
	TIME [epoch: 10.2 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7906903446509608		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.7906903446509608 | validation: 0.8923105454726863]
	TIME [epoch: 10.2 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5990323527365533		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.5990323527365533 | validation: 0.4466676126986047]
	TIME [epoch: 10.2 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4302450390242948		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.4302450390242948 | validation: 0.3803065549207885]
	TIME [epoch: 10.2 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3777946702745961		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.3777946702745961 | validation: 0.8582092885803735]
	TIME [epoch: 10.2 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6871448439038754		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.6871448439038754 | validation: 0.2835976502823689]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_446.pth
	Model improved!!!
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5697073842667717		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.5697073842667717 | validation: 0.7681504793393612]
	TIME [epoch: 10.2 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6627673589723344		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.6627673589723344 | validation: 0.9820085944816103]
	TIME [epoch: 10.2 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740822236095755		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.7740822236095755 | validation: 0.46034276392009255]
	TIME [epoch: 10.2 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4345509493055271		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.4345509493055271 | validation: 0.3057337952677683]
	TIME [epoch: 10.2 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6315548801465788		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.6315548801465788 | validation: 0.3093868974024606]
	TIME [epoch: 10.2 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4480071594392855		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.4480071594392855 | validation: 0.30191054331042205]
	TIME [epoch: 10.2 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.343007659885861		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.343007659885861 | validation: 0.6521766507706687]
	TIME [epoch: 10.2 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46743777218540206		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.46743777218540206 | validation: 0.5825098701619471]
	TIME [epoch: 10.2 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124758841794941		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.4124758841794941 | validation: 0.6812944724013309]
	TIME [epoch: 10.2 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4668364804190678		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.4668364804190678 | validation: 0.40571496411246316]
	TIME [epoch: 10.2 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47952606957883265		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.47952606957883265 | validation: 0.337222647213488]
	TIME [epoch: 10.2 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41567279853195105		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.41567279853195105 | validation: 0.24431109393523565]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_458.pth
	Model improved!!!
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3039573353250765		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.3039573353250765 | validation: 0.27346301120952554]
	TIME [epoch: 10.2 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4174681625906726		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.4174681625906726 | validation: 0.25885607401014754]
	TIME [epoch: 10.2 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5414272587315778		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.5414272587315778 | validation: 0.787620986464143]
	TIME [epoch: 10.2 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5136659617416895		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.5136659617416895 | validation: 0.37705233984932746]
	TIME [epoch: 10.2 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180254902485023		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.5180254902485023 | validation: 0.3113354359489566]
	TIME [epoch: 10.2 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37436492207117483		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.37436492207117483 | validation: 0.48354724567328894]
	TIME [epoch: 10.2 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43508317739451846		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.43508317739451846 | validation: 0.2903068635357912]
	TIME [epoch: 10.2 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139358886835828		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.5139358886835828 | validation: 0.7954417416574855]
	TIME [epoch: 10.2 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6732746309232646		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.6732746309232646 | validation: 0.24204707779585172]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_467.pth
	Model improved!!!
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3718201338039354		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.3718201338039354 | validation: 0.5447891134301506]
	TIME [epoch: 10.2 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4451340412989471		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.4451340412989471 | validation: 0.30715393871221325]
	TIME [epoch: 10.2 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.842242643724058		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.842242643724058 | validation: 0.4548288405219252]
	TIME [epoch: 10.2 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6231469934146341		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.6231469934146341 | validation: 0.34899006218686174]
	TIME [epoch: 10.2 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31460213567917444		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.31460213567917444 | validation: 0.4619844435325923]
	TIME [epoch: 10.2 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3779241897590379		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.3779241897590379 | validation: 0.5476562475894514]
	TIME [epoch: 10.2 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40030524894302577		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.40030524894302577 | validation: 1.165716870270596]
	TIME [epoch: 10.2 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7587847900457653		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.7587847900457653 | validation: 0.21146589099235777]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_475.pth
	Model improved!!!
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34085958996962784		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.34085958996962784 | validation: 0.37096836270967953]
	TIME [epoch: 10.2 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40248304401750834		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.40248304401750834 | validation: 0.3462546472095271]
	TIME [epoch: 10.2 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37539828281226595		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.37539828281226595 | validation: 0.673924534639154]
	TIME [epoch: 10.2 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5642906448585309		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.5642906448585309 | validation: 0.8864275804058624]
	TIME [epoch: 10.2 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6211933758719341		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.6211933758719341 | validation: 0.2949325119836831]
	TIME [epoch: 10.2 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45263332109108373		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.45263332109108373 | validation: 0.48734575984915607]
	TIME [epoch: 10.2 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3911228935465484		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.3911228935465484 | validation: 0.9729686931499829]
	TIME [epoch: 10.2 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49577602522214664		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.49577602522214664 | validation: 0.7977506965640797]
	TIME [epoch: 10.2 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5961553730273009		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.5961553730273009 | validation: 0.3128219219355634]
	TIME [epoch: 10.2 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4721255225767861		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.4721255225767861 | validation: 0.2975936066337533]
	TIME [epoch: 10.2 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4100478777507798		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.4100478777507798 | validation: 0.7344865734352988]
	TIME [epoch: 10.2 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5707408363020666		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.5707408363020666 | validation: 0.631916359355407]
	TIME [epoch: 10.2 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6316419818200026		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.6316419818200026 | validation: 0.3233906433175753]
	TIME [epoch: 10.2 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4825530492395543		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.4825530492395543 | validation: 0.5493338217693006]
	TIME [epoch: 10.2 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260657217397662		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.5260657217397662 | validation: 0.42513640748838366]
	TIME [epoch: 10.2 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42263902623018723		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.42263902623018723 | validation: 0.3053082300043978]
	TIME [epoch: 10.2 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4802911005047803		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.4802911005047803 | validation: 0.6279295394368868]
	TIME [epoch: 10.2 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275927752476506		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.5275927752476506 | validation: 0.38323251233990263]
	TIME [epoch: 10.2 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3893058127655714		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.3893058127655714 | validation: 0.29349565287146706]
	TIME [epoch: 10.2 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968132400768413		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.2968132400768413 | validation: 0.3209962158349307]
	TIME [epoch: 10.2 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6385569713631006		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.6385569713631006 | validation: 0.3599595909067682]
	TIME [epoch: 10.2 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46679069060414147		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.46679069060414147 | validation: 0.3579248299470922]
	TIME [epoch: 10.2 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38197903768539876		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.38197903768539876 | validation: 0.402906726942911]
	TIME [epoch: 10.2 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46038717872257545		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.46038717872257545 | validation: 0.3852654975390216]
	TIME [epoch: 10.2 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4923886845952083		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.4923886845952083 | validation: 0.3069763917791814]
	TIME [epoch: 10.2 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260461899718101		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.5260461899718101 | validation: 0.2706067834044665]
	TIME [epoch: 10.2 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0165282932904982		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 1.0165282932904982 | validation: 1.4980651076476112]
	TIME [epoch: 10.2 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9784494756024736		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.9784494756024736 | validation: 0.430189567500163]
	TIME [epoch: 10.2 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40280597157297143		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.40280597157297143 | validation: 0.22490739425053236]
	TIME [epoch: 10.2 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40417453542616943		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.40417453542616943 | validation: 0.311327674320334]
	TIME [epoch: 10.2 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4042193394177418		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.4042193394177418 | validation: 0.2559959901890854]
	TIME [epoch: 10.2 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5054558191551703		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.5054558191551703 | validation: 0.4515811960298379]
	TIME [epoch: 10.2 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4014959581279906		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.4014959581279906 | validation: 0.5782080058226293]
	TIME [epoch: 10.2 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3917341418104492		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.3917341418104492 | validation: 0.2697342827404815]
	TIME [epoch: 10.2 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3641737891700959		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.3641737891700959 | validation: 0.9783125401455496]
	TIME [epoch: 10.2 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5538206752912936		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.5538206752912936 | validation: 0.26043925938396045]
	TIME [epoch: 10.2 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48796780349786406		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.48796780349786406 | validation: 0.3036354873171201]
	TIME [epoch: 10.2 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4796408944605739		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.4796408944605739 | validation: 0.5938455781642692]
	TIME [epoch: 10.2 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363845774921099		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.5363845774921099 | validation: 0.4259126871576129]
	TIME [epoch: 10.2 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4974761967918117		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.4974761967918117 | validation: 0.32783826482082634]
	TIME [epoch: 10.2 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43216288461652674		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.43216288461652674 | validation: 0.4373467174862744]
	TIME [epoch: 10.2 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5906978726947869		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.5906978726947869 | validation: 0.4312310075509917]
	TIME [epoch: 10.2 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49847106777538414		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.49847106777538414 | validation: 0.7071031404947538]
	TIME [epoch: 10.2 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6039032907302389		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.6039032907302389 | validation: 0.32441569187385055]
	TIME [epoch: 10.2 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5445252841706617		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.5445252841706617 | validation: 0.3045175670479539]
	TIME [epoch: 10.2 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7949351796175302		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.7949351796175302 | validation: 0.5420301006001661]
	TIME [epoch: 10.2 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41911093048307446		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.41911093048307446 | validation: 0.3547753124222647]
	TIME [epoch: 10.2 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45076777333039536		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.45076777333039536 | validation: 0.4957390717219775]
	TIME [epoch: 10.2 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44691008730855497		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.44691008730855497 | validation: 0.2983460305350179]
	TIME [epoch: 10.2 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6282139578087507		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.6282139578087507 | validation: 0.7064824356366026]
	TIME [epoch: 10.2 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.628647648845394		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.628647648845394 | validation: 0.7611712376738415]
	TIME [epoch: 10.2 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5702218427723909		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.5702218427723909 | validation: 0.3382056666728166]
	TIME [epoch: 10.2 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.481432927487468		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.481432927487468 | validation: 0.7296169339543451]
	TIME [epoch: 10.2 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44439933632984463		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.44439933632984463 | validation: 0.6029786236315695]
	TIME [epoch: 10.2 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47875888075753037		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.47875888075753037 | validation: 0.2981282671239165]
	TIME [epoch: 10.2 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29304416036872377		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.29304416036872377 | validation: 0.26752777527015176]
	TIME [epoch: 10.2 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34178082599495274		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.34178082599495274 | validation: 0.3990251890331821]
	TIME [epoch: 10.2 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3934490272215451		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.3934490272215451 | validation: 0.3701379164330114]
	TIME [epoch: 10.2 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3802332007988287		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.3802332007988287 | validation: 0.41381171261787525]
	TIME [epoch: 10.2 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7782047860473441		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.7782047860473441 | validation: 0.6987785149729228]
	TIME [epoch: 10.2 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48813600365909593		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.48813600365909593 | validation: 0.30677537054081055]
	TIME [epoch: 10.2 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1152055117379656		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 1.1152055117379656 | validation: 1.7020813795769831]
	TIME [epoch: 10.2 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9483146581635857		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.9483146581635857 | validation: 0.43746867925029864]
	TIME [epoch: 10.2 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4254090639535721		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.4254090639535721 | validation: 0.603699534367819]
	TIME [epoch: 10.2 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3681985092020529		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.3681985092020529 | validation: 0.2715891499860494]
	TIME [epoch: 10.2 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4072820370931032		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.4072820370931032 | validation: 0.6735087553764032]
	TIME [epoch: 10.2 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7864397744902363		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.7864397744902363 | validation: 0.25242209232344437]
	TIME [epoch: 10.2 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5353429761598866		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.5353429761598866 | validation: 0.7034510744805991]
	TIME [epoch: 10.2 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5108739726252438		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.5108739726252438 | validation: 0.30542505054729147]
	TIME [epoch: 10.2 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40393217744285687		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.40393217744285687 | validation: 0.27766467374868337]
	TIME [epoch: 10.2 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3696387143708678		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.3696387143708678 | validation: 0.25129695924544815]
	TIME [epoch: 10.2 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41706982554264016		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.41706982554264016 | validation: 0.8645831735653505]
	TIME [epoch: 10.2 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5811109898001304		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.5811109898001304 | validation: 0.4246351951210823]
	TIME [epoch: 10.2 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5989405244859561		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.5989405244859561 | validation: 0.32648944994200413]
	TIME [epoch: 10.2 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4195371520933553		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.4195371520933553 | validation: 0.5632645695630555]
	TIME [epoch: 10.2 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4060319417326566		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.4060319417326566 | validation: 0.3364627872535165]
	TIME [epoch: 10.2 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5380107292356653		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.5380107292356653 | validation: 0.28494780553511884]
	TIME [epoch: 10.2 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278927605691841		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.5278927605691841 | validation: 0.34035756795846384]
	TIME [epoch: 10.2 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38307553361015767		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.38307553361015767 | validation: 0.9854587518172637]
	TIME [epoch: 10.2 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7488427621529261		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.7488427621529261 | validation: 0.32013254081763237]
	TIME [epoch: 10.2 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34891939529698685		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.34891939529698685 | validation: 0.31749952947606835]
	TIME [epoch: 10.2 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6111614526421354		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.6111614526421354 | validation: 0.4856321634672719]
	TIME [epoch: 10.2 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8177146808289484		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.8177146808289484 | validation: 0.3741192187024241]
	TIME [epoch: 10.2 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48458334632458094		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.48458334632458094 | validation: 0.3578677506690143]
	TIME [epoch: 10.2 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5442434423071629		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.5442434423071629 | validation: 0.24344777306872808]
	TIME [epoch: 10.2 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39680822155871504		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.39680822155871504 | validation: 0.27479793883162296]
	TIME [epoch: 10.2 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32514731284277537		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.32514731284277537 | validation: 0.2732433787637322]
	TIME [epoch: 10.2 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38687385864342855		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.38687385864342855 | validation: 0.28664209189615697]
	TIME [epoch: 10.2 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4660185694096831		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.4660185694096831 | validation: 0.34519705380273413]
	TIME [epoch: 10.2 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3967960474773631		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.3967960474773631 | validation: 0.5108754412650447]
	TIME [epoch: 10.2 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6207682801122726		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.6207682801122726 | validation: 0.29236295714707045]
	TIME [epoch: 10.2 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3894785225452088		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.3894785225452088 | validation: 0.3158027190370314]
	TIME [epoch: 10.2 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33027427560669514		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.33027427560669514 | validation: 0.26729331085284125]
	TIME [epoch: 10.2 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628677541057219		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.5628677541057219 | validation: 0.3248668943275297]
	TIME [epoch: 10.2 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194556497095842		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.4194556497095842 | validation: 0.2595508644853021]
	TIME [epoch: 10.2 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3694617395174373		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.3694617395174373 | validation: 0.35485528219973217]
	TIME [epoch: 10.2 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.395123954039488		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.395123954039488 | validation: 0.31046526281869546]
	TIME [epoch: 10.2 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0727413810910837		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 1.0727413810910837 | validation: 0.5702279556149914]
	TIME [epoch: 10.2 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4173757128837094		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.4173757128837094 | validation: 0.7511255375356677]
	TIME [epoch: 10.2 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43021578045638276		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.43021578045638276 | validation: 0.441862076818611]
	TIME [epoch: 10.2 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6826146314680399		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.6826146314680399 | validation: 0.2803663277041368]
	TIME [epoch: 10.2 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452827205906859		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.5452827205906859 | validation: 0.432058792078896]
	TIME [epoch: 10.2 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38607443659461965		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.38607443659461965 | validation: 0.25969547768753815]
	TIME [epoch: 10.2 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.503460856001084		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.503460856001084 | validation: 0.5026521332605114]
	TIME [epoch: 10.2 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4041406728629062		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.4041406728629062 | validation: 0.4233503315430126]
	TIME [epoch: 10.2 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42880497317882627		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.42880497317882627 | validation: 0.28228687569129773]
	TIME [epoch: 10.2 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36214406335325655		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.36214406335325655 | validation: 0.353294358365109]
	TIME [epoch: 10.2 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32905270885484816		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.32905270885484816 | validation: 1.5132263184100347]
	TIME [epoch: 10.2 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.97003862661591		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 1.97003862661591 | validation: 0.5187477000315599]
	TIME [epoch: 10.2 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6071676673093869		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.6071676673093869 | validation: 0.3347753514334752]
	TIME [epoch: 10.2 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38489013703926517		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.38489013703926517 | validation: 0.2513259860879732]
	TIME [epoch: 10.2 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38384678521321847		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.38384678521321847 | validation: 0.239697233511966]
	TIME [epoch: 10.2 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4468649605236303		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.4468649605236303 | validation: 0.39801610664956405]
	TIME [epoch: 10.2 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4245620452546306		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.4245620452546306 | validation: 1.1122354197926032]
	TIME [epoch: 10.2 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8395027317370388		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.8395027317370388 | validation: 0.6054299092963382]
	TIME [epoch: 10.2 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39999371645304327		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.39999371645304327 | validation: 0.2608405585534247]
	TIME [epoch: 10.2 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4374780350335155		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.4374780350335155 | validation: 0.273658998221832]
	TIME [epoch: 10.2 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35122293131655036		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.35122293131655036 | validation: 0.24641313922609343]
	TIME [epoch: 10.2 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3549496607096785		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.3549496607096785 | validation: 0.30522944532897583]
	TIME [epoch: 10.2 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5358069550036152		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.5358069550036152 | validation: 0.23867417229224291]
	TIME [epoch: 10.2 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5117956395535601		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.5117956395535601 | validation: 0.3442582601736583]
	TIME [epoch: 10.2 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5239073954059039		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.5239073954059039 | validation: 1.0752810773091024]
	TIME [epoch: 10.2 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8823204682250777		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.8823204682250777 | validation: 1.4758657242488342]
	TIME [epoch: 10.2 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.80966055869076		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.80966055869076 | validation: 0.44311914046568496]
	TIME [epoch: 10.2 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286462549106359		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.5286462549106359 | validation: 0.3698066800009307]
	TIME [epoch: 10.2 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3782596845802575		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.3782596845802575 | validation: 0.5632270205628581]
	TIME [epoch: 10.2 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6217031920748264		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.6217031920748264 | validation: 0.6006370996023821]
	TIME [epoch: 10.2 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6522892805283956		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.6522892805283956 | validation: 0.3369309348286003]
	TIME [epoch: 10.2 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9662888603888057		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.9662888603888057 | validation: 0.41924148499021513]
	TIME [epoch: 10.2 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42403570947472885		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.42403570947472885 | validation: 0.2785761269095521]
	TIME [epoch: 10.2 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35217399422665685		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.35217399422665685 | validation: 0.3067400521298238]
	TIME [epoch: 10.2 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3856424879880266		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.3856424879880266 | validation: 0.41181532004076643]
	TIME [epoch: 10.2 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4287954487670822		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.4287954487670822 | validation: 0.21706534960777682]
	TIME [epoch: 10.2 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3631006854103837		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.3631006854103837 | validation: 0.25496077810418877]
	TIME [epoch: 10.2 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3509858089217273		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.3509858089217273 | validation: 0.4034894257724421]
	TIME [epoch: 10.2 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3904394157237592		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.3904394157237592 | validation: 0.38629081038805607]
	TIME [epoch: 10.2 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4716970851247254		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.4716970851247254 | validation: 1.0239981297819216]
	TIME [epoch: 10.2 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7082191440281745		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.7082191440281745 | validation: 0.19662232237629768]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_613.pth
	Model improved!!!
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49548659247285265		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.49548659247285265 | validation: 0.45613693171649317]
	TIME [epoch: 10.2 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3435763365456923		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.3435763365456923 | validation: 0.3590012776379236]
	TIME [epoch: 10.2 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285292572918143		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.5285292572918143 | validation: 0.2988346820050725]
	TIME [epoch: 10.2 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7370309357846333		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.7370309357846333 | validation: 0.7082119757160444]
	TIME [epoch: 10.2 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4646752589875572		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.4646752589875572 | validation: 0.44533707384548976]
	TIME [epoch: 10.2 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49299050838608666		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.49299050838608666 | validation: 0.45572627842669805]
	TIME [epoch: 10.2 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36573083032672626		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.36573083032672626 | validation: 0.5644029287977343]
	TIME [epoch: 10.2 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4343331754038947		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.4343331754038947 | validation: 0.6788226049030959]
	TIME [epoch: 10.2 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44668364183218634		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.44668364183218634 | validation: 0.24943354240543933]
	TIME [epoch: 10.2 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46844434151932457		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.46844434151932457 | validation: 0.2956902311194368]
	TIME [epoch: 10.2 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3090523890510608		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.3090523890510608 | validation: 0.28365607945835136]
	TIME [epoch: 10.2 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131754341660924		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.3131754341660924 | validation: 0.3844234619387666]
	TIME [epoch: 10.2 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.641202254655644		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.641202254655644 | validation: 0.671982567258016]
	TIME [epoch: 10.2 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7986386262094		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.7986386262094 | validation: 0.27107474517044194]
	TIME [epoch: 10.2 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35014860408877996		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.35014860408877996 | validation: 0.26208835396810826]
	TIME [epoch: 10.2 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3082875561630311		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.3082875561630311 | validation: 0.6166984428527034]
	TIME [epoch: 10.2 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36694374433068094		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.36694374433068094 | validation: 0.2419388011428859]
	TIME [epoch: 10.2 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2813791712863158		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.2813791712863158 | validation: 0.27299953682960487]
	TIME [epoch: 10.2 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784372618478465		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.6784372618478465 | validation: 0.2297619262801717]
	TIME [epoch: 10.2 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41223500715824696		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.41223500715824696 | validation: 0.2881064616230748]
	TIME [epoch: 10.2 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2697773871080936		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.2697773871080936 | validation: 0.4967119736769376]
	TIME [epoch: 10.2 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.325681516795421		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.325681516795421 | validation: 0.25769620138136445]
	TIME [epoch: 10.2 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.373692786682262		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.373692786682262 | validation: 0.2653060515773683]
	TIME [epoch: 10.2 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4169399812098731		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.4169399812098731 | validation: 0.7802121697257443]
	TIME [epoch: 10.2 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5406285319923047		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.5406285319923047 | validation: 0.21491584832006821]
	TIME [epoch: 10.2 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.325341277116546		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.325341277116546 | validation: 0.31835370293595483]
	TIME [epoch: 10.2 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33433346197434066		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.33433346197434066 | validation: 0.34724616649720097]
	TIME [epoch: 10.2 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37795129010655043		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.37795129010655043 | validation: 0.5483885877888431]
	TIME [epoch: 10.2 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5172359568510266		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.5172359568510266 | validation: 0.21272654126610582]
	TIME [epoch: 10.2 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3698262648804268		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.3698262648804268 | validation: 0.4109809191087449]
	TIME [epoch: 10.2 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6953921299007437		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.6953921299007437 | validation: 0.27026597549655385]
	TIME [epoch: 10.2 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6791760373292015		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.6791760373292015 | validation: 0.3950735290748601]
	TIME [epoch: 10.2 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825932171191984		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.2825932171191984 | validation: 0.30056160874795107]
	TIME [epoch: 10.2 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5666813730521734		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.5666813730521734 | validation: 0.30479416076651156]
	TIME [epoch: 10.2 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3260087871578932		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.3260087871578932 | validation: 0.42777178395677184]
	TIME [epoch: 10.2 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4489702190266892		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.4489702190266892 | validation: 0.366620530464769]
	TIME [epoch: 10.2 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3560617783883256		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.3560617783883256 | validation: 0.3693305066289533]
	TIME [epoch: 10.2 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28982347424687555		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.28982347424687555 | validation: 0.2116626180235577]
	TIME [epoch: 10.2 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3555399834742887		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.3555399834742887 | validation: 0.6356961469815259]
	TIME [epoch: 10.2 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3165871978402687		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.3165871978402687 | validation: 0.37363003920530985]
	TIME [epoch: 10.2 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5534321027775579		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.5534321027775579 | validation: 0.8792015588354284]
	TIME [epoch: 10.2 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5073777988303443		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.5073777988303443 | validation: 0.23343357189519331]
	TIME [epoch: 10.2 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25835581606660674		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.25835581606660674 | validation: 0.43854654290944195]
	TIME [epoch: 10.2 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4800072012122241		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.4800072012122241 | validation: 0.3794376598295004]
	TIME [epoch: 10.2 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223771657460492		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.5223771657460492 | validation: 0.2688127903710879]
	TIME [epoch: 10.2 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5722781681250366		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.5722781681250366 | validation: 0.5581388272874229]
	TIME [epoch: 10.2 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5816681825194274		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.5816681825194274 | validation: 0.3473746366658499]
	TIME [epoch: 10.2 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3298030929932599		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.3298030929932599 | validation: 0.44251041500375865]
	TIME [epoch: 10.2 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35608283031367566		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.35608283031367566 | validation: 0.5431634456783355]
	TIME [epoch: 10.2 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45753558009036566		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.45753558009036566 | validation: 0.7293415780023486]
	TIME [epoch: 10.2 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7708424830705687		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.7708424830705687 | validation: 0.3022059981147771]
	TIME [epoch: 10.2 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3880826117786103		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.3880826117786103 | validation: 0.4750407908083751]
	TIME [epoch: 10.2 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3651684475185705		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.3651684475185705 | validation: 0.3868619208037627]
	TIME [epoch: 10.2 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5659796816707517		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.5659796816707517 | validation: 0.4432253930055737]
	TIME [epoch: 10.2 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4092605499055697		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.4092605499055697 | validation: 0.3222663581622991]
	TIME [epoch: 10.2 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39768773483337133		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.39768773483337133 | validation: 0.24930052505981212]
	TIME [epoch: 10.2 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3193713168972183		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.3193713168972183 | validation: 0.5842561856748623]
	TIME [epoch: 10.2 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41458458222197425		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.41458458222197425 | validation: 0.3490029335259275]
	TIME [epoch: 10.2 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3633484079007327		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.3633484079007327 | validation: 0.22499729936722068]
	TIME [epoch: 10.2 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.474872421257273		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.474872421257273 | validation: 0.2960939582459127]
	TIME [epoch: 10.2 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29505352297403825		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.29505352297403825 | validation: 0.23058390262786665]
	TIME [epoch: 10.2 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30799598754377844		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.30799598754377844 | validation: 0.28990009128237554]
	TIME [epoch: 10.2 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2954445722987377		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.2954445722987377 | validation: 0.22766762190405584]
	TIME [epoch: 10.2 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366768420438119		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.2366768420438119 | validation: 0.6428035010327219]
	TIME [epoch: 10.2 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3784198331749575		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.3784198331749575 | validation: 0.43358939315280043]
	TIME [epoch: 10.2 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49208654663598805		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.49208654663598805 | validation: 0.3869566408500401]
	TIME [epoch: 10.2 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3522891802158784		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.3522891802158784 | validation: 0.382841911786891]
	TIME [epoch: 10.2 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40983397155386225		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.40983397155386225 | validation: 0.24589824203372437]
	TIME [epoch: 10.2 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3539951230828481		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.3539951230828481 | validation: 0.5050314270155057]
	TIME [epoch: 10.2 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3445039552616023		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.3445039552616023 | validation: 0.20513368096207046]
	TIME [epoch: 10.2 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297161482013334		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.5297161482013334 | validation: 0.7084656686859825]
	TIME [epoch: 10.2 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3974688077575678		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.3974688077575678 | validation: 0.5241754097524086]
	TIME [epoch: 10.2 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5830107756586769		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.5830107756586769 | validation: 0.7311856784883466]
	TIME [epoch: 10.2 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47598248571788576		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.47598248571788576 | validation: 0.25518052610238223]
	TIME [epoch: 10.2 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.362565243800681		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.362565243800681 | validation: 0.32813084262090697]
	TIME [epoch: 10.2 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31796477308004356		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.31796477308004356 | validation: 0.48893522958172503]
	TIME [epoch: 10.2 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3996798153058883		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.3996798153058883 | validation: 0.2706746036291267]
	TIME [epoch: 10.2 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29548536854872876		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.29548536854872876 | validation: 0.17752839400897222]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_691.pth
	Model improved!!!
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21471532437209495		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.21471532437209495 | validation: 0.2777217238423461]
	TIME [epoch: 10.2 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43916435504189283		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.43916435504189283 | validation: 0.2929869105953709]
	TIME [epoch: 10.2 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34836418696599447		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.34836418696599447 | validation: 0.25386700978152826]
	TIME [epoch: 10.2 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161938786208837		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.5161938786208837 | validation: 0.4153785876578979]
	TIME [epoch: 10.2 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.350236917626075		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.350236917626075 | validation: 0.2452041834683979]
	TIME [epoch: 10.2 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3861151945902441		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.3861151945902441 | validation: 0.23602697023999775]
	TIME [epoch: 10.2 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36718391035479947		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.36718391035479947 | validation: 0.31088999010109686]
	TIME [epoch: 10.2 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47310515205727083		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.47310515205727083 | validation: 0.40743419772155454]
	TIME [epoch: 10.2 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3652415720475318		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.3652415720475318 | validation: 0.24132291433796874]
	TIME [epoch: 10.2 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29618808659611356		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.29618808659611356 | validation: 0.22306561549970128]
	TIME [epoch: 10.2 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25269089529267064		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.25269089529267064 | validation: 0.5435440536318588]
	TIME [epoch: 10.2 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33929336984002456		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.33929336984002456 | validation: 0.27831082214999825]
	TIME [epoch: 10.2 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6754259886607016		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.6754259886607016 | validation: 1.0560967844789773]
	TIME [epoch: 10.2 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8488853252357054		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.8488853252357054 | validation: 0.4530438965620968]
	TIME [epoch: 10.2 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4550196437856041		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.4550196437856041 | validation: 0.2134627415566849]
	TIME [epoch: 10.2 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953716748042402		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.2953716748042402 | validation: 0.5681363300768426]
	TIME [epoch: 10.2 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49831775194184286		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.49831775194184286 | validation: 0.32102651672407406]
	TIME [epoch: 10.2 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2732835093330618		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.2732835093330618 | validation: 0.23022826006167185]
	TIME [epoch: 10.2 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2937116904308699		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.2937116904308699 | validation: 0.3560098780021421]
	TIME [epoch: 10.2 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36901807121204594		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.36901807121204594 | validation: 0.18802268677407782]
	TIME [epoch: 10.2 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4512418911984669		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.4512418911984669 | validation: 0.5085497212969012]
	TIME [epoch: 10.2 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3408458890336244		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.3408458890336244 | validation: 0.2506979307240401]
	TIME [epoch: 10.2 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3467286442192829		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.3467286442192829 | validation: 0.28037656328148247]
	TIME [epoch: 10.2 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27991752574037		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.27991752574037 | validation: 0.30092746701689144]
	TIME [epoch: 10.2 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22579415014689147		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.22579415014689147 | validation: 0.19682541081025207]
	TIME [epoch: 10.2 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39597853330202615		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.39597853330202615 | validation: 0.5284524321764512]
	TIME [epoch: 10.2 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37451042378858757		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.37451042378858757 | validation: 0.24900645845714744]
	TIME [epoch: 10.2 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2687738666897376		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.2687738666897376 | validation: 0.26247985424984116]
	TIME [epoch: 10.2 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3587909725766555		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.3587909725766555 | validation: 0.23172058079654573]
	TIME [epoch: 10.2 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25313932897205443		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.25313932897205443 | validation: 0.3133123150485802]
	TIME [epoch: 10.2 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4590805486331548		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.4590805486331548 | validation: 0.3338822394615675]
	TIME [epoch: 10.2 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3184110572015332		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.3184110572015332 | validation: 0.515881735984207]
	TIME [epoch: 10.2 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34108529758164535		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.34108529758164535 | validation: 0.4343226315318733]
	TIME [epoch: 10.2 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3597450057897888		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.3597450057897888 | validation: 0.593692153712133]
	TIME [epoch: 10.2 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.335963646943967		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.335963646943967 | validation: 0.24515099990819048]
	TIME [epoch: 10.2 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31938364296942234		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.31938364296942234 | validation: 0.21692978350244446]
	TIME [epoch: 10.2 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27286122598998974		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.27286122598998974 | validation: 0.20282929287196305]
	TIME [epoch: 10.2 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2689490392681791		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.2689490392681791 | validation: 0.37950387709359107]
	TIME [epoch: 10.2 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46414199723097643		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.46414199723097643 | validation: 0.42556781299109264]
	TIME [epoch: 10.2 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44535616847525744		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.44535616847525744 | validation: 0.4170909470137748]
	TIME [epoch: 10.2 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34710470224499257		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.34710470224499257 | validation: 0.21211165743065788]
	TIME [epoch: 10.2 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3428778652875911		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.3428778652875911 | validation: 0.30470236847015303]
	TIME [epoch: 10.2 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4112860008517608		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.4112860008517608 | validation: 0.3191759816410372]
	TIME [epoch: 10.2 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3144293593481307		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.3144293593481307 | validation: 0.21705974448104162]
	TIME [epoch: 10.2 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25047084709614487		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.25047084709614487 | validation: 0.1938373182409451]
	TIME [epoch: 10.2 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27320449205004316		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.27320449205004316 | validation: 0.3158179062815381]
	TIME [epoch: 10.2 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950681760806645		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.3950681760806645 | validation: 0.2267202532753663]
	TIME [epoch: 10.2 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609696448345672		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.2609696448345672 | validation: 0.24189821101797648]
	TIME [epoch: 10.2 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660486756221423		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.2660486756221423 | validation: 0.396065275011221]
	TIME [epoch: 10.2 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.406175512578504		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.406175512578504 | validation: 0.18121428696091146]
	TIME [epoch: 10.2 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588411551543019		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.2588411551543019 | validation: 0.22741576288268137]
	TIME [epoch: 10.2 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24563672002173775		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.24563672002173775 | validation: 0.8371871968222925]
	TIME [epoch: 10.2 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5811944616421496		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.5811944616421496 | validation: 0.30761812575703945]
	TIME [epoch: 10.2 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2458049976598323		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.2458049976598323 | validation: 0.16992829537984816]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_745.pth
	Model improved!!!
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4761814165786884		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.4761814165786884 | validation: 0.2123109817343972]
	TIME [epoch: 10.2 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28735332474175246		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.28735332474175246 | validation: 0.4053257547286405]
	TIME [epoch: 10.2 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40277511608489824		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.40277511608489824 | validation: 0.29775591972567284]
	TIME [epoch: 10.2 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4127749807857188		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.4127749807857188 | validation: 0.2738673576387972]
	TIME [epoch: 10.2 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5165923460977602		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.5165923460977602 | validation: 0.3605872804436038]
	TIME [epoch: 10.2 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26936541395426744		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.26936541395426744 | validation: 0.3114144082035693]
	TIME [epoch: 10.2 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24802907120011222		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.24802907120011222 | validation: 0.2155289268539243]
	TIME [epoch: 10.2 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24088611415116912		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.24088611415116912 | validation: 0.21198309319413436]
	TIME [epoch: 10.2 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20956209279844323		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.20956209279844323 | validation: 0.39398557771856035]
	TIME [epoch: 10.2 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3172043824556211		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.3172043824556211 | validation: 0.3161134530364091]
	TIME [epoch: 10.2 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5892788419130486		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.5892788419130486 | validation: 0.2236724178189905]
	TIME [epoch: 10.2 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3764122150256163		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.3764122150256163 | validation: 0.6242093297996971]
	TIME [epoch: 10.2 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40534363948600866		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.40534363948600866 | validation: 0.31978971329181244]
	TIME [epoch: 10.2 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625759150383439		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.2625759150383439 | validation: 0.38236192158260324]
	TIME [epoch: 10.2 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4063187301431691		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.4063187301431691 | validation: 0.2541195753693127]
	TIME [epoch: 10.2 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221437476630125		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.5221437476630125 | validation: 0.21765479997659298]
	TIME [epoch: 10.2 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32777302934746333		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.32777302934746333 | validation: 0.2343073232480649]
	TIME [epoch: 10.2 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30258644449844		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.30258644449844 | validation: 0.28577932398996303]
	TIME [epoch: 10.2 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2888642912307839		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.2888642912307839 | validation: 0.5228486152231825]
	TIME [epoch: 10.2 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38611484016008807		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.38611484016008807 | validation: 0.2502226415876394]
	TIME [epoch: 10.2 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642440286950282		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.2642440286950282 | validation: 0.2359811964005995]
	TIME [epoch: 10.2 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770734681833221		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.2770734681833221 | validation: 0.3001851946935509]
	TIME [epoch: 10.2 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29868576034393424		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.29868576034393424 | validation: 0.23744217002434134]
	TIME [epoch: 10.2 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27769749201879784		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.27769749201879784 | validation: 0.45295074487962916]
	TIME [epoch: 10.2 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3435264265474119		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.3435264265474119 | validation: 0.388812781711611]
	TIME [epoch: 10.2 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26831567101315684		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.26831567101315684 | validation: 0.3361943936853302]
	TIME [epoch: 10.2 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2463824401758537		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.2463824401758537 | validation: 0.46133494862719204]
	TIME [epoch: 10.2 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27823810140773436		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.27823810140773436 | validation: 0.2517295902798952]
	TIME [epoch: 10.2 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27172953411692846		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.27172953411692846 | validation: 0.20530303291562754]
	TIME [epoch: 10.2 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32496223171201244		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.32496223171201244 | validation: 0.20852720901878868]
	TIME [epoch: 10.2 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22269447080355534		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.22269447080355534 | validation: 0.3018770725437999]
	TIME [epoch: 10.2 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23937104363238265		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.23937104363238265 | validation: 0.22661442080324487]
	TIME [epoch: 10.2 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2930133038600526		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.2930133038600526 | validation: 0.31755642063097667]
	TIME [epoch: 10.2 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36657502711745255		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.36657502711745255 | validation: 0.3209741346092801]
	TIME [epoch: 10.2 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28899668533486245		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.28899668533486245 | validation: 0.34747362322676933]
	TIME [epoch: 10.2 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24053871757202633		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.24053871757202633 | validation: 0.20985449989347957]
	TIME [epoch: 10.2 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22966098300263824		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.22966098300263824 | validation: 0.19259610466165442]
	TIME [epoch: 10.2 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23719288904778546		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.23719288904778546 | validation: 0.20887230910265292]
	TIME [epoch: 10.2 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.217737405399531		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.217737405399531 | validation: 0.23195086535639925]
	TIME [epoch: 10.2 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32774664315170876		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.32774664315170876 | validation: 0.3839282390696064]
	TIME [epoch: 10.2 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25945706715569694		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.25945706715569694 | validation: 0.6302237318137256]
	TIME [epoch: 10.2 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44966927752164426		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.44966927752164426 | validation: 0.17431750145435168]
	TIME [epoch: 10.2 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19148104352976475		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.19148104352976475 | validation: 0.29586323422778277]
	TIME [epoch: 10.2 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24911913066539126		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.24911913066539126 | validation: 0.45151657944022544]
	TIME [epoch: 10.2 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28607832174983605		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.28607832174983605 | validation: 0.3557243949800539]
	TIME [epoch: 10.2 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2912282344697663		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.2912282344697663 | validation: 0.23304318940626786]
	TIME [epoch: 10.2 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2842772339006747		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.2842772339006747 | validation: 0.3411467029297146]
	TIME [epoch: 10.2 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28324975624426696		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.28324975624426696 | validation: 0.26141861515654435]
	TIME [epoch: 10.2 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2666295631542823		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.2666295631542823 | validation: 0.2358174538793221]
	TIME [epoch: 10.2 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47702652339947227		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.47702652339947227 | validation: 0.20895333206145034]
	TIME [epoch: 10.2 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2252713057886		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.2252713057886 | validation: 0.23126571023088333]
	TIME [epoch: 10.2 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3170270272832819		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.3170270272832819 | validation: 0.2850905068725053]
	TIME [epoch: 10.2 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28593330764077773		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.28593330764077773 | validation: 0.21489574916291834]
	TIME [epoch: 10.2 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34241851469222545		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.34241851469222545 | validation: 0.226677864273873]
	TIME [epoch: 10.2 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21427011909549387		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.21427011909549387 | validation: 0.3168975132647313]
	TIME [epoch: 10.2 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2377913226208701		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.2377913226208701 | validation: 0.17098601436750535]
	TIME [epoch: 10.2 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23559215297697186		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.23559215297697186 | validation: 0.1939095856720627]
	TIME [epoch: 10.2 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27527428335930715		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.27527428335930715 | validation: 0.25561237398300757]
	TIME [epoch: 10.2 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27836603430389567		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.27836603430389567 | validation: 0.2127807109993135]
	TIME [epoch: 10.2 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24642768757172662		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.24642768757172662 | validation: 0.2810486709073451]
	TIME [epoch: 10.2 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2982494359903676		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.2982494359903676 | validation: 0.20135269992077434]
	TIME [epoch: 10.2 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35691417843029105		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.35691417843029105 | validation: 0.250754144631732]
	TIME [epoch: 10.2 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2723834047021448		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.2723834047021448 | validation: 0.27489481699988566]
	TIME [epoch: 10.2 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2784526730028467		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.2784526730028467 | validation: 0.1950829573259558]
	TIME [epoch: 10.2 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25333744370526373		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.25333744370526373 | validation: 0.1826003934816376]
	TIME [epoch: 10.2 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26783946673445214		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.26783946673445214 | validation: 0.19889884941567396]
	TIME [epoch: 10.2 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.290610427130798		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.290610427130798 | validation: 0.3167463626615238]
	TIME [epoch: 10.2 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3290374989752337		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.3290374989752337 | validation: 0.6354845662869018]
	TIME [epoch: 10.2 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676129625261417		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.5676129625261417 | validation: 0.4343496712379604]
	TIME [epoch: 10.2 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.399822884881538		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.399822884881538 | validation: 0.24161402629499443]
	TIME [epoch: 10.2 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2546404220681947		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.2546404220681947 | validation: 0.32418258315515536]
	TIME [epoch: 10.2 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46516427706129726		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.46516427706129726 | validation: 0.2314492595740794]
	TIME [epoch: 10.2 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1971136461087291		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.1971136461087291 | validation: 0.18662649627120712]
	TIME [epoch: 10.2 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2471599045437828		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.2471599045437828 | validation: 0.24680390142676004]
	TIME [epoch: 10.2 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2557660867038635		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.2557660867038635 | validation: 0.23887854351726898]
	TIME [epoch: 10.2 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26165991202061434		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.26165991202061434 | validation: 0.1727819916870461]
	TIME [epoch: 10.2 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2180152209788802		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.2180152209788802 | validation: 0.1712394245557507]
	TIME [epoch: 10.2 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22368387164744913		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.22368387164744913 | validation: 0.2652768023821432]
	TIME [epoch: 10.2 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23102931832665846		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.23102931832665846 | validation: 0.24325445973904983]
	TIME [epoch: 10.2 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39051234395348045		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.39051234395348045 | validation: 0.36018935289554727]
	TIME [epoch: 10.2 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27878230540354576		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.27878230540354576 | validation: 0.18915098691789667]
	TIME [epoch: 10.2 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25876011339195426		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.25876011339195426 | validation: 0.18184928812675388]
	TIME [epoch: 10.2 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21875933739879422		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.21875933739879422 | validation: 0.20028942334966857]
	TIME [epoch: 10.2 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21397498416350622		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.21397498416350622 | validation: 0.2202760638519645]
	TIME [epoch: 10.2 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596195180742421		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.2596195180742421 | validation: 0.19402883999904721]
	TIME [epoch: 10.2 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23667276536049667		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.23667276536049667 | validation: 0.25515238169167354]
	TIME [epoch: 10.2 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24351984546836905		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.24351984546836905 | validation: 0.20225637129514568]
	TIME [epoch: 10.2 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28022048975939395		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.28022048975939395 | validation: 0.19361521140641227]
	TIME [epoch: 10.2 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2597992305831699		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.2597992305831699 | validation: 0.18021520957941156]
	TIME [epoch: 10.2 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20662504573364432		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.20662504573364432 | validation: 0.2607216846301922]
	TIME [epoch: 10.2 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24098182370081975		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.24098182370081975 | validation: 0.24010491736266973]
	TIME [epoch: 10.2 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.217805099941015		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.217805099941015 | validation: 0.22051507770722478]
	TIME [epoch: 10.2 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3174364147126839		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.3174364147126839 | validation: 0.3831873281213291]
	TIME [epoch: 10.2 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3316649013997729		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.3316649013997729 | validation: 0.19392186195568734]
	TIME [epoch: 10.2 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24486588601185325		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.24486588601185325 | validation: 0.16246007220089154]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_840.pth
	Model improved!!!
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23956895725706104		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.23956895725706104 | validation: 0.17087651087146746]
	TIME [epoch: 10.2 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.218586603490401		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.218586603490401 | validation: 0.22512734534511186]
	TIME [epoch: 10.2 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19033894637825113		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.19033894637825113 | validation: 0.28926838050443743]
	TIME [epoch: 10.2 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45649899628330404		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.45649899628330404 | validation: 0.3415811422001583]
	TIME [epoch: 10.2 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512316237953275		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.2512316237953275 | validation: 0.2854106814342897]
	TIME [epoch: 10.2 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24584111944413495		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.24584111944413495 | validation: 0.1928538178195078]
	TIME [epoch: 10.2 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24437376852910128		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.24437376852910128 | validation: 0.21920727666746317]
	TIME [epoch: 10.2 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22563900413128293		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.22563900413128293 | validation: 0.21077191211664534]
	TIME [epoch: 10.2 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23496423901694757		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.23496423901694757 | validation: 0.18516612432606017]
	TIME [epoch: 10.2 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22086869389946767		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.22086869389946767 | validation: 0.26006574983056063]
	TIME [epoch: 10.2 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22205172437912551		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.22205172437912551 | validation: 0.21034018494684417]
	TIME [epoch: 10.2 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21922169088045318		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.21922169088045318 | validation: 0.27010199016496933]
	TIME [epoch: 10.2 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29719906993778417		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.29719906993778417 | validation: 0.2370564254254826]
	TIME [epoch: 10.2 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20015097718418975		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.20015097718418975 | validation: 0.18766927245805742]
	TIME [epoch: 10.2 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2103504980429644		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.2103504980429644 | validation: 0.22812263783265863]
	TIME [epoch: 10.2 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35427895581241614		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.35427895581241614 | validation: 0.21044185195063192]
	TIME [epoch: 10.2 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23460962310114697		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.23460962310114697 | validation: 0.20357257948557184]
	TIME [epoch: 10.2 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19247296884955062		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.19247296884955062 | validation: 0.23497331073783426]
	TIME [epoch: 10.2 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2426551108017294		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.2426551108017294 | validation: 0.19685110796691646]
	TIME [epoch: 10.2 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27027006438672085		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.27027006438672085 | validation: 0.21472924649668187]
	TIME [epoch: 10.2 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660865771041324		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.2660865771041324 | validation: 0.19134334734761105]
	TIME [epoch: 10.2 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22684040066416786		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.22684040066416786 | validation: 0.294076394956101]
	TIME [epoch: 10.2 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22225722575821677		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.22225722575821677 | validation: 0.21277988337900225]
	TIME [epoch: 10.2 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20008294993021397		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.20008294993021397 | validation: 0.27746507911149143]
	TIME [epoch: 10.2 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31467656397018395		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.31467656397018395 | validation: 0.21853338243641232]
	TIME [epoch: 10.2 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29426422354115983		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.29426422354115983 | validation: 0.25268249201006787]
	TIME [epoch: 10.2 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24708283087959132		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.24708283087959132 | validation: 0.25270556494109114]
	TIME [epoch: 10.2 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22174764718604784		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.22174764718604784 | validation: 0.1796086335730454]
	TIME [epoch: 10.2 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19476628528084203		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.19476628528084203 | validation: 0.28290107697655925]
	TIME [epoch: 10.2 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25622774438638735		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.25622774438638735 | validation: 0.1675303081432878]
	TIME [epoch: 10.2 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18344993770998747		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.18344993770998747 | validation: 0.2606001856601676]
	TIME [epoch: 10.2 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21688102922434518		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.21688102922434518 | validation: 0.37962824180525645]
	TIME [epoch: 10.2 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27565168964335773		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.27565168964335773 | validation: 0.21416598546467036]
	TIME [epoch: 10.2 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625575168556167		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.2625575168556167 | validation: 0.2845401323257927]
	TIME [epoch: 10.2 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24579755870842246		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.24579755870842246 | validation: 0.23798618497099944]
	TIME [epoch: 10.2 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21190808931634283		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.21190808931634283 | validation: 0.1866710996179456]
	TIME [epoch: 10.2 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22165520298117675		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.22165520298117675 | validation: 0.24033752704184025]
	TIME [epoch: 10.2 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21345384212635915		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.21345384212635915 | validation: 0.19059268532997592]
	TIME [epoch: 10.2 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21366668167524444		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.21366668167524444 | validation: 0.28516205944870293]
	TIME [epoch: 10.2 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27858074940840216		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.27858074940840216 | validation: 0.30599353278168184]
	TIME [epoch: 10.2 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2655066413698012		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.2655066413698012 | validation: 0.20897544001695167]
	TIME [epoch: 10.2 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21205446980352538		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.21205446980352538 | validation: 0.24022174569566965]
	TIME [epoch: 10.2 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23790685217052804		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.23790685217052804 | validation: 0.19200389123808173]
	TIME [epoch: 10.2 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23273319336211523		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.23273319336211523 | validation: 0.16505859029670542]
	TIME [epoch: 10.2 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1984406102255742		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.1984406102255742 | validation: 0.1721989591120638]
	TIME [epoch: 10.2 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21828460332891342		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.21828460332891342 | validation: 0.3877957132600248]
	TIME [epoch: 10.2 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.390024843088957		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.390024843088957 | validation: 0.24967190889976257]
	TIME [epoch: 10.2 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22203281458336854		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.22203281458336854 | validation: 0.19495946113950144]
	TIME [epoch: 10.2 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19272635210326466		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.19272635210326466 | validation: 0.3520082835913131]
	TIME [epoch: 10.2 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.264286016487548		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.264286016487548 | validation: 0.1991292660419274]
	TIME [epoch: 10.2 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18451950946719314		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.18451950946719314 | validation: 0.24087178976934515]
	TIME [epoch: 10.2 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23373709847295956		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.23373709847295956 | validation: 0.1577932708128579]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_892.pth
	Model improved!!!
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1950560044500772		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.1950560044500772 | validation: 0.2754506909102721]
	TIME [epoch: 10.2 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25241830447100855		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.25241830447100855 | validation: 0.17888426681598266]
	TIME [epoch: 10.2 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20667262348516383		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.20667262348516383 | validation: 0.19366859043095438]
	TIME [epoch: 10.2 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20392039515584867		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.20392039515584867 | validation: 0.24048558667308556]
	TIME [epoch: 10.2 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2052665270348557		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.2052665270348557 | validation: 0.2173947275662561]
	TIME [epoch: 10.2 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23014318445274545		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.23014318445274545 | validation: 0.16729299834450573]
	TIME [epoch: 10.2 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17900889942442616		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.17900889942442616 | validation: 0.2050895409736015]
	TIME [epoch: 10.2 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31567090837200623		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.31567090837200623 | validation: 0.43735717370259225]
	TIME [epoch: 10.2 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2487994221518056		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.2487994221518056 | validation: 0.1884709116576562]
	TIME [epoch: 10.2 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1920464816366715		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.1920464816366715 | validation: 0.18493534214730292]
	TIME [epoch: 10.2 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19340233316077401		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.19340233316077401 | validation: 0.21484502916660841]
	TIME [epoch: 10.2 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1801814832617707		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.1801814832617707 | validation: 0.1634070030062093]
	TIME [epoch: 10.2 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24663128197639553		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.24663128197639553 | validation: 0.18080250405510284]
	TIME [epoch: 10.2 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18420799732294074		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.18420799732294074 | validation: 0.21125821084347762]
	TIME [epoch: 10.2 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20534760862651197		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.20534760862651197 | validation: 0.27976877878083367]
	TIME [epoch: 10.2 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2352937227312692		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.2352937227312692 | validation: 0.18291561975702242]
	TIME [epoch: 10.2 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.208139981656077		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.208139981656077 | validation: 0.28901956619681607]
	TIME [epoch: 10.2 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999475843239833		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.2999475843239833 | validation: 0.23576980777365303]
	TIME [epoch: 10.2 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23170672756283528		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.23170672756283528 | validation: 0.18294198744591988]
	TIME [epoch: 10.2 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34006643680986415		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.34006643680986415 | validation: 0.222258432764146]
	TIME [epoch: 10.2 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21054090445558832		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.21054090445558832 | validation: 0.1829436962057556]
	TIME [epoch: 10.2 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17987318829368157		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.17987318829368157 | validation: 0.17956235721300323]
	TIME [epoch: 10.2 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759863284238256		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.1759863284238256 | validation: 0.21425026668206332]
	TIME [epoch: 10.2 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22983132273142753		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.22983132273142753 | validation: 0.2953057980387796]
	TIME [epoch: 10.2 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21661423980538025		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.21661423980538025 | validation: 0.19402778846771804]
	TIME [epoch: 10.2 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18354560446396712		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.18354560446396712 | validation: 0.16651743255692011]
	TIME [epoch: 10.2 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17801912902844497		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.17801912902844497 | validation: 0.17027475285385602]
	TIME [epoch: 10.2 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18306844481603188		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.18306844481603188 | validation: 0.2117721829985107]
	TIME [epoch: 10.2 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21057847836746735		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.21057847836746735 | validation: 0.2090609337880233]
	TIME [epoch: 10.2 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719502764150542		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.2719502764150542 | validation: 0.2590653657670824]
	TIME [epoch: 10.2 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20994882616737712		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.20994882616737712 | validation: 0.2578911597623004]
	TIME [epoch: 10.2 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21644921240771012		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.21644921240771012 | validation: 0.15987296467401235]
	TIME [epoch: 10.2 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18734736801928067		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.18734736801928067 | validation: 0.19068855304335322]
	TIME [epoch: 10.2 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2979190949310995		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.2979190949310995 | validation: 0.21119337676421646]
	TIME [epoch: 10.2 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2310136105620983		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.2310136105620983 | validation: 0.18949525004618495]
	TIME [epoch: 10.2 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20041384425243974		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.20041384425243974 | validation: 0.18111048602275814]
	TIME [epoch: 10.2 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21536237620894289		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.21536237620894289 | validation: 0.16040728422709744]
	TIME [epoch: 10.2 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27438421858470113		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.27438421858470113 | validation: 0.15329747601220373]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_930.pth
	Model improved!!!
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18311407896350404		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.18311407896350404 | validation: 0.18135059677146761]
	TIME [epoch: 10.2 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1861643075852709		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.1861643075852709 | validation: 0.17266827814962404]
	TIME [epoch: 10.2 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17567296081418976		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.17567296081418976 | validation: 0.1538440801585172]
	TIME [epoch: 10.2 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19613316801190894		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.19613316801190894 | validation: 0.1957792109174943]
	TIME [epoch: 10.2 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20959577072912933		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.20959577072912933 | validation: 0.24022522933735566]
	TIME [epoch: 10.2 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19795383787040305		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.19795383787040305 | validation: 0.18356424329878024]
	TIME [epoch: 10.2 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18445390947773868		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.18445390947773868 | validation: 0.17126859696294197]
	TIME [epoch: 10.2 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1918783032661148		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.1918783032661148 | validation: 0.17167300988253445]
	TIME [epoch: 10.2 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1798891837518885		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.1798891837518885 | validation: 0.20072513169151343]
	TIME [epoch: 10.2 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20897045220069338		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.20897045220069338 | validation: 0.159987008549647]
	TIME [epoch: 10.2 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063112581574761		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.3063112581574761 | validation: 0.2333623394226737]
	TIME [epoch: 10.2 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21216585901403873		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.21216585901403873 | validation: 0.19900065398030223]
	TIME [epoch: 10.2 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18033218065579065		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.18033218065579065 | validation: 0.17496953453099726]
	TIME [epoch: 10.2 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1776611318296333		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.1776611318296333 | validation: 0.15991197754041728]
	TIME [epoch: 10.2 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17935501977107277		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.17935501977107277 | validation: 0.17005180310396825]
	TIME [epoch: 10.2 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1794718981375722		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.1794718981375722 | validation: 0.16424632603054862]
	TIME [epoch: 10.2 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21426549960064714		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.21426549960064714 | validation: 0.2301498862279407]
	TIME [epoch: 10.2 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25323425806181166		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.25323425806181166 | validation: 0.16748306335410168]
	TIME [epoch: 10.2 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19878085908676565		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.19878085908676565 | validation: 0.21360469838852067]
	TIME [epoch: 10.2 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19955326463369		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.19955326463369 | validation: 0.18948220966404947]
	TIME [epoch: 10.2 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22132961095577358		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.22132961095577358 | validation: 0.30516650757800196]
	TIME [epoch: 10.2 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2292890896815012		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.2292890896815012 | validation: 0.16336779767850676]
	TIME [epoch: 10.2 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18934038184072532		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.18934038184072532 | validation: 0.21803543037839931]
	TIME [epoch: 10.2 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19458773947137611		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.19458773947137611 | validation: 0.29386755094631073]
	TIME [epoch: 10.2 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25753732664979256		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.25753732664979256 | validation: 0.26016960230557884]
	TIME [epoch: 10.2 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21375983184688657		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.21375983184688657 | validation: 0.16640900045683765]
	TIME [epoch: 10.2 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2070434553419501		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.2070434553419501 | validation: 0.23079090431785942]
	TIME [epoch: 10.2 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31391552689307944		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.31391552689307944 | validation: 0.2125720402220545]
	TIME [epoch: 10.2 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20019278297944704		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.20019278297944704 | validation: 0.1523188958574965]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_959.pth
	Model improved!!!
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18906224538987657		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.18906224538987657 | validation: 0.17605266925249702]
	TIME [epoch: 10.2 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1870016547250209		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.1870016547250209 | validation: 0.18269421695110574]
	TIME [epoch: 10.2 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23120213291320618		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.23120213291320618 | validation: 0.19343890084762685]
	TIME [epoch: 10.2 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24102886552079467		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.24102886552079467 | validation: 0.180985559664164]
	TIME [epoch: 10.2 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18661504363146877		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.18661504363146877 | validation: 0.15372088357473002]
	TIME [epoch: 10.2 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1734207542427973		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.1734207542427973 | validation: 0.16533916022380873]
	TIME [epoch: 10.2 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18344215256449697		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.18344215256449697 | validation: 0.277827439428971]
	TIME [epoch: 10.2 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2323806830733722		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.2323806830733722 | validation: 0.19820873072334574]
	TIME [epoch: 10.2 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18251919878526807		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.18251919878526807 | validation: 0.16428995300783164]
	TIME [epoch: 10.2 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17898624343221928		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.17898624343221928 | validation: 0.1721427610170106]
	TIME [epoch: 10.2 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770691693100382		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.1770691693100382 | validation: 0.17078989144707862]
	TIME [epoch: 10.2 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2519417304094043		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.2519417304094043 | validation: 0.19228804898041735]
	TIME [epoch: 10.2 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21436185459393253		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.21436185459393253 | validation: 0.19036957394057435]
	TIME [epoch: 10.2 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21276329229288543		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.21276329229288543 | validation: 0.20033619850406584]
	TIME [epoch: 10.2 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20456648556671309		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.20456648556671309 | validation: 0.17289868985418075]
	TIME [epoch: 10.2 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19204685021642762		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.19204685021642762 | validation: 0.15249946686728147]
	TIME [epoch: 10.2 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20855630730512137		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.20855630730512137 | validation: 0.31237448499243153]
	TIME [epoch: 10.2 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2567091532096469		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.2567091532096469 | validation: 0.18447486264221355]
	TIME [epoch: 10.2 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18277490579740752		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.18277490579740752 | validation: 0.1596653575195104]
	TIME [epoch: 10.2 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17887066113993916		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.17887066113993916 | validation: 0.19022740230290144]
	TIME [epoch: 10.2 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756810194320945		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.1756810194320945 | validation: 0.19001962118605037]
	TIME [epoch: 10.2 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18843727451900646		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.18843727451900646 | validation: 0.1870113455209518]
	TIME [epoch: 10.2 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20561549200665136		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.20561549200665136 | validation: 0.22032058527828075]
	TIME [epoch: 10.2 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22153150985659184		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.22153150985659184 | validation: 0.20254393692996367]
	TIME [epoch: 10.2 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18535350652380428		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.18535350652380428 | validation: 0.23604501364729757]
	TIME [epoch: 10.2 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22564261308518913		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.22564261308518913 | validation: 0.16122897539718659]
	TIME [epoch: 10.2 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19739264544171256		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.19739264544171256 | validation: 0.19149054821780187]
	TIME [epoch: 10.2 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17414821942160028		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.17414821942160028 | validation: 0.1594255362169227]
	TIME [epoch: 10.2 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36918322895490874		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.36918322895490874 | validation: 0.23660549282706497]
	TIME [epoch: 10.2 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20476115652727925		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.20476115652727925 | validation: 0.16990416067307187]
	TIME [epoch: 10.2 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22100135285278544		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.22100135285278544 | validation: 0.19889922161962922]
	TIME [epoch: 10.2 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18045432280517787		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.18045432280517787 | validation: 0.16966430314944092]
	TIME [epoch: 10.2 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1991616417198984		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.1991616417198984 | validation: 0.35209253627281956]
	TIME [epoch: 10.2 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26539180125788764		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.26539180125788764 | validation: 0.1573837102434031]
	TIME [epoch: 10.2 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17756973184075417		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.17756973184075417 | validation: 0.22369310591471314]
	TIME [epoch: 10.2 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20161247336207427		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.20161247336207427 | validation: 0.1683809838669933]
	TIME [epoch: 10.2 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19049966780940528		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.19049966780940528 | validation: 0.1448714139677479]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r1_20240217_161441/states/model_tr_study6_996.pth
	Model improved!!!
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17274168174740095		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.17274168174740095 | validation: 0.19341811804047634]
	TIME [epoch: 10.2 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20721138301740655		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.20721138301740655 | validation: 0.1510511397902014]
	TIME [epoch: 10.2 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19589915602207736		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.19589915602207736 | validation: 0.1683811334918376]
	TIME [epoch: 10.2 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17574214734319188		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.17574214734319188 | validation: 0.15915304160479926]
	TIME [epoch: 10.2 sec]
Finished training in 10296.020 seconds.
