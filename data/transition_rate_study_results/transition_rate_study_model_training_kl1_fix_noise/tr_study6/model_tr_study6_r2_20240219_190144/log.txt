Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r2', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4087767553

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.789282676334121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.789282676334121 | validation: 8.424728097769666]
	TIME [epoch: 72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.01898515269205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.01898515269205 | validation: 8.05497759549391]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.6411608843443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6411608843443 | validation: 7.844963451626327]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.473712698698419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.473712698698419 | validation: 7.362812007550681]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.125951330873673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.125951330873673 | validation: 7.107306310200902]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.963857225672069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.963857225672069 | validation: 7.148361565708542]
	TIME [epoch: 10.3 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.905378543308399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.905378543308399 | validation: 6.610794041257204]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.62705883220045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.62705883220045 | validation: 7.313375938203635]
	TIME [epoch: 10.3 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.879382115659635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.879382115659635 | validation: 6.478508654289685]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.547864198083291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.547864198083291 | validation: 6.908777655701085]
	TIME [epoch: 10.3 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.513262937848912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.513262937848912 | validation: 6.353923476589287]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4244727765940794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4244727765940794 | validation: 6.348306323093077]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.463906073303477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.463906073303477 | validation: 6.356848578233126]
	TIME [epoch: 10.3 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3411873592243575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3411873592243575 | validation: 6.211616261561742]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.416717491906117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.416717491906117 | validation: 8.105186985081398]
	TIME [epoch: 10.3 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.985427109439047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.985427109439047 | validation: 6.391307730215606]
	TIME [epoch: 10.3 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.515069352239142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.515069352239142 | validation: 6.33039746945836]
	TIME [epoch: 10.3 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.055689215547146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.055689215547146 | validation: 6.005619079545243]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.940359556563463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.940359556563463 | validation: 5.890665511322019]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.859004295974645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.859004295974645 | validation: 5.957752625604464]
	TIME [epoch: 10.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.790973107454758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.790973107454758 | validation: 8.709754362267592]
	TIME [epoch: 10.3 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.461511577637358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.461511577637358 | validation: 6.284112588182145]
	TIME [epoch: 10.3 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8616551880959715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8616551880959715 | validation: 6.791824508681189]
	TIME [epoch: 10.2 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.415262328985587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.415262328985587 | validation: 7.5912899530575695]
	TIME [epoch: 10.3 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.627943960505431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.627943960505431 | validation: 6.362515707938453]
	TIME [epoch: 10.3 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.962304959829771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.962304959829771 | validation: 6.239612110159417]
	TIME [epoch: 10.3 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.006156178131415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.006156178131415 | validation: 6.18979390499894]
	TIME [epoch: 10.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.005738583772496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.005738583772496 | validation: 6.232751039225942]
	TIME [epoch: 10.3 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.181084555122521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.181084555122521 | validation: 7.384988120277892]
	TIME [epoch: 10.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.146422118069931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.146422118069931 | validation: 5.68936085060795]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.177122487351186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.177122487351186 | validation: 5.748122616821941]
	TIME [epoch: 10.3 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.127877246659144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.127877246659144 | validation: 6.597253133863184]
	TIME [epoch: 10.3 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.979456824200845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.979456824200845 | validation: 8.465268720310116]
	TIME [epoch: 10.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.588617377727016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.588617377727016 | validation: 6.153130952768338]
	TIME [epoch: 10.3 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.592343285881644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.592343285881644 | validation: 4.514012028946188]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.593510539986381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.593510539986381 | validation: 4.4706638498209275]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.925358980050765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.925358980050765 | validation: 4.104700146752889]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.013790406668958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.013790406668958 | validation: 5.370646127336327]
	TIME [epoch: 10.3 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.536373946281511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.536373946281511 | validation: 4.063835821592813]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.264088566609372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.264088566609372 | validation: 7.7898597505768965]
	TIME [epoch: 10.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.058495422583434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.058495422583434 | validation: 9.133347226368771]
	TIME [epoch: 10.3 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.69898408179156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.69898408179156 | validation: 7.972546578740941]
	TIME [epoch: 10.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.679496590512467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.679496590512467 | validation: 6.24870119951767]
	TIME [epoch: 10.3 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.646364475783369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.646364475783369 | validation: 5.846697062636879]
	TIME [epoch: 10.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.5450891700956735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5450891700956735 | validation: 9.604854691728665]
	TIME [epoch: 10.3 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.714962277393566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.714962277393566 | validation: 6.182594709341416]
	TIME [epoch: 10.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.575752757990589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.575752757990589 | validation: 5.554182514414225]
	TIME [epoch: 10.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.188295529720532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.188295529720532 | validation: 5.4645980387584085]
	TIME [epoch: 10.3 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.111248602131688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.111248602131688 | validation: 5.192142019285954]
	TIME [epoch: 10.3 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.423816074221833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.423816074221833 | validation: 6.97922135618873]
	TIME [epoch: 10.3 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.647270993918792		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 7.647270993918792 | validation: 8.684153126113497]
	TIME [epoch: 10.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.818627740977048		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 6.818627740977048 | validation: 5.52933264386468]
	TIME [epoch: 10.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.428902731837148		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 5.428902731837148 | validation: 5.218752952100462]
	TIME [epoch: 10.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.258886602079819		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 5.258886602079819 | validation: 5.135033269002332]
	TIME [epoch: 10.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4477200867387845		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 5.4477200867387845 | validation: 5.230487095997667]
	TIME [epoch: 10.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6612749980400965		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 5.6612749980400965 | validation: 7.807827979414]
	TIME [epoch: 10.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.14588266379429		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 8.14588266379429 | validation: 7.651263113355058]
	TIME [epoch: 10.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.492247594974344		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 8.492247594974344 | validation: 8.192300079797887]
	TIME [epoch: 10.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.423552939349721		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 6.423552939349721 | validation: 6.292255355641418]
	TIME [epoch: 10.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.26633756860318		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 7.26633756860318 | validation: 7.101700654981859]
	TIME [epoch: 10.3 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.529097316710201		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 6.529097316710201 | validation: 6.043608600476719]
	TIME [epoch: 10.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.268360914497509		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 5.268360914497509 | validation: 4.831875305970831]
	TIME [epoch: 10.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.071279541323943		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 5.071279541323943 | validation: 4.81197546758795]
	TIME [epoch: 10.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.01503072796185		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 5.01503072796185 | validation: 4.802773934314104]
	TIME [epoch: 10.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.13468864258512		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 5.13468864258512 | validation: 4.752784389368901]
	TIME [epoch: 10.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.07068685067582		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 5.07068685067582 | validation: 4.599638342483381]
	TIME [epoch: 10.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.001435928851038		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 5.001435928851038 | validation: 5.734806357885605]
	TIME [epoch: 10.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.4777434787100585		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 7.4777434787100585 | validation: 7.493447211268428]
	TIME [epoch: 10.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.046222313269189		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 6.046222313269189 | validation: 5.546162916200399]
	TIME [epoch: 10.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.410382191829543		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 5.410382191829543 | validation: 4.533639048255202]
	TIME [epoch: 10.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.278429511360823		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 5.278429511360823 | validation: 4.4349938235837305]
	TIME [epoch: 10.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.127848348366789		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 5.127848348366789 | validation: 4.882156761528319]
	TIME [epoch: 10.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.453034089973281		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 5.453034089973281 | validation: 6.619760337969626]
	TIME [epoch: 10.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.057193669878311		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 6.057193669878311 | validation: 6.043657152927802]
	TIME [epoch: 10.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.178941642619106		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 6.178941642619106 | validation: 6.0665108951985784]
	TIME [epoch: 10.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.245241437440809		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 5.245241437440809 | validation: 4.487368633043233]
	TIME [epoch: 10.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.773125624004484		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 4.773125624004484 | validation: 4.370998829018837]
	TIME [epoch: 10.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.441398351533013		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 5.441398351533013 | validation: 5.071456735411642]
	TIME [epoch: 10.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.730028853794076		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 5.730028853794076 | validation: 5.147545696295309]
	TIME [epoch: 10.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.515381721816716		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 5.515381721816716 | validation: 4.269592442569997]
	TIME [epoch: 10.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.701621698209687		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 4.701621698209687 | validation: 4.2242296205009]
	TIME [epoch: 10.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.402046484323457		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 4.402046484323457 | validation: 3.826027063798178]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.128582071530371		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 4.128582071530371 | validation: 3.704018669386556]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.83297653842302		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 3.83297653842302 | validation: 3.280146525694619]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.536957460375009		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 3.536957460375009 | validation: 2.925593513278625]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3721360512868728		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 3.3721360512868728 | validation: 2.655367802001282]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2034327232990876		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 3.2034327232990876 | validation: 2.760501950379654]
	TIME [epoch: 10.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2235394729144375		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 3.2235394729144375 | validation: 2.341193280543692]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.050034799430238		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 3.050034799430238 | validation: 2.688805349802484]
	TIME [epoch: 10.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.128429796608601		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 3.128429796608601 | validation: 2.659982588970411]
	TIME [epoch: 10.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.037056409481382		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 3.037056409481382 | validation: 2.2760925924064246]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1118798841571538		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 3.1118798841571538 | validation: 2.7741021260180467]
	TIME [epoch: 10.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0808638562413715		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 3.0808638562413715 | validation: 2.4131919192322546]
	TIME [epoch: 10.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.644848727999187		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 3.644848727999187 | validation: 5.032819289281416]
	TIME [epoch: 10.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.366031530000213		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 4.366031530000213 | validation: 2.469721869284856]
	TIME [epoch: 10.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1381088484674278		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 3.1381088484674278 | validation: 3.3609543020486865]
	TIME [epoch: 10.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.298860040167418		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 3.298860040167418 | validation: 2.6003017548114316]
	TIME [epoch: 10.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8459097569749217		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 2.8459097569749217 | validation: 2.4740479083384943]
	TIME [epoch: 10.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8679267735416456		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 2.8679267735416456 | validation: 2.400123250818601]
	TIME [epoch: 10.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8758192150201114		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 2.8758192150201114 | validation: 2.3510437390943695]
	TIME [epoch: 10.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.919886922006893		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 2.919886922006893 | validation: 2.592653711432425]
	TIME [epoch: 10.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.287349549113287		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 3.287349549113287 | validation: 2.6742504771980578]
	TIME [epoch: 10.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9488723321061086		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 2.9488723321061086 | validation: 2.702626317397362]
	TIME [epoch: 10.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5539174043926622		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 3.5539174043926622 | validation: 2.96495423808439]
	TIME [epoch: 10.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1966162935561164		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 3.1966162935561164 | validation: 2.5036848186084124]
	TIME [epoch: 10.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.485024815925286		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 4.485024815925286 | validation: 2.6111661405684425]
	TIME [epoch: 10.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.132710464662195		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 3.132710464662195 | validation: 2.6683097673210825]
	TIME [epoch: 10.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6477206894402485		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 3.6477206894402485 | validation: 3.145645371932215]
	TIME [epoch: 10.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.405283480338776		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 3.405283480338776 | validation: 5.232066824110042]
	TIME [epoch: 10.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9651336550898373		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 3.9651336550898373 | validation: 3.105110714572068]
	TIME [epoch: 10.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.018392298230988		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 4.018392298230988 | validation: 2.6865429295342755]
	TIME [epoch: 10.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.243653662923317		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 3.243653662923317 | validation: 2.614056854684926]
	TIME [epoch: 10.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.032938557946916		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 3.032938557946916 | validation: 2.466248339579194]
	TIME [epoch: 10.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.988518644658567		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 2.988518644658567 | validation: 2.568743060560753]
	TIME [epoch: 10.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0575936275824884		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 3.0575936275824884 | validation: 2.506585576634774]
	TIME [epoch: 10.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0195627858975556		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 3.0195627858975556 | validation: 2.4633179034648247]
	TIME [epoch: 10.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.980360826780732		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 2.980360826780732 | validation: 2.2832666025875183]
	TIME [epoch: 10.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1676117370237806		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 3.1676117370237806 | validation: 3.190898541172664]
	TIME [epoch: 10.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.608242307284628		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 3.608242307284628 | validation: 2.573057220078851]
	TIME [epoch: 10.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1215743306005868		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 3.1215743306005868 | validation: 2.378662531292817]
	TIME [epoch: 10.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0323046425840903		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 3.0323046425840903 | validation: 2.920246734311313]
	TIME [epoch: 10.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.175042054794403		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 3.175042054794403 | validation: 2.3345627683389383]
	TIME [epoch: 10.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.046142739528328		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 4.046142739528328 | validation: 3.3623734248044013]
	TIME [epoch: 10.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3811397060821435		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 3.3811397060821435 | validation: 3.013514343958813]
	TIME [epoch: 10.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3572563605147514		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 3.3572563605147514 | validation: 2.5545885711833263]
	TIME [epoch: 10.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.337467215878248		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 3.337467215878248 | validation: 2.8069550859222296]
	TIME [epoch: 10.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9903605531856474		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 2.9903605531856474 | validation: 2.620127631542016]
	TIME [epoch: 10.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0179043719690677		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 3.0179043719690677 | validation: 3.01519467812723]
	TIME [epoch: 10.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4258472720678697		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 3.4258472720678697 | validation: 2.730298137414435]
	TIME [epoch: 10.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.943405877406593		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 3.943405877406593 | validation: 2.487175442350735]
	TIME [epoch: 10.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1419158880429636		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 3.1419158880429636 | validation: 2.5996247749633308]
	TIME [epoch: 10.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.294031144134852		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 3.294031144134852 | validation: 2.4108990740469487]
	TIME [epoch: 10.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1375669887870568		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 3.1375669887870568 | validation: 2.376952888079755]
	TIME [epoch: 10.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2756307852763933		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 3.2756307852763933 | validation: 5.7923832986247135]
	TIME [epoch: 10.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.3118122097680285		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 5.3118122097680285 | validation: 4.101080104385294]
	TIME [epoch: 10.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.087864987797625		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 5.087864987797625 | validation: 4.626459745890129]
	TIME [epoch: 10.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.573356081368415		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 4.573356081368415 | validation: 3.8053417022519445]
	TIME [epoch: 10.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.30051197547744		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 4.30051197547744 | validation: 2.8447303906044112]
	TIME [epoch: 10.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4688575314004475		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 3.4688575314004475 | validation: 2.463674154231639]
	TIME [epoch: 10.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.039953003412736		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 3.039953003412736 | validation: 2.462670868452235]
	TIME [epoch: 10.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.606687701553523		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 4.606687701553523 | validation: 3.29461556391285]
	TIME [epoch: 10.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.568516216162771		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 3.568516216162771 | validation: 2.4920593406603735]
	TIME [epoch: 10.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.028379499993816		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 3.028379499993816 | validation: 2.6627665499182798]
	TIME [epoch: 10.3 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.548870854019038		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 3.548870854019038 | validation: 2.5194744923004246]
	TIME [epoch: 10.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1810469564800203		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 3.1810469564800203 | validation: 3.4170038348609495]
	TIME [epoch: 10.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.420572056637712		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 5.420572056637712 | validation: 5.7386552024397]
	TIME [epoch: 10.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.201339809666114		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 5.201339809666114 | validation: 4.4384970234364785]
	TIME [epoch: 10.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.659554469424725		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 4.659554469424725 | validation: 4.460523191327083]
	TIME [epoch: 10.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.555623345642376		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 4.555623345642376 | validation: 3.845617272192204]
	TIME [epoch: 10.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8233711749334347		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 3.8233711749334347 | validation: 4.009578555931345]
	TIME [epoch: 10.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.024528324655021		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 5.024528324655021 | validation: 5.129103906185389]
	TIME [epoch: 10.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.288968431090264		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 5.288968431090264 | validation: 4.34955363199378]
	TIME [epoch: 10.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.648969719526861		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 4.648969719526861 | validation: 4.165191626936469]
	TIME [epoch: 10.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.600985163265399		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 4.600985163265399 | validation: 3.5181375743994865]
	TIME [epoch: 10.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.701684615916697		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 4.701684615916697 | validation: 5.691984148472932]
	TIME [epoch: 10.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.072657603227358		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 5.072657603227358 | validation: 3.6314624262431074]
	TIME [epoch: 10.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5009063098171183		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 3.5009063098171183 | validation: 3.4897597093391592]
	TIME [epoch: 10.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.538586579130994		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 4.538586579130994 | validation: 4.20312685890261]
	TIME [epoch: 10.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.443535297940641		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 5.443535297940641 | validation: 4.750142516160994]
	TIME [epoch: 10.3 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.886637016732623		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 4.886637016732623 | validation: 4.2452208142501755]
	TIME [epoch: 10.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.307148866594398		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 4.307148866594398 | validation: 3.0423096105678282]
	TIME [epoch: 10.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.843077002928412		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 3.843077002928412 | validation: 3.00622923283944]
	TIME [epoch: 10.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.464529804910095		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 3.464529804910095 | validation: 3.406630173889379]
	TIME [epoch: 10.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.002528954647531		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 4.002528954647531 | validation: 3.9316157960612896]
	TIME [epoch: 10.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.270056931666606		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 4.270056931666606 | validation: 3.110451474566038]
	TIME [epoch: 10.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5742345982618176		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 3.5742345982618176 | validation: 3.349302124274577]
	TIME [epoch: 10.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.292910106834989		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 4.292910106834989 | validation: 2.959730849013323]
	TIME [epoch: 10.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.328577935442231		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 3.328577935442231 | validation: 2.8845904120508674]
	TIME [epoch: 10.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.666543721410659		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 3.666543721410659 | validation: 4.133068290062785]
	TIME [epoch: 10.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.348111575164202		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 4.348111575164202 | validation: 3.492155674729813]
	TIME [epoch: 10.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.11241047404374		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 4.11241047404374 | validation: 5.281775488839652]
	TIME [epoch: 10.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.875217661713878		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 5.875217661713878 | validation: 5.866965578380839]
	TIME [epoch: 10.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.037474844816003		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 5.037474844816003 | validation: 3.424451428262172]
	TIME [epoch: 10.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6097625957148933		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 3.6097625957148933 | validation: 2.838039671892861]
	TIME [epoch: 10.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.379939281350228		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 3.379939281350228 | validation: 2.7113083200776034]
	TIME [epoch: 10.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.334939433869372		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 3.334939433869372 | validation: 2.708165355367014]
	TIME [epoch: 10.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.053573799704393		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 3.053573799704393 | validation: 2.5487505817983327]
	TIME [epoch: 10.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.329674986235682		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 3.329674986235682 | validation: 2.8755164281921286]
	TIME [epoch: 10.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.061900518661355		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 5.061900518661355 | validation: 5.053538663998777]
	TIME [epoch: 10.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.367248607619128		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 5.367248607619128 | validation: 5.282115770104897]
	TIME [epoch: 10.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.475200961153354		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 4.475200961153354 | validation: 3.070186029845483]
	TIME [epoch: 10.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5334073980295058		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 3.5334073980295058 | validation: 3.2854589966893957]
	TIME [epoch: 10.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.613988339991318		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 3.613988339991318 | validation: 2.6956051056568358]
	TIME [epoch: 10.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.793951477234954		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 3.793951477234954 | validation: 6.107366108334863]
	TIME [epoch: 10.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.550152579257717		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 5.550152579257717 | validation: 3.3447442463792236]
	TIME [epoch: 10.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.196874306537462		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 4.196874306537462 | validation: 3.7653163386743933]
	TIME [epoch: 10.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.14007545366958		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 4.14007545366958 | validation: 3.1327893418594908]
	TIME [epoch: 10.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6984025620540684		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 3.6984025620540684 | validation: 2.7626416526167543]
	TIME [epoch: 10.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.403501053333102		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 4.403501053333102 | validation: 3.943967650652177]
	TIME [epoch: 10.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.00192753861663		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 4.00192753861663 | validation: 3.6758103670059525]
	TIME [epoch: 10.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8970937611928544		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 5.8970937611928544 | validation: 7.688483578019604]
	TIME [epoch: 10.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.689949580353729		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 7.689949580353729 | validation: 6.404102275715745]
	TIME [epoch: 10.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.925144552532297		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 5.925144552532297 | validation: 4.159101434206632]
	TIME [epoch: 10.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.759804834608536		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 4.759804834608536 | validation: 4.278918601280903]
	TIME [epoch: 10.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.499239178329373		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 4.499239178329373 | validation: 6.384249726586782]
	TIME [epoch: 10.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.116270199562932		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 7.116270199562932 | validation: 7.776808697011433]
	TIME [epoch: 10.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.2778285604938056		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 6.2778285604938056 | validation: 4.5382768232929305]
	TIME [epoch: 10.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.449604215058562		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 4.449604215058562 | validation: 4.637795442352078]
	TIME [epoch: 10.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.676837714870236		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 4.676837714870236 | validation: 5.34016035517687]
	TIME [epoch: 10.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.970869976838091		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 4.970869976838091 | validation: 3.364748333419286]
	TIME [epoch: 10.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6811669279601005		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 3.6811669279601005 | validation: 3.3973125565405415]
	TIME [epoch: 10.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5307449459166493		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 3.5307449459166493 | validation: 2.8932543716989123]
	TIME [epoch: 10.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2052412184662833		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 3.2052412184662833 | validation: 2.6342357248493453]
	TIME [epoch: 10.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1042256749384958		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 3.1042256749384958 | validation: 2.5120173041749547]
	TIME [epoch: 10.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1163612385646244		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 3.1163612385646244 | validation: 2.6121842328140383]
	TIME [epoch: 10.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2197223233280092		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 3.2197223233280092 | validation: 3.232497668237055]
	TIME [epoch: 10.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6143301929917064		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 3.6143301929917064 | validation: 2.780018961895377]
	TIME [epoch: 10.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2242381769189166		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 3.2242381769189166 | validation: 2.8145558522106406]
	TIME [epoch: 10.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2347468838114297		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 3.2347468838114297 | validation: 2.788594024804026]
	TIME [epoch: 10.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2691870908213945		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 3.2691870908213945 | validation: 2.5567377663918034]
	TIME [epoch: 10.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0714790385883157		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 3.0714790385883157 | validation: 2.7270188792472068]
	TIME [epoch: 10.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4401375548061757		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 3.4401375548061757 | validation: 2.8116963549333764]
	TIME [epoch: 10.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7873332202903405		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 3.7873332202903405 | validation: 2.7934501060585113]
	TIME [epoch: 10.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1882896657635844		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 3.1882896657635844 | validation: 2.5389370670364007]
	TIME [epoch: 10.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.976546853563857		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 3.976546853563857 | validation: 3.0027972972966053]
	TIME [epoch: 10.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.159237482007492		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 3.159237482007492 | validation: 2.477084994286941]
	TIME [epoch: 10.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0442407135813987		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 3.0442407135813987 | validation: 2.6458349242884514]
	TIME [epoch: 10.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.104297329789655		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 3.104297329789655 | validation: 2.5265277349589703]
	TIME [epoch: 10.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.325857364253293		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 3.325857364253293 | validation: 2.5520908390788644]
	TIME [epoch: 10.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.079937643801048		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 3.079937643801048 | validation: 2.459953235430868]
	TIME [epoch: 10.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9161191754587774		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 2.9161191754587774 | validation: 2.42417777629251]
	TIME [epoch: 10.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.873178219202811		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 2.873178219202811 | validation: 2.4695027050461893]
	TIME [epoch: 10.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.950890315018098		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 2.950890315018098 | validation: 3.618477657398819]
	TIME [epoch: 10.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3431382590735894		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 3.3431382590735894 | validation: 2.406943570552186]
	TIME [epoch: 10.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8948668957465484		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 2.8948668957465484 | validation: 2.3941527369192084]
	TIME [epoch: 10.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8908677383856825		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 2.8908677383856825 | validation: 2.2683230302056705]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.882988405471001		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 2.882988405471001 | validation: 2.226298524167443]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.869738831517102		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 2.869738831517102 | validation: 2.3871105475811256]
	TIME [epoch: 10.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9011846896023012		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 2.9011846896023012 | validation: 2.6644150180245663]
	TIME [epoch: 10.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0794150764057373		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 3.0794150764057373 | validation: 2.3579145717483305]
	TIME [epoch: 10.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.224097959512501		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 3.224097959512501 | validation: 3.1503001567280307]
	TIME [epoch: 10.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8369471679439107		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 3.8369471679439107 | validation: 3.4092152697728495]
	TIME [epoch: 10.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7673545597677047		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 3.7673545597677047 | validation: 3.362660256285384]
	TIME [epoch: 10.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.335500778213846		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 3.335500778213846 | validation: 2.5580410581146547]
	TIME [epoch: 10.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.054100129532668		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 3.054100129532668 | validation: 2.6845646758815547]
	TIME [epoch: 10.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.017041010459933		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 3.017041010459933 | validation: 4.034102742551153]
	TIME [epoch: 10.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.955378893996156		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 3.955378893996156 | validation: 2.7639327857710216]
	TIME [epoch: 10.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.351274082971476		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 3.351274082971476 | validation: 2.6760569292974483]
	TIME [epoch: 10.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.158794127023998		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 3.158794127023998 | validation: 2.6505722008315185]
	TIME [epoch: 10.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9796545974106263		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 2.9796545974106263 | validation: 2.4843523311102906]
	TIME [epoch: 10.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1280594343773878		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 3.1280594343773878 | validation: 2.493479815483585]
	TIME [epoch: 10.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9038130276672467		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 2.9038130276672467 | validation: 2.2810381679674463]
	TIME [epoch: 10.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1680080919256683		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 3.1680080919256683 | validation: 3.2805672477383405]
	TIME [epoch: 10.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3440367037881997		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 3.3440367037881997 | validation: 2.760523139172477]
	TIME [epoch: 10.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1648314344628634		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 3.1648314344628634 | validation: 2.480769539394683]
	TIME [epoch: 10.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9726447481167004		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 2.9726447481167004 | validation: 2.307610135048287]
	TIME [epoch: 10.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1998033731121303		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 3.1998033731121303 | validation: 3.03073684779342]
	TIME [epoch: 10.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3427659251079853		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 3.3427659251079853 | validation: 2.7207971110235416]
	TIME [epoch: 10.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0261469705542177		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 3.0261469705542177 | validation: 2.4802651950732995]
	TIME [epoch: 10.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.016892155677992		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 3.016892155677992 | validation: 2.407576703889348]
	TIME [epoch: 10.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9623078364113216		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 2.9623078364113216 | validation: 2.332536176730021]
	TIME [epoch: 10.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9777376141084653		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 2.9777376141084653 | validation: 2.4532717536519386]
	TIME [epoch: 10.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.137113985167537		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 3.137113985167537 | validation: 2.605723404378099]
	TIME [epoch: 10.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.985346548201515		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 2.985346548201515 | validation: 2.5918078365665145]
	TIME [epoch: 10.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9919149681481416		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 2.9919149681481416 | validation: 2.4948826790783296]
	TIME [epoch: 10.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.002880361889635		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 3.002880361889635 | validation: 2.5640644909860493]
	TIME [epoch: 10.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9941551755659415		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 2.9941551755659415 | validation: 2.3881081151475603]
	TIME [epoch: 10.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0935225747582984		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 3.0935225747582984 | validation: 2.4593904082949836]
	TIME [epoch: 10.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.113327588823825		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 3.113327588823825 | validation: 2.800635491119491]
	TIME [epoch: 10.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2102063843871678		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 3.2102063843871678 | validation: 3.311562162040417]
	TIME [epoch: 10.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1381513658261895		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 3.1381513658261895 | validation: 2.5356223562418965]
	TIME [epoch: 10.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0413174103473457		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 3.0413174103473457 | validation: 2.4407338653444484]
	TIME [epoch: 10.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0876813783283232		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 3.0876813783283232 | validation: 2.477276279205777]
	TIME [epoch: 10.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.276903002226026		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 3.276903002226026 | validation: 2.337045180745981]
	TIME [epoch: 10.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1371436688333825		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 3.1371436688333825 | validation: 2.565268234030806]
	TIME [epoch: 10.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9924770874774103		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 2.9924770874774103 | validation: 2.919178029015764]
	TIME [epoch: 10.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.053656300192468		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 3.053656300192468 | validation: 2.5453551964556844]
	TIME [epoch: 10.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0331822586925767		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 3.0331822586925767 | validation: 2.400177035347645]
	TIME [epoch: 10.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.953382551853146		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 2.953382551853146 | validation: 2.520281235547888]
	TIME [epoch: 10.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.179567153225712		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 3.179567153225712 | validation: 2.4797986288685747]
	TIME [epoch: 10.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9997553223389968		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 2.9997553223389968 | validation: 2.3927679084781444]
	TIME [epoch: 10.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0156856080013723		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 3.0156856080013723 | validation: 2.660664647638289]
	TIME [epoch: 10.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0803713396300463		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 3.0803713396300463 | validation: 2.4604783250095177]
	TIME [epoch: 10.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9930564606211494		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 2.9930564606211494 | validation: 2.4000646392643645]
	TIME [epoch: 10.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.980134639188345		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 2.980134639188345 | validation: 2.56488518621416]
	TIME [epoch: 10.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0845883533465814		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 3.0845883533465814 | validation: 2.4235165867903383]
	TIME [epoch: 10.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0181877599073355		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 3.0181877599073355 | validation: 2.481432250095098]
	TIME [epoch: 10.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9770719685012104		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 2.9770719685012104 | validation: 2.5161190761453636]
	TIME [epoch: 10.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0170967844446808		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 3.0170967844446808 | validation: 2.598386895567292]
	TIME [epoch: 10.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9760274532042286		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 2.9760274532042286 | validation: 2.8391442642377838]
	TIME [epoch: 10.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1732400501734093		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 3.1732400501734093 | validation: 2.491755430858915]
	TIME [epoch: 10.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.029090975615541		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 3.029090975615541 | validation: 2.4381852758017812]
	TIME [epoch: 10.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9085859858532572		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 2.9085859858532572 | validation: 2.5006048317510876]
	TIME [epoch: 10.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9845548606699563		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 2.9845548606699563 | validation: 2.53278224318224]
	TIME [epoch: 10.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0546250906070953		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 3.0546250906070953 | validation: 2.4461559589766906]
	TIME [epoch: 10.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1890554351005593		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 3.1890554351005593 | validation: 2.5267402775063545]
	TIME [epoch: 10.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.030420682860388		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 3.030420682860388 | validation: 2.508035495946462]
	TIME [epoch: 10.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9390560967937374		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 2.9390560967937374 | validation: 2.3861826998101963]
	TIME [epoch: 10.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9633674579625877		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 2.9633674579625877 | validation: 2.703704344349721]
	TIME [epoch: 10.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.071564708773767		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 3.071564708773767 | validation: 3.2922390297783806]
	TIME [epoch: 10.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.233789890022637		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 3.233789890022637 | validation: 2.55856555049684]
	TIME [epoch: 10.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0854698379224397		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 3.0854698379224397 | validation: 2.5039997133715395]
	TIME [epoch: 10.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.02764510505301		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 3.02764510505301 | validation: 2.425046191457247]
	TIME [epoch: 10.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.14157903593768		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 3.14157903593768 | validation: 2.721140828742445]
	TIME [epoch: 10.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3236532783290884		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 3.3236532783290884 | validation: 2.350230814850004]
	TIME [epoch: 10.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0456966059062305		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 3.0456966059062305 | validation: 2.7911855682624607]
	TIME [epoch: 10.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.275732221247151		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 3.275732221247151 | validation: 2.5516580520955268]
	TIME [epoch: 10.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.165374346733421		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 3.165374346733421 | validation: 4.3198855195283]
	TIME [epoch: 10.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.604048439710719		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 3.604048439710719 | validation: 2.7154040388854446]
	TIME [epoch: 10.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0540529308925537		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 3.0540529308925537 | validation: 2.628076568373566]
	TIME [epoch: 10.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.554646600205585		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 3.554646600205585 | validation: 2.761099208269883]
	TIME [epoch: 10.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.176781548114934		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 3.176781548114934 | validation: 2.5572554308572935]
	TIME [epoch: 10.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.043560663243883		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 3.043560663243883 | validation: 2.5366520167833415]
	TIME [epoch: 10.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.977121210701597		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 2.977121210701597 | validation: 2.5711919776530703]
	TIME [epoch: 10.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0168167720875645		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 3.0168167720875645 | validation: 3.612004793469456]
	TIME [epoch: 10.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.296127900118217		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 4.296127900118217 | validation: 3.641030708969836]
	TIME [epoch: 10.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.417879270836262		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 3.417879270836262 | validation: 3.1427171659833535]
	TIME [epoch: 10.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.864308374016454		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 3.864308374016454 | validation: 3.86116425569609]
	TIME [epoch: 10.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2758924660006015		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 4.2758924660006015 | validation: 3.542035538561456]
	TIME [epoch: 10.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.927455422792158		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 3.927455422792158 | validation: 3.745518778395947]
	TIME [epoch: 10.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7717281957869657		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 3.7717281957869657 | validation: 3.5722920760618497]
	TIME [epoch: 10.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.809634098336315		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 3.809634098336315 | validation: 3.0100969758595295]
	TIME [epoch: 10.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5027429479196486		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 3.5027429479196486 | validation: 3.2541740511125226]
	TIME [epoch: 10.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.452915130607123		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 3.452915130607123 | validation: 3.182807051075089]
	TIME [epoch: 10.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.201305797265976		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 3.201305797265976 | validation: 2.8126982016048663]
	TIME [epoch: 10.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1659732824474265		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 3.1659732824474265 | validation: 2.3769079757503384]
	TIME [epoch: 10.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1082662704948016		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 3.1082662704948016 | validation: 3.7014085172716835]
	TIME [epoch: 10.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.007101308113407		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 4.007101308113407 | validation: 3.401500423469089]
	TIME [epoch: 10.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4981950206552326		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 3.4981950206552326 | validation: 2.730574232196367]
	TIME [epoch: 10.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4697124142808575		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 3.4697124142808575 | validation: 2.9955520642964877]
	TIME [epoch: 10.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.215373137057324		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 4.215373137057324 | validation: 3.8378454877179364]
	TIME [epoch: 10.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6858772340951282		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 3.6858772340951282 | validation: 2.684704127331902]
	TIME [epoch: 10.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.862626949977636		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 2.862626949977636 | validation: 2.377622023606293]
	TIME [epoch: 10.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1156284154946694		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 3.1156284154946694 | validation: 3.0662023754833707]
	TIME [epoch: 10.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.293871695346001		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 3.293871695346001 | validation: 2.5369271219893723]
	TIME [epoch: 10.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.897756732189891		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 2.897756732189891 | validation: 2.3239838812222]
	TIME [epoch: 10.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0093548046751644		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 3.0093548046751644 | validation: 2.7051640176115006]
	TIME [epoch: 10.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.144634153849588		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 3.144634153849588 | validation: 3.4199655255023096]
	TIME [epoch: 10.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6128493104863475		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 3.6128493104863475 | validation: 2.7311144543730155]
	TIME [epoch: 10.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.019687370202303		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 3.019687370202303 | validation: 2.922677774688464]
	TIME [epoch: 10.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.48361051259199		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 3.48361051259199 | validation: 2.8220512826055235]
	TIME [epoch: 10.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.271805583286189		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 3.271805583286189 | validation: 2.4385111232040697]
	TIME [epoch: 10.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9278101766304587		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 2.9278101766304587 | validation: 2.502987536021833]
	TIME [epoch: 10.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.217638227936009		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 3.217638227936009 | validation: 2.5814128684648803]
	TIME [epoch: 10.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9906165617149925		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 2.9906165617149925 | validation: 2.621139484029036]
	TIME [epoch: 10.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1693143248558195		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 3.1693143248558195 | validation: 2.923374950355427]
	TIME [epoch: 10.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.037314516643109		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 3.037314516643109 | validation: 2.6180692958138785]
	TIME [epoch: 10.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.965340251873204		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 2.965340251873204 | validation: 2.313827061285969]
	TIME [epoch: 10.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.817951708370891		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 2.817951708370891 | validation: 2.2825331599634686]
	TIME [epoch: 10.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9720343902958533		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 2.9720343902958533 | validation: 2.424657770869921]
	TIME [epoch: 10.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8993739595250143		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 2.8993739595250143 | validation: 2.3216117165464447]
	TIME [epoch: 10.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9549442637324494		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 2.9549442637324494 | validation: 2.7616586317922156]
	TIME [epoch: 10.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4391999943347757		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 3.4391999943347757 | validation: 2.734183063847654]
	TIME [epoch: 10.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0902931608076187		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 3.0902931608076187 | validation: 2.46352593745361]
	TIME [epoch: 10.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.888546949933654		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 2.888546949933654 | validation: 2.356692109885006]
	TIME [epoch: 10.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8992190472028376		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 2.8992190472028376 | validation: 2.539426352764985]
	TIME [epoch: 10.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8977594671738283		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 2.8977594671738283 | validation: 2.755406952321191]
	TIME [epoch: 10.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.000092035514739		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 3.000092035514739 | validation: 2.3235851563687975]
	TIME [epoch: 10.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.964820953644952		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 2.964820953644952 | validation: 3.085651697172263]
	TIME [epoch: 10.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.848276460573672		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 2.848276460573672 | validation: 2.646162663328241]
	TIME [epoch: 10.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.517192434703419		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 3.517192434703419 | validation: 4.4179686739490265]
	TIME [epoch: 10.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.741508239950517		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 4.741508239950517 | validation: 4.523557478493869]
	TIME [epoch: 10.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4154210528064555		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 4.4154210528064555 | validation: 4.213770116337724]
	TIME [epoch: 10.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.899467628080048		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 4.899467628080048 | validation: 4.58889122218004]
	TIME [epoch: 10.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.047492866700396		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 5.047492866700396 | validation: 4.7990753266389605]
	TIME [epoch: 10.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.101327283519706		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 5.101327283519706 | validation: 4.671540781169587]
	TIME [epoch: 10.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.862927917393209		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 4.862927917393209 | validation: 4.034020677146434]
	TIME [epoch: 10.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8628317902263065		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 3.8628317902263065 | validation: 2.538029410966563]
	TIME [epoch: 10.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.966891780384258		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 2.966891780384258 | validation: 2.698072282851252]
	TIME [epoch: 10.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4109215298146593		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 3.4109215298146593 | validation: 2.541101000538609]
	TIME [epoch: 10.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.796167940392784		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 2.796167940392784 | validation: 2.1453116102907237]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6060955484908646		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 2.6060955484908646 | validation: 2.0103665828689175]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5659157789845835		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 2.5659157789845835 | validation: 2.627709267281251]
	TIME [epoch: 10.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.010074576856178		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 3.010074576856178 | validation: 2.2390224563465018]
	TIME [epoch: 10.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.029176416988957		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 3.029176416988957 | validation: 2.289387873802236]
	TIME [epoch: 10.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7013579931675036		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 2.7013579931675036 | validation: 2.159205249584646]
	TIME [epoch: 10.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7246102359894353		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 2.7246102359894353 | validation: 3.4761960807052494]
	TIME [epoch: 10.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2004821011869153		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 3.2004821011869153 | validation: 2.1673648728781307]
	TIME [epoch: 10.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6180360536376845		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 2.6180360536376845 | validation: 2.3297686248896516]
	TIME [epoch: 10.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6866283115336373		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 2.6866283115336373 | validation: 2.057848454250096]
	TIME [epoch: 10.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5507214327065846		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 2.5507214327065846 | validation: 2.3266211530912733]
	TIME [epoch: 10.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5079956413211173		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 2.5079956413211173 | validation: 2.425098450836644]
	TIME [epoch: 10.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.593421588551268		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 2.593421588551268 | validation: 1.9267067951052608]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7777287306566927		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 2.7777287306566927 | validation: 2.476084941257062]
	TIME [epoch: 10.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.680833349899494		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 2.680833349899494 | validation: 2.130911199903347]
	TIME [epoch: 10.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.738343480766763		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 2.738343480766763 | validation: 2.141218016112784]
	TIME [epoch: 10.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6583724069857353		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 2.6583724069857353 | validation: 1.987717483699614]
	TIME [epoch: 10.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.494354308628028		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 2.494354308628028 | validation: 1.9731823176817327]
	TIME [epoch: 10.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9005693508086012		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 2.9005693508086012 | validation: 4.136313339920009]
	TIME [epoch: 10.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5301486483177635		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 4.5301486483177635 | validation: 4.152674744189111]
	TIME [epoch: 10.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.452411908762985		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 4.452411908762985 | validation: 3.971238947122115]
	TIME [epoch: 10.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.532310177074449		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 3.532310177074449 | validation: 2.395160156475062]
	TIME [epoch: 10.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4723805393492855		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 2.4723805393492855 | validation: 1.806625594724314]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.639359339251357		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 2.639359339251357 | validation: 1.900258972867868]
	TIME [epoch: 10.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3650931870442387		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 2.3650931870442387 | validation: 2.1257664516091035]
	TIME [epoch: 10.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.638366793856338		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 2.638366793856338 | validation: 1.7827921726429186]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.314133522680296		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 2.314133522680296 | validation: 2.3924231182144764]
	TIME [epoch: 10.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.862714023179848		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 2.862714023179848 | validation: 2.0180208881630355]
	TIME [epoch: 10.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.473161035168945		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 2.473161035168945 | validation: 2.1098540755951443]
	TIME [epoch: 10.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7273735153634573		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 2.7273735153634573 | validation: 1.9426936494612204]
	TIME [epoch: 10.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3127109369599013		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 2.3127109369599013 | validation: 2.293518542138535]
	TIME [epoch: 10.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6851980412995546		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 2.6851980412995546 | validation: 2.4000681889944167]
	TIME [epoch: 10.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5355835319510143		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 2.5355835319510143 | validation: 3.014897356335587]
	TIME [epoch: 10.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.237048026241959		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 3.237048026241959 | validation: 2.1587916889390226]
	TIME [epoch: 10.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.431355509829216		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 2.431355509829216 | validation: 1.8230636469137875]
	TIME [epoch: 10.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.543284883241341		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 2.543284883241341 | validation: 1.9534935466577303]
	TIME [epoch: 10.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4691036708528626		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 2.4691036708528626 | validation: 1.9660365535983544]
	TIME [epoch: 10.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3927791520043535		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 2.3927791520043535 | validation: 1.8414008354552158]
	TIME [epoch: 10.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4945906043893165		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 2.4945906043893165 | validation: 1.9183309617888504]
	TIME [epoch: 10.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5898418712262434		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 2.5898418712262434 | validation: 2.044707086777816]
	TIME [epoch: 10.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3170010186249277		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 2.3170010186249277 | validation: 2.0137629202681437]
	TIME [epoch: 10.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.306407463271959		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 2.306407463271959 | validation: 1.652175775438621]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3672438166927963		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 2.3672438166927963 | validation: 1.9626116152207538]
	TIME [epoch: 10.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.334551966839933		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 2.334551966839933 | validation: 1.7641587417130655]
	TIME [epoch: 10.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.536759144968946		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 2.536759144968946 | validation: 2.031240410622373]
	TIME [epoch: 10.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4932110317142735		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 2.4932110317142735 | validation: 1.7896448259100048]
	TIME [epoch: 10.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.374062026219122		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 2.374062026219122 | validation: 1.8673935509620898]
	TIME [epoch: 10.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5525062773196687		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 2.5525062773196687 | validation: 2.349150911146523]
	TIME [epoch: 10.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3969051009997293		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 2.3969051009997293 | validation: 2.057156974436686]
	TIME [epoch: 10.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6595350598943295		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 2.6595350598943295 | validation: 2.457904495294583]
	TIME [epoch: 10.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.385696005095204		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 2.385696005095204 | validation: 2.3822101866583814]
	TIME [epoch: 10.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.822604881191033		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 3.822604881191033 | validation: 3.8936731261423776]
	TIME [epoch: 10.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.730431249971249		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 3.730431249971249 | validation: 2.9966590867494465]
	TIME [epoch: 10.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6373255919250798		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 2.6373255919250798 | validation: 1.7994743699355786]
	TIME [epoch: 10.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.491267423191034		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 2.491267423191034 | validation: 1.88215094602735]
	TIME [epoch: 10.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.238083380009943		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 2.238083380009943 | validation: 1.858860721881749]
	TIME [epoch: 10.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.27450797345462		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 2.27450797345462 | validation: 1.8622231088702765]
	TIME [epoch: 10.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1430532633629107		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 2.1430532633629107 | validation: 1.6239351396408261]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3458824454970335		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 2.3458824454970335 | validation: 2.1881130734447276]
	TIME [epoch: 10.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3776118885129156		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 2.3776118885129156 | validation: 1.710057293851725]
	TIME [epoch: 10.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2279236865182144		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 2.2279236865182144 | validation: 1.6873294060063597]
	TIME [epoch: 10.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0032597104095395		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 2.0032597104095395 | validation: 2.1444263020892276]
	TIME [epoch: 10.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8145397443819316		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 2.8145397443819316 | validation: 2.0981967789669502]
	TIME [epoch: 10.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3114718596016366		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 2.3114718596016366 | validation: 2.0847732804313956]
	TIME [epoch: 10.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.235097269890767		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 2.235097269890767 | validation: 1.486162522776249]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0536302017768113		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 2.0536302017768113 | validation: 1.761880792174264]
	TIME [epoch: 10.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.047477920117102		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 2.047477920117102 | validation: 1.6724500074245672]
	TIME [epoch: 10.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0621309826188687		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 2.0621309826188687 | validation: 2.0945651875711997]
	TIME [epoch: 10.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.152029311458242		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 2.152029311458242 | validation: 1.6111615098950496]
	TIME [epoch: 10.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.199461795638474		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 2.199461795638474 | validation: 1.6039540654250959]
	TIME [epoch: 10.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.057748506924245		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 2.057748506924245 | validation: 1.5950562763871807]
	TIME [epoch: 10.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.022821489329889		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 2.022821489329889 | validation: 1.9179464046087378]
	TIME [epoch: 10.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2801840512833875		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 2.2801840512833875 | validation: 1.5502050506480032]
	TIME [epoch: 10.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.017921258268867		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 2.017921258268867 | validation: 1.580418174689558]
	TIME [epoch: 10.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8663343714154395		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 1.8663343714154395 | validation: 1.555862294732281]
	TIME [epoch: 10.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8985572941975843		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 1.8985572941975843 | validation: 1.6067305594407912]
	TIME [epoch: 10.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9616904300069091		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 1.9616904300069091 | validation: 1.378825466550211]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.014552749608934		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 2.014552749608934 | validation: 2.214424223878724]
	TIME [epoch: 10.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2036227140032985		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 2.2036227140032985 | validation: 2.0377490451835407]
	TIME [epoch: 10.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8958320104973896		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 1.8958320104973896 | validation: 1.6237456838351427]
	TIME [epoch: 10.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0474436977993555		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 2.0474436977993555 | validation: 1.7409862667229816]
	TIME [epoch: 10.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9392588761348566		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 1.9392588761348566 | validation: 1.8754581299191495]
	TIME [epoch: 10.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0029368415070876		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 2.0029368415070876 | validation: 1.4591047839217646]
	TIME [epoch: 10.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7107230858954996		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 1.7107230858954996 | validation: 1.5747662546776573]
	TIME [epoch: 10.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6304943517047683		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 1.6304943517047683 | validation: 1.2464716948280299]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5568793112160804		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 1.5568793112160804 | validation: 1.2154332600742526]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6041488038936857		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 1.6041488038936857 | validation: 1.7588318653356203]
	TIME [epoch: 10.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6923639229570213		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.6923639229570213 | validation: 1.21799510454236]
	TIME [epoch: 10.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3914343031833198		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 1.3914343031833198 | validation: 1.1580388637181795]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.396457830985622		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 1.396457830985622 | validation: 1.3169472286393984]
	TIME [epoch: 10.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3585239000951246		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 1.3585239000951246 | validation: 1.125063737749276]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3560909470945917		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 1.3560909470945917 | validation: 0.9174707001153636]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4672443881745987		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 1.4672443881745987 | validation: 0.9656478875235474]
	TIME [epoch: 10.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2148615609026467		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 1.2148615609026467 | validation: 0.9178452728168353]
	TIME [epoch: 10.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.113559695456583		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 1.113559695456583 | validation: 1.009681094405104]
	TIME [epoch: 10.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0105079731049824		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 1.0105079731049824 | validation: 0.701725805067777]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.157487683774677		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 1.157487683774677 | validation: 1.5998394338141169]
	TIME [epoch: 10.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.145370826725165		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 1.145370826725165 | validation: 0.7839870538862542]
	TIME [epoch: 10.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1066738915594965		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 1.1066738915594965 | validation: 0.7510382806924952]
	TIME [epoch: 10.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7993203141187695		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.7993203141187695 | validation: 0.7896029844409919]
	TIME [epoch: 10.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9768973958599598		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.9768973958599598 | validation: 0.754328072650922]
	TIME [epoch: 10.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1687300745380285		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 1.1687300745380285 | validation: 0.6796482735836582]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9438071301403973		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.9438071301403973 | validation: 1.031018515051111]
	TIME [epoch: 10.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8804798267899315		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.8804798267899315 | validation: 0.5418112010657679]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8759888779546341		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.8759888779546341 | validation: 0.6312662684148519]
	TIME [epoch: 10.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7898473546547001		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.7898473546547001 | validation: 0.6571229705449416]
	TIME [epoch: 10.3 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8061049871788348		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.8061049871788348 | validation: 0.707858682278629]
	TIME [epoch: 10.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2969674487083807		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 1.2969674487083807 | validation: 1.4096176134426701]
	TIME [epoch: 10.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8801735201390063		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.8801735201390063 | validation: 1.1937713253106685]
	TIME [epoch: 10.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9443054032638258		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.9443054032638258 | validation: 0.877990968988282]
	TIME [epoch: 10.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.885087045798324		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.885087045798324 | validation: 0.8759969619397835]
	TIME [epoch: 10.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.809302414517082		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.809302414517082 | validation: 0.505024165505949]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7400244580788327		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.7400244580788327 | validation: 0.844955623340887]
	TIME [epoch: 10.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1316787913810227		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 1.1316787913810227 | validation: 0.9800451257047873]
	TIME [epoch: 10.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8704613058292991		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.8704613058292991 | validation: 0.556533195987256]
	TIME [epoch: 10.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4500592872499773		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 1.4500592872499773 | validation: 0.8375029725418464]
	TIME [epoch: 10.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0104041536858328		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 1.0104041536858328 | validation: 0.6301695781497898]
	TIME [epoch: 10.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7413783020409597		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.7413783020409597 | validation: 0.7664057639944974]
	TIME [epoch: 10.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7657933224754497		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.7657933224754497 | validation: 0.5437274441653351]
	TIME [epoch: 10.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7065241524254402		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.7065241524254402 | validation: 0.883408569001836]
	TIME [epoch: 10.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7502792437363237		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.7502792437363237 | validation: 0.6697592317348284]
	TIME [epoch: 10.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7335560668898791		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.7335560668898791 | validation: 0.7515464459732786]
	TIME [epoch: 10.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6563271149108862		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.6563271149108862 | validation: 1.0980199112378533]
	TIME [epoch: 10.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9758089267392256		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.9758089267392256 | validation: 0.5279885213991178]
	TIME [epoch: 10.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5641598610386842		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.5641598610386842 | validation: 0.8259788614792908]
	TIME [epoch: 10.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0624829601547277		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 1.0624829601547277 | validation: 0.9034129336878346]
	TIME [epoch: 10.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7494469096614538		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.7494469096614538 | validation: 0.5397274336113606]
	TIME [epoch: 10.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7432552344454155		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.7432552344454155 | validation: 0.6336109816395521]
	TIME [epoch: 10.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6403427090380026		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.6403427090380026 | validation: 0.6058216105947882]
	TIME [epoch: 10.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6778300111613917		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.6778300111613917 | validation: 0.5159751267579168]
	TIME [epoch: 10.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7877903815226769		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.7877903815226769 | validation: 0.4784931982829815]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_491.pth
	Model improved!!!
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8441070856260044		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.8441070856260044 | validation: 0.6139897250736771]
	TIME [epoch: 10.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5788407733765437		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.5788407733765437 | validation: 0.9371220663342423]
	TIME [epoch: 10.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7777223211226587		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.7777223211226587 | validation: 0.5331334544121764]
	TIME [epoch: 10.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8267048171748964		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.8267048171748964 | validation: 0.5329670174392304]
	TIME [epoch: 10.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5488761864033039		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.5488761864033039 | validation: 1.071039632860909]
	TIME [epoch: 10.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7970791537246156		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.7970791537246156 | validation: 0.5322608857841808]
	TIME [epoch: 10.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7066809804484459		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.7066809804484459 | validation: 0.6600259427163502]
	TIME [epoch: 10.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6769991822141901		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.6769991822141901 | validation: 0.9539316329181665]
	TIME [epoch: 10.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.696142689157556		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.696142689157556 | validation: 0.4666197995408117]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324533284831429		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.5324533284831429 | validation: 0.6838142691170142]
	TIME [epoch: 10.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.920980087139502		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.920980087139502 | validation: 0.9462940827193438]
	TIME [epoch: 10.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.876632436299581		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.876632436299581 | validation: 1.4469955730912545]
	TIME [epoch: 10.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.777382233259146		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.777382233259146 | validation: 0.5179931399727977]
	TIME [epoch: 10.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318648810444848		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.5318648810444848 | validation: 0.4403314729124598]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7039286993985552		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.7039286993985552 | validation: 0.6314837336174087]
	TIME [epoch: 10.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7864187526977022		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.7864187526977022 | validation: 0.4949370004389353]
	TIME [epoch: 10.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5443916648025645		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.5443916648025645 | validation: 0.5797147250826011]
	TIME [epoch: 10.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5594219366113942		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.5594219366113942 | validation: 0.5402376244730521]
	TIME [epoch: 10.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6318497336256444		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.6318497336256444 | validation: 0.7499825795162144]
	TIME [epoch: 10.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7691637841533987		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.7691637841533987 | validation: 0.5220381561043684]
	TIME [epoch: 10.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.884492803691207		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.884492803691207 | validation: 0.4615255007720269]
	TIME [epoch: 10.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7413451938395786		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.7413451938395786 | validation: 0.9769458312624582]
	TIME [epoch: 10.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9197286627967033		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.9197286627967033 | validation: 0.9295726808459794]
	TIME [epoch: 10.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6233539690733989		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.6233539690733989 | validation: 0.6936198639167318]
	TIME [epoch: 10.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9757414512818633		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.9757414512818633 | validation: 0.6638056118605005]
	TIME [epoch: 10.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5921331266666305		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.5921331266666305 | validation: 0.47161497187879475]
	TIME [epoch: 10.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6004398457562451		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.6004398457562451 | validation: 0.7259391449113636]
	TIME [epoch: 10.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7642395264055704		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.7642395264055704 | validation: 0.6741676605860684]
	TIME [epoch: 10.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.599729030984059		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.599729030984059 | validation: 0.8191270444180152]
	TIME [epoch: 10.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8716280555768284		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.8716280555768284 | validation: 0.718592104384469]
	TIME [epoch: 10.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8495532015195224		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.8495532015195224 | validation: 0.6561199482731902]
	TIME [epoch: 10.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9663731374109341		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.9663731374109341 | validation: 0.7943781118680394]
	TIME [epoch: 10.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468122400434801		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.6468122400434801 | validation: 0.6968831428513803]
	TIME [epoch: 10.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6535765942113019		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.6535765942113019 | validation: 0.8769086153726621]
	TIME [epoch: 10.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103966904383145		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.7103966904383145 | validation: 0.5841004413652354]
	TIME [epoch: 10.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6251066542375474		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.6251066542375474 | validation: 0.5153004967271672]
	TIME [epoch: 10.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5627712012997931		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.5627712012997931 | validation: 0.6404470985360348]
	TIME [epoch: 10.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5447819841473468		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.5447819841473468 | validation: 1.4177714460861393]
	TIME [epoch: 10.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8714104436008494		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.8714104436008494 | validation: 1.282150882874484]
	TIME [epoch: 10.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.863060636263457		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.863060636263457 | validation: 0.7715601470595277]
	TIME [epoch: 10.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948307119885456		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.5948307119885456 | validation: 0.9185917045447601]
	TIME [epoch: 10.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7067643041539218		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.7067643041539218 | validation: 0.501114463870806]
	TIME [epoch: 10.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5695926167538922		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.5695926167538922 | validation: 0.6328309650945486]
	TIME [epoch: 10.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8760659020289164		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.8760659020289164 | validation: 0.7377894703436428]
	TIME [epoch: 10.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8072022037183887		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.8072022037183887 | validation: 0.8319986979178842]
	TIME [epoch: 10.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7002145597510523		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.7002145597510523 | validation: 0.6448584532850724]
	TIME [epoch: 10.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7439008344877446		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.7439008344877446 | validation: 0.45834268861045585]
	TIME [epoch: 10.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49015550395698104		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.49015550395698104 | validation: 0.7739643269131989]
	TIME [epoch: 10.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5917192906642552		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.5917192906642552 | validation: 0.6698952201162609]
	TIME [epoch: 10.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9000771437051057		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.9000771437051057 | validation: 1.487239131733388]
	TIME [epoch: 10.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8082203488778046		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.8082203488778046 | validation: 0.9061486523045256]
	TIME [epoch: 10.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198917131463197		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.6198917131463197 | validation: 0.3594802835500538]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7106956064892757		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.7106956064892757 | validation: 0.43134063357727687]
	TIME [epoch: 10.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46129697638508665		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.46129697638508665 | validation: 0.7640207928796258]
	TIME [epoch: 10.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5770881246770089		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.5770881246770089 | validation: 0.5391741922618606]
	TIME [epoch: 10.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5000620449775622		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.5000620449775622 | validation: 0.5343676547991995]
	TIME [epoch: 10.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604479033396758		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.5604479033396758 | validation: 0.9309360869873949]
	TIME [epoch: 10.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6952146642417552		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.6952146642417552 | validation: 0.8167289669846871]
	TIME [epoch: 10.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5972971453058573		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.5972971453058573 | validation: 0.6629175871381042]
	TIME [epoch: 10.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5910354849718356		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.5910354849718356 | validation: 0.3855187297296549]
	TIME [epoch: 10.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48784652222276864		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.48784652222276864 | validation: 0.41795033176633356]
	TIME [epoch: 10.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7230759263266924		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.7230759263266924 | validation: 0.8180567648778216]
	TIME [epoch: 10.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9925127275022234		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.9925127275022234 | validation: 0.41117177438031816]
	TIME [epoch: 10.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213140643203011		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.5213140643203011 | validation: 0.4552019287840677]
	TIME [epoch: 10.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4707276987360086		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.4707276987360086 | validation: 0.5133836466008548]
	TIME [epoch: 10.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6676022391367947		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.6676022391367947 | validation: 0.3576680388855442]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48539993775813395		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.48539993775813395 | validation: 0.45619780415750216]
	TIME [epoch: 10.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7096109852041812		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.7096109852041812 | validation: 1.0073733558287719]
	TIME [epoch: 10.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.840868180212123		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.840868180212123 | validation: 3.1700539221137087]
	TIME [epoch: 10.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.969042124749939		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 2.969042124749939 | validation: 2.560480608279819]
	TIME [epoch: 10.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.72483198321643		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 2.72483198321643 | validation: 1.7791995819365638]
	TIME [epoch: 10.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2153698803945847		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 1.2153698803945847 | validation: 1.2273460662333966]
	TIME [epoch: 10.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516944260123381		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.6516944260123381 | validation: 0.315155621665943]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7063577650319336		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.7063577650319336 | validation: 0.820970459604954]
	TIME [epoch: 10.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5705737376451212		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.5705737376451212 | validation: 0.43532786454768074]
	TIME [epoch: 10.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6320632363779941		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.6320632363779941 | validation: 0.4038264884534729]
	TIME [epoch: 10.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6755696339831881		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.6755696339831881 | validation: 0.8418416460218844]
	TIME [epoch: 10.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245145611766123		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.6245145611766123 | validation: 0.45449207112170087]
	TIME [epoch: 10.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5488490640184052		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.5488490640184052 | validation: 0.8245513338009982]
	TIME [epoch: 10.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999801229319667		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.5999801229319667 | validation: 0.3697153101648742]
	TIME [epoch: 10.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2266785414863743		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 1.2266785414863743 | validation: 1.0291598230261387]
	TIME [epoch: 10.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0890783589761655		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 1.0890783589761655 | validation: 0.6917917967873163]
	TIME [epoch: 10.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6419425086307433		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.6419425086307433 | validation: 0.3699199288113355]
	TIME [epoch: 10.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5538225123987963		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.5538225123987963 | validation: 0.6541561030670823]
	TIME [epoch: 10.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5133973542223063		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.5133973542223063 | validation: 0.4091857735557292]
	TIME [epoch: 10.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6912920209581259		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.6912920209581259 | validation: 0.33364510727357866]
	TIME [epoch: 10.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.511187303453425		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.511187303453425 | validation: 0.32826809163367493]
	TIME [epoch: 10.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1214417024760455		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 1.1214417024760455 | validation: 0.9476895004566523]
	TIME [epoch: 10.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7821186366373382		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.7821186366373382 | validation: 0.36950532086879784]
	TIME [epoch: 10.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5456812447815255		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.5456812447815255 | validation: 0.7943025281968303]
	TIME [epoch: 10.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7277765202556216		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.7277765202556216 | validation: 0.5908467117407006]
	TIME [epoch: 10.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8562126037527268		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.8562126037527268 | validation: 0.40982432030597776]
	TIME [epoch: 10.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4694950483372969		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.4694950483372969 | validation: 0.36653141243704895]
	TIME [epoch: 10.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8506607290988134		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.8506607290988134 | validation: 0.4511989513090945]
	TIME [epoch: 10.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5388950347646511		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.5388950347646511 | validation: 0.38327721674926357]
	TIME [epoch: 10.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4533960696855157		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.4533960696855157 | validation: 0.5041196089385447]
	TIME [epoch: 10.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5866982750085199		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.5866982750085199 | validation: 0.35827893297584573]
	TIME [epoch: 10.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7147499128816819		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.7147499128816819 | validation: 0.6372468373321531]
	TIME [epoch: 10.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9201265363179782		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.9201265363179782 | validation: 0.9651678897265873]
	TIME [epoch: 10.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6015785759247583		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.6015785759247583 | validation: 1.1839824576663798]
	TIME [epoch: 10.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5845332503064717		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.5845332503064717 | validation: 0.39813730588228213]
	TIME [epoch: 10.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.751101800608393		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.751101800608393 | validation: 0.8114913992529067]
	TIME [epoch: 10.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393427915911095		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.6393427915911095 | validation: 0.5337656656359723]
	TIME [epoch: 10.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6093704283351437		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.6093704283351437 | validation: 0.973014983020376]
	TIME [epoch: 10.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6753683342066149		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.6753683342066149 | validation: 0.4485172022280803]
	TIME [epoch: 10.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5835156621879302		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.5835156621879302 | validation: 0.7781235159223024]
	TIME [epoch: 10.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6527017509103304		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.6527017509103304 | validation: 1.028325253963626]
	TIME [epoch: 10.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0088044617660787		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 1.0088044617660787 | validation: 0.5180023880948333]
	TIME [epoch: 10.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5433235720843921		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.5433235720843921 | validation: 0.5394352137804616]
	TIME [epoch: 10.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.612431508644331		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.612431508644331 | validation: 0.4127420357989683]
	TIME [epoch: 10.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6329863474814528		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 1.6329863474814528 | validation: 1.394205142070577]
	TIME [epoch: 10.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.199668287324537		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 1.199668287324537 | validation: 1.4458069355735155]
	TIME [epoch: 10.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0031810500919882		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 1.0031810500919882 | validation: 0.44122618396478813]
	TIME [epoch: 10.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250784302616147		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.6250784302616147 | validation: 0.48556561399247705]
	TIME [epoch: 10.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5385867827029726		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.5385867827029726 | validation: 0.33368028204041694]
	TIME [epoch: 10.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7455650245563452		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.7455650245563452 | validation: 0.6512259116293572]
	TIME [epoch: 10.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6819602673593157		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.6819602673593157 | validation: 0.33647394232218103]
	TIME [epoch: 10.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4574387436178502		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.4574387436178502 | validation: 0.38330683893765377]
	TIME [epoch: 10.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5418565776814209		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.5418565776814209 | validation: 0.35723192818309085]
	TIME [epoch: 10.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378361625472498		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.6378361625472498 | validation: 0.7771204908632448]
	TIME [epoch: 10.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391393149328732		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.6391393149328732 | validation: 0.4080692862352319]
	TIME [epoch: 10.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200992660286652		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.5200992660286652 | validation: 1.0627426050977709]
	TIME [epoch: 10.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7434562549653917		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.7434562549653917 | validation: 0.3499985489476192]
	TIME [epoch: 10.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4221285742468627		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.4221285742468627 | validation: 0.4649579507647391]
	TIME [epoch: 10.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46078987927400544		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.46078987927400544 | validation: 0.3741118238983318]
	TIME [epoch: 10.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4397781626448034		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.4397781626448034 | validation: 0.4336281781621923]
	TIME [epoch: 10.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45503808574262405		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.45503808574262405 | validation: 0.33794110681905387]
	TIME [epoch: 10.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361861893855211		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.5361861893855211 | validation: 0.8660945930649951]
	TIME [epoch: 10.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6045858983147998		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.6045858983147998 | validation: 0.48614866558591874]
	TIME [epoch: 10.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5331043217472684		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.5331043217472684 | validation: 0.38613088336553103]
	TIME [epoch: 10.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38953994712758677		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.38953994712758677 | validation: 0.3705447301168661]
	TIME [epoch: 10.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4885182769169264		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.4885182769169264 | validation: 0.43088782015955046]
	TIME [epoch: 10.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7477832943934954		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.7477832943934954 | validation: 0.6445326914724746]
	TIME [epoch: 10.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6239048964630901		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.6239048964630901 | validation: 0.5616088448203683]
	TIME [epoch: 10.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1574789084342807		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 1.1574789084342807 | validation: 0.7980904325985934]
	TIME [epoch: 10.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5565538643830551		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.5565538643830551 | validation: 0.5195643784112081]
	TIME [epoch: 10.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5040087335958487		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.5040087335958487 | validation: 0.4532991744364078]
	TIME [epoch: 10.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5644064906913719		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.5644064906913719 | validation: 0.46760331372991915]
	TIME [epoch: 10.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616926754873072		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.4616926754873072 | validation: 1.0957804612550026]
	TIME [epoch: 10.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7442584329461718		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.7442584329461718 | validation: 0.4114448424456634]
	TIME [epoch: 10.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8217750905100788		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.8217750905100788 | validation: 0.5818824143143163]
	TIME [epoch: 10.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4883901801092917		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.4883901801092917 | validation: 0.47184490674245533]
	TIME [epoch: 10.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6472899856698847		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.6472899856698847 | validation: 0.4096293804628091]
	TIME [epoch: 10.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8133805972596605		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.8133805972596605 | validation: 0.4737436031978892]
	TIME [epoch: 10.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.912826580718832		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.912826580718832 | validation: 0.46537723153600075]
	TIME [epoch: 10.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4702671075172422		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 1.4702671075172422 | validation: 0.9613812830346266]
	TIME [epoch: 10.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7803534659508744		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.7803534659508744 | validation: 0.8493215662216081]
	TIME [epoch: 10.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459379696063305		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.6459379696063305 | validation: 0.48701051944715645]
	TIME [epoch: 10.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393371898921418		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.6393371898921418 | validation: 0.5773887950016479]
	TIME [epoch: 10.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275038047208787		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.5275038047208787 | validation: 0.7195996067043486]
	TIME [epoch: 10.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347768165361269		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.5347768165361269 | validation: 0.7965782704628223]
	TIME [epoch: 10.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8364707029190204		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.8364707029190204 | validation: 1.1015241185315863]
	TIME [epoch: 10.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7210473326903613		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.7210473326903613 | validation: 0.5185957259918661]
	TIME [epoch: 10.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48226769995533214		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.48226769995533214 | validation: 0.38492654160394585]
	TIME [epoch: 10.3 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057298445676334		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.5057298445676334 | validation: 0.7030253019622913]
	TIME [epoch: 10.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5598804238655379		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.5598804238655379 | validation: 0.9257637632991348]
	TIME [epoch: 10.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7521349291308128		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.7521349291308128 | validation: 0.38385500897706937]
	TIME [epoch: 10.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505002855513752		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.505002855513752 | validation: 0.39839904948305]
	TIME [epoch: 10.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4517549980986438		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.4517549980986438 | validation: 0.38898052656662274]
	TIME [epoch: 10.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5551289436853012		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.5551289436853012 | validation: 0.31016490197206004]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5092099086990961		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.5092099086990961 | validation: 0.967640955983492]
	TIME [epoch: 10.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197139484819027		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.5197139484819027 | validation: 0.631893394979323]
	TIME [epoch: 10.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43810774188395074		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.43810774188395074 | validation: 0.44631689633554905]
	TIME [epoch: 10.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5597234823618574		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.5597234823618574 | validation: 0.41187322151053785]
	TIME [epoch: 10.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5804341338837222		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.5804341338837222 | validation: 0.5042842823560659]
	TIME [epoch: 10.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44930529018889687		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.44930529018889687 | validation: 0.37172014931230996]
	TIME [epoch: 10.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4237408421937946		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.4237408421937946 | validation: 0.37337582157362675]
	TIME [epoch: 10.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.569588453951716		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.569588453951716 | validation: 0.33669160774720497]
	TIME [epoch: 10.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4314822474137549		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.4314822474137549 | validation: 0.5830620707858511]
	TIME [epoch: 10.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42134049157900844		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.42134049157900844 | validation: 0.5719798208827568]
	TIME [epoch: 10.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40975359099560277		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.40975359099560277 | validation: 0.3655006821129587]
	TIME [epoch: 10.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.439913997281865		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.439913997281865 | validation: 0.4724337170308518]
	TIME [epoch: 10.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.544581926864578		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.544581926864578 | validation: 0.5754896970904065]
	TIME [epoch: 10.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7620828377459409		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.7620828377459409 | validation: 0.47793266517057087]
	TIME [epoch: 10.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6062627698264109		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.6062627698264109 | validation: 0.7343985839219362]
	TIME [epoch: 10.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5014690521492666		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.5014690521492666 | validation: 0.617094567042025]
	TIME [epoch: 10.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6189871061002192		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.6189871061002192 | validation: 0.3198940025473449]
	TIME [epoch: 10.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4355901989414693		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.4355901989414693 | validation: 0.3151017526032036]
	TIME [epoch: 10.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4677947359274136		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.4677947359274136 | validation: 0.3534875949369845]
	TIME [epoch: 10.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.326010033973073		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.326010033973073 | validation: 0.4550739027068883]
	TIME [epoch: 10.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283705313326121		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.5283705313326121 | validation: 0.4283981128290615]
	TIME [epoch: 10.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.479245944777269		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.479245944777269 | validation: 0.4260755659133496]
	TIME [epoch: 10.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.387348197649725		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.387348197649725 | validation: 0.608197726310621]
	TIME [epoch: 10.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6641062328310053		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.6641062328310053 | validation: 0.4332036142400426]
	TIME [epoch: 10.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5443750225312824		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.5443750225312824 | validation: 0.38542272082665635]
	TIME [epoch: 10.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4539654903109569		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.4539654903109569 | validation: 0.3040635382464573]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5569425151583602		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.5569425151583602 | validation: 0.514034248528368]
	TIME [epoch: 10.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4681308315471996		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.4681308315471996 | validation: 0.34096516392049536]
	TIME [epoch: 10.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4810937276871627		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.4810937276871627 | validation: 0.4803223578618674]
	TIME [epoch: 10.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6840984347151315		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.6840984347151315 | validation: 0.6220798957548273]
	TIME [epoch: 10.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5341303875389702		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.5341303875389702 | validation: 0.6350529584824518]
	TIME [epoch: 10.3 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5772141597457953		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.5772141597457953 | validation: 0.5036053312073849]
	TIME [epoch: 10.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5033949212666828		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.5033949212666828 | validation: 0.4999046474299483]
	TIME [epoch: 10.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37535100398934673		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.37535100398934673 | validation: 0.3220329810365174]
	TIME [epoch: 10.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3861172209487065		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.3861172209487065 | validation: 0.8164814798942436]
	TIME [epoch: 10.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5245486571969046		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.5245486571969046 | validation: 0.3055310015473174]
	TIME [epoch: 10.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5770457660981358		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.5770457660981358 | validation: 0.8067406629968952]
	TIME [epoch: 10.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6019599215732971		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.6019599215732971 | validation: 0.3527171248917989]
	TIME [epoch: 10.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44444922065257775		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.44444922065257775 | validation: 0.42305314635330166]
	TIME [epoch: 10.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241635774152262		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.5241635774152262 | validation: 0.40935677456873093]
	TIME [epoch: 10.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7117941247396153		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.7117941247396153 | validation: 0.3011109009296138]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_692.pth
	Model improved!!!
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49258816945593065		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.49258816945593065 | validation: 0.4861070323755927]
	TIME [epoch: 10.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46880646788824976		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.46880646788824976 | validation: 0.3820446549990337]
	TIME [epoch: 10.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840417947375787		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.5840417947375787 | validation: 1.086824477731206]
	TIME [epoch: 10.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6695382801169792		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.6695382801169792 | validation: 0.28756941771513655]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3649167303349067		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.3649167303349067 | validation: 0.321700346643524]
	TIME [epoch: 10.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4694895071735118		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.4694895071735118 | validation: 0.27305411613726877]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5681470030524591		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.5681470030524591 | validation: 1.1085787320503182]
	TIME [epoch: 10.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6441927709603482		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.6441927709603482 | validation: 0.43891305586197504]
	TIME [epoch: 10.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4975103415591734		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.4975103415591734 | validation: 0.5402119157076609]
	TIME [epoch: 10.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.763045448556347		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.763045448556347 | validation: 0.4279579351159946]
	TIME [epoch: 10.3 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5446079676531649		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.5446079676531649 | validation: 0.48387933360965873]
	TIME [epoch: 10.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5899168208076576		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.5899168208076576 | validation: 0.5079442939149265]
	TIME [epoch: 10.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.524485473246154		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.524485473246154 | validation: 0.3728166888914013]
	TIME [epoch: 10.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5056993329917234		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.5056993329917234 | validation: 0.3447456943539507]
	TIME [epoch: 10.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.671906118754319		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.671906118754319 | validation: 0.42571801916278135]
	TIME [epoch: 10.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3959455143548394		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.3959455143548394 | validation: 0.46268415832004495]
	TIME [epoch: 10.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5564283074204213		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.5564283074204213 | validation: 0.7331998979461511]
	TIME [epoch: 10.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4903244722737325		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.4903244722737325 | validation: 0.7331240868588177]
	TIME [epoch: 10.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5885102030779544		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.5885102030779544 | validation: 0.3407170905469258]
	TIME [epoch: 10.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39164689401130476		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.39164689401130476 | validation: 0.38297540428646254]
	TIME [epoch: 10.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4491230554618665		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.4491230554618665 | validation: 0.3666479606660576]
	TIME [epoch: 10.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48709206783478276		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.48709206783478276 | validation: 0.3680280604179309]
	TIME [epoch: 10.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41579272755223934		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.41579272755223934 | validation: 0.6180858646722389]
	TIME [epoch: 10.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5684338619779956		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.5684338619779956 | validation: 0.9832478517254578]
	TIME [epoch: 10.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7603847440636089		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.7603847440636089 | validation: 0.4042399852513785]
	TIME [epoch: 10.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795271319232381		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.3795271319232381 | validation: 0.37743552425611254]
	TIME [epoch: 10.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3547822213683285		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.3547822213683285 | validation: 0.6975292367783628]
	TIME [epoch: 10.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.540390858326577		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.540390858326577 | validation: 0.429657106000137]
	TIME [epoch: 10.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.851119113265095		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.851119113265095 | validation: 0.7727345261433425]
	TIME [epoch: 10.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6110316906888705		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.6110316906888705 | validation: 0.3080252263645399]
	TIME [epoch: 10.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47948540684516255		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.47948540684516255 | validation: 0.6453189471925186]
	TIME [epoch: 10.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318412144102084		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.5318412144102084 | validation: 0.45096698760145837]
	TIME [epoch: 10.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35734702416443026		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.35734702416443026 | validation: 0.3924295813202538]
	TIME [epoch: 10.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3889505355053064		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.3889505355053064 | validation: 0.5480504600091599]
	TIME [epoch: 10.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4546396951514902		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.4546396951514902 | validation: 0.371967742769945]
	TIME [epoch: 10.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31029611861593165		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.31029611861593165 | validation: 0.42157812512387893]
	TIME [epoch: 10.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6061681547459182		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.6061681547459182 | validation: 0.6545995120435691]
	TIME [epoch: 10.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5986374652765661		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.5986374652765661 | validation: 0.440447259462287]
	TIME [epoch: 10.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4815511777310701		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.4815511777310701 | validation: 0.5151151096471712]
	TIME [epoch: 10.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.543620033037804		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.543620033037804 | validation: 0.41202237279926673]
	TIME [epoch: 10.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6828939530940252		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.6828939530940252 | validation: 0.6538185102457031]
	TIME [epoch: 10.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5616326044506402		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.5616326044506402 | validation: 0.7704917216718249]
	TIME [epoch: 10.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5477227183306964		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.5477227183306964 | validation: 0.5626258539353443]
	TIME [epoch: 10.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322156191349575		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.5322156191349575 | validation: 0.4864894843466832]
	TIME [epoch: 10.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42046066119285985		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.42046066119285985 | validation: 0.3451781264741504]
	TIME [epoch: 10.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36660531972426547		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.36660531972426547 | validation: 0.6959229211395394]
	TIME [epoch: 10.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4954929679198332		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.4954929679198332 | validation: 0.3935749295522836]
	TIME [epoch: 10.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240117177373802		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.4240117177373802 | validation: 0.4809007444505711]
	TIME [epoch: 10.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6760845977393493		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.6760845977393493 | validation: 0.4447588865757672]
	TIME [epoch: 10.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37619201630431737		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.37619201630431737 | validation: 0.7138264010774799]
	TIME [epoch: 10.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5042567150011893		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.5042567150011893 | validation: 0.679025663120794]
	TIME [epoch: 10.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6238705999449199		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.6238705999449199 | validation: 0.39439602107336347]
	TIME [epoch: 10.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43094220970721364		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.43094220970721364 | validation: 0.8126753899071233]
	TIME [epoch: 10.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6021902946692228		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.6021902946692228 | validation: 0.29525517509601007]
	TIME [epoch: 10.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.601270235116715		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.601270235116715 | validation: 0.48203229989994517]
	TIME [epoch: 10.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3576141593000927		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.3576141593000927 | validation: 0.33024934357123853]
	TIME [epoch: 10.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7582518463317987		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.7582518463317987 | validation: 0.27076505725339317]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_749.pth
	Model improved!!!
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49108052676991837		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.49108052676991837 | validation: 0.4478577153301434]
	TIME [epoch: 10.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5613738249642952		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.5613738249642952 | validation: 0.3102053743242403]
	TIME [epoch: 10.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4191218376188943		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.4191218376188943 | validation: 0.4769041972695018]
	TIME [epoch: 10.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49140004542048016		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.49140004542048016 | validation: 0.3477048653085014]
	TIME [epoch: 10.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5682023868014496		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.5682023868014496 | validation: 0.4755818581680624]
	TIME [epoch: 10.3 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4473408074409956		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.4473408074409956 | validation: 0.45276408891365677]
	TIME [epoch: 10.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5852751889012489		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.5852751889012489 | validation: 0.43580240527479364]
	TIME [epoch: 10.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807065376916095		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.5807065376916095 | validation: 0.39135327996959407]
	TIME [epoch: 10.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34259475580584053		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.34259475580584053 | validation: 0.33603203875041887]
	TIME [epoch: 10.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5951350125651025		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.5951350125651025 | validation: 0.37756874044881616]
	TIME [epoch: 10.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5122158846260344		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.5122158846260344 | validation: 0.36770466158960946]
	TIME [epoch: 10.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44794860901398137		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.44794860901398137 | validation: 0.35689890822203607]
	TIME [epoch: 10.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.355073507478914		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.355073507478914 | validation: 0.366319373095743]
	TIME [epoch: 10.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4377608184688924		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.4377608184688924 | validation: 0.36321342665066114]
	TIME [epoch: 10.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6124041127606537		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.6124041127606537 | validation: 0.38556568685266357]
	TIME [epoch: 10.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3958281233219843		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.3958281233219843 | validation: 0.43876568112102776]
	TIME [epoch: 10.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3957643668048848		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.3957643668048848 | validation: 0.7295242763933201]
	TIME [epoch: 10.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5646110265042934		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.5646110265042934 | validation: 0.2996877992473515]
	TIME [epoch: 10.3 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44921496630054536		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.44921496630054536 | validation: 0.6296088930220487]
	TIME [epoch: 10.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5589126323236653		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.5589126323236653 | validation: 0.6526121928308368]
	TIME [epoch: 10.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.670147154189805		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.670147154189805 | validation: 0.4207862784426709]
	TIME [epoch: 10.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42237046123938055		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.42237046123938055 | validation: 0.3184674609059996]
	TIME [epoch: 10.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6219040760719758		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.6219040760719758 | validation: 0.39473784859224764]
	TIME [epoch: 10.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3270181475357616		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.3270181475357616 | validation: 0.2998679415235223]
	TIME [epoch: 10.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4595708123290354		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.4595708123290354 | validation: 0.6021478122571692]
	TIME [epoch: 10.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0621656509338093		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 1.0621656509338093 | validation: 0.41217214505808614]
	TIME [epoch: 10.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6247441873743047		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.6247441873743047 | validation: 0.3555022331622179]
	TIME [epoch: 10.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5040434190416325		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.5040434190416325 | validation: 0.509989643786238]
	TIME [epoch: 10.3 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4082473519600482		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.4082473519600482 | validation: 0.7087955482564198]
	TIME [epoch: 10.3 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5364432061159441		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.5364432061159441 | validation: 1.032424846742411]
	TIME [epoch: 10.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6927048046996648		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.6927048046996648 | validation: 0.35142949560324327]
	TIME [epoch: 10.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49515456309659067		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.49515456309659067 | validation: 0.36789806414140785]
	TIME [epoch: 10.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46245496318185025		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.46245496318185025 | validation: 0.6150125977845472]
	TIME [epoch: 10.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5517529766968143		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.5517529766968143 | validation: 0.4130461063450304]
	TIME [epoch: 10.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3582888133266111		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.3582888133266111 | validation: 0.35686730907308395]
	TIME [epoch: 10.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6143187677125701		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.6143187677125701 | validation: 0.36364376914116664]
	TIME [epoch: 10.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38537321790648515		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.38537321790648515 | validation: 0.3079586353056826]
	TIME [epoch: 10.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3132917423654518		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.3132917423654518 | validation: 0.47116506702142325]
	TIME [epoch: 10.3 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4004636335537599		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.4004636335537599 | validation: 0.716752713412357]
	TIME [epoch: 10.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5940652340980396		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.5940652340980396 | validation: 0.8210055082048342]
	TIME [epoch: 10.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4235764435014849		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.4235764435014849 | validation: 0.27648073650627447]
	TIME [epoch: 10.3 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46101453927177055		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.46101453927177055 | validation: 0.44339677220102375]
	TIME [epoch: 10.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3740691089232223		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.3740691089232223 | validation: 0.4177798721628009]
	TIME [epoch: 10.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4337452865425783		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.4337452865425783 | validation: 0.5451718561453123]
	TIME [epoch: 10.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4879712877455308		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.4879712877455308 | validation: 0.4851720282491875]
	TIME [epoch: 10.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5957831685960706		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.5957831685960706 | validation: 0.40243566145360843]
	TIME [epoch: 10.3 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3935450519390773		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.3935450519390773 | validation: 0.32720074453596226]
	TIME [epoch: 10.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46142792682315054		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.46142792682315054 | validation: 0.7416404573627047]
	TIME [epoch: 10.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5691293728177426		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.5691293728177426 | validation: 0.31191109707836157]
	TIME [epoch: 10.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5698238178650561		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.5698238178650561 | validation: 0.32083257839366597]
	TIME [epoch: 10.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7816384883014298		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.7816384883014298 | validation: 0.37371284921010023]
	TIME [epoch: 10.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4844195375200465		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.4844195375200465 | validation: 0.31184649600423214]
	TIME [epoch: 10.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4132174305387329		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.4132174305387329 | validation: 0.7967089093068236]
	TIME [epoch: 10.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.684478992199284		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.684478992199284 | validation: 0.9055579204266505]
	TIME [epoch: 10.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7937452058585467		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.7937452058585467 | validation: 0.32736526439680946]
	TIME [epoch: 10.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.538643214270031		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.538643214270031 | validation: 0.346268263385296]
	TIME [epoch: 10.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43194949990036113		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.43194949990036113 | validation: 0.5176131243765957]
	TIME [epoch: 10.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43362263081972047		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.43362263081972047 | validation: 0.3711166360684381]
	TIME [epoch: 10.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47323907645749974		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.47323907645749974 | validation: 0.3291592351820619]
	TIME [epoch: 10.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4090373637808355		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.4090373637808355 | validation: 0.6363312490866077]
	TIME [epoch: 10.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7020380178994903		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.7020380178994903 | validation: 0.5781340217865416]
	TIME [epoch: 10.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45519537491846923		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.45519537491846923 | validation: 0.44111374752500904]
	TIME [epoch: 10.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4114812128815177		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.4114812128815177 | validation: 0.35360548408562553]
	TIME [epoch: 10.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38388865186079624		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.38388865186079624 | validation: 0.4945473385684133]
	TIME [epoch: 10.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4117543411911894		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.4117543411911894 | validation: 0.34422086205350283]
	TIME [epoch: 10.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4082638986164812		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.4082638986164812 | validation: 0.3248621940379576]
	TIME [epoch: 10.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5588191964826057		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.5588191964826057 | validation: 0.6258263283298148]
	TIME [epoch: 10.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4629467669105344		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.4629467669105344 | validation: 0.4896875360995061]
	TIME [epoch: 10.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5249610421329665		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.5249610421329665 | validation: 0.6576983846390705]
	TIME [epoch: 10.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5635240834334847		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.5635240834334847 | validation: 0.4598351442834152]
	TIME [epoch: 10.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46434252002685544		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.46434252002685544 | validation: 0.506911824608857]
	TIME [epoch: 10.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5170599977582863		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.5170599977582863 | validation: 0.41073957626178237]
	TIME [epoch: 10.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47857468826748323		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.47857468826748323 | validation: 0.4576967678791142]
	TIME [epoch: 10.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32171976899367905		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.32171976899367905 | validation: 0.3232200346516122]
	TIME [epoch: 10.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45585671021630453		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.45585671021630453 | validation: 0.7238040948448097]
	TIME [epoch: 10.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6088004064339846		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.6088004064339846 | validation: 0.513362533721306]
	TIME [epoch: 10.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42756471062881224		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.42756471062881224 | validation: 0.3774447929763567]
	TIME [epoch: 10.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31960799267330536		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.31960799267330536 | validation: 0.5818529467472139]
	TIME [epoch: 10.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5075102883177272		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.5075102883177272 | validation: 1.3691550263976882]
	TIME [epoch: 10.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8120107825900774		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.8120107825900774 | validation: 0.32802473148650124]
	TIME [epoch: 10.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34141313655831507		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.34141313655831507 | validation: 0.3082214894250424]
	TIME [epoch: 10.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33730772269711123		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.33730772269711123 | validation: 0.38093929148943523]
	TIME [epoch: 10.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35183584249986694		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.35183584249986694 | validation: 0.3738200447958713]
	TIME [epoch: 10.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124543542733985		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.5124543542733985 | validation: 0.6042418068786245]
	TIME [epoch: 10.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4333592110599671		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.4333592110599671 | validation: 0.34572271023619466]
	TIME [epoch: 10.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30456523957324855		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.30456523957324855 | validation: 0.29834954348489007]
	TIME [epoch: 10.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3263444684827502		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.3263444684827502 | validation: 0.9254053964760697]
	TIME [epoch: 10.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5022019377044542		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.5022019377044542 | validation: 0.3421247833305083]
	TIME [epoch: 10.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43021976821222924		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.43021976821222924 | validation: 0.40137174956362515]
	TIME [epoch: 10.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3388149950691176		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.3388149950691176 | validation: 0.36517261231964043]
	TIME [epoch: 10.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4890673647482561		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.4890673647482561 | validation: 0.32340986562568236]
	TIME [epoch: 10.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5809482548847832		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.5809482548847832 | validation: 1.0699401788622627]
	TIME [epoch: 10.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7891161742185304		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.7891161742185304 | validation: 0.3394995624467994]
	TIME [epoch: 10.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37471811714219194		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.37471811714219194 | validation: 0.9685964838772703]
	TIME [epoch: 10.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221116970621299		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.5221116970621299 | validation: 0.7523668835494265]
	TIME [epoch: 10.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119480768222671		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.4119480768222671 | validation: 0.27935007558388253]
	TIME [epoch: 10.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5596647957029554		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.5596647957029554 | validation: 0.2723774177587492]
	TIME [epoch: 10.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39495379458852586		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.39495379458852586 | validation: 0.29942847630895814]
	TIME [epoch: 10.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34721770389772233		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.34721770389772233 | validation: 0.4123038094256878]
	TIME [epoch: 10.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599170240863252		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.5599170240863252 | validation: 0.30230014817221473]
	TIME [epoch: 10.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35197671831513655		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.35197671831513655 | validation: 0.4703178031503798]
	TIME [epoch: 10.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5078165267100448		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.5078165267100448 | validation: 0.330423567721466]
	TIME [epoch: 10.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3740805261174221		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.3740805261174221 | validation: 0.39304952468329357]
	TIME [epoch: 10.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3899963087134171		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.3899963087134171 | validation: 0.9672808490952085]
	TIME [epoch: 10.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.575801450930413		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.575801450930413 | validation: 0.30922631460302025]
	TIME [epoch: 10.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40002215883126385		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.40002215883126385 | validation: 0.44452204843038773]
	TIME [epoch: 10.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37797303058731185		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.37797303058731185 | validation: 0.5060832387018316]
	TIME [epoch: 10.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5501084477825634		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.5501084477825634 | validation: 0.8828266055149854]
	TIME [epoch: 10.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6135225495050023		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.6135225495050023 | validation: 0.3263649869342361]
	TIME [epoch: 10.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.407335187511859		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.407335187511859 | validation: 0.43406181762223206]
	TIME [epoch: 10.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35598845339399754		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.35598845339399754 | validation: 0.3463908417081542]
	TIME [epoch: 10.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4043282018215619		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.4043282018215619 | validation: 0.5319482544879981]
	TIME [epoch: 10.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36099787655778265		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.36099787655778265 | validation: 0.6951991619314905]
	TIME [epoch: 10.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.488330422202744		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.488330422202744 | validation: 0.42714851590819763]
	TIME [epoch: 10.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47030322640084316		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.47030322640084316 | validation: 0.4280349532669719]
	TIME [epoch: 10.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35024990200122297		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.35024990200122297 | validation: 0.4719667504957868]
	TIME [epoch: 10.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48162315752826945		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.48162315752826945 | validation: 0.48428443614844613]
	TIME [epoch: 10.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6569362150121838		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.6569362150121838 | validation: 0.41780517623275304]
	TIME [epoch: 10.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3886277332098501		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.3886277332098501 | validation: 0.5469351357744395]
	TIME [epoch: 10.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5115959661570662		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.5115959661570662 | validation: 2.1144920608748716]
	TIME [epoch: 10.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6150830804827017		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 3.6150830804827017 | validation: 3.016671737455709]
	TIME [epoch: 10.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6567155509964855		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 2.6567155509964855 | validation: 1.0665280964778803]
	TIME [epoch: 10.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5983519163915323		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.5983519163915323 | validation: 0.4125315678547958]
	TIME [epoch: 10.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32525718993027813		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.32525718993027813 | validation: 0.2851993292494674]
	TIME [epoch: 10.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4742102044209445		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.4742102044209445 | validation: 0.5433520027110252]
	TIME [epoch: 10.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.446601224424259		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.446601224424259 | validation: 0.35894505246694475]
	TIME [epoch: 10.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4042641836657487		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.4042641836657487 | validation: 0.3748490461607273]
	TIME [epoch: 10.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35313963433957135		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.35313963433957135 | validation: 0.32011263820091446]
	TIME [epoch: 10.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7325048532746091		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.7325048532746091 | validation: 0.5149091345949212]
	TIME [epoch: 10.3 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45932394167269547		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.45932394167269547 | validation: 0.29648107914138805]
	TIME [epoch: 10.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35433706603212245		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.35433706603212245 | validation: 0.4573567699532054]
	TIME [epoch: 10.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39381338717590497		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.39381338717590497 | validation: 0.9247128416121734]
	TIME [epoch: 10.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5252958512671941		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.5252958512671941 | validation: 0.377532413448826]
	TIME [epoch: 10.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45075928358810585		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.45075928358810585 | validation: 0.3401260964335453]
	TIME [epoch: 10.3 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4018188184463348		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.4018188184463348 | validation: 0.36977968009394024]
	TIME [epoch: 10.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3697047025232022		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.3697047025232022 | validation: 0.33911781532783913]
	TIME [epoch: 10.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3589057498891281		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.3589057498891281 | validation: 0.863093944259027]
	TIME [epoch: 10.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4991257751368135		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.4991257751368135 | validation: 0.3320641692905329]
	TIME [epoch: 10.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4930321542144833		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.4930321542144833 | validation: 0.5356931315914427]
	TIME [epoch: 10.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4523007170702483		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.4523007170702483 | validation: 0.340210872620339]
	TIME [epoch: 10.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40038528252427563		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.40038528252427563 | validation: 0.4397002829262808]
	TIME [epoch: 10.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3920516827274676		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.3920516827274676 | validation: 0.35797473005693503]
	TIME [epoch: 10.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34439632512028606		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.34439632512028606 | validation: 0.39598533969029953]
	TIME [epoch: 10.3 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162282042957166		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.4162282042957166 | validation: 0.3338892436721714]
	TIME [epoch: 10.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4327608814325418		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.4327608814325418 | validation: 0.4538952919888287]
	TIME [epoch: 10.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402318362869316		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.5402318362869316 | validation: 0.3929727653833423]
	TIME [epoch: 10.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3979996176454782		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.3979996176454782 | validation: 0.32092823295243905]
	TIME [epoch: 10.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4346307320781653		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.4346307320781653 | validation: 1.6370956530358514]
	TIME [epoch: 10.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8447932427314073		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.8447932427314073 | validation: 0.5669222897254802]
	TIME [epoch: 10.3 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5601497303624209		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.5601497303624209 | validation: 0.8028499379678783]
	TIME [epoch: 10.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49308663193376717		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.49308663193376717 | validation: 0.38252827392222283]
	TIME [epoch: 10.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35095980698114737		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.35095980698114737 | validation: 0.4049659563376652]
	TIME [epoch: 10.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187647693253261		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.5187647693253261 | validation: 0.4689583973923108]
	TIME [epoch: 10.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7084339999798633		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.7084339999798633 | validation: 0.8644079752009544]
	TIME [epoch: 10.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212082506561453		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.5212082506561453 | validation: 0.3751181078170795]
	TIME [epoch: 10.3 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3480651108225484		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.3480651108225484 | validation: 0.29960591619089616]
	TIME [epoch: 10.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411649455733448		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.5411649455733448 | validation: 0.4465009882994262]
	TIME [epoch: 10.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42485527517986377		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.42485527517986377 | validation: 0.456593293328413]
	TIME [epoch: 10.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4588264779099034		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.4588264779099034 | validation: 0.40836966366935246]
	TIME [epoch: 10.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151289221001857		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.4151289221001857 | validation: 0.5863210188767009]
	TIME [epoch: 10.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4781077213137748		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.4781077213137748 | validation: 0.5658494811407083]
	TIME [epoch: 10.3 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44403615981226563		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.44403615981226563 | validation: 0.35430787211278486]
	TIME [epoch: 10.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6846686163923053		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.6846686163923053 | validation: 0.33717527569703154]
	TIME [epoch: 10.3 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29796317873317324		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.29796317873317324 | validation: 0.34870692623096006]
	TIME [epoch: 10.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6243985049278449		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.6243985049278449 | validation: 0.3157469289358942]
	TIME [epoch: 10.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4244367747591899		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.4244367747591899 | validation: 0.8057099322951892]
	TIME [epoch: 10.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156139365261568		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.5156139365261568 | validation: 0.4161782340828387]
	TIME [epoch: 10.3 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33502455779711776		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.33502455779711776 | validation: 0.6972821628048083]
	TIME [epoch: 10.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5605074628654432		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.5605074628654432 | validation: 0.4497961930941998]
	TIME [epoch: 10.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4970672636440555		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.4970672636440555 | validation: 0.3558982537253384]
	TIME [epoch: 10.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4085469682493934		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.4085469682493934 | validation: 0.3985590413357268]
	TIME [epoch: 10.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3772489564726437		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.3772489564726437 | validation: 0.2681164088771791]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39566417025707024		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.39566417025707024 | validation: 0.49034970311057197]
	TIME [epoch: 10.3 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45604129913431557		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.45604129913431557 | validation: 0.8213595043035917]
	TIME [epoch: 10.3 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5805938818138873		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.5805938818138873 | validation: 0.9517500861873134]
	TIME [epoch: 10.3 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610085750617013		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.5610085750617013 | validation: 0.2795785073760077]
	TIME [epoch: 10.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35533942934922136		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.35533942934922136 | validation: 0.33167622138718567]
	TIME [epoch: 10.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31631569916084296		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.31631569916084296 | validation: 0.6709722488884705]
	TIME [epoch: 10.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177453744789938		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.4177453744789938 | validation: 0.4283012612692497]
	TIME [epoch: 10.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33061284249606443		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.33061284249606443 | validation: 0.316975400958235]
	TIME [epoch: 10.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5144394812741682		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.5144394812741682 | validation: 0.366724726614772]
	TIME [epoch: 10.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47284406831433523		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.47284406831433523 | validation: 0.5976884210680392]
	TIME [epoch: 10.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45225036851792016		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.45225036851792016 | validation: 0.509903519079043]
	TIME [epoch: 10.3 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5297413774393386		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.5297413774393386 | validation: 0.2918070496388277]
	TIME [epoch: 10.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41359106190298645		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.41359106190298645 | validation: 0.26986185632426657]
	TIME [epoch: 10.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41698240503349826		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.41698240503349826 | validation: 0.3813287640197804]
	TIME [epoch: 10.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34821875414328307		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.34821875414328307 | validation: 0.4454243192062796]
	TIME [epoch: 10.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.415743259173476		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.415743259173476 | validation: 0.40394339605017054]
	TIME [epoch: 10.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46327333999975584		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.46327333999975584 | validation: 0.5441258595152266]
	TIME [epoch: 10.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5207425597351655		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.5207425597351655 | validation: 0.5869798086389252]
	TIME [epoch: 10.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5364121379505778		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.5364121379505778 | validation: 0.4895778834270171]
	TIME [epoch: 10.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42418432176196375		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.42418432176196375 | validation: 0.5514871407206637]
	TIME [epoch: 10.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4231195227772531		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.4231195227772531 | validation: 0.4247555791347237]
	TIME [epoch: 10.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38435885296333266		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.38435885296333266 | validation: 0.3525682876526285]
	TIME [epoch: 10.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3729745392448208		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.3729745392448208 | validation: 0.3613167074298872]
	TIME [epoch: 10.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32743149713579056		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.32743149713579056 | validation: 0.2777386331792159]
	TIME [epoch: 10.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6467877870040762		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.6467877870040762 | validation: 0.3294703845078697]
	TIME [epoch: 10.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3454487163597883		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.3454487163597883 | validation: 0.3049298611059655]
	TIME [epoch: 10.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4618215161792392		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.4618215161792392 | validation: 0.31253901522981703]
	TIME [epoch: 10.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32212525274646436		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.32212525274646436 | validation: 0.4036808231278153]
	TIME [epoch: 10.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3555164240479011		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.3555164240479011 | validation: 0.4620272233853984]
	TIME [epoch: 10.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0116347453320587		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 1.0116347453320587 | validation: 0.35001846519429025]
	TIME [epoch: 10.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040386391412022		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.3040386391412022 | validation: 0.3313783974694155]
	TIME [epoch: 10.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5855203278421894		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.5855203278421894 | validation: 0.3924926044092121]
	TIME [epoch: 10.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31779202342754137		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.31779202342754137 | validation: 0.33959477553523676]
	TIME [epoch: 10.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3519461083528408		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.3519461083528408 | validation: 0.3317071192335602]
	TIME [epoch: 10.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4351751750875928		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.4351751750875928 | validation: 0.3146390835010719]
	TIME [epoch: 10.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3065833492610624		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.3065833492610624 | validation: 0.280054087167284]
	TIME [epoch: 10.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4146896387035823		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.4146896387035823 | validation: 0.43645218183698364]
	TIME [epoch: 10.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4052296123933184		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.4052296123933184 | validation: 0.28551909699505373]
	TIME [epoch: 10.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626126016128895		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.3626126016128895 | validation: 0.3275581784703133]
	TIME [epoch: 10.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28638169611163056		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.28638169611163056 | validation: 0.3236857581138963]
	TIME [epoch: 10.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30349859207953955		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.30349859207953955 | validation: 0.2646605261207273]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119575891697392		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.4119575891697392 | validation: 0.2979367977393975]
	TIME [epoch: 10.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43581761090890875		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.43581761090890875 | validation: 1.0021575305177433]
	TIME [epoch: 10.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7801282936678141		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.7801282936678141 | validation: 0.3235658542547135]
	TIME [epoch: 10.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39435765772961845		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.39435765772961845 | validation: 0.5129991551873324]
	TIME [epoch: 10.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280312806833088		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.5280312806833088 | validation: 0.3937280919376168]
	TIME [epoch: 10.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3619427193392134		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.3619427193392134 | validation: 0.2868173056362192]
	TIME [epoch: 10.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28872488660017137		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.28872488660017137 | validation: 0.2961191732707757]
	TIME [epoch: 10.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33097640651196286		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.33097640651196286 | validation: 0.29196121265308533]
	TIME [epoch: 10.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5664870603913406		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.5664870603913406 | validation: 0.33751781251652674]
	TIME [epoch: 10.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29085192610982924		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.29085192610982924 | validation: 0.3966817027284497]
	TIME [epoch: 10.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.370425949659172		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.370425949659172 | validation: 0.3337219413449911]
	TIME [epoch: 10.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2812013245308268		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.2812013245308268 | validation: 0.8987763818289526]
	TIME [epoch: 10.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7146225192641662		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.7146225192641662 | validation: 0.2752715532037691]
	TIME [epoch: 10.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35353333993309655		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.35353333993309655 | validation: 0.29760660487432006]
	TIME [epoch: 10.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799294165082318		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.2799294165082318 | validation: 0.3476020163628415]
	TIME [epoch: 10.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34391912452500534		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.34391912452500534 | validation: 0.30330501520359776]
	TIME [epoch: 10.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3826850653777211		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.3826850653777211 | validation: 0.5664779591787029]
	TIME [epoch: 10.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391711616256808		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.5391711616256808 | validation: 0.3169694694643946]
	TIME [epoch: 10.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2971838535939207		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.2971838535939207 | validation: 0.3011687221781071]
	TIME [epoch: 10.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.517432980216493		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.517432980216493 | validation: 0.30425259796275356]
	TIME [epoch: 10.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26843872240806055		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.26843872240806055 | validation: 0.3299706238797765]
	TIME [epoch: 10.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48966624665935177		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.48966624665935177 | validation: 0.3805496671808939]
	TIME [epoch: 10.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34788696216553583		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.34788696216553583 | validation: 0.27423674323714514]
	TIME [epoch: 10.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24058870027399942		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.24058870027399942 | validation: 0.5323598091682982]
	TIME [epoch: 10.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42650329916227336		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.42650329916227336 | validation: 0.2344555766792275]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_987.pth
	Model improved!!!
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23511164049393102		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.23511164049393102 | validation: 0.3855263540273508]
	TIME [epoch: 10.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3898774344386008		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.3898774344386008 | validation: 0.36327782474594345]
	TIME [epoch: 10.3 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46643435768203456		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.46643435768203456 | validation: 0.38479837660312416]
	TIME [epoch: 10.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3724131953040131		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.3724131953040131 | validation: 0.425747661512306]
	TIME [epoch: 10.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39510526670653245		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.39510526670653245 | validation: 0.5650600479169259]
	TIME [epoch: 10.3 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36990738773747867		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.36990738773747867 | validation: 0.3204503649339596]
	TIME [epoch: 10.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2715005423828646		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.2715005423828646 | validation: 0.2909405819329547]
	TIME [epoch: 10.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3722232213097911		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.3722232213097911 | validation: 0.3655187974894475]
	TIME [epoch: 10.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5024922659097909		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.5024922659097909 | validation: 0.37150809035878996]
	TIME [epoch: 10.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43860975518933615		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.43860975518933615 | validation: 0.5433337372407704]
	TIME [epoch: 10.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.366252030397433		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.366252030397433 | validation: 0.421180504462541]
	TIME [epoch: 10.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4622699156911759		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.4622699156911759 | validation: 0.35714795466271937]
	TIME [epoch: 10.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5860801915025868		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.5860801915025868 | validation: 0.5021116871272174]
	TIME [epoch: 10.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38389792419601604		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.38389792419601604 | validation: 0.3600688147054833]
	TIME [epoch: 10.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32051630219487753		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.32051630219487753 | validation: 0.2350567675228458]
	TIME [epoch: 10.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33640143722330657		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.33640143722330657 | validation: 0.27412090814262363]
	TIME [epoch: 10.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2832456740479613		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.2832456740479613 | validation: 0.3669257965762074]
	TIME [epoch: 10.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7220712719996284		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.7220712719996284 | validation: 0.3441144686376563]
	TIME [epoch: 10.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36752890484003964		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.36752890484003964 | validation: 0.36751159476526696]
	TIME [epoch: 10.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432102922183127		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.3432102922183127 | validation: 0.29631837320143994]
	TIME [epoch: 10.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29184523751964503		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.29184523751964503 | validation: 0.41216022855079404]
	TIME [epoch: 10.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30711427317919704		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.30711427317919704 | validation: 0.24901422192157555]
	TIME [epoch: 10.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31159858512269056		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.31159858512269056 | validation: 0.4332088828003333]
	TIME [epoch: 10.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6026811099461343		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.6026811099461343 | validation: 0.36155580786778907]
	TIME [epoch: 10.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3939417136900052		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.3939417136900052 | validation: 0.4751875101994558]
	TIME [epoch: 10.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339944524075444		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.6339944524075444 | validation: 0.40525644083978263]
	TIME [epoch: 10.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3281832333438885		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.3281832333438885 | validation: 0.30700571827444856]
	TIME [epoch: 10.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4091118919610709		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.4091118919610709 | validation: 0.566489093658382]
	TIME [epoch: 10.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107826477341017		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.3107826477341017 | validation: 0.36307670119914265]
	TIME [epoch: 10.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29173952661659125		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.29173952661659125 | validation: 0.47216284428020944]
	TIME [epoch: 10.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5370127751807064		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.5370127751807064 | validation: 0.2528047033201124]
	TIME [epoch: 10.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26888709669669997		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.26888709669669997 | validation: 0.48088716712493534]
	TIME [epoch: 10.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3822709246315744		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.3822709246315744 | validation: 0.28904883476643894]
	TIME [epoch: 10.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2964589276010777		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.2964589276010777 | validation: 0.6734794541028274]
	TIME [epoch: 10.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.455117038839062		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.455117038839062 | validation: 0.2754576253854959]
	TIME [epoch: 10.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40197876694496404		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.40197876694496404 | validation: 0.5480252222480511]
	TIME [epoch: 10.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4658502678160314		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.4658502678160314 | validation: 0.5223468671097863]
	TIME [epoch: 10.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3867854351581556		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.3867854351581556 | validation: 0.2802208246855886]
	TIME [epoch: 10.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4241357217262137		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.4241357217262137 | validation: 0.2587665468635552]
	TIME [epoch: 10.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35656810100078723		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.35656810100078723 | validation: 0.3443226456745711]
	TIME [epoch: 10.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32601047760489915		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.32601047760489915 | validation: 0.31368795381951464]
	TIME [epoch: 10.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058760412191558		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.3058760412191558 | validation: 0.3565633554604425]
	TIME [epoch: 10.3 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29346077294315626		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.29346077294315626 | validation: 0.3457493266027397]
	TIME [epoch: 10.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32276989347529295		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.32276989347529295 | validation: 0.23708345934610175]
	TIME [epoch: 10.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35491984901610546		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.35491984901610546 | validation: 0.3208197610128126]
	TIME [epoch: 10.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2864801228163189		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.2864801228163189 | validation: 0.4649254957166404]
	TIME [epoch: 10.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5419994157421564		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.5419994157421564 | validation: 0.2730186454601499]
	TIME [epoch: 10.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30080302681244575		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.30080302681244575 | validation: 0.33617444703]
	TIME [epoch: 10.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3330205598314341		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.3330205598314341 | validation: 0.29186235125750243]
	TIME [epoch: 10.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33988593557221874		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.33988593557221874 | validation: 0.3559038625706731]
	TIME [epoch: 10.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35801036658412		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.35801036658412 | validation: 0.2944721199178784]
	TIME [epoch: 10.3 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5081387251784153		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.5081387251784153 | validation: 0.28114211895590485]
	TIME [epoch: 10.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6364309792284283		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.6364309792284283 | validation: 0.46106678617704233]
	TIME [epoch: 10.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35561407289542635		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.35561407289542635 | validation: 0.4925831340893382]
	TIME [epoch: 10.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3602348726608505		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.3602348726608505 | validation: 0.2954514031213736]
	TIME [epoch: 10.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28972497095847916		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.28972497095847916 | validation: 0.32531508582978463]
	TIME [epoch: 10.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28124977000627205		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.28124977000627205 | validation: 0.6968017861174427]
	TIME [epoch: 10.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970038478270658		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.3970038478270658 | validation: 0.2939476839464599]
	TIME [epoch: 10.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6367666105889385		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.6367666105889385 | validation: 0.2856786334092712]
	TIME [epoch: 10.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29899143907639336		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.29899143907639336 | validation: 0.2758947725236614]
	TIME [epoch: 10.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.382083922872999		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.382083922872999 | validation: 0.4391104250801024]
	TIME [epoch: 10.3 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.366527288337145		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.366527288337145 | validation: 0.29748096698298315]
	TIME [epoch: 10.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28807630249817917		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.28807630249817917 | validation: 0.2814696281311323]
	TIME [epoch: 10.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40936170804190253		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.40936170804190253 | validation: 0.2333564571073352]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1051.pth
	Model improved!!!
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2846049840876774		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.2846049840876774 | validation: 0.32137107228109657]
	TIME [epoch: 10.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3350007222628488		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.3350007222628488 | validation: 0.5186336595953905]
	TIME [epoch: 10.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37501847168055635		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.37501847168055635 | validation: 0.31508019807318033]
	TIME [epoch: 10.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42436565454984904		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.42436565454984904 | validation: 0.3178770368891703]
	TIME [epoch: 10.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2731519564217286		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.2731519564217286 | validation: 0.37954801457059734]
	TIME [epoch: 10.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30404303337915917		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.30404303337915917 | validation: 0.30512319932623283]
	TIME [epoch: 10.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31907155196953785		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.31907155196953785 | validation: 0.36714066622895064]
	TIME [epoch: 10.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33752219641734704		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.33752219641734704 | validation: 0.3254434681875302]
	TIME [epoch: 10.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26684112266448157		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.26684112266448157 | validation: 0.2686441503389815]
	TIME [epoch: 10.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719495228608581		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.2719495228608581 | validation: 0.3439745910073822]
	TIME [epoch: 10.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28735139878133814		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.28735139878133814 | validation: 0.3053191389009172]
	TIME [epoch: 10.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34854998325840236		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.34854998325840236 | validation: 0.41737238477553074]
	TIME [epoch: 10.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27349212383805355		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.27349212383805355 | validation: 0.3099658458038537]
	TIME [epoch: 10.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33579789635540963		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.33579789635540963 | validation: 0.381519768232603]
	TIME [epoch: 10.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26727506468399254		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.26727506468399254 | validation: 0.24987467707732663]
	TIME [epoch: 10.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35290562366053935		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.35290562366053935 | validation: 0.3603007762701261]
	TIME [epoch: 10.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3661614434985696		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.3661614434985696 | validation: 0.28346871455261063]
	TIME [epoch: 10.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37296525504224237		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.37296525504224237 | validation: 0.2577423003217584]
	TIME [epoch: 10.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3628157476933815		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.3628157476933815 | validation: 0.48205739740495523]
	TIME [epoch: 10.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3689429636891538		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.3689429636891538 | validation: 0.31781639254921806]
	TIME [epoch: 10.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22697912261913053		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.22697912261913053 | validation: 0.38590547144910753]
	TIME [epoch: 10.3 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3489181300036398		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.3489181300036398 | validation: 0.3141272756409938]
	TIME [epoch: 10.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39242030719016957		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.39242030719016957 | validation: 0.3003228451896998]
	TIME [epoch: 10.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43378845780088815		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.43378845780088815 | validation: 0.4727276537340616]
	TIME [epoch: 10.3 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29452152275279764		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.29452152275279764 | validation: 0.27398155808463875]
	TIME [epoch: 10.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3113828893380235		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.3113828893380235 | validation: 0.39125537631584983]
	TIME [epoch: 10.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3014815736620081		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.3014815736620081 | validation: 0.2908040948655218]
	TIME [epoch: 10.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3837061521916878		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.3837061521916878 | validation: 0.2408525841919338]
	TIME [epoch: 10.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27576446691748774		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.27576446691748774 | validation: 0.29946868085576694]
	TIME [epoch: 10.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609932316928592		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.2609932316928592 | validation: 0.45842010355791085]
	TIME [epoch: 10.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47593199693334753		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.47593199693334753 | validation: 0.2786433976966046]
	TIME [epoch: 10.3 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29470965239653735		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.29470965239653735 | validation: 0.26692324888202046]
	TIME [epoch: 10.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28757688090347655		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.28757688090347655 | validation: 0.27626552941107996]
	TIME [epoch: 10.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4003805273471327		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.4003805273471327 | validation: 0.6459943241966792]
	TIME [epoch: 10.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40410317370913906		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.40410317370913906 | validation: 0.30646071298867256]
	TIME [epoch: 10.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2522743562922252		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.2522743562922252 | validation: 0.28329946012891005]
	TIME [epoch: 10.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2983031731590888		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.2983031731590888 | validation: 0.4421175038036013]
	TIME [epoch: 10.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27881710330305703		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.27881710330305703 | validation: 0.3355307554774287]
	TIME [epoch: 10.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2771457292429701		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.2771457292429701 | validation: 0.24702955064678123]
	TIME [epoch: 10.3 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28524065982027574		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.28524065982027574 | validation: 0.3335802520219937]
	TIME [epoch: 10.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3072257963232218		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.3072257963232218 | validation: 0.22272789169715293]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1092.pth
	Model improved!!!
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3920480929639994		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.3920480929639994 | validation: 0.25081896597074876]
	TIME [epoch: 10.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32478037761889267		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.32478037761889267 | validation: 0.363268019504144]
	TIME [epoch: 10.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26933113499551187		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.26933113499551187 | validation: 0.29451622304351843]
	TIME [epoch: 10.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2577438872574995		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.2577438872574995 | validation: 0.32035998478397104]
	TIME [epoch: 10.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28385070565146997		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.28385070565146997 | validation: 0.33393835017623785]
	TIME [epoch: 10.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31118106237969473		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.31118106237969473 | validation: 0.2798885443217205]
	TIME [epoch: 10.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37176557292248724		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.37176557292248724 | validation: 0.6051207423731784]
	TIME [epoch: 10.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3296542117449474		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.3296542117449474 | validation: 0.2345824885231583]
	TIME [epoch: 10.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.333106039403486		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.333106039403486 | validation: 0.27119839437176774]
	TIME [epoch: 10.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29184867783013735		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.29184867783013735 | validation: 0.32470254211750765]
	TIME [epoch: 10.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2834189865637312		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.2834189865637312 | validation: 0.27216330992376575]
	TIME [epoch: 10.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3161242354051978		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.3161242354051978 | validation: 0.26917116803896524]
	TIME [epoch: 10.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875765846452017		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.2875765846452017 | validation: 0.34632185028025825]
	TIME [epoch: 10.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734584155941796		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.2734584155941796 | validation: 0.32660603279585815]
	TIME [epoch: 10.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332392292414008		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.332392292414008 | validation: 0.28567442591838865]
	TIME [epoch: 10.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26956878731652056		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.26956878731652056 | validation: 0.2973833624586561]
	TIME [epoch: 10.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23919172467661304		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.23919172467661304 | validation: 0.2522566779797545]
	TIME [epoch: 10.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44676187546091894		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.44676187546091894 | validation: 0.7897979936811725]
	TIME [epoch: 10.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4957007479442085		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.4957007479442085 | validation: 0.3308123596218136]
	TIME [epoch: 10.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515698068722697		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.2515698068722697 | validation: 0.25895601569207105]
	TIME [epoch: 10.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24426346215671813		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.24426346215671813 | validation: 0.31047528246781675]
	TIME [epoch: 10.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008613848198887		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.3008613848198887 | validation: 0.3730044292582059]
	TIME [epoch: 10.3 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674417192642487		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.2674417192642487 | validation: 0.2639284441301627]
	TIME [epoch: 10.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961174368421683		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.2961174368421683 | validation: 0.2892436858252842]
	TIME [epoch: 10.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2614368600421929		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.2614368600421929 | validation: 0.5389730067137241]
	TIME [epoch: 10.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37574775538823263		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.37574775538823263 | validation: 0.30515193145174113]
	TIME [epoch: 10.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4064147695327082		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.4064147695327082 | validation: 0.2511143851360728]
	TIME [epoch: 10.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3481841028692301		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.3481841028692301 | validation: 0.41113477707105744]
	TIME [epoch: 10.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30755676674746935		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.30755676674746935 | validation: 0.267951636285787]
	TIME [epoch: 10.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2509451182558877		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.2509451182558877 | validation: 0.24805512843441008]
	TIME [epoch: 10.3 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27977563546012946		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.27977563546012946 | validation: 0.2912241919119007]
	TIME [epoch: 10.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4807864118271515		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.4807864118271515 | validation: 0.5968234484455607]
	TIME [epoch: 10.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33457201156262334		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.33457201156262334 | validation: 0.28497744690989013]
	TIME [epoch: 10.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23428582719851074		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.23428582719851074 | validation: 0.25357874044178724]
	TIME [epoch: 10.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2816635771336003		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.2816635771336003 | validation: 0.2744113840377984]
	TIME [epoch: 10.3 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3178510992967021		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.3178510992967021 | validation: 0.33608068646262423]
	TIME [epoch: 10.3 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28788818860539706		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.28788818860539706 | validation: 0.2748326686389721]
	TIME [epoch: 10.3 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38051253014845465		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.38051253014845465 | validation: 1.11860121808009]
	TIME [epoch: 10.3 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7027008467410256		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.7027008467410256 | validation: 0.336909046992634]
	TIME [epoch: 10.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2924998972211176		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.2924998972211176 | validation: 0.3052556800481086]
	TIME [epoch: 10.3 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42035624004405336		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.42035624004405336 | validation: 0.25571664446638287]
	TIME [epoch: 10.3 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25569756725110077		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.25569756725110077 | validation: 0.3792808401457624]
	TIME [epoch: 10.3 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2843011894597945		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.2843011894597945 | validation: 0.23089477796626978]
	TIME [epoch: 10.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2359967047330652		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.2359967047330652 | validation: 0.3093311874900846]
	TIME [epoch: 10.3 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23658018234846528		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.23658018234846528 | validation: 0.2748673420234536]
	TIME [epoch: 10.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24652878176149945		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.24652878176149945 | validation: 0.2807159507749124]
	TIME [epoch: 10.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2355409434502224		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.2355409434502224 | validation: 0.44530253297486694]
	TIME [epoch: 10.3 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3884523165777489		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.3884523165777489 | validation: 0.2835111174945264]
	TIME [epoch: 10.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21313975253642198		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.21313975253642198 | validation: 0.36050914110836785]
	TIME [epoch: 10.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2750962529266649		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.2750962529266649 | validation: 0.356946730337215]
	TIME [epoch: 10.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28041744961291887		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.28041744961291887 | validation: 0.262901476159819]
	TIME [epoch: 10.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21790419012664874		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.21790419012664874 | validation: 0.4150016235838595]
	TIME [epoch: 10.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4273223718203534		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.4273223718203534 | validation: 0.6521844166663041]
	TIME [epoch: 10.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3961821615946759		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.3961821615946759 | validation: 0.46515725680733233]
	TIME [epoch: 10.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.486113837640976		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.486113837640976 | validation: 0.34754859833893437]
	TIME [epoch: 10.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2927512342531934		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.2927512342531934 | validation: 0.2542301188037584]
	TIME [epoch: 10.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2166551110711529		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.2166551110711529 | validation: 0.28802604844033725]
	TIME [epoch: 10.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25920091239597404		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.25920091239597404 | validation: 0.34622167322450753]
	TIME [epoch: 10.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30047080149865935		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.30047080149865935 | validation: 0.512676458981375]
	TIME [epoch: 10.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4214199818732013		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.4214199818732013 | validation: 0.257365245437048]
	TIME [epoch: 10.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31989137147102104		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.31989137147102104 | validation: 0.2472669241114486]
	TIME [epoch: 10.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2546000798537594		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.2546000798537594 | validation: 0.27871047794859294]
	TIME [epoch: 10.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42556697735660143		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.42556697735660143 | validation: 0.24594777321450628]
	TIME [epoch: 10.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2795109524550032		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.2795109524550032 | validation: 0.23748426203692133]
	TIME [epoch: 10.3 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22449822350101217		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.22449822350101217 | validation: 0.31221593981992407]
	TIME [epoch: 10.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28537184504383734		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.28537184504383734 | validation: 0.4400987424061728]
	TIME [epoch: 10.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5760848264919723		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.5760848264919723 | validation: 0.3052744817659637]
	TIME [epoch: 10.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29451994507623414		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.29451994507623414 | validation: 0.47870926305803696]
	TIME [epoch: 10.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34842655837887254		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.34842655837887254 | validation: 0.27543202216145307]
	TIME [epoch: 10.3 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507321277683586		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.2507321277683586 | validation: 0.4659796768377334]
	TIME [epoch: 10.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4864539243813977		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.4864539243813977 | validation: 0.4005142112238569]
	TIME [epoch: 10.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32354275272503485		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.32354275272503485 | validation: 0.3196456746430699]
	TIME [epoch: 10.3 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2393534389521145		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.2393534389521145 | validation: 0.23343897651061682]
	TIME [epoch: 10.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2494206249233526		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.2494206249233526 | validation: 0.45884242384601]
	TIME [epoch: 10.3 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3255964253955371		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.3255964253955371 | validation: 0.71201345945039]
	TIME [epoch: 10.3 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4594455027707126		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.4594455027707126 | validation: 0.2640383322778046]
	TIME [epoch: 10.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.273789144308516		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.273789144308516 | validation: 0.3966421501979731]
	TIME [epoch: 10.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2668903901050712		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.2668903901050712 | validation: 0.3938849333885787]
	TIME [epoch: 10.3 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28051460612717893		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.28051460612717893 | validation: 0.34334186945314843]
	TIME [epoch: 10.3 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3277523143029405		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.3277523143029405 | validation: 0.27688800234210087]
	TIME [epoch: 10.3 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710555577486743		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.2710555577486743 | validation: 0.2550923976271959]
	TIME [epoch: 10.3 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2880088229316276		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.2880088229316276 | validation: 0.26045210639878]
	TIME [epoch: 10.3 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23635271860555807		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.23635271860555807 | validation: 0.2784675906965287]
	TIME [epoch: 10.3 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28266482243494356		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.28266482243494356 | validation: 0.23663826547593253]
	TIME [epoch: 10.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2828065894339136		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.2828065894339136 | validation: 0.3262755670621754]
	TIME [epoch: 10.3 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4089193039269713		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.4089193039269713 | validation: 0.5366467223207046]
	TIME [epoch: 10.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31199954762602633		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.31199954762602633 | validation: 0.3328644921815971]
	TIME [epoch: 10.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33462031452562524		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.33462031452562524 | validation: 0.23125795246058067]
	TIME [epoch: 10.3 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30453468716182724		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.30453468716182724 | validation: 0.3056204963579712]
	TIME [epoch: 10.3 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31368325114245355		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.31368325114245355 | validation: 0.3826939868637713]
	TIME [epoch: 10.3 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25882123035607363		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.25882123035607363 | validation: 0.2366286642620612]
	TIME [epoch: 10.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2140955239840411		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.2140955239840411 | validation: 0.24336607504632937]
	TIME [epoch: 10.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2545341054107429		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.2545341054107429 | validation: 0.2741494130384189]
	TIME [epoch: 10.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3239906263372757		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.3239906263372757 | validation: 0.2356364115743207]
	TIME [epoch: 10.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25873473066120295		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.25873473066120295 | validation: 0.22222229540189908]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1187.pth
	Model improved!!!
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.258004959613326		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.258004959613326 | validation: 0.26323906388210344]
	TIME [epoch: 10.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2200990716659758		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.2200990716659758 | validation: 0.40298992007840884]
	TIME [epoch: 10.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.271237602692628		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.271237602692628 | validation: 0.2693924465179138]
	TIME [epoch: 10.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22921005460458801		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.22921005460458801 | validation: 0.22729907087095855]
	TIME [epoch: 10.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2517117501924566		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.2517117501924566 | validation: 0.3443376825096249]
	TIME [epoch: 10.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24540297943792838		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.24540297943792838 | validation: 0.23639769366181962]
	TIME [epoch: 10.3 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26363582102495897		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.26363582102495897 | validation: 0.2864076571480351]
	TIME [epoch: 10.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23622402549350907		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.23622402549350907 | validation: 0.23678587672387572]
	TIME [epoch: 10.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2298221485919107		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.2298221485919107 | validation: 0.2345477668594791]
	TIME [epoch: 10.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23784891339024233		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.23784891339024233 | validation: 0.33003362390458946]
	TIME [epoch: 10.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30822610052847016		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.30822610052847016 | validation: 0.2637773052453173]
	TIME [epoch: 10.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30127619053331467		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.30127619053331467 | validation: 0.42112183255081825]
	TIME [epoch: 10.3 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31601991535856583		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.31601991535856583 | validation: 0.3323457850464672]
	TIME [epoch: 10.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2896930045151168		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.2896930045151168 | validation: 0.22474393378426186]
	TIME [epoch: 10.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33525904974722387		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.33525904974722387 | validation: 0.4476393598334588]
	TIME [epoch: 10.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2842402957876605		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.2842402957876605 | validation: 0.28874269205582437]
	TIME [epoch: 10.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2640011158740924		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.2640011158740924 | validation: 0.41130874415465896]
	TIME [epoch: 10.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26405149891277924		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.26405149891277924 | validation: 0.287904564877369]
	TIME [epoch: 10.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2357872952277175		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.2357872952277175 | validation: 0.27515596400928255]
	TIME [epoch: 10.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2649407716319866		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.2649407716319866 | validation: 0.2703880121799869]
	TIME [epoch: 10.3 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23444082236842947		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.23444082236842947 | validation: 0.24660454795612285]
	TIME [epoch: 10.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31606833234959575		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.31606833234959575 | validation: 0.29156987387514743]
	TIME [epoch: 10.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27997020558416763		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.27997020558416763 | validation: 0.24879810099757116]
	TIME [epoch: 10.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2552317719909897		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.2552317719909897 | validation: 0.2581381660076931]
	TIME [epoch: 10.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2352380733370189		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.2352380733370189 | validation: 0.3188832269273849]
	TIME [epoch: 10.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2895994430973042		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.2895994430973042 | validation: 0.344756967322505]
	TIME [epoch: 10.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360569629183242		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.3360569629183242 | validation: 0.34376624729869215]
	TIME [epoch: 10.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28211466796969076		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.28211466796969076 | validation: 0.34205714593947917]
	TIME [epoch: 10.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24130631917624673		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.24130631917624673 | validation: 0.2251802565897289]
	TIME [epoch: 10.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24764053994490048		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.24764053994490048 | validation: 0.34092081249807377]
	TIME [epoch: 10.3 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2969965303769525		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.2969965303769525 | validation: 0.30268399941835233]
	TIME [epoch: 10.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27142741931877734		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.27142741931877734 | validation: 0.3234337144666114]
	TIME [epoch: 10.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23819926556879625		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.23819926556879625 | validation: 0.27978724953208783]
	TIME [epoch: 10.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24230481945781013		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.24230481945781013 | validation: 0.32377865836590813]
	TIME [epoch: 10.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27165796372354145		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.27165796372354145 | validation: 0.3305010378632448]
	TIME [epoch: 10.3 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34651474455480563		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.34651474455480563 | validation: 0.3208378223728201]
	TIME [epoch: 10.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24493615832243326		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.24493615832243326 | validation: 0.2633423671042576]
	TIME [epoch: 10.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2880153709051771		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.2880153709051771 | validation: 0.26784064986959427]
	TIME [epoch: 10.2 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32742900676027153		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.32742900676027153 | validation: 0.2439828542515396]
	TIME [epoch: 10.3 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24645172755102834		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.24645172755102834 | validation: 0.2490448761436961]
	TIME [epoch: 10.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29656144662209644		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.29656144662209644 | validation: 0.23754533399911304]
	TIME [epoch: 10.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2405800426483105		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.2405800426483105 | validation: 0.24888428462018122]
	TIME [epoch: 10.3 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22938583485091488		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.22938583485091488 | validation: 0.22631323255508]
	TIME [epoch: 10.3 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.302431207893028		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.302431207893028 | validation: 0.32650456838529546]
	TIME [epoch: 10.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28586278540317067		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.28586278540317067 | validation: 0.26563404448225425]
	TIME [epoch: 10.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22667660664989073		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.22667660664989073 | validation: 0.36484359555010865]
	TIME [epoch: 10.3 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2659374177975945		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.2659374177975945 | validation: 0.22165495888043482]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1234.pth
	Model improved!!!
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2637532493232063		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.2637532493232063 | validation: 0.28616925476714605]
	TIME [epoch: 10.3 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26074023525724066		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.26074023525724066 | validation: 0.3866051087281197]
	TIME [epoch: 10.3 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27088758454123546		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.27088758454123546 | validation: 0.27252158894575684]
	TIME [epoch: 10.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24827671459779538		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.24827671459779538 | validation: 0.26728044891370184]
	TIME [epoch: 10.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29530438164036543		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.29530438164036543 | validation: 0.25780378201901427]
	TIME [epoch: 10.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28673435640584327		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.28673435640584327 | validation: 0.24504874251663444]
	TIME [epoch: 10.3 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25741032933227925		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.25741032933227925 | validation: 0.3114002099412208]
	TIME [epoch: 10.3 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33107016449055315		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.33107016449055315 | validation: 0.3582115246027126]
	TIME [epoch: 10.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705150962121037		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.2705150962121037 | validation: 0.2916217952736822]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2398045002787792		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.2398045002787792 | validation: 0.27170281418349657]
	TIME [epoch: 10.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25479805998232347		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.25479805998232347 | validation: 0.24594740347810146]
	TIME [epoch: 10.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2865374472012282		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.2865374472012282 | validation: 0.27201810688907463]
	TIME [epoch: 10.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3654471043028207		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.3654471043028207 | validation: 0.2546880114933016]
	TIME [epoch: 10.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2357907885491756		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.2357907885491756 | validation: 0.25836418509401643]
	TIME [epoch: 10.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24377960088227857		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.24377960088227857 | validation: 0.3823725073230931]
	TIME [epoch: 10.3 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29273188035119513		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.29273188035119513 | validation: 0.25660202360523143]
	TIME [epoch: 10.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26893326422554187		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.26893326422554187 | validation: 0.25721600431738956]
	TIME [epoch: 10.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26079374843760034		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.26079374843760034 | validation: 0.2437322791931232]
	TIME [epoch: 10.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21318135468992314		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.21318135468992314 | validation: 0.24878690865759168]
	TIME [epoch: 10.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271479724202849		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.2271479724202849 | validation: 0.29608904020084587]
	TIME [epoch: 10.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31933706405734874		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.31933706405734874 | validation: 0.24875136453076407]
	TIME [epoch: 10.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32118489987365767		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.32118489987365767 | validation: 0.4669882821399773]
	TIME [epoch: 10.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28448238486276006		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.28448238486276006 | validation: 0.26367149017488767]
	TIME [epoch: 10.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2718846086218217		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.2718846086218217 | validation: 0.23902202913260354]
	TIME [epoch: 10.3 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26189293288739257		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.26189293288739257 | validation: 0.2424479927614229]
	TIME [epoch: 10.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25803137629422307		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.25803137629422307 | validation: 0.26727664955299213]
	TIME [epoch: 10.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28763382728507414		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.28763382728507414 | validation: 0.2776962418207653]
	TIME [epoch: 10.3 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23712793424903977		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.23712793424903977 | validation: 0.49919603430463827]
	TIME [epoch: 10.3 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3411681254932289		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.3411681254932289 | validation: 0.2389044197098652]
	TIME [epoch: 10.3 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35292213122558513		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.35292213122558513 | validation: 0.28926299848783077]
	TIME [epoch: 10.3 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25036419688769085		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.25036419688769085 | validation: 0.2556666843375353]
	TIME [epoch: 10.3 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26962695511504664		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.26962695511504664 | validation: 0.35843751208019453]
	TIME [epoch: 10.3 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2461836062696921		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.2461836062696921 | validation: 0.2852270614765093]
	TIME [epoch: 10.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4404951804891307		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.4404951804891307 | validation: 0.316758664668558]
	TIME [epoch: 10.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2708457551346468		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.2708457551346468 | validation: 0.23780354893320435]
	TIME [epoch: 10.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2777409832386864		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.2777409832386864 | validation: 0.2706381232968713]
	TIME [epoch: 10.3 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27416409812672626		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.27416409812672626 | validation: 0.27784937035216023]
	TIME [epoch: 10.3 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23213194805021878		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.23213194805021878 | validation: 0.26484769532643065]
	TIME [epoch: 10.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2277443423027195		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.2277443423027195 | validation: 0.3158096941406008]
	TIME [epoch: 10.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502747109750353		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.2502747109750353 | validation: 0.30657756045458806]
	TIME [epoch: 10.3 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34957131255844404		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.34957131255844404 | validation: 0.26387181731657355]
	TIME [epoch: 10.3 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28729971373940105		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.28729971373940105 | validation: 0.506155642313677]
	TIME [epoch: 10.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146043009703531		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.3146043009703531 | validation: 0.20576283462973924]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1277.pth
	Model improved!!!
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27599810380988415		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.27599810380988415 | validation: 0.23572001404605464]
	TIME [epoch: 10.3 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20745642413143797		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.20745642413143797 | validation: 0.20490750585397569]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1279.pth
	Model improved!!!
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2210272575560915		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.2210272575560915 | validation: 0.25398712244915905]
	TIME [epoch: 10.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24222975999030488		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.24222975999030488 | validation: 0.23354291366013155]
	TIME [epoch: 10.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23828446943864418		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.23828446943864418 | validation: 0.3339245314405682]
	TIME [epoch: 10.3 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3219705803673881		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.3219705803673881 | validation: 0.29129974577717904]
	TIME [epoch: 10.3 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2647211490985186		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.2647211490985186 | validation: 0.28041982297711626]
	TIME [epoch: 10.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25855554006469955		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.25855554006469955 | validation: 0.3755247263452401]
	TIME [epoch: 10.3 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3463834656673472		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.3463834656673472 | validation: 0.410371070051376]
	TIME [epoch: 10.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3542007943565664		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.3542007943565664 | validation: 0.2576420751333205]
	TIME [epoch: 10.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24719571286942132		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.24719571286942132 | validation: 0.4423019543488445]
	TIME [epoch: 10.3 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3636636382699758		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.3636636382699758 | validation: 0.2573274357188488]
	TIME [epoch: 10.3 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2486927740745331		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.2486927740745331 | validation: 0.26040212515198474]
	TIME [epoch: 10.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2998913530225568		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.2998913530225568 | validation: 0.387867690637981]
	TIME [epoch: 10.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.423556377732648		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.423556377732648 | validation: 0.35242230194138185]
	TIME [epoch: 10.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2392016347589127		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.2392016347589127 | validation: 0.2747888716532121]
	TIME [epoch: 10.3 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35474059914208655		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.35474059914208655 | validation: 0.41061737663432574]
	TIME [epoch: 10.3 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27467359600507985		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.27467359600507985 | validation: 0.24544211216987394]
	TIME [epoch: 10.3 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2270551690747173		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.2270551690747173 | validation: 0.28061925724602743]
	TIME [epoch: 10.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2664789188668478		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.2664789188668478 | validation: 0.23986225653618123]
	TIME [epoch: 10.3 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40622526346147164		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.40622526346147164 | validation: 0.4540675651149843]
	TIME [epoch: 10.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38679176826995987		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.38679176826995987 | validation: 0.41696941826385997]
	TIME [epoch: 10.3 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.330835404296095		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.330835404296095 | validation: 0.5478983433555997]
	TIME [epoch: 10.3 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3350606062761324		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.3350606062761324 | validation: 0.24366113440142065]
	TIME [epoch: 10.3 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3590631063969728		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.3590631063969728 | validation: 0.2623730728824024]
	TIME [epoch: 10.3 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2548165353580842		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.2548165353580842 | validation: 0.2953294961897425]
	TIME [epoch: 10.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21681728310036957		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.21681728310036957 | validation: 0.2527044126702217]
	TIME [epoch: 10.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27160483700560284		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.27160483700560284 | validation: 0.23580816401454613]
	TIME [epoch: 10.3 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945958698623673		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.2945958698623673 | validation: 0.3495776311440757]
	TIME [epoch: 10.3 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29835586298882777		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.29835586298882777 | validation: 0.27222724134696075]
	TIME [epoch: 10.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25340560542936197		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.25340560542936197 | validation: 0.32587797510031297]
	TIME [epoch: 10.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.387718110380925		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.387718110380925 | validation: 0.2384453928309592]
	TIME [epoch: 10.3 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21023590998002867		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.21023590998002867 | validation: 0.25767246886300016]
	TIME [epoch: 10.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2040169736244594		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.2040169736244594 | validation: 0.23100324789708357]
	TIME [epoch: 10.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25413822381445794		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.25413822381445794 | validation: 0.3926629597470169]
	TIME [epoch: 10.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25848636793280255		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.25848636793280255 | validation: 0.39756121906024383]
	TIME [epoch: 10.3 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3666577641577303		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.3666577641577303 | validation: 0.2318422775110905]
	TIME [epoch: 10.3 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.288016230637315		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.288016230637315 | validation: 0.4115520276852602]
	TIME [epoch: 10.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3283378452982972		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.3283378452982972 | validation: 0.3594750772701984]
	TIME [epoch: 10.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25181051134233656		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.25181051134233656 | validation: 0.23293963361334258]
	TIME [epoch: 10.3 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22882800100705136		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.22882800100705136 | validation: 0.23403943797749827]
	TIME [epoch: 10.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21664865202806385		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.21664865202806385 | validation: 0.2798653930911223]
	TIME [epoch: 10.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.279634245856431		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.279634245856431 | validation: 0.2668478079382996]
	TIME [epoch: 10.3 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.274447462285868		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.274447462285868 | validation: 0.24042240078242774]
	TIME [epoch: 10.3 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22144687747111033		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.22144687747111033 | validation: 0.24293928040130056]
	TIME [epoch: 10.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576402269939172		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.2576402269939172 | validation: 0.24968548155719186]
	TIME [epoch: 10.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2129683180188807		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.2129683180188807 | validation: 0.23594457561756765]
	TIME [epoch: 10.3 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2116298938169557		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.2116298938169557 | validation: 0.2645584955242343]
	TIME [epoch: 10.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573233417484163		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.2573233417484163 | validation: 0.2499206537401448]
	TIME [epoch: 10.3 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29639325124668947		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.29639325124668947 | validation: 0.3574769035788623]
	TIME [epoch: 10.3 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24555214421083993		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.24555214421083993 | validation: 0.2696864903707322]
	TIME [epoch: 10.3 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21333362197746522		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.21333362197746522 | validation: 0.22317462608050734]
	TIME [epoch: 10.3 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21466702202690224		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.21466702202690224 | validation: 0.3059672053305427]
	TIME [epoch: 10.3 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24096238166986686		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.24096238166986686 | validation: 0.2641532440975244]
	TIME [epoch: 10.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2685555269306852		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.2685555269306852 | validation: 0.260832299430389]
	TIME [epoch: 10.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2436663691833235		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.2436663691833235 | validation: 0.24146458749776556]
	TIME [epoch: 10.3 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2610263697485212		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.2610263697485212 | validation: 0.3198384696885252]
	TIME [epoch: 10.3 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28836204484084305		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.28836204484084305 | validation: 0.23280648809704016]
	TIME [epoch: 10.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2846035149523728		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.2846035149523728 | validation: 0.4201989808719875]
	TIME [epoch: 10.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2962062614215028		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.2962062614215028 | validation: 0.24784564813329163]
	TIME [epoch: 10.3 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21535711147911824		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.21535711147911824 | validation: 0.23535044790337778]
	TIME [epoch: 10.3 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699770831365235		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.2699770831365235 | validation: 0.28730311527203084]
	TIME [epoch: 10.3 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24193608312074172		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.24193608312074172 | validation: 0.34701111381117]
	TIME [epoch: 10.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27699117460481043		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.27699117460481043 | validation: 0.26533304462866447]
	TIME [epoch: 10.3 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25463890461223804		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.25463890461223804 | validation: 0.3123269859414553]
	TIME [epoch: 10.3 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2934437027253939		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.2934437027253939 | validation: 0.25512683908204187]
	TIME [epoch: 10.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2817324523591129		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.2817324523591129 | validation: 0.25536617361294495]
	TIME [epoch: 10.3 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23268784575212278		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.23268784575212278 | validation: 0.2802933658186546]
	TIME [epoch: 10.3 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24927480328934548		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.24927480328934548 | validation: 0.3368998761400269]
	TIME [epoch: 10.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26497636717050466		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.26497636717050466 | validation: 0.316251504055214]
	TIME [epoch: 10.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22556230425448226		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.22556230425448226 | validation: 0.25183597865392043]
	TIME [epoch: 10.3 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2951289050502594		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.2951289050502594 | validation: 0.2611151222727476]
	TIME [epoch: 10.3 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2200255515118184		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.2200255515118184 | validation: 0.2728063018965909]
	TIME [epoch: 10.3 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2538537303270809		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.2538537303270809 | validation: 0.2498444204917052]
	TIME [epoch: 10.3 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2315185248736277		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.2315185248736277 | validation: 0.23711872305200174]
	TIME [epoch: 10.3 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37233966604105745		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.37233966604105745 | validation: 0.22474793504156768]
	TIME [epoch: 10.3 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24850504494094286		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.24850504494094286 | validation: 0.3123077744365542]
	TIME [epoch: 10.3 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23915994543367552		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.23915994543367552 | validation: 0.32869569078394134]
	TIME [epoch: 10.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28943972254863193		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.28943972254863193 | validation: 0.24979094726077625]
	TIME [epoch: 10.3 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2337790227384136		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.2337790227384136 | validation: 0.2360860119768335]
	TIME [epoch: 10.3 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29306714898395686		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.29306714898395686 | validation: 0.2901125273910036]
	TIME [epoch: 10.3 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23486627011419858		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.23486627011419858 | validation: 0.2632230912535508]
	TIME [epoch: 10.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30648136571043405		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.30648136571043405 | validation: 0.2630726158448176]
	TIME [epoch: 10.3 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22955615827845804		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.22955615827845804 | validation: 0.22946402398805976]
	TIME [epoch: 10.3 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2505088854439787		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.2505088854439787 | validation: 0.2137737176502675]
	TIME [epoch: 10.3 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2691566419937629		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.2691566419937629 | validation: 0.3350167050915712]
	TIME [epoch: 10.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638512730907066		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.2638512730907066 | validation: 0.2642517523130923]
	TIME [epoch: 10.3 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20362036266856937		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.20362036266856937 | validation: 0.3897567171156533]
	TIME [epoch: 10.3 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799192404641077		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.2799192404641077 | validation: 0.2141492461788792]
	TIME [epoch: 10.3 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2720687406175867		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.2720687406175867 | validation: 0.23560470686730084]
	TIME [epoch: 10.3 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24505741715583892		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.24505741715583892 | validation: 0.23767925859734768]
	TIME [epoch: 10.3 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2147397684300095		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.2147397684300095 | validation: 0.2520200955254411]
	TIME [epoch: 10.3 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24323325771375645		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.24323325771375645 | validation: 0.3382684676964229]
	TIME [epoch: 10.3 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26852084385988484		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.26852084385988484 | validation: 0.256089642514632]
	TIME [epoch: 10.3 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2797716382560249		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.2797716382560249 | validation: 0.3672335564188531]
	TIME [epoch: 10.3 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2458507448078405		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.2458507448078405 | validation: 0.2840504648664896]
	TIME [epoch: 10.3 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2896072574607274		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.2896072574607274 | validation: 0.2880977678522719]
	TIME [epoch: 10.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4171275595299774		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.4171275595299774 | validation: 0.30411639143673275]
	TIME [epoch: 10.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507692941498528		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.2507692941498528 | validation: 0.28453019740976343]
	TIME [epoch: 10.3 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22200811716135388		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.22200811716135388 | validation: 0.30020223158525455]
	TIME [epoch: 10.3 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3406224699255833		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.3406224699255833 | validation: 0.27718141925427076]
	TIME [epoch: 10.3 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33181415119510355		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.33181415119510355 | validation: 0.32061020430358766]
	TIME [epoch: 10.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009720474549834		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.3009720474549834 | validation: 0.41133609639580626]
	TIME [epoch: 10.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33350543055116627		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.33350543055116627 | validation: 0.2645019307847626]
	TIME [epoch: 10.3 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23541878350718481		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.23541878350718481 | validation: 0.270789110051317]
	TIME [epoch: 10.3 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2747502846922519		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.2747502846922519 | validation: 0.2518283426662668]
	TIME [epoch: 10.3 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.251996256761335		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.251996256761335 | validation: 0.3134010335735977]
	TIME [epoch: 10.3 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2489059732284887		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.2489059732284887 | validation: 0.3062471117041404]
	TIME [epoch: 10.3 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2534976863539754		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.2534976863539754 | validation: 0.25092436290508635]
	TIME [epoch: 10.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2785757303742807		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.2785757303742807 | validation: 0.4451492115100043]
	TIME [epoch: 10.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3210324460651067		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.3210324460651067 | validation: 0.26303558913310193]
	TIME [epoch: 10.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23303117521387443		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.23303117521387443 | validation: 0.25548102252690735]
	TIME [epoch: 10.3 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24980006290473974		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.24980006290473974 | validation: 0.2793168526887012]
	TIME [epoch: 10.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.225769958949631		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.225769958949631 | validation: 0.2672443598623885]
	TIME [epoch: 10.3 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2630637170936686		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.2630637170936686 | validation: 0.32914318846157825]
	TIME [epoch: 10.3 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2234413343685314		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.2234413343685314 | validation: 0.26271283735617723]
	TIME [epoch: 10.3 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22169944222614962		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.22169944222614962 | validation: 0.2438929592682301]
	TIME [epoch: 10.3 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21674078245963657		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.21674078245963657 | validation: 0.28373093858258375]
	TIME [epoch: 10.3 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2375835917990951		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.2375835917990951 | validation: 0.33916479235966207]
	TIME [epoch: 10.3 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26726687339973965		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.26726687339973965 | validation: 0.24544050964769704]
	TIME [epoch: 10.3 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2427018171617017		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.2427018171617017 | validation: 0.2927789336372717]
	TIME [epoch: 10.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27140530882891484		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.27140530882891484 | validation: 0.29167461041807]
	TIME [epoch: 10.3 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2592227430595994		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.2592227430595994 | validation: 0.21497274664020716]
	TIME [epoch: 10.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205313016925943		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.205313016925943 | validation: 0.2519342945592047]
	TIME [epoch: 10.3 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21029891421512764		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.21029891421512764 | validation: 0.24904601239058946]
	TIME [epoch: 10.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23112680145255354		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.23112680145255354 | validation: 0.30079367126398604]
	TIME [epoch: 10.3 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23380850193543717		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.23380850193543717 | validation: 0.26276249965842874]
	TIME [epoch: 10.3 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2313714022825167		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.2313714022825167 | validation: 0.2830706971589484]
	TIME [epoch: 10.3 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23083347753485173		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.23083347753485173 | validation: 0.23024737087754577]
	TIME [epoch: 10.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22417312072466836		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.22417312072466836 | validation: 0.2274493253207418]
	TIME [epoch: 10.3 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20982763702884344		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.20982763702884344 | validation: 0.24422155145447402]
	TIME [epoch: 10.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20746287627379992		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.20746287627379992 | validation: 0.25833451495412]
	TIME [epoch: 10.3 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21017954143652257		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.21017954143652257 | validation: 0.23495077160159625]
	TIME [epoch: 10.3 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24788263520729686		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.24788263520729686 | validation: 0.24595129784308492]
	TIME [epoch: 10.3 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22664687094020639		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.22664687094020639 | validation: 0.23503317085688621]
	TIME [epoch: 10.3 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22582669215365803		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.22582669215365803 | validation: 0.2437927769494356]
	TIME [epoch: 10.3 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21256385791786672		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.21256385791786672 | validation: 0.21890575284544334]
	TIME [epoch: 10.3 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2199498174553154		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.2199498174553154 | validation: 0.2600990477653773]
	TIME [epoch: 10.3 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.206622028373712		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.206622028373712 | validation: 0.2434851963982603]
	TIME [epoch: 10.3 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20400448698300142		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.20400448698300142 | validation: 0.23846262829285497]
	TIME [epoch: 10.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21703337950211754		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.21703337950211754 | validation: 0.29093300133075006]
	TIME [epoch: 10.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22393697581740798		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.22393697581740798 | validation: 0.4172089083414884]
	TIME [epoch: 10.3 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28292051566830473		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.28292051566830473 | validation: 0.22792434673167195]
	TIME [epoch: 10.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22809296565611223		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.22809296565611223 | validation: 0.21820683842293812]
	TIME [epoch: 10.3 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22062660351558322		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.22062660351558322 | validation: 0.24432244564625558]
	TIME [epoch: 10.3 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21765073562999132		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.21765073562999132 | validation: 0.26788337836766973]
	TIME [epoch: 10.3 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20942039302458362		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.20942039302458362 | validation: 0.2623271789027853]
	TIME [epoch: 10.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23500265845396634		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.23500265845396634 | validation: 0.2634986493934372]
	TIME [epoch: 10.3 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29730893176398226		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.29730893176398226 | validation: 0.2187374867357661]
	TIME [epoch: 10.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2251925928274588		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.2251925928274588 | validation: 0.2250625556658061]
	TIME [epoch: 10.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30458974193993443		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.30458974193993443 | validation: 0.22898678483528487]
	TIME [epoch: 10.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.222381750016429		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.222381750016429 | validation: 0.20839068827618992]
	TIME [epoch: 10.3 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18923750816646448		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.18923750816646448 | validation: 0.23795611385936113]
	TIME [epoch: 10.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609260539488219		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.2609260539488219 | validation: 0.38867771800599543]
	TIME [epoch: 10.3 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2465392038288387		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.2465392038288387 | validation: 0.22538584492003794]
	TIME [epoch: 10.3 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22251233201472576		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.22251233201472576 | validation: 0.4173011546136273]
	TIME [epoch: 10.3 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29748090749544664		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.29748090749544664 | validation: 0.22231901756528344]
	TIME [epoch: 10.3 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23186473505870886		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.23186473505870886 | validation: 0.21872023941854185]
	TIME [epoch: 10.3 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20478268890766188		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.20478268890766188 | validation: 0.30576992477120324]
	TIME [epoch: 10.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699877449654074		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.2699877449654074 | validation: 0.314576002548032]
	TIME [epoch: 10.3 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22211054877496586		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.22211054877496586 | validation: 0.37456733403512843]
	TIME [epoch: 10.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31049564456066403		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.31049564456066403 | validation: 0.23181096630458178]
	TIME [epoch: 10.3 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20100733235507948		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.20100733235507948 | validation: 0.21345343167782893]
	TIME [epoch: 10.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23168382782068447		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.23168382782068447 | validation: 0.3130529367560535]
	TIME [epoch: 10.3 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23926876432313957		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.23926876432313957 | validation: 0.21616258182257272]
	TIME [epoch: 10.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22272183993971742		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.22272183993971742 | validation: 0.25460184628671395]
	TIME [epoch: 10.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37375825696641024		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.37375825696641024 | validation: 0.23491372671954858]
	TIME [epoch: 10.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23213238717653845		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.23213238717653845 | validation: 0.329759012863469]
	TIME [epoch: 10.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33276984227707207		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.33276984227707207 | validation: 0.3959806176318578]
	TIME [epoch: 10.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25150372902283147		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.25150372902283147 | validation: 0.30715068476421037]
	TIME [epoch: 10.3 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22437662761869775		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.22437662761869775 | validation: 0.2127865595178743]
	TIME [epoch: 10.3 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22666146419591918		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.22666146419591918 | validation: 0.24292388898329387]
	TIME [epoch: 10.3 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21919251629621078		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.21919251629621078 | validation: 0.2764794049198922]
	TIME [epoch: 10.3 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2233549283386595		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.2233549283386595 | validation: 0.23559396224567764]
	TIME [epoch: 10.3 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21553656430720247		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.21553656430720247 | validation: 0.2236714335377798]
	TIME [epoch: 10.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22171480329660742		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.22171480329660742 | validation: 0.2448039059512408]
	TIME [epoch: 10.3 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23431908061933174		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.23431908061933174 | validation: 0.2729516305087967]
	TIME [epoch: 10.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084316204682021		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.2084316204682021 | validation: 0.2665952859966919]
	TIME [epoch: 10.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26489224906277953		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.26489224906277953 | validation: 0.2550720962168251]
	TIME [epoch: 10.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20151499064272366		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.20151499064272366 | validation: 0.27829481961137675]
	TIME [epoch: 10.3 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29934374019400184		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.29934374019400184 | validation: 0.26273872932640385]
	TIME [epoch: 10.3 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24658095048297027		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.24658095048297027 | validation: 0.2376290451484917]
	TIME [epoch: 10.3 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2427195762543713		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.2427195762543713 | validation: 0.3432767035766874]
	TIME [epoch: 10.3 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22150926578283142		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.22150926578283142 | validation: 0.24305208891987978]
	TIME [epoch: 10.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19573263092148227		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.19573263092148227 | validation: 0.2506608749605309]
	TIME [epoch: 10.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24224296817604096		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.24224296817604096 | validation: 0.23868606195197306]
	TIME [epoch: 10.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21131425174953108		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.21131425174953108 | validation: 0.2413024725102357]
	TIME [epoch: 10.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29027949243080986		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.29027949243080986 | validation: 0.3116848145248]
	TIME [epoch: 10.3 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22213692513249436		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.22213692513249436 | validation: 0.22221336342483647]
	TIME [epoch: 10.3 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20708518087318195		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.20708518087318195 | validation: 0.2679226413507003]
	TIME [epoch: 10.3 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291585183283961		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.2291585183283961 | validation: 0.22647656719011797]
	TIME [epoch: 10.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118292918532096		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.2118292918532096 | validation: 0.2301595796112573]
	TIME [epoch: 10.3 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22648436087753437		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.22648436087753437 | validation: 0.25315182607945047]
	TIME [epoch: 10.3 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23388789650851946		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.23388789650851946 | validation: 0.2928981291079991]
	TIME [epoch: 10.3 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26233156588845746		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.26233156588845746 | validation: 0.29662761913617786]
	TIME [epoch: 10.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.220534165964884		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.220534165964884 | validation: 0.26056791897872983]
	TIME [epoch: 10.3 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21754747127045615		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.21754747127045615 | validation: 0.24849887632952886]
	TIME [epoch: 10.3 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23816449114521254		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.23816449114521254 | validation: 0.2323908035672859]
	TIME [epoch: 10.3 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19762611117466172		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.19762611117466172 | validation: 0.24388556299187394]
	TIME [epoch: 10.3 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20262536003787074		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.20262536003787074 | validation: 0.22583919862104723]
	TIME [epoch: 10.3 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19746688020996578		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.19746688020996578 | validation: 0.24215795655102212]
	TIME [epoch: 10.3 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22682465719533265		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.22682465719533265 | validation: 0.2363654328417244]
	TIME [epoch: 10.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20379294675365472		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.20379294675365472 | validation: 0.23467502704752283]
	TIME [epoch: 10.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19587550219698996		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.19587550219698996 | validation: 0.2446203139888516]
	TIME [epoch: 10.3 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20737669722661325		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.20737669722661325 | validation: 0.2162452502205537]
	TIME [epoch: 10.3 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21637549268555883		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.21637549268555883 | validation: 0.4016744499268285]
	TIME [epoch: 10.3 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33451586846725834		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.33451586846725834 | validation: 0.46736089139498477]
	TIME [epoch: 10.3 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31713927807138265		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.31713927807138265 | validation: 0.25285826368253894]
	TIME [epoch: 10.3 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2152584168483048		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.2152584168483048 | validation: 0.22542131395635626]
	TIME [epoch: 10.3 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20820755024947496		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.20820755024947496 | validation: 0.41418488738852405]
	TIME [epoch: 10.3 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3161560339014685		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.3161560339014685 | validation: 0.23666209599417712]
	TIME [epoch: 10.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2151216007207517		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.2151216007207517 | validation: 0.22428184515018285]
	TIME [epoch: 10.3 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22371368967407096		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.22371368967407096 | validation: 0.2841694017959504]
	TIME [epoch: 10.3 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22082367873327496		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.22082367873327496 | validation: 0.24449080666842546]
	TIME [epoch: 10.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1986480495478591		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.1986480495478591 | validation: 0.21290670886955632]
	TIME [epoch: 10.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22122634882124226		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.22122634882124226 | validation: 0.22260327586689713]
	TIME [epoch: 10.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23262783090279388		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.23262783090279388 | validation: 0.2826159491340235]
	TIME [epoch: 10.3 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20319203851475565		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.20319203851475565 | validation: 0.3117271820898309]
	TIME [epoch: 10.3 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23178643691946038		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.23178643691946038 | validation: 0.2670663727725404]
	TIME [epoch: 10.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22152426132282627		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.22152426132282627 | validation: 0.30363740168562886]
	TIME [epoch: 10.3 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23291043363727676		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.23291043363727676 | validation: 0.24015389669861145]
	TIME [epoch: 10.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21183172360573002		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.21183172360573002 | validation: 0.23869674447971834]
	TIME [epoch: 10.3 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19827915541080307		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.19827915541080307 | validation: 0.2409392581446202]
	TIME [epoch: 10.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20688110684788433		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.20688110684788433 | validation: 0.30482139970488603]
	TIME [epoch: 10.3 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23184398715097188		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.23184398715097188 | validation: 0.2681982803260715]
	TIME [epoch: 10.3 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24427637102598593		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.24427637102598593 | validation: 0.2490893799854827]
	TIME [epoch: 10.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21208580254156212		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.21208580254156212 | validation: 0.2630143894893698]
	TIME [epoch: 10.3 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22991351797060497		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.22991351797060497 | validation: 0.4458836096701662]
	TIME [epoch: 10.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3157306418502392		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.3157306418502392 | validation: 0.2627476817214095]
	TIME [epoch: 10.3 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23777314489915885		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.23777314489915885 | validation: 0.30733552734389336]
	TIME [epoch: 10.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24195906704861211		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.24195906704861211 | validation: 0.24377292239656662]
	TIME [epoch: 10.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20661280952009897		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.20661280952009897 | validation: 0.24680943868106436]
	TIME [epoch: 10.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19910983539853616		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.19910983539853616 | validation: 0.24219659147865927]
	TIME [epoch: 10.3 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2200755280481828		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.2200755280481828 | validation: 0.20438670386459692]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1511.pth
	Model improved!!!
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20093290326347368		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.20093290326347368 | validation: 0.2455642770113605]
	TIME [epoch: 10.3 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23230182485406833		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.23230182485406833 | validation: 0.2584203494552807]
	TIME [epoch: 10.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2549683269916959		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.2549683269916959 | validation: 0.25736715982974373]
	TIME [epoch: 10.3 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2751842079962069		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.2751842079962069 | validation: 0.28984732145103137]
	TIME [epoch: 10.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22346689160657823		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.22346689160657823 | validation: 0.30665946097242236]
	TIME [epoch: 10.3 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2256437422199693		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.2256437422199693 | validation: 0.2900835566144999]
	TIME [epoch: 10.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25337271625530666		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.25337271625530666 | validation: 0.3159029741484494]
	TIME [epoch: 10.3 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2737668763810182		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.2737668763810182 | validation: 0.28928050842393144]
	TIME [epoch: 10.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2341984353493823		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.2341984353493823 | validation: 0.3126067448711175]
	TIME [epoch: 10.3 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2469229268851702		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.2469229268851702 | validation: 0.3352498761551456]
	TIME [epoch: 10.3 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693394866132012		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.2693394866132012 | validation: 0.26688402187557897]
	TIME [epoch: 10.3 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24733762977314674		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.24733762977314674 | validation: 0.2914515697772443]
	TIME [epoch: 10.3 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21070234710130414		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.21070234710130414 | validation: 0.2699244016965658]
	TIME [epoch: 10.3 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26871733258927716		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.26871733258927716 | validation: 0.25216436191649877]
	TIME [epoch: 10.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2433695800514662		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.2433695800514662 | validation: 0.30557237245817875]
	TIME [epoch: 10.3 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22800056142582328		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.22800056142582328 | validation: 0.23791509374157627]
	TIME [epoch: 10.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20765369856509058		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.20765369856509058 | validation: 0.28520590702476517]
	TIME [epoch: 10.3 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21874826969847921		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.21874826969847921 | validation: 0.24193488903609367]
	TIME [epoch: 10.3 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2060065069372127		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.2060065069372127 | validation: 0.25030212418639985]
	TIME [epoch: 10.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200527884020481		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.200527884020481 | validation: 0.23440744426513122]
	TIME [epoch: 10.3 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2821375671030467		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.2821375671030467 | validation: 0.28694360305996774]
	TIME [epoch: 10.3 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21973051888745143		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.21973051888745143 | validation: 0.21424126382715897]
	TIME [epoch: 10.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18311478294852684		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.18311478294852684 | validation: 0.2523797021554995]
	TIME [epoch: 10.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2782452352898691		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.2782452352898691 | validation: 0.25472864840119885]
	TIME [epoch: 10.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20645797329862123		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.20645797329862123 | validation: 0.2739261444463165]
	TIME [epoch: 10.3 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22527364234974043		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.22527364234974043 | validation: 0.23791537254724812]
	TIME [epoch: 10.3 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24978066527115414		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.24978066527115414 | validation: 0.20936198643982676]
	TIME [epoch: 10.3 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2113176610129106		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.2113176610129106 | validation: 0.22894561968744703]
	TIME [epoch: 10.3 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22131221348518068		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.22131221348518068 | validation: 0.3609934480516169]
	TIME [epoch: 10.3 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27907969735662863		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.27907969735662863 | validation: 0.24401186362686847]
	TIME [epoch: 10.3 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1991775451675596		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.1991775451675596 | validation: 0.2706359447413211]
	TIME [epoch: 10.3 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2004810280021497		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.2004810280021497 | validation: 0.21406324796922774]
	TIME [epoch: 10.3 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24910879104847608		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.24910879104847608 | validation: 0.23916893270818954]
	TIME [epoch: 10.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2148152571868442		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.2148152571868442 | validation: 0.3101480456315961]
	TIME [epoch: 10.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24168797115223528		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.24168797115223528 | validation: 0.3651295125189837]
	TIME [epoch: 10.3 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2558441428226305		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.2558441428226305 | validation: 0.2992862769421942]
	TIME [epoch: 10.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22581445531338645		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.22581445531338645 | validation: 0.2571414685373912]
	TIME [epoch: 10.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27655691081410033		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.27655691081410033 | validation: 0.255177444273049]
	TIME [epoch: 10.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20682875836911752		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.20682875836911752 | validation: 0.2559039257100421]
	TIME [epoch: 10.3 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23347448892398442		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.23347448892398442 | validation: 0.2547026576347547]
	TIME [epoch: 10.3 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21243625182603773		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.21243625182603773 | validation: 0.3046580401126221]
	TIME [epoch: 10.3 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22191773554780383		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.22191773554780383 | validation: 0.2692673684828385]
	TIME [epoch: 10.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21930169759767174		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.21930169759767174 | validation: 0.21970737617334077]
	TIME [epoch: 10.3 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2080496999445792		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.2080496999445792 | validation: 0.2217203803357153]
	TIME [epoch: 10.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19708798956108764		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.19708798956108764 | validation: 0.2516470272370394]
	TIME [epoch: 10.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20578760175075725		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.20578760175075725 | validation: 0.19871689819900654]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1557.pth
	Model improved!!!
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24015469552781005		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.24015469552781005 | validation: 0.3817101716707634]
	TIME [epoch: 10.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28207305803175897		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.28207305803175897 | validation: 0.28046426871603186]
	TIME [epoch: 10.3 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22250422859975635		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.22250422859975635 | validation: 0.29042258910645424]
	TIME [epoch: 10.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2396563687466596		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.2396563687466596 | validation: 0.23343747528992487]
	TIME [epoch: 10.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20963915290256913		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.20963915290256913 | validation: 0.2514042762934069]
	TIME [epoch: 10.3 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23650973361245148		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.23650973361245148 | validation: 0.24077053917207686]
	TIME [epoch: 10.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22631519354581192		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.22631519354581192 | validation: 0.278575105331889]
	TIME [epoch: 10.3 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2248456558375415		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.2248456558375415 | validation: 0.2548853826741154]
	TIME [epoch: 10.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2324604154785273		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.2324604154785273 | validation: 0.22275093150444497]
	TIME [epoch: 10.3 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19437247609743968		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.19437247609743968 | validation: 0.21683838569538702]
	TIME [epoch: 10.3 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2653105826481136		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.2653105826481136 | validation: 0.22475119703830918]
	TIME [epoch: 10.3 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20788303110187742		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.20788303110187742 | validation: 0.22471762128903755]
	TIME [epoch: 10.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21866692499779655		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.21866692499779655 | validation: 0.21361119834231726]
	TIME [epoch: 10.3 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21697066485251174		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.21697066485251174 | validation: 0.23425683192619826]
	TIME [epoch: 10.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22387979881425615		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.22387979881425615 | validation: 0.23065370493128878]
	TIME [epoch: 10.3 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21206485736721542		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.21206485736721542 | validation: 0.2246705758504666]
	TIME [epoch: 10.3 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2347110679646772		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.2347110679646772 | validation: 0.23120180503947596]
	TIME [epoch: 10.3 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2346007689023733		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.2346007689023733 | validation: 0.270831545291686]
	TIME [epoch: 10.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21505401132818563		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.21505401132818563 | validation: 0.23287763133453077]
	TIME [epoch: 10.3 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2013744920019124		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.2013744920019124 | validation: 0.20562702968507793]
	TIME [epoch: 10.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.196717570879894		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.196717570879894 | validation: 0.21200343217193962]
	TIME [epoch: 10.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19592274362542533		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.19592274362542533 | validation: 0.2657523235563483]
	TIME [epoch: 10.3 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2103690054879463		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.2103690054879463 | validation: 0.2230812789745808]
	TIME [epoch: 10.3 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20420224973636952		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.20420224973636952 | validation: 0.21929019594442042]
	TIME [epoch: 10.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23776118814954694		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.23776118814954694 | validation: 0.22377307179478442]
	TIME [epoch: 10.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2400420605334906		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.2400420605334906 | validation: 0.21715482763936134]
	TIME [epoch: 10.3 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19798178176913322		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.19798178176913322 | validation: 0.23388284042962448]
	TIME [epoch: 10.3 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018100045870101		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.2018100045870101 | validation: 0.2723464501686808]
	TIME [epoch: 10.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24961637521902696		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.24961637521902696 | validation: 0.26261836413543516]
	TIME [epoch: 10.3 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22715890972556027		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.22715890972556027 | validation: 0.31835143952401024]
	TIME [epoch: 10.3 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2658241991146667		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.2658241991146667 | validation: 0.3213843424038184]
	TIME [epoch: 10.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23176859907534803		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.23176859907534803 | validation: 0.2433654196711304]
	TIME [epoch: 10.3 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23836716718896206		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.23836716718896206 | validation: 0.23116213362238663]
	TIME [epoch: 10.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22301475241061083		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.22301475241061083 | validation: 0.2312736319030424]
	TIME [epoch: 10.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24860154347362567		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.24860154347362567 | validation: 0.23093440891069641]
	TIME [epoch: 10.3 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19442689070136518		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.19442689070136518 | validation: 0.20840028504041072]
	TIME [epoch: 10.3 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19503879175783675		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.19503879175783675 | validation: 0.21557029399178468]
	TIME [epoch: 10.3 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20717455117215908		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.20717455117215908 | validation: 0.22851611846954847]
	TIME [epoch: 10.3 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1930136249129243		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.1930136249129243 | validation: 0.21025314087570757]
	TIME [epoch: 10.3 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20589897300425059		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.20589897300425059 | validation: 0.2095899093529878]
	TIME [epoch: 10.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19181604702942556		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.19181604702942556 | validation: 0.22913444458569993]
	TIME [epoch: 10.3 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19899289466943293		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.19899289466943293 | validation: 0.24102153999866027]
	TIME [epoch: 10.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22257790418313705		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.22257790418313705 | validation: 0.2290779399656655]
	TIME [epoch: 10.3 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21716685787702256		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.21716685787702256 | validation: 0.2226579318038565]
	TIME [epoch: 10.3 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20093380418267714		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.20093380418267714 | validation: 0.22270932430693358]
	TIME [epoch: 10.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000792899842569		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.2000792899842569 | validation: 0.23560707311976747]
	TIME [epoch: 10.3 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19576509796910269		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.19576509796910269 | validation: 0.20483350609369708]
	TIME [epoch: 10.3 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299304698749621		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.2299304698749621 | validation: 0.2049727278479641]
	TIME [epoch: 10.3 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20559366372606808		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.20559366372606808 | validation: 0.2147115701146892]
	TIME [epoch: 10.3 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21841158106696607		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.21841158106696607 | validation: 0.23476773554958727]
	TIME [epoch: 10.3 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19374996576955988		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.19374996576955988 | validation: 0.2454166728757356]
	TIME [epoch: 10.3 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19435275512500796		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.19435275512500796 | validation: 0.2942537541093785]
	TIME [epoch: 10.3 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2647594254937597		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.2647594254937597 | validation: 0.22743334180162425]
	TIME [epoch: 10.3 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21997814118053044		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.21997814118053044 | validation: 0.23641483650767414]
	TIME [epoch: 10.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20525496216177413		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.20525496216177413 | validation: 0.22653140802598404]
	TIME [epoch: 10.3 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20469475580806287		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.20469475580806287 | validation: 0.2404302528320352]
	TIME [epoch: 10.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18912157925827863		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.18912157925827863 | validation: 0.2303778294330531]
	TIME [epoch: 10.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18201170700815822		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.18201170700815822 | validation: 0.21860551441901174]
	TIME [epoch: 10.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20551977812552064		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.20551977812552064 | validation: 0.210877826081535]
	TIME [epoch: 10.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21316432274081953		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.21316432274081953 | validation: 0.238800176882689]
	TIME [epoch: 10.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20439800950003523		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.20439800950003523 | validation: 0.2706797910477011]
	TIME [epoch: 10.3 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31816582373733276		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.31816582373733276 | validation: 0.2206392925121525]
	TIME [epoch: 10.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18654070656594482		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.18654070656594482 | validation: 0.26859962474628324]
	TIME [epoch: 10.3 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21892427931030242		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.21892427931030242 | validation: 0.23339352186968232]
	TIME [epoch: 10.3 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19732601612535552		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.19732601612535552 | validation: 0.1955965883805684]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1622.pth
	Model improved!!!
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20257956777243608		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.20257956777243608 | validation: 0.22066676166391344]
	TIME [epoch: 10.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881988678738215		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.1881988678738215 | validation: 0.2067472553863927]
	TIME [epoch: 10.3 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25272968419131486		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.25272968419131486 | validation: 0.3491319140061264]
	TIME [epoch: 10.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2230192808571747		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.2230192808571747 | validation: 0.22424052543698827]
	TIME [epoch: 10.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2119318341934088		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.2119318341934088 | validation: 0.29595187202310386]
	TIME [epoch: 10.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2302065412536581		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.2302065412536581 | validation: 0.32269652700250007]
	TIME [epoch: 10.3 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22110273414352283		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.22110273414352283 | validation: 0.31134894313416034]
	TIME [epoch: 10.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.221319707799058		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.221319707799058 | validation: 0.22124686908010482]
	TIME [epoch: 10.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1922727914453885		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.1922727914453885 | validation: 0.22084313938218927]
	TIME [epoch: 10.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19430059510047043		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.19430059510047043 | validation: 0.2092076076333043]
	TIME [epoch: 10.3 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1874810525891784		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.1874810525891784 | validation: 0.3011049521366503]
	TIME [epoch: 10.3 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609350110378276		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.2609350110378276 | validation: 0.2756837678143835]
	TIME [epoch: 10.3 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21780329453368258		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.21780329453368258 | validation: 0.2272552766280624]
	TIME [epoch: 10.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1867121020542602		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.1867121020542602 | validation: 0.21567290692352437]
	TIME [epoch: 10.3 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19658547786797365		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.19658547786797365 | validation: 0.26210793053463916]
	TIME [epoch: 10.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21658220483281823		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.21658220483281823 | validation: 0.2037279847887842]
	TIME [epoch: 10.3 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19756879084071488		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.19756879084071488 | validation: 0.2402289379593051]
	TIME [epoch: 10.3 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19905123002596384		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.19905123002596384 | validation: 0.2315842848035466]
	TIME [epoch: 10.3 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19155071501197768		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.19155071501197768 | validation: 0.22652683508267604]
	TIME [epoch: 10.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19983888976785544		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.19983888976785544 | validation: 0.24001815291112]
	TIME [epoch: 10.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23963483062503635		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.23963483062503635 | validation: 0.2904991689743209]
	TIME [epoch: 10.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20252013332377777		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.20252013332377777 | validation: 0.21511484087740937]
	TIME [epoch: 10.3 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20699166316746487		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.20699166316746487 | validation: 0.2795651595407054]
	TIME [epoch: 10.3 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19600037658915742		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.19600037658915742 | validation: 0.23437859568178895]
	TIME [epoch: 10.3 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21400395204852832		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.21400395204852832 | validation: 0.20967634570387617]
	TIME [epoch: 10.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20913401226502287		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.20913401226502287 | validation: 0.20881267185887292]
	TIME [epoch: 10.3 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20108528464276904		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.20108528464276904 | validation: 0.23610862021537274]
	TIME [epoch: 10.3 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2196774843484345		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.2196774843484345 | validation: 0.2400431045798951]
	TIME [epoch: 10.3 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19350003016724318		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.19350003016724318 | validation: 0.2041179410307295]
	TIME [epoch: 10.3 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2147088079418808		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.2147088079418808 | validation: 0.2664159384546724]
	TIME [epoch: 10.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2300843688507709		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.2300843688507709 | validation: 0.23491047502256993]
	TIME [epoch: 10.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24396524131247718		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.24396524131247718 | validation: 0.30352071552647625]
	TIME [epoch: 10.3 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23326510753589663		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.23326510753589663 | validation: 0.2565815207304425]
	TIME [epoch: 10.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2511580347232706		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.2511580347232706 | validation: 0.30513105990519085]
	TIME [epoch: 10.3 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2343229722229046		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.2343229722229046 | validation: 0.24327090848025393]
	TIME [epoch: 10.3 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20432821058841394		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.20432821058841394 | validation: 0.25187864494462525]
	TIME [epoch: 10.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19843231440703585		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.19843231440703585 | validation: 0.2118349939193694]
	TIME [epoch: 10.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1843410865710101		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.1843410865710101 | validation: 0.2621904168956759]
	TIME [epoch: 10.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2339905260224115		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.2339905260224115 | validation: 0.26741646803083713]
	TIME [epoch: 10.3 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205623737723738		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.2205623737723738 | validation: 0.2410754856724738]
	TIME [epoch: 10.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20071529307297134		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.20071529307297134 | validation: 0.23451915237083845]
	TIME [epoch: 10.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18280689602478853		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.18280689602478853 | validation: 0.24043780584050525]
	TIME [epoch: 10.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1987435954593657		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.1987435954593657 | validation: 0.2675423214716363]
	TIME [epoch: 10.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23158705832605114		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.23158705832605114 | validation: 0.2246210231136244]
	TIME [epoch: 10.3 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19339800281818786		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.19339800281818786 | validation: 0.23125661784336626]
	TIME [epoch: 10.3 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2004801493455549		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.2004801493455549 | validation: 0.2514373558587399]
	TIME [epoch: 10.3 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1997077213260884		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.1997077213260884 | validation: 0.2123439138717195]
	TIME [epoch: 10.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17977975652107397		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.17977975652107397 | validation: 0.2220844049609416]
	TIME [epoch: 10.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22097521036087656		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.22097521036087656 | validation: 0.2515271134790329]
	TIME [epoch: 10.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19236477383015935		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.19236477383015935 | validation: 0.21403956016558542]
	TIME [epoch: 10.3 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20445349244578362		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.20445349244578362 | validation: 0.2105157560549202]
	TIME [epoch: 10.3 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21234096217319434		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.21234096217319434 | validation: 0.21687457737133314]
	TIME [epoch: 10.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2004614874989342		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.2004614874989342 | validation: 0.23228776844561988]
	TIME [epoch: 10.3 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1950132223752723		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.1950132223752723 | validation: 0.20205536309689348]
	TIME [epoch: 10.3 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28079473452986187		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.28079473452986187 | validation: 0.2127656329700236]
	TIME [epoch: 10.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1977913392794439		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.1977913392794439 | validation: 0.24839870028977146]
	TIME [epoch: 10.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19948126368366886		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.19948126368366886 | validation: 0.23110056542482282]
	TIME [epoch: 10.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18595801383870914		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.18595801383870914 | validation: 0.21429755671088202]
	TIME [epoch: 10.3 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23444267965686133		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.23444267965686133 | validation: 0.2150174851466244]
	TIME [epoch: 10.3 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22584706317152103		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.22584706317152103 | validation: 0.2233528514591575]
	TIME [epoch: 10.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18847119570888432		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.18847119570888432 | validation: 0.20695489251665852]
	TIME [epoch: 10.3 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20955345370742468		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.20955345370742468 | validation: 0.2410924009033739]
	TIME [epoch: 10.3 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20467839480894737		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.20467839480894737 | validation: 0.24610741976670011]
	TIME [epoch: 10.3 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22544252628032554		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.22544252628032554 | validation: 0.30115322380705495]
	TIME [epoch: 10.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22763764173037404		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.22763764173037404 | validation: 0.2484301235408861]
	TIME [epoch: 10.3 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21988266720799743		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.21988266720799743 | validation: 0.24480191263308493]
	TIME [epoch: 10.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20987644103306075		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.20987644103306075 | validation: 0.232230641776708]
	TIME [epoch: 10.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185564750989532		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.185564750989532 | validation: 0.23238690038450294]
	TIME [epoch: 10.3 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21489201105635852		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.21489201105635852 | validation: 0.23056838585333403]
	TIME [epoch: 10.3 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22111712499668673		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.22111712499668673 | validation: 0.2352137313986514]
	TIME [epoch: 10.3 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20171743816078477		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.20171743816078477 | validation: 0.2259239183730724]
	TIME [epoch: 10.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18848671149841353		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.18848671149841353 | validation: 0.2217426392905538]
	TIME [epoch: 10.3 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20540547427323946		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.20540547427323946 | validation: 0.2580735098993735]
	TIME [epoch: 10.3 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23434908578086694		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.23434908578086694 | validation: 0.26487575400229274]
	TIME [epoch: 10.3 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21686607180302983		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.21686607180302983 | validation: 0.2664635496899932]
	TIME [epoch: 10.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21055159260255235		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.21055159260255235 | validation: 0.21797707015066642]
	TIME [epoch: 10.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18611188594936162		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.18611188594936162 | validation: 0.2231522936892486]
	TIME [epoch: 10.3 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2655473971646452		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.2655473971646452 | validation: 0.2974544822015406]
	TIME [epoch: 10.3 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2935001987742263		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.2935001987742263 | validation: 0.20634296001194666]
	TIME [epoch: 10.3 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19143394893104682		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.19143394893104682 | validation: 0.24111613266701873]
	TIME [epoch: 10.3 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24031807909822595		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.24031807909822595 | validation: 0.2363373894774631]
	TIME [epoch: 10.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19566999569169904		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.19566999569169904 | validation: 0.2582566990806366]
	TIME [epoch: 10.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913915088844325		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.1913915088844325 | validation: 0.26949093531723206]
	TIME [epoch: 10.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21760086086861935		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.21760086086861935 | validation: 0.3031474014358735]
	TIME [epoch: 10.3 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28562087822306564		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.28562087822306564 | validation: 0.3295404507347936]
	TIME [epoch: 10.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25491346591267716		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.25491346591267716 | validation: 0.20587642498719216]
	TIME [epoch: 10.3 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20185942427266265		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.20185942427266265 | validation: 0.2871018553723862]
	TIME [epoch: 10.3 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2627622767911496		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.2627622767911496 | validation: 0.21984563083552588]
	TIME [epoch: 10.3 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19553809365352612		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.19553809365352612 | validation: 0.22993766855978734]
	TIME [epoch: 10.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1945296925869931		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.1945296925869931 | validation: 0.23412673130821318]
	TIME [epoch: 10.3 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21196717744774274		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.21196717744774274 | validation: 0.22044943812650467]
	TIME [epoch: 10.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18669633516712555		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.18669633516712555 | validation: 0.205851566640356]
	TIME [epoch: 10.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19483304167107657		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.19483304167107657 | validation: 0.24303460015833864]
	TIME [epoch: 10.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19678237606806745		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.19678237606806745 | validation: 0.23715224826257195]
	TIME [epoch: 10.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1920295211002284		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.1920295211002284 | validation: 0.23165732115962762]
	TIME [epoch: 10.3 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19222333502733852		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.19222333502733852 | validation: 0.20799201359397956]
	TIME [epoch: 10.3 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882470388609688		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.1882470388609688 | validation: 0.20249670726842545]
	TIME [epoch: 10.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2346908673419859		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.2346908673419859 | validation: 0.24836780470110456]
	TIME [epoch: 10.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19556145333695948		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.19556145333695948 | validation: 0.21494916888929264]
	TIME [epoch: 10.3 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18196598125938576		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.18196598125938576 | validation: 0.23055876288154983]
	TIME [epoch: 10.3 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21440082746727077		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.21440082746727077 | validation: 0.2523783148862677]
	TIME [epoch: 10.3 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19575933990536673		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.19575933990536673 | validation: 0.23567600286402104]
	TIME [epoch: 10.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19501979868135744		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.19501979868135744 | validation: 0.21910136112212375]
	TIME [epoch: 10.3 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875088880128662		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.2875088880128662 | validation: 0.2713998003122024]
	TIME [epoch: 10.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21094592073943552		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.21094592073943552 | validation: 0.21981068165775738]
	TIME [epoch: 10.3 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18946543693602536		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.18946543693602536 | validation: 0.23252393012689332]
	TIME [epoch: 10.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20842450329664244		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.20842450329664244 | validation: 0.27031688550577826]
	TIME [epoch: 10.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20583719869696596		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.20583719869696596 | validation: 0.23493670621654864]
	TIME [epoch: 10.3 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19520238955846353		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.19520238955846353 | validation: 0.21851198435758684]
	TIME [epoch: 10.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20405131489373868		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.20405131489373868 | validation: 0.21204429946339004]
	TIME [epoch: 10.3 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18239895053025937		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.18239895053025937 | validation: 0.2263825914571034]
	TIME [epoch: 10.3 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.198931800830985		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.198931800830985 | validation: 0.21381723886875556]
	TIME [epoch: 10.3 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1927093134500358		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.1927093134500358 | validation: 0.21336591829252954]
	TIME [epoch: 10.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20483592965983127		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.20483592965983127 | validation: 0.28735275521725034]
	TIME [epoch: 10.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21207285112011182		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.21207285112011182 | validation: 0.21537246736197213]
	TIME [epoch: 10.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18568706911234806		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.18568706911234806 | validation: 0.21323373416694597]
	TIME [epoch: 10.3 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18675521331298092		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.18675521331298092 | validation: 0.23516547097718055]
	TIME [epoch: 10.3 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20175596629891834		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.20175596629891834 | validation: 0.2703754360303725]
	TIME [epoch: 10.3 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19304653419045473		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.19304653419045473 | validation: 0.22243641999289346]
	TIME [epoch: 10.3 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21311291250677583		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.21311291250677583 | validation: 0.20482567969726206]
	TIME [epoch: 10.3 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2468615508207431		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.2468615508207431 | validation: 0.2490879442202367]
	TIME [epoch: 10.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2008697329784149		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.2008697329784149 | validation: 0.223927888822886]
	TIME [epoch: 10.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19748511949067193		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.19748511949067193 | validation: 0.2069119117137047]
	TIME [epoch: 10.3 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18906576916876378		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.18906576916876378 | validation: 0.21520103836281618]
	TIME [epoch: 10.3 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19696454968309304		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.19696454968309304 | validation: 0.2839561891864968]
	TIME [epoch: 10.3 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22110092179529853		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.22110092179529853 | validation: 0.27906411291253347]
	TIME [epoch: 10.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23473762677562768		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.23473762677562768 | validation: 0.23418300414203289]
	TIME [epoch: 10.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19295310236559876		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.19295310236559876 | validation: 0.2757136973156617]
	TIME [epoch: 10.3 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142672674069144		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.3142672674069144 | validation: 0.263149386052456]
	TIME [epoch: 10.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19490105388794227		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.19490105388794227 | validation: 0.23820020876346049]
	TIME [epoch: 10.3 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1963705118077761		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.1963705118077761 | validation: 0.2199278501514236]
	TIME [epoch: 10.3 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1874995725720559		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.1874995725720559 | validation: 0.23070022514449534]
	TIME [epoch: 10.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2038447120191754		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.2038447120191754 | validation: 0.23045148769142088]
	TIME [epoch: 10.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20002502312637338		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.20002502312637338 | validation: 0.2080122115626754]
	TIME [epoch: 10.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19020130716914896		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.19020130716914896 | validation: 0.20765491905517253]
	TIME [epoch: 10.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18633076314534192		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.18633076314534192 | validation: 0.24688413658489525]
	TIME [epoch: 10.3 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20338206966381608		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.20338206966381608 | validation: 0.2513706593943163]
	TIME [epoch: 10.3 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18943777896785355		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.18943777896785355 | validation: 0.24983933240960013]
	TIME [epoch: 10.3 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2129594843876194		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.2129594843876194 | validation: 0.23144524609167696]
	TIME [epoch: 10.3 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20354003071446147		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.20354003071446147 | validation: 0.23437830511833901]
	TIME [epoch: 10.3 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22391123651102687		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.22391123651102687 | validation: 0.30852623940350593]
	TIME [epoch: 10.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22909055099125436		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.22909055099125436 | validation: 0.25477998071296504]
	TIME [epoch: 10.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22386002343775963		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.22386002343775963 | validation: 0.21489994147845898]
	TIME [epoch: 10.3 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18587416885314983		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.18587416885314983 | validation: 0.20156710444744647]
	TIME [epoch: 10.3 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18719928532673835		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.18719928532673835 | validation: 0.2201679336109412]
	TIME [epoch: 10.3 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20321171489682444		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.20321171489682444 | validation: 0.19356464855821745]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1768.pth
	Model improved!!!
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20700555424605954		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.20700555424605954 | validation: 0.23724904862288312]
	TIME [epoch: 10.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22067325906853297		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.22067325906853297 | validation: 0.22608005185954302]
	TIME [epoch: 10.3 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18519490366912808		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.18519490366912808 | validation: 0.2103984797200495]
	TIME [epoch: 10.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18899289827315285		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.18899289827315285 | validation: 0.20894469641321117]
	TIME [epoch: 10.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1880237402165948		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.1880237402165948 | validation: 0.21585258518338055]
	TIME [epoch: 10.3 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18095170435994395		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.18095170435994395 | validation: 0.21610517238842192]
	TIME [epoch: 10.3 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21475551331712475		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.21475551331712475 | validation: 0.2337879064423314]
	TIME [epoch: 10.3 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19953640173297044		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.19953640173297044 | validation: 0.2424273707199359]
	TIME [epoch: 10.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19789882491709004		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.19789882491709004 | validation: 0.2265498740330326]
	TIME [epoch: 10.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19951844412136674		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.19951844412136674 | validation: 0.26087880458410284]
	TIME [epoch: 10.3 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20774102776199213		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.20774102776199213 | validation: 0.21531823259947505]
	TIME [epoch: 10.3 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18533429448890154		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.18533429448890154 | validation: 0.22523021227600246]
	TIME [epoch: 10.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17405250800229374		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.17405250800229374 | validation: 0.21464738247897777]
	TIME [epoch: 10.3 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19220746210713222		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.19220746210713222 | validation: 0.20240137088160434]
	TIME [epoch: 10.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20245999520502594		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.20245999520502594 | validation: 0.2365148252013784]
	TIME [epoch: 10.3 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2214841964127347		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.2214841964127347 | validation: 0.2147492140480573]
	TIME [epoch: 10.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18907674092255017		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.18907674092255017 | validation: 0.22087083699806775]
	TIME [epoch: 10.3 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18900732653172514		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.18900732653172514 | validation: 0.22662317656467662]
	TIME [epoch: 10.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20222167603907487		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.20222167603907487 | validation: 0.2585330731319474]
	TIME [epoch: 10.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19874218508356306		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.19874218508356306 | validation: 0.23367488949732504]
	TIME [epoch: 10.3 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21167771332923974		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.21167771332923974 | validation: 0.2507236763428969]
	TIME [epoch: 10.3 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20022148383765948		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.20022148383765948 | validation: 0.21225108650890803]
	TIME [epoch: 10.3 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18437087809829963		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.18437087809829963 | validation: 0.22014880488413976]
	TIME [epoch: 10.3 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1975268087525885		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.1975268087525885 | validation: 0.2110740450359801]
	TIME [epoch: 10.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17118751985331795		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.17118751985331795 | validation: 0.1926059375158414]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1793.pth
	Model improved!!!
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728719008552507		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.1728719008552507 | validation: 0.19275875309708915]
	TIME [epoch: 10.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1807661939877288		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.1807661939877288 | validation: 0.2160648130647792]
	TIME [epoch: 10.3 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19262949183125094		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.19262949183125094 | validation: 0.21709883935721558]
	TIME [epoch: 10.3 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19817523910940743		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.19817523910940743 | validation: 0.24010125845353686]
	TIME [epoch: 10.3 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19107752794174124		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.19107752794174124 | validation: 0.20810062096553011]
	TIME [epoch: 10.3 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19486619697340166		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.19486619697340166 | validation: 0.22331226945436633]
	TIME [epoch: 10.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18408352601693184		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.18408352601693184 | validation: 0.199902932877158]
	TIME [epoch: 10.3 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19056750147124876		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.19056750147124876 | validation: 0.2499023889369856]
	TIME [epoch: 10.3 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2038312957364385		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.2038312957364385 | validation: 0.22943608578412594]
	TIME [epoch: 10.3 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19924699600059687		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.19924699600059687 | validation: 0.20591646516211295]
	TIME [epoch: 10.3 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17761375809086014		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.17761375809086014 | validation: 0.23731591940619381]
	TIME [epoch: 10.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20499483988496556		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.20499483988496556 | validation: 0.2620296512959668]
	TIME [epoch: 10.3 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20623923018081536		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.20623923018081536 | validation: 0.24038702461568195]
	TIME [epoch: 10.3 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20279325726724878		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.20279325726724878 | validation: 0.2516495913936669]
	TIME [epoch: 10.3 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21142160458431208		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.21142160458431208 | validation: 0.2292949631479329]
	TIME [epoch: 10.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1948120595964744		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.1948120595964744 | validation: 0.21617078885756766]
	TIME [epoch: 10.3 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19151310056583518		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.19151310056583518 | validation: 0.2004414764266754]
	TIME [epoch: 10.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18603063341874376		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.18603063341874376 | validation: 0.2075682703118417]
	TIME [epoch: 10.3 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18916948457695112		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.18916948457695112 | validation: 0.21387266824840245]
	TIME [epoch: 10.3 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840610563283208		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.1840610563283208 | validation: 0.21039268745123502]
	TIME [epoch: 10.3 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18885141174161657		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.18885141174161657 | validation: 0.216827518726605]
	TIME [epoch: 10.3 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17473531670307677		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.17473531670307677 | validation: 0.22703742424030612]
	TIME [epoch: 10.3 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2436590706718297		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.2436590706718297 | validation: 0.23005453277625948]
	TIME [epoch: 10.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19732855768764174		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.19732855768764174 | validation: 0.22443547428950872]
	TIME [epoch: 10.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18116230587154136		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.18116230587154136 | validation: 0.19374513518923664]
	TIME [epoch: 10.3 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18627925318162603		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.18627925318162603 | validation: 0.25382403483444343]
	TIME [epoch: 10.3 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21295876773991443		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.21295876773991443 | validation: 0.22873522280491793]
	TIME [epoch: 10.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21022068331849048		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.21022068331849048 | validation: 0.22044709589762604]
	TIME [epoch: 10.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18433084491317708		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.18433084491317708 | validation: 0.2047102777665621]
	TIME [epoch: 10.3 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1979121783070692		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.1979121783070692 | validation: 0.23533466465811284]
	TIME [epoch: 10.3 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2109382529107136		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.2109382529107136 | validation: 0.1989138933732825]
	TIME [epoch: 10.3 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19368775880601716		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.19368775880601716 | validation: 0.27533755441831664]
	TIME [epoch: 10.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23253319697321345		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.23253319697321345 | validation: 0.23398538536858313]
	TIME [epoch: 10.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.191892472477426		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.191892472477426 | validation: 0.22724693201377177]
	TIME [epoch: 10.3 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21387187241922642		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.21387187241922642 | validation: 0.24464890640121378]
	TIME [epoch: 10.3 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19263439992579348		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.19263439992579348 | validation: 0.19531812710963067]
	TIME [epoch: 10.3 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1859294166640399		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.1859294166640399 | validation: 0.2152772165189979]
	TIME [epoch: 10.3 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1820067600828351		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.1820067600828351 | validation: 0.21979390302094742]
	TIME [epoch: 10.3 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19209918864143866		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.19209918864143866 | validation: 0.1935099891868479]
	TIME [epoch: 10.3 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1892540900283879		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.1892540900283879 | validation: 0.20622308414335735]
	TIME [epoch: 10.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19947633699855385		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.19947633699855385 | validation: 0.21652589702323188]
	TIME [epoch: 10.3 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1938326101616426		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.1938326101616426 | validation: 0.20220831137471024]
	TIME [epoch: 10.3 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21030919765656061		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.21030919765656061 | validation: 0.2656658892422435]
	TIME [epoch: 10.3 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26618070147656375		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.26618070147656375 | validation: 0.23021532642729248]
	TIME [epoch: 10.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1900820473131867		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.1900820473131867 | validation: 0.2094653232860049]
	TIME [epoch: 10.3 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1894585114569436		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.1894585114569436 | validation: 0.22192473305627253]
	TIME [epoch: 10.3 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2016721392372784		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.2016721392372784 | validation: 0.22004508924667782]
	TIME [epoch: 10.3 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20372120799281923		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.20372120799281923 | validation: 0.22061711197241976]
	TIME [epoch: 10.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20050634054348154		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.20050634054348154 | validation: 0.23482251561531514]
	TIME [epoch: 10.3 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20161109033522234		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.20161109033522234 | validation: 0.20596397388648657]
	TIME [epoch: 10.3 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22261508408482883		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.22261508408482883 | validation: 0.23912844212778694]
	TIME [epoch: 10.3 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2108285278513117		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.2108285278513117 | validation: 0.200030122481913]
	TIME [epoch: 10.3 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17639350409773097		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.17639350409773097 | validation: 0.2199167433567597]
	TIME [epoch: 10.2 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20291905468892		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.20291905468892 | validation: 0.22020761178790985]
	TIME [epoch: 10.2 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20553745259392783		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.20553745259392783 | validation: 0.21142178002562317]
	TIME [epoch: 10.2 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18231250786559433		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.18231250786559433 | validation: 0.24269704651691273]
	TIME [epoch: 10.2 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19810756922602268		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.19810756922602268 | validation: 0.21275909226240936]
	TIME [epoch: 10.2 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18745563325760048		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.18745563325760048 | validation: 0.21728188892531944]
	TIME [epoch: 10.2 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18794458920290663		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.18794458920290663 | validation: 0.2148274426461208]
	TIME [epoch: 10.2 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20059258330403845		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.20059258330403845 | validation: 0.23501194615373727]
	TIME [epoch: 10.2 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21098476048623388		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.21098476048623388 | validation: 0.22077663762886957]
	TIME [epoch: 10.2 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18479089393499168		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.18479089393499168 | validation: 0.20402238046962873]
	TIME [epoch: 10.2 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.182594882593523		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.182594882593523 | validation: 0.1884765475432372]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1856.pth
	Model improved!!!
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1829927144012436		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.1829927144012436 | validation: 0.2085341701210949]
	TIME [epoch: 10.2 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18221542049319675		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.18221542049319675 | validation: 0.22661877128352345]
	TIME [epoch: 10.2 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19930199762303863		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.19930199762303863 | validation: 0.22439216137251883]
	TIME [epoch: 10.2 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1977362604594094		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.1977362604594094 | validation: 0.18427050729579347]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1860.pth
	Model improved!!!
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18437411232249884		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.18437411232249884 | validation: 0.2074965075994431]
	TIME [epoch: 10.2 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19567354119349267		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.19567354119349267 | validation: 0.27496297840245426]
	TIME [epoch: 10.2 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19896896197220576		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.19896896197220576 | validation: 0.22563628403297142]
	TIME [epoch: 10.2 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18633109553710342		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.18633109553710342 | validation: 0.24253609774073828]
	TIME [epoch: 10.2 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19088279502757835		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.19088279502757835 | validation: 0.23964261279159288]
	TIME [epoch: 10.2 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18350018982305966		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.18350018982305966 | validation: 0.24339738869713237]
	TIME [epoch: 10.2 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27055862198125125		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.27055862198125125 | validation: 0.2740431150476173]
	TIME [epoch: 10.2 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21120104783035135		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.21120104783035135 | validation: 0.24907850196739795]
	TIME [epoch: 10.2 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20080166951274583		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.20080166951274583 | validation: 0.2506752965760971]
	TIME [epoch: 10.2 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20067162755487863		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.20067162755487863 | validation: 0.23197478828147863]
	TIME [epoch: 10.2 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19338792183232134		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.19338792183232134 | validation: 0.22054436138629455]
	TIME [epoch: 10.2 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1842527223402046		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.1842527223402046 | validation: 0.2685565956901564]
	TIME [epoch: 10.2 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20126551170975487		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.20126551170975487 | validation: 0.22103628716173573]
	TIME [epoch: 10.2 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1830139325159968		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.1830139325159968 | validation: 0.20682570410467635]
	TIME [epoch: 10.2 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18851906505962515		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.18851906505962515 | validation: 0.27097814758317756]
	TIME [epoch: 10.2 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21167964643452514		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.21167964643452514 | validation: 0.21635321466923954]
	TIME [epoch: 10.2 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17926776282556414		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.17926776282556414 | validation: 0.22018767583438248]
	TIME [epoch: 10.2 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789007498156784		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.1789007498156784 | validation: 0.203038672322439]
	TIME [epoch: 10.2 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20548111104574107		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.20548111104574107 | validation: 0.22674953696747943]
	TIME [epoch: 10.2 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1929688922977894		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.1929688922977894 | validation: 0.27361925500242307]
	TIME [epoch: 10.2 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21399153537395482		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.21399153537395482 | validation: 0.24488648248834557]
	TIME [epoch: 10.2 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20073841752980873		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.20073841752980873 | validation: 0.24575266191062134]
	TIME [epoch: 10.2 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21222485836500712		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.21222485836500712 | validation: 0.24018244847272624]
	TIME [epoch: 10.2 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19528381422735894		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.19528381422735894 | validation: 0.20539870976544505]
	TIME [epoch: 10.2 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785907188288575		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.1785907188288575 | validation: 0.2286306280898122]
	TIME [epoch: 10.2 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1839691450879476		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.1839691450879476 | validation: 0.21142343707345518]
	TIME [epoch: 10.2 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21524193296771882		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.21524193296771882 | validation: 0.22554563764780391]
	TIME [epoch: 10.2 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.190548590466969		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.190548590466969 | validation: 0.22404299158327146]
	TIME [epoch: 10.2 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1946054530308642		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.1946054530308642 | validation: 0.22423661028742026]
	TIME [epoch: 10.2 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19951294134629696		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.19951294134629696 | validation: 0.21674423629685524]
	TIME [epoch: 10.2 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694262502046916		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.18694262502046916 | validation: 0.2079799572479791]
	TIME [epoch: 10.2 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18374007771330927		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.18374007771330927 | validation: 0.20404171526972967]
	TIME [epoch: 10.2 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18204795941207905		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.18204795941207905 | validation: 0.21065059241481382]
	TIME [epoch: 10.3 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18173790750666502		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.18173790750666502 | validation: 0.2134476054268303]
	TIME [epoch: 10.2 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2167555115860889		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.2167555115860889 | validation: 0.209929408255839]
	TIME [epoch: 10.2 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19262504620547008		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.19262504620547008 | validation: 0.21025941279196023]
	TIME [epoch: 10.2 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1926078097620569		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.1926078097620569 | validation: 0.25909838786858685]
	TIME [epoch: 10.2 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2040376828359805		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.2040376828359805 | validation: 0.19639472688406276]
	TIME [epoch: 10.2 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19423208927131544		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.19423208927131544 | validation: 0.21452147894420223]
	TIME [epoch: 10.2 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16816757608219562		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.16816757608219562 | validation: 0.2187184380780112]
	TIME [epoch: 10.2 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17798884939502665		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.17798884939502665 | validation: 0.2659485755662666]
	TIME [epoch: 10.2 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24729753172633498		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.24729753172633498 | validation: 0.24370531027659553]
	TIME [epoch: 10.2 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20672846797683514		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.20672846797683514 | validation: 0.20314267187825308]
	TIME [epoch: 10.2 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19011337641973794		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.19011337641973794 | validation: 0.20859113519428576]
	TIME [epoch: 10.2 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17582224354055662		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.17582224354055662 | validation: 0.2161835000200612]
	TIME [epoch: 10.2 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18427684604302116		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.18427684604302116 | validation: 0.19973633593536863]
	TIME [epoch: 10.2 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1842788306491527		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.1842788306491527 | validation: 0.2268497509781276]
	TIME [epoch: 10.2 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19341545865566379		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.19341545865566379 | validation: 0.22009397913121365]
	TIME [epoch: 10.2 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1871342543905324		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.1871342543905324 | validation: 0.21226862906145294]
	TIME [epoch: 10.2 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19570118445879345		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.19570118445879345 | validation: 0.23894934071714943]
	TIME [epoch: 10.2 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1986784853262378		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.1986784853262378 | validation: 0.22894854568129433]
	TIME [epoch: 10.2 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1847528153181796		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.1847528153181796 | validation: 0.21125859724203058]
	TIME [epoch: 10.2 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2151501999558098		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.2151501999558098 | validation: 0.25917574425498036]
	TIME [epoch: 10.2 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19658705525908496		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.19658705525908496 | validation: 0.19985633369950465]
	TIME [epoch: 10.2 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18753480946824136		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.18753480946824136 | validation: 0.18557054470855053]
	TIME [epoch: 10.2 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1877329527471202		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.1877329527471202 | validation: 0.2017989335903669]
	TIME [epoch: 10.2 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18756901339161963		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.18756901339161963 | validation: 0.22498054446261836]
	TIME [epoch: 10.2 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18322326076532655		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.18322326076532655 | validation: 0.22950949135224222]
	TIME [epoch: 10.2 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771645544114438		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.1771645544114438 | validation: 0.2115569036315009]
	TIME [epoch: 10.2 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18861584180512386		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.18861584180512386 | validation: 0.2628742011825321]
	TIME [epoch: 10.2 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20261993670436795		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.20261993670436795 | validation: 0.19472075691824117]
	TIME [epoch: 10.2 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17935326135371604		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.17935326135371604 | validation: 0.20365840763651913]
	TIME [epoch: 10.2 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1912432923695624		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.1912432923695624 | validation: 0.20789213627393138]
	TIME [epoch: 10.2 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1796837146973783		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.1796837146973783 | validation: 0.22298864588779732]
	TIME [epoch: 10.2 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711664304968048		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.1711664304968048 | validation: 0.20187452670780126]
	TIME [epoch: 10.2 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17906136643911133		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.17906136643911133 | validation: 0.19575095913306528]
	TIME [epoch: 10.2 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1847300808305518		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.1847300808305518 | validation: 0.2273907972219026]
	TIME [epoch: 10.2 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21560034765605157		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.21560034765605157 | validation: 0.20526783105139992]
	TIME [epoch: 10.2 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18326972409522144		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.18326972409522144 | validation: 0.18824336506106953]
	TIME [epoch: 10.2 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765703964781962		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.1765703964781962 | validation: 0.21299634076199628]
	TIME [epoch: 10.2 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720923263238276		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.1720923263238276 | validation: 0.20492146877145032]
	TIME [epoch: 10.2 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17838776938744774		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.17838776938744774 | validation: 0.21097877307363916]
	TIME [epoch: 10.2 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18347247938388983		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.18347247938388983 | validation: 0.23593430161199208]
	TIME [epoch: 10.2 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19149653124206356		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.19149653124206356 | validation: 0.22840018520307437]
	TIME [epoch: 10.2 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.186748769656553		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.186748769656553 | validation: 0.2067604698822759]
	TIME [epoch: 10.2 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19469079889483926		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.19469079889483926 | validation: 0.2619693796605211]
	TIME [epoch: 10.2 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.216211911800931		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.216211911800931 | validation: 0.21882817269579385]
	TIME [epoch: 10.2 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853627184687692		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.1853627184687692 | validation: 0.23754216987291293]
	TIME [epoch: 10.2 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19497468721542077		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.19497468721542077 | validation: 0.21339411192473642]
	TIME [epoch: 10.2 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20405756676816736		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.20405756676816736 | validation: 0.20478620555875296]
	TIME [epoch: 10.2 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18555324017448027		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.18555324017448027 | validation: 0.19773154554816927]
	TIME [epoch: 10.2 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17737835371537317		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.17737835371537317 | validation: 0.21956013523480256]
	TIME [epoch: 10.2 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17475950463105333		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.17475950463105333 | validation: 0.19569664219206598]
	TIME [epoch: 10.2 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18001267891046382		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.18001267891046382 | validation: 0.2198452364638677]
	TIME [epoch: 10.2 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17958956214938016		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.17958956214938016 | validation: 0.21300613199209995]
	TIME [epoch: 10.2 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18003955746159744		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.18003955746159744 | validation: 0.20534111237746147]
	TIME [epoch: 10.2 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17604087327129073		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.17604087327129073 | validation: 0.21611413695353002]
	TIME [epoch: 10.2 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1780251991019939		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.1780251991019939 | validation: 0.2226721784422921]
	TIME [epoch: 10.2 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18264641049042887		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.18264641049042887 | validation: 0.19873549005205834]
	TIME [epoch: 10.2 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19575195517091182		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.19575195517091182 | validation: 0.22412976016722128]
	TIME [epoch: 10.2 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17851991659621338		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.17851991659621338 | validation: 0.21299659222859105]
	TIME [epoch: 10.2 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19608331055434708		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.19608331055434708 | validation: 0.20784206829298835]
	TIME [epoch: 10.2 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17539742109126316		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.17539742109126316 | validation: 0.20571205140497748]
	TIME [epoch: 10.2 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17868374425071082		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.17868374425071082 | validation: 0.21132534082693943]
	TIME [epoch: 10.2 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19201422740927565		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.19201422740927565 | validation: 0.23753450650169725]
	TIME [epoch: 10.2 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18274174909443977		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.18274174909443977 | validation: 0.2271684337862448]
	TIME [epoch: 10.2 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20399025905198181		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.20399025905198181 | validation: 0.2510943311562814]
	TIME [epoch: 10.2 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1932663808488704		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.1932663808488704 | validation: 0.2409393135593254]
	TIME [epoch: 10.2 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2197911384421428		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.2197911384421428 | validation: 0.23132290020673285]
	TIME [epoch: 10.2 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19387695375601166		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.19387695375601166 | validation: 0.2336077610805588]
	TIME [epoch: 10.2 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19828838370030982		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.19828838370030982 | validation: 0.23542674979767353]
	TIME [epoch: 10.2 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20142022065651705		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.20142022065651705 | validation: 0.2182154575597012]
	TIME [epoch: 10.2 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18526374781439595		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.18526374781439595 | validation: 0.20841484698578477]
	TIME [epoch: 10.2 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1883068654088595		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.1883068654088595 | validation: 0.2767720069140744]
	TIME [epoch: 10.2 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19154791154621048		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.19154791154621048 | validation: 0.20150068335774948]
	TIME [epoch: 10.2 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911236342023054		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.1911236342023054 | validation: 0.20266477945014433]
	TIME [epoch: 10.2 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17670018445070976		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.17670018445070976 | validation: 0.213666830111328]
	TIME [epoch: 10.2 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18056389267073794		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.18056389267073794 | validation: 0.18229225192103535]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240219_190144/states/model_tr_study6_1968.pth
	Model improved!!!
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19853203329853994		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.19853203329853994 | validation: 0.22604374805535757]
	TIME [epoch: 10.2 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18487353314039595		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.18487353314039595 | validation: 0.2272341122738615]
	TIME [epoch: 10.2 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1895213465820314		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.1895213465820314 | validation: 0.2064879379049303]
	TIME [epoch: 10.2 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18066891402625093		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.18066891402625093 | validation: 0.19852256662450665]
	TIME [epoch: 10.2 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1957862639439476		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.1957862639439476 | validation: 0.2003769944229979]
	TIME [epoch: 10.2 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18586962658461864		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.18586962658461864 | validation: 0.22105734846266104]
	TIME [epoch: 10.2 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17764984186188548		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.17764984186188548 | validation: 0.18565047648270513]
	TIME [epoch: 10.2 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19044860463704708		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.19044860463704708 | validation: 0.2330111955327633]
	TIME [epoch: 10.2 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1788957969093895		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.1788957969093895 | validation: 0.20782696397292907]
	TIME [epoch: 10.2 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19256857691116108		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.19256857691116108 | validation: 0.20807566011363313]
	TIME [epoch: 10.2 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1942409698234749		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.1942409698234749 | validation: 0.21245140290604744]
	TIME [epoch: 10.2 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853369250407227		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.1853369250407227 | validation: 0.20219337404252685]
	TIME [epoch: 10.2 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19746178472626838		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.19746178472626838 | validation: 0.20514078009980627]
	TIME [epoch: 10.2 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17638566285373988		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.17638566285373988 | validation: 0.2143562824613351]
	TIME [epoch: 10.2 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1686865282892425		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.1686865282892425 | validation: 0.23330024980285888]
	TIME [epoch: 10.2 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18959467680355183		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.18959467680355183 | validation: 0.22502226546041823]
	TIME [epoch: 10.2 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1987271079749484		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.1987271079749484 | validation: 0.24606575134323252]
	TIME [epoch: 10.2 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1945179507326123		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.1945179507326123 | validation: 0.22748010414196707]
	TIME [epoch: 10.2 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18395346493999293		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.18395346493999293 | validation: 0.21997000591076205]
	TIME [epoch: 10.2 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19737949555334863		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.19737949555334863 | validation: 0.21333035143275234]
	TIME [epoch: 10.2 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17993935856502746		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.17993935856502746 | validation: 0.2099017592929786]
	TIME [epoch: 10.2 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837532736183057		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.1837532736183057 | validation: 0.19555003383652436]
	TIME [epoch: 10.2 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18611358740164183		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.18611358740164183 | validation: 0.21611656167966917]
	TIME [epoch: 10.2 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18696010790690604		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.18696010790690604 | validation: 0.1998067204715998]
	TIME [epoch: 10.2 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17632728550590945		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.17632728550590945 | validation: 0.2352703364137375]
	TIME [epoch: 10.2 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2056837916230009		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.2056837916230009 | validation: 0.2255835699467074]
	TIME [epoch: 10.2 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19874603726932955		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.19874603726932955 | validation: 0.23847529897994693]
	TIME [epoch: 10.2 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2448776798811127		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.2448776798811127 | validation: 0.3422218618632137]
	TIME [epoch: 10.2 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29339297536737513		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.29339297536737513 | validation: 0.24260997581383728]
	TIME [epoch: 10.2 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19782731060216138		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.19782731060216138 | validation: 0.18259080200543082]
	TIME [epoch: 10.2 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18721292183387073		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.18721292183387073 | validation: 0.2259682905147283]
	TIME [epoch: 10.2 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18266955316589856		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.18266955316589856 | validation: 0.2248332517686103]
	TIME [epoch: 10.2 sec]
Finished training in 20702.111 seconds.
