Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2843672262

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.791681629168078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.791681629168078 | validation: 7.620976408609277]
	TIME [epoch: 80.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.569387086008248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.569387086008248 | validation: 9.291718547645809]
	TIME [epoch: 9.77 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.958846477741003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.958846477741003 | validation: 6.2589075412867965]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.578052066335094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.578052066335094 | validation: 6.531607046799319]
	TIME [epoch: 9.76 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6683828408944965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6683828408944965 | validation: 6.12933664165501]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.319301370708722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.319301370708722 | validation: 5.667000758184376]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.257338802232133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.257338802232133 | validation: 5.523127885697529]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.299201226420033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.299201226420033 | validation: 5.8574882972658555]
	TIME [epoch: 9.75 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.343454652609282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.343454652609282 | validation: 5.839077206489142]
	TIME [epoch: 9.74 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.322472172422382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.322472172422382 | validation: 6.639564530875321]
	TIME [epoch: 9.74 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.364398807941162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.364398807941162 | validation: 5.459477441198187]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.977720239681004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.977720239681004 | validation: 6.264198548425526]
	TIME [epoch: 9.75 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6790166446319095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6790166446319095 | validation: 8.726710023302003]
	TIME [epoch: 9.74 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.421941288197582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.421941288197582 | validation: 5.6237917005175495]
	TIME [epoch: 9.74 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.043830787568397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.043830787568397 | validation: 6.271859398904346]
	TIME [epoch: 9.76 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.312109713136946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.312109713136946 | validation: 5.780364999651827]
	TIME [epoch: 9.73 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.176935850216082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.176935850216082 | validation: 5.5965192568805024]
	TIME [epoch: 9.74 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.361124646011145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.361124646011145 | validation: 5.800607203489377]
	TIME [epoch: 9.74 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.2943200785979965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2943200785979965 | validation: 5.759995138086403]
	TIME [epoch: 9.76 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.282220313669467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.282220313669467 | validation: 6.341502525154237]
	TIME [epoch: 9.73 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.53443950129787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.53443950129787 | validation: 5.803172348516893]
	TIME [epoch: 9.73 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.670256517880413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.670256517880413 | validation: 7.121553089268237]
	TIME [epoch: 9.76 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.220642133549383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.220642133549383 | validation: 5.430224234252419]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.965651927955433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.965651927955433 | validation: 6.1122940378388675]
	TIME [epoch: 9.73 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9276905818072505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9276905818072505 | validation: 5.602283282334845]
	TIME [epoch: 9.74 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.337834814769392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.337834814769392 | validation: 6.098764144164561]
	TIME [epoch: 9.76 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.202705497009651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.202705497009651 | validation: 5.647421876700595]
	TIME [epoch: 9.74 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.954660462673194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.954660462673194 | validation: 5.4767041793536775]
	TIME [epoch: 9.74 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.298448000714223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.298448000714223 | validation: 5.913317893979998]
	TIME [epoch: 9.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.259123677164949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.259123677164949 | validation: 5.6817149326824055]
	TIME [epoch: 9.76 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.597526629500668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.597526629500668 | validation: 5.500092155174002]
	TIME [epoch: 9.74 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3912054050872005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3912054050872005 | validation: 5.830903148020991]
	TIME [epoch: 9.74 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.862645798409439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.862645798409439 | validation: 6.011818978170937]
	TIME [epoch: 9.76 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.007558930487003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.007558930487003 | validation: 5.352146814308517]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.757986182733461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.757986182733461 | validation: 5.314713973798381]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.585746295656111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.585746295656111 | validation: 5.1807572529095625]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.651161626030158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.651161626030158 | validation: 5.091989534209766]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.049964052425475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.049964052425475 | validation: 6.787386746342251]
	TIME [epoch: 9.73 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.510418168551769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.510418168551769 | validation: 4.130739763803559]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5392617843704715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5392617843704715 | validation: 3.7932542090869292]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.636015735874096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.636015735874096 | validation: 3.997433570482304]
	TIME [epoch: 9.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.496429652904313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.496429652904313 | validation: 3.881974445384937]
	TIME [epoch: 9.74 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9887673428428814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9887673428428814 | validation: 3.6842234087379104]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.873058464223174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.873058464223174 | validation: 4.444586087354124]
	TIME [epoch: 9.77 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.611351809150263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.611351809150263 | validation: 6.90194729987523]
	TIME [epoch: 9.74 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.360195675200939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.360195675200939 | validation: 3.521454681608312]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.516740974915827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.516740974915827 | validation: 7.517846605571362]
	TIME [epoch: 9.74 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.397331923671261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.397331923671261 | validation: 3.5292345982176436]
	TIME [epoch: 9.76 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.534202640067018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.534202640067018 | validation: 5.683970262909899]
	TIME [epoch: 9.74 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.404539056220015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.404539056220015 | validation: 5.032693982497774]
	TIME [epoch: 9.74 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.495096548567583		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 5.495096548567583 | validation: 5.320651581538587]
	TIME [epoch: 9.75 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.150246885177575		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 4.150246885177575 | validation: 3.489999323951439]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.986054091431319		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 4.986054091431319 | validation: 7.29601600350706]
	TIME [epoch: 9.73 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.187908607746683		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 6.187908607746683 | validation: 4.705128709168441]
	TIME [epoch: 9.74 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.683322875395881		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 4.683322875395881 | validation: 4.177589024874284]
	TIME [epoch: 9.77 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.413901953752434		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 5.413901953752434 | validation: 6.341059472113498]
	TIME [epoch: 9.74 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.851574622681381		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 5.851574622681381 | validation: 6.562522263604948]
	TIME [epoch: 9.73 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.601567332985519		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 5.601567332985519 | validation: 4.562819045736046]
	TIME [epoch: 9.73 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.421300989372195		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 4.421300989372195 | validation: 4.6677538209001925]
	TIME [epoch: 9.76 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.165367313028677		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 5.165367313028677 | validation: 5.070931927894535]
	TIME [epoch: 9.74 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.278467377722502		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 6.278467377722502 | validation: 5.980289929604922]
	TIME [epoch: 9.74 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5216541182658005		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 5.5216541182658005 | validation: 5.720612542803308]
	TIME [epoch: 9.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.163973159889194		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 5.163973159889194 | validation: 5.12269653889807]
	TIME [epoch: 9.76 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.12143256440684		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 5.12143256440684 | validation: 5.01818195888924]
	TIME [epoch: 9.74 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.469443807728658		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 4.469443807728658 | validation: 4.004830263924897]
	TIME [epoch: 9.74 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9144279459863496		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 3.9144279459863496 | validation: 3.5046591786372936]
	TIME [epoch: 9.76 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.585660136140812		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 5.585660136140812 | validation: 8.871502401998992]
	TIME [epoch: 9.74 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.496854621231032		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 7.496854621231032 | validation: 6.718831663565322]
	TIME [epoch: 9.72 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.621432761957723		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 6.621432761957723 | validation: 6.22712280093455]
	TIME [epoch: 9.71 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.16541486816274		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 6.16541486816274 | validation: 6.715099728563906]
	TIME [epoch: 9.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.780485012819809		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 5.780485012819809 | validation: 4.943218848396837]
	TIME [epoch: 9.74 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.179642284138927		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 4.179642284138927 | validation: 3.357117212591242]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3670499438098664		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 3.3670499438098664 | validation: 3.032598788636787]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.023148442913793		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 3.023148442913793 | validation: 3.419454835848744]
	TIME [epoch: 9.75 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.18041709237895		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 3.18041709237895 | validation: 3.15251074680699]
	TIME [epoch: 9.71 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.839533476988064		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 4.839533476988064 | validation: 5.8731017011948765]
	TIME [epoch: 9.72 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.660720506579885		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 5.660720506579885 | validation: 4.969224289649029]
	TIME [epoch: 9.74 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9328112715478936		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 3.9328112715478936 | validation: 3.4462321926797395]
	TIME [epoch: 9.72 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.33806149322806		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 3.33806149322806 | validation: 4.041750383214712]
	TIME [epoch: 9.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.155535137930772		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 3.155535137930772 | validation: 3.4705872023838866]
	TIME [epoch: 9.72 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0749564472529025		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 3.0749564472529025 | validation: 3.1834503958500044]
	TIME [epoch: 9.74 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0759084729314004		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 3.0759084729314004 | validation: 3.0270560254505394]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9216466803463748		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 2.9216466803463748 | validation: 3.01846417600118]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.893699711928897		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 2.893699711928897 | validation: 3.2671001504912556]
	TIME [epoch: 9.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9894953267610704		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 2.9894953267610704 | validation: 3.090114195491268]
	TIME [epoch: 9.73 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.950480512780376		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 2.950480512780376 | validation: 3.067785879667771]
	TIME [epoch: 9.72 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.921985701945335		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 2.921985701945335 | validation: 3.102503424192422]
	TIME [epoch: 9.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.952869386686063		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 2.952869386686063 | validation: 3.3597110502092553]
	TIME [epoch: 9.72 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9925612933159984		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 2.9925612933159984 | validation: 3.2111477679277574]
	TIME [epoch: 9.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9896356897827525		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 2.9896356897827525 | validation: 3.1539821724731634]
	TIME [epoch: 9.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9536896323518156		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 2.9536896323518156 | validation: 3.11200778694835]
	TIME [epoch: 9.74 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.899250322072736		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 2.899250322072736 | validation: 2.9610427499383487]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.048881474241079		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 3.048881474241079 | validation: 3.1243361413502924]
	TIME [epoch: 9.74 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8938373999427514		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 2.8938373999427514 | validation: 3.216781202507423]
	TIME [epoch: 9.76 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8953447220099515		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 2.8953447220099515 | validation: 2.9386155201601265]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8851141296628753		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 2.8851141296628753 | validation: 2.9133232830271782]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3304644596052406		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 3.3304644596052406 | validation: 4.392558508381801]
	TIME [epoch: 9.76 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.580757399481584		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 3.580757399481584 | validation: 3.515948010897746]
	TIME [epoch: 9.74 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3576251783504594		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 3.3576251783504594 | validation: 2.96414675542346]
	TIME [epoch: 9.73 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2467559149324194		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 3.2467559149324194 | validation: 3.6903562344149736]
	TIME [epoch: 9.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.228651655233667		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 3.228651655233667 | validation: 3.0775905964593124]
	TIME [epoch: 9.75 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.534416846673255		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 3.534416846673255 | validation: 4.11597377832581]
	TIME [epoch: 9.73 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.498302967774118		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 3.498302967774118 | validation: 3.1972900589248265]
	TIME [epoch: 9.74 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4272674434806247		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 3.4272674434806247 | validation: 3.1329195216789025]
	TIME [epoch: 9.75 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5492752563086984		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 4.5492752563086984 | validation: 4.30810656567135]
	TIME [epoch: 9.73 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.656577000457588		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 3.656577000457588 | validation: 3.268248455314452]
	TIME [epoch: 9.72 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3490386869455024		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 3.3490386869455024 | validation: 3.46260742778164]
	TIME [epoch: 9.74 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.169642433577894		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 3.169642433577894 | validation: 2.9939281080487583]
	TIME [epoch: 9.75 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.956220084343362		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 2.956220084343362 | validation: 3.2988026765464658]
	TIME [epoch: 9.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.953964734113966		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 2.953964734113966 | validation: 2.950227297853147]
	TIME [epoch: 9.73 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.976606697057103		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 2.976606697057103 | validation: 3.159497298674487]
	TIME [epoch: 9.76 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2784622624156525		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 3.2784622624156525 | validation: 3.7364268690622073]
	TIME [epoch: 9.73 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2545245734027106		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 3.2545245734027106 | validation: 3.261918586428862]
	TIME [epoch: 9.73 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9256731700748113		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 2.9256731700748113 | validation: 3.0666583665028133]
	TIME [epoch: 9.75 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9053053004696876		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 2.9053053004696876 | validation: 3.3913518718887]
	TIME [epoch: 9.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.009125924406066		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 3.009125924406066 | validation: 2.994810101172801]
	TIME [epoch: 9.73 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.864993785879107		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 2.864993785879107 | validation: 3.2390967796484573]
	TIME [epoch: 9.73 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.088356169917796		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 3.088356169917796 | validation: 3.207600336872243]
	TIME [epoch: 9.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9190522000446775		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 2.9190522000446775 | validation: 2.969663417091764]
	TIME [epoch: 9.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.093284683654396		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 3.093284683654396 | validation: 3.9549931127091527]
	TIME [epoch: 9.73 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1788329056649056		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 3.1788329056649056 | validation: 2.9059665315843644]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.924201639967171		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 2.924201639967171 | validation: 3.388466195924891]
	TIME [epoch: 9.73 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0830215178604865		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 3.0830215178604865 | validation: 3.042045084808436]
	TIME [epoch: 9.72 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6464342221939745		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 3.6464342221939745 | validation: 3.046959728681845]
	TIME [epoch: 9.74 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.019711291447673		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 3.019711291447673 | validation: 3.0723168620803736]
	TIME [epoch: 9.74 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0808380829925177		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 3.0808380829925177 | validation: 3.070909655358791]
	TIME [epoch: 9.73 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8830793917616377		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 2.8830793917616377 | validation: 2.9571038715905167]
	TIME [epoch: 9.74 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.912250675335982		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 2.912250675335982 | validation: 4.4260637999692225]
	TIME [epoch: 9.76 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4088471451500113		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 3.4088471451500113 | validation: 4.116194281007775]
	TIME [epoch: 9.73 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.495144640460325		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 4.495144640460325 | validation: 5.657118019902447]
	TIME [epoch: 9.73 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.967395694300792		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 4.967395694300792 | validation: 4.827710094276398]
	TIME [epoch: 9.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.763090042570736		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 4.763090042570736 | validation: 5.712885958889837]
	TIME [epoch: 9.73 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.967760334669629		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 4.967760334669629 | validation: 4.916140651256115]
	TIME [epoch: 9.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6927520965368865		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 5.6927520965368865 | validation: 5.997423607889957]
	TIME [epoch: 9.72 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.1928367343681225		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 5.1928367343681225 | validation: 5.05598442233019]
	TIME [epoch: 9.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.118785332366197		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 5.118785332366197 | validation: 4.981620578111532]
	TIME [epoch: 9.72 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3518030549946625		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 4.3518030549946625 | validation: 4.841555819318476]
	TIME [epoch: 9.73 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.168032531030248		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 4.168032531030248 | validation: 4.104709580636767]
	TIME [epoch: 9.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.968925731803627		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 3.968925731803627 | validation: 4.001215909786056]
	TIME [epoch: 9.73 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4006271478209187		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 3.4006271478209187 | validation: 3.3397466140680234]
	TIME [epoch: 9.73 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.93841909977433		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 3.93841909977433 | validation: 3.652399679202649]
	TIME [epoch: 9.73 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6644414827322835		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 3.6644414827322835 | validation: 3.8063039209973626]
	TIME [epoch: 9.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.524274945380962		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 3.524274945380962 | validation: 4.673310313255789]
	TIME [epoch: 9.73 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.559229508144996		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 3.559229508144996 | validation: 3.3089821007479845]
	TIME [epoch: 9.72 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2510549607872634		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 3.2510549607872634 | validation: 3.0288162818333424]
	TIME [epoch: 9.76 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.575970942935818		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 3.575970942935818 | validation: 2.954393581702764]
	TIME [epoch: 9.73 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0350768414497984		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 3.0350768414497984 | validation: 2.8823541921999327]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.881885123373869		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 2.881885123373869 | validation: 3.385835141471779]
	TIME [epoch: 9.75 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0212683754080603		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 3.0212683754080603 | validation: 3.7740198976064137]
	TIME [epoch: 9.73 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.556205347467471		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 3.556205347467471 | validation: 4.650605193401086]
	TIME [epoch: 9.73 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.696511560595085		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 3.696511560595085 | validation: 3.145817301774871]
	TIME [epoch: 9.73 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.87043047969685		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 2.87043047969685 | validation: 3.0502114625506955]
	TIME [epoch: 9.74 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9519571464094296		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 2.9519571464094296 | validation: 2.84726528313898]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7594763947930825		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 2.7594763947930825 | validation: 2.9024334293071576]
	TIME [epoch: 9.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8618593864955413		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 2.8618593864955413 | validation: 2.919232584778387]
	TIME [epoch: 9.75 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7435548123173237		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 2.7435548123173237 | validation: 2.9634480617695784]
	TIME [epoch: 9.72 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.180305257090626		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 3.180305257090626 | validation: 3.0712965128032623]
	TIME [epoch: 9.72 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0978863602782436		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 3.0978863602782436 | validation: 3.558232044053467]
	TIME [epoch: 9.73 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1039165070033428		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 3.1039165070033428 | validation: 2.9089482900409305]
	TIME [epoch: 9.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.761080455858674		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 2.761080455858674 | validation: 2.836306155942225]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6634528919091065		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 2.6634528919091065 | validation: 2.905808122341333]
	TIME [epoch: 9.72 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4853768114443		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 3.4853768114443 | validation: 5.873919571643276]
	TIME [epoch: 9.74 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9503098732689588		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 3.9503098732689588 | validation: 3.3550989857336377]
	TIME [epoch: 9.72 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.054850005473466		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 3.054850005473466 | validation: 2.9034425493293874]
	TIME [epoch: 9.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8399685268701576		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 2.8399685268701576 | validation: 2.889655008556973]
	TIME [epoch: 9.74 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.751082444414583		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 2.751082444414583 | validation: 2.976161652473586]
	TIME [epoch: 9.73 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7516981572417576		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 2.7516981572417576 | validation: 2.947301494045853]
	TIME [epoch: 9.71 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9193061605060047		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 2.9193061605060047 | validation: 2.8086021738115123]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.776831690561267		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 2.776831690561267 | validation: 2.838842652824303]
	TIME [epoch: 9.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8206368290073853		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 2.8206368290073853 | validation: 3.4939038021140916]
	TIME [epoch: 9.72 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0070594154808012		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 3.0070594154808012 | validation: 3.1325430365688622]
	TIME [epoch: 9.72 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7456490082732357		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 2.7456490082732357 | validation: 2.8176979478210757]
	TIME [epoch: 9.75 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6747650024980603		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 2.6747650024980603 | validation: 3.3006281797576826]
	TIME [epoch: 9.71 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.867330147478743		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 2.867330147478743 | validation: 2.8935031704140695]
	TIME [epoch: 9.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.810451494802173		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 2.810451494802173 | validation: 2.91209566090786]
	TIME [epoch: 9.74 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3369416013295803		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 3.3369416013295803 | validation: 3.6588190876181144]
	TIME [epoch: 9.72 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1095622437084334		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 3.1095622437084334 | validation: 2.9158654919176747]
	TIME [epoch: 9.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7522011793323293		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 2.7522011793323293 | validation: 2.8580893346248852]
	TIME [epoch: 9.72 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8687346896800694		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 2.8687346896800694 | validation: 2.814089734485597]
	TIME [epoch: 9.74 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.717946000408263		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 2.717946000408263 | validation: 3.4621952998292205]
	TIME [epoch: 9.72 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0411755011604704		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 3.0411755011604704 | validation: 2.971460496432111]
	TIME [epoch: 9.71 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8790948336790096		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 2.8790948336790096 | validation: 3.2583914732905512]
	TIME [epoch: 9.74 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.811506307775659		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 2.811506307775659 | validation: 2.819613472518113]
	TIME [epoch: 9.72 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6346122129397505		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 2.6346122129397505 | validation: 2.9081729238913487]
	TIME [epoch: 9.72 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6767192743597876		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 2.6767192743597876 | validation: 3.087030820219534]
	TIME [epoch: 9.73 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7252911631848598		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 2.7252911631848598 | validation: 2.9500729905550656]
	TIME [epoch: 9.74 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0768408470201374		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 3.0768408470201374 | validation: 3.3124207300013087]
	TIME [epoch: 9.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.830287663452707		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 2.830287663452707 | validation: 3.35384583300935]
	TIME [epoch: 9.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8424810773243463		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 2.8424810773243463 | validation: 2.9629467111415715]
	TIME [epoch: 9.75 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.745805444272625		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 2.745805444272625 | validation: 3.0124547940169624]
	TIME [epoch: 9.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9543250052596073		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 2.9543250052596073 | validation: 3.804042937291307]
	TIME [epoch: 9.72 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.098279830762393		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 3.098279830762393 | validation: 2.8498896344544473]
	TIME [epoch: 9.74 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7184114621294633		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 2.7184114621294633 | validation: 2.950083227698373]
	TIME [epoch: 9.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7166979931100306		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 2.7166979931100306 | validation: 3.0396282289800873]
	TIME [epoch: 9.72 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7049682559954875		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 2.7049682559954875 | validation: 2.8636925252279766]
	TIME [epoch: 9.72 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8052102691266727		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 2.8052102691266727 | validation: 2.988945868539456]
	TIME [epoch: 9.75 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8044619520074874		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 2.8044619520074874 | validation: 3.0618030742032842]
	TIME [epoch: 9.72 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6912978271253336		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 2.6912978271253336 | validation: 2.8045564546652346]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.738885348134327		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 2.738885348134327 | validation: 2.8417828532019396]
	TIME [epoch: 9.74 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3448979046279446		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 3.3448979046279446 | validation: 2.8672547446668557]
	TIME [epoch: 9.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.712599905436485		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 2.712599905436485 | validation: 3.0484787086237306]
	TIME [epoch: 9.71 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.761366220942295		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 2.761366220942295 | validation: 2.866438698789172]
	TIME [epoch: 9.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9520448004477333		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 2.9520448004477333 | validation: 3.045389452466327]
	TIME [epoch: 9.74 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7233004356682775		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 2.7233004356682775 | validation: 2.76955940992081]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6051900459373623		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 2.6051900459373623 | validation: 2.760622704820075]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7790906733023917		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 2.7790906733023917 | validation: 2.9987676662717453]
	TIME [epoch: 9.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7041580606232962		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 2.7041580606232962 | validation: 2.8930218478806924]
	TIME [epoch: 9.72 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7684182921043288		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 2.7684182921043288 | validation: 2.776287012155453]
	TIME [epoch: 9.71 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7003161925841477		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 2.7003161925841477 | validation: 2.7852695079785117]
	TIME [epoch: 9.73 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7611585443181026		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 2.7611585443181026 | validation: 2.7819259476538236]
	TIME [epoch: 9.71 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.625816343672253		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 2.625816343672253 | validation: 2.8549852927885877]
	TIME [epoch: 9.71 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7586957693209344		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 2.7586957693209344 | validation: 2.877540432233093]
	TIME [epoch: 9.72 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.681324887441039		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 2.681324887441039 | validation: 2.7689727142018548]
	TIME [epoch: 9.73 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6302084782940414		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.6302084782940414 | validation: 2.797211410890834]
	TIME [epoch: 9.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.693985317721555		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 2.693985317721555 | validation: 2.8492426443748182]
	TIME [epoch: 9.71 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6994721444139365		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 2.6994721444139365 | validation: 2.7685714592273354]
	TIME [epoch: 9.74 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6449639118823303		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 2.6449639118823303 | validation: 2.786078284990072]
	TIME [epoch: 9.71 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8294922006038368		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 2.8294922006038368 | validation: 3.0127430700941593]
	TIME [epoch: 9.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7072193434212024		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 2.7072193434212024 | validation: 2.8369417173946863]
	TIME [epoch: 9.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.654009007551494		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 2.654009007551494 | validation: 2.772092662064455]
	TIME [epoch: 9.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.785653504108132		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 2.785653504108132 | validation: 2.85343252225627]
	TIME [epoch: 9.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7368712733211176		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 2.7368712733211176 | validation: 3.071570160344483]
	TIME [epoch: 9.71 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.867921977606348		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 2.867921977606348 | validation: 3.0014565234025747]
	TIME [epoch: 9.73 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7058425913046698		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 2.7058425913046698 | validation: 2.8771835529393552]
	TIME [epoch: 9.71 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6973499261154834		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 2.6973499261154834 | validation: 2.86035612051954]
	TIME [epoch: 9.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.630805077690531		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 2.630805077690531 | validation: 2.78997022477651]
	TIME [epoch: 9.73 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6270985434483407		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 2.6270985434483407 | validation: 2.953369473903075]
	TIME [epoch: 9.72 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7249086264928617		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 2.7249086264928617 | validation: 2.992269432305211]
	TIME [epoch: 9.72 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7265322826178946		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 2.7265322826178946 | validation: 2.8114729351806425]
	TIME [epoch: 9.71 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.673872952827847		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 2.673872952827847 | validation: 2.8718034203298037]
	TIME [epoch: 9.74 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7340622393199596		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 2.7340622393199596 | validation: 3.1483218053004056]
	TIME [epoch: 9.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.701945722366274		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 2.701945722366274 | validation: 3.0896650111857458]
	TIME [epoch: 9.73 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.774188286931616		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 2.774188286931616 | validation: 2.819476727621571]
	TIME [epoch: 9.74 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6372560969412007		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 2.6372560969412007 | validation: 2.9967478378595303]
	TIME [epoch: 9.73 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7723482708096854		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 2.7723482708096854 | validation: 2.7092243171471186]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6729926216869044		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 2.6729926216869044 | validation: 2.9244194552859257]
	TIME [epoch: 9.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6595897924882457		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 2.6595897924882457 | validation: 2.883921039941398]
	TIME [epoch: 9.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.851197825884857		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 2.851197825884857 | validation: 2.8275808365134067]
	TIME [epoch: 9.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6639454420416357		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 2.6639454420416357 | validation: 2.7248735567363838]
	TIME [epoch: 9.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.704911898068599		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 2.704911898068599 | validation: 2.991387439735419]
	TIME [epoch: 9.77 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.658929951879935		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 2.658929951879935 | validation: 2.841970576613329]
	TIME [epoch: 9.73 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.639264799952415		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 2.639264799952415 | validation: 2.978481555886097]
	TIME [epoch: 9.74 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.659498598698687		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 2.659498598698687 | validation: 3.145916521958501]
	TIME [epoch: 9.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.940832817249057		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 3.940832817249057 | validation: 5.10726799602163]
	TIME [epoch: 9.74 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.153834305125145		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 5.153834305125145 | validation: 4.499200382773687]
	TIME [epoch: 9.74 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.029540535674918		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 5.029540535674918 | validation: 5.555788554651569]
	TIME [epoch: 9.74 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.408093219784709		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 4.408093219784709 | validation: 2.9302784306109273]
	TIME [epoch: 9.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6907160042243015		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 2.6907160042243015 | validation: 3.4673069310982174]
	TIME [epoch: 9.73 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.38433897095116		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 3.38433897095116 | validation: 2.984574576360216]
	TIME [epoch: 9.74 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6248666101639593		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 2.6248666101639593 | validation: 2.6420671466488894]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5034149872698626		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 2.5034149872698626 | validation: 2.739707840774069]
	TIME [epoch: 9.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6926947522823634		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 2.6926947522823634 | validation: 2.6376768418791414]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5112263202961267		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.5112263202961267 | validation: 2.7894259258463303]
	TIME [epoch: 9.75 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5562079695256954		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 2.5562079695256954 | validation: 3.028339959154994]
	TIME [epoch: 9.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7996593091687934		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 2.7996593091687934 | validation: 2.6298832619080845]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.566685931583076		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 2.566685931583076 | validation: 2.6522641601676935]
	TIME [epoch: 9.73 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7602623942612894		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 2.7602623942612894 | validation: 3.858555237473547]
	TIME [epoch: 9.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2391141480613905		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 3.2391141480613905 | validation: 2.974710339976665]
	TIME [epoch: 9.72 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.636095112268028		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 2.636095112268028 | validation: 2.6767699079829628]
	TIME [epoch: 9.72 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.666655342729845		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 2.666655342729845 | validation: 2.8410077092793773]
	TIME [epoch: 9.75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6268883938385224		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 2.6268883938385224 | validation: 2.809487737964697]
	TIME [epoch: 9.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.597389709853259		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 2.597389709853259 | validation: 2.803622978030426]
	TIME [epoch: 9.72 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7555228507545797		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 2.7555228507545797 | validation: 2.8738744354802055]
	TIME [epoch: 9.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.613301493087286		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 2.613301493087286 | validation: 2.775771508095677]
	TIME [epoch: 9.74 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6618121263820935		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 2.6618121263820935 | validation: 2.689494499424236]
	TIME [epoch: 9.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5848213451574633		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 2.5848213451574633 | validation: 2.628073883374908]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5862075525573145		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 2.5862075525573145 | validation: 2.6537053665464043]
	TIME [epoch: 9.75 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6174740849897375		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 2.6174740849897375 | validation: 2.690218777303761]
	TIME [epoch: 9.72 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4941137402679647		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 2.4941137402679647 | validation: 2.619208455216291]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5390140436352797		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 2.5390140436352797 | validation: 2.6769379177122268]
	TIME [epoch: 9.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6224386139652176		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 2.6224386139652176 | validation: 2.5306561007283936]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4630945399293305		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 2.4630945399293305 | validation: 2.7631642244771912]
	TIME [epoch: 9.72 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5264398238209376		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 2.5264398238209376 | validation: 2.5507247536338187]
	TIME [epoch: 9.72 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3361922151909185		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 2.3361922151909185 | validation: 3.3455907679066708]
	TIME [epoch: 9.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.387606927607206		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 3.387606927607206 | validation: 4.202569235550589]
	TIME [epoch: 9.72 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2089816500915185		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 3.2089816500915185 | validation: 3.1629629315201853]
	TIME [epoch: 9.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.85038229831413		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 2.85038229831413 | validation: 2.8995120983273344]
	TIME [epoch: 9.75 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7352901649748085		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 2.7352901649748085 | validation: 2.929002734252385]
	TIME [epoch: 9.72 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7634931335309605		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 2.7634931335309605 | validation: 2.9116615209381176]
	TIME [epoch: 9.72 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.037209902759873		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 4.037209902759873 | validation: 3.0175939970009296]
	TIME [epoch: 9.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.868240758036019		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 2.868240758036019 | validation: 3.0179173355251083]
	TIME [epoch: 9.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7751980618582914		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 2.7751980618582914 | validation: 3.528485902282534]
	TIME [epoch: 9.72 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1762634393709788		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 3.1762634393709788 | validation: 2.9109129295696663]
	TIME [epoch: 9.72 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4918155949528993		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 3.4918155949528993 | validation: 3.0172994069039327]
	TIME [epoch: 9.75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8124551326080693		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 2.8124551326080693 | validation: 3.0384798167734863]
	TIME [epoch: 9.71 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.881660600134355		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 2.881660600134355 | validation: 2.9621325213192575]
	TIME [epoch: 9.72 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8823498511059946		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 2.8823498511059946 | validation: 3.0883577451269133]
	TIME [epoch: 9.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.778705002497544		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 2.778705002497544 | validation: 3.1317602064005317]
	TIME [epoch: 9.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.208301617650603		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 4.208301617650603 | validation: 6.676685395678503]
	TIME [epoch: 9.72 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3321098106277205		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 4.3321098106277205 | validation: 3.0578300778605456]
	TIME [epoch: 9.72 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.776775631244752		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 2.776775631244752 | validation: 2.9882394589886894]
	TIME [epoch: 9.74 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8292240952459418		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 2.8292240952459418 | validation: 3.3556595982604827]
	TIME [epoch: 9.72 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9411654587859473		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 3.9411654587859473 | validation: 4.459357143557439]
	TIME [epoch: 9.72 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.898325385915546		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 3.898325385915546 | validation: 3.1928740047948625]
	TIME [epoch: 9.74 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.761893826428055		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 2.761893826428055 | validation: 3.0351416718033764]
	TIME [epoch: 9.71 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.637434052999075		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 2.637434052999075 | validation: 2.584560976761701]
	TIME [epoch: 9.71 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.492390821858023		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 2.492390821858023 | validation: 2.596654216779397]
	TIME [epoch: 9.73 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3959827283729616		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 2.3959827283729616 | validation: 2.6746198455407386]
	TIME [epoch: 9.73 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.394094022545157		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 2.394094022545157 | validation: 2.5067230749202674]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.64585481386245		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 2.64585481386245 | validation: 3.158221310484628]
	TIME [epoch: 9.72 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3523436308925647		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 2.3523436308925647 | validation: 2.3262902357430066]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.310290722482081		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 2.310290722482081 | validation: 2.6414254151149317]
	TIME [epoch: 9.71 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5181076791912753		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 2.5181076791912753 | validation: 2.6616238434126216]
	TIME [epoch: 9.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4128882022195066		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 2.4128882022195066 | validation: 2.3018465412039184]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0864476019458515		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 2.0864476019458515 | validation: 2.3830740110617588]
	TIME [epoch: 9.71 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3859049304728686		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 2.3859049304728686 | validation: 2.828210272885848]
	TIME [epoch: 9.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4961976840760736		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 2.4961976840760736 | validation: 2.866364541900962]
	TIME [epoch: 9.72 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4136131197940704		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 2.4136131197940704 | validation: 2.385259417220298]
	TIME [epoch: 9.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7381285559263735		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 2.7381285559263735 | validation: 3.0297527529639843]
	TIME [epoch: 9.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.766905593444997		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 2.766905593444997 | validation: 2.868392455310576]
	TIME [epoch: 9.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.610180285704372		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 2.610180285704372 | validation: 2.758722412957139]
	TIME [epoch: 9.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5678252669194257		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 2.5678252669194257 | validation: 2.7116461610618217]
	TIME [epoch: 9.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.601729072676698		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 2.601729072676698 | validation: 2.783480359165328]
	TIME [epoch: 9.71 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.620410378265551		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 2.620410378265551 | validation: 2.7180721937174406]
	TIME [epoch: 9.73 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5492183025733146		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 2.5492183025733146 | validation: 2.6380316688539205]
	TIME [epoch: 9.71 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.514362031280943		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 2.514362031280943 | validation: 2.711017737431657]
	TIME [epoch: 9.71 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.487404073322411		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 2.487404073322411 | validation: 2.5720388599813475]
	TIME [epoch: 9.71 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.624000605284316		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 2.624000605284316 | validation: 2.697946648945834]
	TIME [epoch: 9.74 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4961372861802706		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 2.4961372861802706 | validation: 2.630455164667895]
	TIME [epoch: 9.72 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.519965419558912		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 2.519965419558912 | validation: 2.6806469669543573]
	TIME [epoch: 9.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.476946177794775		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 2.476946177794775 | validation: 2.562854048751151]
	TIME [epoch: 9.73 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.487863423539742		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 2.487863423539742 | validation: 2.7305115183036106]
	TIME [epoch: 9.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3831731258446145		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 2.3831731258446145 | validation: 2.5538100007519366]
	TIME [epoch: 9.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.33375494734343		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 2.33375494734343 | validation: 2.3632055725801626]
	TIME [epoch: 9.71 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.476343314107016		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 2.476343314107016 | validation: 3.0920730249083523]
	TIME [epoch: 9.73 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.677510722422395		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 2.677510722422395 | validation: 3.2911034643054835]
	TIME [epoch: 9.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.875829721101625		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 3.875829721101625 | validation: 3.6521632760907927]
	TIME [epoch: 9.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9658780155387516		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 2.9658780155387516 | validation: 2.8789793844366933]
	TIME [epoch: 9.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.744299046525165		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 2.744299046525165 | validation: 3.0459747660144183]
	TIME [epoch: 9.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0965856502033504		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 3.0965856502033504 | validation: 3.0204999599030713]
	TIME [epoch: 9.72 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8263161957108607		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 2.8263161957108607 | validation: 3.4311504138145876]
	TIME [epoch: 9.73 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.823492805190928		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 3.823492805190928 | validation: 3.744512015625961]
	TIME [epoch: 9.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.427539142597387		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 3.427539142597387 | validation: 4.412390119644146]
	TIME [epoch: 9.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1844877819262423		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 3.1844877819262423 | validation: 3.2358281272714406]
	TIME [epoch: 9.71 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8353466933725966		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 2.8353466933725966 | validation: 2.94186192192363]
	TIME [epoch: 9.77 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1614186378706846		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 3.1614186378706846 | validation: 3.158376277480564]
	TIME [epoch: 9.73 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8266773498532527		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 2.8266773498532527 | validation: 2.943052785620838]
	TIME [epoch: 9.72 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7863621181504774		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 2.7863621181504774 | validation: 2.946211278856541]
	TIME [epoch: 9.75 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7993287392417363		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 2.7993287392417363 | validation: 2.9397100264892657]
	TIME [epoch: 9.72 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8112573524817623		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 2.8112573524817623 | validation: 3.148039804985401]
	TIME [epoch: 9.72 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7812891274435656		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 2.7812891274435656 | validation: 2.8580805698785707]
	TIME [epoch: 9.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9112987182029295		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 2.9112987182029295 | validation: 2.956590317908014]
	TIME [epoch: 9.73 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7903622073189736		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 2.7903622073189736 | validation: 3.1828864200292]
	TIME [epoch: 9.72 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8130298788010135		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 2.8130298788010135 | validation: 3.568504957691058]
	TIME [epoch: 9.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0015821235727462		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 3.0015821235727462 | validation: 2.3367625834806023]
	TIME [epoch: 9.74 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4870285000178862		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 2.4870285000178862 | validation: 2.8186256877900906]
	TIME [epoch: 9.72 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.160826139426419		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 3.160826139426419 | validation: 2.8802440019326343]
	TIME [epoch: 9.72 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.745739711733973		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 2.745739711733973 | validation: 2.931517818680795]
	TIME [epoch: 9.74 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.592323082847489		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 2.592323082847489 | validation: 2.701274775324251]
	TIME [epoch: 9.73 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.455082942585855		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 2.455082942585855 | validation: 2.3993220954695733]
	TIME [epoch: 9.72 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.367885266465586		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 2.367885266465586 | validation: 1.9473795700390881]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8163681656742945		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 1.8163681656742945 | validation: 2.534460068151322]
	TIME [epoch: 9.74 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.800244157746286		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 2.800244157746286 | validation: 2.8916695031015025]
	TIME [epoch: 9.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0029426826323573		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 3.0029426826323573 | validation: 3.080038848666618]
	TIME [epoch: 9.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.863640852539441		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 2.863640852539441 | validation: 2.953356030509445]
	TIME [epoch: 9.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.725982416315027		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 2.725982416315027 | validation: 2.9342168869444345]
	TIME [epoch: 9.71 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7763734509470828		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 2.7763734509470828 | validation: 3.0873151082143346]
	TIME [epoch: 9.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.730858562757837		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 2.730858562757837 | validation: 2.9784394827249945]
	TIME [epoch: 9.71 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.753002470359672		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 2.753002470359672 | validation: 3.0963950879512483]
	TIME [epoch: 9.72 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8624447248817892		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 2.8624447248817892 | validation: 2.99627750792758]
	TIME [epoch: 9.71 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.713349796988902		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 2.713349796988902 | validation: 2.9387929102105432]
	TIME [epoch: 9.71 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7207430392864986		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 2.7207430392864986 | validation: 2.891393674215536]
	TIME [epoch: 9.74 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.750354528839171		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 2.750354528839171 | validation: 2.910036207738292]
	TIME [epoch: 9.71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6975795313530893		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 2.6975795313530893 | validation: 2.972709637441456]
	TIME [epoch: 9.71 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.699177317143671		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 2.699177317143671 | validation: 3.4356753573538588]
	TIME [epoch: 9.73 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6818109443240097		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 2.6818109443240097 | validation: 2.2055898325613263]
	TIME [epoch: 9.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6667530865175557		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 1.6667530865175557 | validation: 2.5546788360825463]
	TIME [epoch: 9.71 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8635960029740477		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 1.8635960029740477 | validation: 2.266573547382467]
	TIME [epoch: 9.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6940642779381563		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 1.6940642779381563 | validation: 1.8009301461062996]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4030158101712549		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.4030158101712549 | validation: 1.6556358026933682]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6830784814721294		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 1.6830784814721294 | validation: 1.6365690350392783]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.470764252349087		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 2.470764252349087 | validation: 1.836612793173185]
	TIME [epoch: 9.75 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0576739373843496		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 2.0576739373843496 | validation: 2.484738799923492]
	TIME [epoch: 9.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0058584137062905		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 3.0058584137062905 | validation: 2.060700921637604]
	TIME [epoch: 9.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.917194980274956		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 1.917194980274956 | validation: 2.260942553295635]
	TIME [epoch: 9.74 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7016421447376362		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 1.7016421447376362 | validation: 1.5527391649518365]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5748242692111607		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 1.5748242692111607 | validation: 1.7144374046404733]
	TIME [epoch: 9.72 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4602492326537908		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 1.4602492326537908 | validation: 2.13139739557835]
	TIME [epoch: 9.72 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2306113790525466		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 1.2306113790525466 | validation: 1.5715549066830223]
	TIME [epoch: 9.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.082120364370619		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 1.082120364370619 | validation: 1.2262181028947057]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9285645256728836		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.9285645256728836 | validation: 0.8027409210482835]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9403225069074412		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.9403225069074412 | validation: 1.1081545261627759]
	TIME [epoch: 9.76 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9968417099721748		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.9968417099721748 | validation: 0.8618271230863656]
	TIME [epoch: 9.72 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.014508493148945		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 1.014508493148945 | validation: 0.7723966534025789]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9142115703063098		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.9142115703063098 | validation: 0.7808779247479263]
	TIME [epoch: 9.74 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9216119817752857		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.9216119817752857 | validation: 0.71999925934935]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8969099208943883		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.8969099208943883 | validation: 1.4298227813547828]
	TIME [epoch: 9.72 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0874109704478014		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 1.0874109704478014 | validation: 0.8894252661601196]
	TIME [epoch: 9.72 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9540712612903587		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 0.9540712612903587 | validation: 0.8808559536348619]
	TIME [epoch: 9.74 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8520803945908316		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.8520803945908316 | validation: 1.45406794204478]
	TIME [epoch: 9.72 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9313407581683852		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.9313407581683852 | validation: 0.7560889055912122]
	TIME [epoch: 9.71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.76144799914082		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.76144799914082 | validation: 0.6253523727169957]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7843343443065993		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.7843343443065993 | validation: 1.3869946469409922]
	TIME [epoch: 9.72 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.03498961045551		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 1.03498961045551 | validation: 1.2092085512037398]
	TIME [epoch: 9.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2684518482999314		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 1.2684518482999314 | validation: 0.8847935293731543]
	TIME [epoch: 9.73 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8654531588345403		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.8654531588345403 | validation: 0.7376123851194057]
	TIME [epoch: 9.72 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7550628408347583		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.7550628408347583 | validation: 1.6687107356844586]
	TIME [epoch: 9.72 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0260309140914714		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 1.0260309140914714 | validation: 0.7263050507044898]
	TIME [epoch: 9.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8136348912635993		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.8136348912635993 | validation: 1.2561651628111024]
	TIME [epoch: 9.74 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9069954265368072		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.9069954265368072 | validation: 0.6848071243413816]
	TIME [epoch: 9.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8402239362911745		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.8402239362911745 | validation: 0.8324500334566594]
	TIME [epoch: 9.71 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1573623290270356		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 1.1573623290270356 | validation: 1.1565130851947565]
	TIME [epoch: 9.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8071407539569913		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.8071407539569913 | validation: 1.025332773953837]
	TIME [epoch: 9.72 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9450952854105756		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.9450952854105756 | validation: 0.7420891032192202]
	TIME [epoch: 9.72 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7339044872225334		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.7339044872225334 | validation: 0.6327594228239602]
	TIME [epoch: 9.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.788106488462099		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 0.788106488462099 | validation: 0.8322410724917413]
	TIME [epoch: 9.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9361808260199711		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.9361808260199711 | validation: 0.688718109301969]
	TIME [epoch: 9.71 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9668637411463573		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.9668637411463573 | validation: 0.9267638148711099]
	TIME [epoch: 9.71 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7156284225420511		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.7156284225420511 | validation: 1.1778754214458291]
	TIME [epoch: 9.74 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8347313725302152		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.8347313725302152 | validation: 0.6229520624035465]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7953123142883799		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.7953123142883799 | validation: 0.9320928437248667]
	TIME [epoch: 9.72 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3107951634290975		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 1.3107951634290975 | validation: 1.515889044154072]
	TIME [epoch: 9.73 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.871762907314598		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.871762907314598 | validation: 0.7174004822069401]
	TIME [epoch: 9.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2018144438754317		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 1.2018144438754317 | validation: 1.0483798146317411]
	TIME [epoch: 9.72 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8518749561235331		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 0.8518749561235331 | validation: 0.6817902467061704]
	TIME [epoch: 9.71 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7438615526558708		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.7438615526558708 | validation: 0.94162646566629]
	TIME [epoch: 9.74 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.884120027793205		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.884120027793205 | validation: 0.5597712537164455]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.811441932199586		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.811441932199586 | validation: 0.6112222567248164]
	TIME [epoch: 9.72 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6808859651966339		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.6808859651966339 | validation: 0.8205355411681342]
	TIME [epoch: 9.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.909056731639394		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 0.909056731639394 | validation: 0.642440256687107]
	TIME [epoch: 9.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7975617185993376		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 0.7975617185993376 | validation: 0.5513053773596898]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6459615059285261		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.6459615059285261 | validation: 0.5570661808792475]
	TIME [epoch: 9.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8737109029243735		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 0.8737109029243735 | validation: 0.6381963777593364]
	TIME [epoch: 9.73 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7612104914237656		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.7612104914237656 | validation: 0.6268598536486014]
	TIME [epoch: 9.72 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8561994525769947		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.8561994525769947 | validation: 1.1395492121555644]
	TIME [epoch: 9.71 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7714170848824768		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.7714170848824768 | validation: 0.9274043611754286]
	TIME [epoch: 9.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.772508777331471		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.772508777331471 | validation: 0.6629159148384726]
	TIME [epoch: 9.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7373468612833933		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.7373468612833933 | validation: 0.6036806110291865]
	TIME [epoch: 9.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7211469253481148		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.7211469253481148 | validation: 0.5867907039007697]
	TIME [epoch: 9.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0953813933514094		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 1.0953813933514094 | validation: 0.775783967197248]
	TIME [epoch: 9.73 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7424858701335741		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.7424858701335741 | validation: 0.5816749020049893]
	TIME [epoch: 9.73 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6936620018518711		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.6936620018518711 | validation: 0.7262217810016236]
	TIME [epoch: 9.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7996740302282912		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.7996740302282912 | validation: 0.6535871308563982]
	TIME [epoch: 9.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7835644569464003		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.7835644569464003 | validation: 0.5595181056377068]
	TIME [epoch: 9.72 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8161635889423376		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.8161635889423376 | validation: 0.5473403022898439]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9907596495034225		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.9907596495034225 | validation: 0.6799556113603743]
	TIME [epoch: 9.74 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7931832415255735		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.7931832415255735 | validation: 0.770877281863117]
	TIME [epoch: 9.72 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.704844929402709		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.704844929402709 | validation: 0.6442511759253062]
	TIME [epoch: 9.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7502896150991265		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.7502896150991265 | validation: 0.5710563545558714]
	TIME [epoch: 9.72 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.654025615514444		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.654025615514444 | validation: 3.425389934390285]
	TIME [epoch: 9.73 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.463653680538475		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 1.463653680538475 | validation: 0.5960954837337159]
	TIME [epoch: 9.72 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9580613673172167		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.9580613673172167 | validation: 0.7286879391001919]
	TIME [epoch: 9.72 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8197995984491321		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.8197995984491321 | validation: 0.7468935385434344]
	TIME [epoch: 9.74 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6653422643929933		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.6653422643929933 | validation: 1.0286613701598253]
	TIME [epoch: 9.71 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8629367080339503		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.8629367080339503 | validation: 0.9340821707904039]
	TIME [epoch: 9.71 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8700711454124603		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.8700711454124603 | validation: 0.849189825722469]
	TIME [epoch: 9.73 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7726828795464395		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.7726828795464395 | validation: 0.7590666432103487]
	TIME [epoch: 9.72 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8591177858823151		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.8591177858823151 | validation: 0.7572738920103538]
	TIME [epoch: 9.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6755931755243216		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.6755931755243216 | validation: 1.3210133943695794]
	TIME [epoch: 9.71 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1187076825590578		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 1.1187076825590578 | validation: 0.6566053916623148]
	TIME [epoch: 9.74 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7002262785017229		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.7002262785017229 | validation: 0.6117088907088631]
	TIME [epoch: 9.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7492995174006476		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.7492995174006476 | validation: 0.7220475136239819]
	TIME [epoch: 9.71 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8843276864915831		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.8843276864915831 | validation: 0.6343120362531488]
	TIME [epoch: 9.74 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6403606820070402		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.6403606820070402 | validation: 0.7787226216499485]
	TIME [epoch: 9.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7723467824295438		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 0.7723467824295438 | validation: 1.0404224459238771]
	TIME [epoch: 9.71 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8482186879563832		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.8482186879563832 | validation: 1.332690105975953]
	TIME [epoch: 9.72 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.941776726422602		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.941776726422602 | validation: 0.7536940442887397]
	TIME [epoch: 9.73 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6545152421456929		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.6545152421456929 | validation: 0.7985364729402656]
	TIME [epoch: 9.71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7277322699318411		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.7277322699318411 | validation: 1.3416971882084565]
	TIME [epoch: 9.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.957947230153328		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.957947230153328 | validation: 0.5576925433255431]
	TIME [epoch: 9.75 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6934596556550763		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.6934596556550763 | validation: 0.6405432209011093]
	TIME [epoch: 9.72 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7161350102101305		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.7161350102101305 | validation: 0.5108256505541522]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6624800862632574		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.6624800862632574 | validation: 0.6697763924510268]
	TIME [epoch: 9.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7695810915726891		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.7695810915726891 | validation: 1.0351688422614862]
	TIME [epoch: 9.72 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8006891516307049		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.8006891516307049 | validation: 0.8008301901902827]
	TIME [epoch: 9.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6288977145287455		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.6288977145287455 | validation: 0.6531142058101815]
	TIME [epoch: 9.72 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6451994157685872		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.6451994157685872 | validation: 0.5548290459058728]
	TIME [epoch: 9.73 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9378250872226411		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.9378250872226411 | validation: 0.7264688595589138]
	TIME [epoch: 9.72 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6687066387820758		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.6687066387820758 | validation: 0.5682062188856101]
	TIME [epoch: 9.71 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6634695389397554		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.6634695389397554 | validation: 1.4159254096849692]
	TIME [epoch: 9.73 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9108569698649405		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.9108569698649405 | validation: 1.0479428137910987]
	TIME [epoch: 9.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8201922057144365		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.8201922057144365 | validation: 1.367985585787325]
	TIME [epoch: 9.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9085503839812406		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.9085503839812406 | validation: 0.8162101680169613]
	TIME [epoch: 9.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6701002100615909		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.6701002100615909 | validation: 0.5986760907134173]
	TIME [epoch: 9.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897752949794437		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.5897752949794437 | validation: 0.5146927943401542]
	TIME [epoch: 9.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6375268866688584		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.6375268866688584 | validation: 0.5505846225518368]
	TIME [epoch: 9.71 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5929768659820938		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.5929768659820938 | validation: 1.0423530351774657]
	TIME [epoch: 9.73 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8825758568643373		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.8825758568643373 | validation: 1.0208497295969021]
	TIME [epoch: 9.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7599519811802132		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.7599519811802132 | validation: 0.6032944188557795]
	TIME [epoch: 9.71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7116209457021946		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.7116209457021946 | validation: 0.7907821769886146]
	TIME [epoch: 9.73 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6944213073348456		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.6944213073348456 | validation: 0.7507987091400489]
	TIME [epoch: 9.72 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6638509594289654		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.6638509594289654 | validation: 0.565399082020186]
	TIME [epoch: 9.72 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6518426446741956		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.6518426446741956 | validation: 0.4938741238631937]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.614258102868413		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.614258102868413 | validation: 0.6925981273115902]
	TIME [epoch: 9.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8531980402692021		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.8531980402692021 | validation: 0.8714810419057554]
	TIME [epoch: 9.72 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7012326275776489		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.7012326275776489 | validation: 0.6595514787601516]
	TIME [epoch: 9.72 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389677998982057		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.6389677998982057 | validation: 0.592232494191915]
	TIME [epoch: 9.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6847081560173129		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.6847081560173129 | validation: 0.8777287128664412]
	TIME [epoch: 9.72 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6228637025504818		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.6228637025504818 | validation: 0.6042124960768489]
	TIME [epoch: 9.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5794987260413795		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.5794987260413795 | validation: 0.5948749578589112]
	TIME [epoch: 9.72 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6004760117201201		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.6004760117201201 | validation: 0.6171746997233225]
	TIME [epoch: 9.73 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6102050962414637		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.6102050962414637 | validation: 0.5222971493966239]
	TIME [epoch: 9.72 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5794814040927985		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.5794814040927985 | validation: 0.7135468971218489]
	TIME [epoch: 9.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422016060036286		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.6422016060036286 | validation: 0.587392198051914]
	TIME [epoch: 9.74 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6970780532706632		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.6970780532706632 | validation: 0.7203573840565549]
	TIME [epoch: 9.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5981176054056428		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.5981176054056428 | validation: 0.6118133270388845]
	TIME [epoch: 9.72 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6656663439720727		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.6656663439720727 | validation: 0.5664499581807809]
	TIME [epoch: 9.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.550904700909695		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.550904700909695 | validation: 0.5078070128322912]
	TIME [epoch: 9.73 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7317188784498726		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.7317188784498726 | validation: 0.7815663859362968]
	TIME [epoch: 9.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1011790594669004		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 1.1011790594669004 | validation: 0.7617710941511537]
	TIME [epoch: 9.72 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5401461850568945		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.5401461850568945 | validation: 0.5540531463568534]
	TIME [epoch: 9.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5458356566866291		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.5458356566866291 | validation: 0.6561117250284886]
	TIME [epoch: 9.72 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6611072550014961		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.6611072550014961 | validation: 0.5364110247086312]
	TIME [epoch: 9.71 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7062849897941208		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.7062849897941208 | validation: 1.4999430061887002]
	TIME [epoch: 9.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7806505584361525		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.7806505584361525 | validation: 0.7593442019225839]
	TIME [epoch: 9.72 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243462363887847		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.5243462363887847 | validation: 0.4459053308226794]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9263810114768931		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.9263810114768931 | validation: 0.526892613580524]
	TIME [epoch: 9.72 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4908259579488933		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.4908259579488933 | validation: 0.46893552505285113]
	TIME [epoch: 9.73 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807971624117696		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.5807971624117696 | validation: 1.2078464830781832]
	TIME [epoch: 9.71 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997097784487434		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.6997097784487434 | validation: 0.4143886405615889]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5798648796255066		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.5798648796255066 | validation: 0.4712907685425222]
	TIME [epoch: 9.76 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8381042113239523		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.8381042113239523 | validation: 0.7309154620938361]
	TIME [epoch: 9.73 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475906139414329		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.6475906139414329 | validation: 0.6612653309300873]
	TIME [epoch: 9.73 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6466580208739312		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.6466580208739312 | validation: 0.6025153418953975]
	TIME [epoch: 9.74 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5486198694775638		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.5486198694775638 | validation: 0.5388319624800424]
	TIME [epoch: 9.73 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7118973493932649		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.7118973493932649 | validation: 0.5383384070054045]
	TIME [epoch: 9.72 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288021772865579		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.5288021772865579 | validation: 0.4773987470165722]
	TIME [epoch: 9.73 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6110963282112557		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.6110963282112557 | validation: 0.4895369099543337]
	TIME [epoch: 9.74 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5466146631592042		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.5466146631592042 | validation: 0.5609618275766445]
	TIME [epoch: 9.73 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407430843146797		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.5407430843146797 | validation: 0.5015246524558556]
	TIME [epoch: 9.72 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.521798072483903		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.521798072483903 | validation: 0.4593928509065677]
	TIME [epoch: 9.75 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5267298093257542		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.5267298093257542 | validation: 0.5444563377873384]
	TIME [epoch: 9.72 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300716319820423		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.5300716319820423 | validation: 0.9060087000991294]
	TIME [epoch: 9.73 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5685378057516756		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.5685378057516756 | validation: 0.8927909213763261]
	TIME [epoch: 9.73 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5611488802946643		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.5611488802946643 | validation: 0.7794936171824943]
	TIME [epoch: 9.73 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6081732069809191		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.6081732069809191 | validation: 0.5071419861672701]
	TIME [epoch: 9.72 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8426660598126483		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.8426660598126483 | validation: 0.9502665566849443]
	TIME [epoch: 9.72 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513244348691133		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.6513244348691133 | validation: 0.43464959479322957]
	TIME [epoch: 9.75 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5122342394039736		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.5122342394039736 | validation: 0.43984017728738084]
	TIME [epoch: 9.72 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5737002725962941		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.5737002725962941 | validation: 0.47679807509870886]
	TIME [epoch: 9.72 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.609816321927949		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.609816321927949 | validation: 0.8529199160554086]
	TIME [epoch: 9.75 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0500427651305366		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 1.0500427651305366 | validation: 0.5251780425435199]
	TIME [epoch: 9.73 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49629806218256906		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.49629806218256906 | validation: 0.3920577417116667]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0590517885930113		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 1.0590517885930113 | validation: 0.4687576250812886]
	TIME [epoch: 9.73 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53203546543171		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.53203546543171 | validation: 0.5104264552480577]
	TIME [epoch: 9.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280555925549231		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.5280555925549231 | validation: 0.5496559450881572]
	TIME [epoch: 9.72 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344882843795296		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.5344882843795296 | validation: 0.5358526003975093]
	TIME [epoch: 9.72 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5521898602138716		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.5521898602138716 | validation: 0.8167003091788001]
	TIME [epoch: 9.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6120138575869136		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.6120138575869136 | validation: 0.5079315360113009]
	TIME [epoch: 9.72 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47601837823199994		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.47601837823199994 | validation: 0.49760197790914157]
	TIME [epoch: 9.72 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624234541609187		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.5624234541609187 | validation: 0.5207683560530678]
	TIME [epoch: 9.74 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.457637152727172		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.457637152727172 | validation: 0.4907834906928557]
	TIME [epoch: 9.72 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5443938853855739		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.5443938853855739 | validation: 0.47630574817674565]
	TIME [epoch: 9.73 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4588585296507143		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.4588585296507143 | validation: 0.5235218610350946]
	TIME [epoch: 9.72 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5796544207368762		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.5796544207368762 | validation: 1.0434998824811157]
	TIME [epoch: 9.75 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200085215410581		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.6200085215410581 | validation: 0.7126652730344987]
	TIME [epoch: 9.72 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926889705115837		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.6926889705115837 | validation: 2.216022823439125]
	TIME [epoch: 9.72 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1459560823472383		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 1.1459560823472383 | validation: 0.458356209947159]
	TIME [epoch: 9.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44076856057157415		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.44076856057157415 | validation: 0.46379902555336106]
	TIME [epoch: 9.72 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.677027911279969		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.677027911279969 | validation: 0.778330576282635]
	TIME [epoch: 9.72 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001152321563742		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.6001152321563742 | validation: 0.7782388538238684]
	TIME [epoch: 9.73 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6743109145798953		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.6743109145798953 | validation: 0.572264462060012]
	TIME [epoch: 9.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.686776772495014		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.686776772495014 | validation: 0.5002932758745906]
	TIME [epoch: 9.72 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4112925751016777		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.4112925751016777 | validation: 0.5003487742138133]
	TIME [epoch: 9.72 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4438459922268786		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.4438459922268786 | validation: 0.3978012556917925]
	TIME [epoch: 9.75 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49513665839882837		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.49513665839882837 | validation: 0.5745658663810393]
	TIME [epoch: 9.72 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6041169692335178		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.6041169692335178 | validation: 0.6259641249297694]
	TIME [epoch: 9.72 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4521169392572764		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.4521169392572764 | validation: 0.47272550697179117]
	TIME [epoch: 9.73 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42777841365785624		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.42777841365785624 | validation: 0.3613926905215438]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4898422198149007		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.4898422198149007 | validation: 0.40996928925709414]
	TIME [epoch: 9.71 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42373893270619467		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.42373893270619467 | validation: 0.3967241297255479]
	TIME [epoch: 9.71 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7628508619869523		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.7628508619869523 | validation: 0.809000904684317]
	TIME [epoch: 9.73 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6059535968270258		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.6059535968270258 | validation: 0.39149667291942436]
	TIME [epoch: 9.71 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47434934012177515		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.47434934012177515 | validation: 0.45572298066075895]
	TIME [epoch: 9.71 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46753359666376026		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.46753359666376026 | validation: 0.5062134065874015]
	TIME [epoch: 9.73 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47586457904033647		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.47586457904033647 | validation: 0.4117975774645639]
	TIME [epoch: 9.72 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44410598844925264		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.44410598844925264 | validation: 0.397057876400477]
	TIME [epoch: 9.72 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4492123065439785		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.4492123065439785 | validation: 0.44579555431898854]
	TIME [epoch: 9.72 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49651451105685585		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.49651451105685585 | validation: 0.43382743339901736]
	TIME [epoch: 9.75 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4567051499388204		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.4567051499388204 | validation: 0.6287636020281017]
	TIME [epoch: 9.73 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.788329553270148		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.788329553270148 | validation: 0.7489068426604706]
	TIME [epoch: 9.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4600418128429268		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 0.4600418128429268 | validation: 0.4699757047169815]
	TIME [epoch: 9.75 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44858028241152204		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.44858028241152204 | validation: 0.7788281473085388]
	TIME [epoch: 9.73 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6874359046094203		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.6874359046094203 | validation: 0.5835580261005636]
	TIME [epoch: 9.74 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.619600856760421		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.619600856760421 | validation: 0.39547572248671303]
	TIME [epoch: 9.75 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42044150420227844		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.42044150420227844 | validation: 0.376318173415615]
	TIME [epoch: 9.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.433407085255166		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.433407085255166 | validation: 0.3777203784463872]
	TIME [epoch: 9.74 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975094279493239		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.5975094279493239 | validation: 0.8659185367180101]
	TIME [epoch: 9.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5468003995120745		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.5468003995120745 | validation: 0.367560419915895]
	TIME [epoch: 9.76 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43372608940048146		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.43372608940048146 | validation: 0.45386788137650685]
	TIME [epoch: 9.73 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41738191798191976		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.41738191798191976 | validation: 0.4376551206591803]
	TIME [epoch: 9.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47224104933212024		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.47224104933212024 | validation: 0.4059448893435924]
	TIME [epoch: 9.75 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49484880455469965		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.49484880455469965 | validation: 0.4853849053871731]
	TIME [epoch: 9.74 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046411838480409		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.5046411838480409 | validation: 0.40987726112608885]
	TIME [epoch: 9.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7875358689649146		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.7875358689649146 | validation: 0.4213514039242301]
	TIME [epoch: 9.74 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41063812446562753		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.41063812446562753 | validation: 0.3783319489980354]
	TIME [epoch: 9.75 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38787437710535916		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.38787437710535916 | validation: 0.37108102337865234]
	TIME [epoch: 9.73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40082405268468674		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.40082405268468674 | validation: 0.5070525286063263]
	TIME [epoch: 9.74 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44912806950252515		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.44912806950252515 | validation: 0.4006845959421154]
	TIME [epoch: 9.76 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4440580947285791		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.4440580947285791 | validation: 0.392211879223605]
	TIME [epoch: 9.73 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4012134334998033		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.4012134334998033 | validation: 0.44192869660342105]
	TIME [epoch: 9.74 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4161066555305992		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.4161066555305992 | validation: 0.36714110509010556]
	TIME [epoch: 9.75 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40187286144100903		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.40187286144100903 | validation: 0.6459329366018618]
	TIME [epoch: 9.74 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260502441200252		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.6260502441200252 | validation: 0.38856188322128987]
	TIME [epoch: 9.73 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42553786071308586		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.42553786071308586 | validation: 0.48748825219101466]
	TIME [epoch: 9.73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5144005895968088		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.5144005895968088 | validation: 0.43342368493999844]
	TIME [epoch: 9.76 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5603856828978918		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.5603856828978918 | validation: 0.44322499262749376]
	TIME [epoch: 9.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7467575341629218		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.7467575341629218 | validation: 0.39083528166862946]
	TIME [epoch: 9.73 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37832303004574197		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.37832303004574197 | validation: 0.6445670850077455]
	TIME [epoch: 9.76 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163296185120374		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.5163296185120374 | validation: 0.3906920257685216]
	TIME [epoch: 9.74 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882647163470315		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.3882647163470315 | validation: 0.3224628491755918]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3920947908746791		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.3920947908746791 | validation: 0.3497949294588234]
	TIME [epoch: 9.72 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47336748128791184		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.47336748128791184 | validation: 0.3852849082542254]
	TIME [epoch: 9.73 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43408091477062377		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.43408091477062377 | validation: 0.5961661498493351]
	TIME [epoch: 9.74 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535626432697354		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.535626432697354 | validation: 0.33395595547344675]
	TIME [epoch: 9.72 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45647348087084544		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.45647348087084544 | validation: 0.37543858577190087]
	TIME [epoch: 9.74 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44123246308917086		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.44123246308917086 | validation: 0.555266941921701]
	TIME [epoch: 9.72 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43539662511527133		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.43539662511527133 | validation: 0.39826160325760784]
	TIME [epoch: 9.71 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3651817641908436		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.3651817641908436 | validation: 0.3721257227660209]
	TIME [epoch: 9.74 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.350055683869207		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.350055683869207 | validation: 0.34431180033072856]
	TIME [epoch: 9.72 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3712415933850603		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.3712415933850603 | validation: 0.44983057091143525]
	TIME [epoch: 9.71 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3858859591714735		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.3858859591714735 | validation: 0.32203175837940834]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006363854423863		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.4006363854423863 | validation: 0.33792377706820487]
	TIME [epoch: 9.73 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616799822473281		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.4616799822473281 | validation: 0.3408668594224795]
	TIME [epoch: 9.72 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37832887832883155		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.37832887832883155 | validation: 0.32574634676043973]
	TIME [epoch: 9.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43363682476402066		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.43363682476402066 | validation: 0.5475546773800973]
	TIME [epoch: 9.73 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4314530555802925		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.4314530555802925 | validation: 0.2761580981716766]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33100011339452395		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.33100011339452395 | validation: 0.4919946796819396]
	TIME [epoch: 9.71 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4171326058225214		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.4171326058225214 | validation: 0.5690590786741813]
	TIME [epoch: 9.73 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5069520772029144		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.5069520772029144 | validation: 0.38192525971855407]
	TIME [epoch: 9.72 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931671091646122		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.3931671091646122 | validation: 0.387407656873316]
	TIME [epoch: 9.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4272272567559873		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.4272272567559873 | validation: 0.4028664092646125]
	TIME [epoch: 9.71 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42809448978439735		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.42809448978439735 | validation: 0.32324218620247236]
	TIME [epoch: 9.73 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3836142497236653		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.3836142497236653 | validation: 0.35422415936958246]
	TIME [epoch: 9.71 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35792287763946484		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.35792287763946484 | validation: 0.291850931224707]
	TIME [epoch: 9.71 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36407231576975757		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.36407231576975757 | validation: 0.4229233284710584]
	TIME [epoch: 9.73 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3646904931555092		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.3646904931555092 | validation: 0.4092961592156238]
	TIME [epoch: 9.71 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33384532771254827		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.33384532771254827 | validation: 0.29650377345150175]
	TIME [epoch: 9.71 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30094364917729016		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.30094364917729016 | validation: 0.3076684036158293]
	TIME [epoch: 9.71 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47446434817575317		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.47446434817575317 | validation: 0.3738065586727167]
	TIME [epoch: 9.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3422830502836371		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.3422830502836371 | validation: 0.37523840877052694]
	TIME [epoch: 9.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35579410926359994		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.35579410926359994 | validation: 0.5304642885469417]
	TIME [epoch: 9.71 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45394965591639813		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.45394965591639813 | validation: 0.32395627573644786]
	TIME [epoch: 9.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196504745621893		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.4196504745621893 | validation: 0.47661775912483756]
	TIME [epoch: 9.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3552082697029609		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.3552082697029609 | validation: 0.4738326533558581]
	TIME [epoch: 9.71 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5087293286647971		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.5087293286647971 | validation: 0.525921544352336]
	TIME [epoch: 9.72 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47767176536177525		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.47767176536177525 | validation: 0.3880871473781074]
	TIME [epoch: 9.71 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49332159007389154		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.49332159007389154 | validation: 0.44570759665009774]
	TIME [epoch: 9.71 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4927766897942737		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.4927766897942737 | validation: 0.3168196422603006]
	TIME [epoch: 9.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3617390764508565		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.3617390764508565 | validation: 0.6209498359234842]
	TIME [epoch: 9.73 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49618275192831085		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.49618275192831085 | validation: 0.3749630147529271]
	TIME [epoch: 9.71 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44122028408999		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.44122028408999 | validation: 0.3409765020869848]
	TIME [epoch: 9.71 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3546134810685774		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.3546134810685774 | validation: 0.32439379458115214]
	TIME [epoch: 9.73 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41418534184148026		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.41418534184148026 | validation: 0.29149238188259396]
	TIME [epoch: 9.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35462015401605307		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.35462015401605307 | validation: 0.536889766749388]
	TIME [epoch: 9.71 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3923037166460601		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.3923037166460601 | validation: 0.3224412472665328]
	TIME [epoch: 9.71 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3954619900612669		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.3954619900612669 | validation: 0.7090523389586262]
	TIME [epoch: 9.72 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5494737373407089		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.5494737373407089 | validation: 0.4349805182586546]
	TIME [epoch: 9.71 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3507413629310203		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.3507413629310203 | validation: 0.6012232308149018]
	TIME [epoch: 9.71 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45905026945267774		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.45905026945267774 | validation: 0.489016040711285]
	TIME [epoch: 9.73 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4702591562353143		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.4702591562353143 | validation: 0.5740454524725936]
	TIME [epoch: 9.71 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4189961096525189		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.4189961096525189 | validation: 0.2713502793741812]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_652.pth
	Model improved!!!
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3734693671940332		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.3734693671940332 | validation: 0.3456734577970934]
	TIME [epoch: 9.72 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37546811582268835		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.37546811582268835 | validation: 0.27869553520534124]
	TIME [epoch: 9.72 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32576863861873806		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.32576863861873806 | validation: 0.3404824264050053]
	TIME [epoch: 9.71 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42442989655591035		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.42442989655591035 | validation: 0.41877741394274004]
	TIME [epoch: 9.71 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3989102652997419		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.3989102652997419 | validation: 0.3763778807435051]
	TIME [epoch: 9.73 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.354590133729706		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.354590133729706 | validation: 0.48206337749380823]
	TIME [epoch: 9.72 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33898444978656894		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.33898444978656894 | validation: 0.2713409308102518]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33405234150303664		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.33405234150303664 | validation: 0.34694855706686456]
	TIME [epoch: 9.74 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38056836380100384		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.38056836380100384 | validation: 0.5607652686564175]
	TIME [epoch: 9.71 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.382593615530726		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.382593615530726 | validation: 0.38293819151061015]
	TIME [epoch: 9.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3760074950118832		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.3760074950118832 | validation: 0.4290304134203026]
	TIME [epoch: 9.71 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3491369243088273		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.3491369243088273 | validation: 0.2572859201783241]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2820859413452889		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.2820859413452889 | validation: 0.3478844206618409]
	TIME [epoch: 9.72 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4040060136203117		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.4040060136203117 | validation: 0.2951819582433174]
	TIME [epoch: 9.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47481531032859864		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.47481531032859864 | validation: 0.36263909295329727]
	TIME [epoch: 9.74 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31990855834455456		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.31990855834455456 | validation: 0.5110935191304737]
	TIME [epoch: 9.72 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43878154830155286		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.43878154830155286 | validation: 0.4038003093336164]
	TIME [epoch: 9.72 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35574758245821175		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.35574758245821175 | validation: 0.4559030397710837]
	TIME [epoch: 9.73 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41963204973385676		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.41963204973385676 | validation: 0.36752680055510767]
	TIME [epoch: 9.72 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38299006996776624		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.38299006996776624 | validation: 0.3463118804728837]
	TIME [epoch: 9.72 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37764926414088446		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.37764926414088446 | validation: 0.32243402320881365]
	TIME [epoch: 9.72 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3169316121261708		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.3169316121261708 | validation: 0.32638041168167164]
	TIME [epoch: 9.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3324228577734137		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.3324228577734137 | validation: 0.38414701977309235]
	TIME [epoch: 9.71 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3519776388175773		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.3519776388175773 | validation: 0.32546391022357923]
	TIME [epoch: 9.72 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34702265293066065		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.34702265293066065 | validation: 0.44276742496619104]
	TIME [epoch: 9.73 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41995297257039577		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.41995297257039577 | validation: 0.4605802836156462]
	TIME [epoch: 9.72 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3621281240708333		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.3621281240708333 | validation: 0.37053566501108565]
	TIME [epoch: 9.72 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3268099714694669		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.3268099714694669 | validation: 0.32753849071937313]
	TIME [epoch: 9.72 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34272518380457473		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.34272518380457473 | validation: 0.38111707517127685]
	TIME [epoch: 9.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40232595033217305		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.40232595033217305 | validation: 0.3714557498727959]
	TIME [epoch: 9.72 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3254030405166379		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.3254030405166379 | validation: 0.3324329601841906]
	TIME [epoch: 9.71 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.517476017044174		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.517476017044174 | validation: 0.3275652706773828]
	TIME [epoch: 9.74 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4831870970804205		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.4831870970804205 | validation: 0.25433644284172285]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_685.pth
	Model improved!!!
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30535507905040743		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.30535507905040743 | validation: 0.29294825848584]
	TIME [epoch: 9.71 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4462552266979598		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.4462552266979598 | validation: 0.35604355654231595]
	TIME [epoch: 9.73 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28363608615544933		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.28363608615544933 | validation: 0.28948181518049637]
	TIME [epoch: 9.71 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674874666138813		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.2674874666138813 | validation: 0.26327074001422657]
	TIME [epoch: 9.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2982661559087998		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.2982661559087998 | validation: 0.24317740605584726]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_690.pth
	Model improved!!!
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2866857113139994		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.2866857113139994 | validation: 0.34166476307862625]
	TIME [epoch: 9.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3460396544198622		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.3460396544198622 | validation: 0.5115703159714657]
	TIME [epoch: 9.72 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3399369637063429		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.3399369637063429 | validation: 0.5352615746759469]
	TIME [epoch: 9.72 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3410410576616579		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.3410410576616579 | validation: 0.36947842492118016]
	TIME [epoch: 9.75 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30318651461104584		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.30318651461104584 | validation: 0.3617794483258962]
	TIME [epoch: 9.73 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3019510692095734		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.3019510692095734 | validation: 0.3036042547231848]
	TIME [epoch: 9.72 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3234692815212248		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.3234692815212248 | validation: 0.2849902111152451]
	TIME [epoch: 9.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29551973606736454		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.29551973606736454 | validation: 0.5016932602474813]
	TIME [epoch: 9.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.365990565015515		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.365990565015515 | validation: 0.41278861757802465]
	TIME [epoch: 9.73 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39682781579382354		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.39682781579382354 | validation: 0.307665304757125]
	TIME [epoch: 9.72 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3247408011282486		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.3247408011282486 | validation: 0.4636742649918817]
	TIME [epoch: 9.74 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36167861379546606		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.36167861379546606 | validation: 0.32287494089892105]
	TIME [epoch: 9.73 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30280366654826496		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.30280366654826496 | validation: 0.24378901976484835]
	TIME [epoch: 9.73 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3014102338879783		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.3014102338879783 | validation: 0.6544729781385497]
	TIME [epoch: 9.74 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4118550319098982		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.4118550319098982 | validation: 0.32383187825286286]
	TIME [epoch: 9.73 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33024993196749364		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.33024993196749364 | validation: 0.37597562728675754]
	TIME [epoch: 9.73 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2840752500543468		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.2840752500543468 | validation: 0.2523419917561944]
	TIME [epoch: 9.73 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3039172645186121		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.3039172645186121 | validation: 0.3285863610805161]
	TIME [epoch: 9.75 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3178140595688887		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.3178140595688887 | validation: 0.2596473358493767]
	TIME [epoch: 9.73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925309892762358		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.2925309892762358 | validation: 0.3103762585543687]
	TIME [epoch: 9.72 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2847710522676344		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.2847710522676344 | validation: 0.22401700971854227]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_711.pth
	Model improved!!!
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3265805263315501		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.3265805263315501 | validation: 0.258457685634219]
	TIME [epoch: 9.72 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3769873839132879		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.3769873839132879 | validation: 0.23939034978937734]
	TIME [epoch: 9.72 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613611653992429		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.2613611653992429 | validation: 0.39319456338955844]
	TIME [epoch: 9.73 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3377484856180887		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.3377484856180887 | validation: 0.2939881144821002]
	TIME [epoch: 9.73 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37882817533302077		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.37882817533302077 | validation: 0.2521883531818111]
	TIME [epoch: 9.72 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31031856332713614		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.31031856332713614 | validation: 0.2952754838142078]
	TIME [epoch: 9.72 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2467252688866109		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.2467252688866109 | validation: 0.569512097648316]
	TIME [epoch: 9.75 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3560322441566076		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.3560322441566076 | validation: 0.2825784017750975]
	TIME [epoch: 9.72 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2612775800666137		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.2612775800666137 | validation: 0.2456073780574151]
	TIME [epoch: 9.72 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28172310810049345		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.28172310810049345 | validation: 0.3613003562935866]
	TIME [epoch: 9.74 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836186483696257		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.2836186483696257 | validation: 0.3050617336426016]
	TIME [epoch: 9.72 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24480869123701354		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.24480869123701354 | validation: 0.2649234016052234]
	TIME [epoch: 9.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28028233503425637		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.28028233503425637 | validation: 0.27468461573240016]
	TIME [epoch: 9.72 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2927320529215068		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.2927320529215068 | validation: 0.3815521268679732]
	TIME [epoch: 9.73 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37587294987694997		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.37587294987694997 | validation: 0.445621442012982]
	TIME [epoch: 9.72 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3228292771825448		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.3228292771825448 | validation: 0.30100610019541973]
	TIME [epoch: 9.71 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5136726381776693		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.5136726381776693 | validation: 0.39780963387696994]
	TIME [epoch: 9.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948714157414467		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.2948714157414467 | validation: 0.30130316054348866]
	TIME [epoch: 9.71 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34176619915011053		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.34176619915011053 | validation: 0.2541946210627571]
	TIME [epoch: 9.72 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3157125249291338		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.3157125249291338 | validation: 0.3467199365686603]
	TIME [epoch: 9.73 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3340479771596524		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.3340479771596524 | validation: 0.28733271394178894]
	TIME [epoch: 9.74 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3034895603066546		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.3034895603066546 | validation: 0.4955945478147243]
	TIME [epoch: 9.71 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305320910316972		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.305320910316972 | validation: 0.26389296933904566]
	TIME [epoch: 9.72 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22910258444869477		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.22910258444869477 | validation: 0.27173160806156543]
	TIME [epoch: 9.74 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33093226969301764		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.33093226969301764 | validation: 0.3013294238680221]
	TIME [epoch: 9.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30370472886030175		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.30370472886030175 | validation: 0.2569983525928765]
	TIME [epoch: 9.72 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27832778443624245		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.27832778443624245 | validation: 0.3280892775937812]
	TIME [epoch: 9.74 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33395029087998035		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.33395029087998035 | validation: 0.45510050633271726]
	TIME [epoch: 9.72 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28322837416162994		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.28322837416162994 | validation: 0.21479590004113477]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20632651414928596		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.20632651414928596 | validation: 0.2252828474189932]
	TIME [epoch: 9.73 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36370543236485553		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.36370543236485553 | validation: 0.32833463894246884]
	TIME [epoch: 9.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2525724899634298		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.2525724899634298 | validation: 0.36461357120064447]
	TIME [epoch: 9.72 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3252108991686925		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.3252108991686925 | validation: 0.2552974953086058]
	TIME [epoch: 9.73 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22128052413490282		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.22128052413490282 | validation: 0.3000882900975688]
	TIME [epoch: 9.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2816355278171085		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.2816355278171085 | validation: 0.40405903679983113]
	TIME [epoch: 9.73 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33227225383917747		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.33227225383917747 | validation: 0.26455032642801807]
	TIME [epoch: 9.73 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35131952069900524		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.35131952069900524 | validation: 0.29782401390828506]
	TIME [epoch: 9.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28267511429404435		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.28267511429404435 | validation: 0.22560905265678124]
	TIME [epoch: 9.73 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39152888346442466		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.39152888346442466 | validation: 0.4217314144707987]
	TIME [epoch: 9.73 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34927632635530304		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.34927632635530304 | validation: 0.7878231145876958]
	TIME [epoch: 9.73 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37470727177617974		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.37470727177617974 | validation: 0.35823373114368834]
	TIME [epoch: 9.75 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31590764278833416		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.31590764278833416 | validation: 0.23886083935718064]
	TIME [epoch: 9.73 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29774210014657077		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.29774210014657077 | validation: 0.2868609610669994]
	TIME [epoch: 9.73 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636934624201689		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.2636934624201689 | validation: 0.2904423268667495]
	TIME [epoch: 9.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34188493493432465		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.34188493493432465 | validation: 0.372452249585804]
	TIME [epoch: 9.72 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063407824687152		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.3063407824687152 | validation: 0.24007914482177126]
	TIME [epoch: 9.72 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40401284371055246		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.40401284371055246 | validation: 0.3898604797401608]
	TIME [epoch: 9.73 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34577715499122996		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.34577715499122996 | validation: 0.3734050270101809]
	TIME [epoch: 9.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34152314789195054		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.34152314789195054 | validation: 0.3463448927162359]
	TIME [epoch: 9.72 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3492821372345706		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.3492821372345706 | validation: 0.3481740771879492]
	TIME [epoch: 9.72 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33098896111263254		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.33098896111263254 | validation: 0.5159118707530113]
	TIME [epoch: 9.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3904633746806275		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.3904633746806275 | validation: 0.27125021295139456]
	TIME [epoch: 9.73 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3158027238818686		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.3158027238818686 | validation: 0.44369816003765233]
	TIME [epoch: 9.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30369707571492827		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.30369707571492827 | validation: 0.2550992094399337]
	TIME [epoch: 9.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3904064008946086		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.3904064008946086 | validation: 0.2981862780412913]
	TIME [epoch: 9.73 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31026677289683213		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.31026677289683213 | validation: 0.24437338791457783]
	TIME [epoch: 9.73 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24773137015839092		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.24773137015839092 | validation: 0.2895015706149882]
	TIME [epoch: 9.73 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29583669802366297		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.29583669802366297 | validation: 0.3022541094221555]
	TIME [epoch: 9.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2808586100474191		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.2808586100474191 | validation: 0.22543324258060835]
	TIME [epoch: 9.73 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2857823505438709		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.2857823505438709 | validation: 0.2753087345748644]
	TIME [epoch: 9.73 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28362569114140046		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.28362569114140046 | validation: 0.28128938564470424]
	TIME [epoch: 9.75 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588255968535308		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.2588255968535308 | validation: 0.3014291852157503]
	TIME [epoch: 9.73 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3186829971694074		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.3186829971694074 | validation: 0.23794360739558215]
	TIME [epoch: 9.73 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29785363255175434		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.29785363255175434 | validation: 0.3541780986040914]
	TIME [epoch: 9.73 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.247981334295927		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.247981334295927 | validation: 0.24752767151180588]
	TIME [epoch: 9.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32649803911076436		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.32649803911076436 | validation: 0.4883688984111806]
	TIME [epoch: 9.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3175884332338136		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.3175884332338136 | validation: 0.36657461964402394]
	TIME [epoch: 9.72 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24746288570970315		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.24746288570970315 | validation: 0.27885666729747566]
	TIME [epoch: 9.75 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681509897991189		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.2681509897991189 | validation: 0.22752310433216621]
	TIME [epoch: 9.72 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25007679035442376		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.25007679035442376 | validation: 0.3102255055173022]
	TIME [epoch: 9.77 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25253024337675606		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.25253024337675606 | validation: 0.21983184919382287]
	TIME [epoch: 9.75 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21052277668483338		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.21052277668483338 | validation: 0.26565796097562]
	TIME [epoch: 9.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2851591959714338		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.2851591959714338 | validation: 0.2707242998751371]
	TIME [epoch: 9.72 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.274424770266673		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.274424770266673 | validation: 0.3801364133495503]
	TIME [epoch: 9.72 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166304039488103		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.3166304039488103 | validation: 0.3036687522852546]
	TIME [epoch: 9.75 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2783466112766681		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.2783466112766681 | validation: 0.27135325913542174]
	TIME [epoch: 9.72 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24814163801415975		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.24814163801415975 | validation: 0.3497742116949489]
	TIME [epoch: 9.72 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2849031429800443		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.2849031429800443 | validation: 0.2789272481393168]
	TIME [epoch: 9.75 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2911401811725063		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.2911401811725063 | validation: 0.4754793113704077]
	TIME [epoch: 9.72 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3423074439709128		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.3423074439709128 | validation: 0.24826428522413305]
	TIME [epoch: 9.72 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27930915689848784		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.27930915689848784 | validation: 0.23623484493907454]
	TIME [epoch: 9.72 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2575255714231735		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.2575255714231735 | validation: 0.25223653923574313]
	TIME [epoch: 9.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21739596707586487		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.21739596707586487 | validation: 0.19356091435725772]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_794.pth
	Model improved!!!
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31219319535117507		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.31219319535117507 | validation: 0.42988854572868707]
	TIME [epoch: 9.72 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3435106657235384		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.3435106657235384 | validation: 0.3992184559000821]
	TIME [epoch: 9.74 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30966330372867457		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.30966330372867457 | validation: 0.2266912056438437]
	TIME [epoch: 9.72 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23845450830390685		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.23845450830390685 | validation: 0.219610332366419]
	TIME [epoch: 9.71 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2245818226919125		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.2245818226919125 | validation: 0.2461743013394087]
	TIME [epoch: 9.73 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21598629491836485		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.21598629491836485 | validation: 0.3227305738247482]
	TIME [epoch: 9.72 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23692862323566777		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.23692862323566777 | validation: 0.19576834544074465]
	TIME [epoch: 9.72 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22395844189734787		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.22395844189734787 | validation: 0.33502818169882126]
	TIME [epoch: 9.71 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2814650899875921		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.2814650899875921 | validation: 0.32391285223135363]
	TIME [epoch: 9.73 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26419648493914516		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.26419648493914516 | validation: 0.3116655493414922]
	TIME [epoch: 9.72 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2610116639899969		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.2610116639899969 | validation: 0.2798914443595483]
	TIME [epoch: 9.71 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25406630566915456		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.25406630566915456 | validation: 0.21218171909585554]
	TIME [epoch: 9.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22017498906917465		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.22017498906917465 | validation: 0.2528084731710073]
	TIME [epoch: 9.72 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20925045059299796		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.20925045059299796 | validation: 0.1969634833430986]
	TIME [epoch: 9.72 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2490282217043372		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.2490282217043372 | validation: 0.2051037598407391]
	TIME [epoch: 9.72 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2115855703583874		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.2115855703583874 | validation: 0.2508876066678196]
	TIME [epoch: 9.73 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25326432266964904		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.25326432266964904 | validation: 0.20862534770739558]
	TIME [epoch: 9.72 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26280358712636137		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.26280358712636137 | validation: 0.23269294002167804]
	TIME [epoch: 9.72 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.225440276435608		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.225440276435608 | validation: 0.22758440109178316]
	TIME [epoch: 9.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20179563739687428		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.20179563739687428 | validation: 0.20820201865044247]
	TIME [epoch: 9.72 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2630398115721705		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.2630398115721705 | validation: 0.31000446807719445]
	TIME [epoch: 9.71 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3505517470915059		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.3505517470915059 | validation: 0.3755116868583685]
	TIME [epoch: 9.73 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31402836439258686		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.31402836439258686 | validation: 0.28366180480756154]
	TIME [epoch: 9.72 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2258584212280867		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.2258584212280867 | validation: 0.18640924448865534]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2686680549839359		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.2686680549839359 | validation: 0.19092166246442366]
	TIME [epoch: 9.72 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2076481104297155		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.2076481104297155 | validation: 0.2048721744406911]
	TIME [epoch: 9.73 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2151441186903389		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.2151441186903389 | validation: 0.22310419715272733]
	TIME [epoch: 9.72 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25261190967074393		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.25261190967074393 | validation: 0.2178013234420236]
	TIME [epoch: 9.72 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30061046541860564		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.30061046541860564 | validation: 0.28401587592359046]
	TIME [epoch: 9.75 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394638006633935		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.2394638006633935 | validation: 0.1853300755105397]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24530620077459453		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.24530620077459453 | validation: 0.3742406629674775]
	TIME [epoch: 9.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037529339962426		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.3037529339962426 | validation: 0.4300102722958556]
	TIME [epoch: 9.72 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3753219643295741		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.3753219643295741 | validation: 0.29029643051944826]
	TIME [epoch: 9.72 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25619467482664493		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.25619467482664493 | validation: 0.22145934748320933]
	TIME [epoch: 9.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26091107096795396		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.26091107096795396 | validation: 0.381626531643353]
	TIME [epoch: 9.71 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2715785817036646		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.2715785817036646 | validation: 0.33083526844797917]
	TIME [epoch: 9.73 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26526665850674563		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.26526665850674563 | validation: 0.24603743453418925]
	TIME [epoch: 9.71 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3653425029771497		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.3653425029771497 | validation: 0.20017458490035295]
	TIME [epoch: 9.71 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26850759384066686		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.26850759384066686 | validation: 0.3750259092281322]
	TIME [epoch: 9.73 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30757122664876335		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.30757122664876335 | validation: 0.34550267707687826]
	TIME [epoch: 9.71 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31580878516172634		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.31580878516172634 | validation: 0.2529117515220364]
	TIME [epoch: 9.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4191773210616647		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.4191773210616647 | validation: 0.4227275307916581]
	TIME [epoch: 9.71 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35878362523001184		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.35878362523001184 | validation: 0.2224462067738957]
	TIME [epoch: 9.73 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22883114804458335		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.22883114804458335 | validation: 0.34978667882115694]
	TIME [epoch: 9.71 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3519893532052926		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.3519893532052926 | validation: 0.22162834258880146]
	TIME [epoch: 9.71 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23652047734228426		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.23652047734228426 | validation: 0.2575566510806971]
	TIME [epoch: 9.73 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24206238677546055		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.24206238677546055 | validation: 0.2192081691694124]
	TIME [epoch: 9.71 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2146138037212598		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.2146138037212598 | validation: 0.2623236693909696]
	TIME [epoch: 9.71 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29025516156151854		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.29025516156151854 | validation: 0.24386051099086342]
	TIME [epoch: 9.72 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23666013747486603		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.23666013747486603 | validation: 0.23125484971744237]
	TIME [epoch: 9.72 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23947893381681934		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.23947893381681934 | validation: 0.18540782315732485]
	TIME [epoch: 9.71 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2157710799388596		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.2157710799388596 | validation: 0.2714755999874975]
	TIME [epoch: 9.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23591588273627256		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.23591588273627256 | validation: 0.2783831591564009]
	TIME [epoch: 9.73 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27595730357718873		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.27595730357718873 | validation: 0.22848394412250492]
	TIME [epoch: 9.71 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2112283302752888		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.2112283302752888 | validation: 0.21101239574449815]
	TIME [epoch: 9.71 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21536820555616626		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.21536820555616626 | validation: 0.2237439953125471]
	TIME [epoch: 9.73 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23137050280768617		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.23137050280768617 | validation: 0.22413477710012136]
	TIME [epoch: 9.71 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24042280756620033		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.24042280756620033 | validation: 0.22147071243452504]
	TIME [epoch: 9.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23154666844255206		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.23154666844255206 | validation: 0.23320665052082937]
	TIME [epoch: 9.72 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20392358639981403		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.20392358639981403 | validation: 0.24097199882556333]
	TIME [epoch: 9.72 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30405152944899005		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.30405152944899005 | validation: 0.34161461476677185]
	TIME [epoch: 9.71 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581814664758082		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.2581814664758082 | validation: 0.25028067872540816]
	TIME [epoch: 9.71 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674686351761458		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.2674686351761458 | validation: 0.3493428604348651]
	TIME [epoch: 9.74 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30734419881667163		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.30734419881667163 | validation: 0.3118323915192703]
	TIME [epoch: 9.71 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2427007491429524		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.2427007491429524 | validation: 0.19721763815300639]
	TIME [epoch: 9.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2622983674245959		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.2622983674245959 | validation: 0.412202272744494]
	TIME [epoch: 9.72 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27835966302820336		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.27835966302820336 | validation: 0.2592401636600778]
	TIME [epoch: 9.73 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28484363365952026		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.28484363365952026 | validation: 0.30121126156557737]
	TIME [epoch: 9.71 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588928239036211		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.2588928239036211 | validation: 0.18509184128735293]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_863.pth
	Model improved!!!
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3390559343708364		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.3390559343708364 | validation: 0.2774046468033524]
	TIME [epoch: 9.74 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366037539213508		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.2366037539213508 | validation: 0.22293318777856222]
	TIME [epoch: 9.71 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26524582362151217		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.26524582362151217 | validation: 0.4168163131746569]
	TIME [epoch: 9.71 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28775910899443585		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.28775910899443585 | validation: 0.1743655903351065]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22540287041393797		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.22540287041393797 | validation: 0.22983498113363304]
	TIME [epoch: 9.72 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25732024535949555		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.25732024535949555 | validation: 0.3014139767433636]
	TIME [epoch: 9.72 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22686727312010616		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.22686727312010616 | validation: 0.2265676984773102]
	TIME [epoch: 9.71 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22074640916348837		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.22074640916348837 | validation: 0.2313123186640544]
	TIME [epoch: 9.73 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21230762932111485		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.21230762932111485 | validation: 0.27020675381729753]
	TIME [epoch: 9.71 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2484482765838028		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.2484482765838028 | validation: 0.31224279215535305]
	TIME [epoch: 9.71 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3098476344922006		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.3098476344922006 | validation: 0.21339377280122493]
	TIME [epoch: 9.73 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18814572293958737		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.18814572293958737 | validation: 0.18175876344259462]
	TIME [epoch: 9.72 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24950329116482944		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.24950329116482944 | validation: 0.21368187919533882]
	TIME [epoch: 9.71 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29900910453201895		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.29900910453201895 | validation: 0.2248205327985401]
	TIME [epoch: 9.73 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23127118666715257		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.23127118666715257 | validation: 0.30823749885570945]
	TIME [epoch: 9.72 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2542134957985204		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.2542134957985204 | validation: 0.19330011041814316]
	TIME [epoch: 9.71 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18509123101021988		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.18509123101021988 | validation: 0.17648173141140353]
	TIME [epoch: 9.71 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18598183797345086		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.18598183797345086 | validation: 0.23383673839689123]
	TIME [epoch: 9.74 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20165757279561936		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.20165757279561936 | validation: 0.2505623183129546]
	TIME [epoch: 9.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2142957721500053		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.2142957721500053 | validation: 0.18158654849824032]
	TIME [epoch: 9.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19733544672531744		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.19733544672531744 | validation: 0.1748749503421557]
	TIME [epoch: 9.73 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2206308689169912		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.2206308689169912 | validation: 0.23609345267313434]
	TIME [epoch: 9.72 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23386999855395357		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.23386999855395357 | validation: 0.2580155177278649]
	TIME [epoch: 9.71 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23021964283468677		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.23021964283468677 | validation: 0.25128929761493757]
	TIME [epoch: 9.73 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2310309809642444		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.2310309809642444 | validation: 0.1953030115766498]
	TIME [epoch: 9.72 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29775259814988325		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.29775259814988325 | validation: 0.20976034894089815]
	TIME [epoch: 9.71 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19653466451301874		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.19653466451301874 | validation: 0.20902018126485625]
	TIME [epoch: 9.71 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1982827206885088		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.1982827206885088 | validation: 0.19590044064954765]
	TIME [epoch: 9.74 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21248352840950116		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.21248352840950116 | validation: 0.20437762702841028]
	TIME [epoch: 9.71 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24161364817060402		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.24161364817060402 | validation: 0.2040546293290227]
	TIME [epoch: 9.72 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23293519864542186		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.23293519864542186 | validation: 0.31836649209940554]
	TIME [epoch: 9.73 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23501977689215212		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.23501977689215212 | validation: 0.27041828997547435]
	TIME [epoch: 9.72 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20959299823459449		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.20959299823459449 | validation: 0.2200497033776299]
	TIME [epoch: 9.71 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19830625777458094		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.19830625777458094 | validation: 0.1777810727038964]
	TIME [epoch: 9.71 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907616215165358		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.1907616215165358 | validation: 0.2687149608236796]
	TIME [epoch: 9.74 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23255435438148445		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.23255435438148445 | validation: 0.19505848604240356]
	TIME [epoch: 9.71 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2178242571623059		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.2178242571623059 | validation: 0.24730341183209845]
	TIME [epoch: 9.72 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21506694277624233		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.21506694277624233 | validation: 0.195060395441542]
	TIME [epoch: 9.74 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19625903321929092		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.19625903321929092 | validation: 0.18146172560572515]
	TIME [epoch: 9.72 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19001323127514036		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.19001323127514036 | validation: 0.2102480421092382]
	TIME [epoch: 9.71 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24858306963232524		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.24858306963232524 | validation: 0.2126881782493693]
	TIME [epoch: 9.71 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22666888561959775		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.22666888561959775 | validation: 0.1870495607553597]
	TIME [epoch: 9.73 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28942202001719247		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.28942202001719247 | validation: 0.34055818480090877]
	TIME [epoch: 9.71 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30210597454909627		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.30210597454909627 | validation: 0.24731575116740645]
	TIME [epoch: 9.71 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2219458974571368		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.2219458974571368 | validation: 0.3060561547146783]
	TIME [epoch: 9.74 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2245666760545922		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.2245666760545922 | validation: 0.2179503830442556]
	TIME [epoch: 9.71 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24692410091296937		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.24692410091296937 | validation: 0.20838894769398245]
	TIME [epoch: 9.71 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2904648517457479		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.2904648517457479 | validation: 0.26360635615995714]
	TIME [epoch: 9.72 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2981377776159028		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.2981377776159028 | validation: 0.23952913707733928]
	TIME [epoch: 9.72 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21715665932411107		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.21715665932411107 | validation: 0.25545693831514416]
	TIME [epoch: 9.71 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24743589549717382		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.24743589549717382 | validation: 0.2694628516355588]
	TIME [epoch: 9.72 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21908789556931846		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.21908789556931846 | validation: 0.23391414361223248]
	TIME [epoch: 9.74 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2213452405148392		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.2213452405148392 | validation: 0.25305120056455876]
	TIME [epoch: 9.71 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2408206065967975		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.2408206065967975 | validation: 0.2738410943522817]
	TIME [epoch: 9.71 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24607107624781727		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.24607107624781727 | validation: 0.551054705024767]
	TIME [epoch: 9.73 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40840905696622654		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.40840905696622654 | validation: 0.2913019958702715]
	TIME [epoch: 9.71 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24901380849415428		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.24901380849415428 | validation: 0.225535760256992]
	TIME [epoch: 9.72 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1957799139952441		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.1957799139952441 | validation: 0.209430023063576]
	TIME [epoch: 9.72 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2757151727969011		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.2757151727969011 | validation: 0.23631339942642343]
	TIME [epoch: 9.73 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.255025636350489		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.255025636350489 | validation: 0.1925039554291665]
	TIME [epoch: 9.71 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21186998333335208		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.21186998333335208 | validation: 0.21205281800614015]
	TIME [epoch: 9.71 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18590335668918295		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.18590335668918295 | validation: 0.17941778115189116]
	TIME [epoch: 9.74 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19503766806899098		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.19503766806899098 | validation: 0.19712822903270272]
	TIME [epoch: 9.71 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2694388039594767		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.2694388039594767 | validation: 0.4256914641093732]
	TIME [epoch: 9.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2450391926240271		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.2450391926240271 | validation: 0.16669338068416487]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_928.pth
	Model improved!!!
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19908400801195253		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.19908400801195253 | validation: 0.17975979793763328]
	TIME [epoch: 9.73 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2212608096119356		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.2212608096119356 | validation: 0.1990962578273734]
	TIME [epoch: 9.72 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23330990907715377		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.23330990907715377 | validation: 0.22085556872029188]
	TIME [epoch: 9.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1944045149724965		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.1944045149724965 | validation: 0.21349263920226846]
	TIME [epoch: 9.74 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18251557956933584		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.18251557956933584 | validation: 0.1839315998075539]
	TIME [epoch: 9.72 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907101965995871		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.1907101965995871 | validation: 0.22359080943683587]
	TIME [epoch: 9.71 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27060668593284126		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.27060668593284126 | validation: 0.23948560188334753]
	TIME [epoch: 9.74 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907154110901157		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.1907154110901157 | validation: 0.17973503922436937]
	TIME [epoch: 9.72 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20380122194308298		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.20380122194308298 | validation: 0.20867001758276146]
	TIME [epoch: 9.72 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18431016949126974		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.18431016949126974 | validation: 0.18425548793740093]
	TIME [epoch: 9.72 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21029315995946005		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.21029315995946005 | validation: 0.3831573110718061]
	TIME [epoch: 9.74 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2976160030023159		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.2976160030023159 | validation: 0.22163952684412613]
	TIME [epoch: 9.72 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20115265573945557		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.20115265573945557 | validation: 0.2112034647202007]
	TIME [epoch: 9.72 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20002304895716874		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.20002304895716874 | validation: 0.2892470668121073]
	TIME [epoch: 9.74 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21324488239830214		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.21324488239830214 | validation: 0.27455731453226195]
	TIME [epoch: 9.72 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507929603718947		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.2507929603718947 | validation: 0.20516196262743747]
	TIME [epoch: 9.72 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872802621955851		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.1872802621955851 | validation: 0.3029979515431089]
	TIME [epoch: 9.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2864594363611535		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.2864594363611535 | validation: 0.284075891931466]
	TIME [epoch: 9.72 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21952819802050713		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.21952819802050713 | validation: 0.18683562980870405]
	TIME [epoch: 9.72 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21794504983347643		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.21794504983347643 | validation: 0.35318245181678665]
	TIME [epoch: 9.72 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26261388396037827		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.26261388396037827 | validation: 0.230100765697355]
	TIME [epoch: 9.75 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22127842192847522		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.22127842192847522 | validation: 0.1769889771737886]
	TIME [epoch: 9.72 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20775523012709654		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.20775523012709654 | validation: 0.3007854109636771]
	TIME [epoch: 9.72 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2527723611656717		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.2527723611656717 | validation: 0.19440620812698867]
	TIME [epoch: 9.74 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18044040282558202		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.18044040282558202 | validation: 0.1864115007773126]
	TIME [epoch: 9.72 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.192494951967742		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.192494951967742 | validation: 0.18061881272808997]
	TIME [epoch: 9.72 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16143690930722607		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.16143690930722607 | validation: 0.14876930506982533]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_955.pth
	Model improved!!!
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18573736759576773		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.18573736759576773 | validation: 0.15469183974223652]
	TIME [epoch: 9.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1796697881383545		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.1796697881383545 | validation: 0.19254721333523306]
	TIME [epoch: 9.72 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1848648147738805		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.1848648147738805 | validation: 0.17004675724389123]
	TIME [epoch: 9.72 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19049225801489184		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.19049225801489184 | validation: 0.18234646344583558]
	TIME [epoch: 9.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712060166762183		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.1712060166762183 | validation: 0.14069595341147648]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_960.pth
	Model improved!!!
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20261656583058177		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.20261656583058177 | validation: 0.16721404110126611]
	TIME [epoch: 9.72 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18433683989919727		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.18433683989919727 | validation: 0.20974494922661216]
	TIME [epoch: 9.73 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23948168235443973		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.23948168235443973 | validation: 0.20478643387578765]
	TIME [epoch: 9.72 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2091491568373335		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.2091491568373335 | validation: 0.20581170408743213]
	TIME [epoch: 9.71 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21208876842148938		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.21208876842148938 | validation: 0.2339395171188829]
	TIME [epoch: 9.72 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20986095931462767		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.20986095931462767 | validation: 0.17922426588975612]
	TIME [epoch: 9.73 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18267419402734542		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.18267419402734542 | validation: 0.20090335590603114]
	TIME [epoch: 9.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18152222713412988		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.18152222713412988 | validation: 0.16901196861288129]
	TIME [epoch: 9.71 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19105400929734045		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.19105400929734045 | validation: 0.23402286358207497]
	TIME [epoch: 9.74 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20813463769996582		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.20813463769996582 | validation: 0.27866627920944276]
	TIME [epoch: 9.72 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2764045086092896		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.2764045086092896 | validation: 0.259972439814856]
	TIME [epoch: 9.71 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118401512746526		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.2118401512746526 | validation: 0.15629213055959792]
	TIME [epoch: 9.72 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16681413487360564		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.16681413487360564 | validation: 0.17992847685883803]
	TIME [epoch: 9.72 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19961705478942132		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.19961705478942132 | validation: 0.247734865345243]
	TIME [epoch: 9.72 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20601588196270235		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.20601588196270235 | validation: 0.22867231025598994]
	TIME [epoch: 9.71 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2207269939228491		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.2207269939228491 | validation: 0.1989914544557388]
	TIME [epoch: 9.74 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19545696411352495		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.19545696411352495 | validation: 0.25410020217148366]
	TIME [epoch: 9.71 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21155381214798155		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.21155381214798155 | validation: 0.2109124815271822]
	TIME [epoch: 9.71 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18318360207836334		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.18318360207836334 | validation: 0.19376805009471748]
	TIME [epoch: 9.73 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1821166178307601		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.1821166178307601 | validation: 0.1661137073509849]
	TIME [epoch: 9.72 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.261180031943879		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.261180031943879 | validation: 0.2268283472917415]
	TIME [epoch: 9.72 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19331087338393466		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.19331087338393466 | validation: 0.18244563446672415]
	TIME [epoch: 9.72 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15984755440045617		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.15984755440045617 | validation: 0.19365993239873788]
	TIME [epoch: 9.74 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2012633980224728		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.2012633980224728 | validation: 0.2656092214033539]
	TIME [epoch: 9.72 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22878883515806853		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.22878883515806853 | validation: 0.23188637408578586]
	TIME [epoch: 9.71 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853740588254043		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.1853740588254043 | validation: 0.18481402166620242]
	TIME [epoch: 9.73 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20890792930797675		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.20890792930797675 | validation: 0.1633363283319052]
	TIME [epoch: 9.71 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18874302769290646		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.18874302769290646 | validation: 0.21335744180244395]
	TIME [epoch: 9.71 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20878810017215832		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.20878810017215832 | validation: 0.24200891458424095]
	TIME [epoch: 9.73 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18327055263303507		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.18327055263303507 | validation: 0.17443103198257717]
	TIME [epoch: 9.73 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840544957584405		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.1840544957584405 | validation: 0.21965562981088313]
	TIME [epoch: 9.72 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20855911542211922		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.20855911542211922 | validation: 0.26012220929777785]
	TIME [epoch: 9.72 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19268021210651326		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.19268021210651326 | validation: 0.17272758245719927]
	TIME [epoch: 9.74 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18267958869439696		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.18267958869439696 | validation: 0.20380774616663597]
	TIME [epoch: 9.72 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17588116270951087		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.17588116270951087 | validation: 0.32455521489748007]
	TIME [epoch: 9.71 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2420566309566849		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.2420566309566849 | validation: 0.18961589308974724]
	TIME [epoch: 9.73 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18346629239756412		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.18346629239756412 | validation: 0.1800087695978339]
	TIME [epoch: 9.72 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16024319422410147		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.16024319422410147 | validation: 0.19903043331629888]
	TIME [epoch: 9.71 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17692277961826713		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.17692277961826713 | validation: 0.17332067112730898]
	TIME [epoch: 9.72 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17806042400504618		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.17806042400504618 | validation: 0.3069310511317523]
	TIME [epoch: 9.74 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23317090642198543		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.23317090642198543 | validation: 0.1849723193786403]
	TIME [epoch: 9.71 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19587040030108144		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.19587040030108144 | validation: 0.19303246005397995]
	TIME [epoch: 9.71 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19337583005691114		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.19337583005691114 | validation: 0.20096143030257083]
	TIME [epoch: 9.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16890244809795835		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.16890244809795835 | validation: 0.20061063424581005]
	TIME [epoch: 9.72 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19165572321675867		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.19165572321675867 | validation: 0.2044567584531309]
	TIME [epoch: 9.71 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19236504482995437		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.19236504482995437 | validation: 0.1711533037640863]
	TIME [epoch: 9.73 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19685607584565273		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.19685607584565273 | validation: 0.18050996520249393]
	TIME [epoch: 9.72 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1617957826781129		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.1617957826781129 | validation: 0.2255834305809005]
	TIME [epoch: 9.71 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3310487400136323		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.3310487400136323 | validation: 0.23475594206841982]
	TIME [epoch: 9.72 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16968842841231016		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.16968842841231016 | validation: 0.23034470229970377]
	TIME [epoch: 9.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18792267565841572		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.18792267565841572 | validation: 0.22112076855857268]
	TIME [epoch: 9.71 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17543194735394063		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.17543194735394063 | validation: 0.20110556976319507]
	TIME [epoch: 9.72 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18050428178077285		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.18050428178077285 | validation: 0.16251347412172953]
	TIME [epoch: 9.74 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18940816462367943		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.18940816462367943 | validation: 0.22412058372222673]
	TIME [epoch: 9.71 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18009937655993946		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.18009937655993946 | validation: 0.15066620484195928]
	TIME [epoch: 9.72 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15820097795409888		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.15820097795409888 | validation: 0.2575657770288051]
	TIME [epoch: 9.72 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1977277155013384		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.1977277155013384 | validation: 0.2704665856506195]
	TIME [epoch: 9.74 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22183393872595197		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.22183393872595197 | validation: 0.20798459189317964]
	TIME [epoch: 9.72 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19237825373543868		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.19237825373543868 | validation: 0.14604815321115108]
	TIME [epoch: 9.71 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16698228297605852		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.16698228297605852 | validation: 0.17476179576337575]
	TIME [epoch: 9.74 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21040691223537644		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.21040691223537644 | validation: 0.25891850220969603]
	TIME [epoch: 9.71 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22339128024791793		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.22339128024791793 | validation: 0.18261422443001585]
	TIME [epoch: 9.71 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17684721056037817		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.17684721056037817 | validation: 0.15217108537792817]
	TIME [epoch: 9.72 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1585423720321795		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.1585423720321795 | validation: 0.18633400425485008]
	TIME [epoch: 9.73 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17621810218304917		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.17621810218304917 | validation: 0.23257104351007388]
	TIME [epoch: 9.72 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20457869911005472		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.20457869911005472 | validation: 0.251248614594219]
	TIME [epoch: 9.71 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2220287409314618		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.2220287409314618 | validation: 0.23514208544769774]
	TIME [epoch: 9.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25269672207762095		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.25269672207762095 | validation: 0.16067314477100117]
	TIME [epoch: 9.72 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17609716296560857		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.17609716296560857 | validation: 0.23854588338480726]
	TIME [epoch: 9.72 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18106191896057883		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.18106191896057883 | validation: 0.14949157396714188]
	TIME [epoch: 9.74 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17039323890722088		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.17039323890722088 | validation: 0.19686990613723246]
	TIME [epoch: 9.72 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17547673576973116		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.17547673576973116 | validation: 0.230635376981572]
	TIME [epoch: 9.72 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2536123008657647		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.2536123008657647 | validation: 0.21822390644518144]
	TIME [epoch: 9.72 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1932105800464669		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.1932105800464669 | validation: 0.17956461570605237]
	TIME [epoch: 9.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2030072986773998		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.2030072986773998 | validation: 0.17781738816018947]
	TIME [epoch: 9.72 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717055631482209		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.1717055631482209 | validation: 0.17964800321516045]
	TIME [epoch: 9.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19035914154567962		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.19035914154567962 | validation: 0.23257476604947705]
	TIME [epoch: 9.74 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19231866776005038		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.19231866776005038 | validation: 0.16416316224821764]
	TIME [epoch: 9.72 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26752954512213356		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.26752954512213356 | validation: 0.3785382254351745]
	TIME [epoch: 9.71 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24688366059976524		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.24688366059976524 | validation: 0.17844006551685784]
	TIME [epoch: 9.73 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162759129877844		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.162759129877844 | validation: 0.16066678876264212]
	TIME [epoch: 9.74 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16884447504961972		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.16884447504961972 | validation: 0.21282762594639867]
	TIME [epoch: 9.72 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19518288168638726		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.19518288168638726 | validation: 0.21186995743797332]
	TIME [epoch: 9.71 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21481671356657767		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.21481671356657767 | validation: 0.15806524601589086]
	TIME [epoch: 9.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1703644893150927		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.1703644893150927 | validation: 0.16848223079359792]
	TIME [epoch: 9.72 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15058410033794806		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.15058410033794806 | validation: 0.15772849786905718]
	TIME [epoch: 9.72 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16357666200661267		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.16357666200661267 | validation: 0.22265142842032926]
	TIME [epoch: 9.74 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16686146236826987		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.16686146236826987 | validation: 0.17234497605442584]
	TIME [epoch: 9.72 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15873466453880308		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.15873466453880308 | validation: 0.3163147604628954]
	TIME [epoch: 9.72 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3458034281772995		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.3458034281772995 | validation: 0.31420397821058244]
	TIME [epoch: 9.72 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2108344537565825		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.2108344537565825 | validation: 0.1902127833992464]
	TIME [epoch: 9.74 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2091360728677682		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.2091360728677682 | validation: 0.2687009877460806]
	TIME [epoch: 9.72 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18187025701102694		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.18187025701102694 | validation: 0.17710462892129722]
	TIME [epoch: 9.72 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225343535664571		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.16225343535664571 | validation: 0.22665078598492097]
	TIME [epoch: 9.73 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21072620803944142		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.21072620803944142 | validation: 0.1903961192024434]
	TIME [epoch: 9.72 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15545596223945118		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.15545596223945118 | validation: 0.17768727874234888]
	TIME [epoch: 9.72 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17307581924505083		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.17307581924505083 | validation: 0.1714648571453982]
	TIME [epoch: 9.73 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17587343456687324		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.17587343456687324 | validation: 0.1960592550962562]
	TIME [epoch: 9.73 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17754773369759302		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.17754773369759302 | validation: 0.22335126945549175]
	TIME [epoch: 9.71 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20422475087345923		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.20422475087345923 | validation: 0.1992727470387807]
	TIME [epoch: 9.72 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17192651353485028		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.17192651353485028 | validation: 0.15385854298554327]
	TIME [epoch: 9.74 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14864032255986684		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.14864032255986684 | validation: 0.16878800211013012]
	TIME [epoch: 9.72 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1467373870910676		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.1467373870910676 | validation: 0.24813968059182606]
	TIME [epoch: 9.72 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34617926042507385		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.34617926042507385 | validation: 0.2891152585792447]
	TIME [epoch: 9.73 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576053575593052		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.2576053575593052 | validation: 0.22299219334883255]
	TIME [epoch: 9.72 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16528372922380558		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.16528372922380558 | validation: 0.1642606295990458]
	TIME [epoch: 9.72 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19450355312833242		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.19450355312833242 | validation: 0.15721119022814833]
	TIME [epoch: 9.72 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18903574267956988		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.18903574267956988 | validation: 0.16235633676922653]
	TIME [epoch: 9.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20688833786298777		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.20688833786298777 | validation: 0.20708711242663025]
	TIME [epoch: 9.72 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17340298817663174		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.17340298817663174 | validation: 0.17389147792067064]
	TIME [epoch: 9.72 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15326833853618846		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.15326833853618846 | validation: 0.1462313870488934]
	TIME [epoch: 9.74 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18263111024582618		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.18263111024582618 | validation: 0.24310212827415187]
	TIME [epoch: 9.72 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18667136621980512		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.18667136621980512 | validation: 0.1366725218704762]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1073.pth
	Model improved!!!
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16238728932097599		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.16238728932097599 | validation: 0.1818932618223515]
	TIME [epoch: 9.73 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15753631508732985		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.15753631508732985 | validation: 0.17148710737504844]
	TIME [epoch: 9.72 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17066451592043194		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.17066451592043194 | validation: 0.15318307808493256]
	TIME [epoch: 9.72 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13763201623490048		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.13763201623490048 | validation: 0.16326291657827405]
	TIME [epoch: 9.71 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15576780095338708		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.15576780095338708 | validation: 0.19664005680373897]
	TIME [epoch: 9.74 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765617798500866		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.1765617798500866 | validation: 0.14141082117733705]
	TIME [epoch: 9.71 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15349006208593555		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.15349006208593555 | validation: 0.17415058568970765]
	TIME [epoch: 9.72 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15439459193373703		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.15439459193373703 | validation: 0.19576978881739635]
	TIME [epoch: 9.73 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23969642149069204		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.23969642149069204 | validation: 0.2692402790536128]
	TIME [epoch: 9.72 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22250972035532074		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.22250972035532074 | validation: 0.20340231519537777]
	TIME [epoch: 9.72 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590601800981794		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.1590601800981794 | validation: 0.1643221741920607]
	TIME [epoch: 9.72 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17124129489743795		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.17124129489743795 | validation: 0.1450897758970678]
	TIME [epoch: 9.73 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15765757182758275		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.15765757182758275 | validation: 0.20138711753799876]
	TIME [epoch: 9.71 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20552610391675033		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.20552610391675033 | validation: 0.24193337486859728]
	TIME [epoch: 9.71 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18608148906890754		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.18608148906890754 | validation: 0.20654173858577]
	TIME [epoch: 9.75 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522779065607553		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.1522779065607553 | validation: 0.14417178929487132]
	TIME [epoch: 9.71 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16091874137089124		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.16091874137089124 | validation: 0.18123843700425127]
	TIME [epoch: 9.71 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17582966602057087		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.17582966602057087 | validation: 0.2143845594374988]
	TIME [epoch: 9.72 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18428980599496966		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.18428980599496966 | validation: 0.19145024192996166]
	TIME [epoch: 9.72 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19908797670885442		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.19908797670885442 | validation: 0.16931132284702735]
	TIME [epoch: 9.71 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17376514162321333		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.17376514162321333 | validation: 0.20087504727687674]
	TIME [epoch: 9.71 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16990904319486122		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.16990904319486122 | validation: 0.1814877596614429]
	TIME [epoch: 9.73 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20532550789935433		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.20532550789935433 | validation: 0.20092017451748484]
	TIME [epoch: 9.71 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18552457090598576		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.18552457090598576 | validation: 0.15905124017333624]
	TIME [epoch: 9.71 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1731225591113868		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.1731225591113868 | validation: 0.15610744767508994]
	TIME [epoch: 9.73 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19833298398899196		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.19833298398899196 | validation: 0.2515301162575381]
	TIME [epoch: 9.71 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15544467778908605		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.15544467778908605 | validation: 0.18328371881300307]
	TIME [epoch: 9.72 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19295504900243624		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.19295504900243624 | validation: 0.2175709077787836]
	TIME [epoch: 9.72 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19314998213430565		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.19314998213430565 | validation: 0.17251698809829932]
	TIME [epoch: 9.73 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16146284104090192		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.16146284104090192 | validation: 0.23437104479753415]
	TIME [epoch: 9.71 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18546228396178782		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.18546228396178782 | validation: 0.16495110172286606]
	TIME [epoch: 9.71 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610124206251834		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.1610124206251834 | validation: 0.15545255629837815]
	TIME [epoch: 9.75 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152674614779331		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.152674614779331 | validation: 0.1828575651030159]
	TIME [epoch: 9.72 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1699089617393686		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.1699089617393686 | validation: 0.14439801969724633]
	TIME [epoch: 9.71 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15176695978468469		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.15176695978468469 | validation: 0.16195423823312063]
	TIME [epoch: 9.73 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15472136826571187		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.15472136826571187 | validation: 0.17270870486865605]
	TIME [epoch: 9.72 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694336677950912		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.18694336677950912 | validation: 0.19506838878028987]
	TIME [epoch: 9.72 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16779906910325393		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.16779906910325393 | validation: 0.22311387078248993]
	TIME [epoch: 9.72 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2207796294438545		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.2207796294438545 | validation: 0.17320903498069817]
	TIME [epoch: 9.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16093523572670798		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.16093523572670798 | validation: 0.1551710808341007]
	TIME [epoch: 9.71 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17465131325474115		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.17465131325474115 | validation: 0.19611052890961042]
	TIME [epoch: 9.72 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1599746793974952		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.1599746793974952 | validation: 0.17831504202293866]
	TIME [epoch: 9.73 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17847638224685283		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.17847638224685283 | validation: 0.15231162501823606]
	TIME [epoch: 9.72 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15535059505045992		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.15535059505045992 | validation: 0.15202739246074806]
	TIME [epoch: 9.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14128934558794232		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.14128934558794232 | validation: 0.1825291907205176]
	TIME [epoch: 9.71 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872235733389308		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.1872235733389308 | validation: 0.2678243752241935]
	TIME [epoch: 9.73 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17538866242956072		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.17538866242956072 | validation: 0.1605670032266908]
	TIME [epoch: 9.71 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17758541683218027		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.17758541683218027 | validation: 0.23394362292387066]
	TIME [epoch: 9.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17599226831297665		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.17599226831297665 | validation: 0.1490754076503989]
	TIME [epoch: 9.74 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14089413586567695		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.14089413586567695 | validation: 0.16032566801358406]
	TIME [epoch: 9.71 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15257351289083185		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.15257351289083185 | validation: 0.1668474955004507]
	TIME [epoch: 9.71 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17709296485482848		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.17709296485482848 | validation: 0.18720090878238316]
	TIME [epoch: 9.73 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18295316981496068		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.18295316981496068 | validation: 0.2162694550523994]
	TIME [epoch: 9.72 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17493125244254865		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.17493125244254865 | validation: 0.16177015760497837]
	TIME [epoch: 9.71 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17291548432699194		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.17291548432699194 | validation: 0.17234594672922804]
	TIME [epoch: 9.71 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14753671184429554		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.14753671184429554 | validation: 0.14703121855394857]
	TIME [epoch: 9.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17753649755534132		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.17753649755534132 | validation: 0.1836509455004229]
	TIME [epoch: 9.72 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17020274536148636		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.17020274536148636 | validation: 0.14965774010191396]
	TIME [epoch: 9.71 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496904605706725		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.1496904605706725 | validation: 0.14683688615648355]
	TIME [epoch: 9.73 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558335904352373		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.1558335904352373 | validation: 0.1548595543434935]
	TIME [epoch: 9.72 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14985441815120099		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.14985441815120099 | validation: 0.15982944167572805]
	TIME [epoch: 9.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609561776720268		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.1609561776720268 | validation: 0.22003560219470086]
	TIME [epoch: 9.72 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1714043475244223		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.1714043475244223 | validation: 0.22951197524487427]
	TIME [epoch: 9.73 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20003093529042912		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.20003093529042912 | validation: 0.2037366593164747]
	TIME [epoch: 9.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16006570836649742		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.16006570836649742 | validation: 0.16524737918052548]
	TIME [epoch: 9.71 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522087357792211		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.1522087357792211 | validation: 0.14027055012867165]
	TIME [epoch: 9.74 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13932961670147412		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.13932961670147412 | validation: 0.14276089171397638]
	TIME [epoch: 9.71 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1371540234530599		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.1371540234530599 | validation: 0.1514292766351722]
	TIME [epoch: 9.71 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1667002617747225		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.1667002617747225 | validation: 0.1444475256813669]
	TIME [epoch: 9.73 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15470835589395013		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.15470835589395013 | validation: 0.14855962246111323]
	TIME [epoch: 9.73 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16790176097425205		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.16790176097425205 | validation: 0.25430638632483316]
	TIME [epoch: 9.71 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1910336877896906		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.1910336877896906 | validation: 0.21046312330047975]
	TIME [epoch: 9.71 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676235979489628		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.1676235979489628 | validation: 0.15781105913976554]
	TIME [epoch: 9.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16848777930666267		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.16848777930666267 | validation: 0.20321982605058872]
	TIME [epoch: 9.71 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18851945348983856		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.18851945348983856 | validation: 0.13624218347727968]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1148.pth
	Model improved!!!
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14496105065015782		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.14496105065015782 | validation: 0.17560268523096517]
	TIME [epoch: 9.73 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715815964188811		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.1715815964188811 | validation: 0.23279736361164002]
	TIME [epoch: 9.71 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1949656900771044		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.1949656900771044 | validation: 0.1579431309750757]
	TIME [epoch: 9.72 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1476269300113766		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.1476269300113766 | validation: 0.12855678258565287]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1152.pth
	Model improved!!!
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15907266789177119		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.15907266789177119 | validation: 0.1351122763725981]
	TIME [epoch: 9.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15177873192434377		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.15177873192434377 | validation: 0.16303179330877302]
	TIME [epoch: 9.73 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16018494856591894		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.16018494856591894 | validation: 0.13737419136541218]
	TIME [epoch: 9.73 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14232794591033132		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.14232794591033132 | validation: 0.14323671629838877]
	TIME [epoch: 9.75 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14357601555182553		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.14357601555182553 | validation: 0.13218430201879502]
	TIME [epoch: 9.72 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15247438876984737		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.15247438876984737 | validation: 0.17045742237105857]
	TIME [epoch: 9.73 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1877392464222002		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.1877392464222002 | validation: 0.21122474221697107]
	TIME [epoch: 9.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19843622395917265		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.19843622395917265 | validation: 0.21086007809964255]
	TIME [epoch: 9.74 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568183184398082		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.1568183184398082 | validation: 0.13811433485263172]
	TIME [epoch: 9.73 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20912121522269217		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.20912121522269217 | validation: 0.22024002724394415]
	TIME [epoch: 9.73 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16521953999089256		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.16521953999089256 | validation: 0.17238703385911314]
	TIME [epoch: 9.75 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14464324053865002		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.14464324053865002 | validation: 0.1419504560484518]
	TIME [epoch: 9.73 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290755466808809		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.15290755466808809 | validation: 0.16143308303625753]
	TIME [epoch: 9.72 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651880075506416		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.1651880075506416 | validation: 0.2526262494664994]
	TIME [epoch: 9.75 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23305020542119834		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.23305020542119834 | validation: 0.16220949455259742]
	TIME [epoch: 9.73 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149864742596822		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.149864742596822 | validation: 0.1569669779529775]
	TIME [epoch: 9.73 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14969278386630352		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.14969278386630352 | validation: 0.19029399141432368]
	TIME [epoch: 9.73 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1795921273910891		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.1795921273910891 | validation: 0.17135108251899403]
	TIME [epoch: 9.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1781711724162114		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.1781711724162114 | validation: 0.19953486240484813]
	TIME [epoch: 9.72 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751228600861467		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.1751228600861467 | validation: 0.18410684401472374]
	TIME [epoch: 9.72 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15354399146869993		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.15354399146869993 | validation: 0.14881478388089422]
	TIME [epoch: 9.75 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819566143411297		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.1819566143411297 | validation: 0.23521468600157477]
	TIME [epoch: 9.73 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15357794976453593		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.15357794976453593 | validation: 0.13351485315804898]
	TIME [epoch: 9.73 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275954728211708		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.15275954728211708 | validation: 0.15279865490680616]
	TIME [epoch: 9.75 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15666906859100724		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.15666906859100724 | validation: 0.15506797987286372]
	TIME [epoch: 9.73 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.181209891605771		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.181209891605771 | validation: 0.16834492985725724]
	TIME [epoch: 9.73 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16866839919535342		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.16866839919535342 | validation: 0.16037472598847607]
	TIME [epoch: 9.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16341891669639846		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.16341891669639846 | validation: 0.17335913318235663]
	TIME [epoch: 9.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15434308518147755		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.15434308518147755 | validation: 0.18026770974744247]
	TIME [epoch: 9.73 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14545759497425997		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.14545759497425997 | validation: 0.2164266587523851]
	TIME [epoch: 9.72 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17523366514973357		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.17523366514973357 | validation: 0.1560966754935589]
	TIME [epoch: 9.75 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16590811680970238		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.16590811680970238 | validation: 0.1689620948654347]
	TIME [epoch: 9.73 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1780634322318157		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.1780634322318157 | validation: 0.2079143433138706]
	TIME [epoch: 9.72 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1696202120032233		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.1696202120032233 | validation: 0.15093497853218257]
	TIME [epoch: 9.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1448444205440711		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.1448444205440711 | validation: 0.141023751796403]
	TIME [epoch: 9.73 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1931848424910126		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.1931848424910126 | validation: 0.1422656043672496]
	TIME [epoch: 9.72 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1383741972833305		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.1383741972833305 | validation: 0.14144538381301117]
	TIME [epoch: 9.72 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14716450856195049		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.14716450856195049 | validation: 0.1605955115962385]
	TIME [epoch: 9.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15585030293334395		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.15585030293334395 | validation: 0.17975430336413553]
	TIME [epoch: 9.72 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19224351070749462		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.19224351070749462 | validation: 0.17337861368990667]
	TIME [epoch: 9.72 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15366324498029565		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.15366324498029565 | validation: 0.16234021885461508]
	TIME [epoch: 9.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288736509283234		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.17288736509283234 | validation: 0.1506532110324774]
	TIME [epoch: 9.73 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15196470961800035		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.15196470961800035 | validation: 0.14296806295466433]
	TIME [epoch: 9.72 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18840664010965233		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.18840664010965233 | validation: 0.15339793264814183]
	TIME [epoch: 9.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15942368148840744		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.15942368148840744 | validation: 0.19420729597505557]
	TIME [epoch: 9.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15307153768337908		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.15307153768337908 | validation: 0.15390045063465216]
	TIME [epoch: 9.73 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17938188161516772		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.17938188161516772 | validation: 0.22798504146959303]
	TIME [epoch: 9.72 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18933147897141972		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.18933147897141972 | validation: 0.1582115078994449]
	TIME [epoch: 9.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16020012759720823		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.16020012759720823 | validation: 0.2272190267907343]
	TIME [epoch: 9.72 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16669853552514996		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.16669853552514996 | validation: 0.1549625588169884]
	TIME [epoch: 9.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503131911224254		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.1503131911224254 | validation: 0.1560862765706535]
	TIME [epoch: 9.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17142745191572822		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.17142745191572822 | validation: 0.14433398392984478]
	TIME [epoch: 9.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15511487348725309		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.15511487348725309 | validation: 0.16717340318778384]
	TIME [epoch: 9.73 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15473474862886277		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.15473474862886277 | validation: 0.16754001277426228]
	TIME [epoch: 9.73 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162764443729233		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.162764443729233 | validation: 0.1960513216188661]
	TIME [epoch: 9.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16341539037838665		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.16341539037838665 | validation: 0.15593169493205802]
	TIME [epoch: 9.72 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1344035017553585		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.1344035017553585 | validation: 0.15417336207390098]
	TIME [epoch: 9.73 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1455568327378827		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.1455568327378827 | validation: 0.1353127968896458]
	TIME [epoch: 9.75 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676245279362641		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.1676245279362641 | validation: 0.1842050655577068]
	TIME [epoch: 9.73 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15353953222319966		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.15353953222319966 | validation: 0.18886048237583702]
	TIME [epoch: 9.73 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16248950662124836		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.16248950662124836 | validation: 0.15245559076641688]
	TIME [epoch: 9.73 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1599821860566592		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.1599821860566592 | validation: 0.1642305498556118]
	TIME [epoch: 9.75 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16692784446148698		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.16692784446148698 | validation: 0.17017544667491294]
	TIME [epoch: 9.73 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13638737178805588		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.13638737178805588 | validation: 0.13871223477678726]
	TIME [epoch: 9.73 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692229676305063		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.1692229676305063 | validation: 0.2063113322927099]
	TIME [epoch: 9.75 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20633594429496735		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.20633594429496735 | validation: 0.15688243925022322]
	TIME [epoch: 9.73 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14803827441659048		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.14803827441659048 | validation: 0.15876812236814428]
	TIME [epoch: 9.73 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530143404680163		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.1530143404680163 | validation: 0.13023484090573306]
	TIME [epoch: 9.74 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22070628226074232		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.22070628226074232 | validation: 0.1886921707105583]
	TIME [epoch: 9.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17377152870229456		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.17377152870229456 | validation: 0.1189033385763252]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1222.pth
	Model improved!!!
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14024572711066569		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.14024572711066569 | validation: 0.13313830905768637]
	TIME [epoch: 9.73 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162164857419141		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.162164857419141 | validation: 0.14430464713695607]
	TIME [epoch: 9.75 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14769445548534166		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.14769445548534166 | validation: 0.14299707043995644]
	TIME [epoch: 9.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1561040074930299		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.1561040074930299 | validation: 0.12801688674261444]
	TIME [epoch: 9.72 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13618236129193145		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.13618236129193145 | validation: 0.13548251724950283]
	TIME [epoch: 9.75 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14538588844040543		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.14538588844040543 | validation: 0.16345771809421042]
	TIME [epoch: 9.72 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676166178156598		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.1676166178156598 | validation: 0.14964670459772478]
	TIME [epoch: 9.73 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17283470538026433		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.17283470538026433 | validation: 0.15844557546030683]
	TIME [epoch: 9.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14860111270546122		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.14860111270546122 | validation: 0.15292970169530384]
	TIME [epoch: 9.74 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601173717528137		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.1601173717528137 | validation: 0.2010355278024395]
	TIME [epoch: 9.72 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16694977276842082		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.16694977276842082 | validation: 0.19844459461166067]
	TIME [epoch: 9.72 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1696007608538208		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.1696007608538208 | validation: 0.14589649288807788]
	TIME [epoch: 9.75 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14001493112593127		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.14001493112593127 | validation: 0.15888187429809975]
	TIME [epoch: 9.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13902258302339587		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.13902258302339587 | validation: 0.13376890185510892]
	TIME [epoch: 9.72 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13229610841125744		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.13229610841125744 | validation: 0.131955513847385]
	TIME [epoch: 9.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18161085158403195		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.18161085158403195 | validation: 0.1505484791786892]
	TIME [epoch: 9.73 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13517649348348054		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.13517649348348054 | validation: 0.15015197923226034]
	TIME [epoch: 9.72 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1395289996019439		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.1395289996019439 | validation: 0.14008848000267965]
	TIME [epoch: 9.72 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15832225397789979		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.15832225397789979 | validation: 0.17581106871342697]
	TIME [epoch: 9.75 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1722005168143828		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.1722005168143828 | validation: 0.129796882474559]
	TIME [epoch: 9.72 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13846551117872236		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.13846551117872236 | validation: 0.19391882035205968]
	TIME [epoch: 9.73 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15915950592643346		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.15915950592643346 | validation: 0.1546101639396159]
	TIME [epoch: 9.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13784297751921754		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.13784297751921754 | validation: 0.173353046457143]
	TIME [epoch: 9.73 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503787461478122		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.1503787461478122 | validation: 0.1321155421373931]
	TIME [epoch: 9.72 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12529795919442943		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.12529795919442943 | validation: 0.1399160350808102]
	TIME [epoch: 9.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13446273892743918		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.13446273892743918 | validation: 0.12778880082523963]
	TIME [epoch: 9.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14541300514856834		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.14541300514856834 | validation: 0.14773556595876092]
	TIME [epoch: 9.73 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13509803396841366		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.13509803396841366 | validation: 0.1664622504545109]
	TIME [epoch: 9.72 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18716107203369728		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.18716107203369728 | validation: 0.1779292172182401]
	TIME [epoch: 9.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1880368449041959		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.1880368449041959 | validation: 0.15396768951830478]
	TIME [epoch: 9.72 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518906492278714		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.1518906492278714 | validation: 0.16367179220422867]
	TIME [epoch: 9.72 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157080948311491		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.157080948311491 | validation: 0.13663544147266998]
	TIME [epoch: 9.74 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1347822576750587		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.1347822576750587 | validation: 0.11755103441659129]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1255.pth
	Model improved!!!
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13386658098584564		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.13386658098584564 | validation: 0.13721093470375018]
	TIME [epoch: 9.72 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13750379114603878		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.13750379114603878 | validation: 0.15751517306970889]
	TIME [epoch: 9.71 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14724861398460418		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.14724861398460418 | validation: 0.14468517915253332]
	TIME [epoch: 9.73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15580675819437761		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.15580675819437761 | validation: 0.1408970360187808]
	TIME [epoch: 9.71 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18152431449078069		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.18152431449078069 | validation: 0.14379291293581314]
	TIME [epoch: 9.71 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14835750000112174		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.14835750000112174 | validation: 0.1534722272295365]
	TIME [epoch: 9.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13660502783954104		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.13660502783954104 | validation: 0.1287265371635182]
	TIME [epoch: 9.71 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14513425980679		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.14513425980679 | validation: 0.12781485161683456]
	TIME [epoch: 9.71 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14763054850896012		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.14763054850896012 | validation: 0.1642745712173714]
	TIME [epoch: 9.71 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15709076954594306		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.15709076954594306 | validation: 0.17479778163381185]
	TIME [epoch: 9.72 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16338820232440526		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.16338820232440526 | validation: 0.16978645434287554]
	TIME [epoch: 9.72 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16691836413549493		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.16691836413549493 | validation: 0.14072696953288372]
	TIME [epoch: 9.71 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1442905725688992		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.1442905725688992 | validation: 0.14973315191919936]
	TIME [epoch: 9.73 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1425786569607137		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.1425786569607137 | validation: 0.1544522285177554]
	TIME [epoch: 9.71 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14352066431828464		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.14352066431828464 | validation: 0.13168314929666486]
	TIME [epoch: 9.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19307034065895148		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.19307034065895148 | validation: 0.179353929166158]
	TIME [epoch: 9.73 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643666506926146		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.1643666506926146 | validation: 0.17157985683063184]
	TIME [epoch: 9.72 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1477554852960526		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.1477554852960526 | validation: 0.1691758222887207]
	TIME [epoch: 9.71 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1699588295888023		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.1699588295888023 | validation: 0.18047231786596318]
	TIME [epoch: 9.71 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532139479358972		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.1532139479358972 | validation: 0.14241382389225657]
	TIME [epoch: 9.73 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14315738935270506		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.14315738935270506 | validation: 0.1582644307351226]
	TIME [epoch: 9.71 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13925164187885863		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.13925164187885863 | validation: 0.15013589396426483]
	TIME [epoch: 9.71 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14741380975479218		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.14741380975479218 | validation: 0.14016819658815957]
	TIME [epoch: 9.74 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13242496473581905		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.13242496473581905 | validation: 0.16964427221324463]
	TIME [epoch: 9.72 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475873354289452		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.1475873354289452 | validation: 0.17334500688862836]
	TIME [epoch: 9.71 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13941453343192783		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.13941453343192783 | validation: 0.13360234443886243]
	TIME [epoch: 9.72 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14566156550131715		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.14566156550131715 | validation: 0.17667826631275307]
	TIME [epoch: 9.73 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564927795808907		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.1564927795808907 | validation: 0.18520974264390344]
	TIME [epoch: 9.71 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16445104294162255		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.16445104294162255 | validation: 0.1769911113668487]
	TIME [epoch: 9.71 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16212923806906887		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.16212923806906887 | validation: 0.1540404507065135]
	TIME [epoch: 9.73 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14003329817644056		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.14003329817644056 | validation: 0.1426435558669016]
	TIME [epoch: 9.71 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15458566434898918		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.15458566434898918 | validation: 0.16351513556998104]
	TIME [epoch: 9.71 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17171370833733282		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.17171370833733282 | validation: 0.14906977502826396]
	TIME [epoch: 9.73 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15910860286455566		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.15910860286455566 | validation: 0.12617377537341937]
	TIME [epoch: 9.71 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13303750870423114		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.13303750870423114 | validation: 0.1280550297065068]
	TIME [epoch: 9.71 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13632901745777126		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.13632901745777126 | validation: 0.12293354783989079]
	TIME [epoch: 9.71 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14510196553871318		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.14510196553871318 | validation: 0.1752380415680561]
	TIME [epoch: 9.74 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14046356488286235		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.14046356488286235 | validation: 0.14693624900227348]
	TIME [epoch: 9.72 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16274211594840354		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.16274211594840354 | validation: 0.21705965226133525]
	TIME [epoch: 9.71 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18963039019189143		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.18963039019189143 | validation: 0.15735147730467403]
	TIME [epoch: 9.73 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14332649213437548		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.14332649213437548 | validation: 0.14108050269160527]
	TIME [epoch: 9.71 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1400964376421989		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.1400964376421989 | validation: 0.12520912962612513]
	TIME [epoch: 9.71 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13504450803658305		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.13504450803658305 | validation: 0.13864956366413844]
	TIME [epoch: 9.72 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155581129438131		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.155581129438131 | validation: 0.1494354579199966]
	TIME [epoch: 9.73 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14801350988809428		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.14801350988809428 | validation: 0.12981423934672687]
	TIME [epoch: 9.71 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15183914528113024		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.15183914528113024 | validation: 0.2004134267554426]
	TIME [epoch: 9.71 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549411224364812		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.15549411224364812 | validation: 0.13501152943065986]
	TIME [epoch: 9.74 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1420096067874465		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.1420096067874465 | validation: 0.144084370684188]
	TIME [epoch: 9.71 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1487439983428153		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.1487439983428153 | validation: 0.11395510949644035]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1304.pth
	Model improved!!!
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14856803054918868		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.14856803054918868 | validation: 0.13612034271657128]
	TIME [epoch: 9.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13679296684629288		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.13679296684629288 | validation: 0.11003663597075763]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1306.pth
	Model improved!!!
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14049175893705723		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.14049175893705723 | validation: 0.19403399581072528]
	TIME [epoch: 9.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539896498701272		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.1539896498701272 | validation: 0.1625248094939974]
	TIME [epoch: 9.72 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13195000160669634		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.13195000160669634 | validation: 0.13942785936043556]
	TIME [epoch: 9.73 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16592608196906022		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.16592608196906022 | validation: 0.15065956485200116]
	TIME [epoch: 9.72 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14638939529273626		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.14638939529273626 | validation: 0.14886599252747595]
	TIME [epoch: 9.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13141608399884055		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.13141608399884055 | validation: 0.1002573005550594]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1312.pth
	Model improved!!!
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13858509340777486		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.13858509340777486 | validation: 0.1340970577782128]
	TIME [epoch: 9.71 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147088638335157		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.147088638335157 | validation: 0.14504935584581038]
	TIME [epoch: 9.71 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14344911927279286		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.14344911927279286 | validation: 0.12907131223947677]
	TIME [epoch: 9.72 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12815992634047707		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.12815992634047707 | validation: 0.14379600464806055]
	TIME [epoch: 9.71 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13649820082377345		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.13649820082377345 | validation: 0.1640127552384886]
	TIME [epoch: 9.71 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1430825770699201		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.1430825770699201 | validation: 0.13825481168461048]
	TIME [epoch: 9.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14127360630443125		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.14127360630443125 | validation: 0.12410736421371375]
	TIME [epoch: 9.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13148747926584958		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.13148747926584958 | validation: 0.15777144357501277]
	TIME [epoch: 9.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1385847082225476		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.1385847082225476 | validation: 0.13987194828767796]
	TIME [epoch: 9.7 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14245217698781218		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.14245217698781218 | validation: 0.15488650745192567]
	TIME [epoch: 9.74 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15783340787231756		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.15783340787231756 | validation: 0.15899283971620962]
	TIME [epoch: 9.71 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13650964298020596		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.13650964298020596 | validation: 0.14365492049874307]
	TIME [epoch: 9.71 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12755157501617942		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.12755157501617942 | validation: 0.12598733445224478]
	TIME [epoch: 9.72 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1466908510386642		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.1466908510386642 | validation: 0.1690953424573913]
	TIME [epoch: 9.72 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15625779565925918		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.15625779565925918 | validation: 0.16079384416772996]
	TIME [epoch: 9.71 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13920718721622713		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.13920718721622713 | validation: 0.1425383255369441]
	TIME [epoch: 9.71 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379492471657119		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.1379492471657119 | validation: 0.15347241252334143]
	TIME [epoch: 9.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2109102686026339		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.2109102686026339 | validation: 0.14087616499427386]
	TIME [epoch: 9.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15593520657377866		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.15593520657377866 | validation: 0.13966649589722782]
	TIME [epoch: 9.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13499868219728053		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.13499868219728053 | validation: 0.13744952569598695]
	TIME [epoch: 9.72 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15381466047675846		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.15381466047675846 | validation: 0.13643382762696096]
	TIME [epoch: 9.71 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14508160665257833		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.14508160665257833 | validation: 0.14960918301150708]
	TIME [epoch: 9.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1405625260159134		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.1405625260159134 | validation: 0.14059623220027348]
	TIME [epoch: 9.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13735697194673957		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.13735697194673957 | validation: 0.1625644571947472]
	TIME [epoch: 9.73 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16222603472059752		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.16222603472059752 | validation: 0.1705593133417031]
	TIME [epoch: 9.71 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19643620254881114		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.19643620254881114 | validation: 0.19055860874926298]
	TIME [epoch: 9.71 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1845576774391194		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.1845576774391194 | validation: 0.13545538301362312]
	TIME [epoch: 9.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12986754436276263		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.12986754436276263 | validation: 0.13626027112565417]
	TIME [epoch: 9.71 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14636926737703754		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.14636926737703754 | validation: 0.13635554383038015]
	TIME [epoch: 9.71 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13412451657042143		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.13412451657042143 | validation: 0.13446024275797705]
	TIME [epoch: 9.71 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1378956953503214		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.1378956953503214 | validation: 0.12970717477749485]
	TIME [epoch: 9.72 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11087198596641548		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.11087198596641548 | validation: 0.12474131978193413]
	TIME [epoch: 9.71 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12427949990911495		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.12427949990911495 | validation: 0.13955825632946603]
	TIME [epoch: 9.71 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1393313684652333		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.1393313684652333 | validation: 0.11270674388960185]
	TIME [epoch: 9.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520221134197522		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.1520221134197522 | validation: 0.20395372118845026]
	TIME [epoch: 9.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15082218248955537		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.15082218248955537 | validation: 0.13930847036814878]
	TIME [epoch: 9.71 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13227623998032445		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.13227623998032445 | validation: 0.14758058567289944]
	TIME [epoch: 9.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13896583760993592		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.13896583760993592 | validation: 0.1267303566612735]
	TIME [epoch: 9.71 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13361324256210882		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.13361324256210882 | validation: 0.14761101157915132]
	TIME [epoch: 9.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12414326681689783		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.12414326681689783 | validation: 0.13015718041797703]
	TIME [epoch: 9.71 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12440774276078206		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.12440774276078206 | validation: 0.1179107184484569]
	TIME [epoch: 9.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13183535331731075		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.13183535331731075 | validation: 0.15798768839547292]
	TIME [epoch: 9.71 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14032218770714863		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.14032218770714863 | validation: 0.13585824199348162]
	TIME [epoch: 9.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13559502510498028		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.13559502510498028 | validation: 0.16502049308483568]
	TIME [epoch: 9.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1499672289082341		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.1499672289082341 | validation: 0.13163956990172346]
	TIME [epoch: 9.71 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12183076198048455		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.12183076198048455 | validation: 0.13620290838014643]
	TIME [epoch: 9.71 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15066241451292273		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.15066241451292273 | validation: 0.13095019421348714]
	TIME [epoch: 9.71 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12428477699506588		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.12428477699506588 | validation: 0.165329974740526]
	TIME [epoch: 9.72 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622940899673802		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.1622940899673802 | validation: 0.13104456008304]
	TIME [epoch: 9.71 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1247461975311531		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.1247461975311531 | validation: 0.13820015911345443]
	TIME [epoch: 9.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13015901316236125		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.13015901316236125 | validation: 0.1252114319824496]
	TIME [epoch: 9.72 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12019936914527996		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.12019936914527996 | validation: 0.15141177834519082]
	TIME [epoch: 9.71 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13668279717686077		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.13668279717686077 | validation: 0.1560080958682755]
	TIME [epoch: 9.7 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1450684471174284		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.1450684471174284 | validation: 0.13674567028845158]
	TIME [epoch: 9.73 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12671074359879714		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.12671074359879714 | validation: 0.12215110474482739]
	TIME [epoch: 9.72 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12465042073619807		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.12465042073619807 | validation: 0.12492389201636468]
	TIME [epoch: 9.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12093566508055945		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.12093566508055945 | validation: 0.12569968828969313]
	TIME [epoch: 9.71 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11918379532854191		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.11918379532854191 | validation: 0.13321789439443957]
	TIME [epoch: 9.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13494629623374782		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.13494629623374782 | validation: 0.13927498892551385]
	TIME [epoch: 9.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1307170454191819		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.1307170454191819 | validation: 0.12153751832866717]
	TIME [epoch: 9.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12616731940011616		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.12616731940011616 | validation: 0.11385210378535492]
	TIME [epoch: 9.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1287766631696526		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.1287766631696526 | validation: 0.14613625295862231]
	TIME [epoch: 9.7 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14377444750707957		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.14377444750707957 | validation: 0.16138688659071013]
	TIME [epoch: 9.71 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17674356332249597		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.17674356332249597 | validation: 0.19865681234012278]
	TIME [epoch: 9.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15295219009001754		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.15295219009001754 | validation: 0.14717203656262262]
	TIME [epoch: 9.73 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13024582392770928		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.13024582392770928 | validation: 0.13024423257536477]
	TIME [epoch: 9.71 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1383332925778346		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.1383332925778346 | validation: 0.1516250204634173]
	TIME [epoch: 9.71 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11514729603670486		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.11514729603670486 | validation: 0.1259386018056753]
	TIME [epoch: 9.73 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11258378723701568		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.11258378723701568 | validation: 0.13955884168123572]
	TIME [epoch: 9.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452044553488418		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.1452044553488418 | validation: 0.16396197034458213]
	TIME [epoch: 9.71 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13034949738987162		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.13034949738987162 | validation: 0.13871794104059817]
	TIME [epoch: 9.72 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1252248053477068		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.1252248053477068 | validation: 0.13789376292235717]
	TIME [epoch: 9.71 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13264028849126858		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.13264028849126858 | validation: 0.1748060233414309]
	TIME [epoch: 9.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14225410389642096		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.14225410389642096 | validation: 0.16458639371992406]
	TIME [epoch: 9.71 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342807089555204		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.1342807089555204 | validation: 0.1465438618046636]
	TIME [epoch: 9.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1317196616609276		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.1317196616609276 | validation: 0.12831746925864118]
	TIME [epoch: 9.71 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11799957247422747		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.11799957247422747 | validation: 0.1281451687005981]
	TIME [epoch: 9.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12428225172555915		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.12428225172555915 | validation: 0.12494048877928292]
	TIME [epoch: 9.73 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1328476072440842		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.1328476072440842 | validation: 0.16130303521877618]
	TIME [epoch: 9.71 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12785541242180218		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.12785541242180218 | validation: 0.13315738903141136]
	TIME [epoch: 9.71 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12908818836593366		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.12908818836593366 | validation: 0.11533998978481581]
	TIME [epoch: 9.71 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537237206491993		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.1537237206491993 | validation: 0.1393645122019438]
	TIME [epoch: 9.73 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.134795242453613		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.134795242453613 | validation: 0.1256416640981138]
	TIME [epoch: 9.71 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14137636202367404		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.14137636202367404 | validation: 0.18546189263159846]
	TIME [epoch: 9.71 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481431310387318		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.1481431310387318 | validation: 0.18448242808259596]
	TIME [epoch: 9.73 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16179204094873753		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.16179204094873753 | validation: 0.18965780606549945]
	TIME [epoch: 9.71 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15607654113297806		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.15607654113297806 | validation: 0.17172569102720672]
	TIME [epoch: 9.71 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1263494242273288		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.1263494242273288 | validation: 0.130959631530875]
	TIME [epoch: 9.72 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12011102347290777		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.12011102347290777 | validation: 0.1236672400200495]
	TIME [epoch: 9.71 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12084874187975692		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.12084874187975692 | validation: 0.13974214053704445]
	TIME [epoch: 9.71 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1306615906696404		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.1306615906696404 | validation: 0.16911027711052193]
	TIME [epoch: 9.71 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13425930008148476		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.13425930008148476 | validation: 0.138568949640702]
	TIME [epoch: 9.73 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13020914602485564		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.13020914602485564 | validation: 0.12134134803023987]
	TIME [epoch: 9.71 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13106892608253942		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.13106892608253942 | validation: 0.13540919119919365]
	TIME [epoch: 9.71 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12912273884356204		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.12912273884356204 | validation: 0.13459374602857732]
	TIME [epoch: 9.73 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13777400581038018		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.13777400581038018 | validation: 0.12544814744377103]
	TIME [epoch: 9.72 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11845198045670055		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.11845198045670055 | validation: 0.12683470171633052]
	TIME [epoch: 9.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14574422634628376		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.14574422634628376 | validation: 0.14760024095421803]
	TIME [epoch: 9.71 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11403039886005013		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.11403039886005013 | validation: 0.13634782855384583]
	TIME [epoch: 9.73 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12397474399747806		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.12397474399747806 | validation: 0.16516748061371928]
	TIME [epoch: 9.7 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254304138776136		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.1254304138776136 | validation: 0.1453905626483295]
	TIME [epoch: 9.71 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1182603574053944		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.1182603574053944 | validation: 0.13024687808525454]
	TIME [epoch: 9.73 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11600036632041937		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.11600036632041937 | validation: 0.10938617605003474]
	TIME [epoch: 9.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13075644857017452		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.13075644857017452 | validation: 0.1585702965554855]
	TIME [epoch: 9.71 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12372092131541805		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.12372092131541805 | validation: 0.12397660859986558]
	TIME [epoch: 9.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12314355785216309		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.12314355785216309 | validation: 0.153851903145794]
	TIME [epoch: 9.72 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.142604950736509		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.142604950736509 | validation: 0.11236019991972249]
	TIME [epoch: 9.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11715621145906399		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.11715621145906399 | validation: 0.11758679324962841]
	TIME [epoch: 9.71 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1194738655652882		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.1194738655652882 | validation: 0.12159051304325967]
	TIME [epoch: 9.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11532399884037337		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.11532399884037337 | validation: 0.12893864884362582]
	TIME [epoch: 9.71 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13732068830504526		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.13732068830504526 | validation: 0.17670945498683074]
	TIME [epoch: 9.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14373539788020637		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.14373539788020637 | validation: 0.13451489401514208]
	TIME [epoch: 9.73 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15283408797846051		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.15283408797846051 | validation: 0.1341251477513538]
	TIME [epoch: 9.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14443361998476828		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.14443361998476828 | validation: 0.14619705623083865]
	TIME [epoch: 9.71 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12940045601790848		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.12940045601790848 | validation: 0.12920163998243475]
	TIME [epoch: 9.71 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11882023641631081		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.11882023641631081 | validation: 0.14257344668287908]
	TIME [epoch: 9.72 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1499049170443897		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.1499049170443897 | validation: 0.11705831370935461]
	TIME [epoch: 9.7 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11767721649914464		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.11767721649914464 | validation: 0.12267171751638203]
	TIME [epoch: 9.71 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12153253325512077		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.12153253325512077 | validation: 0.11862808545855436]
	TIME [epoch: 9.74 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11781275635522734		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.11781275635522734 | validation: 0.11585059452989807]
	TIME [epoch: 9.71 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12580078263582056		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.12580078263582056 | validation: 0.16269195459718305]
	TIME [epoch: 9.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15576634318485322		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.15576634318485322 | validation: 0.17676123026554075]
	TIME [epoch: 9.72 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16446341756248606		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.16446341756248606 | validation: 0.1323317012350245]
	TIME [epoch: 9.71 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1474016978278395		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.1474016978278395 | validation: 0.1903428346618535]
	TIME [epoch: 9.7 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13730875437361983		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.13730875437361983 | validation: 0.12928964340301088]
	TIME [epoch: 9.7 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12340852187270987		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.12340852187270987 | validation: 0.12342184201520798]
	TIME [epoch: 9.72 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1298659836147627		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.1298659836147627 | validation: 0.12215532012866019]
	TIME [epoch: 9.7 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1226247797564366		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.1226247797564366 | validation: 0.12105860938510739]
	TIME [epoch: 9.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11113259794788696		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.11113259794788696 | validation: 0.12164741658576728]
	TIME [epoch: 9.72 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12383231072098444		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.12383231072098444 | validation: 0.1427045067120794]
	TIME [epoch: 9.7 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13143773603773765		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.13143773603773765 | validation: 0.12155029158445682]
	TIME [epoch: 9.7 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12926287368101588		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.12926287368101588 | validation: 0.13801080597784057]
	TIME [epoch: 9.71 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1295186594649855		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.1295186594649855 | validation: 0.11164365552763166]
	TIME [epoch: 9.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12519675692390542		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.12519675692390542 | validation: 0.12326165798875285]
	TIME [epoch: 9.71 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12240702163911359		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.12240702163911359 | validation: 0.12279738434553376]
	TIME [epoch: 9.7 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253435610977357		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.1253435610977357 | validation: 0.14540380810737524]
	TIME [epoch: 9.73 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13434276822927257		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.13434276822927257 | validation: 0.13939650915861146]
	TIME [epoch: 9.71 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1194768269263218		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.1194768269263218 | validation: 0.12935334794975822]
	TIME [epoch: 9.71 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12371921209478456		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.12371921209478456 | validation: 0.12440784075581739]
	TIME [epoch: 9.72 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12022633628839094		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.12022633628839094 | validation: 0.117032867628128]
	TIME [epoch: 9.72 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11881133140312414		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.11881133140312414 | validation: 0.11659325702677613]
	TIME [epoch: 9.71 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11370687588072363		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.11370687588072363 | validation: 0.10249659075625452]
	TIME [epoch: 9.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11171905527879085		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.11171905527879085 | validation: 0.11554436176586112]
	TIME [epoch: 9.73 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11134549614540519		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.11134549614540519 | validation: 0.1295342241993734]
	TIME [epoch: 9.71 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11755975042166429		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.11755975042166429 | validation: 0.12825267495098866]
	TIME [epoch: 9.71 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12055016312601378		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.12055016312601378 | validation: 0.11108595095078105]
	TIME [epoch: 9.73 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13812002919241967		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.13812002919241967 | validation: 0.15559082979899247]
	TIME [epoch: 9.71 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1406749654649274		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.1406749654649274 | validation: 0.13198079951417793]
	TIME [epoch: 9.71 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12193223606606005		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.12193223606606005 | validation: 0.15563581219709258]
	TIME [epoch: 9.71 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13673391245652095		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.13673391245652095 | validation: 0.13880831676927577]
	TIME [epoch: 9.72 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457786201436494		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.1457786201436494 | validation: 0.15554352412404981]
	TIME [epoch: 9.71 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15335252913019062		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.15335252913019062 | validation: 0.14698131836564401]
	TIME [epoch: 9.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12189076061527959		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.12189076061527959 | validation: 0.12537255865376687]
	TIME [epoch: 9.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12766544843937694		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.12766544843937694 | validation: 0.13725305728734147]
	TIME [epoch: 9.71 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.115427174213826		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.115427174213826 | validation: 0.12405345867304954]
	TIME [epoch: 9.71 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11265904664261399		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.11265904664261399 | validation: 0.11600312730768807]
	TIME [epoch: 9.72 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11300797167632182		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.11300797167632182 | validation: 0.1105750580529724]
	TIME [epoch: 9.72 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11330608909532529		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.11330608909532529 | validation: 0.12970412145834337]
	TIME [epoch: 9.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1394717710413737		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.1394717710413737 | validation: 0.1390139786999956]
	TIME [epoch: 9.71 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14230029174220946		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.14230029174220946 | validation: 0.12410490371096305]
	TIME [epoch: 9.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1244213179382982		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.1244213179382982 | validation: 0.14507535923484266]
	TIME [epoch: 9.71 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12734757047310669		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.12734757047310669 | validation: 0.12403714224284793]
	TIME [epoch: 9.71 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13037664327069703		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.13037664327069703 | validation: 0.13958042951575594]
	TIME [epoch: 9.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11606615594852202		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.11606615594852202 | validation: 0.13275673520008405]
	TIME [epoch: 9.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12061501019905		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.12061501019905 | validation: 0.1278941795258343]
	TIME [epoch: 9.71 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1299401013390434		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.1299401013390434 | validation: 0.11995335464345434]
	TIME [epoch: 9.71 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14259974153516464		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.14259974153516464 | validation: 0.12951180727076722]
	TIME [epoch: 9.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13178839948754364		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.13178839948754364 | validation: 0.14984075652528778]
	TIME [epoch: 9.71 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14393656403643507		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.14393656403643507 | validation: 0.1577923889036832]
	TIME [epoch: 9.71 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13845901242855962		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.13845901242855962 | validation: 0.1297522880048384]
	TIME [epoch: 9.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253061134978394		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.1253061134978394 | validation: 0.117926176248892]
	TIME [epoch: 9.71 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12703419310773442		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.12703419310773442 | validation: 0.14010448334064982]
	TIME [epoch: 9.71 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12593335859747612		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.12593335859747612 | validation: 0.13052931389192554]
	TIME [epoch: 9.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12225152341217735		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.12225152341217735 | validation: 0.1607601913203723]
	TIME [epoch: 9.72 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12752627088735663		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.12752627088735663 | validation: 0.12348577364996483]
	TIME [epoch: 9.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11723920287829843		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.11723920287829843 | validation: 0.12256488942821658]
	TIME [epoch: 9.71 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1142980212145148		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.1142980212145148 | validation: 0.12037094883308999]
	TIME [epoch: 9.73 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11459688773391759		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.11459688773391759 | validation: 0.11795109408706177]
	TIME [epoch: 9.71 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11547192247144408		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.11547192247144408 | validation: 0.12626901566989074]
	TIME [epoch: 9.71 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12335576160751394		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.12335576160751394 | validation: 0.14289792838433268]
	TIME [epoch: 9.74 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1252105965795836		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.1252105965795836 | validation: 0.11880904434518837]
	TIME [epoch: 9.71 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12392228497725558		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.12392228497725558 | validation: 0.12344614056947853]
	TIME [epoch: 9.71 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11957831712331564		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.11957831712331564 | validation: 0.11138559045850276]
	TIME [epoch: 9.71 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10867582250263348		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.10867582250263348 | validation: 0.10626856173418006]
	TIME [epoch: 9.72 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11220403808850805		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.11220403808850805 | validation: 0.11985002380857808]
	TIME [epoch: 9.71 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12524571381008903		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.12524571381008903 | validation: 0.1709002665079516]
	TIME [epoch: 9.71 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520997224104349		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.1520997224104349 | validation: 0.11710836610731903]
	TIME [epoch: 9.73 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11598806976137559		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.11598806976137559 | validation: 0.10844488742372722]
	TIME [epoch: 9.71 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13447797776925613		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.13447797776925613 | validation: 0.1763326585386087]
	TIME [epoch: 9.71 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16291838818618448		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.16291838818618448 | validation: 0.15578983336709834]
	TIME [epoch: 9.73 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13904419637075868		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.13904419637075868 | validation: 0.17494936842659428]
	TIME [epoch: 9.71 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15599174060085697		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.15599174060085697 | validation: 0.1605459125243892]
	TIME [epoch: 9.71 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1437111675769989		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.1437111675769989 | validation: 0.15932203125742014]
	TIME [epoch: 9.71 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15945554107477358		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.15945554107477358 | validation: 0.1282422269717267]
	TIME [epoch: 9.73 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14383748386432432		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.14383748386432432 | validation: 0.15068917397159837]
	TIME [epoch: 9.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12334629516973153		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.12334629516973153 | validation: 0.1116742375302527]
	TIME [epoch: 9.71 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13345444545381413		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.13345444545381413 | validation: 0.1526631264997094]
	TIME [epoch: 9.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1899778953316152		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.1899778953316152 | validation: 0.20884764586619098]
	TIME [epoch: 9.71 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19188529052262854		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.19188529052262854 | validation: 0.1685037601862602]
	TIME [epoch: 9.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674998014199451		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.1674998014199451 | validation: 0.2250618142332732]
	TIME [epoch: 9.71 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19994836673918318		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.19994836673918318 | validation: 0.1602417784141854]
	TIME [epoch: 9.73 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15834777540880013		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.15834777540880013 | validation: 0.16485943212695084]
	TIME [epoch: 9.71 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14014603764154798		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.14014603764154798 | validation: 0.12753912032279371]
	TIME [epoch: 9.7 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11645124837641092		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.11645124837641092 | validation: 0.12018540125043682]
	TIME [epoch: 9.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12309853939695234		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.12309853939695234 | validation: 0.12120650185512054]
	TIME [epoch: 9.7 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11483458710503092		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.11483458710503092 | validation: 0.11440820034382307]
	TIME [epoch: 9.71 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11487374761376934		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.11487374761376934 | validation: 0.10380633056773904]
	TIME [epoch: 9.72 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11673743899768722		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.11673743899768722 | validation: 0.1303658279408723]
	TIME [epoch: 9.71 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13460402258540732		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.13460402258540732 | validation: 0.15614165338664815]
	TIME [epoch: 9.7 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1409996605308564		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.1409996605308564 | validation: 0.1227009904513099]
	TIME [epoch: 9.71 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13115346021748958		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.13115346021748958 | validation: 0.13266421076620513]
	TIME [epoch: 9.73 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12365888076471832		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.12365888076471832 | validation: 0.1441479770069784]
	TIME [epoch: 9.71 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11268363997247337		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.11268363997247337 | validation: 0.1171605284432032]
	TIME [epoch: 9.7 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11271217670981948		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.11271217670981948 | validation: 0.12338902479345507]
	TIME [epoch: 9.73 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11142201672352889		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.11142201672352889 | validation: 0.12570870999531938]
	TIME [epoch: 9.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12093729578730042		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.12093729578730042 | validation: 0.11119797963369596]
	TIME [epoch: 9.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10734395915521769		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.10734395915521769 | validation: 0.12380550456319048]
	TIME [epoch: 9.72 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12817344684662077		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.12817344684662077 | validation: 0.12195209624497409]
	TIME [epoch: 9.72 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11913235187355761		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.11913235187355761 | validation: 0.11293112854350042]
	TIME [epoch: 9.71 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10674234506046135		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.10674234506046135 | validation: 0.14243311937721137]
	TIME [epoch: 9.7 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11206152172242348		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.11206152172242348 | validation: 0.11156244800273715]
	TIME [epoch: 9.73 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10260755647997877		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.10260755647997877 | validation: 0.1104361130511105]
	TIME [epoch: 9.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10783611176967715		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.10783611176967715 | validation: 0.12107423917209756]
	TIME [epoch: 9.71 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11601542284940813		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.11601542284940813 | validation: 0.11706164761915475]
	TIME [epoch: 9.72 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11480247132601987		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.11480247132601987 | validation: 0.11332037406595885]
	TIME [epoch: 9.71 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13571881195911484		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.13571881195911484 | validation: 0.11650840745676375]
	TIME [epoch: 9.71 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13157724883152583		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.13157724883152583 | validation: 0.15051397675524888]
	TIME [epoch: 9.71 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14733437145667955		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.14733437145667955 | validation: 0.13315125591869842]
	TIME [epoch: 9.73 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11991629983198256		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.11991629983198256 | validation: 0.11363283682755194]
	TIME [epoch: 9.71 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11618288782069497		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.11618288782069497 | validation: 0.1133232430535583]
	TIME [epoch: 9.7 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11761106204874679		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.11761106204874679 | validation: 0.11731685840080416]
	TIME [epoch: 9.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11784898973874154		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.11784898973874154 | validation: 0.11883162856057006]
	TIME [epoch: 9.71 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0976954532930279		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.0976954532930279 | validation: 0.1269259070861516]
	TIME [epoch: 9.71 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12238347215819825		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.12238347215819825 | validation: 0.12396771667719036]
	TIME [epoch: 9.71 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11435998228116881		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.11435998228116881 | validation: 0.11277947608472096]
	TIME [epoch: 9.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092354355889309		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.1092354355889309 | validation: 0.11315662572130693]
	TIME [epoch: 9.72 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11985798275042517		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.11985798275042517 | validation: 0.11082763792910379]
	TIME [epoch: 9.71 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11506623115257297		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.11506623115257297 | validation: 0.10506306116317848]
	TIME [epoch: 9.73 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11225145835534422		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.11225145835534422 | validation: 0.1046952462842454]
	TIME [epoch: 9.71 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10109331275127997		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.10109331275127997 | validation: 0.11559737212741691]
	TIME [epoch: 9.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10716358034257148		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.10716358034257148 | validation: 0.10154310568835877]
	TIME [epoch: 9.72 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11935351728152344		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.11935351728152344 | validation: 0.1317494363295145]
	TIME [epoch: 9.71 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11681478257823603		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.11681478257823603 | validation: 0.1300660715889287]
	TIME [epoch: 9.7 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11616067981957996		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.11616067981957996 | validation: 0.11804363853643687]
	TIME [epoch: 9.7 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11428714342104315		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.11428714342104315 | validation: 0.09616261263659383]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1557.pth
	Model improved!!!
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11080987523592352		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.11080987523592352 | validation: 0.1154813347454417]
	TIME [epoch: 9.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11018945043047534		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.11018945043047534 | validation: 0.10311551722395393]
	TIME [epoch: 9.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10587957140230389		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.10587957140230389 | validation: 0.12148016806379194]
	TIME [epoch: 9.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1015854575043594		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.1015854575043594 | validation: 0.12339614810454906]
	TIME [epoch: 9.71 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13043399327584537		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.13043399327584537 | validation: 0.12429399323261171]
	TIME [epoch: 9.7 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11193182135151711		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.11193182135151711 | validation: 0.10946525487460643]
	TIME [epoch: 9.71 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1219541331055218		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.1219541331055218 | validation: 0.11139996600552199]
	TIME [epoch: 9.72 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10532078805154296		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.10532078805154296 | validation: 0.09843271323302069]
	TIME [epoch: 9.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10246122663804476		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.10246122663804476 | validation: 0.11959885414931412]
	TIME [epoch: 9.7 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10781714683837562		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.10781714683837562 | validation: 0.11529019549181203]
	TIME [epoch: 9.72 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1100653386623047		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.1100653386623047 | validation: 0.10326048272730937]
	TIME [epoch: 9.71 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10607922249730879		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.10607922249730879 | validation: 0.11891566894147397]
	TIME [epoch: 9.71 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11544890579161186		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.11544890579161186 | validation: 0.11552338500080968]
	TIME [epoch: 9.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11321946133483377		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.11321946133483377 | validation: 0.1225094663088302]
	TIME [epoch: 9.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11130849902405031		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.11130849902405031 | validation: 0.13968050372285779]
	TIME [epoch: 9.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10786546302222913		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.10786546302222913 | validation: 0.12029599059363687]
	TIME [epoch: 9.7 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11785901439939868		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.11785901439939868 | validation: 0.09310733657592547]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1574.pth
	Model improved!!!
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10159286730572806		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.10159286730572806 | validation: 0.11443583748979493]
	TIME [epoch: 9.72 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10807886468530921		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.10807886468530921 | validation: 0.12106341959929807]
	TIME [epoch: 9.72 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1051373982866924		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.1051373982866924 | validation: 0.10447320110880799]
	TIME [epoch: 9.76 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10459837556426957		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.10459837556426957 | validation: 0.12723558704527366]
	TIME [epoch: 9.72 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11819191562786151		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.11819191562786151 | validation: 0.1339032746270392]
	TIME [epoch: 9.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11358858791580828		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.11358858791580828 | validation: 0.11384787366335244]
	TIME [epoch: 9.72 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10351991921032018		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.10351991921032018 | validation: 0.13391015524405206]
	TIME [epoch: 9.75 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12048273052567984		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.12048273052567984 | validation: 0.15153739396101024]
	TIME [epoch: 9.72 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11615771564616059		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.11615771564616059 | validation: 0.11250512250755794]
	TIME [epoch: 9.71 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10340623287603623		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.10340623287603623 | validation: 0.12302507302699779]
	TIME [epoch: 9.74 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10270681841549245		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.10270681841549245 | validation: 0.11268991612102233]
	TIME [epoch: 9.71 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.119340925695372		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.119340925695372 | validation: 0.15433061178721658]
	TIME [epoch: 9.73 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12569178672263354		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.12569178672263354 | validation: 0.11107372942975395]
	TIME [epoch: 9.74 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12983318176542472		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.12983318176542472 | validation: 0.1155928179988468]
	TIME [epoch: 9.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12431262268389516		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.12431262268389516 | validation: 0.11206432916487373]
	TIME [epoch: 9.73 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11364242532204749		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.11364242532204749 | validation: 0.12348779550584342]
	TIME [epoch: 9.72 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10972187240888101		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.10972187240888101 | validation: 0.11589257456055199]
	TIME [epoch: 9.73 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11061229492611624		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.11061229492611624 | validation: 0.11379948403435462]
	TIME [epoch: 9.71 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10716192690238588		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.10716192690238588 | validation: 0.1016680714220358]
	TIME [epoch: 9.71 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10710439758323653		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.10710439758323653 | validation: 0.11201464178135809]
	TIME [epoch: 9.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10175771165043099		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.10175771165043099 | validation: 0.10427592079871911]
	TIME [epoch: 9.72 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10761964152101755		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.10761964152101755 | validation: 0.1131748505295225]
	TIME [epoch: 9.72 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12429880966580034		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.12429880966580034 | validation: 0.10258779714829382]
	TIME [epoch: 9.73 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11185130623942312		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.11185130623942312 | validation: 0.13829585185014223]
	TIME [epoch: 9.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1477342026784324		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.1477342026784324 | validation: 0.1322151428673721]
	TIME [epoch: 9.72 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12307545378991638		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.12307545378991638 | validation: 0.12938334372669918]
	TIME [epoch: 9.71 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10255518546155369		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.10255518546155369 | validation: 0.12608657331809447]
	TIME [epoch: 9.74 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12182077472237404		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.12182077472237404 | validation: 0.11572469635382043]
	TIME [epoch: 9.71 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10678516384612102		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.10678516384612102 | validation: 0.13413386404182664]
	TIME [epoch: 9.71 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11714973535517466		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.11714973535517466 | validation: 0.10968933181789133]
	TIME [epoch: 9.73 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10442851219359003		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.10442851219359003 | validation: 0.10364667815401425]
	TIME [epoch: 9.72 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11065184870679698		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.11065184870679698 | validation: 0.1288861761260519]
	TIME [epoch: 9.71 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11558034992797957		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.11558034992797957 | validation: 0.12388731340935215]
	TIME [epoch: 9.72 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11950138885078776		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.11950138885078776 | validation: 0.11065080887846708]
	TIME [epoch: 9.73 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1021118298202659		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.1021118298202659 | validation: 0.11540510252720369]
	TIME [epoch: 9.71 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10609177656373485		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.10609177656373485 | validation: 0.10340892788212433]
	TIME [epoch: 9.71 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10690130406323281		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.10690130406323281 | validation: 0.11952466780181661]
	TIME [epoch: 9.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11060844045733191		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.11060844045733191 | validation: 0.1349885163167804]
	TIME [epoch: 9.72 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10753746415407987		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.10753746415407987 | validation: 0.10166519702861859]
	TIME [epoch: 9.71 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10868983517043773		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.10868983517043773 | validation: 0.13055342892292834]
	TIME [epoch: 9.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1268516144449479		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.1268516144449479 | validation: 0.1259704139748122]
	TIME [epoch: 9.73 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12585528433821086		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.12585528433821086 | validation: 0.1397720412386733]
	TIME [epoch: 9.71 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12321212814871763		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.12321212814871763 | validation: 0.12111360590853179]
	TIME [epoch: 9.72 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11804765924472789		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.11804765924472789 | validation: 0.10361478443912121]
	TIME [epoch: 9.74 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12073890932031899		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.12073890932031899 | validation: 0.13412360517969643]
	TIME [epoch: 9.72 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10020646137725797		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.10020646137725797 | validation: 0.1101346564943926]
	TIME [epoch: 9.71 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10908940545493043		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.10908940545493043 | validation: 0.10456285040161722]
	TIME [epoch: 9.73 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10650672374119478		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.10650672374119478 | validation: 0.09422518125821022]
	TIME [epoch: 9.72 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09907217699197327		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.09907217699197327 | validation: 0.105437862814992]
	TIME [epoch: 9.72 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10019755249755757		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.10019755249755757 | validation: 0.11305703482662031]
	TIME [epoch: 9.72 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11285244444543499		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.11285244444543499 | validation: 0.12253466007409411]
	TIME [epoch: 9.73 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11542683357086066		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.11542683357086066 | validation: 0.12103562997991656]
	TIME [epoch: 9.72 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10856945474899762		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.10856945474899762 | validation: 0.1276786513519747]
	TIME [epoch: 9.71 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12161885606371911		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.12161885606371911 | validation: 0.10627475420772989]
	TIME [epoch: 9.74 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10742202634963467		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.10742202634963467 | validation: 0.11401058025002783]
	TIME [epoch: 9.71 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13009831637905114		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.13009831637905114 | validation: 0.11902396639647118]
	TIME [epoch: 9.71 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11168083018519348		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.11168083018519348 | validation: 0.10439286930815084]
	TIME [epoch: 9.72 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11536980027915666		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.11536980027915666 | validation: 0.12247558022549558]
	TIME [epoch: 9.72 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10849040089117681		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.10849040089117681 | validation: 0.11789959204352414]
	TIME [epoch: 9.72 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10398215761004144		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.10398215761004144 | validation: 0.11249691424084667]
	TIME [epoch: 9.71 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10668520366284702		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.10668520366284702 | validation: 0.11236083524071272]
	TIME [epoch: 9.74 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11063433331211388		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.11063433331211388 | validation: 0.11679041545781967]
	TIME [epoch: 9.72 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1088972408425812		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.1088972408425812 | validation: 0.1160467098173875]
	TIME [epoch: 9.71 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1177721234962458		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.1177721234962458 | validation: 0.10985567883804606]
	TIME [epoch: 9.74 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1027314642792111		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.1027314642792111 | validation: 0.1116139677803244]
	TIME [epoch: 9.72 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11555686202344488		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.11555686202344488 | validation: 0.09564303003147939]
	TIME [epoch: 9.71 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10690511308081922		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.10690511308081922 | validation: 0.10721568948013463]
	TIME [epoch: 9.72 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10455845889496199		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.10455845889496199 | validation: 0.10998658885820518]
	TIME [epoch: 9.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102817027675567		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.102817027675567 | validation: 0.12276141029630944]
	TIME [epoch: 9.72 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11832015329472675		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.11832015329472675 | validation: 0.12282210505605658]
	TIME [epoch: 9.72 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1194726889651776		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.1194726889651776 | validation: 0.1322657514338269]
	TIME [epoch: 9.74 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13702462329482962		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.13702462329482962 | validation: 0.1259934261282662]
	TIME [epoch: 9.72 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12368465176537762		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.12368465176537762 | validation: 0.11669591541236493]
	TIME [epoch: 9.72 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11669550950798009		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.11669550950798009 | validation: 0.09769683377586834]
	TIME [epoch: 9.72 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11022994716159826		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.11022994716159826 | validation: 0.11767942650529356]
	TIME [epoch: 9.72 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10790389239666373		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.10790389239666373 | validation: 0.1144085731131795]
	TIME [epoch: 9.72 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10745019241793216		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.10745019241793216 | validation: 0.10990790774750363]
	TIME [epoch: 9.72 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11642944113688354		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.11642944113688354 | validation: 0.12653391232158742]
	TIME [epoch: 9.74 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1137804394685955		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.1137804394685955 | validation: 0.12280441248496042]
	TIME [epoch: 9.71 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09987976819762656		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.09987976819762656 | validation: 0.11272963571946303]
	TIME [epoch: 9.7 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12296322028255488		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.12296322028255488 | validation: 0.12682277350107357]
	TIME [epoch: 9.73 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.132145705541093		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.132145705541093 | validation: 0.11155884209273544]
	TIME [epoch: 9.7 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11730479645606065		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.11730479645606065 | validation: 0.10330663434865066]
	TIME [epoch: 9.7 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10139555958863991		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.10139555958863991 | validation: 0.0960677585588691]
	TIME [epoch: 9.72 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11201860943433836		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.11201860943433836 | validation: 0.12551332367850518]
	TIME [epoch: 9.73 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11127886377905986		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.11127886377905986 | validation: 0.10579944801946418]
	TIME [epoch: 9.72 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11281397115878807		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.11281397115878807 | validation: 0.11013195570364674]
	TIME [epoch: 9.71 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11057128775165959		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.11057128775165959 | validation: 0.11623978753500669]
	TIME [epoch: 9.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10658662686250472		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.10658662686250472 | validation: 0.11736472900461432]
	TIME [epoch: 9.71 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10939548224306186		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.10939548224306186 | validation: 0.10137930898189289]
	TIME [epoch: 9.72 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11918948781207676		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.11918948781207676 | validation: 0.11670021624560603]
	TIME [epoch: 9.72 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11084328083090025		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.11084328083090025 | validation: 0.1491122749791747]
	TIME [epoch: 9.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1265448276305945		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.1265448276305945 | validation: 0.10770232486927497]
	TIME [epoch: 9.71 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12241372244051066		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.12241372244051066 | validation: 0.11210875795051031]
	TIME [epoch: 9.73 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10840328691939372		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.10840328691939372 | validation: 0.10663651222348858]
	TIME [epoch: 9.74 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09604260225922258		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.09604260225922258 | validation: 0.10125896664826897]
	TIME [epoch: 9.71 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10904209269284446		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.10904209269284446 | validation: 0.10924868109593373]
	TIME [epoch: 9.72 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10942113420437134		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.10942113420437134 | validation: 0.1380119744896953]
	TIME [epoch: 9.75 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12517754191865654		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.12517754191865654 | validation: 0.1171059860067882]
	TIME [epoch: 9.71 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10781910707232126		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.10781910707232126 | validation: 0.09717759509208972]
	TIME [epoch: 9.71 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11521717095562545		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.11521717095562545 | validation: 0.12223201898013264]
	TIME [epoch: 9.72 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11265575093687659		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.11265575093687659 | validation: 0.10565223152957724]
	TIME [epoch: 9.73 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11027070323915958		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.11027070323915958 | validation: 0.10498687651482538]
	TIME [epoch: 9.71 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10649059857338021		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.10649059857338021 | validation: 0.10745352917277089]
	TIME [epoch: 9.71 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09336576029060281		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.09336576029060281 | validation: 0.10258465296512716]
	TIME [epoch: 9.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10463678469213358		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.10463678469213358 | validation: 0.12101356131353067]
	TIME [epoch: 9.71 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10424840805198898		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.10424840805198898 | validation: 0.10638047945628881]
	TIME [epoch: 9.71 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10236298192492443		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.10236298192492443 | validation: 0.12240207403587874]
	TIME [epoch: 9.75 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13553051284010498		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.13553051284010498 | validation: 0.10321929590846338]
	TIME [epoch: 9.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11219318075775922		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.11219318075775922 | validation: 0.10288611982688163]
	TIME [epoch: 9.73 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09846226784679077		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.09846226784679077 | validation: 0.11170055240185404]
	TIME [epoch: 9.71 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1149749551636321		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.1149749551636321 | validation: 0.10988848078947049]
	TIME [epoch: 9.75 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10977681925824374		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.10977681925824374 | validation: 0.10468527886780014]
	TIME [epoch: 9.71 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11826776934353156		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.11826776934353156 | validation: 0.13237844803335333]
	TIME [epoch: 9.71 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11507043940691294		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.11507043940691294 | validation: 0.11551977571007935]
	TIME [epoch: 9.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11492399564842168		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.11492399564842168 | validation: 0.11193161867799699]
	TIME [epoch: 9.72 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11072519575592019		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.11072519575592019 | validation: 0.11007115796698774]
	TIME [epoch: 9.71 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10434463026371887		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.10434463026371887 | validation: 0.10772566547868212]
	TIME [epoch: 9.73 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10907964099786856		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.10907964099786856 | validation: 0.10389995079545745]
	TIME [epoch: 9.72 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10505855356574263		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.10505855356574263 | validation: 0.09629773981476834]
	TIME [epoch: 9.72 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09933681770249278		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.09933681770249278 | validation: 0.10111241624378811]
	TIME [epoch: 9.71 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10083373364344203		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.10083373364344203 | validation: 0.11997275974848735]
	TIME [epoch: 9.74 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10711424170228608		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.10711424170228608 | validation: 0.11433959352054904]
	TIME [epoch: 9.71 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10764336113134998		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.10764336113134998 | validation: 0.09668218822772413]
	TIME [epoch: 9.72 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10087321950336406		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.10087321950336406 | validation: 0.1081293632474596]
	TIME [epoch: 9.73 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10455068022099057		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.10455068022099057 | validation: 0.11974738797727849]
	TIME [epoch: 9.71 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.107425470707784		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.107425470707784 | validation: 0.10212035005291585]
	TIME [epoch: 9.72 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0959322199083437		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.0959322199083437 | validation: 0.11196291662847649]
	TIME [epoch: 9.71 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10424047767739186		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.10424047767739186 | validation: 0.11034733955706534]
	TIME [epoch: 9.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10036800825621761		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.10036800825621761 | validation: 0.11516579595382562]
	TIME [epoch: 9.72 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11065458173231717		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.11065458173231717 | validation: 0.11446117716387612]
	TIME [epoch: 9.71 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11280158765150114		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.11280158765150114 | validation: 0.10576562279898717]
	TIME [epoch: 9.73 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10481742861453838		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.10481742861453838 | validation: 0.1056092389332019]
	TIME [epoch: 9.71 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966933933670842		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.09966933933670842 | validation: 0.10764651476026124]
	TIME [epoch: 9.72 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11761225230650667		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.11761225230650667 | validation: 0.10817070980017185]
	TIME [epoch: 9.73 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10642435463690032		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.10642435463690032 | validation: 0.11762826684870996]
	TIME [epoch: 9.73 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1130924076602238		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.1130924076602238 | validation: 0.1303224973590696]
	TIME [epoch: 9.71 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12165857547528444		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.12165857547528444 | validation: 0.11095786625438919]
	TIME [epoch: 9.71 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10619421693770022		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.10619421693770022 | validation: 0.10729351193744682]
	TIME [epoch: 9.74 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11598017823915951		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.11598017823915951 | validation: 0.10162984803484294]
	TIME [epoch: 9.71 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10737798657589656		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.10737798657589656 | validation: 0.12011878516173795]
	TIME [epoch: 9.71 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11488549822107585		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.11488549822107585 | validation: 0.1253366985168529]
	TIME [epoch: 9.73 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10974941278828372		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.10974941278828372 | validation: 0.1185013691714013]
	TIME [epoch: 9.71 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1123858262129361		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.1123858262129361 | validation: 0.10719708650441724]
	TIME [epoch: 9.71 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10323268459556476		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.10323268459556476 | validation: 0.11272547945670741]
	TIME [epoch: 9.72 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10648447460221293		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.10648447460221293 | validation: 0.10719920917710557]
	TIME [epoch: 9.75 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09595578774569828		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.09595578774569828 | validation: 0.11385513352400657]
	TIME [epoch: 9.72 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10589708840533589		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.10589708840533589 | validation: 0.10220185102936981]
	TIME [epoch: 9.72 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10362337854132483		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.10362337854132483 | validation: 0.09859841267693714]
	TIME [epoch: 9.75 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11540583303345746		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.11540583303345746 | validation: 0.11709102772143286]
	TIME [epoch: 9.73 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.098829609681831		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.098829609681831 | validation: 0.11025323924484541]
	TIME [epoch: 9.72 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1088687371457816		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.1088687371457816 | validation: 0.1206492203922953]
	TIME [epoch: 9.72 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12251211944254525		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.12251211944254525 | validation: 0.11316771756588764]
	TIME [epoch: 9.75 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10703904954383166		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.10703904954383166 | validation: 0.12748056894859316]
	TIME [epoch: 9.72 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11603971581474577		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.11603971581474577 | validation: 0.13050437625378017]
	TIME [epoch: 9.72 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.112589341505358		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.112589341505358 | validation: 0.1161328712236677]
	TIME [epoch: 9.75 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10827529890493656		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.10827529890493656 | validation: 0.10748429567481001]
	TIME [epoch: 9.71 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09824023862057388		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.09824023862057388 | validation: 0.11385111015036062]
	TIME [epoch: 9.71 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10601415494452042		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.10601415494452042 | validation: 0.09867301853656306]
	TIME [epoch: 9.73 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10195840849671459		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.10195840849671459 | validation: 0.10368903259891372]
	TIME [epoch: 9.72 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09795516458700788		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.09795516458700788 | validation: 0.13744751474768183]
	TIME [epoch: 9.72 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12461343060509553		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.12461343060509553 | validation: 0.12140893835954217]
	TIME [epoch: 9.71 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10623417533937271		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.10623417533937271 | validation: 0.1039684217574041]
	TIME [epoch: 9.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10000282889470255		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.10000282889470255 | validation: 0.11098324774946089]
	TIME [epoch: 9.71 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1014671316401878		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.1014671316401878 | validation: 0.11312622005097811]
	TIME [epoch: 9.71 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11307558667868656		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.11307558667868656 | validation: 0.12780717367190392]
	TIME [epoch: 9.73 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10948958154074036		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.10948958154074036 | validation: 0.12618759779807237]
	TIME [epoch: 9.72 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10951927636726495		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.10951927636726495 | validation: 0.12624406413006684]
	TIME [epoch: 9.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10723315014168369		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.10723315014168369 | validation: 0.11716347114224249]
	TIME [epoch: 9.71 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10914575724774725		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.10914575724774725 | validation: 0.10707170518767978]
	TIME [epoch: 9.73 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10544198082290554		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.10544198082290554 | validation: 0.11423096229594873]
	TIME [epoch: 9.71 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11339695628956611		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.11339695628956611 | validation: 0.10122776973970027]
	TIME [epoch: 9.71 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10578607385151481		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.10578607385151481 | validation: 0.11012326371007645]
	TIME [epoch: 9.75 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10922247505935949		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.10922247505935949 | validation: 0.10819643512188501]
	TIME [epoch: 9.71 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11552645099019096		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.11552645099019096 | validation: 0.10212986045111634]
	TIME [epoch: 9.72 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10721787996300872		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.10721787996300872 | validation: 0.14907060519472856]
	TIME [epoch: 9.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11594530724638259		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.11594530724638259 | validation: 0.11199682225878327]
	TIME [epoch: 9.73 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1079728790015404		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.1079728790015404 | validation: 0.12064718800021515]
	TIME [epoch: 9.72 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13239633328826148		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.13239633328826148 | validation: 0.11483353825690032]
	TIME [epoch: 9.72 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10828446100971437		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.10828446100971437 | validation: 0.10859490325772168]
	TIME [epoch: 9.75 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10825580560692996		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.10825580560692996 | validation: 0.1169161464827046]
	TIME [epoch: 9.71 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1024471857526327		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.1024471857526327 | validation: 0.08783276746681287]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1756.pth
	Model improved!!!
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09631355883459407		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.09631355883459407 | validation: 0.11107169579603156]
	TIME [epoch: 9.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09779929699177453		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.09779929699177453 | validation: 0.10178846884610607]
	TIME [epoch: 9.72 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10170645575532802		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.10170645575532802 | validation: 0.12458938055168638]
	TIME [epoch: 9.72 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11320709801114655		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.11320709801114655 | validation: 0.12129857147691993]
	TIME [epoch: 9.74 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10147266541927488		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.10147266541927488 | validation: 0.09911871552207943]
	TIME [epoch: 9.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09874152916502482		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.09874152916502482 | validation: 0.09989821712430448]
	TIME [epoch: 9.72 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10339216463305823		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.10339216463305823 | validation: 0.13907097234815724]
	TIME [epoch: 9.72 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11712872771373457		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.11712872771373457 | validation: 0.11281918482825354]
	TIME [epoch: 9.74 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10461377850100131		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.10461377850100131 | validation: 0.12873380264178913]
	TIME [epoch: 9.73 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10901463165488993		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.10901463165488993 | validation: 0.09652797317827329]
	TIME [epoch: 9.72 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1006649366022184		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.1006649366022184 | validation: 0.1181999525506221]
	TIME [epoch: 9.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1035235533727262		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.1035235533727262 | validation: 0.09872003017936447]
	TIME [epoch: 9.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12339230251784288		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.12339230251784288 | validation: 0.14060110432723422]
	TIME [epoch: 9.7 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12126919373526499		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.12126919373526499 | validation: 0.13146439668908538]
	TIME [epoch: 9.74 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11183907003842257		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.11183907003842257 | validation: 0.11058059471384639]
	TIME [epoch: 9.74 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10587402288739205		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.10587402288739205 | validation: 0.11640147430878386]
	TIME [epoch: 9.72 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1082578500609225		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.1082578500609225 | validation: 0.11574317770352041]
	TIME [epoch: 9.71 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11210836294640333		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.11210836294640333 | validation: 0.10912324429453986]
	TIME [epoch: 9.74 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10141254557586155		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.10141254557586155 | validation: 0.10320621753165846]
	TIME [epoch: 9.72 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10603140283729165		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.10603140283729165 | validation: 0.11243444511664703]
	TIME [epoch: 9.72 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10245180484510848		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.10245180484510848 | validation: 0.10892147917136065]
	TIME [epoch: 9.73 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1059893042252968		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.1059893042252968 | validation: 0.10943683904738442]
	TIME [epoch: 9.72 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09664116175836363		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.09664116175836363 | validation: 0.11094734918286606]
	TIME [epoch: 9.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11109528536372966		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.11109528536372966 | validation: 0.11240527620257434]
	TIME [epoch: 9.72 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10008338870134015		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.10008338870134015 | validation: 0.1096457683332425]
	TIME [epoch: 9.75 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10900156874042781		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.10900156874042781 | validation: 0.11334967737316248]
	TIME [epoch: 9.72 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10326854414563588		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.10326854414563588 | validation: 0.107259801100173]
	TIME [epoch: 9.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09486828169779035		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.09486828169779035 | validation: 0.10076810623080362]
	TIME [epoch: 9.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09572097876440323		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.09572097876440323 | validation: 0.08929260070577548]
	TIME [epoch: 9.72 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10879288715813065		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.10879288715813065 | validation: 0.10683397902920326]
	TIME [epoch: 9.72 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09983072661940959		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.09983072661940959 | validation: 0.1043054549063547]
	TIME [epoch: 9.73 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10326690447701621		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.10326690447701621 | validation: 0.10596899328350055]
	TIME [epoch: 9.75 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1063393197323945		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.1063393197323945 | validation: 0.11119861454849743]
	TIME [epoch: 9.71 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1094360534694702		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.1094360534694702 | validation: 0.11823738451557426]
	TIME [epoch: 9.72 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11019911893155732		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.11019911893155732 | validation: 0.11521048689861683]
	TIME [epoch: 9.74 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10767432375326043		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.10767432375326043 | validation: 0.11077337940316664]
	TIME [epoch: 9.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10055735389767093		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.10055735389767093 | validation: 0.11390056265153523]
	TIME [epoch: 9.71 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09983648229948024		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.09983648229948024 | validation: 0.13823132985081318]
	TIME [epoch: 9.74 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12023190397782624		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.12023190397782624 | validation: 0.1216116521957137]
	TIME [epoch: 9.74 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12536597512094874		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.12536597512094874 | validation: 0.14055354109262655]
	TIME [epoch: 9.72 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11928979659711084		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.11928979659711084 | validation: 0.10605600595735626]
	TIME [epoch: 9.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10095180430503461		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.10095180430503461 | validation: 0.10655032775618266]
	TIME [epoch: 9.74 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10280528346311653		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.10280528346311653 | validation: 0.09403134030767354]
	TIME [epoch: 9.72 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09715429127260994		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.09715429127260994 | validation: 0.11474107929107379]
	TIME [epoch: 9.71 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1160729436785298		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.1160729436785298 | validation: 0.09527528604436906]
	TIME [epoch: 9.74 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11441785586357782		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.11441785586357782 | validation: 0.12128019259829234]
	TIME [epoch: 9.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1057650338711702		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.1057650338711702 | validation: 0.10572366119050194]
	TIME [epoch: 9.72 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09508613152477376		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.09508613152477376 | validation: 0.1124756424514339]
	TIME [epoch: 9.71 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0972946717610135		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.0972946717610135 | validation: 0.10637966632881553]
	TIME [epoch: 9.73 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09936164371141351		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.09936164371141351 | validation: 0.09669934661800458]
	TIME [epoch: 9.72 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09740866201806495		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.09740866201806495 | validation: 0.10018131444811874]
	TIME [epoch: 9.72 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10930618506596787		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.10930618506596787 | validation: 0.122561256412116]
	TIME [epoch: 9.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09820622558613312		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.09820622558613312 | validation: 0.11185691773432492]
	TIME [epoch: 9.72 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10428600060481294		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.10428600060481294 | validation: 0.10302540168300443]
	TIME [epoch: 9.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09831080921273565		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.09831080921273565 | validation: 0.10549268244196146]
	TIME [epoch: 9.73 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09340366513286583		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.09340366513286583 | validation: 0.09908438087747254]
	TIME [epoch: 9.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09526722348419044		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.09526722348419044 | validation: 0.10682710720616434]
	TIME [epoch: 9.71 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09321495588874064		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.09321495588874064 | validation: 0.11740660405772146]
	TIME [epoch: 9.72 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11984281929235223		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.11984281929235223 | validation: 0.11876405546797263]
	TIME [epoch: 9.75 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10279421028711902		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.10279421028711902 | validation: 0.08512741708392951]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1816.pth
	Model improved!!!
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09242667304422422		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.09242667304422422 | validation: 0.1040319056933584]
	TIME [epoch: 9.72 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10058089861635207		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.10058089861635207 | validation: 0.10508969747217366]
	TIME [epoch: 9.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09248954367695703		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.09248954367695703 | validation: 0.11556881044839055]
	TIME [epoch: 9.73 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10673125448829361		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.10673125448829361 | validation: 0.10672656984639695]
	TIME [epoch: 9.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10496296808811152		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.10496296808811152 | validation: 0.11372224751772685]
	TIME [epoch: 9.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09998032894288142		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.09998032894288142 | validation: 0.10877804372490435]
	TIME [epoch: 9.75 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10698172900697729		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.10698172900697729 | validation: 0.11798391018426102]
	TIME [epoch: 9.72 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09987583140252518		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.09987583140252518 | validation: 0.1179226926916131]
	TIME [epoch: 9.72 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10276242074486733		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.10276242074486733 | validation: 0.08940526735551912]
	TIME [epoch: 9.75 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1029956432992282		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.1029956432992282 | validation: 0.11443079151379262]
	TIME [epoch: 9.72 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10342981872463722		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.10342981872463722 | validation: 0.09895533704012095]
	TIME [epoch: 9.72 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11233425586613532		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.11233425586613532 | validation: 0.12282658949886052]
	TIME [epoch: 9.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11376709027551013		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.11376709027551013 | validation: 0.1218827743929532]
	TIME [epoch: 9.73 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1106191810984545		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.1106191810984545 | validation: 0.10688749774779073]
	TIME [epoch: 9.71 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0971358580088977		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.0971358580088977 | validation: 0.10879228913448417]
	TIME [epoch: 9.71 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09696832644140556		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.09696832644140556 | validation: 0.08314797840733816]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1832.pth
	Model improved!!!
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08733318288878981		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.08733318288878981 | validation: 0.09962202568440759]
	TIME [epoch: 9.72 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09881390244527913		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.09881390244527913 | validation: 0.1134095756064798]
	TIME [epoch: 9.72 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09670480059685428		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.09670480059685428 | validation: 0.10068869039371307]
	TIME [epoch: 9.75 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09637589174588866		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.09637589174588866 | validation: 0.0888524821544576]
	TIME [epoch: 9.72 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09588335242173184		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.09588335242173184 | validation: 0.11416111035609987]
	TIME [epoch: 9.72 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10767655929993125		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.10767655929993125 | validation: 0.11059478065903751]
	TIME [epoch: 9.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10555767733634144		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.10555767733634144 | validation: 0.09876652153148763]
	TIME [epoch: 9.74 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09529987494228058		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.09529987494228058 | validation: 0.10883493607404805]
	TIME [epoch: 9.72 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09477826893557756		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.09477826893557756 | validation: 0.10400776700617222]
	TIME [epoch: 9.72 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09177996491378251		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.09177996491378251 | validation: 0.09715478790207435]
	TIME [epoch: 9.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09952237525000215		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.09952237525000215 | validation: 0.10009817947718315]
	TIME [epoch: 9.72 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09594517790246596		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.09594517790246596 | validation: 0.10826612367171673]
	TIME [epoch: 9.71 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09739939352805271		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.09739939352805271 | validation: 0.11758854343759506]
	TIME [epoch: 9.72 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10500426648364514		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.10500426648364514 | validation: 0.11097744504732976]
	TIME [epoch: 9.72 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1011583813601579		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.1011583813601579 | validation: 0.09982788260558799]
	TIME [epoch: 9.72 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09831836000669311		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.09831836000669311 | validation: 0.11349757357139657]
	TIME [epoch: 9.73 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.096412424016552		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.096412424016552 | validation: 0.10336610427576506]
	TIME [epoch: 9.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09577518057892445		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.09577518057892445 | validation: 0.10568221763275865]
	TIME [epoch: 9.71 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09896691628724685		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.09896691628724685 | validation: 0.10086137923683655]
	TIME [epoch: 9.71 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09804648300971283		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.09804648300971283 | validation: 0.11049227165818583]
	TIME [epoch: 9.75 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09990515788582599		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.09990515788582599 | validation: 0.08951179235147003]
	TIME [epoch: 9.72 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09870101655264799		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.09870101655264799 | validation: 0.09884878193325641]
	TIME [epoch: 9.72 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10389551667456717		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.10389551667456717 | validation: 0.11883391675081935]
	TIME [epoch: 9.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1163171123939926		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.1163171123939926 | validation: 0.10133460261979689]
	TIME [epoch: 9.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10726279181591836		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.10726279181591836 | validation: 0.10968328613820892]
	TIME [epoch: 9.72 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09445529221380997		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.09445529221380997 | validation: 0.09818574801403383]
	TIME [epoch: 9.71 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09633384493208323		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.09633384493208323 | validation: 0.08898655321438138]
	TIME [epoch: 9.74 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10159746258366617		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.10159746258366617 | validation: 0.11097609271932683]
	TIME [epoch: 9.72 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09673524103555727		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.09673524103555727 | validation: 0.09489756660162861]
	TIME [epoch: 9.71 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1028447409793222		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.1028447409793222 | validation: 0.10925277973864357]
	TIME [epoch: 9.74 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10406662472776121		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.10406662472776121 | validation: 0.10617649146585413]
	TIME [epoch: 9.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09949788470257895		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.09949788470257895 | validation: 0.09343809960543084]
	TIME [epoch: 9.71 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09726173813051783		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.09726173813051783 | validation: 0.11849772479944073]
	TIME [epoch: 9.72 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10105008699580653		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.10105008699580653 | validation: 0.10418711116740176]
	TIME [epoch: 9.74 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.095374213416095		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.095374213416095 | validation: 0.11193659904524692]
	TIME [epoch: 9.72 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11493925880452249		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.11493925880452249 | validation: 0.1006970893188839]
	TIME [epoch: 9.72 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11128199854029405		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.11128199854029405 | validation: 0.10426686651419025]
	TIME [epoch: 9.74 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09525033484285889		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.09525033484285889 | validation: 0.10328208447211326]
	TIME [epoch: 9.71 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0958787040573993		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.0958787040573993 | validation: 0.10170113383892018]
	TIME [epoch: 9.72 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09406747987119157		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.09406747987119157 | validation: 0.10747779780189796]
	TIME [epoch: 9.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09427419201123113		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.09427419201123113 | validation: 0.10201255862226609]
	TIME [epoch: 9.72 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962892892843827		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.0962892892843827 | validation: 0.09777027876091228]
	TIME [epoch: 9.72 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09525704058480693		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.09525704058480693 | validation: 0.12139775273282478]
	TIME [epoch: 9.72 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09691498097716086		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.09691498097716086 | validation: 0.11754304122364381]
	TIME [epoch: 9.74 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09690733923257253		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.09690733923257253 | validation: 0.09194395627145072]
	TIME [epoch: 9.72 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09589412953189927		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.09589412953189927 | validation: 0.09431338445797696]
	TIME [epoch: 9.72 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09712251715264408		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.09712251715264408 | validation: 0.10739099022338941]
	TIME [epoch: 9.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10400448199650034		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.10400448199650034 | validation: 0.10383351060431288]
	TIME [epoch: 9.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1042361902216246		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.1042361902216246 | validation: 0.11267672546805]
	TIME [epoch: 9.72 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09003388498460131		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.09003388498460131 | validation: 0.1038357431304304]
	TIME [epoch: 9.72 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09570320281430658		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.09570320281430658 | validation: 0.1047436792990975]
	TIME [epoch: 9.74 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09835999662708299		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.09835999662708299 | validation: 0.08994463783365043]
	TIME [epoch: 9.72 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1019760853966926		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.1019760853966926 | validation: 0.10371209092326387]
	TIME [epoch: 9.73 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10701887226276736		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.10701887226276736 | validation: 0.10431790583454362]
	TIME [epoch: 9.75 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10061231877993256		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.10061231877993256 | validation: 0.10173948979486788]
	TIME [epoch: 9.72 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09232416765769713		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.09232416765769713 | validation: 0.1109290836952021]
	TIME [epoch: 9.73 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09513248900038718		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.09513248900038718 | validation: 0.11740722944867608]
	TIME [epoch: 9.74 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09332093795047258		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.09332093795047258 | validation: 0.10303858973931786]
	TIME [epoch: 9.73 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09622535698501311		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.09622535698501311 | validation: 0.08753945732836277]
	TIME [epoch: 9.73 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10118175541284118		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.10118175541284118 | validation: 0.09401114148821872]
	TIME [epoch: 9.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09626542018454548		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.09626542018454548 | validation: 0.09620559486118793]
	TIME [epoch: 9.75 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0979747206086691		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.0979747206086691 | validation: 0.10198518030287261]
	TIME [epoch: 9.72 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09750741072517755		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.09750741072517755 | validation: 0.10232923421530105]
	TIME [epoch: 9.73 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10170069580259085		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.10170069580259085 | validation: 0.08613957465570954]
	TIME [epoch: 9.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09639959307327861		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.09639959307327861 | validation: 0.08658080347503408]
	TIME [epoch: 9.72 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09999126034945216		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.09999126034945216 | validation: 0.08584119938637605]
	TIME [epoch: 9.71 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0963767196516864		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.0963767196516864 | validation: 0.080387634220089]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r0_20240219_184940/states/model_tr_study6_1899.pth
	Model improved!!!
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09518580036549253		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.09518580036549253 | validation: 0.1017100750228884]
	TIME [epoch: 9.75 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10662059084372502		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.10662059084372502 | validation: 0.12393162826850564]
	TIME [epoch: 9.72 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10256936203977092		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.10256936203977092 | validation: 0.10205014972205347]
	TIME [epoch: 9.72 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09691224106135135		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.09691224106135135 | validation: 0.09894987537462754]
	TIME [epoch: 9.75 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09459568662820146		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.09459568662820146 | validation: 0.10305382766759141]
	TIME [epoch: 9.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10088086250378778		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.10088086250378778 | validation: 0.10461554853191134]
	TIME [epoch: 9.72 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09816371886303776		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.09816371886303776 | validation: 0.09837717044131734]
	TIME [epoch: 9.75 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09034299061237885		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.09034299061237885 | validation: 0.09566227005380584]
	TIME [epoch: 9.73 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09792970068047083		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.09792970068047083 | validation: 0.10338763027698804]
	TIME [epoch: 9.73 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10060691850156575		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.10060691850156575 | validation: 0.09371502283126358]
	TIME [epoch: 9.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09380985863444408		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.09380985863444408 | validation: 0.0933146303882396]
	TIME [epoch: 9.75 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09957230929930459		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.09957230929930459 | validation: 0.09887373460813617]
	TIME [epoch: 9.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09526256819868832		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.09526256819868832 | validation: 0.11371576281276081]
	TIME [epoch: 9.73 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10322975248842206		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.10322975248842206 | validation: 0.1125670420766174]
	TIME [epoch: 9.76 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10304647860533575		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.10304647860533575 | validation: 0.10546138512622408]
	TIME [epoch: 9.73 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09731340884512693		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.09731340884512693 | validation: 0.10971015016998541]
	TIME [epoch: 9.73 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0994816392504544		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.0994816392504544 | validation: 0.1121196955756701]
	TIME [epoch: 9.75 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10470889570399682		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.10470889570399682 | validation: 0.09857337823552714]
	TIME [epoch: 9.74 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09681505584192365		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.09681505584192365 | validation: 0.1134965354754698]
	TIME [epoch: 9.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09872455731025187		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.09872455731025187 | validation: 0.0963462980550938]
	TIME [epoch: 9.74 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09806750521173127		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.09806750521173127 | validation: 0.09384922208601795]
	TIME [epoch: 9.76 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09315649518607656		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.09315649518607656 | validation: 0.09759270272513139]
	TIME [epoch: 9.73 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09253778062235582		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.09253778062235582 | validation: 0.09997871779529159]
	TIME [epoch: 9.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10838990010676489		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.10838990010676489 | validation: 0.09812877121704423]
	TIME [epoch: 9.76 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09155014818388098		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.09155014818388098 | validation: 0.10486909290278006]
	TIME [epoch: 9.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08951033484067913		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.08951033484067913 | validation: 0.08874692149540803]
	TIME [epoch: 9.73 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09442332166433338		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.09442332166433338 | validation: 0.09925443369289276]
	TIME [epoch: 9.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09200626514277399		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.09200626514277399 | validation: 0.10338387142678962]
	TIME [epoch: 9.75 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09878205010207942		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.09878205010207942 | validation: 0.10088432678214798]
	TIME [epoch: 9.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10062909852016173		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.10062909852016173 | validation: 0.09124709904769175]
	TIME [epoch: 9.74 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09479230798788875		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.09479230798788875 | validation: 0.09251905298569163]
	TIME [epoch: 9.76 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09482411161743656		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.09482411161743656 | validation: 0.09946515986760947]
	TIME [epoch: 9.73 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09642276014911204		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.09642276014911204 | validation: 0.10861249118990196]
	TIME [epoch: 9.74 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11044612656828834		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.11044612656828834 | validation: 0.10010764735335621]
	TIME [epoch: 9.75 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1063019638505911		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.1063019638505911 | validation: 0.08916085114405724]
	TIME [epoch: 9.74 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09557869874070127		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.09557869874070127 | validation: 0.11681356456289216]
	TIME [epoch: 9.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1010772749370781		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.1010772749370781 | validation: 0.11140685798655316]
	TIME [epoch: 9.73 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09861324719864413		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.09861324719864413 | validation: 0.09189726272056602]
	TIME [epoch: 9.76 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09623886360614334		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.09623886360614334 | validation: 0.10506268118960105]
	TIME [epoch: 9.73 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10297082806557183		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.10297082806557183 | validation: 0.09634069825720215]
	TIME [epoch: 9.73 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0948950504667875		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.0948950504667875 | validation: 0.11463265608456949]
	TIME [epoch: 9.76 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10428428890377366		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.10428428890377366 | validation: 0.10612067741903271]
	TIME [epoch: 9.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09670661708013302		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.09670661708013302 | validation: 0.10510550899880895]
	TIME [epoch: 9.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09255518923270424		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.09255518923270424 | validation: 0.10535770981556983]
	TIME [epoch: 9.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09564385892577247		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.09564385892577247 | validation: 0.09398805614307103]
	TIME [epoch: 9.75 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09215194384402872		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.09215194384402872 | validation: 0.10575082850696238]
	TIME [epoch: 9.74 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09117952759742606		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.09117952759742606 | validation: 0.08613505668425299]
	TIME [epoch: 9.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09055991501143093		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.09055991501143093 | validation: 0.10847284084575322]
	TIME [epoch: 9.76 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09207177492576697		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.09207177492576697 | validation: 0.09404072996702954]
	TIME [epoch: 9.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08991118623209664		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.08991118623209664 | validation: 0.08450639268223363]
	TIME [epoch: 9.74 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10040809336001641		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.10040809336001641 | validation: 0.08928642601687219]
	TIME [epoch: 9.76 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09247576861877557		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.09247576861877557 | validation: 0.10040602822276765]
	TIME [epoch: 9.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09775210255158949		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.09775210255158949 | validation: 0.097280416983008]
	TIME [epoch: 9.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937858215794904		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.08937858215794904 | validation: 0.10969827842117934]
	TIME [epoch: 9.74 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09598519148825009		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.09598519148825009 | validation: 0.10230451591483167]
	TIME [epoch: 9.75 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10135768372186986		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.10135768372186986 | validation: 0.11503772635132667]
	TIME [epoch: 9.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08847785785721202		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.08847785785721202 | validation: 0.08541894643650061]
	TIME [epoch: 9.73 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09859158600342631		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.09859158600342631 | validation: 0.09742245210615615]
	TIME [epoch: 9.76 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09760413742061166		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.09760413742061166 | validation: 0.10744746434000395]
	TIME [epoch: 9.73 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10370237419320585		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.10370237419320585 | validation: 0.11067346362542199]
	TIME [epoch: 9.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09921226579368835		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.09921226579368835 | validation: 0.10573485521446639]
	TIME [epoch: 9.74 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10411932980078271		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.10411932980078271 | validation: 0.1221855435086948]
	TIME [epoch: 9.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10428988107909358		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.10428988107909358 | validation: 0.12832498325438468]
	TIME [epoch: 9.73 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1046358816989581		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.1046358816989581 | validation: 0.10010135466672285]
	TIME [epoch: 9.73 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885578348187813		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.0885578348187813 | validation: 0.10976794853212418]
	TIME [epoch: 9.76 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09254509832595162		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.09254509832595162 | validation: 0.10950757521089585]
	TIME [epoch: 9.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09081010267651243		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.09081010267651243 | validation: 0.10230044291131521]
	TIME [epoch: 9.73 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09884188387219336		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.09884188387219336 | validation: 0.11125457261004301]
	TIME [epoch: 9.76 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09701336004368977		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.09701336004368977 | validation: 0.09863186890077749]
	TIME [epoch: 9.73 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09762798872512027		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.09762798872512027 | validation: 0.09828475138632888]
	TIME [epoch: 9.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09762760674367087		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.09762760674367087 | validation: 0.1039814714023908]
	TIME [epoch: 9.74 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09512934193019619		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.09512934193019619 | validation: 0.09555638775026987]
	TIME [epoch: 9.76 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09666185379672097		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.09666185379672097 | validation: 0.10541974481908005]
	TIME [epoch: 9.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09656738311667452		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.09656738311667452 | validation: 0.11526676127282062]
	TIME [epoch: 9.74 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0910458445049534		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.0910458445049534 | validation: 0.09897629173568223]
	TIME [epoch: 9.76 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09365161886832699		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.09365161886832699 | validation: 0.09044508576603282]
	TIME [epoch: 9.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09531391299041363		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.09531391299041363 | validation: 0.09360362485356377]
	TIME [epoch: 9.74 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09728384523571157		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.09728384523571157 | validation: 0.10204615896888002]
	TIME [epoch: 9.76 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09286394315214376		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.09286394315214376 | validation: 0.09909002478174352]
	TIME [epoch: 9.75 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08979714854212625		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.08979714854212625 | validation: 0.10587435301552604]
	TIME [epoch: 9.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09276516601737093		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.09276516601737093 | validation: 0.10467865733723575]
	TIME [epoch: 9.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09372719893569295		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.09372719893569295 | validation: 0.08736210492003958]
	TIME [epoch: 9.76 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08704543256706648		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.08704543256706648 | validation: 0.0899777739752824]
	TIME [epoch: 9.73 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09466487291144242		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.09466487291144242 | validation: 0.09871579674510934]
	TIME [epoch: 9.73 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09411890303298107		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.09411890303298107 | validation: 0.112156770883153]
	TIME [epoch: 9.75 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09910827863982503		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.09910827863982503 | validation: 0.09557417993109224]
	TIME [epoch: 9.73 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10083494295151998		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.10083494295151998 | validation: 0.10134286058069863]
	TIME [epoch: 9.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301318091725926		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.09301318091725926 | validation: 0.09115388514673864]
	TIME [epoch: 9.74 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09432811497646566		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.09432811497646566 | validation: 0.10471961727344913]
	TIME [epoch: 9.74 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09282368480261632		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.09282368480261632 | validation: 0.10343380813899508]
	TIME [epoch: 9.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0941844644326618		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.0941844644326618 | validation: 0.09301365952230466]
	TIME [epoch: 9.73 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1059790067201501		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.1059790067201501 | validation: 0.1060054010246496]
	TIME [epoch: 9.75 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09651413927586697		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.09651413927586697 | validation: 0.10251602149844675]
	TIME [epoch: 9.73 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10164125356941663		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.10164125356941663 | validation: 0.10253888650552018]
	TIME [epoch: 9.73 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09763424480412489		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.09763424480412489 | validation: 0.09302079414264705]
	TIME [epoch: 9.75 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10806090660831327		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.10806090660831327 | validation: 0.09863036156114899]
	TIME [epoch: 9.73 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09170296345171583		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.09170296345171583 | validation: 0.08778166225092175]
	TIME [epoch: 9.73 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09581225245310936		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.09581225245310936 | validation: 0.09842019500794537]
	TIME [epoch: 9.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09793977162436356		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.09793977162436356 | validation: 0.11645437672391776]
	TIME [epoch: 9.75 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10027341907496654		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.10027341907496654 | validation: 0.10157136155206621]
	TIME [epoch: 9.73 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09835078023990766		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.09835078023990766 | validation: 0.11044537894510194]
	TIME [epoch: 9.74 sec]
Finished training in 19621.422 seconds.
