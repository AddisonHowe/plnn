Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3961728883

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.611496279591117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.611496279591117 | validation: 7.187024595077759]
	TIME [epoch: 72.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.368866564191992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.368866564191992 | validation: 6.514981141043901]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.390959194234288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.390959194234288 | validation: 5.807842141544998]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.475619458405758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.475619458405758 | validation: 10.239859307379424]
	TIME [epoch: 10.3 sec]
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.907193055295755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.907193055295755 | validation: 6.829134234264388]
	TIME [epoch: 10.3 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.5072144503140255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5072144503140255 | validation: 5.433097181594796]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.882331829389047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.882331829389047 | validation: 10.218362337469237]
	TIME [epoch: 10.4 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.382726431602585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.382726431602585 | validation: 7.679484070253559]
	TIME [epoch: 10.3 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.979660280197663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.979660280197663 | validation: 6.9081212841374295]
	TIME [epoch: 10.3 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.74884944766235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.74884944766235 | validation: 6.739771914918435]
	TIME [epoch: 10.4 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.316972569010429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.316972569010429 | validation: 5.113996766606345]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.301933902666123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.301933902666123 | validation: 5.876926452645574]
	TIME [epoch: 10.4 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.458151364289927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.458151364289927 | validation: 4.822110954143262]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.312683830201555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.312683830201555 | validation: 4.4355004978847985]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.576187330889789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.576187330889789 | validation: 5.8138521517799795]
	TIME [epoch: 10.4 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.183541568453855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.183541568453855 | validation: 5.172732315350686]
	TIME [epoch: 10.3 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.401214963702293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.401214963702293 | validation: 4.781398062748994]
	TIME [epoch: 10.3 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.49288538911477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.49288538911477 | validation: 4.45854096265309]
	TIME [epoch: 10.4 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.147481995135689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.147481995135689 | validation: 5.081414629209319]
	TIME [epoch: 10.4 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.797118983552005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.797118983552005 | validation: 4.5391669684630624]
	TIME [epoch: 10.3 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.348597339250604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.348597339250604 | validation: 4.959356413515054]
	TIME [epoch: 10.3 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.302596156441858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.302596156441858 | validation: 4.3696041287391925]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.650281598056393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.650281598056393 | validation: 4.467265943519579]
	TIME [epoch: 10.4 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.990908780540906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.990908780540906 | validation: 4.785361853814861]
	TIME [epoch: 10.4 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.89202102811165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.89202102811165 | validation: 5.111920228383793]
	TIME [epoch: 10.3 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.133544116213419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.133544116213419 | validation: 5.262324294088545]
	TIME [epoch: 10.4 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.139707741327091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.139707741327091 | validation: 4.59957154794047]
	TIME [epoch: 10.3 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.800395946073762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.800395946073762 | validation: 4.5192198586929315]
	TIME [epoch: 10.3 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.067183318935458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.067183318935458 | validation: 4.495306525387828]
	TIME [epoch: 10.3 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.254686663136811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.254686663136811 | validation: 4.112201120039874]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.8945845945991575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8945845945991575 | validation: 5.254120812499147]
	TIME [epoch: 10.3 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.607589991950569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.607589991950569 | validation: 4.778328187477572]
	TIME [epoch: 10.3 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.634961338398369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.634961338398369 | validation: 4.4517718720781225]
	TIME [epoch: 10.3 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.402624328307068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.402624328307068 | validation: 4.031063927906829]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5955210406026525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5955210406026525 | validation: 4.80850412304771]
	TIME [epoch: 10.3 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.442124979828402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.442124979828402 | validation: 4.547844598776372]
	TIME [epoch: 10.3 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.809519826083518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.809519826083518 | validation: 4.685070613602023]
	TIME [epoch: 10.3 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.7471762922757765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7471762922757765 | validation: 5.050490369589896]
	TIME [epoch: 10.4 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.125197981258624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.125197981258624 | validation: 4.003683188375641]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.723207025183665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.723207025183665 | validation: 5.2299671934450735]
	TIME [epoch: 10.3 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.954446060790842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.954446060790842 | validation: 5.594456368397451]
	TIME [epoch: 10.3 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.158087947181142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.158087947181142 | validation: 4.005019283523918]
	TIME [epoch: 10.4 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.760936898505118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.760936898505118 | validation: 5.0045065904194725]
	TIME [epoch: 10.3 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.206885520326989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.206885520326989 | validation: 3.923383201163931]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.50572256595409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.50572256595409 | validation: 3.8295113741238156]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.625087384235554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.625087384235554 | validation: 4.986821231110751]
	TIME [epoch: 10.4 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.051832104904167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.051832104904167 | validation: 4.042068241312563]
	TIME [epoch: 10.3 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.229363273400257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.229363273400257 | validation: 3.5277007561000313]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.854892750634305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.854892750634305 | validation: 3.158352938321332]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.836631274917454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.836631274917454 | validation: 2.9530326743010016]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5887818085835397		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 3.5887818085835397 | validation: 3.74621852349505]
	TIME [epoch: 10.3 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.481261580438398		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 3.481261580438398 | validation: 3.024699325324026]
	TIME [epoch: 10.3 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2869965668555303		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 3.2869965668555303 | validation: 3.0384456301860348]
	TIME [epoch: 10.3 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2467771493904367		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 3.2467771493904367 | validation: 3.091445947256759]
	TIME [epoch: 10.4 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1919362968134846		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 3.1919362968134846 | validation: 3.3388686509565377]
	TIME [epoch: 10.3 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3834261963119188		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 3.3834261963119188 | validation: 2.7437854018736245]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0637894298698005		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 3.0637894298698005 | validation: 2.779204156582407]
	TIME [epoch: 10.3 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1101386938658413		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 3.1101386938658413 | validation: 3.2579468894568873]
	TIME [epoch: 10.4 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1606032052518667		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 3.1606032052518667 | validation: 2.6706956446036476]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.106344331199752		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 3.106344331199752 | validation: 3.3279251977030406]
	TIME [epoch: 10.3 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3420442139912803		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 3.3420442139912803 | validation: 2.858478726286851]
	TIME [epoch: 10.3 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3868708052733623		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 3.3868708052733623 | validation: 3.074589932629101]
	TIME [epoch: 10.4 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.431839520888242		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 3.431839520888242 | validation: 2.9350703748171583]
	TIME [epoch: 10.3 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.127979472935873		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 3.127979472935873 | validation: 2.7215931854821713]
	TIME [epoch: 10.3 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.18819515153593		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 3.18819515153593 | validation: 3.075811651515763]
	TIME [epoch: 10.3 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3490877851804037		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 3.3490877851804037 | validation: 3.096072946354419]
	TIME [epoch: 10.4 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.072249348448492		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 3.072249348448492 | validation: 2.728030595722501]
	TIME [epoch: 10.3 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1298230373137095		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 3.1298230373137095 | validation: 3.0389830255731924]
	TIME [epoch: 10.3 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9908609618418858		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 2.9908609618418858 | validation: 2.6957428388836617]
	TIME [epoch: 10.3 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.960428186735485		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 2.960428186735485 | validation: 2.5144214984196838]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8148845182257825		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 2.8148845182257825 | validation: 3.103404414259386]
	TIME [epoch: 10.4 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0718611239063662		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 3.0718611239063662 | validation: 3.0953302006063677]
	TIME [epoch: 10.3 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.876563713866903		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 2.876563713866903 | validation: 2.9409081623438547]
	TIME [epoch: 10.3 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.939828297004935		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 2.939828297004935 | validation: 3.0566443384694004]
	TIME [epoch: 10.4 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8249175882659436		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 3.8249175882659436 | validation: 4.011103778835844]
	TIME [epoch: 10.3 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.763617045547697		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 3.763617045547697 | validation: 2.6799991597635087]
	TIME [epoch: 10.3 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0853472763848346		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 3.0853472763848346 | validation: 3.4277358350799285]
	TIME [epoch: 10.3 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.515976208839316		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 3.515976208839316 | validation: 3.141169510210584]
	TIME [epoch: 10.4 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6528733104003437		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 3.6528733104003437 | validation: 4.165892954928344]
	TIME [epoch: 10.3 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6277090300954713		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 3.6277090300954713 | validation: 4.041861021666135]
	TIME [epoch: 10.3 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.595496784508623		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 3.595496784508623 | validation: 3.1578103539970126]
	TIME [epoch: 10.3 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.022771103440187		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 4.022771103440187 | validation: 3.0070655428752913]
	TIME [epoch: 10.4 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.167512676494243		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 3.167512676494243 | validation: 2.8737759761913555]
	TIME [epoch: 10.3 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1194163314135706		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 3.1194163314135706 | validation: 2.9203140463618773]
	TIME [epoch: 10.3 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.099283426967504		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 3.099283426967504 | validation: 2.7974054592567383]
	TIME [epoch: 10.3 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.100370548613738		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 3.100370548613738 | validation: 2.4642522082414144]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.892321689329208		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 2.892321689329208 | validation: 2.438004249987068]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.12361131227208		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 3.12361131227208 | validation: 2.648425082610901]
	TIME [epoch: 10.3 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4767137714133134		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 3.4767137714133134 | validation: 2.805480559121778]
	TIME [epoch: 10.3 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.367823780903705		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 3.367823780903705 | validation: 2.6404596065034465]
	TIME [epoch: 10.4 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1811696662144673		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 3.1811696662144673 | validation: 2.945274422728661]
	TIME [epoch: 10.3 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1549097985192125		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 3.1549097985192125 | validation: 2.698051014442971]
	TIME [epoch: 10.3 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.367142408371361		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 3.367142408371361 | validation: 3.707964409357418]
	TIME [epoch: 10.3 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6522379807013805		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 3.6522379807013805 | validation: 2.7052666692221137]
	TIME [epoch: 10.4 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.058373142620804		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 4.058373142620804 | validation: 3.489065329171519]
	TIME [epoch: 10.3 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3363171513680996		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 3.3363171513680996 | validation: 2.8941645730630454]
	TIME [epoch: 10.3 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.266221452160927		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 3.266221452160927 | validation: 3.185669876491571]
	TIME [epoch: 10.3 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.152503944327564		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 3.152503944327564 | validation: 4.4974155308794765]
	TIME [epoch: 10.4 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.832696992294808		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 3.832696992294808 | validation: 2.9960337784113147]
	TIME [epoch: 10.3 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2299929274835257		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 3.2299929274835257 | validation: 2.792421795901971]
	TIME [epoch: 10.3 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.168194870416761		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 3.168194870416761 | validation: 2.7122310994316696]
	TIME [epoch: 10.3 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.284274387349985		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 3.284274387349985 | validation: 2.818793115524203]
	TIME [epoch: 10.4 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3015751170666086		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 3.3015751170666086 | validation: 2.936520097622648]
	TIME [epoch: 10.3 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.329922092576898		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 3.329922092576898 | validation: 2.8567959330247503]
	TIME [epoch: 10.3 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.293658249917281		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 3.293658249917281 | validation: 2.8013229703175626]
	TIME [epoch: 10.3 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1289367175075		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 3.1289367175075 | validation: 2.750943947489342]
	TIME [epoch: 10.4 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.000434002691085		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 3.000434002691085 | validation: 3.049284134602467]
	TIME [epoch: 10.4 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.484344948350318		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 3.484344948350318 | validation: 2.8268940028131615]
	TIME [epoch: 10.3 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0850061505349915		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 3.0850061505349915 | validation: 2.887807998608404]
	TIME [epoch: 10.3 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.833032735673438		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 3.833032735673438 | validation: 2.762690620837673]
	TIME [epoch: 10.4 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1303547299842966		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 3.1303547299842966 | validation: 2.855021333892245]
	TIME [epoch: 10.3 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3878481717676494		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 3.3878481717676494 | validation: 3.2260571631639294]
	TIME [epoch: 10.3 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.212408292755593		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 3.212408292755593 | validation: 2.748305701048058]
	TIME [epoch: 10.3 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9757815152894254		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 2.9757815152894254 | validation: 2.663847339027469]
	TIME [epoch: 10.4 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2180073993923672		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 3.2180073993923672 | validation: 2.6213269402729225]
	TIME [epoch: 10.3 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1011582309559147		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 3.1011582309559147 | validation: 3.025365893066163]
	TIME [epoch: 10.3 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1538374691230167		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 3.1538374691230167 | validation: 2.5530923372575383]
	TIME [epoch: 10.3 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7721367500761365		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 2.7721367500761365 | validation: 2.6453768289008606]
	TIME [epoch: 10.4 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.069451593123136		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 3.069451593123136 | validation: 2.644575585059255]
	TIME [epoch: 10.3 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9091094898873022		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 2.9091094898873022 | validation: 2.6464012523861435]
	TIME [epoch: 10.3 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9467520463122794		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 2.9467520463122794 | validation: 2.7718439723530945]
	TIME [epoch: 10.3 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1030327399720017		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 3.1030327399720017 | validation: 2.640864021854734]
	TIME [epoch: 10.4 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.999476565550809		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 2.999476565550809 | validation: 2.7579319022368716]
	TIME [epoch: 10.3 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1376701995921925		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 3.1376701995921925 | validation: 3.3805940814476982]
	TIME [epoch: 10.3 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1856730074637944		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 3.1856730074637944 | validation: 2.8749895953413653]
	TIME [epoch: 10.3 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.111344457279928		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 3.111344457279928 | validation: 3.000581639392107]
	TIME [epoch: 10.4 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2893367931193493		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 3.2893367931193493 | validation: 2.9769865132471574]
	TIME [epoch: 10.3 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.143008144150042		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 3.143008144150042 | validation: 2.732332268192032]
	TIME [epoch: 10.3 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.174997970338944		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 3.174997970338944 | validation: 3.0914269468346234]
	TIME [epoch: 10.3 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.155232632997647		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 3.155232632997647 | validation: 2.7290348697582103]
	TIME [epoch: 10.4 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9522650618198933		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 2.9522650618198933 | validation: 2.959899745704792]
	TIME [epoch: 10.3 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.087998039289057		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 3.087998039289057 | validation: 3.1023406229874877]
	TIME [epoch: 10.3 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.97863275862397		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 2.97863275862397 | validation: 2.881740309537112]
	TIME [epoch: 10.3 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.029347486166705		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 3.029347486166705 | validation: 3.0899036390898114]
	TIME [epoch: 10.4 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0018950491862326		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 3.0018950491862326 | validation: 2.8213233863691345]
	TIME [epoch: 10.3 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.9340576196252535		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 4.9340576196252535 | validation: 3.2581919698119406]
	TIME [epoch: 10.3 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.059563863934104		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 3.059563863934104 | validation: 2.6941270541049955]
	TIME [epoch: 10.3 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.032293232266908		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 3.032293232266908 | validation: 2.839954523203427]
	TIME [epoch: 10.3 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.058546181767686		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 3.058546181767686 | validation: 2.653439217672231]
	TIME [epoch: 10.3 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.934057629306588		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 2.934057629306588 | validation: 2.6165389045878773]
	TIME [epoch: 10.3 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.024137256134202		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 3.024137256134202 | validation: 2.6707402648870264]
	TIME [epoch: 10.3 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8311121048604755		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 2.8311121048604755 | validation: 2.5207728776782448]
	TIME [epoch: 10.4 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.790031362380426		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 2.790031362380426 | validation: 2.82900093549939]
	TIME [epoch: 10.3 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9268893221251506		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 2.9268893221251506 | validation: 3.534261048158665]
	TIME [epoch: 10.3 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6490871447938185		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 3.6490871447938185 | validation: 2.6539208227628888]
	TIME [epoch: 10.3 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.802115743968936		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 2.802115743968936 | validation: 2.429864263485395]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_146.pth
	Model improved!!!
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4990152420761786		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 2.4990152420761786 | validation: 2.4989142411336536]
	TIME [epoch: 10.3 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8146993349324854		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 2.8146993349324854 | validation: 2.580217132769849]
	TIME [epoch: 10.3 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7388764870244566		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.7388764870244566 | validation: 2.8341134710624067]
	TIME [epoch: 10.3 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.68889553992979		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 3.68889553992979 | validation: 3.874069629106803]
	TIME [epoch: 10.4 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.819045034859265		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 3.819045034859265 | validation: 3.17021079634834]
	TIME [epoch: 10.3 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4673068404453304		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 3.4673068404453304 | validation: 3.0748781014338875]
	TIME [epoch: 10.3 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.250116044630122		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 3.250116044630122 | validation: 2.881486620068854]
	TIME [epoch: 10.3 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2154647824928473		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 3.2154647824928473 | validation: 2.9597900451355965]
	TIME [epoch: 10.3 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.242443212611698		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 3.242443212611698 | validation: 2.8758619062666244]
	TIME [epoch: 10.3 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0555740729055216		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 3.0555740729055216 | validation: 2.5737690429356315]
	TIME [epoch: 10.3 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.847100788855186		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 2.847100788855186 | validation: 2.5694551278945506]
	TIME [epoch: 10.3 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7347159530874263		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 2.7347159530874263 | validation: 2.4764544952837584]
	TIME [epoch: 10.4 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5812533979546304		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 2.5812533979546304 | validation: 2.1418828030978982]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_159.pth
	Model improved!!!
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5216999587637385		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 2.5216999587637385 | validation: 2.3962589698928407]
	TIME [epoch: 10.3 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.482944877694635		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 2.482944877694635 | validation: 2.051346518410599]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2886557953397215		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 2.2886557953397215 | validation: 2.4667610233880466]
	TIME [epoch: 10.3 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.692397661695575		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 2.692397661695575 | validation: 2.214971554966399]
	TIME [epoch: 10.3 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7750869004518544		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 2.7750869004518544 | validation: 2.5694160573733904]
	TIME [epoch: 10.3 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6112435147384736		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 2.6112435147384736 | validation: 2.308899071007106]
	TIME [epoch: 10.3 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.478792417468641		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 2.478792417468641 | validation: 2.344515351354263]
	TIME [epoch: 10.3 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9116290056805405		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 2.9116290056805405 | validation: 2.5988192262129637]
	TIME [epoch: 10.3 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9436319503123487		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 2.9436319503123487 | validation: 2.857388276993396]
	TIME [epoch: 10.3 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.234008739761316		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 3.234008739761316 | validation: 2.9234634405888613]
	TIME [epoch: 10.3 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.061302360106518		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 3.061302360106518 | validation: 2.4923500899001847]
	TIME [epoch: 10.3 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.697681790899007		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 2.697681790899007 | validation: 2.259012547333608]
	TIME [epoch: 10.3 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4075001794214375		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 2.4075001794214375 | validation: 2.052032473947207]
	TIME [epoch: 10.3 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1297464461805413		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 2.1297464461805413 | validation: 1.90892406509919]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_173.pth
	Model improved!!!
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8579097867931784		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 2.8579097867931784 | validation: 2.9238043372918536]
	TIME [epoch: 10.4 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9843106202933813		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 2.9843106202933813 | validation: 1.996842536510728]
	TIME [epoch: 10.4 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0602603527516727		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 2.0602603527516727 | validation: 1.7372425087297376]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_176.pth
	Model improved!!!
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.837171414480468		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 1.837171414480468 | validation: 2.320316416032176]
	TIME [epoch: 10.3 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.95497497862318		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 1.95497497862318 | validation: 1.5875124839867079]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.133632060760874		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 2.133632060760874 | validation: 1.909474126458764]
	TIME [epoch: 10.3 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.011302021517828		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 2.011302021517828 | validation: 1.745236359216982]
	TIME [epoch: 10.3 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0155627291658735		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 2.0155627291658735 | validation: 2.007614338111696]
	TIME [epoch: 10.3 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0704250775594972		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 2.0704250775594972 | validation: 1.8959311799418748]
	TIME [epoch: 10.4 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9451320067681948		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 1.9451320067681948 | validation: 1.5050922307205212]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.134872272954183		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 2.134872272954183 | validation: 1.6064211436790359]
	TIME [epoch: 10.3 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8299800217843802		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 1.8299800217843802 | validation: 1.508595872278053]
	TIME [epoch: 10.3 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6282683009172523		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 1.6282683009172523 | validation: 1.474571654251801]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1110183598606427		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 2.1110183598606427 | validation: 1.7290500497388832]
	TIME [epoch: 10.3 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.940413971584333		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 1.940413971584333 | validation: 1.507213721251526]
	TIME [epoch: 10.3 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1480413569489665		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 2.1480413569489665 | validation: 1.9433528749618316]
	TIME [epoch: 10.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0774777960260553		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 2.0774777960260553 | validation: 1.6569541936702614]
	TIME [epoch: 10.3 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5561331983641475		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 1.5561331983641475 | validation: 1.2366831539282925]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_191.pth
	Model improved!!!
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7728832978838418		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 1.7728832978838418 | validation: 1.3011492214981872]
	TIME [epoch: 10.3 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6551519145243454		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 1.6551519145243454 | validation: 1.4051559152168673]
	TIME [epoch: 10.3 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4639045776102166		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 1.4639045776102166 | validation: 1.3271650717688157]
	TIME [epoch: 10.3 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4539004686374868		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 1.4539004686374868 | validation: 1.9253890475257822]
	TIME [epoch: 10.3 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7388440525326374		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 1.7388440525326374 | validation: 1.4050604076420459]
	TIME [epoch: 10.3 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5151633338377832		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 1.5151633338377832 | validation: 1.1880174640019376]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3447022515082174		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 1.3447022515082174 | validation: 1.7177146636897385]
	TIME [epoch: 10.4 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4833290341004928		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 1.4833290341004928 | validation: 1.092871438684946]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4303420711542545		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 1.4303420711542545 | validation: 1.0689105369174663]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_200.pth
	Model improved!!!
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3907175057851375		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 1.3907175057851375 | validation: 1.1514130865553565]
	TIME [epoch: 10.3 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1936047123301776		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 1.1936047123301776 | validation: 1.0632764722215209]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_202.pth
	Model improved!!!
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.304057726857846		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 1.304057726857846 | validation: 1.090002210763133]
	TIME [epoch: 10.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0795420867846197		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 1.0795420867846197 | validation: 0.9025723909125043]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_204.pth
	Model improved!!!
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2010949221712273		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 1.2010949221712273 | validation: 1.0471683974079158]
	TIME [epoch: 10.3 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.174168885529371		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.174168885529371 | validation: 0.8549553783295122]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_206.pth
	Model improved!!!
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3579768219773747		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 1.3579768219773747 | validation: 1.0679737288915576]
	TIME [epoch: 10.3 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2548535976890771		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 1.2548535976890771 | validation: 1.0224538050935201]
	TIME [epoch: 10.3 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1911856160024965		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 1.1911856160024965 | validation: 0.8932732137286084]
	TIME [epoch: 10.3 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.105155206588274		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 1.105155206588274 | validation: 0.8596736116421445]
	TIME [epoch: 10.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.134419288366908		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 1.134419288366908 | validation: 0.7441622586388073]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0885473017709035		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 1.0885473017709035 | validation: 0.9754878703659653]
	TIME [epoch: 10.3 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9644045794851299		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 0.9644045794851299 | validation: 0.8166395087758568]
	TIME [epoch: 10.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4239380483302244		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 1.4239380483302244 | validation: 1.0958172076047012]
	TIME [epoch: 10.3 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0631138759503487		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 1.0631138759503487 | validation: 0.9028003834503564]
	TIME [epoch: 10.3 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2528269532928165		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 1.2528269532928165 | validation: 0.8211764969759]
	TIME [epoch: 10.3 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1359972341731261		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 1.1359972341731261 | validation: 0.995711042900839]
	TIME [epoch: 10.3 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.023653055219405		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 1.023653055219405 | validation: 1.0221686285624625]
	TIME [epoch: 10.3 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8755444113489836		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 0.8755444113489836 | validation: 1.4104232584730856]
	TIME [epoch: 10.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1981342584000987		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 1.1981342584000987 | validation: 0.9622976883152052]
	TIME [epoch: 10.3 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9566973315481059		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 0.9566973315481059 | validation: 0.8433468457294819]
	TIME [epoch: 10.3 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9305766313949366		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 0.9305766313949366 | validation: 1.2379431683235473]
	TIME [epoch: 10.3 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0567169206922948		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 1.0567169206922948 | validation: 0.9743742309965453]
	TIME [epoch: 10.4 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8941890392247951		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 0.8941890392247951 | validation: 0.9492938740576857]
	TIME [epoch: 10.3 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.935429368132937		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.935429368132937 | validation: 0.8263162426827424]
	TIME [epoch: 10.3 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9213088864082024		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 0.9213088864082024 | validation: 0.6752782396360673]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_226.pth
	Model improved!!!
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9643984632867028		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 0.9643984632867028 | validation: 0.693489118242045]
	TIME [epoch: 10.4 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0087555780125372		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 1.0087555780125372 | validation: 1.076884538549389]
	TIME [epoch: 10.3 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0537969329396084		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 1.0537969329396084 | validation: 1.0135480410320363]
	TIME [epoch: 10.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0728901392745132		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.0728901392745132 | validation: 0.9743432558153239]
	TIME [epoch: 10.3 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0956304171356974		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 1.0956304171356974 | validation: 0.7389965925940593]
	TIME [epoch: 10.3 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8026351987634903		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 0.8026351987634903 | validation: 0.8535237957520857]
	TIME [epoch: 10.3 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8506570033530119		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 0.8506570033530119 | validation: 1.2292865443256564]
	TIME [epoch: 10.3 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9758173169988174		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 0.9758173169988174 | validation: 0.8963837669413043]
	TIME [epoch: 10.3 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8781323440451659		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 0.8781323440451659 | validation: 0.7962996714181378]
	TIME [epoch: 10.3 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9413320386549637		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 0.9413320386549637 | validation: 0.9002415638084256]
	TIME [epoch: 10.3 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8889425238120975		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 0.8889425238120975 | validation: 0.9961338570411661]
	TIME [epoch: 10.3 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8288191537712404		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 0.8288191537712404 | validation: 0.6749154902354192]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_238.pth
	Model improved!!!
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7818492985313247		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 0.7818492985313247 | validation: 0.962699128715079]
	TIME [epoch: 10.4 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9721433421821871		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 0.9721433421821871 | validation: 0.7182439519324189]
	TIME [epoch: 10.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.93999315894469		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 0.93999315894469 | validation: 0.6609452688102541]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_241.pth
	Model improved!!!
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7890546896145706		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 0.7890546896145706 | validation: 0.6519429162919097]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_242.pth
	Model improved!!!
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8762505063121051		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 0.8762505063121051 | validation: 0.8124690046755155]
	TIME [epoch: 10.3 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9112614654500533		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.9112614654500533 | validation: 0.8923845239428911]
	TIME [epoch: 10.3 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7187128823420152		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 0.7187128823420152 | validation: 0.7172908073774674]
	TIME [epoch: 10.3 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7673961008272245		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 0.7673961008272245 | validation: 0.8178225878980887]
	TIME [epoch: 10.3 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6878865887856662		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 0.6878865887856662 | validation: 0.8810607517460136]
	TIME [epoch: 10.3 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8724691841775801		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 0.8724691841775801 | validation: 0.812963272269989]
	TIME [epoch: 10.3 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.812129490618506		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 0.812129490618506 | validation: 0.6436284745271118]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_249.pth
	Model improved!!!
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6767562968602492		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 0.6767562968602492 | validation: 1.004276064002251]
	TIME [epoch: 10.3 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8895616866292866		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 0.8895616866292866 | validation: 0.6948116542376783]
	TIME [epoch: 10.3 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9863672801749594		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 0.9863672801749594 | validation: 0.8465640930187545]
	TIME [epoch: 10.3 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9080573980512089		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 0.9080573980512089 | validation: 0.6155868601120996]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_253.pth
	Model improved!!!
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6877996951825642		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 0.6877996951825642 | validation: 0.8082088912832553]
	TIME [epoch: 10.3 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6858860327796582		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 0.6858860327796582 | validation: 0.5421495339398755]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_255.pth
	Model improved!!!
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8013551105887051		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 0.8013551105887051 | validation: 0.682017563932888]
	TIME [epoch: 10.4 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.795562525182372		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 0.795562525182372 | validation: 0.5808852609087362]
	TIME [epoch: 10.3 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5836879816103988		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 0.5836879816103988 | validation: 0.5242918448233324]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_258.pth
	Model improved!!!
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6092191966948609		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 0.6092191966948609 | validation: 0.7306944424332374]
	TIME [epoch: 10.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6737247944838983		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 0.6737247944838983 | validation: 0.5314684332310062]
	TIME [epoch: 10.3 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5939409827786395		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 0.5939409827786395 | validation: 0.769688637578386]
	TIME [epoch: 10.3 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7406554725700756		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 0.7406554725700756 | validation: 0.9558690794006934]
	TIME [epoch: 10.3 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6541839462829385		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.6541839462829385 | validation: 0.6438280924395948]
	TIME [epoch: 10.3 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6557264553276563		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 0.6557264553276563 | validation: 0.7559582580517952]
	TIME [epoch: 10.3 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269761280518103		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 0.7269761280518103 | validation: 0.7777190586712511]
	TIME [epoch: 10.3 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6408294831403311		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 0.6408294831403311 | validation: 0.605803667176949]
	TIME [epoch: 10.3 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6574063527675584		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 0.6574063527675584 | validation: 0.4799213376020009]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_267.pth
	Model improved!!!
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5185077302755873		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 0.5185077302755873 | validation: 1.1833782835582458]
	TIME [epoch: 10.3 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.700295396218545		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 0.700295396218545 | validation: 0.9160253396035691]
	TIME [epoch: 10.3 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556191216886632		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 0.6556191216886632 | validation: 0.7637677557428013]
	TIME [epoch: 10.3 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6192186796938653		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 0.6192186796938653 | validation: 0.593572655270213]
	TIME [epoch: 10.3 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4905887065799129		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 0.4905887065799129 | validation: 0.4429078419885623]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_272.pth
	Model improved!!!
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377866107396257		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 0.6377866107396257 | validation: 0.6433063676747639]
	TIME [epoch: 10.3 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5968329323942582		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 0.5968329323942582 | validation: 0.4801948667547862]
	TIME [epoch: 10.3 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48377373047562744		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 0.48377373047562744 | validation: 1.1153298610825855]
	TIME [epoch: 10.3 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.853384807335523		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 0.853384807335523 | validation: 0.6175976627697536]
	TIME [epoch: 10.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7104655501318858		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 0.7104655501318858 | validation: 0.7346267821214071]
	TIME [epoch: 10.3 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6112654430936196		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 0.6112654430936196 | validation: 0.494938608304124]
	TIME [epoch: 10.3 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5539917339857096		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 0.5539917339857096 | validation: 0.48334911393008795]
	TIME [epoch: 10.3 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7281010552675491		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 0.7281010552675491 | validation: 0.6020599091435871]
	TIME [epoch: 10.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5741094510218094		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 0.5741094510218094 | validation: 0.5169279790808092]
	TIME [epoch: 10.3 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5017941115858978		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.5017941115858978 | validation: 0.4895923763842498]
	TIME [epoch: 10.3 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6817647950434906		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 0.6817647950434906 | validation: 0.4465254289299979]
	TIME [epoch: 10.3 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4962494863128805		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 0.4962494863128805 | validation: 0.40864427559281685]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324542798294127		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 0.5324542798294127 | validation: 0.501324549845078]
	TIME [epoch: 10.3 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7345200737929217		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 0.7345200737929217 | validation: 0.6532058030884598]
	TIME [epoch: 10.3 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.549238363836315		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 0.549238363836315 | validation: 0.5039552672645915]
	TIME [epoch: 10.3 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4180338656590873		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 0.4180338656590873 | validation: 0.46951033119936486]
	TIME [epoch: 10.3 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43243458624063413		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 0.43243458624063413 | validation: 0.5309192836122995]
	TIME [epoch: 10.3 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559403248176198		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 0.4559403248176198 | validation: 0.4066719347186885]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_290.pth
	Model improved!!!
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5375791563712861		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 0.5375791563712861 | validation: 0.40642844868951544]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_291.pth
	Model improved!!!
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5834089935747299		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 0.5834089935747299 | validation: 0.3348779320403587]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_292.pth
	Model improved!!!
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36111119717508977		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 0.36111119717508977 | validation: 0.4706967632155164]
	TIME [epoch: 10.3 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5678328354843734		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 0.5678328354843734 | validation: 0.7191266259441065]
	TIME [epoch: 10.3 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988983868950243		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 0.5988983868950243 | validation: 0.5131074740498416]
	TIME [epoch: 10.3 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39984610465160025		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 0.39984610465160025 | validation: 0.6038006092197483]
	TIME [epoch: 10.3 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5309675324501388		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 0.5309675324501388 | validation: 0.4457151930745306]
	TIME [epoch: 10.3 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227075229335878		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 0.5227075229335878 | validation: 0.5089674485588382]
	TIME [epoch: 10.3 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4107108481908256		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 0.4107108481908256 | validation: 0.45555533094249084]
	TIME [epoch: 10.3 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4726051352301065		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 0.4726051352301065 | validation: 0.6020868081940732]
	TIME [epoch: 10.3 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5901477350094909		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.5901477350094909 | validation: 0.7609244933255824]
	TIME [epoch: 10.3 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7275696135801669		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 0.7275696135801669 | validation: 0.5929038085636106]
	TIME [epoch: 10.4 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5108728158139753		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 0.5108728158139753 | validation: 0.515796021588055]
	TIME [epoch: 10.3 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.538893952662342		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 0.538893952662342 | validation: 0.42204835064632884]
	TIME [epoch: 10.3 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47281980866718376		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 0.47281980866718376 | validation: 0.5450784860583601]
	TIME [epoch: 10.3 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.574846977745529		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 0.574846977745529 | validation: 0.9874844612710184]
	TIME [epoch: 10.3 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7701104183860595		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 0.7701104183860595 | validation: 0.5735554237550717]
	TIME [epoch: 10.3 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234118613620806		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 0.5234118613620806 | validation: 0.4745572045837345]
	TIME [epoch: 10.3 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4565550347346594		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 0.4565550347346594 | validation: 0.5029627766812368]
	TIME [epoch: 10.3 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5262996467260536		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 0.5262996467260536 | validation: 0.5651411124271951]
	TIME [epoch: 10.3 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4128899352365612		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 0.4128899352365612 | validation: 0.39347313802430606]
	TIME [epoch: 10.3 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4871171507050427		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.4871171507050427 | validation: 0.3995374229226472]
	TIME [epoch: 10.3 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576717923128545		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 0.4576717923128545 | validation: 0.7227071543310291]
	TIME [epoch: 10.3 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5804341598575942		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 0.5804341598575942 | validation: 0.46074727673907007]
	TIME [epoch: 10.3 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4318596545370762		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 0.4318596545370762 | validation: 0.445342201863283]
	TIME [epoch: 10.3 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40348710331833787		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 0.40348710331833787 | validation: 0.5129977108881304]
	TIME [epoch: 10.3 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5581628624111037		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.5581628624111037 | validation: 0.45306948691559334]
	TIME [epoch: 10.3 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47067886722661284		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 0.47067886722661284 | validation: 0.42010984327294615]
	TIME [epoch: 10.3 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3810325525462904		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.3810325525462904 | validation: 0.6452351759581029]
	TIME [epoch: 10.3 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49142101762286894		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.49142101762286894 | validation: 1.031579727619334]
	TIME [epoch: 10.3 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7340107723935044		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 0.7340107723935044 | validation: 0.47039483908591256]
	TIME [epoch: 10.3 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43513030921124934		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 0.43513030921124934 | validation: 0.5316081024415877]
	TIME [epoch: 10.3 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44079085364484527		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.44079085364484527 | validation: 0.431455844319173]
	TIME [epoch: 10.3 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5891968069167973		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.5891968069167973 | validation: 1.0160964410737479]
	TIME [epoch: 10.3 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49028942207131115		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.49028942207131115 | validation: 0.37492080791613397]
	TIME [epoch: 10.3 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40730261910286475		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 0.40730261910286475 | validation: 0.7750344301339493]
	TIME [epoch: 10.3 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5339857108337428		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 0.5339857108337428 | validation: 0.46970659157643724]
	TIME [epoch: 10.3 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3838505727703345		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.3838505727703345 | validation: 0.416617389798371]
	TIME [epoch: 10.3 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38599856966744883		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 0.38599856966744883 | validation: 0.3896546653587032]
	TIME [epoch: 10.3 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42377127656696356		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 0.42377127656696356 | validation: 0.32548421798014704]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_330.pth
	Model improved!!!
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47571322187170295		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.47571322187170295 | validation: 0.61578865468262]
	TIME [epoch: 10.3 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5141979007368056		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 0.5141979007368056 | validation: 0.6289464437906915]
	TIME [epoch: 10.3 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4498321674502724		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 0.4498321674502724 | validation: 0.3142514467678183]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_333.pth
	Model improved!!!
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42721617062572814		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.42721617062572814 | validation: 0.5136527044434464]
	TIME [epoch: 10.3 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5531143811851298		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 0.5531143811851298 | validation: 0.4477069483705013]
	TIME [epoch: 10.3 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6179502177635958		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.6179502177635958 | validation: 0.5144069979562761]
	TIME [epoch: 10.3 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3974510276757616		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.3974510276757616 | validation: 0.39848293317845995]
	TIME [epoch: 10.3 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5931931117055769		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.5931931117055769 | validation: 0.41485628077970305]
	TIME [epoch: 10.3 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184551902328459		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.5184551902328459 | validation: 0.5137399672536974]
	TIME [epoch: 10.3 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4998874615329559		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.4998874615329559 | validation: 0.855170057070237]
	TIME [epoch: 10.3 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6458574290970892		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.6458574290970892 | validation: 0.3546981909297383]
	TIME [epoch: 10.3 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40508984263411774		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.40508984263411774 | validation: 0.439114847939001]
	TIME [epoch: 10.3 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.391342988263463		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.391342988263463 | validation: 0.4600416327422596]
	TIME [epoch: 10.3 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5800971395177956		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.5800971395177956 | validation: 0.4197064636828881]
	TIME [epoch: 10.3 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3788728134588989		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.3788728134588989 | validation: 0.331351150462881]
	TIME [epoch: 10.3 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3772862299766989		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 0.3772862299766989 | validation: 0.46230702569355325]
	TIME [epoch: 10.3 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4426048334715126		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.4426048334715126 | validation: 0.5778338907009164]
	TIME [epoch: 10.3 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40714305649516797		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 0.40714305649516797 | validation: 0.29981479963550156]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_348.pth
	Model improved!!!
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3592205722787354		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 0.3592205722787354 | validation: 0.408830475669874]
	TIME [epoch: 10.3 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.371907577569014		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.371907577569014 | validation: 0.438235894434647]
	TIME [epoch: 10.3 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43428962698308304		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.43428962698308304 | validation: 0.430661010673374]
	TIME [epoch: 10.3 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6451217740319766		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.6451217740319766 | validation: 0.3888805050888033]
	TIME [epoch: 10.3 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41650558338945853		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 0.41650558338945853 | validation: 0.4339625623380161]
	TIME [epoch: 10.3 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3349514299591312		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.3349514299591312 | validation: 0.4250603569167203]
	TIME [epoch: 10.3 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3897631712261562		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.3897631712261562 | validation: 0.3765506472779346]
	TIME [epoch: 10.3 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3989415418358118		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.3989415418358118 | validation: 0.44036538941199765]
	TIME [epoch: 10.3 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9485697639943279		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 0.9485697639943279 | validation: 0.5483207981563277]
	TIME [epoch: 10.3 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3676175705352425		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.3676175705352425 | validation: 0.37805134364095894]
	TIME [epoch: 10.3 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.583412956758725		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 0.583412956758725 | validation: 0.3858158732833375]
	TIME [epoch: 10.3 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33045585610371886		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.33045585610371886 | validation: 0.37019012976541177]
	TIME [epoch: 10.3 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34441721912952306		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.34441721912952306 | validation: 0.5023230469227733]
	TIME [epoch: 10.3 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36330004374475583		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.36330004374475583 | validation: 0.2783989246521791]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_362.pth
	Model improved!!!
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33056542226382674		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.33056542226382674 | validation: 0.39501307452397016]
	TIME [epoch: 10.3 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45192260347595486		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.45192260347595486 | validation: 0.3078114815074348]
	TIME [epoch: 10.3 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5042499995827077		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.5042499995827077 | validation: 0.577534343640894]
	TIME [epoch: 10.3 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38820141859510165		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.38820141859510165 | validation: 0.30483166593066363]
	TIME [epoch: 10.3 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3565405124610244		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 0.3565405124610244 | validation: 0.39526746347109043]
	TIME [epoch: 10.3 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4841194872065679		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.4841194872065679 | validation: 0.5884301257169731]
	TIME [epoch: 10.3 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4961291235124481		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.4961291235124481 | validation: 0.45836110677870656]
	TIME [epoch: 10.3 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4906142298085818		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.4906142298085818 | validation: 0.4628776595653346]
	TIME [epoch: 10.3 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4752991035720182		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.4752991035720182 | validation: 0.46224379212347344]
	TIME [epoch: 10.3 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32502623387721163		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.32502623387721163 | validation: 0.2952349425588382]
	TIME [epoch: 10.3 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3967348391530899		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.3967348391530899 | validation: 0.3262520913692428]
	TIME [epoch: 10.3 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49508086688513114		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.49508086688513114 | validation: 0.4276511000327482]
	TIME [epoch: 10.3 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3713612443615265		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.3713612443615265 | validation: 0.5477386656843652]
	TIME [epoch: 10.3 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36490565315349077		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.36490565315349077 | validation: 0.440665889725014]
	TIME [epoch: 10.3 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40187078592442294		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.40187078592442294 | validation: 0.4737214821164845]
	TIME [epoch: 10.3 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4463509492167795		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.4463509492167795 | validation: 0.69969300989654]
	TIME [epoch: 10.3 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43574582417986046		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.43574582417986046 | validation: 0.4049271280114799]
	TIME [epoch: 10.3 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34712444010211735		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.34712444010211735 | validation: 0.3201548834316153]
	TIME [epoch: 10.3 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29772774033839344		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.29772774033839344 | validation: 0.37733944151755366]
	TIME [epoch: 10.3 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3277924420924173		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.3277924420924173 | validation: 0.4895067736086614]
	TIME [epoch: 10.3 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4708093286309129		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.4708093286309129 | validation: 0.4899768938614381]
	TIME [epoch: 10.3 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.382566710282337		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.382566710282337 | validation: 0.34126723614047905]
	TIME [epoch: 10.3 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44606549466786893		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.44606549466786893 | validation: 0.42205546170062674]
	TIME [epoch: 10.3 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40975040709695276		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.40975040709695276 | validation: 0.5102931563675012]
	TIME [epoch: 10.3 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39478900326921307		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.39478900326921307 | validation: 0.5128100324113748]
	TIME [epoch: 10.3 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5307245968724497		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.5307245968724497 | validation: 0.31161210638870707]
	TIME [epoch: 10.3 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3100457417970365		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.3100457417970365 | validation: 0.28907681799322077]
	TIME [epoch: 10.3 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3679820926568224		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.3679820926568224 | validation: 0.3589117284668801]
	TIME [epoch: 10.3 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5600116747120263		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.5600116747120263 | validation: 0.3678430113971989]
	TIME [epoch: 10.3 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3129547906578408		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.3129547906578408 | validation: 0.5150987967840785]
	TIME [epoch: 10.3 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3658156273876757		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.3658156273876757 | validation: 0.3868043105541745]
	TIME [epoch: 10.3 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3461701951754253		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.3461701951754253 | validation: 0.29395466757827565]
	TIME [epoch: 10.3 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3486128563382308		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.3486128563382308 | validation: 0.4223553453586736]
	TIME [epoch: 10.3 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35077712559596347		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.35077712559596347 | validation: 0.7021411791276924]
	TIME [epoch: 10.3 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4856282956111631		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.4856282956111631 | validation: 0.44639496715165045]
	TIME [epoch: 10.3 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41969588834675864		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.41969588834675864 | validation: 0.400931219637513]
	TIME [epoch: 10.3 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33493141861951886		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.33493141861951886 | validation: 0.39095387693708517]
	TIME [epoch: 10.3 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3854644688735972		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.3854644688735972 | validation: 0.43392890485697266]
	TIME [epoch: 10.3 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3175312113736477		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.3175312113736477 | validation: 0.38979693529792686]
	TIME [epoch: 10.3 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3144779263327431		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.3144779263327431 | validation: 0.3314905888348569]
	TIME [epoch: 10.3 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3853185352181621		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.3853185352181621 | validation: 0.33924097671627246]
	TIME [epoch: 10.3 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237006014569094		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.3237006014569094 | validation: 0.3527720798631188]
	TIME [epoch: 10.3 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3343678039135559		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.3343678039135559 | validation: 0.3518314460840806]
	TIME [epoch: 10.3 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34640887561184086		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.34640887561184086 | validation: 0.41715532711798686]
	TIME [epoch: 10.3 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35914944904070556		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.35914944904070556 | validation: 0.36825349488971687]
	TIME [epoch: 10.3 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3251319530950404		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.3251319530950404 | validation: 0.38707005309291376]
	TIME [epoch: 10.3 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33688038871871706		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.33688038871871706 | validation: 0.35717517446259067]
	TIME [epoch: 10.3 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28873493559054914		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.28873493559054914 | validation: 0.40536170727954024]
	TIME [epoch: 10.3 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39834121402191774		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.39834121402191774 | validation: 0.41356098396083985]
	TIME [epoch: 10.3 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335672760833114		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.5335672760833114 | validation: 1.0597370743446513]
	TIME [epoch: 10.3 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8603535635381224		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.8603535635381224 | validation: 0.5427220229630824]
	TIME [epoch: 10.3 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40108730407740073		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.40108730407740073 | validation: 0.3064911639682258]
	TIME [epoch: 10.3 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261685413635708		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.3261685413635708 | validation: 0.586539533293689]
	TIME [epoch: 10.3 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3494321863936459		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.3494321863936459 | validation: 0.31202844396467566]
	TIME [epoch: 10.3 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.346093502357071		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.346093502357071 | validation: 0.4739095726768886]
	TIME [epoch: 10.3 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3891265737701702		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.3891265737701702 | validation: 0.44029096736869117]
	TIME [epoch: 10.3 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39632026724846625		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.39632026724846625 | validation: 0.32219995411577673]
	TIME [epoch: 10.3 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2550234627420817		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.2550234627420817 | validation: 0.32701465219890563]
	TIME [epoch: 10.3 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3228234466056107		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.3228234466056107 | validation: 0.45113545897373414]
	TIME [epoch: 10.3 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36725651115283453		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.36725651115283453 | validation: 0.38434250612660875]
	TIME [epoch: 10.3 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27424353947194735		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.27424353947194735 | validation: 0.38975517519993036]
	TIME [epoch: 10.3 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4807476434514726		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.4807476434514726 | validation: 0.503437818026802]
	TIME [epoch: 10.3 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35038256422746583		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 0.35038256422746583 | validation: 0.33404156917065897]
	TIME [epoch: 10.3 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5395896704368126		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.5395896704368126 | validation: 0.4000432382520996]
	TIME [epoch: 10.3 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3220587822210036		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.3220587822210036 | validation: 0.35503350779904114]
	TIME [epoch: 10.3 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26901438025284585		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.26901438025284585 | validation: 0.28985122455808365]
	TIME [epoch: 10.3 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29541871119977614		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.29541871119977614 | validation: 0.6340437287437349]
	TIME [epoch: 10.3 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46714767007880464		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.46714767007880464 | validation: 0.31588528359359574]
	TIME [epoch: 10.3 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26967756786120517		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.26967756786120517 | validation: 0.32864522282144976]
	TIME [epoch: 10.3 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33010911934127496		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.33010911934127496 | validation: 0.2448561188049071]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_432.pth
	Model improved!!!
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3306564823408848		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.3306564823408848 | validation: 0.41692472881177794]
	TIME [epoch: 10.3 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2952073255558937		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.2952073255558937 | validation: 0.33864507745822464]
	TIME [epoch: 10.3 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4212822485487459		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.4212822485487459 | validation: 0.3753474038703106]
	TIME [epoch: 10.3 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710203519353326		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.2710203519353326 | validation: 0.32382287442866786]
	TIME [epoch: 10.3 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107710614614865		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.3107710614614865 | validation: 0.3408822784372464]
	TIME [epoch: 10.3 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37235373131849936		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.37235373131849936 | validation: 0.3229788699648891]
	TIME [epoch: 10.3 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4176808032317466		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.4176808032317466 | validation: 0.29422393397262037]
	TIME [epoch: 10.3 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3319745946681148		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.3319745946681148 | validation: 0.5689621212914947]
	TIME [epoch: 10.3 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3679574367487972		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.3679574367487972 | validation: 0.3508125260558246]
	TIME [epoch: 10.4 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40601820887027423		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.40601820887027423 | validation: 0.4299436927462103]
	TIME [epoch: 10.3 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.354935478948497		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.354935478948497 | validation: 0.3424196514904093]
	TIME [epoch: 10.3 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230822022910591		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.3230822022910591 | validation: 0.6753439721152552]
	TIME [epoch: 10.3 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187789559903405		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.5187789559903405 | validation: 0.36592917962230515]
	TIME [epoch: 10.3 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4348652125856824		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.4348652125856824 | validation: 0.3846774799778781]
	TIME [epoch: 10.3 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30709780027326944		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.30709780027326944 | validation: 0.3295015606765906]
	TIME [epoch: 10.3 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2712653945977825		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.2712653945977825 | validation: 0.3880417388669645]
	TIME [epoch: 10.3 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33458236098462335		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.33458236098462335 | validation: 0.3165429057265618]
	TIME [epoch: 10.3 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102476763112054		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.3102476763112054 | validation: 0.297671347472961]
	TIME [epoch: 10.3 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30380694453542334		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.30380694453542334 | validation: 0.36715533251140675]
	TIME [epoch: 10.3 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32271722035458494		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.32271722035458494 | validation: 0.3796583365233511]
	TIME [epoch: 10.3 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2733601889427766		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.2733601889427766 | validation: 0.29751052128589395]
	TIME [epoch: 10.4 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4981724855712474		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.4981724855712474 | validation: 0.3594241564690026]
	TIME [epoch: 10.3 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26443298128105674		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.26443298128105674 | validation: 0.27153482339537016]
	TIME [epoch: 10.3 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2481950719569565		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.2481950719569565 | validation: 0.27582955058927133]
	TIME [epoch: 10.3 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36002824628261726		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.36002824628261726 | validation: 0.3394071406716068]
	TIME [epoch: 10.3 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.302025529425107		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.302025529425107 | validation: 0.2852734398803364]
	TIME [epoch: 10.3 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28913980559066127		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.28913980559066127 | validation: 0.3144763190836642]
	TIME [epoch: 10.3 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37243231079312056		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.37243231079312056 | validation: 0.33271552388209785]
	TIME [epoch: 10.3 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27317314081371546		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.27317314081371546 | validation: 0.2992615971424646]
	TIME [epoch: 10.3 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2377995381328279		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.2377995381328279 | validation: 0.407051248736768]
	TIME [epoch: 10.3 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40855324407622773		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.40855324407622773 | validation: 0.2957412302246986]
	TIME [epoch: 10.3 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27059994701845935		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.27059994701845935 | validation: 0.3831871865072969]
	TIME [epoch: 10.3 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36368909996878884		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.36368909996878884 | validation: 0.3511405286564128]
	TIME [epoch: 10.4 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29684427533654506		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.29684427533654506 | validation: 0.3977183361553069]
	TIME [epoch: 10.3 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28341751864363185		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.28341751864363185 | validation: 0.27220699855468505]
	TIME [epoch: 10.3 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27977131683624296		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.27977131683624296 | validation: 0.25410671982027644]
	TIME [epoch: 10.3 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615854873350995		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.3615854873350995 | validation: 0.4140092415723278]
	TIME [epoch: 10.3 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39430239150674906		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.39430239150674906 | validation: 0.3075228646074946]
	TIME [epoch: 10.3 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2266093486820447		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.2266093486820447 | validation: 0.23051212909301277]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_471.pth
	Model improved!!!
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2630720265874867		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.2630720265874867 | validation: 0.26051163310722125]
	TIME [epoch: 10.3 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2903125934976427		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.2903125934976427 | validation: 0.4236953824225915]
	TIME [epoch: 10.3 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3064090603194054		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.3064090603194054 | validation: 0.23569415272154104]
	TIME [epoch: 10.3 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34034106531564257		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.34034106531564257 | validation: 0.4286928489589579]
	TIME [epoch: 10.3 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28413563880787185		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.28413563880787185 | validation: 0.30592134430976337]
	TIME [epoch: 10.3 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31231617094848013		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.31231617094848013 | validation: 0.3565592392176293]
	TIME [epoch: 10.3 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.327949968563246		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.327949968563246 | validation: 0.32669500643583954]
	TIME [epoch: 10.3 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28369806444348417		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.28369806444348417 | validation: 0.6318055661592841]
	TIME [epoch: 10.3 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48085308390356474		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.48085308390356474 | validation: 0.39750960629789606]
	TIME [epoch: 10.3 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3145380791130886		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.3145380791130886 | validation: 0.2737887057502123]
	TIME [epoch: 10.3 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24409232831897282		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.24409232831897282 | validation: 0.2686478390833371]
	TIME [epoch: 10.3 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27206757655721836		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.27206757655721836 | validation: 0.48902606660422626]
	TIME [epoch: 10.3 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4072198348009601		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.4072198348009601 | validation: 0.32422758385788675]
	TIME [epoch: 10.3 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.268617306062367		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.268617306062367 | validation: 0.3180372660733046]
	TIME [epoch: 10.3 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2479917937872244		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.2479917937872244 | validation: 0.2395727291087622]
	TIME [epoch: 10.3 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29621948125141034		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.29621948125141034 | validation: 0.3238923806309974]
	TIME [epoch: 10.3 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26116877142237277		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.26116877142237277 | validation: 0.3029911632480492]
	TIME [epoch: 10.3 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28520146318146306		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.28520146318146306 | validation: 0.302498099043368]
	TIME [epoch: 10.3 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35165279224231805		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.35165279224231805 | validation: 0.41018353233712596]
	TIME [epoch: 10.3 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29279283445914367		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.29279283445914367 | validation: 0.2640857096045555]
	TIME [epoch: 10.3 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2995246530665377		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.2995246530665377 | validation: 0.3896400133429891]
	TIME [epoch: 10.3 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33443956267400055		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.33443956267400055 | validation: 0.2604421281042782]
	TIME [epoch: 10.3 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23187017453489372		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.23187017453489372 | validation: 0.2921810293421055]
	TIME [epoch: 10.3 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2970161535697809		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.2970161535697809 | validation: 0.4970512898879942]
	TIME [epoch: 10.3 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3475528442344514		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.3475528442344514 | validation: 0.2813381337579458]
	TIME [epoch: 10.3 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31277401913068714		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.31277401913068714 | validation: 0.30546367056027734]
	TIME [epoch: 10.3 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596960839423987		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.2596960839423987 | validation: 0.26743616063249864]
	TIME [epoch: 10.3 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22616433504045216		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.22616433504045216 | validation: 0.3200668494031097]
	TIME [epoch: 10.3 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23768526752497438		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.23768526752497438 | validation: 0.28829490152326837]
	TIME [epoch: 10.3 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28613682575830096		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.28613682575830096 | validation: 0.36684577215413455]
	TIME [epoch: 10.3 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2901921067379495		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.2901921067379495 | validation: 0.3361984641421097]
	TIME [epoch: 10.3 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23675015722582052		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.23675015722582052 | validation: 0.2638911599832023]
	TIME [epoch: 10.3 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2695528946118619		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.2695528946118619 | validation: 0.323574018433752]
	TIME [epoch: 10.3 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26247899978403766		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.26247899978403766 | validation: 0.3812995914969314]
	TIME [epoch: 10.3 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31623969620379294		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.31623969620379294 | validation: 0.2828697071157134]
	TIME [epoch: 10.3 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24417647810158916		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.24417647810158916 | validation: 0.2567370905738471]
	TIME [epoch: 10.3 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24289376992717954		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.24289376992717954 | validation: 0.28441490149855253]
	TIME [epoch: 10.3 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3112977725181187		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.3112977725181187 | validation: 0.2687510226731993]
	TIME [epoch: 10.3 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2834366264843167		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.2834366264843167 | validation: 0.44427594727966585]
	TIME [epoch: 10.3 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720257658407137		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.3720257658407137 | validation: 0.2570145425823143]
	TIME [epoch: 10.3 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23340182805442994		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.23340182805442994 | validation: 0.26002733362621155]
	TIME [epoch: 10.3 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26980485243749214		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.26980485243749214 | validation: 0.2959986449881159]
	TIME [epoch: 10.3 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23510043637153172		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.23510043637153172 | validation: 0.24660625919887166]
	TIME [epoch: 10.3 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.276257314619473		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.276257314619473 | validation: 0.32734438617901146]
	TIME [epoch: 10.3 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31797046852762534		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.31797046852762534 | validation: 0.3936684095655532]
	TIME [epoch: 10.3 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4003933133296889		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.4003933133296889 | validation: 0.3198121583523345]
	TIME [epoch: 10.3 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28296463185685194		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.28296463185685194 | validation: 0.2764822534194892]
	TIME [epoch: 10.3 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.312086713598161		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.312086713598161 | validation: 0.3060169957458311]
	TIME [epoch: 10.3 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24921144602321652		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.24921144602321652 | validation: 0.3062185289611332]
	TIME [epoch: 10.3 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2824917044765126		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.2824917044765126 | validation: 0.3100584874403494]
	TIME [epoch: 10.3 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24702972351547103		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.24702972351547103 | validation: 0.27148351540972165]
	TIME [epoch: 10.3 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23911821674569103		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.23911821674569103 | validation: 0.3322185119897219]
	TIME [epoch: 10.3 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613572892879046		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.2613572892879046 | validation: 0.3052783858818256]
	TIME [epoch: 10.3 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38521402937703525		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.38521402937703525 | validation: 0.30406105737087147]
	TIME [epoch: 10.3 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142668536426215		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.3142668536426215 | validation: 0.3683919167574598]
	TIME [epoch: 10.3 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26616916256764306		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.26616916256764306 | validation: 0.33128152594088184]
	TIME [epoch: 10.3 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30787501280344154		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.30787501280344154 | validation: 0.30732759976116747]
	TIME [epoch: 10.3 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25822268856586855		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.25822268856586855 | validation: 0.3839601499338926]
	TIME [epoch: 10.3 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3918200242342575		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.3918200242342575 | validation: 0.305207477045293]
	TIME [epoch: 10.3 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25266251040991977		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.25266251040991977 | validation: 0.3124664044687117]
	TIME [epoch: 10.3 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2513201565633995		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.2513201565633995 | validation: 0.257171201513696]
	TIME [epoch: 10.3 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2441019059250981		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.2441019059250981 | validation: 0.2590202067888861]
	TIME [epoch: 10.3 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2252608736504867		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.2252608736504867 | validation: 0.28372064518297335]
	TIME [epoch: 10.3 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23920345164267248		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.23920345164267248 | validation: 0.2909225131383812]
	TIME [epoch: 10.3 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3030131989165591		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.3030131989165591 | validation: 0.298336814010922]
	TIME [epoch: 10.3 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2439652518531516		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.2439652518531516 | validation: 0.38132229707860277]
	TIME [epoch: 10.3 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660336358884853		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.2660336358884853 | validation: 0.2675224498939788]
	TIME [epoch: 10.3 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29116919319447215		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.29116919319447215 | validation: 0.31288131604053915]
	TIME [epoch: 10.3 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2493879581304605		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.2493879581304605 | validation: 0.34119304997061134]
	TIME [epoch: 10.3 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2548209443614485		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.2548209443614485 | validation: 0.5120056164745698]
	TIME [epoch: 10.3 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3797121010544177		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.3797121010544177 | validation: 0.22949796515478993]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_542.pth
	Model improved!!!
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23484066618778776		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.23484066618778776 | validation: 0.25477313246503874]
	TIME [epoch: 10.3 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26303506274019267		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.26303506274019267 | validation: 0.37526430451298887]
	TIME [epoch: 10.3 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3292136218199929		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.3292136218199929 | validation: 0.2609159842737185]
	TIME [epoch: 10.3 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2729495301564308		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.2729495301564308 | validation: 0.3398653707469417]
	TIME [epoch: 10.3 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2601322905851169		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.2601322905851169 | validation: 0.23525028882811094]
	TIME [epoch: 10.3 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1954219938700727		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.1954219938700727 | validation: 0.26630195887078684]
	TIME [epoch: 10.3 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28655743454689475		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.28655743454689475 | validation: 0.380612602875613]
	TIME [epoch: 10.3 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146564568813761		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.3146564568813761 | validation: 0.3030883347577897]
	TIME [epoch: 10.3 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23046114774771076		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.23046114774771076 | validation: 0.3449840167527519]
	TIME [epoch: 10.3 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3043937919868626		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.3043937919868626 | validation: 0.32676461036698834]
	TIME [epoch: 10.3 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2718647990362131		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.2718647990362131 | validation: 0.23285853293040226]
	TIME [epoch: 10.3 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24476877678985728		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.24476877678985728 | validation: 0.46265803921209214]
	TIME [epoch: 10.3 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3554640814426919		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.3554640814426919 | validation: 0.2331393155393416]
	TIME [epoch: 10.3 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22266186176803165		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.22266186176803165 | validation: 0.2261359344090187]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_556.pth
	Model improved!!!
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28789098302549365		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.28789098302549365 | validation: 0.28647936289980175]
	TIME [epoch: 10.3 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25277734627350423		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.25277734627350423 | validation: 0.2710048733980912]
	TIME [epoch: 10.3 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2266554166016305		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.2266554166016305 | validation: 0.31337048211618096]
	TIME [epoch: 10.3 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4048384243287579		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.4048384243287579 | validation: 0.6302825521528506]
	TIME [epoch: 10.3 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3973090987126371		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.3973090987126371 | validation: 0.2431648598966592]
	TIME [epoch: 10.3 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23999616790020745		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.23999616790020745 | validation: 0.23300632656249165]
	TIME [epoch: 10.3 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2496151559045149		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.2496151559045149 | validation: 0.2928057162946794]
	TIME [epoch: 10.3 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22848126668399216		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.22848126668399216 | validation: 0.24896374336773483]
	TIME [epoch: 10.3 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20079044507575458		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.20079044507575458 | validation: 0.3092938354571052]
	TIME [epoch: 10.3 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28188599189736313		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.28188599189736313 | validation: 0.24894999368714146]
	TIME [epoch: 10.3 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2204786052814315		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.2204786052814315 | validation: 0.24726540422243737]
	TIME [epoch: 10.3 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.217227437685272		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.217227437685272 | validation: 0.2467294955985724]
	TIME [epoch: 10.3 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24129705261899118		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.24129705261899118 | validation: 0.27153171429582773]
	TIME [epoch: 10.3 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24192594645576654		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.24192594645576654 | validation: 0.30280366124217367]
	TIME [epoch: 10.3 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32829260315731823		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.32829260315731823 | validation: 0.3449094123846696]
	TIME [epoch: 10.3 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28220840943250075		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.28220840943250075 | validation: 0.2642031041475119]
	TIME [epoch: 10.3 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660036791737506		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.2660036791737506 | validation: 0.253934807487325]
	TIME [epoch: 10.3 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3129034048209771		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.3129034048209771 | validation: 0.49158749943880964]
	TIME [epoch: 10.3 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4270452305953242		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.4270452305953242 | validation: 0.2537527878821275]
	TIME [epoch: 10.3 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705038299923889		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.2705038299923889 | validation: 0.3996492122614126]
	TIME [epoch: 10.3 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2745594281857219		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.2745594281857219 | validation: 0.28402579787212356]
	TIME [epoch: 10.3 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27987830538943415		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.27987830538943415 | validation: 0.2729006686811583]
	TIME [epoch: 10.3 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24900834402970146		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.24900834402970146 | validation: 0.2724402167560742]
	TIME [epoch: 10.3 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23129098186460983		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.23129098186460983 | validation: 0.25047088084627817]
	TIME [epoch: 10.3 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2517196258329529		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.2517196258329529 | validation: 0.2531467758730457]
	TIME [epoch: 10.3 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22300969530666676		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.22300969530666676 | validation: 0.2154343752487744]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_582.pth
	Model improved!!!
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21576759429884967		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.21576759429884967 | validation: 0.36416339126936564]
	TIME [epoch: 10.3 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25026031329896814		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.25026031329896814 | validation: 0.2431965370848193]
	TIME [epoch: 10.3 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24816968299769906		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.24816968299769906 | validation: 0.41077441337775195]
	TIME [epoch: 10.3 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26023934872712273		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.26023934872712273 | validation: 0.24517186427084106]
	TIME [epoch: 10.3 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2790132865425603		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.2790132865425603 | validation: 0.36332428958955987]
	TIME [epoch: 10.3 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2847074752234924		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.2847074752234924 | validation: 0.30303739319472595]
	TIME [epoch: 10.3 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24745867305230557		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.24745867305230557 | validation: 0.33772068737654887]
	TIME [epoch: 10.3 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28519444712180403		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.28519444712180403 | validation: 0.264199428299476]
	TIME [epoch: 10.3 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21658516340465916		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.21658516340465916 | validation: 0.23172346622763015]
	TIME [epoch: 10.3 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20548980463904537		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.20548980463904537 | validation: 0.26441162887886693]
	TIME [epoch: 10.3 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23691018894878463		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.23691018894878463 | validation: 0.26175132335683976]
	TIME [epoch: 10.3 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20021801560545663		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.20021801560545663 | validation: 0.1983665174777852]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_594.pth
	Model improved!!!
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19157524347651061		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.19157524347651061 | validation: 0.2698139179237483]
	TIME [epoch: 10.3 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25030893836414414		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.25030893836414414 | validation: 0.4253924682309724]
	TIME [epoch: 10.3 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30314442558322596		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.30314442558322596 | validation: 0.3189490710663567]
	TIME [epoch: 10.3 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22667583422929968		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.22667583422929968 | validation: 0.2229981398604589]
	TIME [epoch: 10.3 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20650250337714726		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.20650250337714726 | validation: 0.21087270574834216]
	TIME [epoch: 10.3 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22115934669452414		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.22115934669452414 | validation: 0.20690169719335558]
	TIME [epoch: 10.3 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26892752904075923		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.26892752904075923 | validation: 0.37221080045345545]
	TIME [epoch: 10.3 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2768174345177556		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.2768174345177556 | validation: 0.28140083462489607]
	TIME [epoch: 10.3 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26276233110976205		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.26276233110976205 | validation: 0.26265032950728134]
	TIME [epoch: 10.3 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2560637505232418		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.2560637505232418 | validation: 0.41726038292538403]
	TIME [epoch: 10.3 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30211161411949183		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.30211161411949183 | validation: 0.2826004322264529]
	TIME [epoch: 10.3 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26303833280767275		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.26303833280767275 | validation: 0.3337473566208054]
	TIME [epoch: 10.3 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2614765265437681		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.2614765265437681 | validation: 0.23586947339946193]
	TIME [epoch: 10.3 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27220113554556724		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.27220113554556724 | validation: 0.4066017795183297]
	TIME [epoch: 10.3 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27063760424493777		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.27063760424493777 | validation: 0.270267114339538]
	TIME [epoch: 10.3 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22811907378009674		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.22811907378009674 | validation: 0.25792019277889994]
	TIME [epoch: 10.3 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21340807204437606		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.21340807204437606 | validation: 0.24813256829154196]
	TIME [epoch: 10.3 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23693644397910812		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.23693644397910812 | validation: 0.24991173281521925]
	TIME [epoch: 10.3 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2381779874759827		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.2381779874759827 | validation: 0.28675972254844956]
	TIME [epoch: 10.3 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26222816122975284		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.26222816122975284 | validation: 0.2795748422458055]
	TIME [epoch: 10.3 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23787664050291418		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.23787664050291418 | validation: 0.24541114344346787]
	TIME [epoch: 10.3 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.304164511797123		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.304164511797123 | validation: 0.3338599068608674]
	TIME [epoch: 10.3 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2468671313836282		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.2468671313836282 | validation: 0.3314662076580281]
	TIME [epoch: 10.3 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2604636095756334		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.2604636095756334 | validation: 0.3545691496635473]
	TIME [epoch: 10.3 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31973888620359253		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.31973888620359253 | validation: 0.3089607525217321]
	TIME [epoch: 10.3 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24974401398197416		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.24974401398197416 | validation: 0.28630803800191706]
	TIME [epoch: 10.3 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2759259041352804		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.2759259041352804 | validation: 0.2689413605268104]
	TIME [epoch: 10.3 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2766792110324709		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.2766792110324709 | validation: 0.30214469371146563]
	TIME [epoch: 10.3 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2643707719043634		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.2643707719043634 | validation: 0.41001471311246657]
	TIME [epoch: 10.3 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32401489193055805		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.32401489193055805 | validation: 0.3085513920191133]
	TIME [epoch: 10.3 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2750750901608007		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.2750750901608007 | validation: 0.3021094391914429]
	TIME [epoch: 10.3 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515264488102057		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.2515264488102057 | validation: 0.28776330715677584]
	TIME [epoch: 10.3 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2480675367917841		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.2480675367917841 | validation: 0.2544110232765243]
	TIME [epoch: 10.3 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22803263108826205		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.22803263108826205 | validation: 0.2700121211746418]
	TIME [epoch: 10.3 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26274096841787703		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.26274096841787703 | validation: 0.2521976182228664]
	TIME [epoch: 10.3 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2347193120030424		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.2347193120030424 | validation: 0.26483170262205025]
	TIME [epoch: 10.3 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2261838197637344		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.2261838197637344 | validation: 0.2542192693006646]
	TIME [epoch: 10.3 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2474350354453067		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.2474350354453067 | validation: 0.2649866583703825]
	TIME [epoch: 10.3 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23771526258509543		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.23771526258509543 | validation: 0.27958893060170714]
	TIME [epoch: 10.3 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25747426175015364		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.25747426175015364 | validation: 0.24567863509692828]
	TIME [epoch: 10.3 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2101907167056291		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.2101907167056291 | validation: 0.24404264204634232]
	TIME [epoch: 10.3 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21343404039279154		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.21343404039279154 | validation: 0.26064544381077703]
	TIME [epoch: 10.3 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2446972994224134		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.2446972994224134 | validation: 0.2566572326526442]
	TIME [epoch: 10.3 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2812514394595868		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.2812514394595868 | validation: 0.26174544608269146]
	TIME [epoch: 10.3 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25906383898627294		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.25906383898627294 | validation: 0.2501228497605621]
	TIME [epoch: 10.3 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23320842320701743		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.23320842320701743 | validation: 0.2818120084882682]
	TIME [epoch: 10.3 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24789354528084032		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.24789354528084032 | validation: 0.24195520447317775]
	TIME [epoch: 10.3 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21569970894698648		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.21569970894698648 | validation: 0.23868764306225898]
	TIME [epoch: 10.3 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18375487231335458		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.18375487231335458 | validation: 0.21026170370250188]
	TIME [epoch: 10.3 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19950594626581647		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.19950594626581647 | validation: 0.25448605252471657]
	TIME [epoch: 10.3 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23919651623657656		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.23919651623657656 | validation: 0.29882325255996867]
	TIME [epoch: 10.3 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2210383957016766		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.2210383957016766 | validation: 0.22319742076236948]
	TIME [epoch: 10.3 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20394147872374777		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.20394147872374777 | validation: 0.21873855204203]
	TIME [epoch: 10.3 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.195409204870439		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.195409204870439 | validation: 0.24031600694577834]
	TIME [epoch: 10.3 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20667939385238068		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.20667939385238068 | validation: 0.2508261260069042]
	TIME [epoch: 10.3 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20749786074104332		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.20749786074104332 | validation: 0.19940155615693797]
	TIME [epoch: 10.3 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20007914651252454		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.20007914651252454 | validation: 0.2383846838111411]
	TIME [epoch: 10.3 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2246147046749225		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.2246147046749225 | validation: 0.3021294599582366]
	TIME [epoch: 10.3 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2905729596940626		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.2905729596940626 | validation: 0.24567444701786492]
	TIME [epoch: 10.3 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2060631759389852		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.2060631759389852 | validation: 0.22308283523327116]
	TIME [epoch: 10.3 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21647672366232973		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.21647672366232973 | validation: 0.299113772656554]
	TIME [epoch: 10.3 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24522960611464106		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.24522960611464106 | validation: 0.25946863322614994]
	TIME [epoch: 10.3 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2667601392289488		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.2667601392289488 | validation: 0.22268084959578902]
	TIME [epoch: 10.3 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19953710146989387		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.19953710146989387 | validation: 0.22949059927220872]
	TIME [epoch: 10.3 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018148948682966		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.2018148948682966 | validation: 0.22861412626782326]
	TIME [epoch: 10.3 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19421565042268957		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.19421565042268957 | validation: 0.2388177075112621]
	TIME [epoch: 10.3 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20112728031039057		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.20112728031039057 | validation: 0.2792662396518277]
	TIME [epoch: 10.3 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.272217177615974		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.272217177615974 | validation: 0.26013699512127153]
	TIME [epoch: 10.3 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2172483825313937		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.2172483825313937 | validation: 0.22692652491545148]
	TIME [epoch: 10.3 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2114942898220445		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.2114942898220445 | validation: 0.2640187545040694]
	TIME [epoch: 10.3 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21862869435053783		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.21862869435053783 | validation: 0.2667174222352798]
	TIME [epoch: 10.3 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21330572741964163		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.21330572741964163 | validation: 0.22458952306419322]
	TIME [epoch: 10.3 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24620487901992244		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.24620487901992244 | validation: 0.2472573727446531]
	TIME [epoch: 10.3 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20131968262739028		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.20131968262739028 | validation: 0.2374338071312153]
	TIME [epoch: 10.3 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000798886468885		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.2000798886468885 | validation: 0.21130216152130848]
	TIME [epoch: 10.3 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21369307323440076		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.21369307323440076 | validation: 0.26320191470106036]
	TIME [epoch: 10.3 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22078293377098887		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.22078293377098887 | validation: 0.24124052585394992]
	TIME [epoch: 10.3 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19017119504162522		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.19017119504162522 | validation: 0.20831280087403511]
	TIME [epoch: 10.3 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21714048057490723		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.21714048057490723 | validation: 0.258053898995789]
	TIME [epoch: 10.3 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21484291094547903		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.21484291094547903 | validation: 0.22002533252782017]
	TIME [epoch: 10.3 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2079420836245463		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.2079420836245463 | validation: 0.27147468034063693]
	TIME [epoch: 10.3 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2534084029964335		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.2534084029964335 | validation: 0.21037147778045934]
	TIME [epoch: 10.3 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22152023283811578		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.22152023283811578 | validation: 0.21540298480348685]
	TIME [epoch: 10.3 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20962595806409712		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.20962595806409712 | validation: 0.21410854456555883]
	TIME [epoch: 10.3 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18172736381853424		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.18172736381853424 | validation: 0.2122572875822813]
	TIME [epoch: 10.3 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2122993926367311		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.2122993926367311 | validation: 0.2568415659809203]
	TIME [epoch: 10.3 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2154017873644043		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.2154017873644043 | validation: 0.27082126757526886]
	TIME [epoch: 10.3 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20963829515546012		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.20963829515546012 | validation: 0.22507297335674956]
	TIME [epoch: 10.3 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26437309355594263		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.26437309355594263 | validation: 0.23038913852909995]
	TIME [epoch: 10.3 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20874000771718793		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.20874000771718793 | validation: 0.18545982562304175]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_684.pth
	Model improved!!!
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18229472583194598		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.18229472583194598 | validation: 0.20815089172785603]
	TIME [epoch: 10.3 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974488169358766		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.1974488169358766 | validation: 0.23007342913224396]
	TIME [epoch: 10.3 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19065243097287443		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.19065243097287443 | validation: 0.20426966304793615]
	TIME [epoch: 10.3 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20058704101550182		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.20058704101550182 | validation: 0.2055626395557664]
	TIME [epoch: 10.3 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20596526439559573		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.20596526439559573 | validation: 0.1971179360218521]
	TIME [epoch: 10.3 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18592366463041266		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.18592366463041266 | validation: 0.23325381775153198]
	TIME [epoch: 10.3 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18976020022695522		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.18976020022695522 | validation: 0.23469450034552]
	TIME [epoch: 10.3 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21936046658633107		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.21936046658633107 | validation: 0.21871131639633773]
	TIME [epoch: 10.3 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18489424913676356		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.18489424913676356 | validation: 0.2548577483324316]
	TIME [epoch: 10.3 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22586901690423317		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.22586901690423317 | validation: 0.2501349694531101]
	TIME [epoch: 10.3 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2116273827236706		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.2116273827236706 | validation: 0.21221131825645956]
	TIME [epoch: 10.3 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2480231018910093		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.2480231018910093 | validation: 0.30000921752982435]
	TIME [epoch: 10.3 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23089493108942577		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.23089493108942577 | validation: 0.21835844666368626]
	TIME [epoch: 10.3 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20321301966550748		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.20321301966550748 | validation: 0.2282436866541585]
	TIME [epoch: 10.3 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20534308632156884		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.20534308632156884 | validation: 0.21867422667579509]
	TIME [epoch: 10.3 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19230827575198095		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.19230827575198095 | validation: 0.23429539543404546]
	TIME [epoch: 10.3 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22954668406670117		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.22954668406670117 | validation: 0.2545021392733277]
	TIME [epoch: 10.3 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19747093522184486		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.19747093522184486 | validation: 0.2273557718203503]
	TIME [epoch: 10.3 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21600367968155015		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.21600367968155015 | validation: 0.22270715011699252]
	TIME [epoch: 10.3 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19283812564943464		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.19283812564943464 | validation: 0.22567622921715655]
	TIME [epoch: 10.3 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1991759059420451		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.1991759059420451 | validation: 0.23741514171562494]
	TIME [epoch: 10.3 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.187843994440534		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.187843994440534 | validation: 0.20288107264736296]
	TIME [epoch: 10.3 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1802066528486837		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.1802066528486837 | validation: 0.20240218364553536]
	TIME [epoch: 10.3 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19828452019536724		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.19828452019536724 | validation: 0.215035807947259]
	TIME [epoch: 10.3 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19044103706604049		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.19044103706604049 | validation: 0.19672369624372985]
	TIME [epoch: 10.3 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2126935364573001		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.2126935364573001 | validation: 0.2362667179759017]
	TIME [epoch: 10.3 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19766638814026852		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.19766638814026852 | validation: 0.22020263259085662]
	TIME [epoch: 10.3 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18090458763838063		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.18090458763838063 | validation: 0.20738950768110223]
	TIME [epoch: 10.3 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19279530862669086		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.19279530862669086 | validation: 0.2651594155050267]
	TIME [epoch: 10.3 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2333302046236258		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.2333302046236258 | validation: 0.22323906891958467]
	TIME [epoch: 10.3 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19819665759128774		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.19819665759128774 | validation: 0.22399656122199735]
	TIME [epoch: 10.3 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19030695212737697		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.19030695212737697 | validation: 0.21161313118482197]
	TIME [epoch: 10.3 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20037632334580963		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.20037632334580963 | validation: 0.23294338565951944]
	TIME [epoch: 10.3 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2275762626067724		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.2275762626067724 | validation: 0.27333528732533546]
	TIME [epoch: 10.3 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20313013367155888		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.20313013367155888 | validation: 0.20866642742758656]
	TIME [epoch: 10.3 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18354799126035565		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.18354799126035565 | validation: 0.24882432243409192]
	TIME [epoch: 10.3 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20401624649790112		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.20401624649790112 | validation: 0.21303427050625665]
	TIME [epoch: 10.3 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18566640287406097		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.18566640287406097 | validation: 0.246581391623777]
	TIME [epoch: 10.3 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20233486848350046		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.20233486848350046 | validation: 0.22812986722107004]
	TIME [epoch: 10.3 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20112243491631077		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.20112243491631077 | validation: 0.23305815629011858]
	TIME [epoch: 10.3 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2345492401571243		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.2345492401571243 | validation: 0.3027935317263022]
	TIME [epoch: 10.3 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21812413567527567		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.21812413567527567 | validation: 0.22327055096102835]
	TIME [epoch: 10.3 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1956479840584754		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.1956479840584754 | validation: 0.23010138560685056]
	TIME [epoch: 10.3 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1960205885331526		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.1960205885331526 | validation: 0.21963264003741473]
	TIME [epoch: 10.3 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1960829801924347		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.1960829801924347 | validation: 0.23263337976668383]
	TIME [epoch: 10.3 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20857703359021365		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.20857703359021365 | validation: 0.23977920144375603]
	TIME [epoch: 10.3 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21103321696326813		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.21103321696326813 | validation: 0.21514185349443996]
	TIME [epoch: 10.3 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2678536391231775		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.2678536391231775 | validation: 0.29471005612297846]
	TIME [epoch: 10.3 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2556351335670158		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.2556351335670158 | validation: 0.22486693845142164]
	TIME [epoch: 10.3 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21274626833863178		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.21274626833863178 | validation: 0.23446729985055864]
	TIME [epoch: 10.3 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21363254093657638		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.21363254093657638 | validation: 0.2487510241638232]
	TIME [epoch: 10.3 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21013232521671657		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.21013232521671657 | validation: 0.2297625879868527]
	TIME [epoch: 10.3 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2078099909081052		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.2078099909081052 | validation: 0.2692461924732677]
	TIME [epoch: 10.3 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24079383676762472		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.24079383676762472 | validation: 0.24798820988386933]
	TIME [epoch: 10.3 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21812772017772		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.21812772017772 | validation: 0.222949537879367]
	TIME [epoch: 10.3 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20114913687833208		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.20114913687833208 | validation: 0.27000139462408185]
	TIME [epoch: 10.3 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2138086450970773		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.2138086450970773 | validation: 0.26623644445810973]
	TIME [epoch: 10.3 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2632910433049771		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.2632910433049771 | validation: 0.324421414431761]
	TIME [epoch: 10.3 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24991741595657305		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.24991741595657305 | validation: 0.24927958433137662]
	TIME [epoch: 10.3 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20769035154670776		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.20769035154670776 | validation: 0.22621693357052217]
	TIME [epoch: 10.3 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2156481392228899		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.2156481392228899 | validation: 0.21598464185283103]
	TIME [epoch: 10.3 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835623252270413		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.1835623252270413 | validation: 0.2047502043712566]
	TIME [epoch: 10.7 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19962486172735844		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.19962486172735844 | validation: 0.20064832767336896]
	TIME [epoch: 10.3 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1891160267934956		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.1891160267934956 | validation: 0.21473439438493805]
	TIME [epoch: 10.3 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937618208308704		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.1937618208308704 | validation: 0.235297585333331]
	TIME [epoch: 10.4 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19411603051169424		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.19411603051169424 | validation: 0.1968907785545266]
	TIME [epoch: 10.3 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789667524730469		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.1789667524730469 | validation: 0.19051075091925995]
	TIME [epoch: 10.3 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19223254264618778		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.19223254264618778 | validation: 0.22213763366690203]
	TIME [epoch: 10.3 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21109447301915657		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.21109447301915657 | validation: 0.25179082478365267]
	TIME [epoch: 10.3 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20394116497000322		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.20394116497000322 | validation: 0.22382574911968334]
	TIME [epoch: 10.3 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19850936418186893		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.19850936418186893 | validation: 0.21679494261401847]
	TIME [epoch: 10.3 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18646998057551167		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.18646998057551167 | validation: 0.19769132463261557]
	TIME [epoch: 10.3 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18170012691475562		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.18170012691475562 | validation: 0.2219027164879757]
	TIME [epoch: 10.3 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881250761187642		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.1881250761187642 | validation: 0.21352160602900092]
	TIME [epoch: 10.3 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18045003636679718		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.18045003636679718 | validation: 0.20585864341989646]
	TIME [epoch: 10.3 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18284834678700945		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.18284834678700945 | validation: 0.2134853669967523]
	TIME [epoch: 10.3 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21066729354063313		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.21066729354063313 | validation: 0.25048980129562515]
	TIME [epoch: 10.3 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22194012516402267		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.22194012516402267 | validation: 0.21780550505206223]
	TIME [epoch: 10.3 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19127380204594163		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.19127380204594163 | validation: 0.18786959288187738]
	TIME [epoch: 10.3 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17330539662427288		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.17330539662427288 | validation: 0.20666752785239978]
	TIME [epoch: 10.3 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20999565484541494		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.20999565484541494 | validation: 0.23541061966899487]
	TIME [epoch: 10.3 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2471678177634044		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.2471678177634044 | validation: 0.27147763033667666]
	TIME [epoch: 10.3 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20924503622261642		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.20924503622261642 | validation: 0.2365532961470328]
	TIME [epoch: 10.3 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19219534170299438		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.19219534170299438 | validation: 0.23968399115260183]
	TIME [epoch: 10.3 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1810324450525025		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.1810324450525025 | validation: 0.1947933267538998]
	TIME [epoch: 10.3 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17504596757399396		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.17504596757399396 | validation: 0.18621185798454437]
	TIME [epoch: 10.3 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17627592624270577		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.17627592624270577 | validation: 0.21856941500412966]
	TIME [epoch: 10.3 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.211572675768149		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.211572675768149 | validation: 0.2540276739442705]
	TIME [epoch: 10.3 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20591014434121507		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.20591014434121507 | validation: 0.19740461919353286]
	TIME [epoch: 10.3 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18005562354103807		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.18005562354103807 | validation: 0.20524757301596538]
	TIME [epoch: 10.3 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17065903946214958		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.17065903946214958 | validation: 0.23152075275685327]
	TIME [epoch: 10.3 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1845503592053771		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.1845503592053771 | validation: 0.1869444471843897]
	TIME [epoch: 10.3 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17077791791755764		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.17077791791755764 | validation: 0.21578332281096205]
	TIME [epoch: 10.3 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18610158644177577		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.18610158644177577 | validation: 0.2099998481341816]
	TIME [epoch: 10.3 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17690961586484116		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.17690961586484116 | validation: 0.22098062756700432]
	TIME [epoch: 10.3 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18121111256261846		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.18121111256261846 | validation: 0.1933844781141583]
	TIME [epoch: 10.3 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1709433899577088		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.1709433899577088 | validation: 0.21022179997568555]
	TIME [epoch: 10.3 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715544444817653		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.1715544444817653 | validation: 0.2009032071226055]
	TIME [epoch: 10.3 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18131138555808715		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.18131138555808715 | validation: 0.21573332797476455]
	TIME [epoch: 10.3 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18567129633553872		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.18567129633553872 | validation: 0.22993244131331]
	TIME [epoch: 10.3 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17275411594994142		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.17275411594994142 | validation: 0.22375159496092514]
	TIME [epoch: 10.3 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18705199668688602		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.18705199668688602 | validation: 0.24905419506506035]
	TIME [epoch: 10.3 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177458868048328		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.2177458868048328 | validation: 0.23340976497041716]
	TIME [epoch: 10.3 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19013114410462675		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.19013114410462675 | validation: 0.21256586952385648]
	TIME [epoch: 10.3 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18294062291698004		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.18294062291698004 | validation: 0.21699406549068306]
	TIME [epoch: 10.3 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1970142811766468		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.1970142811766468 | validation: 0.21797947008110208]
	TIME [epoch: 10.3 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19538246938731857		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.19538246938731857 | validation: 0.20995566347883896]
	TIME [epoch: 10.3 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1806828348874652		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.1806828348874652 | validation: 0.20883202503126252]
	TIME [epoch: 10.3 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16946704491817452		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.16946704491817452 | validation: 0.21999774019916515]
	TIME [epoch: 10.3 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1816810427212299		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.1816810427212299 | validation: 0.21765619849561943]
	TIME [epoch: 10.3 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1922398921805259		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.1922398921805259 | validation: 0.20371036256147565]
	TIME [epoch: 10.3 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16640511046163142		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.16640511046163142 | validation: 0.2118630474335915]
	TIME [epoch: 10.3 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16913835057597035		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.16913835057597035 | validation: 0.2274806367134277]
	TIME [epoch: 10.3 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17129034350533376		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.17129034350533376 | validation: 0.21038963437439984]
	TIME [epoch: 10.3 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16423465617707197		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.16423465617707197 | validation: 0.19307036048727486]
	TIME [epoch: 10.3 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17912231770364545		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.17912231770364545 | validation: 0.23266555326573182]
	TIME [epoch: 10.3 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20550953524256274		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.20550953524256274 | validation: 0.21180511127074447]
	TIME [epoch: 10.3 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679955708210454		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.1679955708210454 | validation: 0.21465810970201715]
	TIME [epoch: 10.4 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21257357605398908		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.21257357605398908 | validation: 0.24410177279346443]
	TIME [epoch: 10.3 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.23928105911216985		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.23928105911216985 | validation: 0.22530624667937033]
	TIME [epoch: 10.3 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20200594165842692		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.20200594165842692 | validation: 0.2415629186479245]
	TIME [epoch: 10.3 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.220690757349844		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.220690757349844 | validation: 0.24829073710472496]
	TIME [epoch: 10.3 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21502014088294782		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.21502014088294782 | validation: 0.22211001467607008]
	TIME [epoch: 10.3 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1924341867678949		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.1924341867678949 | validation: 0.22217862790700327]
	TIME [epoch: 10.3 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2214969610568792		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.2214969610568792 | validation: 0.2615913260247616]
	TIME [epoch: 10.3 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21609844052791236		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.21609844052791236 | validation: 0.2014473745860186]
	TIME [epoch: 10.3 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751297733041673		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.1751297733041673 | validation: 0.22356109309972882]
	TIME [epoch: 10.3 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1761621560666074		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.1761621560666074 | validation: 0.23639853247586737]
	TIME [epoch: 10.3 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16951293149541014		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.16951293149541014 | validation: 0.20200676168629528]
	TIME [epoch: 10.3 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17591217123665898		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.17591217123665898 | validation: 0.23868245887609443]
	TIME [epoch: 10.4 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17970042569235034		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.17970042569235034 | validation: 0.24181529710192287]
	TIME [epoch: 10.3 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1777841827968431		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.1777841827968431 | validation: 0.20533364845776803]
	TIME [epoch: 10.3 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17051409353357988		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.17051409353357988 | validation: 0.2215711026975416]
	TIME [epoch: 10.3 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17776749699437852		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.17776749699437852 | validation: 0.20054056359034345]
	TIME [epoch: 10.3 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.174901260680183		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.174901260680183 | validation: 0.2122951676527285]
	TIME [epoch: 10.3 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17592229448665203		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.17592229448665203 | validation: 0.18713305774560118]
	TIME [epoch: 10.3 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17526291165209346		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.17526291165209346 | validation: 0.20609298572845056]
	TIME [epoch: 10.3 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16924212300580072		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.16924212300580072 | validation: 0.2386032645686646]
	TIME [epoch: 10.3 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20040359938962876		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.20040359938962876 | validation: 0.21389094088755767]
	TIME [epoch: 10.3 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17824381549578866		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.17824381549578866 | validation: 0.1978000318049147]
	TIME [epoch: 10.3 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17012111941800054		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.17012111941800054 | validation: 0.20056047153076606]
	TIME [epoch: 10.3 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745527370101024		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.1745527370101024 | validation: 0.2013239434018685]
	TIME [epoch: 10.3 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17373800756689356		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.17373800756689356 | validation: 0.1878318250289991]
	TIME [epoch: 10.3 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1757546751821834		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.1757546751821834 | validation: 0.20546671237689473]
	TIME [epoch: 10.3 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694179378619896		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.18694179378619896 | validation: 0.21885211803886612]
	TIME [epoch: 10.3 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17745187059447148		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.17745187059447148 | validation: 0.18473785323147263]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_830.pth
	Model improved!!!
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18686426124724936		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.18686426124724936 | validation: 0.21144453345479924]
	TIME [epoch: 10.3 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745825786051262		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.1745825786051262 | validation: 0.2032119473261969]
	TIME [epoch: 10.3 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16733888431242747		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.16733888431242747 | validation: 0.22196209634741]
	TIME [epoch: 10.3 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17299959590748612		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.17299959590748612 | validation: 0.23728138004508828]
	TIME [epoch: 10.3 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19311305530019662		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.19311305530019662 | validation: 0.21719094512013878]
	TIME [epoch: 10.3 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18989966944051417		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.18989966944051417 | validation: 0.23867019572937223]
	TIME [epoch: 10.3 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18699514361814756		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.18699514361814756 | validation: 0.1987224794939047]
	TIME [epoch: 10.3 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17554194253734695		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.17554194253734695 | validation: 0.21716996027776397]
	TIME [epoch: 10.3 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16629747265357553		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.16629747265357553 | validation: 0.19235323627670275]
	TIME [epoch: 10.3 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1763162087808952		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.1763162087808952 | validation: 0.21739393518809982]
	TIME [epoch: 10.3 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20516570478673235		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.20516570478673235 | validation: 0.23645264419631487]
	TIME [epoch: 10.3 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19909268961487356		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.19909268961487356 | validation: 0.20919608235325327]
	TIME [epoch: 10.3 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20227676625130292		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.20227676625130292 | validation: 0.20571605878172097]
	TIME [epoch: 10.3 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17476104435771153		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.17476104435771153 | validation: 0.20207411984780088]
	TIME [epoch: 10.3 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717470460364463		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.1717470460364463 | validation: 0.19516517664909838]
	TIME [epoch: 10.3 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16637295746016906		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.16637295746016906 | validation: 0.20810890448143693]
	TIME [epoch: 10.3 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17197957809974054		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.17197957809974054 | validation: 0.21364904542208396]
	TIME [epoch: 10.3 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17346481697302318		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.17346481697302318 | validation: 0.22044782376921895]
	TIME [epoch: 10.3 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18153068628120825		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.18153068628120825 | validation: 0.2153730830638866]
	TIME [epoch: 10.3 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1984503685743958		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.1984503685743958 | validation: 0.20449913997560606]
	TIME [epoch: 10.3 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17839872370206358		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.17839872370206358 | validation: 0.2338488568306877]
	TIME [epoch: 10.3 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17351679646057055		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.17351679646057055 | validation: 0.197809293148159]
	TIME [epoch: 10.3 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18102661068866233		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.18102661068866233 | validation: 0.2111148439509131]
	TIME [epoch: 10.3 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676120392135911		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.1676120392135911 | validation: 0.1877399980131641]
	TIME [epoch: 10.3 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17000342325392598		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.17000342325392598 | validation: 0.20419385234834223]
	TIME [epoch: 10.3 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17941436637415037		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.17941436637415037 | validation: 0.19664133331425362]
	TIME [epoch: 10.3 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17988078823269976		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.17988078823269976 | validation: 0.20886410546102052]
	TIME [epoch: 10.3 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17919197566805078		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.17919197566805078 | validation: 0.21754889476356912]
	TIME [epoch: 10.3 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1849218436579299		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.1849218436579299 | validation: 0.2192068570659559]
	TIME [epoch: 10.3 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785646977889696		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.1785646977889696 | validation: 0.19029261350674556]
	TIME [epoch: 10.3 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714782400351194		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.16714782400351194 | validation: 0.20502358182973343]
	TIME [epoch: 10.3 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751745924326978		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.1751745924326978 | validation: 0.19858433333053702]
	TIME [epoch: 10.3 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18873211738591097		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.18873211738591097 | validation: 0.21838405708151862]
	TIME [epoch: 10.3 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19387378587736273		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.19387378587736273 | validation: 0.21668081306681433]
	TIME [epoch: 10.3 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17961796285243417		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.17961796285243417 | validation: 0.21141224911093404]
	TIME [epoch: 10.3 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17491513886019835		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.17491513886019835 | validation: 0.20698772417796057]
	TIME [epoch: 10.3 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19736823031429962		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.19736823031429962 | validation: 0.21664359610145975]
	TIME [epoch: 10.3 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17753392480684957		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.17753392480684957 | validation: 0.203058541459215]
	TIME [epoch: 10.3 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742783392120363		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.1742783392120363 | validation: 0.19738218657734355]
	TIME [epoch: 10.3 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17134858755443155		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.17134858755443155 | validation: 0.19140218861285405]
	TIME [epoch: 10.3 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17623853350396043		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.17623853350396043 | validation: 0.21147454955605083]
	TIME [epoch: 10.4 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17095387697688375		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.17095387697688375 | validation: 0.20273552579113285]
	TIME [epoch: 10.3 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16533650329285854		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.16533650329285854 | validation: 0.19939850747484286]
	TIME [epoch: 10.3 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671941399816447		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.1671941399816447 | validation: 0.19203317130391623]
	TIME [epoch: 10.3 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16713576754587098		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.16713576754587098 | validation: 0.19440632655118759]
	TIME [epoch: 10.4 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1713954750028445		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.1713954750028445 | validation: 0.18697714591710238]
	TIME [epoch: 10.3 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17108739853096389		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.17108739853096389 | validation: 0.17878128864865991]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_877.pth
	Model improved!!!
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16452371534897803		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.16452371534897803 | validation: 0.19689246463796173]
	TIME [epoch: 10.3 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18014033269517898		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.18014033269517898 | validation: 0.21696104421914292]
	TIME [epoch: 10.3 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19892714685512863		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.19892714685512863 | validation: 0.22038520736943715]
	TIME [epoch: 10.3 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18992318160186467		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.18992318160186467 | validation: 0.20362470623486584]
	TIME [epoch: 10.3 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17313538743300733		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.17313538743300733 | validation: 0.194965772207658]
	TIME [epoch: 10.3 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16153131854053943		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.16153131854053943 | validation: 0.17912140934569698]
	TIME [epoch: 10.3 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16665822414605544		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.16665822414605544 | validation: 0.19568025329171057]
	TIME [epoch: 10.3 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17539411305902103		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.17539411305902103 | validation: 0.19608590265413817]
	TIME [epoch: 10.3 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17554491284727208		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.17554491284727208 | validation: 0.2118256126720214]
	TIME [epoch: 10.3 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18182921217824868		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.18182921217824868 | validation: 0.2017756657811622]
	TIME [epoch: 10.3 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17319777996873673		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.17319777996873673 | validation: 0.18341045900634725]
	TIME [epoch: 10.3 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16837826032963754		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.16837826032963754 | validation: 0.21259709212895977]
	TIME [epoch: 10.3 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16958956746818563		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.16958956746818563 | validation: 0.18603313573100302]
	TIME [epoch: 10.3 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17026958338049292		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.17026958338049292 | validation: 0.19206579427870388]
	TIME [epoch: 10.3 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16990185020705778		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.16990185020705778 | validation: 0.1707327017132255]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240217_161441/states/model_tr_study6_892.pth
	Model improved!!!
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17066313983769638		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.17066313983769638 | validation: 0.18950499869004397]
	TIME [epoch: 10.3 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18908131098834424		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.18908131098834424 | validation: 0.22974335300072368]
	TIME [epoch: 10.3 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.20414050563055844		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.20414050563055844 | validation: 0.2085032310909552]
	TIME [epoch: 10.3 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19536604041613065		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.19536604041613065 | validation: 0.2257467898705352]
	TIME [epoch: 10.3 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.21794260593358236		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.21794260593358236 | validation: 0.23090582776126836]
	TIME [epoch: 10.3 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.22710026440890901		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.22710026440890901 | validation: 0.2397211674104048]
	TIME [epoch: 10.3 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19339754881613663		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.19339754881613663 | validation: 0.21202642402648053]
	TIME [epoch: 10.3 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18212068161623218		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.18212068161623218 | validation: 0.20568583110867644]
	TIME [epoch: 10.3 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17168389876328233		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.17168389876328233 | validation: 0.2113443497106146]
	TIME [epoch: 10.3 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18499104561464372		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.18499104561464372 | validation: 0.22643998629864479]
	TIME [epoch: 10.3 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.19194396117847384		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.19194396117847384 | validation: 0.20372786835858367]
	TIME [epoch: 10.3 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16798156133358022		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.16798156133358022 | validation: 0.2001301112355229]
	TIME [epoch: 10.3 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288930636854788		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.17288930636854788 | validation: 0.18299339182239563]
	TIME [epoch: 10.3 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16134532068071678		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.16134532068071678 | validation: 0.18450432901580371]
	TIME [epoch: 10.3 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16455077309174584		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.16455077309174584 | validation: 0.20325124972398156]
	TIME [epoch: 10.3 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16642142674289004		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.16642142674289004 | validation: 0.1956011877639403]
	TIME [epoch: 10.3 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17066945547526333		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.17066945547526333 | validation: 0.1978054424468081]
	TIME [epoch: 10.3 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1817134517278009		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.1817134517278009 | validation: 0.19351124409270395]
	TIME [epoch: 10.3 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1826342034563797		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.1826342034563797 | validation: 0.19870235220964566]
	TIME [epoch: 10.3 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749830993821484		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.1749830993821484 | validation: 0.21124918157434508]
	TIME [epoch: 10.3 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18790158147958644		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.18790158147958644 | validation: 0.19338927998793076]
	TIME [epoch: 10.3 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732251367025346		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.1732251367025346 | validation: 0.1871024254330676]
	TIME [epoch: 10.3 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619825176759088		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.1619825176759088 | validation: 0.20113318121724924]
	TIME [epoch: 10.3 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16697034871985017		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.16697034871985017 | validation: 0.19201493575744266]
	TIME [epoch: 10.3 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16420666033321352		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.16420666033321352 | validation: 0.19407296176906974]
	TIME [epoch: 10.3 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15956699407516622		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.15956699407516622 | validation: 0.19363510606711848]
	TIME [epoch: 10.3 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15647410089311645		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.15647410089311645 | validation: 0.19151180143420476]
	TIME [epoch: 10.3 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16373882229949344		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.16373882229949344 | validation: 0.1977900671985414]
	TIME [epoch: 10.3 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18247035458356856		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.18247035458356856 | validation: 0.2050685745981764]
	TIME [epoch: 10.3 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17029869777987452		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.17029869777987452 | validation: 0.1894364525078057]
	TIME [epoch: 10.3 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16964208917271428		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.16964208917271428 | validation: 0.1950318051325212]
	TIME [epoch: 10.3 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17015094574214254		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.17015094574214254 | validation: 0.2160518997765746]
	TIME [epoch: 10.3 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17055941955019294		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.17055941955019294 | validation: 0.19431345641230344]
	TIME [epoch: 10.3 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225874028793325		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.16225874028793325 | validation: 0.1937354451588971]
	TIME [epoch: 10.3 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16032597699255854		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.16032597699255854 | validation: 0.2071331808985086]
	TIME [epoch: 10.3 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16439746133159355		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.16439746133159355 | validation: 0.19729308158110315]
	TIME [epoch: 10.3 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614969180348603		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.1614969180348603 | validation: 0.20214897099320492]
	TIME [epoch: 10.3 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17611192087072908		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.17611192087072908 | validation: 0.2076008684437121]
	TIME [epoch: 10.3 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17411362297104466		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.17411362297104466 | validation: 0.19929058883208373]
	TIME [epoch: 10.3 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16681164964869635		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.16681164964869635 | validation: 0.20080557463652404]
	TIME [epoch: 10.3 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16525690928729092		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.16525690928729092 | validation: 0.19932261581432964]
	TIME [epoch: 10.3 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1666504785912234		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.1666504785912234 | validation: 0.19475528143451243]
	TIME [epoch: 10.3 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708392804577045		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.1708392804577045 | validation: 0.19218098505931458]
	TIME [epoch: 10.3 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17048272991490798		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.17048272991490798 | validation: 0.19086563368274415]
	TIME [epoch: 10.3 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15713021527639198		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.15713021527639198 | validation: 0.187722458823002]
	TIME [epoch: 10.3 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17077670442763268		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.17077670442763268 | validation: 0.1879298232270574]
	TIME [epoch: 10.3 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17069077691001522		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.17069077691001522 | validation: 0.2071381729298394]
	TIME [epoch: 10.3 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16312111342904143		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.16312111342904143 | validation: 0.18260285542312446]
	TIME [epoch: 10.3 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643695157241984		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.1643695157241984 | validation: 0.18392706928193367]
	TIME [epoch: 10.3 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15575764326051306		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.15575764326051306 | validation: 0.1805734374200326]
	TIME [epoch: 10.3 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16601154044836344		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.16601154044836344 | validation: 0.194028403898153]
	TIME [epoch: 10.3 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17004421307877546		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.17004421307877546 | validation: 0.19871062054426655]
	TIME [epoch: 10.3 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16846069251232149		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.16846069251232149 | validation: 0.22494209899235018]
	TIME [epoch: 10.3 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17437824786329115		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.17437824786329115 | validation: 0.23598849421964538]
	TIME [epoch: 10.3 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1820303378074469		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.1820303378074469 | validation: 0.20987075139102615]
	TIME [epoch: 10.3 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16727111539041767		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.16727111539041767 | validation: 0.1888310493507219]
	TIME [epoch: 10.3 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16468720151002586		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.16468720151002586 | validation: 0.1913272338838749]
	TIME [epoch: 10.3 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1713497512625636		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.1713497512625636 | validation: 0.2125076988079236]
	TIME [epoch: 10.3 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17523032396804605		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.17523032396804605 | validation: 0.19096073364026248]
	TIME [epoch: 10.3 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16661938992247527		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.16661938992247527 | validation: 0.20459459936563879]
	TIME [epoch: 10.3 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17422009280030398		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.17422009280030398 | validation: 0.1979573094540966]
	TIME [epoch: 10.4 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17919153539545143		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.17919153539545143 | validation: 0.20556568276238238]
	TIME [epoch: 10.3 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18718168907766256		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.18718168907766256 | validation: 0.22159567114691697]
	TIME [epoch: 10.3 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785189702911166		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.1785189702911166 | validation: 0.18888132206245703]
	TIME [epoch: 10.3 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17325143950910138		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.17325143950910138 | validation: 0.20864554429313445]
	TIME [epoch: 10.3 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18130039076529775		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.18130039076529775 | validation: 0.20726833295257902]
	TIME [epoch: 10.3 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17656103098594567		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.17656103098594567 | validation: 0.21044894844615308]
	TIME [epoch: 10.3 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16741638374704657		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.16741638374704657 | validation: 0.20021212382271236]
	TIME [epoch: 10.3 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554362934420323		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.1554362934420323 | validation: 0.18458822027939328]
	TIME [epoch: 10.3 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600085052362618		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.1600085052362618 | validation: 0.17608074132265392]
	TIME [epoch: 10.3 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1649514776981417		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.1649514776981417 | validation: 0.1847612687318232]
	TIME [epoch: 10.3 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16322044342761016		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.16322044342761016 | validation: 0.18878993627401877]
	TIME [epoch: 10.3 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16129456643063728		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.16129456643063728 | validation: 0.18967063019782224]
	TIME [epoch: 10.3 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569359886407991		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.1569359886407991 | validation: 0.18598192604753158]
	TIME [epoch: 10.3 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.159278007648442		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.159278007648442 | validation: 0.18197708416973982]
	TIME [epoch: 10.3 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16213524833759818		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.16213524833759818 | validation: 0.1717968125771397]
	TIME [epoch: 10.3 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16095374496140014		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.16095374496140014 | validation: 0.1776326399195499]
	TIME [epoch: 10.3 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16514340487825793		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.16514340487825793 | validation: 0.18136858801899375]
	TIME [epoch: 10.3 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16564548995527129		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.16564548995527129 | validation: 0.18828999118199435]
	TIME [epoch: 10.3 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714206643513094		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.16714206643513094 | validation: 0.18917018947653705]
	TIME [epoch: 10.3 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16132519374409107		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.16132519374409107 | validation: 0.18159402835867064]
	TIME [epoch: 10.3 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15959042999515846		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.15959042999515846 | validation: 0.19900903978541068]
	TIME [epoch: 10.3 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17257062865399445		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.17257062865399445 | validation: 0.1864524502981003]
	TIME [epoch: 10.3 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771264002104082		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.1771264002104082 | validation: 0.19050843861336936]
	TIME [epoch: 10.3 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1740146737271092		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.1740146737271092 | validation: 0.19113267091898137]
	TIME [epoch: 10.3 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16383755407453401		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.16383755407453401 | validation: 0.1844487300561978]
	TIME [epoch: 10.3 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16711834426674463		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.16711834426674463 | validation: 0.21207052229188478]
	TIME [epoch: 10.3 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16804967774664434		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.16804967774664434 | validation: 0.20477298268729513]
	TIME [epoch: 10.3 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.164013629312653		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.164013629312653 | validation: 0.20987115800008974]
	TIME [epoch: 10.3 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.178580354968768		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.178580354968768 | validation: 0.21479843208718577]
	TIME [epoch: 10.3 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.18338505402914085		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.18338505402914085 | validation: 0.23544562150614234]
	TIME [epoch: 10.3 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1863839244549395		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.1863839244549395 | validation: 0.2217897443294431]
	TIME [epoch: 10.3 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.179609968108528		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.179609968108528 | validation: 0.18878153170918652]
	TIME [epoch: 10.3 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17837957986882355		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.17837957986882355 | validation: 0.20595568543825762]
	TIME [epoch: 10.3 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17251277848539504		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.17251277848539504 | validation: 0.20801253883475704]
	TIME [epoch: 10.3 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16205333363261118		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.16205333363261118 | validation: 0.18985341084401916]
	TIME [epoch: 10.3 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17974254670983444		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.17974254670983444 | validation: 0.18512823636482942]
	TIME [epoch: 10.4 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17310030540139126		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.17310030540139126 | validation: 0.20360266071969157]
	TIME [epoch: 10.3 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17822207566175663		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.17822207566175663 | validation: 0.19058876745219902]
	TIME [epoch: 10.3 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805539405150665		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.1805539405150665 | validation: 0.18537001663352864]
	TIME [epoch: 10.3 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16614156530903804		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.16614156530903804 | validation: 0.19247317341948836]
	TIME [epoch: 10.3 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15844583256703895		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.15844583256703895 | validation: 0.1893444078030012]
	TIME [epoch: 10.3 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646618240962554		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.15646618240962554 | validation: 0.18557975752683567]
	TIME [epoch: 10.3 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628760001378095		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.1628760001378095 | validation: 0.21098282810933014]
	TIME [epoch: 10.3 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16413327756292737		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.16413327756292737 | validation: 0.17709062062763026]
	TIME [epoch: 10.3 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16461767027682417		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.16461767027682417 | validation: 0.18295600757190147]
	TIME [epoch: 10.3 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.16674165072538819		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.16674165072538819 | validation: 0.1955669341679696]
	TIME [epoch: 10.3 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.17133628983465565		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.17133628983465565 | validation: 0.19653856905789918]
	TIME [epoch: 10.3 sec]
Finished training in 10423.999 seconds.
