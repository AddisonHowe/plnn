Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 30611230

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.188587658660612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.188587658660612 | validation: 9.702988732753298]
	TIME [epoch: 71.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.957052375405343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.957052375405343 | validation: 9.342957053464048]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.617015755960704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.617015755960704 | validation: 8.848896466223401]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.287909262731436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.287909262731436 | validation: 8.799256216228288]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.077546675444676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.077546675444676 | validation: 8.383992571223015]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.804648962369962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.804648962369962 | validation: 7.941819402062983]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.335294687787446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.335294687787446 | validation: 7.278121191386265]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.808520785389311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.808520785389311 | validation: 7.076936411328918]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.602649872065631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.602649872065631 | validation: 6.7520489172622185]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.484218396054866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.484218396054866 | validation: 6.766040477861325]
	TIME [epoch: 10.3 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4463399094756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4463399094756 | validation: 6.786912582800048]
	TIME [epoch: 10.3 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.485545767493195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.485545767493195 | validation: 6.7537479595327]
	TIME [epoch: 10.3 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.455381530166726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.455381530166726 | validation: 6.69209907946785]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.5317764919914385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5317764919914385 | validation: 6.664131498173393]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.426221056871559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.426221056871559 | validation: 6.624814169141437]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.360316107349148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.360316107349148 | validation: 6.57490474367673]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.462807048275136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.462807048275136 | validation: 6.559916021750076]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.340248293594155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.340248293594155 | validation: 6.539704287529921]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3376188540737175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3376188540737175 | validation: 6.681933921557664]
	TIME [epoch: 10.3 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.416024740463021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.416024740463021 | validation: 6.5635796879063255]
	TIME [epoch: 10.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.273790969906061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.273790969906061 | validation: 6.767217752446426]
	TIME [epoch: 10.3 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.329088532028775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.329088532028775 | validation: 6.444501464803211]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.455049541766627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.455049541766627 | validation: 6.732888915074077]
	TIME [epoch: 10.3 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.333499342361337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.333499342361337 | validation: 6.582695157615526]
	TIME [epoch: 10.3 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.294957327672077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.294957327672077 | validation: 6.633549497212611]
	TIME [epoch: 10.3 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.317700905844575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.317700905844575 | validation: 6.530921697151158]
	TIME [epoch: 10.3 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.259802449072369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.259802449072369 | validation: 6.511511909708483]
	TIME [epoch: 10.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.245462600718607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.245462600718607 | validation: 6.53766717736707]
	TIME [epoch: 10.3 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.288002763196275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.288002763196275 | validation: 6.639390012409559]
	TIME [epoch: 10.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.245319029027044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.245319029027044 | validation: 6.455490898743363]
	TIME [epoch: 10.3 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.498891054468034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.498891054468034 | validation: 6.629606716640652]
	TIME [epoch: 10.3 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.298534953293089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.298534953293089 | validation: 6.575266070425357]
	TIME [epoch: 10.3 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.236125381045838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.236125381045838 | validation: 6.482451155369281]
	TIME [epoch: 10.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.253093013995973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.253093013995973 | validation: 6.570305677898086]
	TIME [epoch: 10.3 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.263464785951906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.263464785951906 | validation: 6.466269560494825]
	TIME [epoch: 10.3 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.171611185406008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.171611185406008 | validation: 6.673938816019404]
	TIME [epoch: 10.3 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.340516868583611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.340516868583611 | validation: 6.618277201354263]
	TIME [epoch: 10.3 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.381137738176569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.381137738176569 | validation: 6.35921134145402]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.21261184197575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.21261184197575 | validation: 6.333794119450894]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.157752116675846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.157752116675846 | validation: 6.526128593432337]
	TIME [epoch: 10.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.103791382856068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.103791382856068 | validation: 6.044323585793713]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.176341577274232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.176341577274232 | validation: 6.177666877056732]
	TIME [epoch: 10.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.816942563950624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.816942563950624 | validation: 5.670335166323565]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.401665963746807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.401665963746807 | validation: 7.668273530543677]
	TIME [epoch: 10.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.250488494013842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.250488494013842 | validation: 3.4282037254597357]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.883324361543788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.883324361543788 | validation: 3.4629668866236116]
	TIME [epoch: 10.2 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.258401205948823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.258401205948823 | validation: 3.900377473015167]
	TIME [epoch: 10.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.349523811231339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.349523811231339 | validation: 3.421390791927988]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.032158163891616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.032158163891616 | validation: 3.5211617653266423]
	TIME [epoch: 10.3 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5311100810306995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5311100810306995 | validation: 3.352399348183691]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6500207480034588		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 3.6500207480034588 | validation: 4.163805198638235]
	TIME [epoch: 10.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9361563160128528		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 3.9361563160128528 | validation: 3.36603310490518]
	TIME [epoch: 10.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.369323605239326		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 3.369323605239326 | validation: 3.4489614452138015]
	TIME [epoch: 10.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.831869174712159		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 2.831869174712159 | validation: 2.855898714863167]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.63711205275657		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 2.63711205275657 | validation: 1.7011797425031423]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.169271913410575		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 2.169271913410575 | validation: 2.2653393384086566]
	TIME [epoch: 10.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8288534401039582		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 2.8288534401039582 | validation: 4.656426272053554]
	TIME [epoch: 10.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1058305395532004		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 3.1058305395532004 | validation: 3.2332806032250008]
	TIME [epoch: 10.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0771502644212765		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 4.0771502644212765 | validation: 7.003749620526552]
	TIME [epoch: 10.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.955876680205849		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 4.955876680205849 | validation: 2.7770575731053317]
	TIME [epoch: 10.3 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2007269244984187		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 3.2007269244984187 | validation: 3.7596824795421777]
	TIME [epoch: 10.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4126037036601446		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 3.4126037036601446 | validation: 2.6936883669805036]
	TIME [epoch: 10.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7693814973921547		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 3.7693814973921547 | validation: 3.408369476287736]
	TIME [epoch: 10.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.408437440464339		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 3.408437440464339 | validation: 3.081844575153425]
	TIME [epoch: 10.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.143731650433376		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 3.143731650433376 | validation: 3.757537037455478]
	TIME [epoch: 10.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.326417625224098		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 4.326417625224098 | validation: 3.5222878970030957]
	TIME [epoch: 10.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9944129955742946		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 3.9944129955742946 | validation: 2.979245987457142]
	TIME [epoch: 10.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8202481338700793		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 3.8202481338700793 | validation: 2.876122603664162]
	TIME [epoch: 10.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5517393973179843		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 3.5517393973179843 | validation: 3.0682491635646203]
	TIME [epoch: 10.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3759564303384813		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 3.3759564303384813 | validation: 4.466622269739902]
	TIME [epoch: 10.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.085254415619332		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 4.085254415619332 | validation: 3.04447632749681]
	TIME [epoch: 10.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.408302858692168		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 3.408302858692168 | validation: 2.8613758988325504]
	TIME [epoch: 10.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5551799655570457		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 3.5551799655570457 | validation: 3.13877538036463]
	TIME [epoch: 10.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3305384113068994		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 3.3305384113068994 | validation: 2.8904844242025085]
	TIME [epoch: 10.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2310260502114354		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 3.2310260502114354 | validation: 2.8085444552156447]
	TIME [epoch: 10.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.222006913414532		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 3.222006913414532 | validation: 2.8341297377288073]
	TIME [epoch: 10.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.190606358105927		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 3.190606358105927 | validation: 2.896964149225163]
	TIME [epoch: 10.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1526025677386222		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 3.1526025677386222 | validation: 3.311313379375373]
	TIME [epoch: 10.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.945618502924275		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 5.945618502924275 | validation: 5.829423875052713]
	TIME [epoch: 10.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.477495830047088		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 6.477495830047088 | validation: 5.681665509266584]
	TIME [epoch: 10.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.428225631027308		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 6.428225631027308 | validation: 5.587003770710567]
	TIME [epoch: 10.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.324880963633305		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 6.324880963633305 | validation: 5.511973107588447]
	TIME [epoch: 10.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.17387623205321		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 6.17387623205321 | validation: 5.3692377437149625]
	TIME [epoch: 10.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.003590852643325		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 6.003590852643325 | validation: 5.665412680061417]
	TIME [epoch: 10.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.578726820089353		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 5.578726820089353 | validation: 5.1350396488623336]
	TIME [epoch: 10.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.557889298381695		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 5.557889298381695 | validation: 5.405742228211968]
	TIME [epoch: 10.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.874686721210116		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 5.874686721210116 | validation: 4.845028297051227]
	TIME [epoch: 10.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.82449924312425		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 5.82449924312425 | validation: 6.295763330844813]
	TIME [epoch: 10.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.967943989735292		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 6.967943989735292 | validation: 7.055693693548193]
	TIME [epoch: 10.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.212773985376461		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 7.212773985376461 | validation: 6.294353996650612]
	TIME [epoch: 10.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.25160105090958		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 6.25160105090958 | validation: 5.415970508425025]
	TIME [epoch: 10.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.006783899989377		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 6.006783899989377 | validation: 5.230582649410741]
	TIME [epoch: 10.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.618217488975669		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 6.618217488975669 | validation: 6.3188816523645235]
	TIME [epoch: 10.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.208198895371389		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 6.208198895371389 | validation: 5.846206075239975]
	TIME [epoch: 10.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.435781482809162		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 6.435781482809162 | validation: 7.795094431896829]
	TIME [epoch: 10.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.552916704651182		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 6.552916704651182 | validation: 5.024021403809693]
	TIME [epoch: 10.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.628517848289595		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.628517848289595 | validation: 5.085399299035774]
	TIME [epoch: 10.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.286354071575709		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 6.286354071575709 | validation: 5.13428289268739]
	TIME [epoch: 10.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.731704020177007		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 5.731704020177007 | validation: 5.238593407200815]
	TIME [epoch: 10.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7861914759105595		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 5.7861914759105595 | validation: 5.5308747094335855]
	TIME [epoch: 10.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.059267495187795		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 6.059267495187795 | validation: 5.653037628290092]
	TIME [epoch: 10.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.119908331310814		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 8.119908331310814 | validation: 9.01103917503093]
	TIME [epoch: 10.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.104480304217152		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 9.104480304217152 | validation: 9.09604646795401]
	TIME [epoch: 10.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.509387128028784		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 8.509387128028784 | validation: 6.556366776762802]
	TIME [epoch: 10.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.97858579529411		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 6.97858579529411 | validation: 5.683470046497521]
	TIME [epoch: 10.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3369302298302586		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 6.3369302298302586 | validation: 5.861291856575454]
	TIME [epoch: 10.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.962765501997263		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 5.962765501997263 | validation: 5.55919764941553]
	TIME [epoch: 10.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.086633739890912		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 6.086633739890912 | validation: 6.312648103422969]
	TIME [epoch: 10.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.122552455798582		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 6.122552455798582 | validation: 5.187126297794264]
	TIME [epoch: 10.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.63810268253142		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 5.63810268253142 | validation: 5.228192940053487]
	TIME [epoch: 10.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.607118100607662		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 5.607118100607662 | validation: 4.823660443858751]
	TIME [epoch: 10.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.321249056920482		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 5.321249056920482 | validation: 4.3293244510949]
	TIME [epoch: 10.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.526947110555997		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 4.526947110555997 | validation: 3.1947688698723136]
	TIME [epoch: 10.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.830071345756087		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 4.830071345756087 | validation: 6.858370923606978]
	TIME [epoch: 10.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.822190474420142		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 6.822190474420142 | validation: 6.612410802682041]
	TIME [epoch: 10.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.003824077268407		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 5.003824077268407 | validation: 4.043337374505884]
	TIME [epoch: 10.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.249330713867584		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 4.249330713867584 | validation: 3.435297229098754]
	TIME [epoch: 10.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.664017507975433		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 4.664017507975433 | validation: 4.392056005570077]
	TIME [epoch: 10.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.474177921112946		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 4.474177921112946 | validation: 3.7126127032142158]
	TIME [epoch: 10.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.277872604265712		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 4.277872604265712 | validation: 3.516233947687504]
	TIME [epoch: 10.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.996689167475459		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 3.996689167475459 | validation: 3.3330103797929906]
	TIME [epoch: 10.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.105792459773067		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 4.105792459773067 | validation: 3.725348852902945]
	TIME [epoch: 10.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.099065362876031		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 4.099065362876031 | validation: 3.137681443197697]
	TIME [epoch: 10.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.703661280077506		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 4.703661280077506 | validation: 6.390646959428399]
	TIME [epoch: 10.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.66354618292322		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 6.66354618292322 | validation: 5.388259027999984]
	TIME [epoch: 10.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.572115920056167		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 4.572115920056167 | validation: 3.248821069112172]
	TIME [epoch: 10.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9076156863503515		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 3.9076156863503515 | validation: 3.3543133182319496]
	TIME [epoch: 10.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.325697916248137		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 4.325697916248137 | validation: 3.1760039328384786]
	TIME [epoch: 10.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.077648811816352		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 4.077648811816352 | validation: 3.3711035147641573]
	TIME [epoch: 10.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.991832289982876		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 3.991832289982876 | validation: 3.386842068088887]
	TIME [epoch: 10.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9946853754883307		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 3.9946853754883307 | validation: 3.103765595431329]
	TIME [epoch: 10.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.243363402490161		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 4.243363402490161 | validation: 3.3590529520540553]
	TIME [epoch: 10.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.842846374889058		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 3.842846374889058 | validation: 3.240583039278117]
	TIME [epoch: 10.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6202879063359674		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 3.6202879063359674 | validation: 2.9860942989634918]
	TIME [epoch: 10.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.454416601291664		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 5.454416601291664 | validation: 6.70557499553129]
	TIME [epoch: 10.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.8620421636155315		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 7.8620421636155315 | validation: 7.815793416042076]
	TIME [epoch: 10.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.814713144520465		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 6.814713144520465 | validation: 4.992616002192515]
	TIME [epoch: 10.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.089899861962204		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 5.089899861962204 | validation: 3.593464496974448]
	TIME [epoch: 10.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3135903067328862		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 3.3135903067328862 | validation: 3.85853205920164]
	TIME [epoch: 10.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.600519694821345		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 3.600519694821345 | validation: 5.2656570687434225]
	TIME [epoch: 10.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.993385148664113		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 6.993385148664113 | validation: 5.446329919201214]
	TIME [epoch: 10.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.969987798490931		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 5.969987798490931 | validation: 5.04320368736819]
	TIME [epoch: 10.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.712614498832958		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 5.712614498832958 | validation: 5.710398934192031]
	TIME [epoch: 10.3 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.788675155811061		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 4.788675155811061 | validation: 4.428693151556538]
	TIME [epoch: 10.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9545698036239374		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 3.9545698036239374 | validation: 2.650637944850828]
	TIME [epoch: 10.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0664689859225276		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 3.0664689859225276 | validation: 2.73110421244645]
	TIME [epoch: 10.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6284643833231898		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 3.6284643833231898 | validation: 2.687855264340659]
	TIME [epoch: 10.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3203116385834077		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 3.3203116385834077 | validation: 3.598615841863483]
	TIME [epoch: 10.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.804613125596595		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 3.804613125596595 | validation: 3.1016937149969]
	TIME [epoch: 10.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.55836990866581		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 3.55836990866581 | validation: 3.065564971473563]
	TIME [epoch: 10.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.649734815263385		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 3.649734815263385 | validation: 3.066719909221246]
	TIME [epoch: 10.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8033441644252037		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 3.8033441644252037 | validation: 3.111010712663605]
	TIME [epoch: 10.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5950405927040117		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 3.5950405927040117 | validation: 3.188119782114419]
	TIME [epoch: 10.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5192118598297513		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 3.5192118598297513 | validation: 2.991757478715606]
	TIME [epoch: 10.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.237705229096866		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 4.237705229096866 | validation: 2.8278568360982757]
	TIME [epoch: 10.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2643425654948843		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 3.2643425654948843 | validation: 3.837095726975982]
	TIME [epoch: 10.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.039058712069833		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 4.039058712069833 | validation: 2.496504087723665]
	TIME [epoch: 10.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1966826985153953		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 3.1966826985153953 | validation: 2.395751237698697]
	TIME [epoch: 10.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0329796661765345		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 3.0329796661765345 | validation: 3.0560049639978786]
	TIME [epoch: 10.3 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.283393569877719		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 3.283393569877719 | validation: 2.5320297853364426]
	TIME [epoch: 10.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2351093169248784		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 3.2351093169248784 | validation: 3.0911611223813256]
	TIME [epoch: 10.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.206024804254806		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 4.206024804254806 | validation: 2.7238278298587013]
	TIME [epoch: 10.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.819849242215853		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 2.819849242215853 | validation: 2.3315838195451817]
	TIME [epoch: 10.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.89628208483449		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 2.89628208483449 | validation: 3.16498594673347]
	TIME [epoch: 10.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.494439622016598		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 4.494439622016598 | validation: 4.056210142243822]
	TIME [epoch: 10.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.927489094773134		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 3.927489094773134 | validation: 3.0604745341598214]
	TIME [epoch: 10.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5612505525971754		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 3.5612505525971754 | validation: 4.250633475716159]
	TIME [epoch: 10.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9676253000032866		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 3.9676253000032866 | validation: 3.019161590230486]
	TIME [epoch: 10.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.024867058038943		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 3.024867058038943 | validation: 3.639687919039374]
	TIME [epoch: 10.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.215574850148849		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 3.215574850148849 | validation: 2.56634029235002]
	TIME [epoch: 10.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0288481175400785		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 3.0288481175400785 | validation: 4.751662275554932]
	TIME [epoch: 10.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.350588762634713		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 5.350588762634713 | validation: 4.660809378016764]
	TIME [epoch: 10.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.81539290516396		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 3.81539290516396 | validation: 2.629234488631646]
	TIME [epoch: 10.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.076521587168531		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 3.076521587168531 | validation: 3.9854090546600847]
	TIME [epoch: 10.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.422995214255476		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 4.422995214255476 | validation: 4.137817181549141]
	TIME [epoch: 10.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9101475036831617		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 3.9101475036831617 | validation: 3.321750897776186]
	TIME [epoch: 10.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.367312094903164		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 3.367312094903164 | validation: 2.6286431878510825]
	TIME [epoch: 10.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7604103609063393		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 2.7604103609063393 | validation: 2.3625024240634525]
	TIME [epoch: 10.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9238347911308997		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 2.9238347911308997 | validation: 4.348060636628181]
	TIME [epoch: 10.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.909863781505842		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 4.909863781505842 | validation: 5.607729066733537]
	TIME [epoch: 10.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.16282158765085		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 5.16282158765085 | validation: 4.227390600381365]
	TIME [epoch: 10.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4245477284134025		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 3.4245477284134025 | validation: 2.7981746178433005]
	TIME [epoch: 10.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1358673938147668		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 3.1358673938147668 | validation: 2.603929363091952]
	TIME [epoch: 10.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1571208486078266		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 3.1571208486078266 | validation: 4.18666702040046]
	TIME [epoch: 10.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5464217461985017		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 3.5464217461985017 | validation: 2.867545551368636]
	TIME [epoch: 10.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6482270689572274		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 2.6482270689572274 | validation: 2.093295007366817]
	TIME [epoch: 10.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.531399219109348		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 2.531399219109348 | validation: 2.5002396645477685]
	TIME [epoch: 10.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.893819926875256		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 2.893819926875256 | validation: 2.8174605049275225]
	TIME [epoch: 10.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.615479311264698		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 2.615479311264698 | validation: 2.4279215275695147]
	TIME [epoch: 10.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.550101951535821		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 3.550101951535821 | validation: 4.763547792419796]
	TIME [epoch: 10.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.931946629928548		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 3.931946629928548 | validation: 2.335830358314048]
	TIME [epoch: 10.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.503723707297983		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 2.503723707297983 | validation: 2.055025860946564]
	TIME [epoch: 10.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5685971749756007		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 3.5685971749756007 | validation: 2.9382178763569082]
	TIME [epoch: 10.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6149319505238777		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 2.6149319505238777 | validation: 2.418106123422681]
	TIME [epoch: 10.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.276733288996892		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 3.276733288996892 | validation: 4.327029481196946]
	TIME [epoch: 10.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2024025297418275		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 4.2024025297418275 | validation: 3.068028840239247]
	TIME [epoch: 10.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9852710101690185		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 2.9852710101690185 | validation: 2.7378436501637906]
	TIME [epoch: 10.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9750304332979787		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 2.9750304332979787 | validation: 3.436731681553219]
	TIME [epoch: 10.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.850764633773674		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 3.850764633773674 | validation: 4.68877946937597]
	TIME [epoch: 10.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.807524647338445		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 4.807524647338445 | validation: 4.812999594055733]
	TIME [epoch: 10.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9720160990752182		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 3.9720160990752182 | validation: 2.7481169029180945]
	TIME [epoch: 10.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.334339540032191		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 3.334339540032191 | validation: 3.480091196120294]
	TIME [epoch: 10.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3273663523028683		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 3.3273663523028683 | validation: 2.575927330665593]
	TIME [epoch: 10.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0910757020139825		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 3.0910757020139825 | validation: 2.5315089828490027]
	TIME [epoch: 10.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7777585586343108		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 2.7777585586343108 | validation: 2.6428788243155483]
	TIME [epoch: 10.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8556526629085175		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 2.8556526629085175 | validation: 2.474436443061767]
	TIME [epoch: 10.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7235774888851454		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 2.7235774888851454 | validation: 2.8862430332200892]
	TIME [epoch: 10.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4285138928855887		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 3.4285138928855887 | validation: 3.095406970672396]
	TIME [epoch: 10.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.197707441044808		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 3.197707441044808 | validation: 3.3538146423568382]
	TIME [epoch: 10.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9881835268038275		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 2.9881835268038275 | validation: 2.182620899131195]
	TIME [epoch: 10.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6874661393234844		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 2.6874661393234844 | validation: 3.9801845445060544]
	TIME [epoch: 10.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.516052558605255		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 3.516052558605255 | validation: 2.6835000197925876]
	TIME [epoch: 10.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9000947546389484		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 2.9000947546389484 | validation: 2.281811072163825]
	TIME [epoch: 10.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4153497731181846		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 3.4153497731181846 | validation: 4.389152356670855]
	TIME [epoch: 10.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.662952646746322		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 3.662952646746322 | validation: 2.6120326940848417]
	TIME [epoch: 10.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.902080074303927		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 2.902080074303927 | validation: 2.6441470571138725]
	TIME [epoch: 10.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7557286719877987		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 2.7557286719877987 | validation: 2.313554104218245]
	TIME [epoch: 10.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.857754401128053		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 2.857754401128053 | validation: 2.8987256130901415]
	TIME [epoch: 10.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3246505774993147		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 3.3246505774993147 | validation: 2.7805247260486308]
	TIME [epoch: 10.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0742112114670475		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 3.0742112114670475 | validation: 3.3545033760351615]
	TIME [epoch: 10.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.267267720348409		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 4.267267720348409 | validation: 4.772694533292858]
	TIME [epoch: 10.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.116665842328583		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 5.116665842328583 | validation: 4.531071766096044]
	TIME [epoch: 10.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.671273556506611		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 4.671273556506611 | validation: 2.9462318842578634]
	TIME [epoch: 10.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.370654336909509		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 3.370654336909509 | validation: 3.1581999170885013]
	TIME [epoch: 10.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.131337993211564		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 3.131337993211564 | validation: 2.5924806591104277]
	TIME [epoch: 10.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2048308020176193		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 3.2048308020176193 | validation: 2.4500682505774654]
	TIME [epoch: 10.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5539669973856767		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 2.5539669973856767 | validation: 2.174526569530531]
	TIME [epoch: 10.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4592607934301816		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 2.4592607934301816 | validation: 2.4718299995635653]
	TIME [epoch: 10.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.377496759251154		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 3.377496759251154 | validation: 2.8326238303124]
	TIME [epoch: 10.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8647054894011044		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 2.8647054894011044 | validation: 3.205282384331692]
	TIME [epoch: 10.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0022818599616046		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 3.0022818599616046 | validation: 2.3546182996968357]
	TIME [epoch: 10.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.839787196729528		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 2.839787196729528 | validation: 2.2844954286584134]
	TIME [epoch: 10.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.643244696911753		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 2.643244696911753 | validation: 2.1781305237691364]
	TIME [epoch: 10.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4699511719103646		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 2.4699511719103646 | validation: 3.542253955910212]
	TIME [epoch: 10.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.979665909791245		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 3.979665909791245 | validation: 2.537381048494927]
	TIME [epoch: 10.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5302412608515197		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 2.5302412608515197 | validation: 2.323583362882992]
	TIME [epoch: 10.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5098390890992617		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 2.5098390890992617 | validation: 2.1108933825084724]
	TIME [epoch: 10.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7562855476212977		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 2.7562855476212977 | validation: 2.4331032045712697]
	TIME [epoch: 10.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.535497370125082		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 2.535497370125082 | validation: 2.0914608630426743]
	TIME [epoch: 10.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4168743586493404		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 2.4168743586493404 | validation: 2.346510221231211]
	TIME [epoch: 10.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.173143643291328		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 2.173143643291328 | validation: 1.9885033326031567]
	TIME [epoch: 10.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9980498876088102		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.9980498876088102 | validation: 1.7964089482367056]
	TIME [epoch: 10.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.060751348484304		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 2.060751348484304 | validation: 1.8161095454967944]
	TIME [epoch: 10.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8357676485484309		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 1.8357676485484309 | validation: 1.6933837734167885]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.864542851021539		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 1.864542851021539 | validation: 1.8258655983415344]
	TIME [epoch: 10.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8777778446509175		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 1.8777778446509175 | validation: 2.6505378580742036]
	TIME [epoch: 10.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5942725821633488		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 3.5942725821633488 | validation: 3.1508859504797058]
	TIME [epoch: 10.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5787652225175868		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 3.5787652225175868 | validation: 4.408327534001748]
	TIME [epoch: 10.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.160304152542499		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 4.160304152542499 | validation: 3.1556131749098086]
	TIME [epoch: 10.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4874417671266817		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 3.4874417671266817 | validation: 3.265060946864398]
	TIME [epoch: 10.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.39281675720541		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 3.39281675720541 | validation: 3.038095551237765]
	TIME [epoch: 10.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.368432723068819		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 3.368432723068819 | validation: 3.1611956216585373]
	TIME [epoch: 10.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.421515523012333		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 3.421515523012333 | validation: 4.08746355811987]
	TIME [epoch: 10.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.159934440721646		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 4.159934440721646 | validation: 3.713351604186479]
	TIME [epoch: 10.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4373006254466447		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 3.4373006254466447 | validation: 2.8004035817670587]
	TIME [epoch: 10.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2860046020303577		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 3.2860046020303577 | validation: 2.9204804087790786]
	TIME [epoch: 10.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3278652794799704		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 3.3278652794799704 | validation: 2.851629983391127]
	TIME [epoch: 10.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2650003805787065		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 3.2650003805787065 | validation: 2.8059136388730135]
	TIME [epoch: 10.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2347487194085076		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 3.2347487194085076 | validation: 3.0360706473866124]
	TIME [epoch: 10.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.07458829855297		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 3.07458829855297 | validation: 2.777040693657274]
	TIME [epoch: 10.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8695292370779564		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 2.8695292370779564 | validation: 2.2306225268963296]
	TIME [epoch: 10.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9390577925733399		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 1.9390577925733399 | validation: 1.6607631138121448]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.584285375790731		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 1.584285375790731 | validation: 1.5843211084742277]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4676708623646584		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.4676708623646584 | validation: 1.28300908504823]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2565251829173318		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 1.2565251829173318 | validation: 1.6332745454368294]
	TIME [epoch: 10.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3088082742292801		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 1.3088082742292801 | validation: 1.3579744146710226]
	TIME [epoch: 10.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0329187572519336		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 1.0329187572519336 | validation: 1.5015386675807296]
	TIME [epoch: 10.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.259158648616642		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 1.259158648616642 | validation: 2.218058806842376]
	TIME [epoch: 10.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9560265315662508		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 1.9560265315662508 | validation: 1.3186424077942949]
	TIME [epoch: 10.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1656037556960643		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 1.1656037556960643 | validation: 1.1167198097921485]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0038237241388726		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 1.0038237241388726 | validation: 0.9477483849943448]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1555877684808276		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 1.1555877684808276 | validation: 1.0246736995509076]
	TIME [epoch: 10.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.047582190279385		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 1.047582190279385 | validation: 0.9010655781302347]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8922144753494677		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 0.8922144753494677 | validation: 0.9338101401162047]
	TIME [epoch: 10.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1396795409268972		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 1.1396795409268972 | validation: 0.8019313050261179]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9327151631893568		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 0.9327151631893568 | validation: 0.8756170843476444]
	TIME [epoch: 10.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9231920655183968		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 0.9231920655183968 | validation: 1.1096901403154025]
	TIME [epoch: 10.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0686104889305512		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 1.0686104889305512 | validation: 0.9400184476005976]
	TIME [epoch: 10.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1173311322680128		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 1.1173311322680128 | validation: 0.9411804043187276]
	TIME [epoch: 10.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9665355424277079		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 0.9665355424277079 | validation: 1.481675645841001]
	TIME [epoch: 10.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1130743188440557		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 1.1130743188440557 | validation: 0.8691382724205405]
	TIME [epoch: 10.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9231576635219982		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 0.9231576635219982 | validation: 0.8148566181106035]
	TIME [epoch: 10.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.018841314352199		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 1.018841314352199 | validation: 0.8030190136048284]
	TIME [epoch: 10.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8567370570409596		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 0.8567370570409596 | validation: 1.1275650905180967]
	TIME [epoch: 10.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1276325630900164		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 1.1276325630900164 | validation: 0.7975280558714719]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9130647344281589		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 0.9130647344281589 | validation: 0.7468663717536288]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8469526500835212		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 0.8469526500835212 | validation: 0.836309043079528]
	TIME [epoch: 10.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7714724389578257		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 0.7714724389578257 | validation: 0.7850824663491333]
	TIME [epoch: 10.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.244292033901339		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 2.244292033901339 | validation: 1.965405102469894]
	TIME [epoch: 10.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1241953973168273		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 1.1241953973168273 | validation: 0.7206413357214839]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7472815079360042		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 0.7472815079360042 | validation: 0.7843065847896847]
	TIME [epoch: 10.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0619214989802352		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.0619214989802352 | validation: 0.6653220777184738]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7876358755175616		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 0.7876358755175616 | validation: 0.7400209585911048]
	TIME [epoch: 10.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6797473971040207		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 0.6797473971040207 | validation: 0.8390753338196433]
	TIME [epoch: 10.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0081927473146064		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 1.0081927473146064 | validation: 1.0151905402032841]
	TIME [epoch: 10.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8828845178811381		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.8828845178811381 | validation: 0.6190033164980631]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7521997412696511		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 0.7521997412696511 | validation: 0.953284915513496]
	TIME [epoch: 10.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7768514999867573		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 0.7768514999867573 | validation: 1.4286215531946045]
	TIME [epoch: 10.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8781333374937205		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 0.8781333374937205 | validation: 0.7681466499818089]
	TIME [epoch: 10.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7706002050924616		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 0.7706002050924616 | validation: 0.9198242771230136]
	TIME [epoch: 10.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7509769386915307		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 0.7509769386915307 | validation: 0.6300203174786541]
	TIME [epoch: 10.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6271587297675297		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 0.6271587297675297 | validation: 0.8013876356368013]
	TIME [epoch: 10.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7726237963571452		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 0.7726237963571452 | validation: 0.8461938199520538]
	TIME [epoch: 10.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2970982532765836		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 1.2970982532765836 | validation: 0.6924439449188623]
	TIME [epoch: 10.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7017990580415561		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 0.7017990580415561 | validation: 0.49128646409214444]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8650478775332721		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.8650478775332721 | validation: 0.5116659662438362]
	TIME [epoch: 10.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7136503230013649		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 0.7136503230013649 | validation: 0.5342702868574434]
	TIME [epoch: 10.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7144816822616462		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 0.7144816822616462 | validation: 0.4285579451569669]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6591992071407502		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 0.6591992071407502 | validation: 0.5536278367826605]
	TIME [epoch: 10.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7467302477797026		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.7467302477797026 | validation: 0.5384616187314457]
	TIME [epoch: 10.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6250155297360845		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 0.6250155297360845 | validation: 0.9714606956498436]
	TIME [epoch: 10.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8665894506523992		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 0.8665894506523992 | validation: 0.7272762221230474]
	TIME [epoch: 10.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6448061650228645		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 0.6448061650228645 | validation: 0.6311868542384461]
	TIME [epoch: 10.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.658402806462578		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 0.658402806462578 | validation: 0.8851997416007279]
	TIME [epoch: 10.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6581304934157176		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.6581304934157176 | validation: 0.7943146272943693]
	TIME [epoch: 10.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6554428529455201		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.6554428529455201 | validation: 0.7428362205644191]
	TIME [epoch: 10.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6270358732083297		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.6270358732083297 | validation: 1.0351673917568789]
	TIME [epoch: 10.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7937110029782941		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 0.7937110029782941 | validation: 0.6051992559963784]
	TIME [epoch: 10.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7521782656373677		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.7521782656373677 | validation: 0.7968734531219263]
	TIME [epoch: 10.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7853368196563236		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 0.7853368196563236 | validation: 0.8151809375861953]
	TIME [epoch: 10.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7695290018686805		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.7695290018686805 | validation: 0.7425183514306969]
	TIME [epoch: 10.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8982767070169928		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 0.8982767070169928 | validation: 0.8492843955496651]
	TIME [epoch: 10.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6348198920931234		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 0.6348198920931234 | validation: 0.9290619984225416]
	TIME [epoch: 10.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7839464257444886		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 0.7839464257444886 | validation: 0.991576635941582]
	TIME [epoch: 10.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5808924493973139		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 0.5808924493973139 | validation: 0.628474187074878]
	TIME [epoch: 10.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6831801933117144		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 0.6831801933117144 | validation: 0.5756776451906171]
	TIME [epoch: 10.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7057231080701442		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 0.7057231080701442 | validation: 0.6115105058608695]
	TIME [epoch: 10.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6687388315571436		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 0.6687388315571436 | validation: 0.5609718805064978]
	TIME [epoch: 10.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7837892906948293		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 0.7837892906948293 | validation: 0.5949154953774406]
	TIME [epoch: 10.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6455145415298011		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 0.6455145415298011 | validation: 0.6410927977438291]
	TIME [epoch: 10.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6845009005581952		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 0.6845009005581952 | validation: 0.6929363865448934]
	TIME [epoch: 10.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6070377171371562		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 0.6070377171371562 | validation: 0.664497270773604]
	TIME [epoch: 10.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6212801443623442		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.6212801443623442 | validation: 0.5642539692466481]
	TIME [epoch: 10.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5663898670239981		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 0.5663898670239981 | validation: 0.5290718512430801]
	TIME [epoch: 10.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.760902482050053		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 0.760902482050053 | validation: 0.8158150890214362]
	TIME [epoch: 10.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5881045408855567		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 0.5881045408855567 | validation: 0.5646046128066352]
	TIME [epoch: 10.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.478391972479333		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 0.478391972479333 | validation: 0.6232654468192249]
	TIME [epoch: 10.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6519810160707951		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 0.6519810160707951 | validation: 0.5597712592204922]
	TIME [epoch: 10.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5396892037156353		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 0.5396892037156353 | validation: 0.5239871893636199]
	TIME [epoch: 10.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.492660754114009		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 0.492660754114009 | validation: 0.8719717402185925]
	TIME [epoch: 10.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8224813816896044		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 0.8224813816896044 | validation: 0.6404462572287749]
	TIME [epoch: 10.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6975618196983715		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 0.6975618196983715 | validation: 0.5544087891070579]
	TIME [epoch: 10.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945363664738599		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 0.5945363664738599 | validation: 0.562513584705835]
	TIME [epoch: 10.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6971061164960289		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 0.6971061164960289 | validation: 0.6631643862307897]
	TIME [epoch: 10.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024798631174544		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 0.6024798631174544 | validation: 0.5641152053167237]
	TIME [epoch: 10.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377010149886935		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 0.6377010149886935 | validation: 0.5351681388420019]
	TIME [epoch: 10.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6534099450908465		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 0.6534099450908465 | validation: 1.058590204249486]
	TIME [epoch: 10.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.749223936737038		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 0.749223936737038 | validation: 0.4668383853435732]
	TIME [epoch: 10.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6128174873156038		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 0.6128174873156038 | validation: 0.6739670374513557]
	TIME [epoch: 10.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505872697766514		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 0.505872697766514 | validation: 0.5133213436826316]
	TIME [epoch: 10.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764634763655693		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 0.5764634763655693 | validation: 0.6638124968761148]
	TIME [epoch: 10.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6142896818276448		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 0.6142896818276448 | validation: 0.5933341849685804]
	TIME [epoch: 10.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6055196516577178		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 0.6055196516577178 | validation: 0.5307767060570432]
	TIME [epoch: 10.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.582859559760455		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 0.582859559760455 | validation: 0.6596317892279271]
	TIME [epoch: 10.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.621865418308617		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 0.621865418308617 | validation: 0.5188473863422592]
	TIME [epoch: 10.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5963817748926872		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 0.5963817748926872 | validation: 0.5966830677205964]
	TIME [epoch: 10.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6407162239763899		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 0.6407162239763899 | validation: 0.6338803323657268]
	TIME [epoch: 10.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5222348264878698		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 0.5222348264878698 | validation: 0.491574112228694]
	TIME [epoch: 10.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6279070624221769		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 0.6279070624221769 | validation: 0.45020989330803746]
	TIME [epoch: 10.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.572863854920873		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 0.572863854920873 | validation: 0.6969720864696308]
	TIME [epoch: 10.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7073346167020172		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 0.7073346167020172 | validation: 0.8820681739635381]
	TIME [epoch: 10.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7923291382233499		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 0.7923291382233499 | validation: 0.944144392962674]
	TIME [epoch: 10.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8449053309817808		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 0.8449053309817808 | validation: 0.9869727712875985]
	TIME [epoch: 10.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8150995830494662		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 0.8150995830494662 | validation: 0.5357505138802966]
	TIME [epoch: 10.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475502093383685		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 0.6475502093383685 | validation: 0.562603465996166]
	TIME [epoch: 10.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7585223640628087		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 0.7585223640628087 | validation: 0.6004365521555943]
	TIME [epoch: 10.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6354748257196494		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 0.6354748257196494 | validation: 0.5061064306761509]
	TIME [epoch: 10.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7503423034575807		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 0.7503423034575807 | validation: 0.6716280475162588]
	TIME [epoch: 10.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6547531014178465		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 0.6547531014178465 | validation: 0.5257131110494135]
	TIME [epoch: 10.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9650444634372878		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 0.9650444634372878 | validation: 0.5961200623256266]
	TIME [epoch: 10.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965468187051857		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 0.5965468187051857 | validation: 0.5759650284485005]
	TIME [epoch: 10.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6819387577733633		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 0.6819387577733633 | validation: 0.7436474213960738]
	TIME [epoch: 10.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7224198002523188		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 0.7224198002523188 | validation: 0.646282311809901]
	TIME [epoch: 10.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7240135324133375		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 0.7240135324133375 | validation: 0.649139627241338]
	TIME [epoch: 10.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7795767613438055		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 0.7795767613438055 | validation: 0.6647294561415498]
	TIME [epoch: 10.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6431163238251972		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 0.6431163238251972 | validation: 0.5160192210892945]
	TIME [epoch: 10.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.655951391734986		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 0.655951391734986 | validation: 0.6206321315345272]
	TIME [epoch: 10.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6295680622643		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 0.6295680622643 | validation: 0.537236557275501]
	TIME [epoch: 10.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5048667555209592		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 0.5048667555209592 | validation: 0.5193363410913538]
	TIME [epoch: 10.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7997157047366412		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 0.7997157047366412 | validation: 0.7196874178213059]
	TIME [epoch: 10.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6471605917271733		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.6471605917271733 | validation: 0.5680470523369586]
	TIME [epoch: 10.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5734428371011482		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.5734428371011482 | validation: 0.5879117049707127]
	TIME [epoch: 10.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5861194447276011		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.5861194447276011 | validation: 0.8356074389308498]
	TIME [epoch: 10.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7353036961707223		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 0.7353036961707223 | validation: 0.7984763423106679]
	TIME [epoch: 10.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8305520194635004		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.8305520194635004 | validation: 0.7763844220786412]
	TIME [epoch: 10.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6445932527554092		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.6445932527554092 | validation: 0.4827092871836092]
	TIME [epoch: 10.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6717241382382937		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.6717241382382937 | validation: 0.5563114769937119]
	TIME [epoch: 10.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6664403812185163		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 0.6664403812185163 | validation: 0.5747364192417564]
	TIME [epoch: 10.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5336361868166388		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 0.5336361868166388 | validation: 0.457983574047872]
	TIME [epoch: 10.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4579146094732625		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.4579146094732625 | validation: 0.420274846389851]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46661177625531386		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.46661177625531386 | validation: 0.5066971774124533]
	TIME [epoch: 10.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300725705529131		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.5300725705529131 | validation: 0.6780628456723173]
	TIME [epoch: 10.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4965982455244717		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.4965982455244717 | validation: 0.6237352857698553]
	TIME [epoch: 10.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.675224883775815		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 0.675224883775815 | validation: 0.567897198729778]
	TIME [epoch: 10.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5026862081453457		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 0.5026862081453457 | validation: 0.46375074258843924]
	TIME [epoch: 10.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5430249813781174		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.5430249813781174 | validation: 0.40598521018639516]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.595922073381147		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.595922073381147 | validation: 0.49961395751321896]
	TIME [epoch: 10.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4368736732579457		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 0.4368736732579457 | validation: 0.4961898170367236]
	TIME [epoch: 10.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5630682251826161		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.5630682251826161 | validation: 0.6975638618837954]
	TIME [epoch: 10.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8151430772761605		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.8151430772761605 | validation: 0.4651376789051767]
	TIME [epoch: 10.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5801047627569821		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.5801047627569821 | validation: 0.8103572238116011]
	TIME [epoch: 10.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.584223346821443		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 0.584223346821443 | validation: 0.4186930794035382]
	TIME [epoch: 10.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4682671385525373		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.4682671385525373 | validation: 0.5132080107943838]
	TIME [epoch: 10.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4917203417236224		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.4917203417236224 | validation: 0.6673143324206976]
	TIME [epoch: 10.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48274110912202295		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.48274110912202295 | validation: 0.8887972363808541]
	TIME [epoch: 10.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5538303822997175		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 0.5538303822997175 | validation: 0.5388110103933907]
	TIME [epoch: 10.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5797326736848062		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.5797326736848062 | validation: 0.6125629346252695]
	TIME [epoch: 10.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48481938559463816		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.48481938559463816 | validation: 0.44424489418952706]
	TIME [epoch: 10.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48948004727957545		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.48948004727957545 | validation: 0.4006454358316834]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4010208262673197		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.4010208262673197 | validation: 0.45224550719751827]
	TIME [epoch: 10.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142508504891616		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.4142508504891616 | validation: 0.41143776643812024]
	TIME [epoch: 10.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5515128361646559		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 0.5515128361646559 | validation: 0.6754522636570022]
	TIME [epoch: 10.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49868122333966297		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.49868122333966297 | validation: 0.4308259797850637]
	TIME [epoch: 10.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5200946823521095		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 0.5200946823521095 | validation: 0.48698791668339725]
	TIME [epoch: 10.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.559470885532444		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 0.559470885532444 | validation: 0.528554399099654]
	TIME [epoch: 10.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4554008347568449		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.4554008347568449 | validation: 0.5063191768974418]
	TIME [epoch: 10.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4981491441244402		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.4981491441244402 | validation: 0.7568619093041482]
	TIME [epoch: 10.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8280361175787586		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.8280361175787586 | validation: 0.5886996317348039]
	TIME [epoch: 10.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5887488582705087		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.5887488582705087 | validation: 0.6511222496552173]
	TIME [epoch: 10.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5463190213786808		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 0.5463190213786808 | validation: 0.49052150692669283]
	TIME [epoch: 10.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4692262571043143		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 0.4692262571043143 | validation: 0.3734273982459517]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6268762300506692		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.6268762300506692 | validation: 0.559092752289336]
	TIME [epoch: 10.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5147599321020969		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 0.5147599321020969 | validation: 0.5503323093825594]
	TIME [epoch: 10.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5005594846974135		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.5005594846974135 | validation: 0.5863383414503026]
	TIME [epoch: 10.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49740673317812173		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.49740673317812173 | validation: 0.3784350506449852]
	TIME [epoch: 10.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35745065458832875		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.35745065458832875 | validation: 0.3935621846881127]
	TIME [epoch: 10.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4086059057167045		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.4086059057167045 | validation: 0.5425435185260129]
	TIME [epoch: 10.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5852862452299183		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.5852862452299183 | validation: 0.4628564400803802]
	TIME [epoch: 10.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43257422912792876		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.43257422912792876 | validation: 0.5173337487233259]
	TIME [epoch: 10.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4570475879998094		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 0.4570475879998094 | validation: 0.48749957500481106]
	TIME [epoch: 10.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4191178198483607		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.4191178198483607 | validation: 0.4397830167420591]
	TIME [epoch: 10.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38556903012479826		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.38556903012479826 | validation: 0.38210616968600447]
	TIME [epoch: 10.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3814701132264845		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.3814701132264845 | validation: 0.416403677512039]
	TIME [epoch: 10.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48917518730857656		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.48917518730857656 | validation: 0.3547727896792668]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41544052093136097		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.41544052093136097 | validation: 0.5480608348595101]
	TIME [epoch: 10.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39927116877879054		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.39927116877879054 | validation: 0.3516389896443606]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3329124792938883		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.3329124792938883 | validation: 0.32338153742455805]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6665296617175451		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.6665296617175451 | validation: 0.8701656900795237]
	TIME [epoch: 10.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237665127815706		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.5237665127815706 | validation: 0.36235544415446574]
	TIME [epoch: 10.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4231532576159007		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.4231532576159007 | validation: 0.2941538941170967]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41368643513045467		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 0.41368643513045467 | validation: 0.3980587505353834]
	TIME [epoch: 10.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5463775651943266		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.5463775651943266 | validation: 0.4222196350976377]
	TIME [epoch: 10.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4600408534668038		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.4600408534668038 | validation: 0.4698065453179411]
	TIME [epoch: 10.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40656432843886703		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.40656432843886703 | validation: 0.3689773422398028]
	TIME [epoch: 10.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47441786888639453		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.47441786888639453 | validation: 0.4101479277057482]
	TIME [epoch: 10.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626614888308688		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.3626614888308688 | validation: 0.3994422026219614]
	TIME [epoch: 10.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4041079416303425		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.4041079416303425 | validation: 0.6153698321186151]
	TIME [epoch: 10.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48469598948597054		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.48469598948597054 | validation: 0.3729416288472963]
	TIME [epoch: 10.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.361931418148544		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.361931418148544 | validation: 0.3592690526832181]
	TIME [epoch: 10.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4165114844960545		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 0.4165114844960545 | validation: 0.4258138843954381]
	TIME [epoch: 10.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4372345810220229		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.4372345810220229 | validation: 0.38353743007299285]
	TIME [epoch: 10.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3864218080626563		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.3864218080626563 | validation: 0.40012709764495924]
	TIME [epoch: 10.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43954356310896714		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.43954356310896714 | validation: 0.4793926631133594]
	TIME [epoch: 10.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43170306137375924		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.43170306137375924 | validation: 0.45904819351179527]
	TIME [epoch: 10.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4241984429861995		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 0.4241984429861995 | validation: 0.317773821186799]
	TIME [epoch: 10.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3515327956657248		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.3515327956657248 | validation: 0.3123318025786514]
	TIME [epoch: 10.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3443304179520915		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.3443304179520915 | validation: 0.6947281342351744]
	TIME [epoch: 10.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4649942319664772		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.4649942319664772 | validation: 0.48254025720573707]
	TIME [epoch: 10.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46308834497738083		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.46308834497738083 | validation: 0.3794957789852901]
	TIME [epoch: 10.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329850983010665		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.4329850983010665 | validation: 0.4699481480157459]
	TIME [epoch: 10.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38083307072371675		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.38083307072371675 | validation: 0.2915249168039758]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3520671073204725		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.3520671073204725 | validation: 0.5309260801448995]
	TIME [epoch: 10.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4433568882688485		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.4433568882688485 | validation: 0.4333737173356471]
	TIME [epoch: 10.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4098009318633268		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.4098009318633268 | validation: 0.43355345402242784]
	TIME [epoch: 10.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.405559630048431		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.405559630048431 | validation: 0.37261655786338255]
	TIME [epoch: 10.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39627797943367127		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.39627797943367127 | validation: 0.3252059096185271]
	TIME [epoch: 10.3 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38916618567464684		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.38916618567464684 | validation: 0.38761638468065157]
	TIME [epoch: 10.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4305884856933342		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.4305884856933342 | validation: 0.3606365963006384]
	TIME [epoch: 10.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44264098461123813		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.44264098461123813 | validation: 0.6675235681376674]
	TIME [epoch: 10.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469490115672877		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.5469490115672877 | validation: 0.359500834797863]
	TIME [epoch: 10.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3908704692163189		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.3908704692163189 | validation: 0.4279357757017526]
	TIME [epoch: 10.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3843142991735206		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.3843142991735206 | validation: 0.40507570281539346]
	TIME [epoch: 10.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3361193346665233		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.3361193346665233 | validation: 0.42829832092904163]
	TIME [epoch: 10.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46040192813926656		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.46040192813926656 | validation: 0.49388332952670627]
	TIME [epoch: 10.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3674708947044313		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.3674708947044313 | validation: 0.35034293847363157]
	TIME [epoch: 10.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3521202983391033		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.3521202983391033 | validation: 0.3342554124762907]
	TIME [epoch: 10.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4419096484188426		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.4419096484188426 | validation: 0.3816638752611039]
	TIME [epoch: 10.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32792921957702015		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.32792921957702015 | validation: 0.33570837442755724]
	TIME [epoch: 10.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3726137750527116		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.3726137750527116 | validation: 0.4293145077706392]
	TIME [epoch: 10.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274506585294595		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.3274506585294595 | validation: 0.328765740469081]
	TIME [epoch: 10.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3726812209328192		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.3726812209328192 | validation: 0.42848113943446264]
	TIME [epoch: 10.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3195444054951843		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.3195444054951843 | validation: 0.47723841911293235]
	TIME [epoch: 10.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45189278719334514		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.45189278719334514 | validation: 0.40152564590658574]
	TIME [epoch: 10.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3863565159727599		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.3863565159727599 | validation: 0.3840296404709288]
	TIME [epoch: 10.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5104319396154018		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.5104319396154018 | validation: 0.4565976762234968]
	TIME [epoch: 10.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41941004024099515		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.41941004024099515 | validation: 0.2911273730083459]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2973682945912388		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.2973682945912388 | validation: 0.4865406156786168]
	TIME [epoch: 10.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3908859596025165		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.3908859596025165 | validation: 0.3811331985865913]
	TIME [epoch: 10.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4754312163975971		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.4754312163975971 | validation: 0.6594382813006265]
	TIME [epoch: 10.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4115720486851605		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.4115720486851605 | validation: 0.3769493211237047]
	TIME [epoch: 10.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47032210886522563		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.47032210886522563 | validation: 0.3578143450021024]
	TIME [epoch: 10.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.587600852747171		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.587600852747171 | validation: 0.4739577000047591]
	TIME [epoch: 10.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44932972596072646		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.44932972596072646 | validation: 0.3168650120547567]
	TIME [epoch: 10.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5542456902684106		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.5542456902684106 | validation: 0.7210262636754121]
	TIME [epoch: 10.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45658370094409556		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.45658370094409556 | validation: 0.4084430232655772]
	TIME [epoch: 10.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3472775569288669		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.3472775569288669 | validation: 0.23909902562706645]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4626217654645998		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.4626217654645998 | validation: 0.5604476128660886]
	TIME [epoch: 10.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5752514192293474		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.5752514192293474 | validation: 0.6151629060003492]
	TIME [epoch: 10.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4275814277140265		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.4275814277140265 | validation: 0.48636717827526477]
	TIME [epoch: 10.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4917303779254444		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.4917303779254444 | validation: 0.6325637673809547]
	TIME [epoch: 10.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306107120891674		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.5306107120891674 | validation: 0.39329539865804053]
	TIME [epoch: 10.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44019174644498077		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.44019174644498077 | validation: 0.5149378317688381]
	TIME [epoch: 10.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7445945218154926		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.7445945218154926 | validation: 0.5968588685625968]
	TIME [epoch: 10.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435543875407534		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.6435543875407534 | validation: 0.6390858101546698]
	TIME [epoch: 10.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45285829488538515		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.45285829488538515 | validation: 0.44345599855786305]
	TIME [epoch: 10.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5433248525144985		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.5433248525144985 | validation: 0.4435967875196261]
	TIME [epoch: 10.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162490398120114		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.4162490398120114 | validation: 0.34350994912966343]
	TIME [epoch: 10.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3121141214230601		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.3121141214230601 | validation: 0.311101677733089]
	TIME [epoch: 10.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3407321306479549		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.3407321306479549 | validation: 0.3212281495469038]
	TIME [epoch: 10.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41493898163264625		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.41493898163264625 | validation: 0.5082565742499218]
	TIME [epoch: 10.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3167473966011177		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.3167473966011177 | validation: 0.3389537571096831]
	TIME [epoch: 10.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3171856768912604		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.3171856768912604 | validation: 0.28853853150754066]
	TIME [epoch: 10.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3381669791460999		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.3381669791460999 | validation: 0.4636756984390379]
	TIME [epoch: 10.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3498716893407374		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.3498716893407374 | validation: 0.3580978339713191]
	TIME [epoch: 10.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3562643916340812		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.3562643916340812 | validation: 0.36635470127250414]
	TIME [epoch: 10.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49491867058540623		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.49491867058540623 | validation: 0.474811179595834]
	TIME [epoch: 10.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4748949028121868		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.4748949028121868 | validation: 0.3711354224084494]
	TIME [epoch: 10.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3329769395346316		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.3329769395346316 | validation: 0.34757247236104377]
	TIME [epoch: 10.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34058781934009674		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.34058781934009674 | validation: 0.4749393041873448]
	TIME [epoch: 10.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220253945463347		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.5220253945463347 | validation: 0.7881945282409356]
	TIME [epoch: 10.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49914209108813734		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.49914209108813734 | validation: 0.3682644804275364]
	TIME [epoch: 10.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29468403361758777		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.29468403361758777 | validation: 0.3528538045916366]
	TIME [epoch: 10.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28010828367684615		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.28010828367684615 | validation: 0.39964412365252555]
	TIME [epoch: 10.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31473447161060925		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.31473447161060925 | validation: 0.28245223469067704]
	TIME [epoch: 10.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28061708043796035		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.28061708043796035 | validation: 0.49370665066883584]
	TIME [epoch: 10.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3634816266307293		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.3634816266307293 | validation: 0.6269431066487493]
	TIME [epoch: 10.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39539139746755303		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.39539139746755303 | validation: 0.35287886886678477]
	TIME [epoch: 10.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43293756541318096		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.43293756541318096 | validation: 0.46168853123767184]
	TIME [epoch: 10.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35759460239228974		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.35759460239228974 | validation: 0.3903642608087497]
	TIME [epoch: 10.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505472606094423		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.505472606094423 | validation: 0.26632116170128894]
	TIME [epoch: 10.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40000732634865344		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.40000732634865344 | validation: 0.2849974416631486]
	TIME [epoch: 10.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825733203759065		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.2825733203759065 | validation: 0.27756390973503]
	TIME [epoch: 10.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26452095942841203		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.26452095942841203 | validation: 0.35474257538765797]
	TIME [epoch: 10.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3734916853944689		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.3734916853944689 | validation: 0.48772652498192837]
	TIME [epoch: 10.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7574685478903501		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.7574685478903501 | validation: 0.5079387289239327]
	TIME [epoch: 10.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3469938845007269		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.3469938845007269 | validation: 0.31531539002690245]
	TIME [epoch: 10.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922095368754548		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.2922095368754548 | validation: 0.3019279850491164]
	TIME [epoch: 10.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30215250974422553		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.30215250974422553 | validation: 0.2557223180606709]
	TIME [epoch: 10.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27056593582299837		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.27056593582299837 | validation: 0.24080470930057618]
	TIME [epoch: 10.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3447511089785084		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.3447511089785084 | validation: 0.3139779605314653]
	TIME [epoch: 10.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36483364175723126		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.36483364175723126 | validation: 0.30394667710581214]
	TIME [epoch: 10.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3092774757808173		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.3092774757808173 | validation: 0.3633671347148588]
	TIME [epoch: 10.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3280277975273313		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.3280277975273313 | validation: 0.23981014025202715]
	TIME [epoch: 10.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34423532924339295		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.34423532924339295 | validation: 0.34140413502853834]
	TIME [epoch: 10.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2786220691676135		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.2786220691676135 | validation: 0.3681188744307643]
	TIME [epoch: 10.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.284272679498221		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.284272679498221 | validation: 0.3304269673057465]
	TIME [epoch: 10.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3297204415482752		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.3297204415482752 | validation: 0.24712879454762993]
	TIME [epoch: 10.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2711815294669639		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.2711815294669639 | validation: 0.3844717935347529]
	TIME [epoch: 10.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256880582906189		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.5256880582906189 | validation: 0.4920471108605833]
	TIME [epoch: 10.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5216068337023687		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.5216068337023687 | validation: 0.37360368235130686]
	TIME [epoch: 10.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3759729477109105		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.3759729477109105 | validation: 0.5157722476488487]
	TIME [epoch: 10.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49110778489632506		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.49110778489632506 | validation: 0.24464271900501813]
	TIME [epoch: 10.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36811923006512454		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.36811923006512454 | validation: 0.3315517452100468]
	TIME [epoch: 10.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21459735252550263		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.21459735252550263 | validation: 0.26301839908945224]
	TIME [epoch: 10.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2667156371863314		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.2667156371863314 | validation: 0.34046030140484035]
	TIME [epoch: 10.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28422074284551646		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.28422074284551646 | validation: 0.30332359667568054]
	TIME [epoch: 10.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34356744827335406		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.34356744827335406 | validation: 0.38148292141944096]
	TIME [epoch: 10.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3319933520264087		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.3319933520264087 | validation: 0.49085978050711476]
	TIME [epoch: 10.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3997549553865179		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.3997549553865179 | validation: 0.27773663781006563]
	TIME [epoch: 10.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3382533953781671		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.3382533953781671 | validation: 0.5725643781674729]
	TIME [epoch: 10.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7659029197870153		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.7659029197870153 | validation: 0.5115117339785706]
	TIME [epoch: 10.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4443877764931831		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.4443877764931831 | validation: 0.3628133925753331]
	TIME [epoch: 10.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.358616336979191		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.358616336979191 | validation: 0.3546381716203624]
	TIME [epoch: 10.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3412400653534471		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.3412400653534471 | validation: 0.3587298232222468]
	TIME [epoch: 10.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31234738107198545		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.31234738107198545 | validation: 0.24178555815332609]
	TIME [epoch: 10.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2656639036235051		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.2656639036235051 | validation: 0.5233455034374542]
	TIME [epoch: 10.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3446147535558074		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.3446147535558074 | validation: 0.29784284713957887]
	TIME [epoch: 10.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285115471108937		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.3285115471108937 | validation: 0.4137321577978776]
	TIME [epoch: 10.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4887766308576559		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.4887766308576559 | validation: 0.39475025658373275]
	TIME [epoch: 10.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3680403187606644		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.3680403187606644 | validation: 0.3229561456252666]
	TIME [epoch: 10.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39524447813347735		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.39524447813347735 | validation: 0.30281596724966714]
	TIME [epoch: 10.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3505929007927401		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 0.3505929007927401 | validation: 0.3090789928674961]
	TIME [epoch: 10.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28233623122417334		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.28233623122417334 | validation: 0.5100770193723336]
	TIME [epoch: 10.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37767095581469795		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.37767095581469795 | validation: 0.45886548362487867]
	TIME [epoch: 10.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33203921845328105		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.33203921845328105 | validation: 0.2694241240357493]
	TIME [epoch: 10.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36621156303614644		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.36621156303614644 | validation: 0.3822646670689332]
	TIME [epoch: 10.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26864467108373813		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.26864467108373813 | validation: 0.29787125040559487]
	TIME [epoch: 10.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.268941651409743		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.268941651409743 | validation: 0.381880239137532]
	TIME [epoch: 10.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41269266420274864		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.41269266420274864 | validation: 0.2837933595934538]
	TIME [epoch: 10.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2417175856469711		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.2417175856469711 | validation: 0.1825879968192557]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21409649190438965		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.21409649190438965 | validation: 0.27393363822845956]
	TIME [epoch: 10.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2229498442131809		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.2229498442131809 | validation: 0.25492919839113737]
	TIME [epoch: 10.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4806896439721705		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.4806896439721705 | validation: 0.5813378086757075]
	TIME [epoch: 10.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4134032206862132		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.4134032206862132 | validation: 0.4777497774928433]
	TIME [epoch: 10.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3962918635027292		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.3962918635027292 | validation: 0.24430568674207945]
	TIME [epoch: 10.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28390646806919934		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.28390646806919934 | validation: 0.411685688063091]
	TIME [epoch: 10.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3464712725791319		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.3464712725791319 | validation: 0.4304891447773531]
	TIME [epoch: 10.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5880457080416222		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.5880457080416222 | validation: 0.9722370880525338]
	TIME [epoch: 10.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5404308206450186		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.5404308206450186 | validation: 0.3221700719299658]
	TIME [epoch: 10.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35467019223030694		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.35467019223030694 | validation: 0.6498164628944404]
	TIME [epoch: 10.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49753533077416295		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.49753533077416295 | validation: 0.2988981816773436]
	TIME [epoch: 10.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3024934958667485		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.3024934958667485 | validation: 0.40868767802570616]
	TIME [epoch: 10.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932610942466264		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.2932610942466264 | validation: 0.3771239366797843]
	TIME [epoch: 10.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.323956069068029		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.323956069068029 | validation: 0.31053816154075803]
	TIME [epoch: 10.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3650653624169909		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.3650653624169909 | validation: 0.5116426961874302]
	TIME [epoch: 10.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5162490255985925		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.5162490255985925 | validation: 0.2151763591315318]
	TIME [epoch: 10.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2802268664507759		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.2802268664507759 | validation: 0.4366190453971368]
	TIME [epoch: 10.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44295747692355186		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.44295747692355186 | validation: 0.3327044753299842]
	TIME [epoch: 10.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2904997700370558		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.2904997700370558 | validation: 0.677714583130919]
	TIME [epoch: 10.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40203231172988707		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.40203231172988707 | validation: 0.2007518564766338]
	TIME [epoch: 10.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999170754694374		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.2999170754694374 | validation: 0.3235110783060039]
	TIME [epoch: 10.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27816122969583323		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.27816122969583323 | validation: 0.30839006897957594]
	TIME [epoch: 10.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2652558126325325		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.2652558126325325 | validation: 0.3236875926586083]
	TIME [epoch: 10.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39448490261290664		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.39448490261290664 | validation: 0.23719181749795495]
	TIME [epoch: 10.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37373325549102004		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.37373325549102004 | validation: 0.2651935507400759]
	TIME [epoch: 10.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33132974575922003		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.33132974575922003 | validation: 0.42063325372644733]
	TIME [epoch: 10.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2809363606935126		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.2809363606935126 | validation: 0.39178038521422265]
	TIME [epoch: 10.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29564058799705417		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.29564058799705417 | validation: 0.22782598916112776]
	TIME [epoch: 10.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33951878948406333		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.33951878948406333 | validation: 0.4525497263279647]
	TIME [epoch: 10.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3823825408298947		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.3823825408298947 | validation: 0.5765577609374636]
	TIME [epoch: 10.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39196915010023636		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.39196915010023636 | validation: 0.34828335041068414]
	TIME [epoch: 10.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38840563435722947		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.38840563435722947 | validation: 0.26527082974930005]
	TIME [epoch: 10.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29779951461429716		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.29779951461429716 | validation: 0.3340854145678223]
	TIME [epoch: 10.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261525492302596		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.3261525492302596 | validation: 0.3011369882729234]
	TIME [epoch: 10.2 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636546390208942		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.2636546390208942 | validation: 0.27302781894286965]
	TIME [epoch: 10.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20281441605785852		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.20281441605785852 | validation: 0.3653669065533164]
	TIME [epoch: 10.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20476433864790394		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.20476433864790394 | validation: 0.3804288566342671]
	TIME [epoch: 10.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31488814157106254		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.31488814157106254 | validation: 0.2433437792320226]
	TIME [epoch: 10.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21958345315902683		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.21958345315902683 | validation: 0.20366357915344446]
	TIME [epoch: 10.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2679810009806881		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.2679810009806881 | validation: 0.2740394998818896]
	TIME [epoch: 10.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2548229385354881		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.2548229385354881 | validation: 0.22512475783058136]
	TIME [epoch: 10.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767686432238855		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.2767686432238855 | validation: 0.16648116984008934]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24671397512968607		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.24671397512968607 | validation: 0.37609823997740494]
	TIME [epoch: 10.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35485477150381717		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.35485477150381717 | validation: 0.2532675113153967]
	TIME [epoch: 10.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26007173757649843		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.26007173757649843 | validation: 0.3571236755644688]
	TIME [epoch: 10.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28104263508461547		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.28104263508461547 | validation: 0.44112319271001116]
	TIME [epoch: 10.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322987152200703		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.5322987152200703 | validation: 0.47831123977125667]
	TIME [epoch: 10.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27926323972773553		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.27926323972773553 | validation: 0.206167450418173]
	TIME [epoch: 10.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366040596065436		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.2366040596065436 | validation: 0.23548876167602623]
	TIME [epoch: 10.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22560711260731967		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.22560711260731967 | validation: 0.34306741519700423]
	TIME [epoch: 10.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32749008699181553		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.32749008699181553 | validation: 0.43095553384503665]
	TIME [epoch: 10.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2829743147296031		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.2829743147296031 | validation: 0.2512456369440309]
	TIME [epoch: 10.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974214388906474		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.2974214388906474 | validation: 0.2857442806175816]
	TIME [epoch: 10.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702312549767267		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.2702312549767267 | validation: 0.22807210755367352]
	TIME [epoch: 10.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2104265201277551		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.2104265201277551 | validation: 0.18599513943423934]
	TIME [epoch: 10.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2995780221082688		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.2995780221082688 | validation: 0.3046981283260901]
	TIME [epoch: 10.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2933160961262647		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.2933160961262647 | validation: 0.23767612745819136]
	TIME [epoch: 10.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.213383238251678		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.213383238251678 | validation: 0.3013084470002081]
	TIME [epoch: 10.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21807790254829226		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.21807790254829226 | validation: 0.3607073908760897]
	TIME [epoch: 10.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3124894907663576		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.3124894907663576 | validation: 0.24840754799786205]
	TIME [epoch: 10.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32023780520584444		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.32023780520584444 | validation: 0.20553306052747328]
	TIME [epoch: 10.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2524995905019736		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.2524995905019736 | validation: 0.31552255177925664]
	TIME [epoch: 10.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26971140761720064		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.26971140761720064 | validation: 0.2675366646649309]
	TIME [epoch: 10.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3117329980809869		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.3117329980809869 | validation: 0.3508086557288152]
	TIME [epoch: 10.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932740310231683		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.2932740310231683 | validation: 0.4488191971546797]
	TIME [epoch: 10.3 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32823271634105894		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.32823271634105894 | validation: 0.23241059707212317]
	TIME [epoch: 10.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22669619992781875		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.22669619992781875 | validation: 0.2702864099884989]
	TIME [epoch: 10.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2361636842007718		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.2361636842007718 | validation: 0.21533742065241568]
	TIME [epoch: 10.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.266696253288057		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.266696253288057 | validation: 0.25532188210832507]
	TIME [epoch: 10.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032194602051803		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.3032194602051803 | validation: 0.319086108858779]
	TIME [epoch: 10.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27392378712273835		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.27392378712273835 | validation: 0.2842272155890541]
	TIME [epoch: 10.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26776959576859477		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.26776959576859477 | validation: 0.2455731637243539]
	TIME [epoch: 10.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719916816742204		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.2719916816742204 | validation: 0.40488851690967437]
	TIME [epoch: 10.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22451574222544388		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.22451574222544388 | validation: 0.20006717083224757]
	TIME [epoch: 10.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2659318209908868		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.2659318209908868 | validation: 0.3010531543581077]
	TIME [epoch: 10.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47225956422825865		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.47225956422825865 | validation: 0.43076852072649785]
	TIME [epoch: 10.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3883192935453844		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.3883192935453844 | validation: 0.30154980974562695]
	TIME [epoch: 10.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23608857707814496		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.23608857707814496 | validation: 0.5399884800369931]
	TIME [epoch: 10.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5770685433107301		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.5770685433107301 | validation: 0.27734243274192]
	TIME [epoch: 10.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3821675941406232		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.3821675941406232 | validation: 0.47049301357140044]
	TIME [epoch: 10.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2988505906329188		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.2988505906329188 | validation: 0.3067145648928543]
	TIME [epoch: 10.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734194640240851		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.2734194640240851 | validation: 0.2225038963946949]
	TIME [epoch: 10.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30145302102368304		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.30145302102368304 | validation: 0.4644938717914026]
	TIME [epoch: 10.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975504461386523		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.2975504461386523 | validation: 0.26650412532683554]
	TIME [epoch: 10.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.314081432518006		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.314081432518006 | validation: 0.19672983395353322]
	TIME [epoch: 10.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.290615890999806		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.290615890999806 | validation: 0.2586760310379117]
	TIME [epoch: 10.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23286017043230553		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.23286017043230553 | validation: 0.2469664279397948]
	TIME [epoch: 10.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28096236402369124		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.28096236402369124 | validation: 0.3212763032853751]
	TIME [epoch: 10.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24656770409761367		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.24656770409761367 | validation: 0.22443521128327887]
	TIME [epoch: 10.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24012708273730882		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.24012708273730882 | validation: 0.3479853626070908]
	TIME [epoch: 10.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31954576756997355		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.31954576756997355 | validation: 0.35557627887436144]
	TIME [epoch: 10.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2720605799813054		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.2720605799813054 | validation: 0.22711178008153993]
	TIME [epoch: 10.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2845538785665742		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.2845538785665742 | validation: 0.28203968615251607]
	TIME [epoch: 10.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32897387210493767		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.32897387210493767 | validation: 0.247309460753684]
	TIME [epoch: 10.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21413137638407567		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.21413137638407567 | validation: 0.3478587110742388]
	TIME [epoch: 10.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4949544708024892		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.4949544708024892 | validation: 0.44784719792963756]
	TIME [epoch: 10.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4131289345134455		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.4131289345134455 | validation: 0.2960159710316763]
	TIME [epoch: 10.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3080261691012874		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.3080261691012874 | validation: 0.23479877828807488]
	TIME [epoch: 10.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21358935716168684		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.21358935716168684 | validation: 0.21530929399628218]
	TIME [epoch: 10.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24343500245764518		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.24343500245764518 | validation: 0.25960043613529876]
	TIME [epoch: 10.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23481105393972385		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.23481105393972385 | validation: 0.1945537674061056]
	TIME [epoch: 10.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35137431238094646		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.35137431238094646 | validation: 0.193513310732387]
	TIME [epoch: 10.3 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18314386265182309		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.18314386265182309 | validation: 0.3081535706404216]
	TIME [epoch: 10.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2761526204632044		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.2761526204632044 | validation: 0.42721754439156573]
	TIME [epoch: 10.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3800676153108212		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.3800676153108212 | validation: 0.3062423478914636]
	TIME [epoch: 10.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32293081327300327		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.32293081327300327 | validation: 0.21947487534666124]
	TIME [epoch: 10.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2166734095305603		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.2166734095305603 | validation: 0.28047013871005294]
	TIME [epoch: 10.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26093982815208794		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.26093982815208794 | validation: 0.26475101931515777]
	TIME [epoch: 10.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21279101713303494		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.21279101713303494 | validation: 0.20752770635689152]
	TIME [epoch: 10.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21554065590774935		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.21554065590774935 | validation: 0.18557187666072517]
	TIME [epoch: 10.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875443042445992		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.2875443042445992 | validation: 0.24244940121966355]
	TIME [epoch: 10.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636200495003568		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.2636200495003568 | validation: 0.42009190342143127]
	TIME [epoch: 10.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3992533771797983		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.3992533771797983 | validation: 0.46491175743947794]
	TIME [epoch: 10.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3301632794652092		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.3301632794652092 | validation: 0.34819356941551005]
	TIME [epoch: 10.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24696694787593354		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.24696694787593354 | validation: 0.20398688052589237]
	TIME [epoch: 10.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21666472442183782		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.21666472442183782 | validation: 0.2135560526674003]
	TIME [epoch: 10.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21409253878670703		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.21409253878670703 | validation: 0.26557241789038377]
	TIME [epoch: 10.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2469703160499397		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.2469703160499397 | validation: 0.3101142988776182]
	TIME [epoch: 10.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573069009162353		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.2573069009162353 | validation: 0.32174544900285945]
	TIME [epoch: 10.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22551780997575666		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.22551780997575666 | validation: 0.24957894313569576]
	TIME [epoch: 10.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3398431140475885		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.3398431140475885 | validation: 0.21299663534913116]
	TIME [epoch: 10.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2917747890768583		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.2917747890768583 | validation: 0.33727160960778074]
	TIME [epoch: 10.3 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.291214621988216		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.291214621988216 | validation: 0.25602541059625616]
	TIME [epoch: 10.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.214555696110504		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.214555696110504 | validation: 0.29458186683451065]
	TIME [epoch: 10.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2275797046918801		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.2275797046918801 | validation: 0.26208004245360766]
	TIME [epoch: 10.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18927757762556785		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.18927757762556785 | validation: 0.26314100002484203]
	TIME [epoch: 10.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26303771597084985		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.26303771597084985 | validation: 0.2574093002588486]
	TIME [epoch: 10.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26013483605195875		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.26013483605195875 | validation: 0.22459963605168093]
	TIME [epoch: 10.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21171323713054302		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.21171323713054302 | validation: 0.34238318189055333]
	TIME [epoch: 10.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173859545223392		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.5173859545223392 | validation: 0.45062250135116194]
	TIME [epoch: 10.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42259360354483055		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.42259360354483055 | validation: 0.4835237486336448]
	TIME [epoch: 10.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4581951723841707		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.4581951723841707 | validation: 0.365579131588065]
	TIME [epoch: 10.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33919811265873684		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.33919811265873684 | validation: 0.24309928197803124]
	TIME [epoch: 10.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24338629299148068		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.24338629299148068 | validation: 0.36171114341963106]
	TIME [epoch: 10.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25057557364900707		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.25057557364900707 | validation: 0.2065066026463443]
	TIME [epoch: 10.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2244167309020552		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.2244167309020552 | validation: 0.2941908283412624]
	TIME [epoch: 10.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26040844921933165		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.26040844921933165 | validation: 0.45412528438195593]
	TIME [epoch: 10.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34747525809148083		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.34747525809148083 | validation: 0.20155044873474892]
	TIME [epoch: 10.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2035766732791457		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.2035766732791457 | validation: 0.23224674923794553]
	TIME [epoch: 10.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23298026506250574		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.23298026506250574 | validation: 0.22122346273309976]
	TIME [epoch: 10.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21895554436328188		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.21895554436328188 | validation: 0.5016485457651535]
	TIME [epoch: 10.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2980854072819378		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.2980854072819378 | validation: 0.25388089851658274]
	TIME [epoch: 10.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21126474690841465		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.21126474690841465 | validation: 0.26183917566106607]
	TIME [epoch: 10.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32904466790577414		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.32904466790577414 | validation: 0.39843012714794285]
	TIME [epoch: 10.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32080241958361977		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.32080241958361977 | validation: 0.3295986291042857]
	TIME [epoch: 10.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651749854788623		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.2651749854788623 | validation: 0.4150457101890247]
	TIME [epoch: 10.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036744865952527		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.3036744865952527 | validation: 0.2611400996873601]
	TIME [epoch: 10.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23657819005545183		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.23657819005545183 | validation: 0.29243006760146567]
	TIME [epoch: 10.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875654791134193		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.2875654791134193 | validation: 0.28201330028927385]
	TIME [epoch: 10.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33095627372554737		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.33095627372554737 | validation: 0.32183376423939886]
	TIME [epoch: 10.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3354559596806877		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.3354559596806877 | validation: 0.40994220541682536]
	TIME [epoch: 10.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3520382745049571		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.3520382745049571 | validation: 0.4305451932374058]
	TIME [epoch: 10.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4059050980298496		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.4059050980298496 | validation: 0.2924781510542096]
	TIME [epoch: 10.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2743055674501137		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.2743055674501137 | validation: 0.21648465323840468]
	TIME [epoch: 10.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20092736650371545		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.20092736650371545 | validation: 0.21713574711618616]
	TIME [epoch: 10.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19101748805363164		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.19101748805363164 | validation: 0.22202764775530662]
	TIME [epoch: 10.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28540218897994835		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.28540218897994835 | validation: 0.35232668464607747]
	TIME [epoch: 10.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.230954486873621		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.230954486873621 | validation: 0.25071338463301607]
	TIME [epoch: 10.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749239609713684		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.2749239609713684 | validation: 0.6415155891614274]
	TIME [epoch: 10.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46671550975225246		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.46671550975225246 | validation: 0.490708246624251]
	TIME [epoch: 10.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31227963610701587		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.31227963610701587 | validation: 0.2735484076734618]
	TIME [epoch: 10.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2777000733250767		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.2777000733250767 | validation: 0.33618094214513883]
	TIME [epoch: 10.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3699464088255702		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.3699464088255702 | validation: 0.3737515516606325]
	TIME [epoch: 10.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27349069478189025		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.27349069478189025 | validation: 0.22041982665906765]
	TIME [epoch: 10.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2628625167055498		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.2628625167055498 | validation: 0.2866613143790071]
	TIME [epoch: 10.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27890935545978274		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.27890935545978274 | validation: 0.2808768759299093]
	TIME [epoch: 10.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2201166938501923		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.2201166938501923 | validation: 0.28822205674282925]
	TIME [epoch: 10.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.283065630519422		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.283065630519422 | validation: 0.2833932217297449]
	TIME [epoch: 10.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609973949599532		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.2609973949599532 | validation: 0.28162553182244204]
	TIME [epoch: 10.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24867797936366473		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.24867797936366473 | validation: 0.24028440442723115]
	TIME [epoch: 10.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24593461421854418		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.24593461421854418 | validation: 0.3335706012832261]
	TIME [epoch: 10.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134418622529991		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.3134418622529991 | validation: 0.3018143037363897]
	TIME [epoch: 10.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2759888040035298		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.2759888040035298 | validation: 0.25218227244541247]
	TIME [epoch: 10.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32063612322312385		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.32063612322312385 | validation: 0.41677862015427364]
	TIME [epoch: 10.3 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2941363881125561		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.2941363881125561 | validation: 0.2271299171365391]
	TIME [epoch: 10.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20877602688515456		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.20877602688515456 | validation: 0.24262479992912192]
	TIME [epoch: 10.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3736209256833576		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.3736209256833576 | validation: 0.31420943627380793]
	TIME [epoch: 10.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24897967088379538		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.24897967088379538 | validation: 0.30813897021446857]
	TIME [epoch: 10.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22698920507808534		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.22698920507808534 | validation: 0.235806454024261]
	TIME [epoch: 10.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19881892658332143		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.19881892658332143 | validation: 0.2694225258145795]
	TIME [epoch: 10.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21265022385859242		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.21265022385859242 | validation: 0.29158565958454913]
	TIME [epoch: 10.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24600876591663537		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.24600876591663537 | validation: 0.2624287628087102]
	TIME [epoch: 10.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22303215733391726		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.22303215733391726 | validation: 0.2304067601272846]
	TIME [epoch: 10.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19961200696742618		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.19961200696742618 | validation: 0.21610322900500098]
	TIME [epoch: 10.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2468177786898374		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.2468177786898374 | validation: 0.31808792469605157]
	TIME [epoch: 10.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2380982505356813		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.2380982505356813 | validation: 0.22127880740813724]
	TIME [epoch: 10.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23253204053886325		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.23253204053886325 | validation: 0.22331823097763617]
	TIME [epoch: 10.3 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31104028626376384		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.31104028626376384 | validation: 0.2587511203342833]
	TIME [epoch: 10.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21118715879268785		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.21118715879268785 | validation: 0.2603738348827199]
	TIME [epoch: 10.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3320081078670932		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.3320081078670932 | validation: 0.27224651255501847]
	TIME [epoch: 10.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22094953300851405		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.22094953300851405 | validation: 0.17326699381150992]
	TIME [epoch: 10.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613591938049063		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.2613591938049063 | validation: 0.27927764768975577]
	TIME [epoch: 10.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20431973979477394		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.20431973979477394 | validation: 0.21169182658647784]
	TIME [epoch: 10.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17533838086970424		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.17533838086970424 | validation: 0.28419807336066877]
	TIME [epoch: 10.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512354469558714		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.2512354469558714 | validation: 0.22494309174463317]
	TIME [epoch: 10.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16573520247784806		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.16573520247784806 | validation: 0.33449793700597524]
	TIME [epoch: 10.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21072989209013468		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.21072989209013468 | validation: 0.1996305681797294]
	TIME [epoch: 10.3 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3225877392914501		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.3225877392914501 | validation: 0.41954408312232616]
	TIME [epoch: 10.3 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3501252228851661		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.3501252228851661 | validation: 0.30978008613567726]
	TIME [epoch: 10.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27785128708656254		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.27785128708656254 | validation: 0.3136336304219152]
	TIME [epoch: 10.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30670384914499343		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.30670384914499343 | validation: 0.4623532767723067]
	TIME [epoch: 10.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3172329681053798		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.3172329681053798 | validation: 0.2271824527427563]
	TIME [epoch: 10.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26706580925803186		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.26706580925803186 | validation: 0.22204806209958972]
	TIME [epoch: 10.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19738643994373187		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.19738643994373187 | validation: 0.19876337181851264]
	TIME [epoch: 10.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17642476437086324		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.17642476437086324 | validation: 0.18923152199618654]
	TIME [epoch: 10.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28695172284223364		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.28695172284223364 | validation: 0.29463383030443924]
	TIME [epoch: 10.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.323711258814851		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.323711258814851 | validation: 0.41137237926884845]
	TIME [epoch: 10.3 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2614999309911127		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.2614999309911127 | validation: 0.24897193382800709]
	TIME [epoch: 10.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20840374349238439		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.20840374349238439 | validation: 0.206421795379923]
	TIME [epoch: 10.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.178330421798369		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.178330421798369 | validation: 0.21713019745820789]
	TIME [epoch: 10.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20629347481460583		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.20629347481460583 | validation: 0.2444676804942597]
	TIME [epoch: 10.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31171867088716054		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.31171867088716054 | validation: 0.3046552620522281]
	TIME [epoch: 10.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31122761365417195		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.31122761365417195 | validation: 0.24432416589448466]
	TIME [epoch: 10.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767702761234646		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.2767702761234646 | validation: 0.3580530314368997]
	TIME [epoch: 10.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29014821770668386		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.29014821770668386 | validation: 0.3055303516192343]
	TIME [epoch: 10.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21995531015891873		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.21995531015891873 | validation: 0.25153829104126213]
	TIME [epoch: 10.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2033106486655265		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.2033106486655265 | validation: 0.2176672214942578]
	TIME [epoch: 10.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2344826054018762		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.2344826054018762 | validation: 0.2699127558456355]
	TIME [epoch: 10.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22694687140311834		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.22694687140311834 | validation: 0.2309716889659719]
	TIME [epoch: 10.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19436840105968628		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.19436840105968628 | validation: 0.24060866963694924]
	TIME [epoch: 10.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17527925009775763		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.17527925009775763 | validation: 0.28841346719442185]
	TIME [epoch: 10.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21116058476921426		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.21116058476921426 | validation: 0.17097336338299837]
	TIME [epoch: 10.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613210858066165		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.1613210858066165 | validation: 0.26903534297292153]
	TIME [epoch: 10.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23228108878071518		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.23228108878071518 | validation: 0.242347881077903]
	TIME [epoch: 10.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2602404808403582		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.2602404808403582 | validation: 0.2871468304196207]
	TIME [epoch: 10.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2314492096279399		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.2314492096279399 | validation: 0.38508446982925615]
	TIME [epoch: 10.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30172364904821086		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.30172364904821086 | validation: 0.27076037527196856]
	TIME [epoch: 10.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33168290248006543		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.33168290248006543 | validation: 0.20658817011769032]
	TIME [epoch: 10.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26586750401189735		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.26586750401189735 | validation: 0.2626304153985447]
	TIME [epoch: 10.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2737296055623174		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.2737296055623174 | validation: 0.3350444051216153]
	TIME [epoch: 10.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27893918961232983		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.27893918961232983 | validation: 0.2463603553268446]
	TIME [epoch: 10.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24118788915761974		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.24118788915761974 | validation: 0.23534072978412732]
	TIME [epoch: 10.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20634897595927376		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.20634897595927376 | validation: 0.262431996053618]
	TIME [epoch: 10.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24190365303407213		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.24190365303407213 | validation: 0.2573079160157247]
	TIME [epoch: 10.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1972705039688111		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.1972705039688111 | validation: 0.24783295888374604]
	TIME [epoch: 10.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22112364536531198		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.22112364536531198 | validation: 0.40867726395901316]
	TIME [epoch: 10.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36087353177357945		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.36087353177357945 | validation: 0.24757745153640084]
	TIME [epoch: 10.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881689472910145		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.1881689472910145 | validation: 0.21263710082877255]
	TIME [epoch: 10.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19591112212203687		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.19591112212203687 | validation: 0.2039956666425362]
	TIME [epoch: 10.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2257041205499414		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.2257041205499414 | validation: 0.21428128218323816]
	TIME [epoch: 10.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19405843788998728		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.19405843788998728 | validation: 0.189066758710797]
	TIME [epoch: 10.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19655812779326398		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.19655812779326398 | validation: 0.20561348702571614]
	TIME [epoch: 10.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33706597014163064		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.33706597014163064 | validation: 0.6028072448404354]
	TIME [epoch: 10.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4257693411468155		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.4257693411468155 | validation: 0.2520942463560992]
	TIME [epoch: 10.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1949297052245825		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.1949297052245825 | validation: 0.26704344621036546]
	TIME [epoch: 10.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44527632076871715		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.44527632076871715 | validation: 0.8692089152821157]
	TIME [epoch: 10.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.54240232049128		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.54240232049128 | validation: 0.2897983345378405]
	TIME [epoch: 10.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23245079044585298		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.23245079044585298 | validation: 0.2289693950484722]
	TIME [epoch: 10.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.221492959469845		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.221492959469845 | validation: 0.3100881506398035]
	TIME [epoch: 10.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24447643012048603		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.24447643012048603 | validation: 0.24293579304237908]
	TIME [epoch: 10.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1847635609487673		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.1847635609487673 | validation: 0.3170218252330762]
	TIME [epoch: 10.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23993541972288587		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.23993541972288587 | validation: 0.3839438413549898]
	TIME [epoch: 10.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25267492401453817		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.25267492401453817 | validation: 0.26007233643106803]
	TIME [epoch: 10.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24694123010718236		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.24694123010718236 | validation: 0.35322384795686623]
	TIME [epoch: 10.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23273273294178498		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.23273273294178498 | validation: 0.22221184159959456]
	TIME [epoch: 10.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18557471138666784		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.18557471138666784 | validation: 0.23680938108422112]
	TIME [epoch: 10.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21940910686981505		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.21940910686981505 | validation: 0.22664908095204472]
	TIME [epoch: 10.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2722455866068098		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.2722455866068098 | validation: 0.3575862086579684]
	TIME [epoch: 10.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25995203019338037		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.25995203019338037 | validation: 0.3283440124941899]
	TIME [epoch: 10.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27789941384605477		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.27789941384605477 | validation: 0.31314141143857366]
	TIME [epoch: 10.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33130507165409073		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.33130507165409073 | validation: 0.394267906319755]
	TIME [epoch: 10.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25971668348548993		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.25971668348548993 | validation: 0.22763622871332204]
	TIME [epoch: 10.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1982181229652175		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.1982181229652175 | validation: 0.2993948151618328]
	TIME [epoch: 10.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21341175617213368		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.21341175617213368 | validation: 0.1857886743914809]
	TIME [epoch: 10.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15919212859290555		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.15919212859290555 | validation: 0.26139337540337565]
	TIME [epoch: 10.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24409516804517223		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.24409516804517223 | validation: 0.23144742363193233]
	TIME [epoch: 10.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19983583072216377		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.19983583072216377 | validation: 0.24513272557834215]
	TIME [epoch: 10.2 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20061687708465378		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.20061687708465378 | validation: 0.25766861125179313]
	TIME [epoch: 10.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17527312535552048		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.17527312535552048 | validation: 0.2077195041095731]
	TIME [epoch: 10.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16155589051910177		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.16155589051910177 | validation: 0.22298504265059238]
	TIME [epoch: 10.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2277033299027586		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.2277033299027586 | validation: 0.3263291553475541]
	TIME [epoch: 10.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2860172642886968		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.2860172642886968 | validation: 0.2853038960270453]
	TIME [epoch: 10.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19087792499100392		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.19087792499100392 | validation: 0.23896428921115218]
	TIME [epoch: 10.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19832828390175522		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.19832828390175522 | validation: 0.2616620356849143]
	TIME [epoch: 10.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21422502801915294		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.21422502801915294 | validation: 0.168999233459747]
	TIME [epoch: 10.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16920385195381388		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.16920385195381388 | validation: 0.188818622141299]
	TIME [epoch: 10.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2025143948745388		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.2025143948745388 | validation: 0.23375515531805552]
	TIME [epoch: 10.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19450450526674518		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.19450450526674518 | validation: 0.23993238318201995]
	TIME [epoch: 10.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2259975145236234		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.2259975145236234 | validation: 0.3528859836398362]
	TIME [epoch: 10.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974424597993973		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.2974424597993973 | validation: 0.28814987757680544]
	TIME [epoch: 10.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24005064935967485		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.24005064935967485 | validation: 0.2490859037602372]
	TIME [epoch: 10.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2276878799328268		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.2276878799328268 | validation: 0.4704695181920201]
	TIME [epoch: 10.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2698391974355256		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.2698391974355256 | validation: 0.25724458952141555]
	TIME [epoch: 10.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394553192074635		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.2394553192074635 | validation: 0.23630416804869928]
	TIME [epoch: 10.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22195398866127233		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.22195398866127233 | validation: 0.2544535086071166]
	TIME [epoch: 10.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24011279014434045		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.24011279014434045 | validation: 0.212323563935467]
	TIME [epoch: 10.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18795468069596358		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.18795468069596358 | validation: 0.2720328584762752]
	TIME [epoch: 10.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24951667742159378		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.24951667742159378 | validation: 0.1685136828948191]
	TIME [epoch: 10.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18202745092370512		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.18202745092370512 | validation: 0.21570619291983925]
	TIME [epoch: 10.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19019519527995227		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.19019519527995227 | validation: 0.24872428498743163]
	TIME [epoch: 10.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17810879064372193		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.17810879064372193 | validation: 0.16373005660460394]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17154240333965182		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.17154240333965182 | validation: 0.2717659170170038]
	TIME [epoch: 10.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2094801021124598		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.2094801021124598 | validation: 0.18522743888201512]
	TIME [epoch: 10.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24880639796771487		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.24880639796771487 | validation: 0.2824868287219964]
	TIME [epoch: 10.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2487056993855845		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.2487056993855845 | validation: 0.18922982850165818]
	TIME [epoch: 10.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18673362410809669		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.18673362410809669 | validation: 0.17384960399024138]
	TIME [epoch: 10.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21335097576113538		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.21335097576113538 | validation: 0.18564265760118076]
	TIME [epoch: 10.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2245402375201742		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.2245402375201742 | validation: 0.305097847009382]
	TIME [epoch: 10.3 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2779320593659712		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.2779320593659712 | validation: 0.28637279641299035]
	TIME [epoch: 10.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3061300418749478		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.3061300418749478 | validation: 0.20249492171160755]
	TIME [epoch: 10.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17298941201187015		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.17298941201187015 | validation: 0.1804074730633507]
	TIME [epoch: 10.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14981431463294248		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.14981431463294248 | validation: 0.21657990434073526]
	TIME [epoch: 10.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15336911683865334		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.15336911683865334 | validation: 0.16077488997096862]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_883.pth
	Model improved!!!
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1997145935689149		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.1997145935689149 | validation: 0.2584012839935572]
	TIME [epoch: 10.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19702562981616012		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.19702562981616012 | validation: 0.21016680712501992]
	TIME [epoch: 10.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19387460270017065		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.19387460270017065 | validation: 0.17208239160436806]
	TIME [epoch: 10.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19330145473589974		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.19330145473589974 | validation: 0.31082532291072773]
	TIME [epoch: 10.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2487610795584927		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.2487610795584927 | validation: 0.39557028017447154]
	TIME [epoch: 10.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3206621113030371		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.3206621113030371 | validation: 0.31703420080457373]
	TIME [epoch: 10.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944720706463098		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.2944720706463098 | validation: 0.2835217007463514]
	TIME [epoch: 10.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17978351392245986		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.17978351392245986 | validation: 0.17214256506923623]
	TIME [epoch: 10.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19228123505754283		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.19228123505754283 | validation: 0.24400126120795057]
	TIME [epoch: 10.3 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26135216752055734		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.26135216752055734 | validation: 0.3590145784166609]
	TIME [epoch: 10.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3540204043423585		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.3540204043423585 | validation: 0.32300348377799104]
	TIME [epoch: 10.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2835468412896792		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.2835468412896792 | validation: 0.322527900060506]
	TIME [epoch: 10.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3130440113658751		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.3130440113658751 | validation: 0.29991624182972454]
	TIME [epoch: 10.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23491997943052284		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.23491997943052284 | validation: 0.3320368161039586]
	TIME [epoch: 10.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3099766947244141		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.3099766947244141 | validation: 0.22211622967862074]
	TIME [epoch: 10.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20554319588039097		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.20554319588039097 | validation: 0.22941624347134293]
	TIME [epoch: 10.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770482097983421		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.1770482097983421 | validation: 0.2551434453865592]
	TIME [epoch: 10.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19487539440315574		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.19487539440315574 | validation: 0.22370346437584432]
	TIME [epoch: 10.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22951029581939406		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.22951029581939406 | validation: 0.2557819056361757]
	TIME [epoch: 10.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25095919213903434		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.25095919213903434 | validation: 0.26553885199238525]
	TIME [epoch: 10.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3130202385439972		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.3130202385439972 | validation: 0.523997902322117]
	TIME [epoch: 10.3 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297897359768441		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.297897359768441 | validation: 0.37465119860844637]
	TIME [epoch: 10.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24942753628665365		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.24942753628665365 | validation: 0.1881100456562635]
	TIME [epoch: 10.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18664052184917593		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.18664052184917593 | validation: 0.19351731456444832]
	TIME [epoch: 10.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18433231735849326		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.18433231735849326 | validation: 0.19445524218386015]
	TIME [epoch: 10.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16010032257761228		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.16010032257761228 | validation: 0.1737142333896366]
	TIME [epoch: 10.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15029503048368528		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.15029503048368528 | validation: 0.1729621588239693]
	TIME [epoch: 10.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19942826354725124		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.19942826354725124 | validation: 0.2393971865497508]
	TIME [epoch: 10.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2254101245002813		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.2254101245002813 | validation: 0.27664215380123364]
	TIME [epoch: 10.3 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23827786178592264		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.23827786178592264 | validation: 0.21206923993388269]
	TIME [epoch: 10.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17123050730290706		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.17123050730290706 | validation: 0.20828549767010615]
	TIME [epoch: 10.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17338648808964413		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.17338648808964413 | validation: 0.22627551391400932]
	TIME [epoch: 10.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22676199881683234		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.22676199881683234 | validation: 0.18009797778568984]
	TIME [epoch: 10.3 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311758333681466		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.15311758333681466 | validation: 0.17610217237182169]
	TIME [epoch: 10.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721891727214162		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.1721891727214162 | validation: 0.1940748873918894]
	TIME [epoch: 10.2 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14389012223530337		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.14389012223530337 | validation: 0.15876728616724387]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_919.pth
	Model improved!!!
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19645730413031526		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.19645730413031526 | validation: 0.2431430815058285]
	TIME [epoch: 10.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2059481257598134		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.2059481257598134 | validation: 0.23701108830494336]
	TIME [epoch: 10.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2549567450963768		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.2549567450963768 | validation: 0.2843032736458413]
	TIME [epoch: 10.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21190611764099185		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.21190611764099185 | validation: 0.25739585486692]
	TIME [epoch: 10.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2114827146866889		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.2114827146866889 | validation: 0.23502381647119827]
	TIME [epoch: 10.3 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15627893153150954		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.15627893153150954 | validation: 0.25092646533835017]
	TIME [epoch: 10.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19744434154439588		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.19744434154439588 | validation: 0.2366119728140391]
	TIME [epoch: 10.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20990663966112919		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.20990663966112919 | validation: 0.320398109597657]
	TIME [epoch: 10.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19926823154678003		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.19926823154678003 | validation: 0.23233036212824737]
	TIME [epoch: 10.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237255862273056		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.2237255862273056 | validation: 0.34751052530267423]
	TIME [epoch: 10.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.272556431446927		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.272556431446927 | validation: 0.32610353224106775]
	TIME [epoch: 10.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24294241964539154		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.24294241964539154 | validation: 0.20831691715398967]
	TIME [epoch: 10.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22272291138729697		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.22272291138729697 | validation: 0.25260812016165596]
	TIME [epoch: 10.3 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18620213120726145		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.18620213120726145 | validation: 0.25385224634389814]
	TIME [epoch: 10.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797374238785291		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.1797374238785291 | validation: 0.2427353897131046]
	TIME [epoch: 10.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17035575702881783		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.17035575702881783 | validation: 0.1801605745239303]
	TIME [epoch: 10.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25394146502678955		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.25394146502678955 | validation: 0.1737614430868892]
	TIME [epoch: 10.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18136726282876717		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.18136726282876717 | validation: 0.16751514218145214]
	TIME [epoch: 10.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24116276509804963		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.24116276509804963 | validation: 0.2243488262342586]
	TIME [epoch: 10.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14632541526288337		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.14632541526288337 | validation: 0.1721735074810285]
	TIME [epoch: 10.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17982293085151768		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.17982293085151768 | validation: 0.2266113288333079]
	TIME [epoch: 10.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21704520756062834		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.21704520756062834 | validation: 0.158901766067402]
	TIME [epoch: 10.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2230997049661915		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.2230997049661915 | validation: 0.2828273193760202]
	TIME [epoch: 10.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2301228305985497		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.2301228305985497 | validation: 0.15248218518741413]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_943.pth
	Model improved!!!
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035288104743034		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.16035288104743034 | validation: 0.18074743094423126]
	TIME [epoch: 10.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2782356599814433		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.2782356599814433 | validation: 0.30645830564923954]
	TIME [epoch: 10.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26621965108808093		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.26621965108808093 | validation: 0.1736395769560356]
	TIME [epoch: 10.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17158583333178506		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.17158583333178506 | validation: 0.1625950217259385]
	TIME [epoch: 10.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16145508933401254		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.16145508933401254 | validation: 0.19293408104797102]
	TIME [epoch: 10.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1763768756018584		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.1763768756018584 | validation: 0.18257332191157588]
	TIME [epoch: 10.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1702942217119385		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.1702942217119385 | validation: 0.2429978337614405]
	TIME [epoch: 10.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22726936112300739		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.22726936112300739 | validation: 0.28950480758092356]
	TIME [epoch: 10.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21924657468591469		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.21924657468591469 | validation: 0.22327386272559963]
	TIME [epoch: 10.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18484132517764557		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.18484132517764557 | validation: 0.25584109024860546]
	TIME [epoch: 10.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25484616309540015		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.25484616309540015 | validation: 0.1830488760167845]
	TIME [epoch: 10.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20196888529604934		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.20196888529604934 | validation: 0.22946812201043063]
	TIME [epoch: 10.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20392953553548282		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.20392953553548282 | validation: 0.2168536616460461]
	TIME [epoch: 10.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19264467470180863		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.19264467470180863 | validation: 0.1888563478384143]
	TIME [epoch: 10.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17577630314194806		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.17577630314194806 | validation: 0.26711195688370504]
	TIME [epoch: 10.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19172492293829854		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.19172492293829854 | validation: 0.20186886923082634]
	TIME [epoch: 10.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605453289452225		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.1605453289452225 | validation: 0.23708370395285275]
	TIME [epoch: 10.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718415304602965		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.1718415304602965 | validation: 0.328271243965382]
	TIME [epoch: 10.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2258375099080611		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.2258375099080611 | validation: 0.21793735716398746]
	TIME [epoch: 10.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20129539304090058		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.20129539304090058 | validation: 0.18043815593974416]
	TIME [epoch: 10.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17335201047251056		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.17335201047251056 | validation: 0.2710603813168147]
	TIME [epoch: 10.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1852236567595273		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.1852236567595273 | validation: 0.1668296928213071]
	TIME [epoch: 10.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21171202166572795		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.21171202166572795 | validation: 0.25475617911762777]
	TIME [epoch: 10.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22550833734565026		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.22550833734565026 | validation: 0.21814792912794656]
	TIME [epoch: 10.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16422804507947514		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.16422804507947514 | validation: 0.2870805747645029]
	TIME [epoch: 10.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2049248690151722		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.2049248690151722 | validation: 0.18181527912228732]
	TIME [epoch: 10.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23924076231186137		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.23924076231186137 | validation: 0.198939092279758]
	TIME [epoch: 10.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18790051953947567		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.18790051953947567 | validation: 0.1625008743588051]
	TIME [epoch: 10.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13291210756082067		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.13291210756082067 | validation: 0.1723081751553259]
	TIME [epoch: 10.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1444031472208831		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.1444031472208831 | validation: 0.2627609708809131]
	TIME [epoch: 10.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19827504266680437		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.19827504266680437 | validation: 0.19932558553513802]
	TIME [epoch: 10.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19130633135668815		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.19130633135668815 | validation: 0.1987761097106506]
	TIME [epoch: 10.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15596104942185823		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.15596104942185823 | validation: 0.22982885528269517]
	TIME [epoch: 10.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613254832085257		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.1613254832085257 | validation: 0.3622833707049503]
	TIME [epoch: 10.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21277510088399404		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.21277510088399404 | validation: 0.2607103814963913]
	TIME [epoch: 10.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16862429389438519		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.16862429389438519 | validation: 0.18092992430731003]
	TIME [epoch: 10.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15757772529973013		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.15757772529973013 | validation: 0.20609171231940285]
	TIME [epoch: 10.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22576912093111634		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.22576912093111634 | validation: 0.2584349244917713]
	TIME [epoch: 10.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18357340623647786		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.18357340623647786 | validation: 0.18066225067251704]
	TIME [epoch: 10.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20944248144225056		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.20944248144225056 | validation: 0.18829952890820567]
	TIME [epoch: 10.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14714887506148028		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.14714887506148028 | validation: 0.1994936539530427]
	TIME [epoch: 10.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1880339864763251		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.1880339864763251 | validation: 0.18592162351324404]
	TIME [epoch: 10.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16241093463371667		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.16241093463371667 | validation: 0.18375756270567323]
	TIME [epoch: 10.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571549150443579		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.1571549150443579 | validation: 0.1770858197523263]
	TIME [epoch: 10.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1944380672077108		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.1944380672077108 | validation: 0.18353855366293012]
	TIME [epoch: 10.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14632616121949166		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.14632616121949166 | validation: 0.1924850781120504]
	TIME [epoch: 10.3 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17449482676532366		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.17449482676532366 | validation: 0.20938876106831053]
	TIME [epoch: 10.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2500033547049041		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.2500033547049041 | validation: 0.20663775543849766]
	TIME [epoch: 10.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15366656226729225		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.15366656226729225 | validation: 0.1908227428389494]
	TIME [epoch: 10.3 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15106228730615212		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.15106228730615212 | validation: 0.19698008108960785]
	TIME [epoch: 10.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16593810480296975		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.16593810480296975 | validation: 0.18306890990766234]
	TIME [epoch: 10.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1980302833304804		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.1980302833304804 | validation: 0.2823048394530988]
	TIME [epoch: 10.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551161049420286		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.1551161049420286 | validation: 0.1617822323513065]
	TIME [epoch: 10.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19084754475712812		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.19084754475712812 | validation: 0.19684782076488702]
	TIME [epoch: 10.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13973552739194817		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.13973552739194817 | validation: 0.21513435618916085]
	TIME [epoch: 10.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17250688004199072		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.17250688004199072 | validation: 0.1757746652507425]
	TIME [epoch: 10.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16283678659614326		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.16283678659614326 | validation: 0.1930961249049029]
	TIME [epoch: 10.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19796899621000788		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.19796899621000788 | validation: 0.2772828912900881]
	TIME [epoch: 10.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1864355977305948		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.1864355977305948 | validation: 0.21920697031472425]
	TIME [epoch: 10.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17819803393941427		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.17819803393941427 | validation: 0.19969934360274647]
	TIME [epoch: 10.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16798180498629434		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.16798180498629434 | validation: 0.18137142510472884]
	TIME [epoch: 10.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749174472796166		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.1749174472796166 | validation: 0.2707739649040517]
	TIME [epoch: 10.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1940789702988432		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.1940789702988432 | validation: 0.19000153634846023]
	TIME [epoch: 10.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16396160733962017		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.16396160733962017 | validation: 0.1924769921864929]
	TIME [epoch: 10.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15644593972609339		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.15644593972609339 | validation: 0.22600568512484587]
	TIME [epoch: 10.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16467978399548072		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.16467978399548072 | validation: 0.16953561908167672]
	TIME [epoch: 10.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17962065740175723		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.17962065740175723 | validation: 0.26189064231602066]
	TIME [epoch: 10.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19086963044550925		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.19086963044550925 | validation: 0.20415599244827384]
	TIME [epoch: 10.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21030755736467124		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.21030755736467124 | validation: 0.2177189815309858]
	TIME [epoch: 10.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185330365044675		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.185330365044675 | validation: 0.22180608306481514]
	TIME [epoch: 10.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1991211452200589		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.1991211452200589 | validation: 0.19800147632516094]
	TIME [epoch: 10.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18554835861481717		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.18554835861481717 | validation: 0.21807184601759363]
	TIME [epoch: 10.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16844629402410577		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.16844629402410577 | validation: 0.15914252576329183]
	TIME [epoch: 10.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1996724010326988		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.1996724010326988 | validation: 0.1549860383555652]
	TIME [epoch: 10.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1914503249430211		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.1914503249430211 | validation: 0.2672118858999107]
	TIME [epoch: 10.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22437765636666612		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.22437765636666612 | validation: 0.30073883384356853]
	TIME [epoch: 10.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36432734677422374		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.36432734677422374 | validation: 0.5057259417292721]
	TIME [epoch: 10.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38394641257360307		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.38394641257360307 | validation: 0.26358979739500904]
	TIME [epoch: 10.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2653078421108231		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.2653078421108231 | validation: 0.26882173970335965]
	TIME [epoch: 10.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2322777754119015		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.2322777754119015 | validation: 0.3363251589994215]
	TIME [epoch: 10.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31475635586116846		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.31475635586116846 | validation: 0.3216578435646026]
	TIME [epoch: 10.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25965982118113146		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.25965982118113146 | validation: 0.19424734600994442]
	TIME [epoch: 10.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17267572821712468		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.17267572821712468 | validation: 0.19518395113139828]
	TIME [epoch: 10.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14793720022960422		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.14793720022960422 | validation: 0.19911366688486928]
	TIME [epoch: 10.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.179991647800502		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.179991647800502 | validation: 0.23396663458896785]
	TIME [epoch: 10.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19542919566970338		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.19542919566970338 | validation: 0.23131595248516668]
	TIME [epoch: 10.3 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16832259760490417		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.16832259760490417 | validation: 0.23280272461746357]
	TIME [epoch: 10.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16910861435958302		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.16910861435958302 | validation: 0.222853424272894]
	TIME [epoch: 10.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19948899374081258		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.19948899374081258 | validation: 0.2401349304516955]
	TIME [epoch: 10.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1990028743554942		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.1990028743554942 | validation: 0.21258999504368484]
	TIME [epoch: 10.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1818281541781376		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.1818281541781376 | validation: 0.23405046862571413]
	TIME [epoch: 10.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19449990709605686		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.19449990709605686 | validation: 0.26558317403577986]
	TIME [epoch: 10.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21288618670815138		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.21288618670815138 | validation: 0.20698736823911315]
	TIME [epoch: 10.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853973025797399		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.1853973025797399 | validation: 0.22137638340636695]
	TIME [epoch: 10.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1830670391232878		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.1830670391232878 | validation: 0.2214131296231713]
	TIME [epoch: 10.3 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015638211031956		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.2015638211031956 | validation: 0.19902742258056133]
	TIME [epoch: 10.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21184866874634078		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.21184866874634078 | validation: 0.2191696523266733]
	TIME [epoch: 10.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16529134411562185		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.16529134411562185 | validation: 0.1800978131845492]
	TIME [epoch: 10.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14656989624519773		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.14656989624519773 | validation: 0.19806496070623344]
	TIME [epoch: 10.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15825261064083926		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.15825261064083926 | validation: 0.30495476798419346]
	TIME [epoch: 10.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2104019058127573		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.2104019058127573 | validation: 0.21973085871609868]
	TIME [epoch: 10.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715954854006181		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.1715954854006181 | validation: 0.2079702196510023]
	TIME [epoch: 10.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581552709623922		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.1581552709623922 | validation: 0.15537731736409732]
	TIME [epoch: 10.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16207184559499485		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.16207184559499485 | validation: 0.16288436591313307]
	TIME [epoch: 10.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15407826322286164		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.15407826322286164 | validation: 0.215395624467024]
	TIME [epoch: 10.3 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872605157703294		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.1872605157703294 | validation: 0.17916646826361274]
	TIME [epoch: 10.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1959044578566654		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.1959044578566654 | validation: 0.17400164791827835]
	TIME [epoch: 10.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15996048666476873		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.15996048666476873 | validation: 0.162774445789521]
	TIME [epoch: 10.3 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15526248610771573		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.15526248610771573 | validation: 0.16762533923082326]
	TIME [epoch: 10.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15811027199331168		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.15811027199331168 | validation: 0.17776239304543673]
	TIME [epoch: 10.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12800922116045793		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.12800922116045793 | validation: 0.13754118103646615]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1054.pth
	Model improved!!!
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14180578361613927		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.14180578361613927 | validation: 0.1908565640619395]
	TIME [epoch: 10.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19224399368214645		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.19224399368214645 | validation: 0.2643177601511729]
	TIME [epoch: 10.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21908646076108323		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.21908646076108323 | validation: 0.1407331631262901]
	TIME [epoch: 10.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16783804525912963		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.16783804525912963 | validation: 0.21099219003228342]
	TIME [epoch: 10.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156112690250895		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.156112690250895 | validation: 0.2063389121205716]
	TIME [epoch: 10.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17398342753746657		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.17398342753746657 | validation: 0.1993696632636836]
	TIME [epoch: 10.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19196816074926737		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.19196816074926737 | validation: 0.2227905543250635]
	TIME [epoch: 10.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20371528264659836		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.20371528264659836 | validation: 0.236346888230066]
	TIME [epoch: 10.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681209850890339		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.2681209850890339 | validation: 0.3283693850108433]
	TIME [epoch: 10.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29024037021032945		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.29024037021032945 | validation: 0.22968178750376908]
	TIME [epoch: 10.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2475726536037987		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.2475726536037987 | validation: 0.35713009289367875]
	TIME [epoch: 10.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23728089416255785		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.23728089416255785 | validation: 0.1754148831895041]
	TIME [epoch: 10.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15066483431212535		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.15066483431212535 | validation: 0.2148749793784705]
	TIME [epoch: 10.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17529994088048612		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.17529994088048612 | validation: 0.2263402793683468]
	TIME [epoch: 10.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20410584285071595		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.20410584285071595 | validation: 0.2234545670369041]
	TIME [epoch: 10.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19809938619102724		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.19809938619102724 | validation: 0.21868924607780638]
	TIME [epoch: 10.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21915489294604545		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.21915489294604545 | validation: 0.1875011196317101]
	TIME [epoch: 10.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16033189831298345		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.16033189831298345 | validation: 0.31518782966840514]
	TIME [epoch: 10.3 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27105956464912484		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.27105956464912484 | validation: 0.3448931559794561]
	TIME [epoch: 10.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36642131845119785		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.36642131845119785 | validation: 0.2801598354808407]
	TIME [epoch: 10.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2354135168106691		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.2354135168106691 | validation: 0.20419058000141782]
	TIME [epoch: 10.3 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2010587896702951		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.2010587896702951 | validation: 0.2352248584219734]
	TIME [epoch: 10.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21464441957550928		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.21464441957550928 | validation: 0.24582079368338722]
	TIME [epoch: 10.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20369015044893266		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.20369015044893266 | validation: 0.20872507387063435]
	TIME [epoch: 10.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20893837405680188		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.20893837405680188 | validation: 0.188179505493056]
	TIME [epoch: 10.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161200344517512		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.161200344517512 | validation: 0.16054288726756216]
	TIME [epoch: 10.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485335089455787		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.1485335089455787 | validation: 0.1622289469651681]
	TIME [epoch: 10.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1451345885402313		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.1451345885402313 | validation: 0.2624948949339248]
	TIME [epoch: 10.3 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17254871561336454		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.17254871561336454 | validation: 0.16203556646013093]
	TIME [epoch: 10.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14389950559017148		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.14389950559017148 | validation: 0.17169402619379664]
	TIME [epoch: 10.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16792807913917618		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.16792807913917618 | validation: 0.19174162755460156]
	TIME [epoch: 10.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18432601710864588		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.18432601710864588 | validation: 0.2380790629443898]
	TIME [epoch: 10.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20940098778447477		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.20940098778447477 | validation: 0.2472455594160553]
	TIME [epoch: 10.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2313002321010916		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.2313002321010916 | validation: 0.32189411779919497]
	TIME [epoch: 10.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2518163387826675		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.2518163387826675 | validation: 0.2845709516666958]
	TIME [epoch: 10.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2519625161465115		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.2519625161465115 | validation: 0.23055219384262074]
	TIME [epoch: 10.3 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19000483185226308		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.19000483185226308 | validation: 0.17290746423638606]
	TIME [epoch: 10.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1369450217412771		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.1369450217412771 | validation: 0.1616612081513023]
	TIME [epoch: 10.3 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14376502125614588		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.14376502125614588 | validation: 0.15970463620843783]
	TIME [epoch: 10.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1314953057539423		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.1314953057539423 | validation: 0.15316785387747273]
	TIME [epoch: 10.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14476900540304596		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.14476900540304596 | validation: 0.17129433187840307]
	TIME [epoch: 10.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1848195829272418		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.1848195829272418 | validation: 0.1875129171616683]
	TIME [epoch: 10.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594823323858387		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.1594823323858387 | validation: 0.1730611745859435]
	TIME [epoch: 10.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551658328271163		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.1551658328271163 | validation: 0.2117439408054315]
	TIME [epoch: 10.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15921267040776627		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.15921267040776627 | validation: 0.23654726110071533]
	TIME [epoch: 10.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16387367738697514		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.16387367738697514 | validation: 0.18800165713006287]
	TIME [epoch: 10.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18925588362851614		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.18925588362851614 | validation: 0.2271903457365356]
	TIME [epoch: 10.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22465548666369947		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.22465548666369947 | validation: 0.25534273590356305]
	TIME [epoch: 10.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21277602708056684		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.21277602708056684 | validation: 0.22287850463810344]
	TIME [epoch: 10.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1829212807105927		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.1829212807105927 | validation: 0.18444675413663603]
	TIME [epoch: 10.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17059192502893028		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.17059192502893028 | validation: 0.2508249103572776]
	TIME [epoch: 10.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16754367774055642		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.16754367774055642 | validation: 0.150801730410645]
	TIME [epoch: 10.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16818795786377025		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.16818795786377025 | validation: 0.1966471270793503]
	TIME [epoch: 10.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15694381537042806		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.15694381537042806 | validation: 0.13716140562391116]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1108.pth
	Model improved!!!
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16662334981586283		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.16662334981586283 | validation: 0.16309690162798066]
	TIME [epoch: 10.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17002887544680906		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.17002887544680906 | validation: 0.174633167186525]
	TIME [epoch: 10.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15612103384553375		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.15612103384553375 | validation: 0.18393504101290434]
	TIME [epoch: 10.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14849705296579238		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.14849705296579238 | validation: 0.17119245880317357]
	TIME [epoch: 10.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22419352228701594		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.22419352228701594 | validation: 0.20299052152802904]
	TIME [epoch: 10.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13718884943822246		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.13718884943822246 | validation: 0.17795141685915564]
	TIME [epoch: 10.3 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1454380704172536		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.1454380704172536 | validation: 0.17618067653573297]
	TIME [epoch: 10.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13720939269024018		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.13720939269024018 | validation: 0.14217298840122417]
	TIME [epoch: 10.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14666543013114372		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.14666543013114372 | validation: 0.16913844005737388]
	TIME [epoch: 10.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19557410953078905		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.19557410953078905 | validation: 0.1892479460441174]
	TIME [epoch: 10.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.145572190775315		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.145572190775315 | validation: 0.20627181517398488]
	TIME [epoch: 10.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15164375886366738		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.15164375886366738 | validation: 0.130195838499648]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1120.pth
	Model improved!!!
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12138601078228314		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.12138601078228314 | validation: 0.15717990799392534]
	TIME [epoch: 10.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12454325917714855		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.12454325917714855 | validation: 0.19435101921207068]
	TIME [epoch: 10.3 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536090713694712		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.1536090713694712 | validation: 0.18132957570831298]
	TIME [epoch: 10.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15466205475356104		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.15466205475356104 | validation: 0.2117367854283997]
	TIME [epoch: 10.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18948006244619778		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.18948006244619778 | validation: 0.22716388942944427]
	TIME [epoch: 10.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24232348464506445		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.24232348464506445 | validation: 0.21982779957243748]
	TIME [epoch: 10.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1993185472515635		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.1993185472515635 | validation: 0.23501471731578824]
	TIME [epoch: 10.2 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15563803942622237		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.15563803942622237 | validation: 0.16572178210270963]
	TIME [epoch: 10.3 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11559591685831223		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.11559591685831223 | validation: 0.1402187546439543]
	TIME [epoch: 10.3 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12204270178701689		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.12204270178701689 | validation: 0.1720997469720244]
	TIME [epoch: 10.3 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11711970353732717		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.11711970353732717 | validation: 0.14656071528681083]
	TIME [epoch: 10.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162187201945327		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.162187201945327 | validation: 0.21837911286687878]
	TIME [epoch: 10.3 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19693308631872397		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.19693308631872397 | validation: 0.2112614246230195]
	TIME [epoch: 10.3 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21097136300018912		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.21097136300018912 | validation: 0.22657079245404468]
	TIME [epoch: 10.3 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18266010142180814		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.18266010142180814 | validation: 0.1753824956949301]
	TIME [epoch: 10.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1479394393402565		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.1479394393402565 | validation: 0.18633254629131824]
	TIME [epoch: 10.3 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16138564580903392		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.16138564580903392 | validation: 0.21064123593446796]
	TIME [epoch: 10.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882922156825353		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.1882922156825353 | validation: 0.1741124555300241]
	TIME [epoch: 10.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12634906819780714		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.12634906819780714 | validation: 0.1536872893117391]
	TIME [epoch: 10.3 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13590645606659765		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.13590645606659765 | validation: 0.2805849753495746]
	TIME [epoch: 10.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19031540817612957		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.19031540817612957 | validation: 0.2895462913689288]
	TIME [epoch: 10.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23455744202533585		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.23455744202533585 | validation: 0.1877158436060612]
	TIME [epoch: 10.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13630113873136557		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.13630113873136557 | validation: 0.22986980303843157]
	TIME [epoch: 10.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1910914758846261		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.1910914758846261 | validation: 0.1902918268772649]
	TIME [epoch: 10.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13421531079338292		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.13421531079338292 | validation: 0.15107930182075394]
	TIME [epoch: 10.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1273506928806501		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.1273506928806501 | validation: 0.1545609073395344]
	TIME [epoch: 10.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15917387185721835		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.15917387185721835 | validation: 0.2500705895134967]
	TIME [epoch: 10.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16194535758896045		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.16194535758896045 | validation: 0.2525832593191555]
	TIME [epoch: 10.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1825886542041511		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.1825886542041511 | validation: 0.25249651452178457]
	TIME [epoch: 10.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21787818275724097		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.21787818275724097 | validation: 0.3858708518987791]
	TIME [epoch: 10.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29759236864677574		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.29759236864677574 | validation: 0.24248323486173534]
	TIME [epoch: 10.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16860633042510026		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.16860633042510026 | validation: 0.16855417245025037]
	TIME [epoch: 10.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15631178673805327		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.15631178673805327 | validation: 0.19026804968457037]
	TIME [epoch: 10.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17346181195063748		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.17346181195063748 | validation: 0.16763220745459861]
	TIME [epoch: 10.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1826927649170284		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.1826927649170284 | validation: 0.19472638958337002]
	TIME [epoch: 10.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18047960256680276		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.18047960256680276 | validation: 0.17348584071539633]
	TIME [epoch: 10.3 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14864861007295743		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.14864861007295743 | validation: 0.18630301638195051]
	TIME [epoch: 10.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14545515138579165		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.14545515138579165 | validation: 0.17945099131504472]
	TIME [epoch: 10.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17643020102113674		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.17643020102113674 | validation: 0.19790581825984774]
	TIME [epoch: 10.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15006278467164014		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.15006278467164014 | validation: 0.16430794008746388]
	TIME [epoch: 10.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1264507594416961		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.1264507594416961 | validation: 0.14961146283503277]
	TIME [epoch: 10.3 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13514215301639138		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.13514215301639138 | validation: 0.16407270640738694]
	TIME [epoch: 10.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11651473598192053		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.11651473598192053 | validation: 0.15895817354201833]
	TIME [epoch: 10.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12248194456231212		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.12248194456231212 | validation: 0.15113042076104655]
	TIME [epoch: 10.3 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13224266208841046		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.13224266208841046 | validation: 0.14816638909872132]
	TIME [epoch: 10.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14888725217342297		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.14888725217342297 | validation: 0.1798725645496946]
	TIME [epoch: 10.3 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15723223946665849		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.15723223946665849 | validation: 0.19919668378681554]
	TIME [epoch: 10.3 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17794418783281812		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.17794418783281812 | validation: 0.2271674682047956]
	TIME [epoch: 10.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14603909560470335		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.14603909560470335 | validation: 0.14998553240431658]
	TIME [epoch: 10.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12066669304478653		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.12066669304478653 | validation: 0.15710115049361342]
	TIME [epoch: 10.3 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13996654538027284		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.13996654538027284 | validation: 0.15415228999271183]
	TIME [epoch: 10.3 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13313755101045263		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.13313755101045263 | validation: 0.15635213831902403]
	TIME [epoch: 10.3 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616933565071112		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.1616933565071112 | validation: 0.1882621262145582]
	TIME [epoch: 10.3 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1200837739544716		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.1200837739544716 | validation: 0.15819294461059363]
	TIME [epoch: 10.3 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618522458884641		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.1618522458884641 | validation: 0.2652069281331005]
	TIME [epoch: 10.3 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1990645155662454		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.1990645155662454 | validation: 0.19100919251747464]
	TIME [epoch: 10.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16671858088452832		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.16671858088452832 | validation: 0.2505857582758529]
	TIME [epoch: 10.2 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21417852700110246		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.21417852700110246 | validation: 0.18442138281993486]
	TIME [epoch: 10.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503195113136337		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.1503195113136337 | validation: 0.20338544388482482]
	TIME [epoch: 10.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508587223027453		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.1508587223027453 | validation: 0.1735911129445938]
	TIME [epoch: 10.3 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14227671038339348		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.14227671038339348 | validation: 0.16476065819108057]
	TIME [epoch: 10.3 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304286068152412		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.1304286068152412 | validation: 0.19419954664631714]
	TIME [epoch: 10.3 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19686521138622037		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.19686521138622037 | validation: 0.21129873249332282]
	TIME [epoch: 10.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16116879551849592		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.16116879551849592 | validation: 0.2233267566669587]
	TIME [epoch: 10.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1744037412491975		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.1744037412491975 | validation: 0.1960317442536664]
	TIME [epoch: 10.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13448658164574737		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.13448658164574737 | validation: 0.19130957010979344]
	TIME [epoch: 10.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15853923503317616		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.15853923503317616 | validation: 0.17797150147713894]
	TIME [epoch: 10.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12891815384228464		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.12891815384228464 | validation: 0.1852832284175889]
	TIME [epoch: 10.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12967479542957033		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.12967479542957033 | validation: 0.15835164593344203]
	TIME [epoch: 10.2 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12554080198184886		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.12554080198184886 | validation: 0.15877436053988114]
	TIME [epoch: 10.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17917638866980456		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.17917638866980456 | validation: 0.20647660476824686]
	TIME [epoch: 10.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2150507527690594		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.2150507527690594 | validation: 0.2649958109604383]
	TIME [epoch: 10.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27224606585023986		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.27224606585023986 | validation: 0.29789115771877817]
	TIME [epoch: 10.3 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2187752942828099		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.2187752942828099 | validation: 0.17195206662960352]
	TIME [epoch: 10.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528736095159454		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.1528736095159454 | validation: 0.1688393336670889]
	TIME [epoch: 10.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11906677731772622		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.11906677731772622 | validation: 0.16810678977045157]
	TIME [epoch: 10.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1738184235267509		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.1738184235267509 | validation: 0.19876708079437477]
	TIME [epoch: 10.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14739837483243085		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.14739837483243085 | validation: 0.1782563792718714]
	TIME [epoch: 10.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13194093269919724		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.13194093269919724 | validation: 0.1436918082111626]
	TIME [epoch: 10.2 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540221227608075		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.1540221227608075 | validation: 0.19986106674643567]
	TIME [epoch: 10.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2024953252205742		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.2024953252205742 | validation: 0.17756642105097392]
	TIME [epoch: 10.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16800237949108848		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.16800237949108848 | validation: 0.2146734180971712]
	TIME [epoch: 10.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14547166499822642		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.14547166499822642 | validation: 0.1965729249387304]
	TIME [epoch: 10.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13154428352064487		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.13154428352064487 | validation: 0.19632638163422322]
	TIME [epoch: 10.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14807507822286456		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.14807507822286456 | validation: 0.202930372061284]
	TIME [epoch: 10.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16086736861753165		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.16086736861753165 | validation: 0.18875661729272014]
	TIME [epoch: 10.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15017746016141945		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.15017746016141945 | validation: 0.17174294564325557]
	TIME [epoch: 10.3 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12909479062401347		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.12909479062401347 | validation: 0.16745532135063138]
	TIME [epoch: 10.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11752248643034054		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.11752248643034054 | validation: 0.13491768978624932]
	TIME [epoch: 10.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13653561648742976		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.13653561648742976 | validation: 0.18996220638266573]
	TIME [epoch: 10.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285799166015873		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.15285799166015873 | validation: 0.17011090255200897]
	TIME [epoch: 10.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11867503539542519		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.11867503539542519 | validation: 0.13950428969600215]
	TIME [epoch: 10.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1208242686719468		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.1208242686719468 | validation: 0.1581718167076046]
	TIME [epoch: 10.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12354782533944145		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.12354782533944145 | validation: 0.1632372432020123]
	TIME [epoch: 10.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17559710951255073		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.17559710951255073 | validation: 0.145117519908682]
	TIME [epoch: 10.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11216895713321942		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.11216895713321942 | validation: 0.1616653537722058]
	TIME [epoch: 10.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1271028715007449		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.1271028715007449 | validation: 0.15287387269715422]
	TIME [epoch: 10.3 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1241025234088535		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.1241025234088535 | validation: 0.16073766815420348]
	TIME [epoch: 10.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17579551827866652		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.17579551827866652 | validation: 0.17175191301114245]
	TIME [epoch: 10.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1599464319790184		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.1599464319790184 | validation: 0.1812629949243458]
	TIME [epoch: 10.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13675164171274037		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.13675164171274037 | validation: 0.17798816893616098]
	TIME [epoch: 10.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13540511115795		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.13540511115795 | validation: 0.20168851610628813]
	TIME [epoch: 10.3 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15877341481665094		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.15877341481665094 | validation: 0.15829157968634097]
	TIME [epoch: 10.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17081259633424573		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.17081259633424573 | validation: 0.1963161717457858]
	TIME [epoch: 10.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17068424523014109		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.17068424523014109 | validation: 0.21402695684248088]
	TIME [epoch: 10.3 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23218147060935848		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.23218147060935848 | validation: 0.20523720942062387]
	TIME [epoch: 10.3 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17562170314721803		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.17562170314721803 | validation: 0.18614588629522102]
	TIME [epoch: 10.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18223670251331303		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.18223670251331303 | validation: 0.22429124969291184]
	TIME [epoch: 10.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19106535451651513		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.19106535451651513 | validation: 0.17703900586383506]
	TIME [epoch: 10.3 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13675592259083175		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.13675592259083175 | validation: 0.15402469166366806]
	TIME [epoch: 10.3 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14031215366360278		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.14031215366360278 | validation: 0.16350402770145686]
	TIME [epoch: 10.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15514943500114842		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.15514943500114842 | validation: 0.19253812171788512]
	TIME [epoch: 10.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568375828732778		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.1568375828732778 | validation: 0.19611234579896042]
	TIME [epoch: 10.3 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16038375081491146		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.16038375081491146 | validation: 0.27624524306133774]
	TIME [epoch: 10.3 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16705869010696694		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.16705869010696694 | validation: 0.19090587860203442]
	TIME [epoch: 10.3 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14276897572000458		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.14276897572000458 | validation: 0.16999800058710335]
	TIME [epoch: 10.3 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13269465650532017		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.13269465650532017 | validation: 0.16720403907076226]
	TIME [epoch: 10.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14316079450965236		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.14316079450965236 | validation: 0.16161744920385]
	TIME [epoch: 10.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602442036978524		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.1602442036978524 | validation: 0.19483292250489576]
	TIME [epoch: 10.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17588438026349462		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.17588438026349462 | validation: 0.18506772842368668]
	TIME [epoch: 10.3 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15484429101962677		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.15484429101962677 | validation: 0.17075731883687376]
	TIME [epoch: 10.3 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15363634470949095		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.15363634470949095 | validation: 0.1825290404282058]
	TIME [epoch: 10.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1812276292296596		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.1812276292296596 | validation: 0.21013706392888815]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19361273013194474		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.19361273013194474 | validation: 0.198867103993886]
	TIME [epoch: 10.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17330785727819453		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.17330785727819453 | validation: 0.20470470187961667]
	TIME [epoch: 10.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315677640962458		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.15315677640962458 | validation: 0.2756058056009299]
	TIME [epoch: 10.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19427685856013713		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.19427685856013713 | validation: 0.19775651216046744]
	TIME [epoch: 10.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2088415210926172		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.2088415210926172 | validation: 0.17039501246600275]
	TIME [epoch: 10.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1308700570039388		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.1308700570039388 | validation: 0.1690125494676733]
	TIME [epoch: 10.3 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13244587212886696		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.13244587212886696 | validation: 0.15673860365978518]
	TIME [epoch: 10.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15205581251717942		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.15205581251717942 | validation: 0.15209996165415626]
	TIME [epoch: 10.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597314578164809		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.1597314578164809 | validation: 0.3218412332565908]
	TIME [epoch: 10.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2928453866161796		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.2928453866161796 | validation: 0.2800689136204413]
	TIME [epoch: 10.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1993321723866003		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.1993321723866003 | validation: 0.20838937525814025]
	TIME [epoch: 10.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1769274242775188		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.1769274242775188 | validation: 0.19855237676164103]
	TIME [epoch: 10.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20397596661990733		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.20397596661990733 | validation: 0.21982214084941237]
	TIME [epoch: 10.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25168257811056316		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.25168257811056316 | validation: 0.32548002318391994]
	TIME [epoch: 10.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2685592452272439		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.2685592452272439 | validation: 0.2680250882717598]
	TIME [epoch: 10.3 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17792857369722745		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.17792857369722745 | validation: 0.1896633154427137]
	TIME [epoch: 10.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708051299694607		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.1708051299694607 | validation: 0.20614204028074554]
	TIME [epoch: 10.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19931464916116437		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.19931464916116437 | validation: 0.2108653540379224]
	TIME [epoch: 10.3 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14966949192181703		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.14966949192181703 | validation: 0.2279148736278076]
	TIME [epoch: 10.3 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16277444502018693		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.16277444502018693 | validation: 0.18190538719635815]
	TIME [epoch: 10.3 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664552026580272		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.1664552026580272 | validation: 0.2063426523134642]
	TIME [epoch: 10.3 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495633487302743		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.1495633487302743 | validation: 0.19170670214207405]
	TIME [epoch: 10.3 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14884041872381285		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.14884041872381285 | validation: 0.19377677239878854]
	TIME [epoch: 10.3 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15683689477114995		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.15683689477114995 | validation: 0.19014340748692754]
	TIME [epoch: 10.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14594192193690222		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.14594192193690222 | validation: 0.20957545094105634]
	TIME [epoch: 10.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16911503145684756		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.16911503145684756 | validation: 0.1820211066982003]
	TIME [epoch: 10.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12840651390320812		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.12840651390320812 | validation: 0.16091927171432222]
	TIME [epoch: 10.3 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.125373131273604		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.125373131273604 | validation: 0.1631453845916386]
	TIME [epoch: 10.3 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1270635257505432		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.1270635257505432 | validation: 0.17195313465748868]
	TIME [epoch: 10.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13341246052702713		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.13341246052702713 | validation: 0.17876766503151778]
	TIME [epoch: 10.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144916985350635		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.1144916985350635 | validation: 0.16018776403096865]
	TIME [epoch: 10.3 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12103129502856635		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.12103129502856635 | validation: 0.16560433458736223]
	TIME [epoch: 10.3 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11536303912272503		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.11536303912272503 | validation: 0.1501078477922287]
	TIME [epoch: 10.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13863974427669462		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.13863974427669462 | validation: 0.15468793970118422]
	TIME [epoch: 10.2 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16166269040852127		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.16166269040852127 | validation: 0.16854681352826803]
	TIME [epoch: 10.3 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11453925426174254		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.11453925426174254 | validation: 0.14810180659324473]
	TIME [epoch: 10.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516651354031305		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.1516651354031305 | validation: 0.18823687216830837]
	TIME [epoch: 10.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14330635038321046		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.14330635038321046 | validation: 0.1872412286032737]
	TIME [epoch: 10.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14317549637321852		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.14317549637321852 | validation: 0.21272534322305617]
	TIME [epoch: 10.3 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1979902032142965		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.1979902032142965 | validation: 0.35143877474060975]
	TIME [epoch: 10.3 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29129127824103285		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.29129127824103285 | validation: 0.28181988586226986]
	TIME [epoch: 10.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750333196256529		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.1750333196256529 | validation: 0.188692728620237]
	TIME [epoch: 10.3 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15099440781111526		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.15099440781111526 | validation: 0.18551514134259475]
	TIME [epoch: 10.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1469774337504511		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.1469774337504511 | validation: 0.1737419277902981]
	TIME [epoch: 10.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493610235231273		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.1493610235231273 | validation: 0.1797021185478381]
	TIME [epoch: 10.3 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15003275390924528		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.15003275390924528 | validation: 0.1773720938739379]
	TIME [epoch: 10.3 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160926547467554		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.160926547467554 | validation: 0.19106006231868705]
	TIME [epoch: 10.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15282057104087515		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.15282057104087515 | validation: 0.2511696609196413]
	TIME [epoch: 10.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18593031475802863		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.18593031475802863 | validation: 0.17038419714621586]
	TIME [epoch: 10.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13448724932939876		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.13448724932939876 | validation: 0.18231870123026667]
	TIME [epoch: 10.3 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.146419711758787		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.146419711758787 | validation: 0.2130167834061293]
	TIME [epoch: 10.3 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14137769394211347		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.14137769394211347 | validation: 0.15951457460993343]
	TIME [epoch: 10.3 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13868599599151624		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.13868599599151624 | validation: 0.17019254129727895]
	TIME [epoch: 10.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12646943164417127		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.12646943164417127 | validation: 0.15625429236331498]
	TIME [epoch: 10.3 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12054236988753768		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.12054236988753768 | validation: 0.15166850668315024]
	TIME [epoch: 10.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379143902398177		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.1379143902398177 | validation: 0.1676752360005211]
	TIME [epoch: 10.3 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15307593328195762		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.15307593328195762 | validation: 0.19043159774852203]
	TIME [epoch: 10.3 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14501582066226354		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.14501582066226354 | validation: 0.15287263310989574]
	TIME [epoch: 10.3 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12887588164093722		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.12887588164093722 | validation: 0.20492542218777948]
	TIME [epoch: 10.3 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15706330471961685		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.15706330471961685 | validation: 0.2004916806288638]
	TIME [epoch: 10.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13998608028324747		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.13998608028324747 | validation: 0.18672715791345204]
	TIME [epoch: 10.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14440398841658256		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.14440398841658256 | validation: 0.16527116766530056]
	TIME [epoch: 10.3 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11848415957827127		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.11848415957827127 | validation: 0.16031639051566715]
	TIME [epoch: 10.3 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14279272453494968		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.14279272453494968 | validation: 0.19491140592967]
	TIME [epoch: 10.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16983817597478773		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.16983817597478773 | validation: 0.19282514658731395]
	TIME [epoch: 10.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14405016506131635		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.14405016506131635 | validation: 0.15933615282472904]
	TIME [epoch: 10.3 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12387785809676322		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.12387785809676322 | validation: 0.161507397981502]
	TIME [epoch: 10.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13315296610732258		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.13315296610732258 | validation: 0.17238595797195688]
	TIME [epoch: 10.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13861898520488594		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.13861898520488594 | validation: 0.15381499023729006]
	TIME [epoch: 10.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1249604946540142		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.1249604946540142 | validation: 0.195696840426756]
	TIME [epoch: 10.3 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19156481728245284		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.19156481728245284 | validation: 0.19565543292358306]
	TIME [epoch: 10.2 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644393845921714		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.1644393845921714 | validation: 0.1752406413841789]
	TIME [epoch: 10.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156528578865221		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.156528578865221 | validation: 0.2046944225010926]
	TIME [epoch: 10.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13209759272295457		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.13209759272295457 | validation: 0.17701281241087316]
	TIME [epoch: 10.3 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16521013512413593		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.16521013512413593 | validation: 0.20248023134953783]
	TIME [epoch: 10.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13562399737368785		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.13562399737368785 | validation: 0.15106146270394102]
	TIME [epoch: 10.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12102417783290917		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.12102417783290917 | validation: 0.15075450660550233]
	TIME [epoch: 10.3 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11883849423387291		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.11883849423387291 | validation: 0.15859120791238268]
	TIME [epoch: 10.3 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13849389836246456		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.13849389836246456 | validation: 0.18134021591927685]
	TIME [epoch: 10.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13905699999437196		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.13905699999437196 | validation: 0.194646913936063]
	TIME [epoch: 10.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15780215016987262		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.15780215016987262 | validation: 0.1969669284295143]
	TIME [epoch: 10.3 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1779868878975786		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.1779868878975786 | validation: 0.20056145965213013]
	TIME [epoch: 10.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692569536649111		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.1692569536649111 | validation: 0.1675512729272103]
	TIME [epoch: 10.3 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17621862463937205		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.17621862463937205 | validation: 0.18169123255268965]
	TIME [epoch: 10.3 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15870892360572436		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.15870892360572436 | validation: 0.18593506376868113]
	TIME [epoch: 10.3 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452498958056635		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.1452498958056635 | validation: 0.17855883993614385]
	TIME [epoch: 10.3 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1670309145328143		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.1670309145328143 | validation: 0.20327243113393245]
	TIME [epoch: 10.3 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1862168149182721		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.1862168149182721 | validation: 0.2261801363525777]
	TIME [epoch: 10.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18959972937597044		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.18959972937597044 | validation: 0.23518610188830408]
	TIME [epoch: 10.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17617289983582426		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.17617289983582426 | validation: 0.2029994488788622]
	TIME [epoch: 10.3 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20041128346027745		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.20041128346027745 | validation: 0.21661892916666609]
	TIME [epoch: 10.3 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15798866714270005		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.15798866714270005 | validation: 0.1940371327785571]
	TIME [epoch: 10.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16143355850236987		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.16143355850236987 | validation: 0.22771231475645637]
	TIME [epoch: 10.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15385513374311977		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.15385513374311977 | validation: 0.2046872840901902]
	TIME [epoch: 10.3 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16340422252573356		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.16340422252573356 | validation: 0.1850242928527605]
	TIME [epoch: 10.3 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886679563130772		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.14886679563130772 | validation: 0.1690743864290554]
	TIME [epoch: 10.3 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16565675094004978		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.16565675094004978 | validation: 0.2373001463724693]
	TIME [epoch: 10.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20005861666996302		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.20005861666996302 | validation: 0.23134969913251882]
	TIME [epoch: 10.3 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1943981479806447		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.1943981479806447 | validation: 0.16794831798226814]
	TIME [epoch: 10.3 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13412339729985753		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.13412339729985753 | validation: 0.1722963932710812]
	TIME [epoch: 10.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12987154609616833		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.12987154609616833 | validation: 0.1533192402451948]
	TIME [epoch: 10.3 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13337805985265633		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.13337805985265633 | validation: 0.15433625345269103]
	TIME [epoch: 10.3 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12870574696979467		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.12870574696979467 | validation: 0.18779017389214658]
	TIME [epoch: 10.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18521457389064183		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.18521457389064183 | validation: 0.19461328584478005]
	TIME [epoch: 10.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16208436620015307		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.16208436620015307 | validation: 0.18198288235516827]
	TIME [epoch: 10.3 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16029163235955576		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.16029163235955576 | validation: 0.17099711235933093]
	TIME [epoch: 10.3 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13552664415922322		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.13552664415922322 | validation: 0.16442374385079203]
	TIME [epoch: 10.3 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147147209398822		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.147147209398822 | validation: 0.1909127448792022]
	TIME [epoch: 10.3 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15509932722059583		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.15509932722059583 | validation: 0.21557980526723305]
	TIME [epoch: 10.3 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18032457460879733		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.18032457460879733 | validation: 0.21697935178069372]
	TIME [epoch: 10.3 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2108257960375403		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.2108257960375403 | validation: 0.26349556356083015]
	TIME [epoch: 10.3 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2577897635177863		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.2577897635177863 | validation: 0.24679102778589482]
	TIME [epoch: 10.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2003772488009358		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.2003772488009358 | validation: 0.20574077011191713]
	TIME [epoch: 10.3 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15473440963400736		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.15473440963400736 | validation: 0.17057105881192033]
	TIME [epoch: 10.3 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15553046178591354		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.15553046178591354 | validation: 0.2414982410906367]
	TIME [epoch: 10.3 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17194596441801582		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.17194596441801582 | validation: 0.18643690565098975]
	TIME [epoch: 10.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15853539318975524		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.15853539318975524 | validation: 0.17630737931694754]
	TIME [epoch: 10.3 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13391294828057665		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.13391294828057665 | validation: 0.1723577680058187]
	TIME [epoch: 10.3 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14718281787195214		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.14718281787195214 | validation: 0.22592602941865925]
	TIME [epoch: 10.3 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15390214928822038		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.15390214928822038 | validation: 0.166507212725399]
	TIME [epoch: 10.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1365055382690384		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.1365055382690384 | validation: 0.19464513999667044]
	TIME [epoch: 10.3 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13146870271828362		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.13146870271828362 | validation: 0.16253759339287796]
	TIME [epoch: 10.3 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575109584745708		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.1575109584745708 | validation: 0.21879078166909044]
	TIME [epoch: 10.3 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14706794272153156		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.14706794272153156 | validation: 0.16335308080066624]
	TIME [epoch: 10.3 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13671889623588718		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.13671889623588718 | validation: 0.21945345425154858]
	TIME [epoch: 10.3 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14238625371272112		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.14238625371272112 | validation: 0.14350609652882024]
	TIME [epoch: 10.3 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1217986041453202		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.1217986041453202 | validation: 0.1625825931732107]
	TIME [epoch: 10.3 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13632339146958405		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.13632339146958405 | validation: 0.20737383078809146]
	TIME [epoch: 10.2 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14678097894051836		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.14678097894051836 | validation: 0.1474917997010415]
	TIME [epoch: 10.3 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11499800266951618		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.11499800266951618 | validation: 0.14046663950373936]
	TIME [epoch: 10.3 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12126323991535944		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.12126323991535944 | validation: 0.1604821287949601]
	TIME [epoch: 10.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11779954181059438		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.11779954181059438 | validation: 0.16508924616983245]
	TIME [epoch: 10.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12787412891037236		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.12787412891037236 | validation: 0.16634312639607038]
	TIME [epoch: 10.3 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1337919189027283		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.1337919189027283 | validation: 0.24943016624735728]
	TIME [epoch: 10.3 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21528006727700957		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.21528006727700957 | validation: 0.19924166675930377]
	TIME [epoch: 10.3 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563231498314586		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.1563231498314586 | validation: 0.19410727065493613]
	TIME [epoch: 10.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1315970014701978		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.1315970014701978 | validation: 0.16872127900568865]
	TIME [epoch: 10.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15428983986434902		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.15428983986434902 | validation: 0.159958346655517]
	TIME [epoch: 10.3 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12552509182841548		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.12552509182841548 | validation: 0.1653597150546742]
	TIME [epoch: 10.3 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1394543914627449		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.1394543914627449 | validation: 0.1810913787741089]
	TIME [epoch: 10.3 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14999151883183728		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.14999151883183728 | validation: 0.16149366950382357]
	TIME [epoch: 10.3 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544665270637584		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.1544665270637584 | validation: 0.18994473428552916]
	TIME [epoch: 10.3 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692183890716728		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.1692183890716728 | validation: 0.2142770603367478]
	TIME [epoch: 10.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16072001381832854		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.16072001381832854 | validation: 0.20168922274689396]
	TIME [epoch: 10.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15407881389979733		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.15407881389979733 | validation: 0.15555644266607707]
	TIME [epoch: 10.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13254345682316138		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.13254345682316138 | validation: 0.1780350568712105]
	TIME [epoch: 10.3 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723735221116398		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.1723735221116398 | validation: 0.1934041109635284]
	TIME [epoch: 10.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1474723386520001		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.1474723386520001 | validation: 0.1738031365552792]
	TIME [epoch: 10.3 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14180785444994243		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.14180785444994243 | validation: 0.1545616213449383]
	TIME [epoch: 10.3 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12012879472582468		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.12012879472582468 | validation: 0.17423680131115532]
	TIME [epoch: 10.3 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12309315025254149		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.12309315025254149 | validation: 0.15308448415531523]
	TIME [epoch: 10.3 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12663778204981915		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.12663778204981915 | validation: 0.17214338830745166]
	TIME [epoch: 10.3 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12759361328941823		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.12759361328941823 | validation: 0.14517605606029418]
	TIME [epoch: 10.3 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11626461140394395		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.11626461140394395 | validation: 0.17870534543733668]
	TIME [epoch: 10.3 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15511755274512048		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.15511755274512048 | validation: 0.1701029446360341]
	TIME [epoch: 10.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12203741398157279		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.12203741398157279 | validation: 0.15890437110929942]
	TIME [epoch: 10.3 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11678145276917025		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.11678145276917025 | validation: 0.13762080691061349]
	TIME [epoch: 10.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12968468794415636		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.12968468794415636 | validation: 0.18217229950508568]
	TIME [epoch: 10.2 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13757305352046317		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.13757305352046317 | validation: 0.2135138950104896]
	TIME [epoch: 10.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15366843131374683		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.15366843131374683 | validation: 0.17207151760677492]
	TIME [epoch: 10.3 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12868719235158016		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.12868719235158016 | validation: 0.1558770544819912]
	TIME [epoch: 10.3 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1313877138315635		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.1313877138315635 | validation: 0.21598813262933064]
	TIME [epoch: 10.3 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17058948591575465		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.17058948591575465 | validation: 0.17806551437248808]
	TIME [epoch: 10.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16423252091829682		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.16423252091829682 | validation: 0.17329399765513562]
	TIME [epoch: 10.3 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610055782214074		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.1610055782214074 | validation: 0.16558946229341373]
	TIME [epoch: 10.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13213766094699042		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.13213766094699042 | validation: 0.17029554494326798]
	TIME [epoch: 10.3 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1300729097031652		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.1300729097031652 | validation: 0.17320044094082307]
	TIME [epoch: 10.3 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13718944696019952		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.13718944696019952 | validation: 0.13281119721677517]
	TIME [epoch: 10.3 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11271870416688914		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.11271870416688914 | validation: 0.14406208756187852]
	TIME [epoch: 10.3 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1195025463048092		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.1195025463048092 | validation: 0.14137671230771187]
	TIME [epoch: 10.3 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12680908448808165		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.12680908448808165 | validation: 0.15519403185698435]
	TIME [epoch: 10.3 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11929025488129241		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.11929025488129241 | validation: 0.14167644565112705]
	TIME [epoch: 10.3 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1299197196644974		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.1299197196644974 | validation: 0.14873493111967748]
	TIME [epoch: 10.3 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15075383347895124		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.15075383347895124 | validation: 0.17439091512634305]
	TIME [epoch: 10.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1360794642801782		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.1360794642801782 | validation: 0.17417676185210568]
	TIME [epoch: 10.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12492656080547256		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.12492656080547256 | validation: 0.18739351403415647]
	TIME [epoch: 10.3 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452620473029407		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.1452620473029407 | validation: 0.14815013210837366]
	TIME [epoch: 10.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12666560339634508		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.12666560339634508 | validation: 0.14010902102173942]
	TIME [epoch: 10.3 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13442534523016172		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.13442534523016172 | validation: 0.18118513327708946]
	TIME [epoch: 10.3 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1677816817726373		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.1677816817726373 | validation: 0.20678042162839794]
	TIME [epoch: 10.2 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17730082571149053		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.17730082571149053 | validation: 0.17836795448216713]
	TIME [epoch: 10.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14888322890978664		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.14888322890978664 | validation: 0.18008337929872156]
	TIME [epoch: 10.3 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14665062308437046		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.14665062308437046 | validation: 0.1678739828006723]
	TIME [epoch: 10.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14586934347260908		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.14586934347260908 | validation: 0.1697389135869649]
	TIME [epoch: 10.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1354601112423264		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.1354601112423264 | validation: 0.19512454685790537]
	TIME [epoch: 10.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17575605977540545		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.17575605977540545 | validation: 0.1812286309510423]
	TIME [epoch: 10.2 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15175056312089183		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.15175056312089183 | validation: 0.1924038762675464]
	TIME [epoch: 10.2 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459953702103835		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.1459953702103835 | validation: 0.18821682211155227]
	TIME [epoch: 10.3 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1557585606874158		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.1557585606874158 | validation: 0.17977815653990858]
	TIME [epoch: 10.3 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14630746412572815		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.14630746412572815 | validation: 0.20318351494940487]
	TIME [epoch: 10.3 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16247049861070026		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.16247049861070026 | validation: 0.21003454401715563]
	TIME [epoch: 10.3 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2005397290442818		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.2005397290442818 | validation: 0.23381513134058007]
	TIME [epoch: 10.3 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17060963393663556		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.17060963393663556 | validation: 0.20283055892682966]
	TIME [epoch: 10.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16676634793963446		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.16676634793963446 | validation: 0.20453037500993282]
	TIME [epoch: 10.3 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1694434589390827		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.1694434589390827 | validation: 0.19786613902792755]
	TIME [epoch: 10.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1453486695047679		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.1453486695047679 | validation: 0.17415262771711612]
	TIME [epoch: 10.3 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15303248468075237		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.15303248468075237 | validation: 0.1787105436455808]
	TIME [epoch: 10.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562980298365883		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.1562980298365883 | validation: 0.20561096085102784]
	TIME [epoch: 10.3 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1701042047148316		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.1701042047148316 | validation: 0.22259108667769545]
	TIME [epoch: 10.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13994114880129666		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.13994114880129666 | validation: 0.13780516731224468]
	TIME [epoch: 10.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10458685230108374		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.10458685230108374 | validation: 0.1442975865884861]
	TIME [epoch: 10.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11601291147660905		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.11601291147660905 | validation: 0.15947693401285837]
	TIME [epoch: 10.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12026417222688623		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.12026417222688623 | validation: 0.1416005180268407]
	TIME [epoch: 10.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11234474050839043		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.11234474050839043 | validation: 0.15057286167104753]
	TIME [epoch: 10.3 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1273268619290105		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.1273268619290105 | validation: 0.13809442342262818]
	TIME [epoch: 10.3 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.125970193253447		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.125970193253447 | validation: 0.1468572398252075]
	TIME [epoch: 10.3 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11940389607074013		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.11940389607074013 | validation: 0.1552734612317875]
	TIME [epoch: 10.3 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11339644358907564		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.11339644358907564 | validation: 0.154372913372941]
	TIME [epoch: 10.3 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10840975727571707		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.10840975727571707 | validation: 0.1738382530206994]
	TIME [epoch: 10.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13459214024420796		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.13459214024420796 | validation: 0.12862448356868972]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1453.pth
	Model improved!!!
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10959420138312814		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.10959420138312814 | validation: 0.15634612365191833]
	TIME [epoch: 10.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12151970984568736		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.12151970984568736 | validation: 0.16298119520456542]
	TIME [epoch: 10.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11902570236788809		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.11902570236788809 | validation: 0.16262149794550407]
	TIME [epoch: 10.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342133252750445		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.1342133252750445 | validation: 0.1549494289392338]
	TIME [epoch: 10.2 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12435934894998002		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.12435934894998002 | validation: 0.15806713109195833]
	TIME [epoch: 10.3 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12746325364026354		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.12746325364026354 | validation: 0.16362720634068345]
	TIME [epoch: 10.3 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11874765781602037		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.11874765781602037 | validation: 0.1538193125780298]
	TIME [epoch: 10.3 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12026848181695131		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.12026848181695131 | validation: 0.16858300771374019]
	TIME [epoch: 10.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10882508484206713		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.10882508484206713 | validation: 0.13256866742326154]
	TIME [epoch: 10.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11716097099508338		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.11716097099508338 | validation: 0.14035093436258858]
	TIME [epoch: 10.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11661548509212069		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.11661548509212069 | validation: 0.1487259463061198]
	TIME [epoch: 10.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11950381783633632		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.11950381783633632 | validation: 0.13639711731888898]
	TIME [epoch: 10.3 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10111820659905495		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.10111820659905495 | validation: 0.1339999591189457]
	TIME [epoch: 10.2 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10207613824007229		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.10207613824007229 | validation: 0.16211506727032735]
	TIME [epoch: 10.2 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11238997798813377		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.11238997798813377 | validation: 0.13330332273043202]
	TIME [epoch: 10.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10581358662717719		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.10581358662717719 | validation: 0.1457371598934028]
	TIME [epoch: 10.3 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212521344491548		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.11212521344491548 | validation: 0.136705709602449]
	TIME [epoch: 10.3 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1108329742246111		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.1108329742246111 | validation: 0.1486708643764087]
	TIME [epoch: 10.3 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11157568991250484		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.11157568991250484 | validation: 0.12567580242020202]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1472.pth
	Model improved!!!
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09879103323726118		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.09879103323726118 | validation: 0.16115156078333756]
	TIME [epoch: 10.2 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12931808917398813		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.12931808917398813 | validation: 0.1807928947846719]
	TIME [epoch: 10.3 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13067345228589128		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.13067345228589128 | validation: 0.14431826560878536]
	TIME [epoch: 10.2 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12456738622849647		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.12456738622849647 | validation: 0.1860820564905152]
	TIME [epoch: 10.3 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12790730684378102		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.12790730684378102 | validation: 0.17491061027624985]
	TIME [epoch: 10.3 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13634837912641168		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.13634837912641168 | validation: 0.1336057166036775]
	TIME [epoch: 10.3 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10327058951362782		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.10327058951362782 | validation: 0.14163864297784912]
	TIME [epoch: 10.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092803689108329		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.1092803689108329 | validation: 0.1383974036997823]
	TIME [epoch: 10.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11397938483024384		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.11397938483024384 | validation: 0.17049720553638803]
	TIME [epoch: 10.3 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11230413199051203		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.11230413199051203 | validation: 0.1502126514491996]
	TIME [epoch: 10.3 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1099938542149113		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.1099938542149113 | validation: 0.1275275493781964]
	TIME [epoch: 10.3 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11393405016273292		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.11393405016273292 | validation: 0.14460207368020656]
	TIME [epoch: 10.3 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11095034038363753		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.11095034038363753 | validation: 0.15925276307153563]
	TIME [epoch: 10.2 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11298524590219375		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.11298524590219375 | validation: 0.14522863848110945]
	TIME [epoch: 10.3 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11739004190494418		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.11739004190494418 | validation: 0.1487710556111681]
	TIME [epoch: 10.2 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09526733907071452		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.09526733907071452 | validation: 0.13536006463927117]
	TIME [epoch: 10.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11145978060168389		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.11145978060168389 | validation: 0.14578087680064464]
	TIME [epoch: 10.3 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1191912283975807		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.1191912283975807 | validation: 0.16468815203861947]
	TIME [epoch: 10.3 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12675446141013627		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.12675446141013627 | validation: 0.15967689257979448]
	TIME [epoch: 10.2 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12102156671138505		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.12102156671138505 | validation: 0.1796698408087447]
	TIME [epoch: 10.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1677339991130748		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.1677339991130748 | validation: 0.2180502571798256]
	TIME [epoch: 10.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1901001972239409		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.1901001972239409 | validation: 0.193332752122895]
	TIME [epoch: 10.3 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15110406813100957		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.15110406813100957 | validation: 0.179165914703818]
	TIME [epoch: 10.3 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12860093581173113		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.12860093581173113 | validation: 0.18002646918148732]
	TIME [epoch: 10.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13160988560739167		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.13160988560739167 | validation: 0.1603610736757446]
	TIME [epoch: 10.3 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13087641612823114		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.13087641612823114 | validation: 0.1698625217305367]
	TIME [epoch: 10.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1228083698378128		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.1228083698378128 | validation: 0.15186524422293404]
	TIME [epoch: 10.2 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13576244562923825		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.13576244562923825 | validation: 0.16058655031933528]
	TIME [epoch: 10.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12499464738363233		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.12499464738363233 | validation: 0.16798327503486976]
	TIME [epoch: 10.2 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13180072908506185		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.13180072908506185 | validation: 0.14464032773214192]
	TIME [epoch: 10.3 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13075855651686202		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.13075855651686202 | validation: 0.13612561575659918]
	TIME [epoch: 10.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11881689486130269		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.11881689486130269 | validation: 0.15227831857899346]
	TIME [epoch: 10.3 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11193218561611055		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.11193218561611055 | validation: 0.16099632292989627]
	TIME [epoch: 10.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11269705285608626		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.11269705285608626 | validation: 0.13396086830938306]
	TIME [epoch: 10.3 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11352456573330635		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.11352456573330635 | validation: 0.14925365324544324]
	TIME [epoch: 10.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1352375801596522		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.1352375801596522 | validation: 0.1983801118716687]
	TIME [epoch: 10.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1375925909726641		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.1375925909726641 | validation: 0.18555159043183822]
	TIME [epoch: 10.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1335068412103834		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.1335068412103834 | validation: 0.16744664934279635]
	TIME [epoch: 10.3 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485064782197721		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.1485064782197721 | validation: 0.1797355064923028]
	TIME [epoch: 10.2 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12882180668425885		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.12882180668425885 | validation: 0.15157598914947756]
	TIME [epoch: 10.3 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10465398574542598		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.10465398574542598 | validation: 0.1492657654431987]
	TIME [epoch: 10.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10929234744623051		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.10929234744623051 | validation: 0.16290789187884896]
	TIME [epoch: 10.2 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10759738124095715		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.10759738124095715 | validation: 0.15936361588095352]
	TIME [epoch: 10.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11032730704595446		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.11032730704595446 | validation: 0.14879732295873646]
	TIME [epoch: 10.3 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10850238645497956		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.10850238645497956 | validation: 0.13512454197075635]
	TIME [epoch: 10.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10444184584708915		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.10444184584708915 | validation: 0.13522953311570016]
	TIME [epoch: 10.3 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11854538128597103		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.11854538128597103 | validation: 0.14090897166329133]
	TIME [epoch: 10.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10730402276669734		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.10730402276669734 | validation: 0.15458090571849104]
	TIME [epoch: 10.3 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10525544281684399		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.10525544281684399 | validation: 0.1452127445704633]
	TIME [epoch: 10.3 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11161906354615861		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.11161906354615861 | validation: 0.14095048702170926]
	TIME [epoch: 10.3 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11104706645188674		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.11104706645188674 | validation: 0.1353682197990098]
	TIME [epoch: 10.3 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11807225947746569		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.11807225947746569 | validation: 0.15105121286748172]
	TIME [epoch: 10.3 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11598534410155681		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.11598534410155681 | validation: 0.15572656109079636]
	TIME [epoch: 10.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11432018462528357		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.11432018462528357 | validation: 0.13829364120721357]
	TIME [epoch: 10.3 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11746576687243007		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.11746576687243007 | validation: 0.14694261700692812]
	TIME [epoch: 10.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12893803241616872		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.12893803241616872 | validation: 0.14651459510770865]
	TIME [epoch: 10.3 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12401431019082179		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.12401431019082179 | validation: 0.1388893946870066]
	TIME [epoch: 10.3 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11318761287556915		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.11318761287556915 | validation: 0.14767189657205282]
	TIME [epoch: 10.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11735873494480431		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.11735873494480431 | validation: 0.14620217000137467]
	TIME [epoch: 10.3 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11737931701309408		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.11737931701309408 | validation: 0.14395252920338064]
	TIME [epoch: 10.3 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12428115057663391		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.12428115057663391 | validation: 0.15539118242947264]
	TIME [epoch: 10.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11616119797831		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.11616119797831 | validation: 0.17594893257320338]
	TIME [epoch: 10.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13254082227897626		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.13254082227897626 | validation: 0.15079245023718207]
	TIME [epoch: 10.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12696445261392783		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.12696445261392783 | validation: 0.15295069939205172]
	TIME [epoch: 10.3 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11444614039099146		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.11444614039099146 | validation: 0.19059139251413584]
	TIME [epoch: 10.3 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15332086116115864		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.15332086116115864 | validation: 0.1640143653721976]
	TIME [epoch: 10.3 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12976869668127616		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.12976869668127616 | validation: 0.15787854950505295]
	TIME [epoch: 10.3 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12824786893800386		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.12824786893800386 | validation: 0.15663979496423486]
	TIME [epoch: 10.3 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13981415919973322		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.13981415919973322 | validation: 0.17369101848366827]
	TIME [epoch: 10.3 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14620811613931642		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.14620811613931642 | validation: 0.18189140764663037]
	TIME [epoch: 10.3 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14221887588510204		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.14221887588510204 | validation: 0.14906656918108144]
	TIME [epoch: 10.3 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13634314214547014		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.13634314214547014 | validation: 0.18272098488637348]
	TIME [epoch: 10.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14603192602378043		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.14603192602378043 | validation: 0.1590553273098182]
	TIME [epoch: 10.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458553810972769		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.1458553810972769 | validation: 0.1638715312281382]
	TIME [epoch: 10.3 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1212360045276765		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.1212360045276765 | validation: 0.15612915728656493]
	TIME [epoch: 10.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11465851680447847		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.11465851680447847 | validation: 0.137792077712428]
	TIME [epoch: 10.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11248108630404577		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.11248108630404577 | validation: 0.17164184855474052]
	TIME [epoch: 10.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1184671219255802		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.1184671219255802 | validation: 0.1358043793101829]
	TIME [epoch: 10.3 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11688237057112286		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.11688237057112286 | validation: 0.1622744945503227]
	TIME [epoch: 10.3 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11774616531279762		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.11774616531279762 | validation: 0.14301051828049946]
	TIME [epoch: 10.3 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12194267562835515		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.12194267562835515 | validation: 0.1690974024988384]
	TIME [epoch: 10.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1199467633215272		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.1199467633215272 | validation: 0.14079261684232822]
	TIME [epoch: 10.3 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09942321053476832		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.09942321053476832 | validation: 0.15214045954775304]
	TIME [epoch: 10.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10917174299494592		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.10917174299494592 | validation: 0.15220158826709973]
	TIME [epoch: 10.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1019942582145172		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.1019942582145172 | validation: 0.13246369294372273]
	TIME [epoch: 10.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11932886367907644		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.11932886367907644 | validation: 0.14856525039981647]
	TIME [epoch: 10.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11414161807539018		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.11414161807539018 | validation: 0.14977890330472773]
	TIME [epoch: 10.3 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12260428495558517		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.12260428495558517 | validation: 0.17957831931482487]
	TIME [epoch: 10.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11955544404785556		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.11955544404785556 | validation: 0.1570120602398861]
	TIME [epoch: 10.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10574993571643605		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.10574993571643605 | validation: 0.12734020822685524]
	TIME [epoch: 10.3 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11141839809174126		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.11141839809174126 | validation: 0.15448639409739032]
	TIME [epoch: 10.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11054973282608145		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.11054973282608145 | validation: 0.13986554878008]
	TIME [epoch: 10.3 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12375436960419932		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.12375436960419932 | validation: 0.1746497421202813]
	TIME [epoch: 10.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13040018052761912		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.13040018052761912 | validation: 0.18620822722761204]
	TIME [epoch: 10.3 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13178346666289706		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.13178346666289706 | validation: 0.1516347674891419]
	TIME [epoch: 10.3 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10599542907979716		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.10599542907979716 | validation: 0.1331839937751746]
	TIME [epoch: 10.3 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09963939154108171		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.09963939154108171 | validation: 0.13125961776223602]
	TIME [epoch: 10.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11691556622380643		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.11691556622380643 | validation: 0.14116249674831616]
	TIME [epoch: 10.3 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11666370288336496		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.11666370288336496 | validation: 0.15484346081573136]
	TIME [epoch: 10.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12758420562656553		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.12758420562656553 | validation: 0.15400852623742944]
	TIME [epoch: 10.3 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12229039791220173		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.12229039791220173 | validation: 0.1871132861929437]
	TIME [epoch: 10.3 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13621370696642532		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.13621370696642532 | validation: 0.15212197108662798]
	TIME [epoch: 10.3 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12696274072461947		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.12696274072461947 | validation: 0.14863147497441137]
	TIME [epoch: 10.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12064288680044732		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.12064288680044732 | validation: 0.1583174129144097]
	TIME [epoch: 10.3 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11919945786248529		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.11919945786248529 | validation: 0.17309919196430248]
	TIME [epoch: 10.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13774458586368266		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.13774458586368266 | validation: 0.1595098677021881]
	TIME [epoch: 10.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12704762302716233		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.12704762302716233 | validation: 0.15840091797765732]
	TIME [epoch: 10.3 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1382995559469725		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.1382995559469725 | validation: 0.18092435035390758]
	TIME [epoch: 10.3 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11792429561782676		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.11792429561782676 | validation: 0.1513837328299495]
	TIME [epoch: 10.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1232142641257461		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.1232142641257461 | validation: 0.1684218017353151]
	TIME [epoch: 10.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12149799875152492		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.12149799875152492 | validation: 0.14833014274864237]
	TIME [epoch: 10.3 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11583567843901241		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.11583567843901241 | validation: 0.1422374590083762]
	TIME [epoch: 10.3 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11523060147552297		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.11523060147552297 | validation: 0.15333033230700566]
	TIME [epoch: 10.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11401697254254092		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.11401697254254092 | validation: 0.15903681904056152]
	TIME [epoch: 10.3 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1226577142322256		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.1226577142322256 | validation: 0.18253336457585181]
	TIME [epoch: 10.3 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14407299684616753		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.14407299684616753 | validation: 0.20847711805305458]
	TIME [epoch: 10.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835791909453239		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.1835791909453239 | validation: 0.1774982106798737]
	TIME [epoch: 10.3 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1464828673052067		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.1464828673052067 | validation: 0.16813698207798947]
	TIME [epoch: 10.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1385829218838985		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.1385829218838985 | validation: 0.15839214175745395]
	TIME [epoch: 10.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12577657360968758		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.12577657360968758 | validation: 0.15509507806268624]
	TIME [epoch: 10.3 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1292151141743412		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.1292151141743412 | validation: 0.16551989308287393]
	TIME [epoch: 10.3 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12752822308409656		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.12752822308409656 | validation: 0.14972393861623876]
	TIME [epoch: 10.3 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10688601127435204		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.10688601127435204 | validation: 0.143218189515856]
	TIME [epoch: 10.3 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11710032280978153		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.11710032280978153 | validation: 0.14535179949662635]
	TIME [epoch: 10.3 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11349403435271274		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.11349403435271274 | validation: 0.15073914460607366]
	TIME [epoch: 10.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.119180641277149		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.119180641277149 | validation: 0.16637250009354812]
	TIME [epoch: 10.3 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1192141839432143		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.1192141839432143 | validation: 0.16948338299069826]
	TIME [epoch: 10.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12505841732966036		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.12505841732966036 | validation: 0.16343748669473104]
	TIME [epoch: 10.2 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14509173662869346		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.14509173662869346 | validation: 0.20057905904650444]
	TIME [epoch: 10.3 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15470887892755367		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.15470887892755367 | validation: 0.18201020266301945]
	TIME [epoch: 10.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13690145656397631		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.13690145656397631 | validation: 0.1574423455268224]
	TIME [epoch: 10.3 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11682032977393193		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.11682032977393193 | validation: 0.13852252315660862]
	TIME [epoch: 10.3 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13150198928740445		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.13150198928740445 | validation: 0.16863712691848332]
	TIME [epoch: 10.3 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13599000954471357		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.13599000954471357 | validation: 0.17195348342894562]
	TIME [epoch: 10.3 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13900091490910832		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.13900091490910832 | validation: 0.18056934962653884]
	TIME [epoch: 10.3 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12043660082390009		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.12043660082390009 | validation: 0.19058113214605485]
	TIME [epoch: 10.3 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13250155661562119		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.13250155661562119 | validation: 0.14581402028515325]
	TIME [epoch: 10.3 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13200910488576278		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.13200910488576278 | validation: 0.17000937448549874]
	TIME [epoch: 10.3 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14054687918418077		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.14054687918418077 | validation: 0.1539054255478915]
	TIME [epoch: 10.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12136504689189487		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.12136504689189487 | validation: 0.13509077559452162]
	TIME [epoch: 10.3 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11904840651542122		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.11904840651542122 | validation: 0.13681850333646836]
	TIME [epoch: 10.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10225558160183097		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.10225558160183097 | validation: 0.1426540106366723]
	TIME [epoch: 10.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10529632178817601		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.10529632178817601 | validation: 0.13547154849111218]
	TIME [epoch: 10.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.119585326086041		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.119585326086041 | validation: 0.14524547205800342]
	TIME [epoch: 10.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11031340058154304		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.11031340058154304 | validation: 0.1522519619600167]
	TIME [epoch: 10.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12114562513012413		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.12114562513012413 | validation: 0.16359703043822535]
	TIME [epoch: 10.3 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10525260849027836		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.10525260849027836 | validation: 0.15584728490678731]
	TIME [epoch: 10.2 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1180532810434863		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.1180532810434863 | validation: 0.14640125346618188]
	TIME [epoch: 10.2 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10579359680532874		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.10579359680532874 | validation: 0.16156776228238517]
	TIME [epoch: 10.3 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11512133098882646		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.11512133098882646 | validation: 0.14451487977757957]
	TIME [epoch: 10.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.124264548235451		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.124264548235451 | validation: 0.15836621376330373]
	TIME [epoch: 10.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12553238230281966		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.12553238230281966 | validation: 0.15152014721442822]
	TIME [epoch: 10.3 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10907458796643492		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.10907458796643492 | validation: 0.14482182611909952]
	TIME [epoch: 10.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11227110342689528		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.11227110342689528 | validation: 0.1288303390189815]
	TIME [epoch: 10.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10729615714841692		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.10729615714841692 | validation: 0.13100226690039782]
	TIME [epoch: 10.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10213468231752305		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.10213468231752305 | validation: 0.15109403344627967]
	TIME [epoch: 10.2 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10064371596718676		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.10064371596718676 | validation: 0.1355749687051303]
	TIME [epoch: 10.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10469107528032957		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.10469107528032957 | validation: 0.13604943063383632]
	TIME [epoch: 10.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10834901895797049		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.10834901895797049 | validation: 0.13770825871503084]
	TIME [epoch: 10.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09977532845773032		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.09977532845773032 | validation: 0.14998208412170538]
	TIME [epoch: 10.3 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1022661591041035		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.1022661591041035 | validation: 0.16531611121269407]
	TIME [epoch: 10.2 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12547073385227245		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.12547073385227245 | validation: 0.1226701038385695]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1634.pth
	Model improved!!!
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751397098615033		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.09751397098615033 | validation: 0.1365718177407117]
	TIME [epoch: 10.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1071422779749002		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.1071422779749002 | validation: 0.17975514514034857]
	TIME [epoch: 10.3 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11205417251236627		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.11205417251236627 | validation: 0.15659419571871738]
	TIME [epoch: 10.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11132048548801339		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.11132048548801339 | validation: 0.1738357930333818]
	TIME [epoch: 10.2 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.108393385758409		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.108393385758409 | validation: 0.13881130022867005]
	TIME [epoch: 10.2 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10485506145435353		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.10485506145435353 | validation: 0.12292476867784316]
	TIME [epoch: 10.3 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09846645016485236		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.09846645016485236 | validation: 0.13475824104954406]
	TIME [epoch: 10.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11246518835085832		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.11246518835085832 | validation: 0.14185810955672368]
	TIME [epoch: 10.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11972378801961621		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.11972378801961621 | validation: 0.13844204729355045]
	TIME [epoch: 10.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10634275480160056		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.10634275480160056 | validation: 0.14227784509083868]
	TIME [epoch: 10.2 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09491413178570059		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.09491413178570059 | validation: 0.1462611782916799]
	TIME [epoch: 10.3 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10416707261712946		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.10416707261712946 | validation: 0.11961597070499376]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1646.pth
	Model improved!!!
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09735856357056671		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.09735856357056671 | validation: 0.1290142320256295]
	TIME [epoch: 10.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10208800322197797		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.10208800322197797 | validation: 0.1267976663408607]
	TIME [epoch: 10.3 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1044994263706845		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.1044994263706845 | validation: 0.1496764047115808]
	TIME [epoch: 10.2 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10541202307418177		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.10541202307418177 | validation: 0.14006997711664074]
	TIME [epoch: 10.3 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1068452298813198		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.1068452298813198 | validation: 0.14893802106467421]
	TIME [epoch: 10.2 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11872789877798635		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.11872789877798635 | validation: 0.15734506951261104]
	TIME [epoch: 10.2 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10785337815164633		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.10785337815164633 | validation: 0.14919479287633455]
	TIME [epoch: 10.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09924134289844594		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.09924134289844594 | validation: 0.1369542600840204]
	TIME [epoch: 10.3 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09190808289644717		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.09190808289644717 | validation: 0.13175830574005595]
	TIME [epoch: 10.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0976917917721759		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.0976917917721759 | validation: 0.13111099259786105]
	TIME [epoch: 10.2 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1044525169760889		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.1044525169760889 | validation: 0.1464248093533887]
	TIME [epoch: 10.2 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144070940534602		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.1144070940534602 | validation: 0.14538933352650646]
	TIME [epoch: 10.2 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11809125858545928		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.11809125858545928 | validation: 0.15219646699175507]
	TIME [epoch: 10.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10836562376310746		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.10836562376310746 | validation: 0.1491623096025178]
	TIME [epoch: 10.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10573280369388778		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.10573280369388778 | validation: 0.1723187446771842]
	TIME [epoch: 10.2 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1336650321910279		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.1336650321910279 | validation: 0.1538305090204696]
	TIME [epoch: 10.2 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11637658752913824		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.11637658752913824 | validation: 0.15569900496971292]
	TIME [epoch: 10.2 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11593853081025154		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.11593853081025154 | validation: 0.15658130001996542]
	TIME [epoch: 10.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12005032921573604		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.12005032921573604 | validation: 0.15936825408393981]
	TIME [epoch: 10.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1243416514261583		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.1243416514261583 | validation: 0.14899751161966884]
	TIME [epoch: 10.3 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11676426845932468		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.11676426845932468 | validation: 0.13182940651141128]
	TIME [epoch: 10.2 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11264091117235028		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.11264091117235028 | validation: 0.13156804881244413]
	TIME [epoch: 10.2 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10497693592200796		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.10497693592200796 | validation: 0.1263178714391044]
	TIME [epoch: 10.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10182316803479988		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.10182316803479988 | validation: 0.14272108964235336]
	TIME [epoch: 10.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10760596031585948		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.10760596031585948 | validation: 0.1449229085659342]
	TIME [epoch: 10.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11503551624883121		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.11503551624883121 | validation: 0.16367548935870432]
	TIME [epoch: 10.3 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12874811812573056		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.12874811812573056 | validation: 0.1655011533334907]
	TIME [epoch: 10.2 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11824999550646038		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.11824999550646038 | validation: 0.1429084524612834]
	TIME [epoch: 10.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10390217120583005		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.10390217120583005 | validation: 0.12466699711270036]
	TIME [epoch: 10.2 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10252135538043927		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.10252135538043927 | validation: 0.14072172600475147]
	TIME [epoch: 10.2 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12249494147129122		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.12249494147129122 | validation: 0.17076868751815302]
	TIME [epoch: 10.2 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11030443387849129		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.11030443387849129 | validation: 0.15809306480702381]
	TIME [epoch: 10.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10827055868693296		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.10827055868693296 | validation: 0.16129045599920772]
	TIME [epoch: 10.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168596896784079		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.1168596896784079 | validation: 0.15269125710395504]
	TIME [epoch: 10.2 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10975933661899728		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.10975933661899728 | validation: 0.15686423819316042]
	TIME [epoch: 10.2 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12359260336631843		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.12359260336631843 | validation: 0.16236988571224217]
	TIME [epoch: 10.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12662246201524624		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.12662246201524624 | validation: 0.16327491068767674]
	TIME [epoch: 10.3 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12422698570955837		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.12422698570955837 | validation: 0.15471037925613698]
	TIME [epoch: 10.3 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11650493567692304		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.11650493567692304 | validation: 0.15525803051208287]
	TIME [epoch: 10.2 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12358539172683439		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.12358539172683439 | validation: 0.13782049317759787]
	TIME [epoch: 10.2 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11499492176270572		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.11499492176270572 | validation: 0.14665262329873885]
	TIME [epoch: 10.2 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1151476334775094		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.1151476334775094 | validation: 0.15766298525089856]
	TIME [epoch: 10.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10373596041593161		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.10373596041593161 | validation: 0.13515728873147506]
	TIME [epoch: 10.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10859909566835926		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.10859909566835926 | validation: 0.15568406700469495]
	TIME [epoch: 10.2 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11046893424615609		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.11046893424615609 | validation: 0.15035468738656227]
	TIME [epoch: 10.2 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12245249797650852		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.12245249797650852 | validation: 0.16385982385639758]
	TIME [epoch: 10.2 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11180537208110426		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.11180537208110426 | validation: 0.1555451599619602]
	TIME [epoch: 10.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10879964149503363		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.10879964149503363 | validation: 0.15038322656587214]
	TIME [epoch: 10.2 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10709994815090984		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.10709994815090984 | validation: 0.147074442572208]
	TIME [epoch: 10.2 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12500007024632334		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.12500007024632334 | validation: 0.18025702655082293]
	TIME [epoch: 10.2 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13413322312246		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.13413322312246 | validation: 0.1708271815796039]
	TIME [epoch: 10.2 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1283991796937003		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.1283991796937003 | validation: 0.15347101996189874]
	TIME [epoch: 10.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12994662308856744		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.12994662308856744 | validation: 0.1846152414856307]
	TIME [epoch: 10.2 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13545227978722624		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.13545227978722624 | validation: 0.17464396652831807]
	TIME [epoch: 10.3 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13772660096140743		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.13772660096140743 | validation: 0.18751079881599217]
	TIME [epoch: 10.2 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14057671307119152		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.14057671307119152 | validation: 0.17959836191036765]
	TIME [epoch: 10.2 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12928252264069368		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.12928252264069368 | validation: 0.14184257832879474]
	TIME [epoch: 10.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1261047711996607		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.1261047711996607 | validation: 0.14543227934486422]
	TIME [epoch: 10.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11206127124459013		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.11206127124459013 | validation: 0.1475559863872718]
	TIME [epoch: 10.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10969453389978683		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.10969453389978683 | validation: 0.14330342899953494]
	TIME [epoch: 10.2 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1123972461672988		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.1123972461672988 | validation: 0.15086419467474385]
	TIME [epoch: 10.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10564160561680794		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.10564160561680794 | validation: 0.14389016701769247]
	TIME [epoch: 10.2 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1094332233568412		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.1094332233568412 | validation: 0.14138484199223805]
	TIME [epoch: 10.2 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10786227226232477		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.10786227226232477 | validation: 0.1477759145145516]
	TIME [epoch: 10.2 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11169017900242287		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.11169017900242287 | validation: 0.1541978743038813]
	TIME [epoch: 10.2 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1192578627338727		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.1192578627338727 | validation: 0.13081025596868334]
	TIME [epoch: 10.3 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10930869720974919		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.10930869720974919 | validation: 0.15187915360749435]
	TIME [epoch: 10.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11092656789883933		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.11092656789883933 | validation: 0.1392902560984743]
	TIME [epoch: 10.2 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10553895629905104		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.10553895629905104 | validation: 0.14134261074573817]
	TIME [epoch: 10.2 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10237269985476365		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.10237269985476365 | validation: 0.13456782984095067]
	TIME [epoch: 10.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10584508816139201		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.10584508816139201 | validation: 0.13643060481501867]
	TIME [epoch: 10.3 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10692516947439401		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.10692516947439401 | validation: 0.14147719544759962]
	TIME [epoch: 10.3 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10721644314701584		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.10721644314701584 | validation: 0.15155828952224892]
	TIME [epoch: 10.2 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11946242634126739		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.11946242634126739 | validation: 0.1569717779358101]
	TIME [epoch: 10.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11363065795191188		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.11363065795191188 | validation: 0.1730149350767819]
	TIME [epoch: 10.3 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11790591830099681		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.11790591830099681 | validation: 0.15772911828475902]
	TIME [epoch: 10.3 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10702392610137183		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.10702392610137183 | validation: 0.14305337686353636]
	TIME [epoch: 10.3 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0984941952467104		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.0984941952467104 | validation: 0.13916542488663664]
	TIME [epoch: 10.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11032413821820311		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.11032413821820311 | validation: 0.14323671756863973]
	TIME [epoch: 10.2 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10762183818262343		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.10762183818262343 | validation: 0.1622480083617118]
	TIME [epoch: 10.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10538829654600727		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.10538829654600727 | validation: 0.14193207895322577]
	TIME [epoch: 10.3 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09530439043384231		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.09530439043384231 | validation: 0.12716776909066396]
	TIME [epoch: 10.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09384957817666766		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.09384957817666766 | validation: 0.14276940863187362]
	TIME [epoch: 10.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10073196326384762		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.10073196326384762 | validation: 0.13488144336775051]
	TIME [epoch: 10.3 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.101604429846573		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.101604429846573 | validation: 0.1354298980502602]
	TIME [epoch: 10.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10432925614842403		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.10432925614842403 | validation: 0.14089212303134374]
	TIME [epoch: 10.3 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10667504446760696		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.10667504446760696 | validation: 0.14054653191425653]
	TIME [epoch: 10.2 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1042215474678003		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.1042215474678003 | validation: 0.1653750286988944]
	TIME [epoch: 10.2 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10023778593427093		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.10023778593427093 | validation: 0.13416193854132177]
	TIME [epoch: 10.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09941179427109241		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.09941179427109241 | validation: 0.1582479566998073]
	TIME [epoch: 10.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483319117259451		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.10483319117259451 | validation: 0.1573443373389159]
	TIME [epoch: 10.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09755895901090811		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.09755895901090811 | validation: 0.14425106653065584]
	TIME [epoch: 10.3 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10556297635716747		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.10556297635716747 | validation: 0.1477569770683478]
	TIME [epoch: 10.3 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10457423821034526		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.10457423821034526 | validation: 0.16651896290103643]
	TIME [epoch: 10.2 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10954903781417971		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.10954903781417971 | validation: 0.1544167699198917]
	TIME [epoch: 10.3 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10941608212710234		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.10941608212710234 | validation: 0.1577706858657392]
	TIME [epoch: 10.2 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10014742207317066		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.10014742207317066 | validation: 0.15534464224678757]
	TIME [epoch: 10.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09982950735632637		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.09982950735632637 | validation: 0.1347263489673551]
	TIME [epoch: 10.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10378553954732464		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.10378553954732464 | validation: 0.14773658629854644]
	TIME [epoch: 10.3 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1052143256602474		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.1052143256602474 | validation: 0.1579444496629756]
	TIME [epoch: 10.3 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1091830117936009		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.1091830117936009 | validation: 0.15050161098235182]
	TIME [epoch: 10.3 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1134205231240609		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.1134205231240609 | validation: 0.16547632044225138]
	TIME [epoch: 10.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.106830569315476		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.106830569315476 | validation: 0.14275994105385764]
	TIME [epoch: 10.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11310658104114593		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.11310658104114593 | validation: 0.1357988047840174]
	TIME [epoch: 10.3 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09758056949209021		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.09758056949209021 | validation: 0.12946587118281846]
	TIME [epoch: 10.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10067600325399277		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.10067600325399277 | validation: 0.14267129261083283]
	TIME [epoch: 10.3 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10166812743160518		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.10166812743160518 | validation: 0.15031822186293975]
	TIME [epoch: 10.2 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10041526293062968		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.10041526293062968 | validation: 0.13457748627906665]
	TIME [epoch: 10.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09604419640145241		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.09604419640145241 | validation: 0.1328616561086164]
	TIME [epoch: 10.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10779972578557598		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.10779972578557598 | validation: 0.14931110981069995]
	TIME [epoch: 10.2 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1059261510248819		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.1059261510248819 | validation: 0.13214040647109893]
	TIME [epoch: 10.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09604825069327723		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.09604825069327723 | validation: 0.15246218494916774]
	TIME [epoch: 10.2 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12239143153946064		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.12239143153946064 | validation: 0.14854429316950138]
	TIME [epoch: 10.2 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10307193636948216		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.10307193636948216 | validation: 0.1436919852140423]
	TIME [epoch: 10.3 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09950085218977078		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.09950085218977078 | validation: 0.13776586293234702]
	TIME [epoch: 10.2 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09266988373119626		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.09266988373119626 | validation: 0.1376542898116403]
	TIME [epoch: 10.3 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1009107947070148		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.1009107947070148 | validation: 0.13018751643346352]
	TIME [epoch: 10.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.106693199557654		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.106693199557654 | validation: 0.15343936905354894]
	TIME [epoch: 10.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10793945840112233		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.10793945840112233 | validation: 0.12847574445165139]
	TIME [epoch: 10.3 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10487084177998962		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.10487084177998962 | validation: 0.14478206836574947]
	TIME [epoch: 10.2 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10575794977909363		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.10575794977909363 | validation: 0.13452225021098613]
	TIME [epoch: 10.2 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10716866184733687		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.10716866184733687 | validation: 0.1349005054599199]
	TIME [epoch: 10.3 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10155408359665426		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.10155408359665426 | validation: 0.1513697131462304]
	TIME [epoch: 10.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09920863097126464		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.09920863097126464 | validation: 0.14015143660829849]
	TIME [epoch: 10.3 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10727815268931025		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.10727815268931025 | validation: 0.1447709892982784]
	TIME [epoch: 10.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10551526349853854		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.10551526349853854 | validation: 0.14653520757051305]
	TIME [epoch: 10.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11438394312900527		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.11438394312900527 | validation: 0.1492363919469609]
	TIME [epoch: 10.2 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10645661428439945		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.10645661428439945 | validation: 0.12960874613499576]
	TIME [epoch: 10.3 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10289532749091261		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.10289532749091261 | validation: 0.14243581412979564]
	TIME [epoch: 10.2 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10178923293855473		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.10178923293855473 | validation: 0.12433034763615805]
	TIME [epoch: 10.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.097413817540035		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.097413817540035 | validation: 0.1392099245941465]
	TIME [epoch: 10.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09890713704936967		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.09890713704936967 | validation: 0.13700964180767902]
	TIME [epoch: 10.3 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09965620674883134		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.09965620674883134 | validation: 0.13038377073723936]
	TIME [epoch: 10.3 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0932776869126738		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.0932776869126738 | validation: 0.13312935281644828]
	TIME [epoch: 10.2 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12059536654620015		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.12059536654620015 | validation: 0.1480011762855941]
	TIME [epoch: 10.2 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10838464197795827		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.10838464197795827 | validation: 0.1416185228288136]
	TIME [epoch: 10.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10029256624533825		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.10029256624533825 | validation: 0.14905079890237558]
	TIME [epoch: 10.2 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09897035765637731		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.09897035765637731 | validation: 0.14057270383477533]
	TIME [epoch: 10.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1020588423939078		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.1020588423939078 | validation: 0.14437671071417818]
	TIME [epoch: 10.3 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11769655184115409		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.11769655184115409 | validation: 0.13981535526623243]
	TIME [epoch: 10.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10332527616651277		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.10332527616651277 | validation: 0.14159774130209482]
	TIME [epoch: 10.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10936912732589285		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.10936912732589285 | validation: 0.14103997569610696]
	TIME [epoch: 10.3 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09844246242481355		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.09844246242481355 | validation: 0.13075427546036902]
	TIME [epoch: 10.3 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09984215120806898		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.09984215120806898 | validation: 0.13018627521984133]
	TIME [epoch: 10.2 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09578353158234368		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.09578353158234368 | validation: 0.130422196110733]
	TIME [epoch: 10.2 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10150571986389997		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.10150571986389997 | validation: 0.1439655297657045]
	TIME [epoch: 10.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10349068693448019		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.10349068693448019 | validation: 0.14207644232054198]
	TIME [epoch: 10.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10986431796328418		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.10986431796328418 | validation: 0.14350051478334447]
	TIME [epoch: 10.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10461775368815096		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.10461775368815096 | validation: 0.14051810210511811]
	TIME [epoch: 10.2 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10020236114990015		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.10020236114990015 | validation: 0.14102047823932065]
	TIME [epoch: 10.2 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10281503268008921		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.10281503268008921 | validation: 0.136764596723239]
	TIME [epoch: 10.2 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10318637984677223		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.10318637984677223 | validation: 0.14250502847457944]
	TIME [epoch: 10.3 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10543781557424581		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.10543781557424581 | validation: 0.15470078034681534]
	TIME [epoch: 10.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11591042868629722		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.11591042868629722 | validation: 0.14281998406971658]
	TIME [epoch: 10.3 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11632906201191862		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.11632906201191862 | validation: 0.13478276842779782]
	TIME [epoch: 10.2 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1051040077673591		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.1051040077673591 | validation: 0.1571579593179502]
	TIME [epoch: 10.2 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10963522618743585		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.10963522618743585 | validation: 0.15793242274544614]
	TIME [epoch: 10.3 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10339719484783363		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.10339719484783363 | validation: 0.13743692922614031]
	TIME [epoch: 10.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10268231321466459		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.10268231321466459 | validation: 0.12493923368964616]
	TIME [epoch: 10.3 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09933535890947116		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.09933535890947116 | validation: 0.15170693353121797]
	TIME [epoch: 10.2 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09720105767452954		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.09720105767452954 | validation: 0.1538614504904111]
	TIME [epoch: 10.2 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10813270161509561		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.10813270161509561 | validation: 0.1285468754736475]
	TIME [epoch: 10.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.099902234359557		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.099902234359557 | validation: 0.13203599137036431]
	TIME [epoch: 10.3 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10737866954594541		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.10737866954594541 | validation: 0.13825165290471236]
	TIME [epoch: 10.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10176329473023527		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.10176329473023527 | validation: 0.13393000128643606]
	TIME [epoch: 10.3 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10678186499842186		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.10678186499842186 | validation: 0.13359893839335507]
	TIME [epoch: 10.3 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11135745055206467		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.11135745055206467 | validation: 0.14949072336489233]
	TIME [epoch: 10.3 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10826655767951868		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.10826655767951868 | validation: 0.17331332503470215]
	TIME [epoch: 10.2 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12168420167457865		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.12168420167457865 | validation: 0.16241009753686086]
	TIME [epoch: 10.2 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12900163244376997		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.12900163244376997 | validation: 0.16833812361778505]
	TIME [epoch: 10.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11364537638665342		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.11364537638665342 | validation: 0.15989544217457188]
	TIME [epoch: 10.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11901289901901724		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.11901289901901724 | validation: 0.1813535435925849]
	TIME [epoch: 10.3 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11441269373509037		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.11441269373509037 | validation: 0.16255189255306754]
	TIME [epoch: 10.2 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11346885793851066		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.11346885793851066 | validation: 0.17166830214680803]
	TIME [epoch: 10.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11662508030385232		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.11662508030385232 | validation: 0.15136998681486685]
	TIME [epoch: 10.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12819576362202703		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.12819576362202703 | validation: 0.14707473980407262]
	TIME [epoch: 10.3 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11261853296138462		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.11261853296138462 | validation: 0.1695019155636993]
	TIME [epoch: 10.3 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10601636150207223		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.10601636150207223 | validation: 0.13595806709905056]
	TIME [epoch: 10.2 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10712389684334386		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.10712389684334386 | validation: 0.15632170263016]
	TIME [epoch: 10.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11768822192079545		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.11768822192079545 | validation: 0.14585675304043252]
	TIME [epoch: 10.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1255720762258155		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.1255720762258155 | validation: 0.14258405723231912]
	TIME [epoch: 10.3 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12173158401321729		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.12173158401321729 | validation: 0.1737534897066716]
	TIME [epoch: 10.3 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12764404846622848		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.12764404846622848 | validation: 0.15078196802915877]
	TIME [epoch: 10.3 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12005793052636753		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.12005793052636753 | validation: 0.1503919318985837]
	TIME [epoch: 10.2 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253312222161508		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.1253312222161508 | validation: 0.16227868529579204]
	TIME [epoch: 10.3 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13573913423116152		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.13573913423116152 | validation: 0.15868831933729677]
	TIME [epoch: 10.3 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1299580855560668		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.1299580855560668 | validation: 0.17253527569730934]
	TIME [epoch: 10.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13453499457159693		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.13453499457159693 | validation: 0.17543681520688334]
	TIME [epoch: 10.3 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12272891963783321		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.12272891963783321 | validation: 0.14972736376897824]
	TIME [epoch: 10.3 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12780833828815738		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.12780833828815738 | validation: 0.13888643466697617]
	TIME [epoch: 10.3 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11393774931654965		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.11393774931654965 | validation: 0.16824173739250955]
	TIME [epoch: 10.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1243506719463229		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.1243506719463229 | validation: 0.15166404165710806]
	TIME [epoch: 10.2 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11999108794416098		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.11999108794416098 | validation: 0.1390553454860616]
	TIME [epoch: 10.3 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11092909281903145		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.11092909281903145 | validation: 0.15790995061058272]
	TIME [epoch: 10.2 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11309897858364495		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.11309897858364495 | validation: 0.1292553928760044]
	TIME [epoch: 10.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11124935134569561		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.11124935134569561 | validation: 0.14381999292967837]
	TIME [epoch: 10.2 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10964574321022942		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.10964574321022942 | validation: 0.13455157037305135]
	TIME [epoch: 10.2 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10975159053919496		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.10975159053919496 | validation: 0.13034917281303446]
	TIME [epoch: 10.3 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10753909098100216		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.10753909098100216 | validation: 0.13357623160421972]
	TIME [epoch: 10.3 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10652814323111506		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.10652814323111506 | validation: 0.1336737319324444]
	TIME [epoch: 10.3 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1059013669850453		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.1059013669850453 | validation: 0.1419833956643992]
	TIME [epoch: 10.3 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1105157362025149		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.1105157362025149 | validation: 0.13941184134403567]
	TIME [epoch: 10.3 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11496353429763559		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.11496353429763559 | validation: 0.15310108902919073]
	TIME [epoch: 10.3 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11534053051989235		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.11534053051989235 | validation: 0.1363358813935974]
	TIME [epoch: 10.3 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10929991412749984		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.10929991412749984 | validation: 0.15597600109550253]
	TIME [epoch: 10.3 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10635173993566831		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.10635173993566831 | validation: 0.13538091517198728]
	TIME [epoch: 10.3 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10965332640622558		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.10965332640622558 | validation: 0.13687904420299152]
	TIME [epoch: 10.3 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10060661921316624		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.10060661921316624 | validation: 0.12826468758848794]
	TIME [epoch: 10.2 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10352521312263181		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.10352521312263181 | validation: 0.1414545833537554]
	TIME [epoch: 10.3 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10432949570981805		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.10432949570981805 | validation: 0.14063274400357886]
	TIME [epoch: 10.3 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11481216637809337		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.11481216637809337 | validation: 0.14534305906629716]
	TIME [epoch: 10.3 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11562263509525879		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.11562263509525879 | validation: 0.1300222665059572]
	TIME [epoch: 10.3 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09729146380061267		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.09729146380061267 | validation: 0.1465087553749154]
	TIME [epoch: 10.2 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10987585227929295		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.10987585227929295 | validation: 0.14147335798780053]
	TIME [epoch: 10.3 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10733082975273425		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.10733082975273425 | validation: 0.13806992880692043]
	TIME [epoch: 10.3 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11134806957099183		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.11134806957099183 | validation: 0.13629360567081206]
	TIME [epoch: 10.3 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10828734698265827		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.10828734698265827 | validation: 0.15115834597988434]
	TIME [epoch: 10.3 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11454772851591336		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.11454772851591336 | validation: 0.1537357924787545]
	TIME [epoch: 10.2 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11392451097853198		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.11392451097853198 | validation: 0.14669602060952053]
	TIME [epoch: 10.3 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1210450889730875		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.1210450889730875 | validation: 0.15084853206545837]
	TIME [epoch: 10.3 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09991647849285648		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.09991647849285648 | validation: 0.13749446780385693]
	TIME [epoch: 10.3 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10246485563457859		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.10246485563457859 | validation: 0.13677861206721512]
	TIME [epoch: 10.3 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10730514013892845		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.10730514013892845 | validation: 0.15370406211586232]
	TIME [epoch: 10.3 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10410741632200027		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.10410741632200027 | validation: 0.13590148864186316]
	TIME [epoch: 10.3 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09944727327138006		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.09944727327138006 | validation: 0.14320205891606785]
	TIME [epoch: 10.3 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10526515638621141		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.10526515638621141 | validation: 0.1586111660710106]
	TIME [epoch: 10.2 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1081272769028017		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.1081272769028017 | validation: 0.14497982021105307]
	TIME [epoch: 10.2 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10458492364222424		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.10458492364222424 | validation: 0.1363746466293974]
	TIME [epoch: 10.3 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10405972674407178		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.10405972674407178 | validation: 0.12781073292595982]
	TIME [epoch: 10.3 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11651977589456489		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.11651977589456489 | validation: 0.14414581065657925]
	TIME [epoch: 10.3 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11329489479805448		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.11329489479805448 | validation: 0.13529939600020519]
	TIME [epoch: 10.3 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09855037176517079		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.09855037176517079 | validation: 0.13018871240611676]
	TIME [epoch: 10.2 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10835514592231663		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.10835514592231663 | validation: 0.15162735833133817]
	TIME [epoch: 10.3 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10964415524125323		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.10964415524125323 | validation: 0.13782258521165075]
	TIME [epoch: 10.3 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10809271755681567		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.10809271755681567 | validation: 0.1418310732502924]
	TIME [epoch: 10.3 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11029550244121869		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.11029550244121869 | validation: 0.1580212668934411]
	TIME [epoch: 10.3 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10555977025563452		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.10555977025563452 | validation: 0.15064759556468482]
	TIME [epoch: 10.2 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10542371642282991		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.10542371642282991 | validation: 0.15527585338859046]
	TIME [epoch: 10.3 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10536072864608384		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.10536072864608384 | validation: 0.1293413111985609]
	TIME [epoch: 10.3 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10446771097272622		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.10446771097272622 | validation: 0.14757185251613766]
	TIME [epoch: 10.3 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10856997309326384		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.10856997309326384 | validation: 0.17852006788758182]
	TIME [epoch: 10.3 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11646490851475513		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.11646490851475513 | validation: 0.13880854868451686]
	TIME [epoch: 10.3 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11537943340022386		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.11537943340022386 | validation: 0.142072659604399]
	TIME [epoch: 10.3 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11118051303703562		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.11118051303703562 | validation: 0.13303048674000897]
	TIME [epoch: 10.3 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10428666845008172		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.10428666845008172 | validation: 0.14092025233140767]
	TIME [epoch: 10.3 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1127071150187398		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.1127071150187398 | validation: 0.14584014195106051]
	TIME [epoch: 10.3 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11565720440048603		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.11565720440048603 | validation: 0.15816288257887862]
	TIME [epoch: 10.3 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11911922587444224		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.11911922587444224 | validation: 0.15278591774046285]
	TIME [epoch: 10.3 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10575084349834654		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.10575084349834654 | validation: 0.14420281671120486]
	TIME [epoch: 10.2 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10396517517486965		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.10396517517486965 | validation: 0.145528704517353]
	TIME [epoch: 10.3 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10169509134382629		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.10169509134382629 | validation: 0.14662758987670374]
	TIME [epoch: 10.2 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09885380440654165		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.09885380440654165 | validation: 0.12866256155250558]
	TIME [epoch: 10.3 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10933830248629901		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.10933830248629901 | validation: 0.14990735219512946]
	TIME [epoch: 10.3 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11184034738721327		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.11184034738721327 | validation: 0.15005745615567]
	TIME [epoch: 10.3 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10366476984649267		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.10366476984649267 | validation: 0.1537033547550955]
	TIME [epoch: 10.2 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10187796920986218		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.10187796920986218 | validation: 0.13791689719886863]
	TIME [epoch: 10.3 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10607127538312473		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.10607127538312473 | validation: 0.12958762273327384]
	TIME [epoch: 10.3 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10937489996083014		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.10937489996083014 | validation: 0.13459315265882288]
	TIME [epoch: 10.3 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10294122507966368		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.10294122507966368 | validation: 0.13023127043819094]
	TIME [epoch: 10.3 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09866102031157044		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.09866102031157044 | validation: 0.1371783856054504]
	TIME [epoch: 10.3 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10584675902458292		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.10584675902458292 | validation: 0.1398954690336582]
	TIME [epoch: 10.2 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11322196723090708		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.11322196723090708 | validation: 0.14150130878121214]
	TIME [epoch: 10.3 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10693316617279029		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.10693316617279029 | validation: 0.15043524968055835]
	TIME [epoch: 10.3 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09814954109282281		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.09814954109282281 | validation: 0.13447139200537855]
	TIME [epoch: 10.3 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11369834707996225		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.11369834707996225 | validation: 0.1592777176660492]
	TIME [epoch: 10.2 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1109071834052878		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.1109071834052878 | validation: 0.13778953945536565]
	TIME [epoch: 10.3 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10633596837626073		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.10633596837626073 | validation: 0.1445307356762566]
	TIME [epoch: 10.3 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10506380589294113		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.10506380589294113 | validation: 0.13587895073398967]
	TIME [epoch: 10.3 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10534363798493876		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.10534363798493876 | validation: 0.1319667712564343]
	TIME [epoch: 10.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1053804933293598		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.1053804933293598 | validation: 0.13650015487486244]
	TIME [epoch: 10.3 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11262397083314994		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.11262397083314994 | validation: 0.14791675897137677]
	TIME [epoch: 10.3 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12239937873653824		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.12239937873653824 | validation: 0.13758461439596997]
	TIME [epoch: 10.3 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10726390553402791		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.10726390553402791 | validation: 0.1420905458772788]
	TIME [epoch: 10.3 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09959780327430431		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.09959780327430431 | validation: 0.14488700416524386]
	TIME [epoch: 10.2 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10641371146972012		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.10641371146972012 | validation: 0.1340338792913595]
	TIME [epoch: 10.3 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10037704274065437		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.10037704274065437 | validation: 0.12064874254707221]
	TIME [epoch: 10.3 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1001822385838956		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.1001822385838956 | validation: 0.14476191449976175]
	TIME [epoch: 10.3 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10423272149733906		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.10423272149733906 | validation: 0.11941231047756555]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1924.pth
	Model improved!!!
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10291216051024026		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.10291216051024026 | validation: 0.14426668069221704]
	TIME [epoch: 10.3 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09847166990712966		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.09847166990712966 | validation: 0.12046573237956923]
	TIME [epoch: 10.3 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09206641592013501		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.09206641592013501 | validation: 0.14769747195313476]
	TIME [epoch: 10.3 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1050596908739457		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.1050596908739457 | validation: 0.1383393887700069]
	TIME [epoch: 10.3 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10722103490337251		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.10722103490337251 | validation: 0.13909293759151617]
	TIME [epoch: 10.3 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10704684508451585		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.10704684508451585 | validation: 0.1458225207237833]
	TIME [epoch: 10.2 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10178058003028523		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.10178058003028523 | validation: 0.1317464797310175]
	TIME [epoch: 10.3 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09725068626542173		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.09725068626542173 | validation: 0.1396979896056101]
	TIME [epoch: 10.3 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09816220841062183		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.09816220841062183 | validation: 0.11314950213382635]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r3_20240219_190607/states/model_tr_study6_1933.pth
	Model improved!!!
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10361773880493667		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.10361773880493667 | validation: 0.12955250657437375]
	TIME [epoch: 10.3 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10255674785908657		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.10255674785908657 | validation: 0.13039318289685733]
	TIME [epoch: 10.3 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10088229415139431		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.10088229415139431 | validation: 0.15054598359125204]
	TIME [epoch: 10.3 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1100217139592314		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.1100217139592314 | validation: 0.1303809191334658]
	TIME [epoch: 10.3 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10805326010312521		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.10805326010312521 | validation: 0.1338478475140954]
	TIME [epoch: 10.2 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09570221279664873		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.09570221279664873 | validation: 0.12292764816681136]
	TIME [epoch: 10.2 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10326663645145868		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.10326663645145868 | validation: 0.1395277559060707]
	TIME [epoch: 10.2 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10598238216317968		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.10598238216317968 | validation: 0.1396057214493831]
	TIME [epoch: 10.3 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10712692055877324		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.10712692055877324 | validation: 0.13422049391270996]
	TIME [epoch: 10.2 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1159460496074		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.1159460496074 | validation: 0.14910087214321657]
	TIME [epoch: 10.2 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.101321241098202		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.101321241098202 | validation: 0.1360940869497723]
	TIME [epoch: 10.3 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09206397313893587		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.09206397313893587 | validation: 0.12964948106180402]
	TIME [epoch: 10.2 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.103020839886424		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.103020839886424 | validation: 0.12662462799812174]
	TIME [epoch: 10.3 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966816923133995		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.09966816923133995 | validation: 0.13043739345914895]
	TIME [epoch: 10.2 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09604772351157317		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.09604772351157317 | validation: 0.12630266798160875]
	TIME [epoch: 10.3 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0974366816704801		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.0974366816704801 | validation: 0.12603163175778598]
	TIME [epoch: 10.3 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09123596538404465		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.09123596538404465 | validation: 0.1318324451332205]
	TIME [epoch: 10.3 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09975997542391188		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.09975997542391188 | validation: 0.13491126931912534]
	TIME [epoch: 10.3 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851828150617876		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.09851828150617876 | validation: 0.12504065954756752]
	TIME [epoch: 10.2 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09649599199528403		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.09649599199528403 | validation: 0.13726248293847818]
	TIME [epoch: 10.3 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1006585647097418		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.1006585647097418 | validation: 0.13719783902454805]
	TIME [epoch: 10.2 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10177444277053693		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.10177444277053693 | validation: 0.14082163199204764]
	TIME [epoch: 10.3 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10276158326405833		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.10276158326405833 | validation: 0.13247356130413873]
	TIME [epoch: 10.3 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10864562837675387		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.10864562837675387 | validation: 0.13379156585980354]
	TIME [epoch: 10.2 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10367604075881069		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.10367604075881069 | validation: 0.13016452229863082]
	TIME [epoch: 10.2 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946849012303783		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.10946849012303783 | validation: 0.14012251694107217]
	TIME [epoch: 10.2 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10199716621043291		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.10199716621043291 | validation: 0.13530167011990718]
	TIME [epoch: 10.3 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09147398369263976		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.09147398369263976 | validation: 0.14864155154401248]
	TIME [epoch: 10.3 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10077410006798662		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.10077410006798662 | validation: 0.12483334962718438]
	TIME [epoch: 10.3 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11184398046074787		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.11184398046074787 | validation: 0.14286941243619583]
	TIME [epoch: 10.3 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1090860698887641		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.1090860698887641 | validation: 0.13931500032494323]
	TIME [epoch: 10.2 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10460037055299179		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.10460037055299179 | validation: 0.14480024755604812]
	TIME [epoch: 10.3 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12020998228892361		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.12020998228892361 | validation: 0.16274769472713374]
	TIME [epoch: 10.3 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11950181953593489		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.11950181953593489 | validation: 0.13896066526535308]
	TIME [epoch: 10.3 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1108962760202662		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.1108962760202662 | validation: 0.13059645710823525]
	TIME [epoch: 10.3 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11104010066873342		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.11104010066873342 | validation: 0.14401013226705892]
	TIME [epoch: 10.3 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10999540728126178		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.10999540728126178 | validation: 0.1437109599464412]
	TIME [epoch: 10.3 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11344604632838876		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.11344604632838876 | validation: 0.15297545487320452]
	TIME [epoch: 10.3 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11165944503068173		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.11165944503068173 | validation: 0.14570007503241947]
	TIME [epoch: 10.3 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10910201283800809		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.10910201283800809 | validation: 0.13128053807983536]
	TIME [epoch: 10.3 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0991772774330094		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.0991772774330094 | validation: 0.12288398691727453]
	TIME [epoch: 10.3 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10161971754093424		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.10161971754093424 | validation: 0.15079552182327577]
	TIME [epoch: 10.3 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10982001745767564		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.10982001745767564 | validation: 0.13175588145173073]
	TIME [epoch: 10.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12234665941900842		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.12234665941900842 | validation: 0.15714197142279043]
	TIME [epoch: 10.2 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1150965775676737		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.1150965775676737 | validation: 0.16378283702752705]
	TIME [epoch: 10.3 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10668337541777762		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.10668337541777762 | validation: 0.12548152363030984]
	TIME [epoch: 10.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10390676474461395		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.10390676474461395 | validation: 0.13467410849647746]
	TIME [epoch: 10.3 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034186528878985		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.1034186528878985 | validation: 0.13922070321725785]
	TIME [epoch: 10.3 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10672332166697536		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.10672332166697536 | validation: 0.14731607856487602]
	TIME [epoch: 10.3 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10494307900170477		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.10494307900170477 | validation: 0.13464719428612154]
	TIME [epoch: 10.3 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09579975377080618		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.09579975377080618 | validation: 0.13494933478351484]
	TIME [epoch: 10.3 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09605366647568744		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.09605366647568744 | validation: 0.13150030600887816]
	TIME [epoch: 10.3 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034113424143039		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.1034113424143039 | validation: 0.13783176977266742]
	TIME [epoch: 10.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10989325653363999		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.10989325653363999 | validation: 0.13089255756788593]
	TIME [epoch: 10.2 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09727933777679876		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.09727933777679876 | validation: 0.12476353963098077]
	TIME [epoch: 10.3 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10505035199988581		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.10505035199988581 | validation: 0.13480882117134813]
	TIME [epoch: 10.3 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1062160796713522		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.1062160796713522 | validation: 0.11914211650428799]
	TIME [epoch: 10.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10298126794895066		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.10298126794895066 | validation: 0.13169158011814916]
	TIME [epoch: 10.3 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1042220353151789		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.1042220353151789 | validation: 0.14468760848838888]
	TIME [epoch: 10.3 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10943838672051276		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.10943838672051276 | validation: 0.1517108458460549]
	TIME [epoch: 10.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10389551897569613		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.10389551897569613 | validation: 0.1380525571941195]
	TIME [epoch: 10.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10147090785690882		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.10147090785690882 | validation: 0.12821940928688585]
	TIME [epoch: 10.3 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10169524346434285		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.10169524346434285 | validation: 0.1341606177931591]
	TIME [epoch: 10.3 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11513765272206833		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.11513765272206833 | validation: 0.13450664346705424]
	TIME [epoch: 10.3 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09873805227777221		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.09873805227777221 | validation: 0.13053368548187705]
	TIME [epoch: 10.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1036555188859833		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.1036555188859833 | validation: 0.15641529074755312]
	TIME [epoch: 10.3 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10084208806153452		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.10084208806153452 | validation: 0.1313167175793574]
	TIME [epoch: 10.3 sec]
Finished training in 20678.116 seconds.
