Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r2', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3011523825

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.727983754548664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.727983754548664 | validation: 8.164005192414038]
	TIME [epoch: 71.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.593583441233543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.593583441233543 | validation: 7.502181467772386]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.225361771015659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.225361771015659 | validation: 7.122675296944658]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.124250538101225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.124250538101225 | validation: 6.942575664213053]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.9510738661991835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9510738661991835 | validation: 6.8743826738364]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.867746775067024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.867746775067024 | validation: 6.734403764457514]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.853882038623181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.853882038623181 | validation: 6.513618344756192]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.818012071597581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.818012071597581 | validation: 6.463211464280188]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.579886689962889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.579886689962889 | validation: 6.48079903075683]
	TIME [epoch: 10.5 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.52320149209924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.52320149209924 | validation: 6.3243971245347534]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.604023327523349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.604023327523349 | validation: 6.21031477780843]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.572201694970595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.572201694970595 | validation: 6.50696089415994]
	TIME [epoch: 10.5 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.375468870978281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.375468870978281 | validation: 6.736662753932485]
	TIME [epoch: 10.5 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.346931887249552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.346931887249552 | validation: 9.08253386192167]
	TIME [epoch: 10.5 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.07039590949031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.07039590949031 | validation: 6.951602137686262]
	TIME [epoch: 10.5 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4709379093909805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4709379093909805 | validation: 6.3852875859425335]
	TIME [epoch: 10.5 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.405533019460071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.405533019460071 | validation: 6.361588948381199]
	TIME [epoch: 10.5 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.673598953023126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.673598953023126 | validation: 6.395718907509136]
	TIME [epoch: 10.5 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.293485399340017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.293485399340017 | validation: 8.188484666619711]
	TIME [epoch: 10.5 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.434310969556516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.434310969556516 | validation: 6.506232114734741]
	TIME [epoch: 10.5 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.17184318804295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.17184318804295 | validation: 6.213074154485018]
	TIME [epoch: 10.5 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.756625029018426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.756625029018426 | validation: 7.50318229680739]
	TIME [epoch: 10.5 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.5877903763586385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5877903763586385 | validation: 3.8701305105498354]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.144203449073447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.144203449073447 | validation: 9.267106544604786]
	TIME [epoch: 10.5 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.912464504517475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.912464504517475 | validation: 7.5879477074659905]
	TIME [epoch: 10.5 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.801168473930375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.801168473930375 | validation: 6.289581767233633]
	TIME [epoch: 10.5 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.994438442248876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.994438442248876 | validation: 6.38814974659641]
	TIME [epoch: 10.5 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3116926746267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3116926746267 | validation: 6.4430652621985836]
	TIME [epoch: 10.5 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.008975489617078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.008975489617078 | validation: 6.5575465045833425]
	TIME [epoch: 10.5 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.685212532331121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.685212532331121 | validation: 6.612182163169428]
	TIME [epoch: 10.5 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.107653188787478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.107653188787478 | validation: 5.667681315038046]
	TIME [epoch: 10.5 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.806523055140758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.806523055140758 | validation: 8.652358735214722]
	TIME [epoch: 10.5 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.906752940231295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.906752940231295 | validation: 8.144782436991665]
	TIME [epoch: 10.5 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.890416856777234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.890416856777234 | validation: 6.865051752761437]
	TIME [epoch: 10.5 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.295306913990887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.295306913990887 | validation: 6.147869971164462]
	TIME [epoch: 10.5 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.95458815805795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.95458815805795 | validation: 6.255463303994468]
	TIME [epoch: 10.5 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.661806416047233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.661806416047233 | validation: 4.151517183621056]
	TIME [epoch: 10.5 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.357100355343246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.357100355343246 | validation: 4.881774709989948]
	TIME [epoch: 10.5 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.379115668073976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.379115668073976 | validation: 5.0340995413619645]
	TIME [epoch: 10.5 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.013138470255036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.013138470255036 | validation: 6.028994648976473]
	TIME [epoch: 10.5 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.068378794249983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.068378794249983 | validation: 4.615691174123673]
	TIME [epoch: 10.5 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.146143992045542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.146143992045542 | validation: 4.789353689316676]
	TIME [epoch: 10.5 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.15325336618637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.15325336618637 | validation: 6.038124056737054]
	TIME [epoch: 10.5 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.551301279680642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.551301279680642 | validation: 4.430217272373114]
	TIME [epoch: 10.5 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.939111114415532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.939111114415532 | validation: 4.928915986276805]
	TIME [epoch: 10.5 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.127685861991249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.127685861991249 | validation: 4.020576149518027]
	TIME [epoch: 10.5 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.518685716564167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.518685716564167 | validation: 4.805621287881365]
	TIME [epoch: 10.5 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.564475426189501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.564475426189501 | validation: 4.475800161688645]
	TIME [epoch: 10.5 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.189878618002644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.189878618002644 | validation: 4.317791703569099]
	TIME [epoch: 10.5 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.515285103562919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.515285103562919 | validation: 4.378391302265673]
	TIME [epoch: 10.5 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.010777620453913		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 4.010777620453913 | validation: 3.0545920259955044]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6551326892452196		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 3.6551326892452196 | validation: 3.0541040129595247]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6101244112633175		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 3.6101244112633175 | validation: 3.7709054485664355]
	TIME [epoch: 10.5 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.34967355580544		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 4.34967355580544 | validation: 4.023754919891699]
	TIME [epoch: 10.5 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.755262205818794		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 3.755262205818794 | validation: 2.699402641667989]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1461263575622604		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 3.1461263575622604 | validation: 2.697722848905241]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.258425814250299		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 3.258425814250299 | validation: 2.7838480147941844]
	TIME [epoch: 10.5 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.888292729351217		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 4.888292729351217 | validation: 5.441741405469611]
	TIME [epoch: 10.5 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.955342900711203		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 5.955342900711203 | validation: 5.770455626826107]
	TIME [epoch: 10.5 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.302374947797517		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 5.302374947797517 | validation: 6.0687191270180465]
	TIME [epoch: 10.5 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.751087977360235		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 5.751087977360235 | validation: 4.64903977867476]
	TIME [epoch: 10.5 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.760624884864522		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 4.760624884864522 | validation: 4.682610816843447]
	TIME [epoch: 10.5 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.291295205806663		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 5.291295205806663 | validation: 3.934588373155305]
	TIME [epoch: 10.5 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.354254473181488		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 4.354254473181488 | validation: 4.2386946235175]
	TIME [epoch: 10.5 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.200114657578416		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 4.200114657578416 | validation: 5.154342328595842]
	TIME [epoch: 10.5 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.7438805860778		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 4.7438805860778 | validation: 5.064654721591255]
	TIME [epoch: 10.5 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.125959840565737		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 4.125959840565737 | validation: 3.064026096475136]
	TIME [epoch: 10.5 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9594756595633704		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 3.9594756595633704 | validation: 5.749943802906521]
	TIME [epoch: 10.5 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.375419648655096		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.375419648655096 | validation: 6.5624110109182565]
	TIME [epoch: 10.5 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4896915162361655		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 6.4896915162361655 | validation: 6.279745706255202]
	TIME [epoch: 10.5 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.86037166842093		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 5.86037166842093 | validation: 5.363257192394756]
	TIME [epoch: 10.5 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.723913092321761		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 4.723913092321761 | validation: 4.1661808563917235]
	TIME [epoch: 10.5 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.132439814300403		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 4.132439814300403 | validation: 3.82296183075469]
	TIME [epoch: 10.5 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.321739547357227		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 4.321739547357227 | validation: 3.589687206642576]
	TIME [epoch: 10.5 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.018359207483835		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 4.018359207483835 | validation: 4.492379923728451]
	TIME [epoch: 10.5 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.124691997028868		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 5.124691997028868 | validation: 4.391637295361229]
	TIME [epoch: 10.5 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.442886668514722		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 4.442886668514722 | validation: 3.9234125625125236]
	TIME [epoch: 10.5 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.541840413166595		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 5.541840413166595 | validation: 6.557246555821307]
	TIME [epoch: 10.5 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.339012205559264		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 6.339012205559264 | validation: 5.432055769423705]
	TIME [epoch: 10.5 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.860876394962608		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 5.860876394962608 | validation: 5.27588392365326]
	TIME [epoch: 10.5 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.365536650238502		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 5.365536650238502 | validation: 4.305696554949731]
	TIME [epoch: 10.5 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.694080752361776		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 4.694080752361776 | validation: 4.092462662443516]
	TIME [epoch: 10.5 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.245200703151832		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 4.245200703151832 | validation: 4.039160254754533]
	TIME [epoch: 10.5 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.4831204576316654		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 4.4831204576316654 | validation: 3.3046275804110135]
	TIME [epoch: 10.5 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8176915301602414		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 3.8176915301602414 | validation: 4.519805216266613]
	TIME [epoch: 10.5 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.357373605449508		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 5.357373605449508 | validation: 4.935488886894568]
	TIME [epoch: 10.5 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.311237930030007		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 4.311237930030007 | validation: 3.11832242692766]
	TIME [epoch: 10.5 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6757779302748306		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 3.6757779302748306 | validation: 3.089012471423333]
	TIME [epoch: 10.5 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7655226185185113		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 3.7655226185185113 | validation: 3.2254794098973596]
	TIME [epoch: 10.5 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.159403058527471		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 4.159403058527471 | validation: 4.8366861891177955]
	TIME [epoch: 10.5 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.82657759805629		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 4.82657759805629 | validation: 4.762646212299186]
	TIME [epoch: 10.5 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.955026007578064		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 4.955026007578064 | validation: 5.6079070847836965]
	TIME [epoch: 10.5 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.369881780207731		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 5.369881780207731 | validation: 5.550266264885048]
	TIME [epoch: 10.5 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.940021986448821		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 4.940021986448821 | validation: 4.722203698260373]
	TIME [epoch: 10.5 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.350805010308168		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 4.350805010308168 | validation: 3.1895289339015465]
	TIME [epoch: 10.5 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4942679982346574		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 3.4942679982346574 | validation: 3.016516660140393]
	TIME [epoch: 10.5 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.351367415855063		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 3.351367415855063 | validation: 3.3030059149797215]
	TIME [epoch: 10.5 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.483335512247488		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 3.483335512247488 | validation: 2.5674484112124225]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2951778797993256		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 3.2951778797993256 | validation: 2.760329789787928]
	TIME [epoch: 10.5 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1941065223880036		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 3.1941065223880036 | validation: 2.39869196023419]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_100.pth
	Model improved!!!
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.088093120330243		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 3.088093120330243 | validation: 2.4747131067644528]
	TIME [epoch: 10.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.161678508504614		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 3.161678508504614 | validation: 2.9891711571193005]
	TIME [epoch: 10.5 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2956284014270616		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 3.2956284014270616 | validation: 3.0103284761132962]
	TIME [epoch: 10.5 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.310487238531235		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 3.310487238531235 | validation: 2.861106222329752]
	TIME [epoch: 10.5 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.690471741587203		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 4.690471741587203 | validation: 6.406446693521344]
	TIME [epoch: 10.5 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.018406079443489		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 5.018406079443489 | validation: 2.6916075899464937]
	TIME [epoch: 10.5 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2202126955498955		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 3.2202126955498955 | validation: 2.4331087143590633]
	TIME [epoch: 10.5 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1060480457591972		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 3.1060480457591972 | validation: 2.482513425510669]
	TIME [epoch: 10.5 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.073268965321869		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 3.073268965321869 | validation: 2.4335867494397885]
	TIME [epoch: 10.5 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2175941383568984		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 3.2175941383568984 | validation: 2.781298000997239]
	TIME [epoch: 10.5 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2148489609701123		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 3.2148489609701123 | validation: 2.5155206474330636]
	TIME [epoch: 10.5 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.198492759153055		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 3.198492759153055 | validation: 2.656786404420211]
	TIME [epoch: 10.5 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5738082687031265		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 3.5738082687031265 | validation: 3.0458375198981202]
	TIME [epoch: 10.5 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2358909485191143		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 3.2358909485191143 | validation: 2.4463663181956328]
	TIME [epoch: 10.5 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1284612734225408		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 3.1284612734225408 | validation: 2.475999182531588]
	TIME [epoch: 10.5 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.143459860961651		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 3.143459860961651 | validation: 2.7934803722704498]
	TIME [epoch: 10.5 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2072235811006435		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 3.2072235811006435 | validation: 2.4600745695285196]
	TIME [epoch: 10.5 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0845903229763914		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 3.0845903229763914 | validation: 2.4811882363829407]
	TIME [epoch: 10.5 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.012562892382065		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 3.012562892382065 | validation: 2.7693480764299006]
	TIME [epoch: 10.5 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.351135464363715		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 3.351135464363715 | validation: 2.5298550474733568]
	TIME [epoch: 10.5 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.055015299765573		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 3.055015299765573 | validation: 2.5116478322039955]
	TIME [epoch: 10.5 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.100066097187962		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 3.100066097187962 | validation: 2.6847200774130306]
	TIME [epoch: 10.5 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.071352720586038		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 3.071352720586038 | validation: 2.5593996898065074]
	TIME [epoch: 10.5 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.130034955573072		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 3.130034955573072 | validation: 2.3567162270672]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_124.pth
	Model improved!!!
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9285593226428355		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 2.9285593226428355 | validation: 2.347858050449737]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_125.pth
	Model improved!!!
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8908704011177635		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 2.8908704011177635 | validation: 2.6831864322782604]
	TIME [epoch: 10.5 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.190089558370534		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 3.190089558370534 | validation: 3.3049084680770426]
	TIME [epoch: 10.5 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.177949141895996		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 3.177949141895996 | validation: 2.751426425856228]
	TIME [epoch: 10.5 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0270460331368354		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 3.0270460331368354 | validation: 2.3432935922356046]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_129.pth
	Model improved!!!
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.911317070757686		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.911317070757686 | validation: 2.4521132516037802]
	TIME [epoch: 10.5 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9994068311320574		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 2.9994068311320574 | validation: 2.4759831359608957]
	TIME [epoch: 10.5 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9111760606998978		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 2.9111760606998978 | validation: 2.337440106812152]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.07138834849519		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 3.07138834849519 | validation: 4.039651618210699]
	TIME [epoch: 10.5 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.983042462866718		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 4.983042462866718 | validation: 4.423727731036316]
	TIME [epoch: 10.5 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.774669320942608		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 4.774669320942608 | validation: 4.31094969393036]
	TIME [epoch: 10.5 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.780341914278324		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 4.780341914278324 | validation: 4.440623641147935]
	TIME [epoch: 10.5 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.830427837154667		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 4.830427837154667 | validation: 4.46219866584886]
	TIME [epoch: 10.5 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.56721786183749		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 4.56721786183749 | validation: 3.99032506569937]
	TIME [epoch: 10.5 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.121429287843406		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 4.121429287843406 | validation: 2.872523756360414]
	TIME [epoch: 10.5 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6307502353921217		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 3.6307502353921217 | validation: 3.2185896384280883]
	TIME [epoch: 10.5 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4111360502969448		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 3.4111360502969448 | validation: 2.4992246048292093]
	TIME [epoch: 10.5 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3386389722064775		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 3.3386389722064775 | validation: 2.9089574218244265]
	TIME [epoch: 10.5 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.275238344620508		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 3.275238344620508 | validation: 3.044668450314556]
	TIME [epoch: 10.5 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4287214775133092		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 3.4287214775133092 | validation: 2.545748066320194]
	TIME [epoch: 10.5 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0604033499285768		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 3.0604033499285768 | validation: 2.5353342175818887]
	TIME [epoch: 10.5 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.952736774703074		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 3.952736774703074 | validation: 3.1637090146986417]
	TIME [epoch: 10.5 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.294285560335643		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 4.294285560335643 | validation: 5.461854471302659]
	TIME [epoch: 10.5 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.5572183336049905		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 5.5572183336049905 | validation: 4.307934205109773]
	TIME [epoch: 10.5 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7622045941969424		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 3.7622045941969424 | validation: 2.8453821468749987]
	TIME [epoch: 10.5 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.767239269831844		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 3.767239269831844 | validation: 4.301161293473844]
	TIME [epoch: 10.5 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8821377902584375		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 3.8821377902584375 | validation: 2.6436998387697743]
	TIME [epoch: 10.5 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.106602627388463		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 3.106602627388463 | validation: 2.525224117851038]
	TIME [epoch: 10.5 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1396322737585916		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 3.1396322737585916 | validation: 3.108825822115025]
	TIME [epoch: 10.5 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1599256164681293		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 3.1599256164681293 | validation: 2.353628131071817]
	TIME [epoch: 10.5 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2498575543610206		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 3.2498575543610206 | validation: 3.5786235502431]
	TIME [epoch: 10.5 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2795269545125416		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 3.2795269545125416 | validation: 2.4469881885028997]
	TIME [epoch: 10.5 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8880215583970905		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 2.8880215583970905 | validation: 2.244491586442675]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_157.pth
	Model improved!!!
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0035481262116077		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 3.0035481262116077 | validation: 3.169889151891518]
	TIME [epoch: 10.5 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.367637523668691		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 3.367637523668691 | validation: 3.5987152208995616]
	TIME [epoch: 10.5 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7678266371097267		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 3.7678266371097267 | validation: 2.375810862378061]
	TIME [epoch: 10.5 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0146591531178233		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 3.0146591531178233 | validation: 3.1904979509858418]
	TIME [epoch: 10.5 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.09781731240792		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 3.09781731240792 | validation: 2.7648784440360705]
	TIME [epoch: 10.5 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0239621717779164		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 3.0239621717779164 | validation: 2.8013956720133577]
	TIME [epoch: 10.5 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.785356228938487		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 3.785356228938487 | validation: 2.918152779677249]
	TIME [epoch: 10.5 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.173895667874569		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 3.173895667874569 | validation: 2.5649066496035497]
	TIME [epoch: 10.5 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0836111178108903		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 3.0836111178108903 | validation: 2.4325870082459264]
	TIME [epoch: 10.5 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1722045113696495		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 3.1722045113696495 | validation: 3.7506098012823945]
	TIME [epoch: 10.5 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.264461173325548		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 4.264461173325548 | validation: 3.2229861255351784]
	TIME [epoch: 10.5 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.464052068429551		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 3.464052068429551 | validation: 2.609518186882704]
	TIME [epoch: 10.5 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.082490593349905		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 3.082490593349905 | validation: 2.5119195292388703]
	TIME [epoch: 10.5 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9937923334023564		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 2.9937923334023564 | validation: 2.506894540219246]
	TIME [epoch: 10.5 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.965284232303401		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 2.965284232303401 | validation: 2.4428378004086473]
	TIME [epoch: 10.5 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.025613430181836		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 3.025613430181836 | validation: 2.3154225353732474]
	TIME [epoch: 10.5 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9188927558809956		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 2.9188927558809956 | validation: 2.463616808847945]
	TIME [epoch: 10.5 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9223531076640823		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 2.9223531076640823 | validation: 2.3260514820096154]
	TIME [epoch: 10.5 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8854732667938565		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 2.8854732667938565 | validation: 2.3333940845537304]
	TIME [epoch: 10.5 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9118804746432514		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 2.9118804746432514 | validation: 2.276635938485376]
	TIME [epoch: 10.5 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8646682038824958		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 2.8646682038824958 | validation: 2.390323489720343]
	TIME [epoch: 10.5 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9684347002979665		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 2.9684347002979665 | validation: 2.3620753161445966]
	TIME [epoch: 10.5 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.826194086624505		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 2.826194086624505 | validation: 2.515524308155912]
	TIME [epoch: 10.5 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.767266922484394		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 2.767266922484394 | validation: 2.7506135740808184]
	TIME [epoch: 10.5 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8303292657920345		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 2.8303292657920345 | validation: 2.342092856768674]
	TIME [epoch: 10.5 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8922917147575347		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 2.8922917147575347 | validation: 2.3043205981160644]
	TIME [epoch: 10.5 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.854054245289292		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 2.854054245289292 | validation: 2.2280142572130606]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_184.pth
	Model improved!!!
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.846642559170823		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 2.846642559170823 | validation: 2.2499944983576126]
	TIME [epoch: 10.5 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8308475920524545		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 2.8308475920524545 | validation: 2.2905179049562365]
	TIME [epoch: 10.5 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7318493969979416		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 2.7318493969979416 | validation: 2.334991083054386]
	TIME [epoch: 10.5 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.779682047299141		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 2.779682047299141 | validation: 2.2324903507997074]
	TIME [epoch: 10.5 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.673373722776362		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 2.673373722776362 | validation: 2.2875427050797232]
	TIME [epoch: 10.5 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.654046500176936		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 2.654046500176936 | validation: 2.1839088809396667]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_190.pth
	Model improved!!!
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.295651814094474		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 3.295651814094474 | validation: 3.2899177567150613]
	TIME [epoch: 10.5 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.441923958732196		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 3.441923958732196 | validation: 2.406523754354638]
	TIME [epoch: 10.5 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5380303399274533		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 2.5380303399274533 | validation: 1.8430077983334208]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_193.pth
	Model improved!!!
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1888973361047266		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 2.1888973361047266 | validation: 1.8344406941284257]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6558227829411187		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 2.6558227829411187 | validation: 2.813721853274576]
	TIME [epoch: 10.5 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5529614055131464		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 2.5529614055131464 | validation: 2.041551169680257]
	TIME [epoch: 10.5 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4333844297954728		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 2.4333844297954728 | validation: 2.034026926952725]
	TIME [epoch: 10.5 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2955047410488545		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 2.2955047410488545 | validation: 1.9722426803965034]
	TIME [epoch: 10.5 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2029213507919034		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 2.2029213507919034 | validation: 1.869287419078621]
	TIME [epoch: 10.5 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9735653414581897		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 1.9735653414581897 | validation: 1.5876827588829894]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_200.pth
	Model improved!!!
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9827949069970319		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 1.9827949069970319 | validation: 1.9146925726565496]
	TIME [epoch: 10.5 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8788079103718267		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 1.8788079103718267 | validation: 1.8065234840516364]
	TIME [epoch: 10.5 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0417293796819296		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 2.0417293796819296 | validation: 1.9383519237715612]
	TIME [epoch: 10.5 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.790908715333675		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 1.790908715333675 | validation: 1.460009593025618]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_204.pth
	Model improved!!!
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5431478969745893		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 1.5431478969745893 | validation: 1.3015454900953924]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_205.pth
	Model improved!!!
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3929540608025424		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 1.3929540608025424 | validation: 1.504926217882054]
	TIME [epoch: 10.5 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7831728142896044		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 1.7831728142896044 | validation: 1.0606993176386024]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_207.pth
	Model improved!!!
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1094011420215808		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 1.1094011420215808 | validation: 0.9418163910880246]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_208.pth
	Model improved!!!
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2302585414520588		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 1.2302585414520588 | validation: 0.9670338027991193]
	TIME [epoch: 10.5 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9913107463025664		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 0.9913107463025664 | validation: 1.1979394327157449]
	TIME [epoch: 10.5 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9620504041221493		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 0.9620504041221493 | validation: 0.87598394277895]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0232239314757419		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 1.0232239314757419 | validation: 1.024497290931674]
	TIME [epoch: 10.5 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8386175216644782		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 0.8386175216644782 | validation: 0.9626893202354191]
	TIME [epoch: 10.5 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9444027532553211		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 0.9444027532553211 | validation: 1.0199588940682747]
	TIME [epoch: 10.5 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8373432182145276		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 0.8373432182145276 | validation: 1.0356890338057931]
	TIME [epoch: 10.5 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.869663830639331		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 0.869663830639331 | validation: 0.9310515806058521]
	TIME [epoch: 10.5 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8207551678870301		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 0.8207551678870301 | validation: 0.7966879880866375]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_217.pth
	Model improved!!!
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3515185963857193		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 1.3515185963857193 | validation: 0.7175793112028371]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_218.pth
	Model improved!!!
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.99908885969864		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 0.99908885969864 | validation: 0.7496206737612245]
	TIME [epoch: 10.5 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1100556560277757		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 1.1100556560277757 | validation: 1.3207970107093043]
	TIME [epoch: 10.5 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0268939610295422		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 1.0268939610295422 | validation: 0.7021419088825942]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_221.pth
	Model improved!!!
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0394083614530911		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 1.0394083614530911 | validation: 0.9012651396500152]
	TIME [epoch: 10.5 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8087588972735599		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 0.8087588972735599 | validation: 0.7325400867477535]
	TIME [epoch: 10.5 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8076662918678499		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 0.8076662918678499 | validation: 0.7721372944107904]
	TIME [epoch: 10.5 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0853328351082705		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 1.0853328351082705 | validation: 0.7298272607139581]
	TIME [epoch: 10.5 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7255106256440057		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 0.7255106256440057 | validation: 2.182247924195223]
	TIME [epoch: 10.5 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0693793994912608		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 1.0693793994912608 | validation: 0.681777189227297]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_227.pth
	Model improved!!!
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8034580084331633		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 0.8034580084331633 | validation: 0.6607792373022306]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_228.pth
	Model improved!!!
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6966774940546666		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 0.6966774940546666 | validation: 0.7151864477246543]
	TIME [epoch: 10.5 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0064102104854733		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.0064102104854733 | validation: 0.9561586023234182]
	TIME [epoch: 10.5 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8027695466351311		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 0.8027695466351311 | validation: 1.755282521726947]
	TIME [epoch: 10.5 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0436430877058458		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 1.0436430877058458 | validation: 0.9594077570759378]
	TIME [epoch: 10.5 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8056705330672285		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 0.8056705330672285 | validation: 0.955964831561133]
	TIME [epoch: 10.5 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7556705182523243		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 0.7556705182523243 | validation: 1.503617564610567]
	TIME [epoch: 10.5 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0230072567508146		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.0230072567508146 | validation: 0.7419429759769599]
	TIME [epoch: 10.5 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8223783460673978		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 0.8223783460673978 | validation: 0.8900142264600309]
	TIME [epoch: 10.5 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7460579433786926		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 0.7460579433786926 | validation: 0.810807312716811]
	TIME [epoch: 10.5 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7016560622833297		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 0.7016560622833297 | validation: 0.7609011139268193]
	TIME [epoch: 10.5 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7935850263410826		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 0.7935850263410826 | validation: 0.7679740180369943]
	TIME [epoch: 10.5 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7117005731965714		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 0.7117005731965714 | validation: 0.699761455834895]
	TIME [epoch: 10.5 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8472282463195396		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 0.8472282463195396 | validation: 0.7404358798340869]
	TIME [epoch: 10.5 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6834149137872991		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 0.6834149137872991 | validation: 1.0727391282657248]
	TIME [epoch: 10.5 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7653098878420801		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 0.7653098878420801 | validation: 0.6718569330594545]
	TIME [epoch: 10.5 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783533232932616		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.6783533232932616 | validation: 0.7679498584117675]
	TIME [epoch: 10.5 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7871733243921909		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 0.7871733243921909 | validation: 0.8076629520542593]
	TIME [epoch: 10.5 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8068348953857527		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 0.8068348953857527 | validation: 1.100348561554448]
	TIME [epoch: 10.5 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8682827901370971		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 0.8682827901370971 | validation: 0.7941447272857433]
	TIME [epoch: 10.5 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7038524134012982		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 0.7038524134012982 | validation: 0.6350645613002632]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_248.pth
	Model improved!!!
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7285461837953929		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 0.7285461837953929 | validation: 0.6607660470716704]
	TIME [epoch: 10.5 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7457118239375383		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 0.7457118239375383 | validation: 0.7432432951327391]
	TIME [epoch: 10.5 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.752572341833027		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 0.752572341833027 | validation: 0.7190876460660215]
	TIME [epoch: 10.5 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0286956518182282		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.0286956518182282 | validation: 0.8420914532584586]
	TIME [epoch: 10.5 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7322090520756998		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 0.7322090520756998 | validation: 0.6366410293684178]
	TIME [epoch: 10.5 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7502401325663017		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 0.7502401325663017 | validation: 0.8616368916204654]
	TIME [epoch: 10.5 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7620859419112201		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 0.7620859419112201 | validation: 1.0017791822278233]
	TIME [epoch: 10.5 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7497072113869351		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 0.7497072113869351 | validation: 0.7054151148650156]
	TIME [epoch: 10.5 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6747917699024502		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 0.6747917699024502 | validation: 0.6806838064464336]
	TIME [epoch: 10.5 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7536560458571803		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 0.7536560458571803 | validation: 0.7049196671762255]
	TIME [epoch: 10.5 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7962280470438248		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 0.7962280470438248 | validation: 0.7325270263792396]
	TIME [epoch: 10.5 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7182926009681201		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 0.7182926009681201 | validation: 0.6053002156529698]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_260.pth
	Model improved!!!
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6706965706534322		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 0.6706965706534322 | validation: 0.6387940832899334]
	TIME [epoch: 10.5 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8625802283457208		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 0.8625802283457208 | validation: 0.8419474786678522]
	TIME [epoch: 10.5 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.768569512740551		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.768569512740551 | validation: 0.6380907231428203]
	TIME [epoch: 10.5 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7008350399427457		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 0.7008350399427457 | validation: 0.7403693736444866]
	TIME [epoch: 10.5 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7640240980619736		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 0.7640240980619736 | validation: 1.2017395655129293]
	TIME [epoch: 10.5 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.008215448026858		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 1.008215448026858 | validation: 0.6998771822615875]
	TIME [epoch: 10.5 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6728811163652657		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 0.6728811163652657 | validation: 0.7400575895043013]
	TIME [epoch: 10.5 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6500826177654608		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 0.6500826177654608 | validation: 0.7078296195212633]
	TIME [epoch: 10.5 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6538059284009922		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 0.6538059284009922 | validation: 0.689405674854407]
	TIME [epoch: 10.5 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6702615598958144		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 0.6702615598958144 | validation: 0.6718370942429399]
	TIME [epoch: 10.5 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6319291820308104		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 0.6319291820308104 | validation: 0.6290664427284213]
	TIME [epoch: 10.5 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.631107314349217		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 0.631107314349217 | validation: 0.6841373519574812]
	TIME [epoch: 10.5 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7771882935558393		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 0.7771882935558393 | validation: 0.9995553187775201]
	TIME [epoch: 10.5 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7581767523551978		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 0.7581767523551978 | validation: 1.3724562213586506]
	TIME [epoch: 10.5 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0062668332445424		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.0062668332445424 | validation: 0.9630754040147983]
	TIME [epoch: 10.5 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9118682462511949		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 0.9118682462511949 | validation: 0.6305708696105827]
	TIME [epoch: 10.5 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7338999953430958		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 0.7338999953430958 | validation: 0.7101919330084538]
	TIME [epoch: 10.5 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.689200513553		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 0.689200513553 | validation: 0.7552194398226635]
	TIME [epoch: 10.5 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6697941955297161		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 0.6697941955297161 | validation: 0.6844680951020625]
	TIME [epoch: 10.5 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.660013979439408		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 0.660013979439408 | validation: 0.7008936558291659]
	TIME [epoch: 10.5 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7570250801954921		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 0.7570250801954921 | validation: 0.83998558993178]
	TIME [epoch: 10.5 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6814549750506302		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.6814549750506302 | validation: 0.9137842466599888]
	TIME [epoch: 10.5 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7208216444573947		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 0.7208216444573947 | validation: 0.7271539038271356]
	TIME [epoch: 10.5 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997129950409654		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 0.6997129950409654 | validation: 0.6694017139608246]
	TIME [epoch: 10.5 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6717497435567961		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 0.6717497435567961 | validation: 0.6316156579160116]
	TIME [epoch: 10.5 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7053903294201961		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 0.7053903294201961 | validation: 0.7143959023523258]
	TIME [epoch: 10.5 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7108896061346238		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 0.7108896061346238 | validation: 0.6268215993276093]
	TIME [epoch: 10.5 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474002789872058		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 0.6474002789872058 | validation: 0.625570243665729]
	TIME [epoch: 10.5 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6337187295480835		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 0.6337187295480835 | validation: 0.7816982971478382]
	TIME [epoch: 10.5 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6168236388118115		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 0.6168236388118115 | validation: 0.7419561798788018]
	TIME [epoch: 10.5 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8111238845731853		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 0.8111238845731853 | validation: 0.6333613965913333]
	TIME [epoch: 10.5 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310843359186962		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 0.6310843359186962 | validation: 0.7712092963853102]
	TIME [epoch: 10.5 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6061277188367443		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 0.6061277188367443 | validation: 0.6220161317543784]
	TIME [epoch: 10.5 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.701699762336198		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 0.701699762336198 | validation: 0.7814387152268526]
	TIME [epoch: 10.5 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0432640805264357		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 1.0432640805264357 | validation: 0.6179726503257286]
	TIME [epoch: 10.5 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6007504553392908		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 0.6007504553392908 | validation: 0.5611110190955131]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_296.pth
	Model improved!!!
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5746445923467313		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 0.5746445923467313 | validation: 0.7782759696615577]
	TIME [epoch: 10.5 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6213420513438802		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 0.6213420513438802 | validation: 0.660587690655041]
	TIME [epoch: 10.5 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5513143084811066		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 0.5513143084811066 | validation: 0.6485976978619749]
	TIME [epoch: 10.5 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6809602921078927		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 0.6809602921078927 | validation: 0.7678051617359759]
	TIME [epoch: 10.5 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7442375047266053		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.7442375047266053 | validation: 0.6195468083511803]
	TIME [epoch: 10.5 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6753423189415175		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 0.6753423189415175 | validation: 0.6743819724473145]
	TIME [epoch: 10.5 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6164926341175015		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 0.6164926341175015 | validation: 0.696132829689245]
	TIME [epoch: 10.5 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6672323571162719		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 0.6672323571162719 | validation: 0.821280322902267]
	TIME [epoch: 10.5 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6862561597417682		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 0.6862561597417682 | validation: 0.6002200481785517]
	TIME [epoch: 10.5 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5850252255391235		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 0.5850252255391235 | validation: 0.5976905229924252]
	TIME [epoch: 10.5 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988966171983968		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 0.5988966171983968 | validation: 0.8928088537771858]
	TIME [epoch: 10.5 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926031074472315		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 0.6926031074472315 | validation: 0.5699094293294328]
	TIME [epoch: 10.5 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5800827022243541		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 0.5800827022243541 | validation: 0.627633511525373]
	TIME [epoch: 10.5 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6444328567517832		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 0.6444328567517832 | validation: 0.6578128120300563]
	TIME [epoch: 10.5 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999510012961429		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 0.5999510012961429 | validation: 0.6276106639219916]
	TIME [epoch: 10.5 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.597393958292745		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 0.597393958292745 | validation: 0.6883076713620395]
	TIME [epoch: 10.5 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6263963800508855		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 0.6263963800508855 | validation: 0.7046938360101567]
	TIME [epoch: 10.5 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7680840510707861		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 0.7680840510707861 | validation: 0.5805195610762087]
	TIME [epoch: 10.5 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7261899489704573		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 0.7261899489704573 | validation: 0.5738061121477502]
	TIME [epoch: 10.5 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5910694334606511		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 0.5910694334606511 | validation: 0.908612856088377]
	TIME [epoch: 10.5 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6443617300153875		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 0.6443617300153875 | validation: 0.6086903053627374]
	TIME [epoch: 10.5 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6229767793765293		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 0.6229767793765293 | validation: 0.6601259931973198]
	TIME [epoch: 10.5 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373417143887108		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 0.5373417143887108 | validation: 0.5996559426196371]
	TIME [epoch: 10.5 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411336094547115		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.5411336094547115 | validation: 0.5960443308438841]
	TIME [epoch: 10.5 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5819976902466834		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 0.5819976902466834 | validation: 0.6522545537387747]
	TIME [epoch: 10.5 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5875843259046359		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 0.5875843259046359 | validation: 0.5458085629284933]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_322.pth
	Model improved!!!
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6666538993577282		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 0.6666538993577282 | validation: 0.5468973332660424]
	TIME [epoch: 10.5 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6088405251113977		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 0.6088405251113977 | validation: 0.5305057307073088]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_324.pth
	Model improved!!!
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4987791321514571		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 0.4987791321514571 | validation: 0.6233889589990294]
	TIME [epoch: 10.5 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5296416345262893		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 0.5296416345262893 | validation: 0.5844841813631234]
	TIME [epoch: 10.5 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7024345808082255		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 0.7024345808082255 | validation: 0.6704237669754164]
	TIME [epoch: 10.5 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7409795034730443		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 0.7409795034730443 | validation: 0.7271231159169633]
	TIME [epoch: 10.5 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6627711076870971		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 0.6627711076870971 | validation: 0.5582670376647277]
	TIME [epoch: 10.5 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4953961987526389		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 0.4953961987526389 | validation: 0.5235783064726052]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_330.pth
	Model improved!!!
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.745450897018885		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 0.745450897018885 | validation: 0.7856032705069065]
	TIME [epoch: 10.5 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6495751810869488		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 0.6495751810869488 | validation: 0.7272197954584337]
	TIME [epoch: 10.5 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7160002821767268		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 0.7160002821767268 | validation: 0.6735964923684147]
	TIME [epoch: 10.5 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6119796864766436		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 0.6119796864766436 | validation: 0.6966114550633558]
	TIME [epoch: 10.5 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5467909995766889		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 0.5467909995766889 | validation: 0.5305540828112105]
	TIME [epoch: 10.5 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49575860253658577		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 0.49575860253658577 | validation: 0.5208977472883289]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_336.pth
	Model improved!!!
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5421260074360428		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 0.5421260074360428 | validation: 0.5080682875189632]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_337.pth
	Model improved!!!
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6195906692281454		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 0.6195906692281454 | validation: 0.6490873859870072]
	TIME [epoch: 10.5 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6491157321034668		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.6491157321034668 | validation: 0.7239352099914134]
	TIME [epoch: 10.5 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5786284032052267		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 0.5786284032052267 | validation: 0.5216136374236716]
	TIME [epoch: 10.5 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5335378344929342		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 0.5335378344929342 | validation: 0.6966967739886463]
	TIME [epoch: 10.5 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6742582269764735		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 0.6742582269764735 | validation: 0.5521640664556309]
	TIME [epoch: 10.5 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5652189840377605		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 0.5652189840377605 | validation: 0.5500057793110804]
	TIME [epoch: 10.5 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4980938142962243		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 0.4980938142962243 | validation: 0.4978545652841679]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_344.pth
	Model improved!!!
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4653737768535816		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 0.4653737768535816 | validation: 0.5764948511039403]
	TIME [epoch: 10.5 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46901896010744454		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 0.46901896010744454 | validation: 0.5586665371683442]
	TIME [epoch: 10.5 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48733444713026247		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 0.48733444713026247 | validation: 0.610727661725288]
	TIME [epoch: 10.5 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5879121923443102		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 0.5879121923443102 | validation: 0.6731876233881426]
	TIME [epoch: 10.5 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306879330450165		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 0.5306879330450165 | validation: 0.5808103131456493]
	TIME [epoch: 10.5 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49520181808815894		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 0.49520181808815894 | validation: 0.6052849321204141]
	TIME [epoch: 10.5 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5360613591673605		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 0.5360613591673605 | validation: 0.5348078228782098]
	TIME [epoch: 10.5 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44805914870733893		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 0.44805914870733893 | validation: 0.5471309846370724]
	TIME [epoch: 10.5 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6082325774715749		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 0.6082325774715749 | validation: 0.5721044007025307]
	TIME [epoch: 10.5 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.531513153029171		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 0.531513153029171 | validation: 0.6024018004788799]
	TIME [epoch: 10.5 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5172764130035326		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 0.5172764130035326 | validation: 0.444038842994727]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_355.pth
	Model improved!!!
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.564954232567317		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 0.564954232567317 | validation: 0.5049345375105745]
	TIME [epoch: 10.5 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4676761456294877		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 0.4676761456294877 | validation: 0.5045362712703864]
	TIME [epoch: 10.5 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5183953769752135		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.5183953769752135 | validation: 0.432799396358535]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_358.pth
	Model improved!!!
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.580627096337726		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 0.580627096337726 | validation: 0.5684109424827289]
	TIME [epoch: 10.5 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5731035940682526		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.5731035940682526 | validation: 0.424690403017406]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_360.pth
	Model improved!!!
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5216344405111627		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 0.5216344405111627 | validation: 0.5315707365179925]
	TIME [epoch: 10.5 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5090126481519135		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 0.5090126481519135 | validation: 0.43633308628989065]
	TIME [epoch: 10.5 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48002400343089074		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 0.48002400343089074 | validation: 0.676403335443957]
	TIME [epoch: 10.5 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.606067342667689		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 0.606067342667689 | validation: 0.4447684105198209]
	TIME [epoch: 10.5 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361072008151395		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 0.5361072008151395 | validation: 0.5344045139404859]
	TIME [epoch: 10.5 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4545327975676322		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 0.4545327975676322 | validation: 0.46633447242179393]
	TIME [epoch: 10.5 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49050150778587814		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 0.49050150778587814 | validation: 0.4503079169170201]
	TIME [epoch: 10.5 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4617368388939128		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 0.4617368388939128 | validation: 0.5315669267737916]
	TIME [epoch: 10.5 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5018184632689667		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 0.5018184632689667 | validation: 0.5376908041779381]
	TIME [epoch: 10.5 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5539472926628604		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 0.5539472926628604 | validation: 0.42165037428923074]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_370.pth
	Model improved!!!
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47870988176257134		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 0.47870988176257134 | validation: 0.4293556082182092]
	TIME [epoch: 10.5 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5586320421920287		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 0.5586320421920287 | validation: 0.6907294205189143]
	TIME [epoch: 10.5 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5110203766408454		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 0.5110203766408454 | validation: 0.5724960625347768]
	TIME [epoch: 10.5 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5175587249284334		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 0.5175587249284334 | validation: 0.4423587605567886]
	TIME [epoch: 10.5 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4726514005392959		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 0.4726514005392959 | validation: 0.4529928515569148]
	TIME [epoch: 10.5 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46020313437334776		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 0.46020313437334776 | validation: 0.5126392850826718]
	TIME [epoch: 10.5 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4791486756191243		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.4791486756191243 | validation: 0.46579945521237603]
	TIME [epoch: 10.5 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4137654442531703		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 0.4137654442531703 | validation: 0.4481608965934477]
	TIME [epoch: 10.5 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5814830474574311		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 0.5814830474574311 | validation: 0.5411263541678583]
	TIME [epoch: 10.5 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42135246512833585		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 0.42135246512833585 | validation: 0.4612707338435188]
	TIME [epoch: 10.5 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5453407780884806		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 0.5453407780884806 | validation: 0.5721376900558321]
	TIME [epoch: 10.5 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.503002957476698		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 0.503002957476698 | validation: 0.49456119143283206]
	TIME [epoch: 10.5 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44908366553172385		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 0.44908366553172385 | validation: 0.45955986007079364]
	TIME [epoch: 10.5 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.439938488211242		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 0.439938488211242 | validation: 0.45157029868338155]
	TIME [epoch: 10.5 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5042958860332506		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 0.5042958860332506 | validation: 0.5378440858994016]
	TIME [epoch: 10.5 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5041156839301733		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 0.5041156839301733 | validation: 0.41774994144413136]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_386.pth
	Model improved!!!
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49372032037974234		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 0.49372032037974234 | validation: 0.4477810389424904]
	TIME [epoch: 10.5 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5429796208431615		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 0.5429796208431615 | validation: 0.4596489796623293]
	TIME [epoch: 10.5 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4429341062928037		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 0.4429341062928037 | validation: 0.4397035278475916]
	TIME [epoch: 10.5 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40737773638426483		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 0.40737773638426483 | validation: 0.5282953242405535]
	TIME [epoch: 10.5 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48521048261396116		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 0.48521048261396116 | validation: 0.46538145599864833]
	TIME [epoch: 10.5 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4680129435374968		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 0.4680129435374968 | validation: 0.4938399879232614]
	TIME [epoch: 10.5 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4604150874291932		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 0.4604150874291932 | validation: 0.46024103175168635]
	TIME [epoch: 10.5 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4316670584789638		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 0.4316670584789638 | validation: 0.6910670598321879]
	TIME [epoch: 10.5 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4938881110722851		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 0.4938881110722851 | validation: 0.43348743719051414]
	TIME [epoch: 10.5 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42135107945242317		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.42135107945242317 | validation: 0.548248358880519]
	TIME [epoch: 10.5 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5453594048194352		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 0.5453594048194352 | validation: 0.5465700444299494]
	TIME [epoch: 10.5 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7479996209500352		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 0.7479996209500352 | validation: 0.479823723866868]
	TIME [epoch: 10.5 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5109446432570995		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 0.5109446432570995 | validation: 0.4648159783493647]
	TIME [epoch: 10.5 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4322865394691949		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 0.4322865394691949 | validation: 0.5621142627066357]
	TIME [epoch: 10.5 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45769310184001855		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.45769310184001855 | validation: 0.4643825503922885]
	TIME [epoch: 10.5 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3956170648513682		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.3956170648513682 | validation: 0.4097129582257826]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_402.pth
	Model improved!!!
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196272631572354		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.4196272631572354 | validation: 0.40474252109551245]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_403.pth
	Model improved!!!
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272756899042661		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 0.5272756899042661 | validation: 0.4062827352130891]
	TIME [epoch: 10.5 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3957300518481246		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 0.3957300518481246 | validation: 0.48062749004091054]
	TIME [epoch: 10.5 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40288759118412437		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 0.40288759118412437 | validation: 0.4229901801613224]
	TIME [epoch: 10.5 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4749904326485842		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.4749904326485842 | validation: 0.40890158818477307]
	TIME [epoch: 10.5 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4628610499566774		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.4628610499566774 | validation: 0.5466206298948086]
	TIME [epoch: 10.5 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5059989984764943		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.5059989984764943 | validation: 0.41008489269320564]
	TIME [epoch: 10.5 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38753468291775234		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.38753468291775234 | validation: 0.41196731864373504]
	TIME [epoch: 10.5 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4494570219172987		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 0.4494570219172987 | validation: 0.45115154543677366]
	TIME [epoch: 10.5 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4980486156672318		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.4980486156672318 | validation: 0.4831269211603237]
	TIME [epoch: 10.5 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44746287049550837		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 0.44746287049550837 | validation: 0.5042172609383918]
	TIME [epoch: 10.5 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40529889273504505		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 0.40529889273504505 | validation: 0.42374181800181226]
	TIME [epoch: 10.5 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46788294742577696		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.46788294742577696 | validation: 0.5840522354418378]
	TIME [epoch: 10.5 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.434565090018484		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.434565090018484 | validation: 0.5846389418135381]
	TIME [epoch: 10.5 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4987851197975915		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.4987851197975915 | validation: 0.43513682202495524]
	TIME [epoch: 10.5 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4485421513999347		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.4485421513999347 | validation: 0.45419765294550757]
	TIME [epoch: 10.5 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4697643672819547		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 0.4697643672819547 | validation: 0.4641905726645223]
	TIME [epoch: 10.5 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4384908661722432		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 0.4384908661722432 | validation: 0.39867966569928087]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_420.pth
	Model improved!!!
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45332665110397674		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.45332665110397674 | validation: 0.5357303325076217]
	TIME [epoch: 10.5 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48759031229004296		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 0.48759031229004296 | validation: 0.42359005491453483]
	TIME [epoch: 10.5 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3894777259567962		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 0.3894777259567962 | validation: 0.4459916621050233]
	TIME [epoch: 10.5 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45602489557742204		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 0.45602489557742204 | validation: 0.5574752636841975]
	TIME [epoch: 10.5 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4122563207950658		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 0.4122563207950658 | validation: 0.5008469407237922]
	TIME [epoch: 10.5 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280245353651379		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 0.5280245353651379 | validation: 0.4834585930286313]
	TIME [epoch: 10.5 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187990581356393		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 0.5187990581356393 | validation: 0.4893822957497386]
	TIME [epoch: 10.5 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576720700242573		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.4576720700242573 | validation: 0.45356957711404766]
	TIME [epoch: 10.5 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4524848811873536		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 0.4524848811873536 | validation: 0.551151660761617]
	TIME [epoch: 10.5 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234720821787886		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 0.5234720821787886 | validation: 0.49259780114514407]
	TIME [epoch: 10.5 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4405074441111035		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.4405074441111035 | validation: 0.410238816987455]
	TIME [epoch: 10.5 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4492393739766685		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.4492393739766685 | validation: 0.5438752509360899]
	TIME [epoch: 10.5 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45689651902856615		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.45689651902856615 | validation: 0.529885836705422]
	TIME [epoch: 10.5 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41896201571936126		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.41896201571936126 | validation: 0.4450698060539679]
	TIME [epoch: 10.5 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3912317914797406		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.3912317914797406 | validation: 0.494067672481158]
	TIME [epoch: 10.5 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41379538886371225		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 0.41379538886371225 | validation: 0.4936495188241861]
	TIME [epoch: 10.5 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5002144648638763		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 0.5002144648638763 | validation: 0.5373096210372874]
	TIME [epoch: 10.5 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5053801851382004		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 0.5053801851382004 | validation: 0.6164552747742861]
	TIME [epoch: 10.5 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4728800134333941		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 0.4728800134333941 | validation: 0.5151713582888834]
	TIME [epoch: 10.5 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4233374924230372		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 0.4233374924230372 | validation: 0.5237876410365905]
	TIME [epoch: 10.5 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4611783440313739		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 0.4611783440313739 | validation: 0.5800834785860779]
	TIME [epoch: 10.5 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4432080186950082		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.4432080186950082 | validation: 0.44322237781701407]
	TIME [epoch: 10.5 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246361418694923		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 0.4246361418694923 | validation: 0.4725768753250838]
	TIME [epoch: 10.5 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38973297227198744		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.38973297227198744 | validation: 0.4502973940221452]
	TIME [epoch: 10.5 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4216051832045159		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.4216051832045159 | validation: 0.47869296283098395]
	TIME [epoch: 10.5 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44165331684467046		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.44165331684467046 | validation: 0.42796181578400905]
	TIME [epoch: 10.5 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42334208689234315		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 0.42334208689234315 | validation: 0.4785569085162986]
	TIME [epoch: 10.5 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3728028625529332		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 0.3728028625529332 | validation: 0.4003472285903175]
	TIME [epoch: 10.5 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4361143277106308		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 0.4361143277106308 | validation: 0.44980368101077595]
	TIME [epoch: 10.5 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42998765482625273		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.42998765482625273 | validation: 0.43982862071370593]
	TIME [epoch: 10.5 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39836503594040706		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 0.39836503594040706 | validation: 0.4290628483973318]
	TIME [epoch: 10.5 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3940572537718869		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.3940572537718869 | validation: 0.4829643540235807]
	TIME [epoch: 10.5 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4357755704964889		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.4357755704964889 | validation: 0.4425185467758031]
	TIME [epoch: 10.5 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4385318644315275		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 0.4385318644315275 | validation: 0.39907161384292666]
	TIME [epoch: 10.5 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38622705205457347		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 0.38622705205457347 | validation: 0.46563909941714654]
	TIME [epoch: 10.5 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147877799203853		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.4147877799203853 | validation: 0.45628558961616256]
	TIME [epoch: 10.5 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4039368175919515		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 0.4039368175919515 | validation: 0.37427439613286495]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_457.pth
	Model improved!!!
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38172327971088854		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 0.38172327971088854 | validation: 0.45061785584847724]
	TIME [epoch: 10.5 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3838797193846194		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 0.3838797193846194 | validation: 0.4520332668929323]
	TIME [epoch: 10.5 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.397937763975242		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 0.397937763975242 | validation: 0.42610368897781153]
	TIME [epoch: 10.5 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142505474556127		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 0.4142505474556127 | validation: 0.4035433357556035]
	TIME [epoch: 10.5 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41490953015284393		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 0.41490953015284393 | validation: 0.47418217373663135]
	TIME [epoch: 10.5 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3992314374734004		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.3992314374734004 | validation: 0.5146992388830618]
	TIME [epoch: 10.5 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4757247788801246		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 0.4757247788801246 | validation: 0.4510118862232463]
	TIME [epoch: 10.5 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3828689835651041		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 0.3828689835651041 | validation: 0.41527149084944226]
	TIME [epoch: 10.5 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5066860280257889		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 0.5066860280257889 | validation: 0.450161873661257]
	TIME [epoch: 10.5 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4645005260084307		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 0.4645005260084307 | validation: 0.4081514288426416]
	TIME [epoch: 10.5 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40144860705662255		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.40144860705662255 | validation: 0.5051880649347008]
	TIME [epoch: 10.5 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4579270890046834		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 0.4579270890046834 | validation: 0.5045854454450504]
	TIME [epoch: 10.5 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5102301191461774		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 0.5102301191461774 | validation: 0.6935616089383417]
	TIME [epoch: 10.5 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5119135575833796		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.5119135575833796 | validation: 0.4142361052892632]
	TIME [epoch: 10.5 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40507550924217417		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.40507550924217417 | validation: 0.4514268788811592]
	TIME [epoch: 10.5 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.407627030599185		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.407627030599185 | validation: 0.4268820587629991]
	TIME [epoch: 10.5 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.401093551708697		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 0.401093551708697 | validation: 0.40603212053939736]
	TIME [epoch: 10.5 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4012129816794463		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 0.4012129816794463 | validation: 0.48158953824915457]
	TIME [epoch: 10.5 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4011001153489321		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 0.4011001153489321 | validation: 0.42892432813621784]
	TIME [epoch: 10.5 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4413536137833261		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 0.4413536137833261 | validation: 0.3802965395342609]
	TIME [epoch: 10.5 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4223958067931866		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 0.4223958067931866 | validation: 0.5179821512603578]
	TIME [epoch: 10.5 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4068960513578387		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.4068960513578387 | validation: 0.5380087785939545]
	TIME [epoch: 10.5 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47745880217900155		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 0.47745880217900155 | validation: 0.6424413804396325]
	TIME [epoch: 10.5 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5042607989080841		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 0.5042607989080841 | validation: 0.5098872576681538]
	TIME [epoch: 10.5 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40954842533606994		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 0.40954842533606994 | validation: 0.4337524231487874]
	TIME [epoch: 10.5 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3738233149496499		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 0.3738233149496499 | validation: 0.3858283821660684]
	TIME [epoch: 10.5 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48944740788210755		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 0.48944740788210755 | validation: 0.3950403653860082]
	TIME [epoch: 10.5 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41986275121532907		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 0.41986275121532907 | validation: 0.3886194041639307]
	TIME [epoch: 10.5 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.364777338340776		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 0.364777338340776 | validation: 0.3940354633458951]
	TIME [epoch: 10.5 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3563801275300623		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 0.3563801275300623 | validation: 0.4200246031987579]
	TIME [epoch: 10.5 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4405117479969901		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 0.4405117479969901 | validation: 0.439953238019195]
	TIME [epoch: 10.5 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37854922890108395		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 0.37854922890108395 | validation: 0.39039419341418496]
	TIME [epoch: 10.5 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4586890634576079		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 0.4586890634576079 | validation: 0.6097934506337562]
	TIME [epoch: 10.5 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47650394399344054		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.47650394399344054 | validation: 0.4016444514901514]
	TIME [epoch: 10.5 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39541603883262155		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.39541603883262155 | validation: 0.47962319866924996]
	TIME [epoch: 10.5 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45362423629515425		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.45362423629515425 | validation: 0.5354096361841867]
	TIME [epoch: 10.5 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41372648649959204		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 0.41372648649959204 | validation: 0.47148045423450724]
	TIME [epoch: 10.5 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39337863262832357		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 0.39337863262832357 | validation: 0.3986360668471415]
	TIME [epoch: 10.5 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177101020771913		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 0.4177101020771913 | validation: 0.40666320523990357]
	TIME [epoch: 10.5 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42912054195776667		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 0.42912054195776667 | validation: 0.4086324749286025]
	TIME [epoch: 10.5 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33463687906502143		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 0.33463687906502143 | validation: 0.47307090331897544]
	TIME [epoch: 10.5 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3982528872131271		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.3982528872131271 | validation: 0.4504105628581594]
	TIME [epoch: 10.5 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37331471747237077		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 0.37331471747237077 | validation: 0.4328474371100517]
	TIME [epoch: 10.5 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38413628796293864		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 0.38413628796293864 | validation: 0.40518768772886143]
	TIME [epoch: 10.5 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37235079790227843		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.37235079790227843 | validation: 0.4136051749053196]
	TIME [epoch: 10.5 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.361645192291146		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.361645192291146 | validation: 0.4079049138032868]
	TIME [epoch: 10.5 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3548753856341621		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 0.3548753856341621 | validation: 0.43687617366070514]
	TIME [epoch: 10.5 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4149034465865532		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.4149034465865532 | validation: 0.43153188163072215]
	TIME [epoch: 10.5 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38751234971296195		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 0.38751234971296195 | validation: 0.46372757414724475]
	TIME [epoch: 10.5 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339885904565954		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.6339885904565954 | validation: 0.48353183272551487]
	TIME [epoch: 10.5 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3833762217224005		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 0.3833762217224005 | validation: 0.3977711616843593]
	TIME [epoch: 10.5 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3827642692517216		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 0.3827642692517216 | validation: 0.42049300392644595]
	TIME [epoch: 10.5 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3879345664042947		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.3879345664042947 | validation: 0.37633058920879003]
	TIME [epoch: 10.5 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3823555636284331		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 0.3823555636284331 | validation: 0.3715866424912592]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_511.pth
	Model improved!!!
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36031704972291645		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 0.36031704972291645 | validation: 0.41545138552231736]
	TIME [epoch: 10.5 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4142360032072788		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.4142360032072788 | validation: 0.5981699866946545]
	TIME [epoch: 10.5 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.458713147899348		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 0.458713147899348 | validation: 0.414712981762797]
	TIME [epoch: 10.5 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44546540275227847		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.44546540275227847 | validation: 0.43802054847821126]
	TIME [epoch: 10.5 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4161148508233487		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 0.4161148508233487 | validation: 0.3863885243880721]
	TIME [epoch: 10.5 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36254724657107995		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 0.36254724657107995 | validation: 0.3992431451871311]
	TIME [epoch: 10.5 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3893446851622729		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 0.3893446851622729 | validation: 0.36980586610953353]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_518.pth
	Model improved!!!
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.387597322638764		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.387597322638764 | validation: 0.4599831251187153]
	TIME [epoch: 10.5 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42176696952769294		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 0.42176696952769294 | validation: 0.37927039423740283]
	TIME [epoch: 10.5 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.401967423382146		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 0.401967423382146 | validation: 0.5440122484460171]
	TIME [epoch: 10.5 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177271989667063		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.4177271989667063 | validation: 0.3874106320428631]
	TIME [epoch: 10.5 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3546472794807459		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.3546472794807459 | validation: 0.40262729477895565]
	TIME [epoch: 10.5 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47777648932331546		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.47777648932331546 | validation: 0.4288927380384511]
	TIME [epoch: 10.5 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4076150610675273		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.4076150610675273 | validation: 0.4216461999217189]
	TIME [epoch: 10.5 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35799596193929384		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 0.35799596193929384 | validation: 0.4150781728824465]
	TIME [epoch: 10.5 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36776909538393815		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.36776909538393815 | validation: 0.37284487456703147]
	TIME [epoch: 10.5 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3315860712198959		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.3315860712198959 | validation: 0.4754631024091738]
	TIME [epoch: 10.5 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876740249186196		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.3876740249186196 | validation: 0.5059433993533711]
	TIME [epoch: 10.5 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.40119380954167116		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 0.40119380954167116 | validation: 0.3730919117448319]
	TIME [epoch: 10.5 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3623007203481469		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 0.3623007203481469 | validation: 0.41102533999637986]
	TIME [epoch: 10.5 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36057535340111035		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.36057535340111035 | validation: 0.3655388468035876]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_532.pth
	Model improved!!!
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35604224768044695		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.35604224768044695 | validation: 0.42589492977103194]
	TIME [epoch: 10.5 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35501877334724863		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.35501877334724863 | validation: 0.41952609986913786]
	TIME [epoch: 10.5 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3612023818489772		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.3612023818489772 | validation: 0.4390908716405521]
	TIME [epoch: 10.5 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4054272348046789		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.4054272348046789 | validation: 0.441041718027092]
	TIME [epoch: 10.5 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39374241989212566		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.39374241989212566 | validation: 0.46000483124486385]
	TIME [epoch: 10.5 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36070897382303735		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 0.36070897382303735 | validation: 0.3958699999073205]
	TIME [epoch: 10.5 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3775334849334774		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.3775334849334774 | validation: 0.4793550259035709]
	TIME [epoch: 10.5 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3768978434763784		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.3768978434763784 | validation: 0.43918286298941783]
	TIME [epoch: 10.5 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.353953376108789		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.353953376108789 | validation: 0.4396636288376034]
	TIME [epoch: 10.5 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3466217740507839		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.3466217740507839 | validation: 0.4395563274486689]
	TIME [epoch: 10.5 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3943547170917904		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.3943547170917904 | validation: 0.39222318592026595]
	TIME [epoch: 10.5 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37017913782878337		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.37017913782878337 | validation: 0.3566724211452738]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_544.pth
	Model improved!!!
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35204549581135225		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.35204549581135225 | validation: 0.36713256864557203]
	TIME [epoch: 10.5 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3772033112722228		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 0.3772033112722228 | validation: 0.4465826227606715]
	TIME [epoch: 10.5 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.341882480504678		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.341882480504678 | validation: 0.3678034930397573]
	TIME [epoch: 10.5 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34963223117477077		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.34963223117477077 | validation: 0.4585536202436001]
	TIME [epoch: 10.5 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39759005263808633		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.39759005263808633 | validation: 0.40041195758107434]
	TIME [epoch: 10.5 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35111484050102637		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.35111484050102637 | validation: 0.4211327756638904]
	TIME [epoch: 10.5 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4044887643784813		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.4044887643784813 | validation: 0.41750739134607145]
	TIME [epoch: 10.5 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38324535569755513		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.38324535569755513 | validation: 0.40609131423105665]
	TIME [epoch: 10.5 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420839005569089		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.3420839005569089 | validation: 0.4249487919332614]
	TIME [epoch: 10.5 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37971349711312663		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 0.37971349711312663 | validation: 0.43922176548441555]
	TIME [epoch: 10.5 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38547312173039805		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 0.38547312173039805 | validation: 0.4133839965316971]
	TIME [epoch: 10.5 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3438702386911646		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.3438702386911646 | validation: 0.4188769508464445]
	TIME [epoch: 10.5 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3656844200917386		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.3656844200917386 | validation: 0.5922222834858625]
	TIME [epoch: 10.5 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.42905799888227725		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.42905799888227725 | validation: 0.38180948303037476]
	TIME [epoch: 10.5 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.345201957051253		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.345201957051253 | validation: 0.38630873036221014]
	TIME [epoch: 10.5 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33049504606974844		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.33049504606974844 | validation: 0.36113279211627264]
	TIME [epoch: 10.5 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3410345047485635		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.3410345047485635 | validation: 0.45398768299773035]
	TIME [epoch: 10.5 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36733602103796725		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 0.36733602103796725 | validation: 0.41338165758141104]
	TIME [epoch: 10.5 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33916596441016833		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.33916596441016833 | validation: 0.3785205761453301]
	TIME [epoch: 10.5 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35949730365403354		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 0.35949730365403354 | validation: 0.38069758138279675]
	TIME [epoch: 10.5 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33734799456302234		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.33734799456302234 | validation: 0.4616633185141156]
	TIME [epoch: 10.5 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.41094052883794097		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.41094052883794097 | validation: 0.4036273185934458]
	TIME [epoch: 10.5 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34547971446444803		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.34547971446444803 | validation: 0.4275424779921167]
	TIME [epoch: 10.5 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3359634372086825		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.3359634372086825 | validation: 0.41491619872253976]
	TIME [epoch: 10.5 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.329898653429298		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.329898653429298 | validation: 0.4114103761185983]
	TIME [epoch: 10.5 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.38292637280003516		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.38292637280003516 | validation: 0.3906490499324906]
	TIME [epoch: 10.5 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3766662316021046		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.3766662316021046 | validation: 0.4872763640485499]
	TIME [epoch: 10.5 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.39406654309808603		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.39406654309808603 | validation: 0.40920276481198686]
	TIME [epoch: 10.5 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3639182674727207		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.3639182674727207 | validation: 0.3475254507379117]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_573.pth
	Model improved!!!
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34739106420378746		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.34739106420378746 | validation: 0.4247827151361122]
	TIME [epoch: 10.5 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360656217703542		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.3360656217703542 | validation: 0.39533230303529676]
	TIME [epoch: 10.5 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3668340629109331		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.3668340629109331 | validation: 0.4011426551877941]
	TIME [epoch: 10.5 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37780398665323023		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.37780398665323023 | validation: 0.42388342257245876]
	TIME [epoch: 10.5 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47783112910938685		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 0.47783112910938685 | validation: 0.42374919301088837]
	TIME [epoch: 10.5 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37047094639707806		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.37047094639707806 | validation: 0.39144518526396865]
	TIME [epoch: 10.5 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35106515902441193		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.35106515902441193 | validation: 0.3299989437678353]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_580.pth
	Model improved!!!
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34316342811831324		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.34316342811831324 | validation: 0.42416444516938706]
	TIME [epoch: 10.5 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.340768119678977		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.340768119678977 | validation: 0.3497648006758463]
	TIME [epoch: 10.5 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3135706470882829		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.3135706470882829 | validation: 0.38605724330193647]
	TIME [epoch: 10.5 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34379756721837773		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.34379756721837773 | validation: 0.38697034130209174]
	TIME [epoch: 10.5 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.35055664642429324		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.35055664642429324 | validation: 0.38247143175178516]
	TIME [epoch: 10.5 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3683857992870715		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.3683857992870715 | validation: 0.344456204318146]
	TIME [epoch: 10.5 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32634657848261023		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.32634657848261023 | validation: 0.3732239004889879]
	TIME [epoch: 10.5 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3794186959850063		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.3794186959850063 | validation: 0.3701154203126003]
	TIME [epoch: 10.5 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33820169436750847		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.33820169436750847 | validation: 0.36910930017217297]
	TIME [epoch: 10.5 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.314432397960808		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.314432397960808 | validation: 0.34245954415563484]
	TIME [epoch: 10.5 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3652895536554337		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.3652895536554337 | validation: 0.3812950912273854]
	TIME [epoch: 10.5 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3379141341261386		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.3379141341261386 | validation: 0.38800390864854506]
	TIME [epoch: 10.5 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.322441941691299		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.322441941691299 | validation: 0.4509143380943705]
	TIME [epoch: 10.5 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3975803523152422		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.3975803523152422 | validation: 0.3568945005532828]
	TIME [epoch: 10.5 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34625593565749346		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.34625593565749346 | validation: 0.4639791196273088]
	TIME [epoch: 10.5 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3439021713078908		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.3439021713078908 | validation: 0.37798615606181374]
	TIME [epoch: 10.5 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31679120846575787		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.31679120846575787 | validation: 0.3556176773171714]
	TIME [epoch: 10.5 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.316171514792127		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.316171514792127 | validation: 0.37299559624930567]
	TIME [epoch: 10.5 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3183210489817198		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.3183210489817198 | validation: 0.37544839617121734]
	TIME [epoch: 10.5 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3173241291977843		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.3173241291977843 | validation: 0.35419295776229237]
	TIME [epoch: 10.5 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3250164981667642		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.3250164981667642 | validation: 0.4123704497561078]
	TIME [epoch: 10.5 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.319764617279887		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.319764617279887 | validation: 0.34980473358780656]
	TIME [epoch: 10.5 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32477096652330284		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.32477096652330284 | validation: 0.41756378248679255]
	TIME [epoch: 10.5 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3455950763259083		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.3455950763259083 | validation: 0.3787641684446075]
	TIME [epoch: 10.5 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31266890784498463		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.31266890784498463 | validation: 0.36583886958274087]
	TIME [epoch: 10.5 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33820705954063895		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.33820705954063895 | validation: 0.35563446768629753]
	TIME [epoch: 10.5 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33757441278794154		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.33757441278794154 | validation: 0.3841950846053325]
	TIME [epoch: 10.5 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3298729525640575		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.3298729525640575 | validation: 0.3392497133133115]
	TIME [epoch: 10.5 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3188617635698904		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.3188617635698904 | validation: 0.352857903334621]
	TIME [epoch: 10.5 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073316291795497		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.3073316291795497 | validation: 0.3209865662896757]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_610.pth
	Model improved!!!
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3092838685654134		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.3092838685654134 | validation: 0.3272794819999368]
	TIME [epoch: 10.5 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31386781659281915		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.31386781659281915 | validation: 0.341814253016631]
	TIME [epoch: 10.5 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34858036111801183		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.34858036111801183 | validation: 0.35536644807658235]
	TIME [epoch: 10.5 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33955641834526673		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.33955641834526673 | validation: 0.3434387606927517]
	TIME [epoch: 10.5 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3283715257379606		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.3283715257379606 | validation: 0.3237457034378733]
	TIME [epoch: 10.5 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974170888094076		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.2974170888094076 | validation: 0.3525134640021228]
	TIME [epoch: 10.5 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.37919499874158447		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.37919499874158447 | validation: 0.36297897929941647]
	TIME [epoch: 10.5 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34335533873470137		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.34335533873470137 | validation: 0.3683364129485069]
	TIME [epoch: 10.5 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30286554537240695		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.30286554537240695 | validation: 0.3723487595617357]
	TIME [epoch: 10.5 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32930922000789553		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.32930922000789553 | validation: 0.3166197467916917]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_620.pth
	Model improved!!!
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30033736340742956		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.30033736340742956 | validation: 0.3584701902897803]
	TIME [epoch: 10.5 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052228225580535		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.3052228225580535 | validation: 0.35389280867889084]
	TIME [epoch: 10.5 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975237465934285		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.2975237465934285 | validation: 0.35475466980254977]
	TIME [epoch: 10.5 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34880125389712796		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.34880125389712796 | validation: 0.44726699362947214]
	TIME [epoch: 10.5 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32335972552814063		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.32335972552814063 | validation: 0.3234328218486736]
	TIME [epoch: 10.5 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29547940494433494		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.29547940494433494 | validation: 0.3528416155861164]
	TIME [epoch: 10.5 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33468679302192095		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.33468679302192095 | validation: 0.34889664324377706]
	TIME [epoch: 10.5 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142693593211182		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.3142693593211182 | validation: 0.31674233671790225]
	TIME [epoch: 10.5 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2939315870402409		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.2939315870402409 | validation: 0.34419707105430947]
	TIME [epoch: 10.5 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031843903348333		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.3031843903348333 | validation: 0.3429649916444998]
	TIME [epoch: 10.5 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30634614337279087		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.30634614337279087 | validation: 0.33274864884185995]
	TIME [epoch: 10.5 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30003794923588617		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.30003794923588617 | validation: 0.3569031487993836]
	TIME [epoch: 10.5 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30599946587836574		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.30599946587836574 | validation: 0.3726305222673004]
	TIME [epoch: 10.5 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33551327664157476		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.33551327664157476 | validation: 0.3646999404880583]
	TIME [epoch: 10.5 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32606469115362713		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.32606469115362713 | validation: 0.3151471166441962]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_635.pth
	Model improved!!!
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063521116450584		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.3063521116450584 | validation: 0.3230799351217492]
	TIME [epoch: 10.5 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29931131666167177		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.29931131666167177 | validation: 0.3412629089769461]
	TIME [epoch: 10.5 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31341476416738856		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.31341476416738856 | validation: 0.3447942999909459]
	TIME [epoch: 10.5 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30713324679926324		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.30713324679926324 | validation: 0.3443120968225181]
	TIME [epoch: 10.5 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32360925978144567		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.32360925978144567 | validation: 0.3910763243244802]
	TIME [epoch: 10.5 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3254018781987774		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.3254018781987774 | validation: 0.3612224388519176]
	TIME [epoch: 10.5 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102685023091428		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.3102685023091428 | validation: 0.34052836762698024]
	TIME [epoch: 10.5 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30725107475642155		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.30725107475642155 | validation: 0.3446966523737827]
	TIME [epoch: 10.5 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027345530169865		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.3027345530169865 | validation: 0.3464588238556794]
	TIME [epoch: 10.5 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3563813597032303		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.3563813597032303 | validation: 0.39665554289724086]
	TIME [epoch: 10.5 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3280244275958838		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.3280244275958838 | validation: 0.339547185262524]
	TIME [epoch: 10.5 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920376213068733		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.2920376213068733 | validation: 0.3334339679768904]
	TIME [epoch: 10.5 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31271278451099216		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.31271278451099216 | validation: 0.33623837276747054]
	TIME [epoch: 10.5 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156799148143003		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.3156799148143003 | validation: 0.37605959551693696]
	TIME [epoch: 10.5 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3646434632914042		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.3646434632914042 | validation: 0.32881709898752626]
	TIME [epoch: 10.5 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30135409674810687		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.30135409674810687 | validation: 0.3253690791115582]
	TIME [epoch: 10.5 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2886761320131318		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.2886761320131318 | validation: 0.31066062359255175]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_652.pth
	Model improved!!!
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28877586384733755		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.28877586384733755 | validation: 0.32566844790974364]
	TIME [epoch: 10.5 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31172389297401304		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.31172389297401304 | validation: 0.36251558470637946]
	TIME [epoch: 10.5 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.353901653091225		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.353901653091225 | validation: 0.34507089904395233]
	TIME [epoch: 10.5 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3219080940082455		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.3219080940082455 | validation: 0.34727771769543625]
	TIME [epoch: 10.5 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3271979860504809		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.3271979860504809 | validation: 0.3456529131012404]
	TIME [epoch: 10.5 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3124846524858501		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.3124846524858501 | validation: 0.34077466337303364]
	TIME [epoch: 10.5 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29885180997879945		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.29885180997879945 | validation: 0.31944549128278377]
	TIME [epoch: 10.5 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3118189292604416		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.3118189292604416 | validation: 0.32329533739708255]
	TIME [epoch: 10.5 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31732981182405906		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.31732981182405906 | validation: 0.36148702000107574]
	TIME [epoch: 10.5 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.315046967863226		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.315046967863226 | validation: 0.36135168387103606]
	TIME [epoch: 10.5 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29366798093228635		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.29366798093228635 | validation: 0.3212609400719075]
	TIME [epoch: 10.5 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29049317308618255		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.29049317308618255 | validation: 0.3390677820532347]
	TIME [epoch: 10.5 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32571313458408224		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.32571313458408224 | validation: 0.37563623183716177]
	TIME [epoch: 10.5 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31402757579613433		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.31402757579613433 | validation: 0.3584674134424791]
	TIME [epoch: 10.5 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30032954587676014		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.30032954587676014 | validation: 0.3033709069121869]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_667.pth
	Model improved!!!
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29835813471610423		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.29835813471610423 | validation: 0.32708207921131716]
	TIME [epoch: 10.5 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3090262390377257		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.3090262390377257 | validation: 0.38167751244126213]
	TIME [epoch: 10.5 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30445305441950143		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.30445305441950143 | validation: 0.31385913985584357]
	TIME [epoch: 10.5 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29948899422997444		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.29948899422997444 | validation: 0.3226639873340901]
	TIME [epoch: 10.5 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28617056947567115		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.28617056947567115 | validation: 0.3147330975482725]
	TIME [epoch: 10.5 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2874026001274209		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.2874026001274209 | validation: 0.3198392852016729]
	TIME [epoch: 10.5 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967032542045128		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.2967032542045128 | validation: 0.33169817641285876]
	TIME [epoch: 10.5 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2866297456947813		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.2866297456947813 | validation: 0.32081110651791617]
	TIME [epoch: 10.5 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29473641630526687		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.29473641630526687 | validation: 0.32772622000498547]
	TIME [epoch: 10.5 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3576446151613223		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.3576446151613223 | validation: 0.4477803590965455]
	TIME [epoch: 10.5 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34796981091473034		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.34796981091473034 | validation: 0.38730535969099544]
	TIME [epoch: 10.5 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30014016013030853		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.30014016013030853 | validation: 0.355718421576388]
	TIME [epoch: 10.5 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2868570929885229		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.2868570929885229 | validation: 0.33253941326264136]
	TIME [epoch: 10.5 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2818276138552875		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.2818276138552875 | validation: 0.32671521648591667]
	TIME [epoch: 10.5 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29839147920235		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.29839147920235 | validation: 0.3279423558609004]
	TIME [epoch: 10.5 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27868699495256744		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.27868699495256744 | validation: 0.3134545481495274]
	TIME [epoch: 10.5 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022308331162409		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.3022308331162409 | validation: 0.3166870856068286]
	TIME [epoch: 10.5 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3104654818492096		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.3104654818492096 | validation: 0.31165358145758587]
	TIME [epoch: 10.5 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2955447915967715		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.2955447915967715 | validation: 0.34516067736066547]
	TIME [epoch: 10.5 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31852377941925264		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.31852377941925264 | validation: 0.39097531411330383]
	TIME [epoch: 10.5 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.34983868932702394		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.34983868932702394 | validation: 0.3161258110217291]
	TIME [epoch: 10.5 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.33214654479226835		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.33214654479226835 | validation: 0.3845660606502909]
	TIME [epoch: 10.5 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.31655069114669987		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.31655069114669987 | validation: 0.31551349927468453]
	TIME [epoch: 10.5 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3231427649699402		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.3231427649699402 | validation: 0.3417462476564009]
	TIME [epoch: 10.5 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2794369879878636		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.2794369879878636 | validation: 0.3043965341710991]
	TIME [epoch: 10.5 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3007401567334735		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.3007401567334735 | validation: 0.35806254010527144]
	TIME [epoch: 10.5 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2796536071147122		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.2796536071147122 | validation: 0.29375509001523387]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_694.pth
	Model improved!!!
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28387805962826196		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.28387805962826196 | validation: 0.3245130073836724]
	TIME [epoch: 10.5 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2823092176903771		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.2823092176903771 | validation: 0.29594341020849924]
	TIME [epoch: 10.5 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28930719675633326		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.28930719675633326 | validation: 0.3252154431870313]
	TIME [epoch: 10.5 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2831768650917893		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.2831768650917893 | validation: 0.307671550986513]
	TIME [epoch: 10.5 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2924674816477539		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.2924674816477539 | validation: 0.3236077510409674]
	TIME [epoch: 10.5 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013079105417126		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.3013079105417126 | validation: 0.3068238822271943]
	TIME [epoch: 10.5 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2943824440314099		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.2943824440314099 | validation: 0.3257639919564483]
	TIME [epoch: 10.5 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2908435636986402		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.2908435636986402 | validation: 0.3014326402889825]
	TIME [epoch: 10.5 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.284404758492624		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.284404758492624 | validation: 0.3302816833776697]
	TIME [epoch: 10.5 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.289691557414911		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.289691557414911 | validation: 0.3246504923266145]
	TIME [epoch: 10.5 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28861657128904994		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.28861657128904994 | validation: 0.37124086735681416]
	TIME [epoch: 10.5 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2914581975250404		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.2914581975250404 | validation: 0.3305371103103722]
	TIME [epoch: 10.5 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134592761289926		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.3134592761289926 | validation: 0.32775425830480537]
	TIME [epoch: 10.5 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29803900313424003		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.29803900313424003 | validation: 0.3026037717743065]
	TIME [epoch: 10.5 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2715933633018107		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.2715933633018107 | validation: 0.3454710255190983]
	TIME [epoch: 10.5 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28935793098504464		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.28935793098504464 | validation: 0.3164616110637992]
	TIME [epoch: 10.5 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836351429118038		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.2836351429118038 | validation: 0.34898643858233624]
	TIME [epoch: 10.5 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30098875663589286		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.30098875663589286 | validation: 0.30430732132363636]
	TIME [epoch: 10.5 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28283272538595583		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.28283272538595583 | validation: 0.31174591889713954]
	TIME [epoch: 10.5 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.279465337729652		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.279465337729652 | validation: 0.33887532392374214]
	TIME [epoch: 10.5 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30212324500928006		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.30212324500928006 | validation: 0.3580324031968036]
	TIME [epoch: 10.5 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29320245927442656		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.29320245927442656 | validation: 0.3758770658438824]
	TIME [epoch: 10.5 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.305900847435582		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.305900847435582 | validation: 0.3847070025472435]
	TIME [epoch: 10.5 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30176342941179496		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.30176342941179496 | validation: 0.35720883980900914]
	TIME [epoch: 10.5 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2926476093668845		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.2926476093668845 | validation: 0.40590907272029575]
	TIME [epoch: 10.5 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.36920145713250757		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.36920145713250757 | validation: 0.31618659439514507]
	TIME [epoch: 10.5 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28459993260776384		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.28459993260776384 | validation: 0.32210594738486337]
	TIME [epoch: 10.5 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2852664995671882		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.2852664995671882 | validation: 0.35829707634421826]
	TIME [epoch: 10.5 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.281960706380385		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.281960706380385 | validation: 0.3384272624788237]
	TIME [epoch: 10.5 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28331868192227716		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.28331868192227716 | validation: 0.3136857486983984]
	TIME [epoch: 10.5 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2855684068500971		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.2855684068500971 | validation: 0.406360112870873]
	TIME [epoch: 10.5 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3232563413609687		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.3232563413609687 | validation: 0.3203967236615338]
	TIME [epoch: 10.5 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2830139034638015		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.2830139034638015 | validation: 0.35549440034730223]
	TIME [epoch: 10.5 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770466119497953		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.2770466119497953 | validation: 0.3256686844430108]
	TIME [epoch: 10.5 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3321858787708109		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.3321858787708109 | validation: 0.3312844155060061]
	TIME [epoch: 10.5 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30235989547790376		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.30235989547790376 | validation: 0.33346728356009836]
	TIME [epoch: 10.5 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168103843793257		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.3168103843793257 | validation: 0.3872972308529585]
	TIME [epoch: 10.5 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4221566766774679		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.4221566766774679 | validation: 0.3551179453720873]
	TIME [epoch: 10.5 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29607691108831763		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.29607691108831763 | validation: 0.3072109285501393]
	TIME [epoch: 10.5 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2743714347280821		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.2743714347280821 | validation: 0.3122872154927741]
	TIME [epoch: 10.5 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27878745894123624		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.27878745894123624 | validation: 0.3040797194836349]
	TIME [epoch: 10.5 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28423917625030926		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.28423917625030926 | validation: 0.31817464465195705]
	TIME [epoch: 10.5 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2813039146508732		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.2813039146508732 | validation: 0.32950189033046373]
	TIME [epoch: 10.5 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28581471532936914		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.28581471532936914 | validation: 0.31016591319182185]
	TIME [epoch: 10.5 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28862632094614166		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.28862632094614166 | validation: 0.3079097754933476]
	TIME [epoch: 10.5 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28047722675014575		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.28047722675014575 | validation: 0.3502609457515598]
	TIME [epoch: 10.5 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2878588034703937		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.2878588034703937 | validation: 0.3057806724927672]
	TIME [epoch: 10.5 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28773011847896274		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.28773011847896274 | validation: 0.31994431454755723]
	TIME [epoch: 10.5 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.290317390839986		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.290317390839986 | validation: 0.33506970293546107]
	TIME [epoch: 10.5 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27038785872545235		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.27038785872545235 | validation: 0.33899470170250373]
	TIME [epoch: 10.5 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2958959188510828		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.2958959188510828 | validation: 0.3235968166697771]
	TIME [epoch: 10.5 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2903475919979779		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.2903475919979779 | validation: 0.2917948067675451]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_746.pth
	Model improved!!!
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28883673058682724		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.28883673058682724 | validation: 0.3226256979297968]
	TIME [epoch: 10.5 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28743777589391295		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.28743777589391295 | validation: 0.31123999013089976]
	TIME [epoch: 10.5 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2883729517009041		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.2883729517009041 | validation: 0.3537174192951]
	TIME [epoch: 10.5 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.301270542196329		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.301270542196329 | validation: 0.32906232508274086]
	TIME [epoch: 10.5 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27568718154101896		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.27568718154101896 | validation: 0.31082695116617237]
	TIME [epoch: 10.5 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2732039429633678		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.2732039429633678 | validation: 0.3242724357355095]
	TIME [epoch: 10.5 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28611829119673865		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.28611829119673865 | validation: 0.3349008820324812]
	TIME [epoch: 10.5 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2986979222013242		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.2986979222013242 | validation: 0.28143907943076707]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_754.pth
	Model improved!!!
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29642489787736387		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.29642489787736387 | validation: 0.31778372601168314]
	TIME [epoch: 10.5 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2809040678946645		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.2809040678946645 | validation: 0.32694970962559977]
	TIME [epoch: 10.5 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27464350831541284		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.27464350831541284 | validation: 0.30976442982574137]
	TIME [epoch: 10.5 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27807152175744637		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.27807152175744637 | validation: 0.34435138153712536]
	TIME [epoch: 10.5 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3637992223004742		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.3637992223004742 | validation: 0.4276307456492001]
	TIME [epoch: 10.5 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3207939618845602		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.3207939618845602 | validation: 0.3387752610756272]
	TIME [epoch: 10.5 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3053286737310309		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.3053286737310309 | validation: 0.35642767456688]
	TIME [epoch: 10.5 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.32104828366534777		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.32104828366534777 | validation: 0.33994538366568733]
	TIME [epoch: 10.5 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2845095786842521		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.2845095786842521 | validation: 0.3292821045257924]
	TIME [epoch: 10.5 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27439696525542234		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.27439696525542234 | validation: 0.3271439614538498]
	TIME [epoch: 10.5 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27378682215172623		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.27378682215172623 | validation: 0.3161382848374186]
	TIME [epoch: 10.5 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27261538071787844		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.27261538071787844 | validation: 0.30609387438927066]
	TIME [epoch: 10.5 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.294619633844097		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.294619633844097 | validation: 0.3316025019066857]
	TIME [epoch: 10.5 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30697978292735106		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.30697978292735106 | validation: 0.30980744594854714]
	TIME [epoch: 10.5 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2931938014293626		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.2931938014293626 | validation: 0.3218372034792586]
	TIME [epoch: 10.5 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29370928196971546		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.29370928196971546 | validation: 0.33287666002141986]
	TIME [epoch: 10.5 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2797272021312722		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.2797272021312722 | validation: 0.3179101211072816]
	TIME [epoch: 10.5 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27261854848665007		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.27261854848665007 | validation: 0.31436797659141286]
	TIME [epoch: 10.5 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27996291622512276		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.27996291622512276 | validation: 0.34657223436144463]
	TIME [epoch: 10.5 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.287643785849996		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.287643785849996 | validation: 0.3277299700914583]
	TIME [epoch: 10.5 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27089673100772116		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.27089673100772116 | validation: 0.305350397393086]
	TIME [epoch: 10.5 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27223399499905715		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.27223399499905715 | validation: 0.3157795884203398]
	TIME [epoch: 10.5 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003994696384838		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.3003994696384838 | validation: 0.32280290476071927]
	TIME [epoch: 10.5 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2855201686144139		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.2855201686144139 | validation: 0.324063639492917]
	TIME [epoch: 10.5 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2633238727775503		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.2633238727775503 | validation: 0.3052353096299353]
	TIME [epoch: 10.5 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27585834643302964		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.27585834643302964 | validation: 0.3104163579540225]
	TIME [epoch: 10.5 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27772343521133397		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.27772343521133397 | validation: 0.2868833413107513]
	TIME [epoch: 10.5 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27925225156335		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.27925225156335 | validation: 0.31141286702942933]
	TIME [epoch: 10.5 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28471886321780704		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.28471886321780704 | validation: 0.31265409615220524]
	TIME [epoch: 10.5 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2858740564959897		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.2858740564959897 | validation: 0.31237251256694337]
	TIME [epoch: 10.5 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.270082764261654		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.270082764261654 | validation: 0.316103029201771]
	TIME [epoch: 10.5 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2754539263766179		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.2754539263766179 | validation: 0.3043423910192539]
	TIME [epoch: 10.5 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2776624600624176		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.2776624600624176 | validation: 0.30671193806287245]
	TIME [epoch: 10.5 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2697187222610108		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.2697187222610108 | validation: 0.3013551716952507]
	TIME [epoch: 10.5 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28122562577940835		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.28122562577940835 | validation: 0.34452379953334716]
	TIME [epoch: 10.5 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2815730248808331		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.2815730248808331 | validation: 0.3309474275383324]
	TIME [epoch: 10.5 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30463370812307367		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.30463370812307367 | validation: 0.3164028769441308]
	TIME [epoch: 10.5 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29336681031516154		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.29336681031516154 | validation: 0.3219954330330157]
	TIME [epoch: 10.5 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2861269225470798		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.2861269225470798 | validation: 0.2967506675989758]
	TIME [epoch: 10.5 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2717726434578615		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.2717726434578615 | validation: 0.32747229194422234]
	TIME [epoch: 10.5 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26258308921441376		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.26258308921441376 | validation: 0.29911302230495906]
	TIME [epoch: 10.5 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719857814689618		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.2719857814689618 | validation: 0.31081638437202275]
	TIME [epoch: 10.5 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2717553897756159		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.2717553897756159 | validation: 0.3008061029964066]
	TIME [epoch: 10.5 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2880531374307063		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.2880531374307063 | validation: 0.2936169704529051]
	TIME [epoch: 10.5 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2640760824872439		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.2640760824872439 | validation: 0.29178901874455226]
	TIME [epoch: 10.5 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699587164708822		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.2699587164708822 | validation: 0.30499404185628737]
	TIME [epoch: 10.5 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27293160151212786		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.27293160151212786 | validation: 0.3097469403487419]
	TIME [epoch: 10.5 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.268579565906591		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.268579565906591 | validation: 0.3379830275890845]
	TIME [epoch: 10.5 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2868564405278634		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.2868564405278634 | validation: 0.3271598585729923]
	TIME [epoch: 10.5 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807001771285864		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.2807001771285864 | validation: 0.31759548892017064]
	TIME [epoch: 10.5 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2730526916935287		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.2730526916935287 | validation: 0.33915435810435557]
	TIME [epoch: 10.5 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28698307732832673		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.28698307732832673 | validation: 0.3063313509980599]
	TIME [epoch: 10.5 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2788710131931217		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.2788710131931217 | validation: 0.31870633627502554]
	TIME [epoch: 10.5 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26308169472916		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.26308169472916 | validation: 0.3012333091771498]
	TIME [epoch: 10.5 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27817898248885353		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.27817898248885353 | validation: 0.3245244299064672]
	TIME [epoch: 10.5 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29273709533239295		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.29273709533239295 | validation: 0.37171258617629177]
	TIME [epoch: 10.5 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29457388122742667		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.29457388122742667 | validation: 0.35346802744682765]
	TIME [epoch: 10.5 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3340980518521337		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.3340980518521337 | validation: 0.3988259525771936]
	TIME [epoch: 10.5 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27758223145130134		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.27758223145130134 | validation: 0.3174980534720849]
	TIME [epoch: 10.5 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27787377165004595		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.27787377165004595 | validation: 0.32625578718021847]
	TIME [epoch: 10.5 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836680061265101		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.2836680061265101 | validation: 0.34492715778324234]
	TIME [epoch: 10.5 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.30782507577808665		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.30782507577808665 | validation: 0.36659369817925425]
	TIME [epoch: 10.5 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28295880088900804		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.28295880088900804 | validation: 0.3176615117062692]
	TIME [epoch: 10.5 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26642899695437444		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.26642899695437444 | validation: 0.32541164518882154]
	TIME [epoch: 10.5 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.281132913320183		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.281132913320183 | validation: 0.3121215041076413]
	TIME [epoch: 10.5 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2806535139303247		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.2806535139303247 | validation: 0.331588976749985]
	TIME [epoch: 10.5 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26316014594134124		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.26316014594134124 | validation: 0.29121462380085256]
	TIME [epoch: 10.5 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2665777708045626		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.2665777708045626 | validation: 0.30993227408457363]
	TIME [epoch: 10.5 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2652727971930747		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.2652727971930747 | validation: 0.3031288074858728]
	TIME [epoch: 10.5 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716314139610919		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.2716314139610919 | validation: 0.30616544353241815]
	TIME [epoch: 10.5 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2557405513419046		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.2557405513419046 | validation: 0.31267940135477645]
	TIME [epoch: 10.5 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2707242634707216		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.2707242634707216 | validation: 0.3089745264116816]
	TIME [epoch: 10.5 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.263459552136948		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.263459552136948 | validation: 0.29748412306787136]
	TIME [epoch: 10.5 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25905411104478404		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.25905411104478404 | validation: 0.29885859794817987]
	TIME [epoch: 10.5 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27100428557537437		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.27100428557537437 | validation: 0.3683592293584056]
	TIME [epoch: 10.5 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3112274821207298		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.3112274821207298 | validation: 0.32506067831933877]
	TIME [epoch: 10.5 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28080327052120396		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.28080327052120396 | validation: 0.30962020500927684]
	TIME [epoch: 10.5 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2929436308515607		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.2929436308515607 | validation: 0.34202752291702226]
	TIME [epoch: 10.5 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28157989826102947		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.28157989826102947 | validation: 0.35066011879576636]
	TIME [epoch: 10.5 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2912371375273136		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.2912371375273136 | validation: 0.32266223347147865]
	TIME [epoch: 10.5 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2962200374967489		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.2962200374967489 | validation: 0.3321411719974662]
	TIME [epoch: 10.5 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28407467166889083		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.28407467166889083 | validation: 0.3094480340050685]
	TIME [epoch: 10.5 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702994739122545		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.2702994739122545 | validation: 0.3074498316326138]
	TIME [epoch: 10.5 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2667408019270573		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.2667408019270573 | validation: 0.30947640156863687]
	TIME [epoch: 10.5 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28124613008391003		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.28124613008391003 | validation: 0.37229583971132385]
	TIME [epoch: 10.5 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2867123417307714		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.2867123417307714 | validation: 0.3279797069256886]
	TIME [epoch: 10.5 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28376653659802126		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.28376653659802126 | validation: 0.33259842572381343]
	TIME [epoch: 10.5 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2901059158253526		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.2901059158253526 | validation: 0.3664057672304087]
	TIME [epoch: 10.5 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3016348456711272		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.3016348456711272 | validation: 0.3574553878967828]
	TIME [epoch: 10.5 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27993854907607835		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.27993854907607835 | validation: 0.33798038065849156]
	TIME [epoch: 10.5 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2966851313898743		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.2966851313898743 | validation: 0.33456123061853826]
	TIME [epoch: 10.5 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2778929001913549		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.2778929001913549 | validation: 0.33166628253206737]
	TIME [epoch: 10.5 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28126685735015533		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.28126685735015533 | validation: 0.34281282971058646]
	TIME [epoch: 10.5 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013779755225781		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.3013779755225781 | validation: 0.32745887540469193]
	TIME [epoch: 10.5 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27276004247178653		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.27276004247178653 | validation: 0.323283284911592]
	TIME [epoch: 10.5 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2678744402331142		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.2678744402331142 | validation: 0.3513155419143646]
	TIME [epoch: 10.5 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2698766135986951		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.2698766135986951 | validation: 0.3043469327170319]
	TIME [epoch: 10.5 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28293971284950065		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.28293971284950065 | validation: 0.3025312237824298]
	TIME [epoch: 10.5 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700880798097761		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.2700880798097761 | validation: 0.3085267713913657]
	TIME [epoch: 10.5 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716112002333938		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.2716112002333938 | validation: 0.2985329313104779]
	TIME [epoch: 10.5 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2743758314414305		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.2743758314414305 | validation: 0.3076720275974051]
	TIME [epoch: 10.5 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799756215985264		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.2799756215985264 | validation: 0.31123967981394257]
	TIME [epoch: 10.5 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2632770656709418		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.2632770656709418 | validation: 0.30931034865482415]
	TIME [epoch: 10.5 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26880358875729937		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.26880358875729937 | validation: 0.3070827146812161]
	TIME [epoch: 10.5 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26588175251342777		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.26588175251342777 | validation: 0.30044535586034804]
	TIME [epoch: 10.5 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2637732960363483		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.2637732960363483 | validation: 0.3191928751371546]
	TIME [epoch: 10.5 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28849499462272643		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.28849499462272643 | validation: 0.298622763520492]
	TIME [epoch: 10.5 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2736917679537634		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.2736917679537634 | validation: 0.30096325662984513]
	TIME [epoch: 10.5 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.271085892881069		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.271085892881069 | validation: 0.3455755602890389]
	TIME [epoch: 10.5 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825662530266658		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.2825662530266658 | validation: 0.3209932810224289]
	TIME [epoch: 10.5 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2657251273952858		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.2657251273952858 | validation: 0.301400220468802]
	TIME [epoch: 10.5 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748780806198253		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.2748780806198253 | validation: 0.30688434732347397]
	TIME [epoch: 10.5 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2769673663453102		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.2769673663453102 | validation: 0.31191050110172597]
	TIME [epoch: 10.5 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2793704377148758		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.2793704377148758 | validation: 0.327759478451019]
	TIME [epoch: 10.5 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27500083381328927		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.27500083381328927 | validation: 0.29834639836500987]
	TIME [epoch: 10.5 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2662061911844074		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.2662061911844074 | validation: 0.3068931863516468]
	TIME [epoch: 10.5 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2652359877587541		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.2652359877587541 | validation: 0.2901452055226052]
	TIME [epoch: 10.5 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681247748696136		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.2681247748696136 | validation: 0.3127172625351312]
	TIME [epoch: 10.5 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2663992728401652		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.2663992728401652 | validation: 0.3067654689892414]
	TIME [epoch: 10.5 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26316400793861205		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.26316400793861205 | validation: 0.30420930921015255]
	TIME [epoch: 10.5 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26545709947227875		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.26545709947227875 | validation: 0.3142369532361768]
	TIME [epoch: 10.5 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.265565291556746		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.265565291556746 | validation: 0.33386902017316744]
	TIME [epoch: 10.5 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29748130268950856		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.29748130268950856 | validation: 0.3659116220533917]
	TIME [epoch: 10.5 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.3194702226890552		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.3194702226890552 | validation: 0.35907373244561874]
	TIME [epoch: 10.5 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29880482396775565		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.29880482396775565 | validation: 0.3047709576589353]
	TIME [epoch: 10.5 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2628074134706796		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.2628074134706796 | validation: 0.3012912937023712]
	TIME [epoch: 10.5 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2617775838979913		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.2617775838979913 | validation: 0.3237780826410814]
	TIME [epoch: 10.5 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613475991405709		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.2613475991405709 | validation: 0.3150783478559219]
	TIME [epoch: 10.5 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2662923446800197		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.2662923446800197 | validation: 0.3014474361245331]
	TIME [epoch: 10.5 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2584451238909648		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.2584451238909648 | validation: 0.29752670489586996]
	TIME [epoch: 10.5 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2629652924793371		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.2629652924793371 | validation: 0.31251274275702584]
	TIME [epoch: 10.5 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636318808001124		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.2636318808001124 | validation: 0.3071035353883258]
	TIME [epoch: 10.5 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2637579556322414		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.2637579556322414 | validation: 0.3005677503050448]
	TIME [epoch: 10.5 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2735946520285989		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.2735946520285989 | validation: 0.3375852943726343]
	TIME [epoch: 10.5 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26199471515118133		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.26199471515118133 | validation: 0.31554073059554283]
	TIME [epoch: 10.5 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2776363892588415		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.2776363892588415 | validation: 0.3364036047006168]
	TIME [epoch: 10.5 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.29051435819947613		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.29051435819947613 | validation: 0.31767016908515966]
	TIME [epoch: 10.5 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2744283889518563		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.2744283889518563 | validation: 0.28318836320402513]
	TIME [epoch: 10.5 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770959491500853		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.2770959491500853 | validation: 0.3251043877384586]
	TIME [epoch: 10.5 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2646546354293681		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.2646546354293681 | validation: 0.3000551883545951]
	TIME [epoch: 10.5 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26390675271509856		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.26390675271509856 | validation: 0.28285290942421965]
	TIME [epoch: 10.5 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26033741309578595		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.26033741309578595 | validation: 0.298691729145854]
	TIME [epoch: 10.5 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25662577287427346		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.25662577287427346 | validation: 0.2933855831800586]
	TIME [epoch: 10.5 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2601780834673043		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.2601780834673043 | validation: 0.3004168802217614]
	TIME [epoch: 10.5 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2664547228202781		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.2664547228202781 | validation: 0.3119524469329051]
	TIME [epoch: 10.5 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588293818334596		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.2588293818334596 | validation: 0.3027913673322162]
	TIME [epoch: 10.5 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2590086683384522		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.2590086683384522 | validation: 0.3269525729783335]
	TIME [epoch: 10.5 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581262299123159		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.2581262299123159 | validation: 0.2891347201763756]
	TIME [epoch: 10.5 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.277104258843207		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.277104258843207 | validation: 0.301658853031828]
	TIME [epoch: 10.5 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26034479390697585		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.26034479390697585 | validation: 0.304389221803476]
	TIME [epoch: 10.5 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2482514436623358		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.2482514436623358 | validation: 0.29139682879704554]
	TIME [epoch: 10.5 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25618460849560715		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.25618460849560715 | validation: 0.3053615669349754]
	TIME [epoch: 10.5 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26144315039793004		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.26144315039793004 | validation: 0.30973847667457266]
	TIME [epoch: 10.5 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26186991115664326		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.26186991115664326 | validation: 0.316231889206497]
	TIME [epoch: 10.5 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25938987826296545		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.25938987826296545 | validation: 0.2930785811067754]
	TIME [epoch: 10.5 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25186120539737805		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.25186120539737805 | validation: 0.3150139464486141]
	TIME [epoch: 10.5 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2657178615134298		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.2657178615134298 | validation: 0.2999028368689083]
	TIME [epoch: 10.5 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2672233823547095		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.2672233823547095 | validation: 0.29601213570342466]
	TIME [epoch: 10.5 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2630754132313874		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.2630754132313874 | validation: 0.29809230794904545]
	TIME [epoch: 10.5 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2553695533409037		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.2553695533409037 | validation: 0.32600131609023264]
	TIME [epoch: 10.5 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26381843251271675		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.26381843251271675 | validation: 0.29726644109503925]
	TIME [epoch: 10.5 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25827043813822004		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.25827043813822004 | validation: 0.3035268110036404]
	TIME [epoch: 10.5 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2513079995155619		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.2513079995155619 | validation: 0.29899228981216475]
	TIME [epoch: 10.5 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25563414483562763		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.25563414483562763 | validation: 0.2964233530568803]
	TIME [epoch: 10.5 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25917572108753084		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.25917572108753084 | validation: 0.3060653716301611]
	TIME [epoch: 10.5 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26554239748019015		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.26554239748019015 | validation: 0.2960886849818965]
	TIME [epoch: 10.5 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.285717095435517		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.285717095435517 | validation: 0.3597795373417968]
	TIME [epoch: 10.5 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28101563629632637		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.28101563629632637 | validation: 0.31102650847967456]
	TIME [epoch: 10.5 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26717657809203904		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.26717657809203904 | validation: 0.2925991663397428]
	TIME [epoch: 10.5 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26500586242221746		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.26500586242221746 | validation: 0.29939824537474075]
	TIME [epoch: 10.5 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2601019339774766		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.2601019339774766 | validation: 0.3230159567225125]
	TIME [epoch: 10.5 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642464577969834		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.2642464577969834 | validation: 0.31075388876658294]
	TIME [epoch: 10.5 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26539402446926896		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.26539402446926896 | validation: 0.3323681345737201]
	TIME [epoch: 10.5 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2889049794954432		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.2889049794954432 | validation: 0.308149925089957]
	TIME [epoch: 10.5 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2628408034390794		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.2628408034390794 | validation: 0.31974152753533214]
	TIME [epoch: 10.5 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2664815978067193		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.2664815978067193 | validation: 0.3205591645504173]
	TIME [epoch: 10.5 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28457835286468186		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.28457835286468186 | validation: 0.3216359947880897]
	TIME [epoch: 10.5 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27092088842712		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.27092088842712 | validation: 0.2771920245527035]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_932.pth
	Model improved!!!
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26460983419704764		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.26460983419704764 | validation: 0.2802581493434973]
	TIME [epoch: 10.5 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2600056784474883		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.2600056784474883 | validation: 0.27292286176577135]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_934.pth
	Model improved!!!
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26040104597507824		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.26040104597507824 | validation: 0.30176526667807785]
	TIME [epoch: 10.5 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25743307080745315		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.25743307080745315 | validation: 0.2858648903592225]
	TIME [epoch: 10.5 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531472802003485		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.2531472802003485 | validation: 0.30603296311044476]
	TIME [epoch: 10.5 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2505180936434378		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.2505180936434378 | validation: 0.2832663937562705]
	TIME [epoch: 10.5 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2614200427580355		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.2614200427580355 | validation: 0.32869493067947353]
	TIME [epoch: 10.5 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2727574370631289		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.2727574370631289 | validation: 0.3077279866920359]
	TIME [epoch: 10.5 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596162404057708		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.2596162404057708 | validation: 0.30658873800056935]
	TIME [epoch: 10.5 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26042468287063014		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.26042468287063014 | validation: 0.29548140176225374]
	TIME [epoch: 10.5 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26396960850348067		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.26396960850348067 | validation: 0.3007157953334354]
	TIME [epoch: 10.5 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2591146205581369		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.2591146205581369 | validation: 0.2907234671352416]
	TIME [epoch: 10.5 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.254679627279614		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.254679627279614 | validation: 0.2949780243408839]
	TIME [epoch: 10.5 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25776937155640384		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.25776937155640384 | validation: 0.2716100772904601]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_946.pth
	Model improved!!!
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25028261027563103		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.25028261027563103 | validation: 0.2943975125384648]
	TIME [epoch: 10.5 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2530485966051575		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.2530485966051575 | validation: 0.3066705066021953]
	TIME [epoch: 10.5 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2558698411832255		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.2558698411832255 | validation: 0.2832746254793742]
	TIME [epoch: 10.5 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2597647992976228		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.2597647992976228 | validation: 0.3172324099146497]
	TIME [epoch: 10.5 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.270725191784215		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.270725191784215 | validation: 0.3300642633827202]
	TIME [epoch: 10.5 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27403942925018654		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.27403942925018654 | validation: 0.34027999317494706]
	TIME [epoch: 10.5 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27655896199226765		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.27655896199226765 | validation: 0.29237509936647366]
	TIME [epoch: 10.5 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27213724761969266		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.27213724761969266 | validation: 0.3098569265157656]
	TIME [epoch: 10.5 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2782254207831213		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.2782254207831213 | validation: 0.2968255924702589]
	TIME [epoch: 10.5 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2595550060315602		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.2595550060315602 | validation: 0.29104651913513047]
	TIME [epoch: 10.5 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2586910200392804		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.2586910200392804 | validation: 0.28261165237406183]
	TIME [epoch: 10.5 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2590150455549812		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.2590150455549812 | validation: 0.27930594384131835]
	TIME [epoch: 10.5 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2628422954509425		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.2628422954509425 | validation: 0.27399651834872024]
	TIME [epoch: 10.5 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25363145081725036		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.25363145081725036 | validation: 0.30814345828974893]
	TIME [epoch: 10.5 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2665286148161547		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.2665286148161547 | validation: 0.33358738982715935]
	TIME [epoch: 10.5 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2627910324700017		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.2627910324700017 | validation: 0.29665453241603773]
	TIME [epoch: 10.5 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25454790628814317		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.25454790628814317 | validation: 0.3047505727977548]
	TIME [epoch: 10.5 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700139299314818		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.2700139299314818 | validation: 0.32154927636923575]
	TIME [epoch: 10.5 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2646429323509087		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.2646429323509087 | validation: 0.30061938098391705]
	TIME [epoch: 10.5 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.27142844777899605		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.27142844777899605 | validation: 0.3104514824609262]
	TIME [epoch: 10.5 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26452093850893615		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.26452093850893615 | validation: 0.29680229274654535]
	TIME [epoch: 10.5 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26790616957508906		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.26790616957508906 | validation: 0.3068920571311879]
	TIME [epoch: 10.5 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26535865622241583		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.26535865622241583 | validation: 0.2996639402965184]
	TIME [epoch: 10.5 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2595268833717147		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.2595268833717147 | validation: 0.29029981313644376]
	TIME [epoch: 10.5 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25935307610286873		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.25935307610286873 | validation: 0.28258028933056556]
	TIME [epoch: 10.5 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24913234860488193		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.24913234860488193 | validation: 0.26237099841079753]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r2_20240217_161441/states/model_tr_study6_972.pth
	Model improved!!!
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26270372089039257		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.26270372089039257 | validation: 0.3017548071369612]
	TIME [epoch: 10.5 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25801163894305423		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.25801163894305423 | validation: 0.28755060188411263]
	TIME [epoch: 10.4 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2618751788814217		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.2618751788814217 | validation: 0.3044060103945771]
	TIME [epoch: 10.4 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2629877408305038		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.2629877408305038 | validation: 0.2803522858679144]
	TIME [epoch: 10.4 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25864819997711025		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.25864819997711025 | validation: 0.29745891893359405]
	TIME [epoch: 10.4 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.262926544383905		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.262926544383905 | validation: 0.29022315693536604]
	TIME [epoch: 10.4 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25925322789398325		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.25925322789398325 | validation: 0.2826317014895661]
	TIME [epoch: 10.4 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25818018208949145		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.25818018208949145 | validation: 0.3004978929675769]
	TIME [epoch: 10.4 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25604766628261694		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.25604766628261694 | validation: 0.3008493624042799]
	TIME [epoch: 10.4 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26243751773059276		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.26243751773059276 | validation: 0.28912809663191746]
	TIME [epoch: 10.4 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25655644631954455		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.25655644631954455 | validation: 0.2930138384787147]
	TIME [epoch: 10.4 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25466049962831305		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.25466049962831305 | validation: 0.2809458450766438]
	TIME [epoch: 10.4 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.24893963328848626		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.24893963328848626 | validation: 0.28075070130675467]
	TIME [epoch: 10.4 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2672291298604191		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.2672291298604191 | validation: 0.30850778642613014]
	TIME [epoch: 10.4 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26236584945360153		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.26236584945360153 | validation: 0.29208989831991006]
	TIME [epoch: 10.4 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700252394008213		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.2700252394008213 | validation: 0.3051740605439761]
	TIME [epoch: 10.4 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26544343419347083		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.26544343419347083 | validation: 0.2904686888604702]
	TIME [epoch: 10.4 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25745870262717546		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.25745870262717546 | validation: 0.28396720127920366]
	TIME [epoch: 10.4 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2518872075915013		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.2518872075915013 | validation: 0.29802776390916114]
	TIME [epoch: 10.4 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596127055778929		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.2596127055778929 | validation: 0.301208973655962]
	TIME [epoch: 10.4 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2597531837379023		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.2597531837379023 | validation: 0.29488409378606717]
	TIME [epoch: 10.4 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26352818194227423		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.26352818194227423 | validation: 0.3135371040210911]
	TIME [epoch: 10.4 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2902070198707291		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.2902070198707291 | validation: 0.3021884922473763]
	TIME [epoch: 10.4 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.28778312571277387		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.28778312571277387 | validation: 0.30241599113210504]
	TIME [epoch: 10.4 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2758779144741759		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.2758779144741759 | validation: 0.29345037167839083]
	TIME [epoch: 10.4 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636114681692783		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.2636114681692783 | validation: 0.27684128848512524]
	TIME [epoch: 10.4 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.25911840327680574		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.25911840327680574 | validation: 0.2850883390385154]
	TIME [epoch: 10.4 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.26192591932446274		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.26192591932446274 | validation: 0.26753410557125196]
	TIME [epoch: 10.4 sec]
Finished training in 10588.466 seconds.
