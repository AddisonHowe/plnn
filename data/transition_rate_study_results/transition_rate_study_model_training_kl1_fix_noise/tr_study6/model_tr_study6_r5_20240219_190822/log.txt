Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1047851440

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.577709940264702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.577709940264702 | validation: 9.7683923955235]
	TIME [epoch: 68.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.60654564684049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.60654564684049 | validation: 8.569511611690107]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.804142182600911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.804142182600911 | validation: 7.6953211442694895]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.468153230028083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.468153230028083 | validation: 7.49766617256009]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.297476482278915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.297476482278915 | validation: 7.666530350252892]
	TIME [epoch: 10.2 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.17980228195858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.17980228195858 | validation: 7.236421727239625]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.024268888104322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.024268888104322 | validation: 6.956609177197294]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.817862741126841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.817862741126841 | validation: 6.94035223799593]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.707531762328732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.707531762328732 | validation: 6.736115659230413]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.453652219433525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.453652219433525 | validation: 6.38956450704771]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.219095092261004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.219095092261004 | validation: 6.315284938750068]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.13670155322536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.13670155322536 | validation: 6.1925347339926935]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.117003916226656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.117003916226656 | validation: 5.948615899902809]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.908803897201802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.908803897201802 | validation: 5.676175715073594]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.896738470142408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.896738470142408 | validation: 5.9276120258491645]
	TIME [epoch: 10.2 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.805305337151256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.805305337151256 | validation: 5.719025164753257]
	TIME [epoch: 10.2 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.774847199410869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.774847199410869 | validation: 6.122933246267439]
	TIME [epoch: 10.2 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.822677831440238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.822677831440238 | validation: 5.531730810721324]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.5647769497194135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5647769497194135 | validation: 5.863371910795652]
	TIME [epoch: 10.2 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.951667264137744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.951667264137744 | validation: 8.750802157384781]
	TIME [epoch: 10.2 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.304338363759424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.304338363759424 | validation: 5.750539789657937]
	TIME [epoch: 10.2 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.578948659154496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.578948659154496 | validation: 5.826942932386815]
	TIME [epoch: 10.2 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.5099051697944805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5099051697944805 | validation: 5.273717761045896]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.240062668302102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.240062668302102 | validation: 5.84748210027491]
	TIME [epoch: 10.2 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.2591508351011775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2591508351011775 | validation: 6.125657651209958]
	TIME [epoch: 10.2 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.294203245051296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.294203245051296 | validation: 5.102752054014184]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.884690147522837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.884690147522837 | validation: 8.906813737569768]
	TIME [epoch: 10.2 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.273659469781151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.273659469781151 | validation: 5.648868184189434]
	TIME [epoch: 10.2 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.346501727873823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.346501727873823 | validation: 6.398629348357096]
	TIME [epoch: 10.2 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.59407764075448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.59407764075448 | validation: 5.566691370992844]
	TIME [epoch: 10.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.387977188437618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.387977188437618 | validation: 5.598157022590367]
	TIME [epoch: 10.2 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.209681790999613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.209681790999613 | validation: 5.354221273920333]
	TIME [epoch: 10.2 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.366072971465034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.366072971465034 | validation: 6.321600984402419]
	TIME [epoch: 10.2 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.229801494129982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.229801494129982 | validation: 5.204892912642415]
	TIME [epoch: 10.2 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.541365896796899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.541365896796899 | validation: 5.088005750741228]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.205346739834269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.205346739834269 | validation: 5.548315601680185]
	TIME [epoch: 10.2 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3072965961764025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3072965961764025 | validation: 5.271270775301048]
	TIME [epoch: 10.2 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.152818403828755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.152818403828755 | validation: 5.524068394732056]
	TIME [epoch: 10.2 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.152399596246956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.152399596246956 | validation: 4.891319501878129]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.992767240276409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.992767240276409 | validation: 4.841084893145226]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.964816807766534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.964816807766534 | validation: 5.1845998435344836]
	TIME [epoch: 10.2 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.941551419723337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.941551419723337 | validation: 4.756669090147467]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.91171415668772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.91171415668772 | validation: 5.986238029030649]
	TIME [epoch: 10.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.2267363239981295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2267363239981295 | validation: 4.981291578461758]
	TIME [epoch: 10.2 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.09832868419482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.09832868419482 | validation: 5.71822028435641]
	TIME [epoch: 10.2 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.08169559194871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.08169559194871 | validation: 5.175780299436966]
	TIME [epoch: 10.2 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6432409615238965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6432409615238965 | validation: 5.247385550622769]
	TIME [epoch: 10.2 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.494447925282017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.494447925282017 | validation: 5.581099394276795]
	TIME [epoch: 10.2 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.305047834343452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.305047834343452 | validation: 5.788782836947629]
	TIME [epoch: 10.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.150920474932738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.150920474932738 | validation: 5.042967322005552]
	TIME [epoch: 10.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.084752642160303		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 6.084752642160303 | validation: 5.367855786126022]
	TIME [epoch: 10.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.144658448769357		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 6.144658448769357 | validation: 5.887952906030029]
	TIME [epoch: 10.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.10737465114087		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 6.10737465114087 | validation: 4.920761996602387]
	TIME [epoch: 10.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.898402170500231		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 5.898402170500231 | validation: 4.854237521265024]
	TIME [epoch: 10.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.100886680108776		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 6.100886680108776 | validation: 4.941670085236784]
	TIME [epoch: 10.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.9168186389177535		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 6.9168186389177535 | validation: 4.987471464986702]
	TIME [epoch: 10.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.957474103874458		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 5.957474103874458 | validation: 4.813245783004306]
	TIME [epoch: 10.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.834251654466584		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 5.834251654466584 | validation: 4.813764994640786]
	TIME [epoch: 10.2 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.830895844508824		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 5.830895844508824 | validation: 4.781977143660271]
	TIME [epoch: 10.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.72352052855158		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 5.72352052855158 | validation: 6.202886567204023]
	TIME [epoch: 10.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.0048504606664865		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 6.0048504606664865 | validation: 5.3474852180856685]
	TIME [epoch: 10.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.749848454594951		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 5.749848454594951 | validation: 4.997526496316565]
	TIME [epoch: 10.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.454159125071243		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 6.454159125071243 | validation: 4.852947122904758]
	TIME [epoch: 10.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.591944177597		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 6.591944177597 | validation: 6.2070493590792335]
	TIME [epoch: 10.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.986189171728757		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 5.986189171728757 | validation: 4.7025181656636255]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.956000422907897		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 5.956000422907897 | validation: 4.855197412805343]
	TIME [epoch: 10.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.70189999283595		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 5.70189999283595 | validation: 4.720165282725633]
	TIME [epoch: 10.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.141139502719808		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 6.141139502719808 | validation: 4.786034288720877]
	TIME [epoch: 10.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.642929534680653		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 5.642929534680653 | validation: 5.902137804585287]
	TIME [epoch: 10.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.951615812365368		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 5.951615812365368 | validation: 4.710461214658949]
	TIME [epoch: 10.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.14441299435639		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 6.14441299435639 | validation: 4.962352435825558]
	TIME [epoch: 10.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.029651120213317		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 6.029651120213317 | validation: 4.728412212534667]
	TIME [epoch: 10.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.710310277305554		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 5.710310277305554 | validation: 4.747176141392461]
	TIME [epoch: 10.2 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.586039928275963		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 5.586039928275963 | validation: 4.814955793479653]
	TIME [epoch: 10.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.059941354934885		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 6.059941354934885 | validation: 4.746866413936557]
	TIME [epoch: 10.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.967614060642054		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 5.967614060642054 | validation: 4.789055044185055]
	TIME [epoch: 10.2 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.682815315340899		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 5.682815315340899 | validation: 4.765693149042716]
	TIME [epoch: 10.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.819853085114028		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 5.819853085114028 | validation: 5.166018985059765]
	TIME [epoch: 10.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9827504756547025		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 5.9827504756547025 | validation: 4.926849781033789]
	TIME [epoch: 10.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.662986680264713		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 5.662986680264713 | validation: 5.034168161983319]
	TIME [epoch: 10.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.825521891861301		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 5.825521891861301 | validation: 4.590949668338216]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.155589462661527		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 6.155589462661527 | validation: 5.254262047890469]
	TIME [epoch: 10.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.703243603670558		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 5.703243603670558 | validation: 4.980694017571969]
	TIME [epoch: 10.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.533657505845733		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 5.533657505845733 | validation: 4.751743613796476]
	TIME [epoch: 10.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5163347848237825		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 5.5163347848237825 | validation: 4.682650606506134]
	TIME [epoch: 10.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.694446662418827		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 5.694446662418827 | validation: 5.1331826618941365]
	TIME [epoch: 10.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.606452803004018		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 5.606452803004018 | validation: 4.736988302165814]
	TIME [epoch: 10.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.456946458094175		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 5.456946458094175 | validation: 4.565948190551821]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.545521870478158		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 5.545521870478158 | validation: 5.227552263673458]
	TIME [epoch: 10.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.495221025674559		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 5.495221025674559 | validation: 4.545571947737844]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.518322354259074		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 5.518322354259074 | validation: 5.674092054201163]
	TIME [epoch: 10.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.717484011702509		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 5.717484011702509 | validation: 4.638510654679059]
	TIME [epoch: 10.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.296196101932111		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 5.296196101932111 | validation: 4.648648347463866]
	TIME [epoch: 10.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.395619844890971		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 5.395619844890971 | validation: 4.519895448020007]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4912865698490805		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 5.4912865698490805 | validation: 4.429510724187411]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5436311472090765		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 5.5436311472090765 | validation: 4.392001370499368]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.571658429174066		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.571658429174066 | validation: 5.059429042876644]
	TIME [epoch: 10.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.534630808038678		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 5.534630808038678 | validation: 4.591947705969605]
	TIME [epoch: 10.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.256989320113031		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 5.256989320113031 | validation: 5.336575172636221]
	TIME [epoch: 10.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.468104991790121		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 5.468104991790121 | validation: 4.454384359327306]
	TIME [epoch: 10.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.141746568742092		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 5.141746568742092 | validation: 4.306598424949305]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.056904629392712		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 5.056904629392712 | validation: 4.345859673284336]
	TIME [epoch: 10.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.989096541349369		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 4.989096541349369 | validation: 4.257187203041156]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.311985749389546		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 5.311985749389546 | validation: 4.292793760872803]
	TIME [epoch: 10.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.187693902839692		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 5.187693902839692 | validation: 4.339412990116258]
	TIME [epoch: 10.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.078161556934112		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 5.078161556934112 | validation: 4.749196954658815]
	TIME [epoch: 10.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.035534718913364		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 5.035534718913364 | validation: 5.186314654637423]
	TIME [epoch: 10.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.179482630197061		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 5.179482630197061 | validation: 4.484880342848046]
	TIME [epoch: 10.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.905958907990476		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 4.905958907990476 | validation: 5.438849761223362]
	TIME [epoch: 10.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4587362575579395		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 5.4587362575579395 | validation: 4.383630178523305]
	TIME [epoch: 10.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8870536978325365		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 4.8870536978325365 | validation: 4.2826462673731305]
	TIME [epoch: 10.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.941701692724615		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 4.941701692724615 | validation: 4.465574756124543]
	TIME [epoch: 10.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.860218900324659		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 4.860218900324659 | validation: 4.354005074553092]
	TIME [epoch: 10.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.877634695093111		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 4.877634695093111 | validation: 4.54421199770273]
	TIME [epoch: 10.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.918826433366446		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 4.918826433366446 | validation: 4.940381901176262]
	TIME [epoch: 10.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.06234472112398		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 5.06234472112398 | validation: 4.467092382702078]
	TIME [epoch: 10.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.067610561909443		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 5.067610561909443 | validation: 4.172618898547525]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.837991499774435		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 4.837991499774435 | validation: 4.164080883275455]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.465674972614699		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 5.465674972614699 | validation: 5.4958996611075905]
	TIME [epoch: 10.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.474064719209873		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 5.474064719209873 | validation: 4.185572817408435]
	TIME [epoch: 10.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.447705819677469		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 5.447705819677469 | validation: 5.085538180329324]
	TIME [epoch: 10.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.007225642795527		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 5.007225642795527 | validation: 4.282476473828839]
	TIME [epoch: 10.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.935927481636077		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 4.935927481636077 | validation: 4.206304700768047]
	TIME [epoch: 10.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.852311965534844		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 4.852311965534844 | validation: 4.289016948258969]
	TIME [epoch: 10.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.835783448787597		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 4.835783448787597 | validation: 4.191451426064488]
	TIME [epoch: 10.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.135885405756325		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 5.135885405756325 | validation: 4.4032324237419]
	TIME [epoch: 10.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.909967326398354		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 4.909967326398354 | validation: 4.371207434071599]
	TIME [epoch: 10.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.744748825870096		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 4.744748825870096 | validation: 4.802224918248414]
	TIME [epoch: 10.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.793405471238328		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 4.793405471238328 | validation: 4.446399831179327]
	TIME [epoch: 10.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.737055676687382		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 4.737055676687382 | validation: 4.09401901639477]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6469556310576134		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 4.6469556310576134 | validation: 4.403045403732135]
	TIME [epoch: 10.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.061554605466661		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 5.061554605466661 | validation: 4.21863754877695]
	TIME [epoch: 10.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.777322478802419		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 4.777322478802419 | validation: 4.276544919137234]
	TIME [epoch: 10.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7437138203526485		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 4.7437138203526485 | validation: 4.043844317361561]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.954800472502879		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 4.954800472502879 | validation: 5.004646453636526]
	TIME [epoch: 10.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.961902459229971		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 4.961902459229971 | validation: 4.099843549886834]
	TIME [epoch: 10.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.718550718482701		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 4.718550718482701 | validation: 4.100114552654416]
	TIME [epoch: 10.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.727106765934183		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 4.727106765934183 | validation: 4.131331276829545]
	TIME [epoch: 10.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.910382702698515		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 4.910382702698515 | validation: 5.544001828043872]
	TIME [epoch: 10.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.343002501467353		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 5.343002501467353 | validation: 5.0759258929748245]
	TIME [epoch: 10.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.795724371127892		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 4.795724371127892 | validation: 7.2936637840028355]
	TIME [epoch: 10.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.937746325170696		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 5.937746325170696 | validation: 4.260161860934308]
	TIME [epoch: 10.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.758050128969406		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 4.758050128969406 | validation: 4.488406715076368]
	TIME [epoch: 10.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.972906002430172		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 4.972906002430172 | validation: 4.1780431188826235]
	TIME [epoch: 10.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.605879080223728		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 4.605879080223728 | validation: 3.8489678589028973]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.617287563714833		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 4.617287563714833 | validation: 3.9496893602296077]
	TIME [epoch: 10.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5289400327629625		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 4.5289400327629625 | validation: 5.3551267825927145]
	TIME [epoch: 10.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.655066524800747		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 4.655066524800747 | validation: 4.401953205324026]
	TIME [epoch: 10.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.747175289837353		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 4.747175289837353 | validation: 3.8780398511843726]
	TIME [epoch: 10.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.633618628625059		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 4.633618628625059 | validation: 4.003649401165202]
	TIME [epoch: 10.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.454378306180272		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 4.454378306180272 | validation: 4.207943108182946]
	TIME [epoch: 10.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.507523723081126		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 4.507523723081126 | validation: 3.97302803023128]
	TIME [epoch: 10.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.30485077386992		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 4.30485077386992 | validation: 4.138551779382157]
	TIME [epoch: 10.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.23152754161743		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 5.23152754161743 | validation: 7.6166477349188515]
	TIME [epoch: 10.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.326056135059796		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 10.326056135059796 | validation: 10.74722126505257]
	TIME [epoch: 10.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.505788384011883		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 9.505788384011883 | validation: 7.928901350173957]
	TIME [epoch: 10.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.571899917490695		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 7.571899917490695 | validation: 6.772827789186614]
	TIME [epoch: 10.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.219405954678836		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 6.219405954678836 | validation: 4.103629822602667]
	TIME [epoch: 10.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.790391446019862		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 5.790391446019862 | validation: 6.344866303131807]
	TIME [epoch: 10.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6622728300573595		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 6.6622728300573595 | validation: 6.285611739769845]
	TIME [epoch: 10.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.072579116001138		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 5.072579116001138 | validation: 2.139417858448159]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.25753979848974		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 3.25753979848974 | validation: 1.9056992557453185]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.813465832186746		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 2.813465832186746 | validation: 2.4734725842488015]
	TIME [epoch: 10.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8045221796364297		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 3.8045221796364297 | validation: 3.6790752299093885]
	TIME [epoch: 10.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.566302356241562		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 3.566302356241562 | validation: 3.4484858025070153]
	TIME [epoch: 10.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.846654088350431		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 2.846654088350431 | validation: 1.3604929522498617]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.38908219095629		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 2.38908219095629 | validation: 2.2747616210821224]
	TIME [epoch: 10.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9407876138659725		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 2.9407876138659725 | validation: 2.7315750463883024]
	TIME [epoch: 10.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9513216963923226		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 2.9513216963923226 | validation: 2.11468858737386]
	TIME [epoch: 10.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0755004133870996		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 2.0755004133870996 | validation: 2.230924899540463]
	TIME [epoch: 10.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.326198498674411		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 2.326198498674411 | validation: 3.3894021946351534]
	TIME [epoch: 10.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5199423150333433		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 2.5199423150333433 | validation: 1.2371179366413083]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.669897632666806		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 2.669897632666806 | validation: 1.7677326752671014]
	TIME [epoch: 10.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8586465962142715		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 1.8586465962142715 | validation: 2.889544655617356]
	TIME [epoch: 10.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3478599573181875		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 2.3478599573181875 | validation: 1.9959097882480967]
	TIME [epoch: 10.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8120834296217914		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 1.8120834296217914 | validation: 1.640246320093548]
	TIME [epoch: 10.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.280507027402222		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 2.280507027402222 | validation: 2.3389141194409344]
	TIME [epoch: 10.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.103754446779429		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 2.103754446779429 | validation: 3.3913451170253155]
	TIME [epoch: 10.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6753299073371073		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 2.6753299073371073 | validation: 2.0727012077215012]
	TIME [epoch: 10.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.136331754178684		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 2.136331754178684 | validation: 2.075653564954538]
	TIME [epoch: 10.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1788570300970163		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 2.1788570300970163 | validation: 1.3806680341907773]
	TIME [epoch: 10.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.525255934138172		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 2.525255934138172 | validation: 1.6227761981205537]
	TIME [epoch: 10.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8244351168593513		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 1.8244351168593513 | validation: 2.614642556213815]
	TIME [epoch: 10.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3199191079175074		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 2.3199191079175074 | validation: 2.4791157694345327]
	TIME [epoch: 10.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1035770268035687		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 2.1035770268035687 | validation: 1.8432649860396304]
	TIME [epoch: 10.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.836432600192254		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 1.836432600192254 | validation: 1.1400156150606156]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4922776157562132		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 1.4922776157562132 | validation: 1.5181119397321439]
	TIME [epoch: 10.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7107405709966206		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 1.7107405709966206 | validation: 1.7860338760565304]
	TIME [epoch: 10.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9821144275929026		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 1.9821144275929026 | validation: 1.3680440181650266]
	TIME [epoch: 10.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5864939621971843		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 1.5864939621971843 | validation: 1.5603346796642978]
	TIME [epoch: 10.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7652468414445566		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 1.7652468414445566 | validation: 2.6346145481301724]
	TIME [epoch: 10.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8375976455137404		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 1.8375976455137404 | validation: 1.7962459999109006]
	TIME [epoch: 10.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6004505949268304		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 1.6004505949268304 | validation: 1.526086163701658]
	TIME [epoch: 10.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0040393331282624		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 2.0040393331282624 | validation: 1.5887402867062355]
	TIME [epoch: 10.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6957075756926172		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 1.6957075756926172 | validation: 1.2539425026747828]
	TIME [epoch: 10.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5808842074302798		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 1.5808842074302798 | validation: 1.2131928373842578]
	TIME [epoch: 10.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.190673445438656		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 2.190673445438656 | validation: 1.5243856229739743]
	TIME [epoch: 10.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4127984627074799		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 1.4127984627074799 | validation: 1.176149973964697]
	TIME [epoch: 10.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5688376315726955		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 1.5688376315726955 | validation: 1.6001253324215585]
	TIME [epoch: 10.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0842071458356974		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 2.0842071458356974 | validation: 1.5566574965017672]
	TIME [epoch: 10.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4642894407098666		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 1.4642894407098666 | validation: 1.2289752852811302]
	TIME [epoch: 10.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4767251635266332		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 1.4767251635266332 | validation: 1.2175927950247354]
	TIME [epoch: 10.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7649430198625118		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 1.7649430198625118 | validation: 1.5818480758295135]
	TIME [epoch: 10.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.386692599769006		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 1.386692599769006 | validation: 1.1244021029164508]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.911663391726996		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 1.911663391726996 | validation: 1.518380945964021]
	TIME [epoch: 10.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5786738453498663		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 1.5786738453498663 | validation: 1.4354844269124658]
	TIME [epoch: 10.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3509381032245165		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 1.3509381032245165 | validation: 2.0191161225009777]
	TIME [epoch: 10.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8465152284748243		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 1.8465152284748243 | validation: 1.1727673056869015]
	TIME [epoch: 10.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3994553590637968		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 1.3994553590637968 | validation: 2.238791617723681]
	TIME [epoch: 10.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.74033113080336		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 1.74033113080336 | validation: 1.2855500220695328]
	TIME [epoch: 10.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2894863350219947		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 1.2894863350219947 | validation: 1.1158378162637277]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1712058652209485		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 1.1712058652209485 | validation: 1.0594241369848123]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3076044194196896		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 1.3076044194196896 | validation: 1.2143881398892054]
	TIME [epoch: 10.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.244206796841054		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 1.244206796841054 | validation: 1.1880116359044866]
	TIME [epoch: 10.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4004896806165195		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 1.4004896806165195 | validation: 1.4547795649798925]
	TIME [epoch: 10.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1555277162346438		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 1.1555277162346438 | validation: 1.0816705949982623]
	TIME [epoch: 10.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.239855664431366		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 1.239855664431366 | validation: 1.0045825280439138]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1106729028981932		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 1.1106729028981932 | validation: 1.0420064935340905]
	TIME [epoch: 10.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.252913523217833		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 1.252913523217833 | validation: 1.1811207793215672]
	TIME [epoch: 10.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.067277303817558		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 1.067277303817558 | validation: 1.704720030952264]
	TIME [epoch: 10.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2299678568718833		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 1.2299678568718833 | validation: 0.9113695929308845]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.13202274869729		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 1.13202274869729 | validation: 1.1795602504324276]
	TIME [epoch: 10.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0961229369542504		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 1.0961229369542504 | validation: 1.219718543239731]
	TIME [epoch: 10.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3095879857604946		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 1.3095879857604946 | validation: 1.0901672418728647]
	TIME [epoch: 10.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0142798628582501		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 1.0142798628582501 | validation: 1.2233952233006842]
	TIME [epoch: 10.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1142292298454335		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 1.1142292298454335 | validation: 1.06458985169768]
	TIME [epoch: 10.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9789722342592249		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 0.9789722342592249 | validation: 1.1220611461433327]
	TIME [epoch: 10.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1233206824509885		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 1.1233206824509885 | validation: 1.0824999493009808]
	TIME [epoch: 10.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1098493492811183		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 1.1098493492811183 | validation: 0.9609075583449166]
	TIME [epoch: 10.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9967332591020638		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 0.9967332591020638 | validation: 1.2261068376259636]
	TIME [epoch: 10.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1447948488203328		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 1.1447948488203328 | validation: 0.8712276484863821]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0486300024703992		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 1.0486300024703992 | validation: 1.368672435783785]
	TIME [epoch: 10.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0394045773184386		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 1.0394045773184386 | validation: 1.0503231036455938]
	TIME [epoch: 10.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7798378425820558		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 1.7798378425820558 | validation: 0.7631257488061093]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8984943403072801		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 0.8984943403072801 | validation: 1.4282924020495074]
	TIME [epoch: 10.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3503943661894955		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 1.3503943661894955 | validation: 1.0157293511455818]
	TIME [epoch: 10.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.225905319760717		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 1.225905319760717 | validation: 0.7802779696300874]
	TIME [epoch: 10.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2023101608593103		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 1.2023101608593103 | validation: 1.4675217373280105]
	TIME [epoch: 10.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2172404760310376		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.2172404760310376 | validation: 0.8750155525024447]
	TIME [epoch: 10.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.912847323574286		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 0.912847323574286 | validation: 0.8551586848003969]
	TIME [epoch: 10.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4007624669977463		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 1.4007624669977463 | validation: 1.1663442977405691]
	TIME [epoch: 10.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1928301092639781		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 1.1928301092639781 | validation: 1.1744299034030494]
	TIME [epoch: 10.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2131206927829825		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 1.2131206927829825 | validation: 0.8191668488997257]
	TIME [epoch: 10.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3547761523636148		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 1.3547761523636148 | validation: 1.5709014691051943]
	TIME [epoch: 10.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0189209821618141		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 1.0189209821618141 | validation: 1.1596659252747434]
	TIME [epoch: 10.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9045882482899096		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 0.9045882482899096 | validation: 1.2226899849822925]
	TIME [epoch: 10.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9872447317214904		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 0.9872447317214904 | validation: 0.9227862979232327]
	TIME [epoch: 10.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8991033419885879		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 0.8991033419885879 | validation: 1.3334007796663099]
	TIME [epoch: 10.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0646777304395365		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 1.0646777304395365 | validation: 0.7589317692506947]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8995445001292351		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 0.8995445001292351 | validation: 1.1683321802080353]
	TIME [epoch: 10.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0915172061256802		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 1.0915172061256802 | validation: 0.8080022939829735]
	TIME [epoch: 10.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3217447633070905		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 1.3217447633070905 | validation: 0.8960968330784627]
	TIME [epoch: 10.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9962260121873706		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 0.9962260121873706 | validation: 0.9648823926165733]
	TIME [epoch: 10.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2319585824335764		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 1.2319585824335764 | validation: 1.196051205201207]
	TIME [epoch: 10.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9161116106728864		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 0.9161116106728864 | validation: 0.9065394020630931]
	TIME [epoch: 10.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0252615882771032		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 1.0252615882771032 | validation: 0.9628725075411234]
	TIME [epoch: 10.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1081379318072488		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 1.1081379318072488 | validation: 1.5937017040142893]
	TIME [epoch: 10.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1510087510638802		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 1.1510087510638802 | validation: 1.140090863485321]
	TIME [epoch: 10.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9711039597057208		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 0.9711039597057208 | validation: 0.9918397390271195]
	TIME [epoch: 10.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.059237060648525		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 1.059237060648525 | validation: 1.059096948325004]
	TIME [epoch: 10.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1882613358323193		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 1.1882613358323193 | validation: 1.1578552942869607]
	TIME [epoch: 10.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0199121134233822		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 1.0199121134233822 | validation: 1.3726259958554368]
	TIME [epoch: 10.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4146310899942793		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 1.4146310899942793 | validation: 1.167175488317356]
	TIME [epoch: 10.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0614075648469086		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 1.0614075648469086 | validation: 1.293481011402735]
	TIME [epoch: 10.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.089720683839761		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 1.089720683839761 | validation: 1.5771396669329953]
	TIME [epoch: 10.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6339763795936868		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 1.6339763795936868 | validation: 0.9641322027032396]
	TIME [epoch: 10.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.804525981596534		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 0.804525981596534 | validation: 0.7739204134917497]
	TIME [epoch: 10.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9822832152337597		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 0.9822832152337597 | validation: 1.224621353573946]
	TIME [epoch: 10.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8327545412444495		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 0.8327545412444495 | validation: 0.9390922466530032]
	TIME [epoch: 10.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9525916242299519		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 0.9525916242299519 | validation: 0.6838983673747439]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9029895144463383		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 0.9029895144463383 | validation: 0.7560515231426503]
	TIME [epoch: 10.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8134227699862165		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 0.8134227699862165 | validation: 1.392857754313277]
	TIME [epoch: 10.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9920202871858326		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 0.9920202871858326 | validation: 0.8529884488234278]
	TIME [epoch: 10.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8166916541087353		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 0.8166916541087353 | validation: 1.1222329563604254]
	TIME [epoch: 10.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8710149999565937		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 0.8710149999565937 | validation: 1.0054500578392052]
	TIME [epoch: 10.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0907241886491101		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 1.0907241886491101 | validation: 0.817578792174044]
	TIME [epoch: 10.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0019812057056356		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 1.0019812057056356 | validation: 0.9677645342384912]
	TIME [epoch: 10.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0826080641885356		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 1.0826080641885356 | validation: 0.7701462149357553]
	TIME [epoch: 10.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5084722774082304		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 1.5084722774082304 | validation: 0.6995852649058286]
	TIME [epoch: 10.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7978374123243335		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 0.7978374123243335 | validation: 1.989593579750527]
	TIME [epoch: 10.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2794322798974105		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 1.2794322798974105 | validation: 0.8449485445909458]
	TIME [epoch: 10.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8227346177958712		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 0.8227346177958712 | validation: 0.6332858806105103]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7164229615370981		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 0.7164229615370981 | validation: 0.6407327210643879]
	TIME [epoch: 10.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7114660171583767		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 0.7114660171583767 | validation: 0.9116251067637015]
	TIME [epoch: 10.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9598031716604961		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 0.9598031716604961 | validation: 0.9622968727008404]
	TIME [epoch: 10.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8729952264636415		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 0.8729952264636415 | validation: 0.8957254196297482]
	TIME [epoch: 10.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7369096913564175		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 0.7369096913564175 | validation: 0.9279060707994848]
	TIME [epoch: 10.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7380256517722529		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 0.7380256517722529 | validation: 1.4384048734008885]
	TIME [epoch: 10.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9968453253101954		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 0.9968453253101954 | validation: 0.8156883301912415]
	TIME [epoch: 10.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7272081697970444		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 0.7272081697970444 | validation: 0.6864923150267659]
	TIME [epoch: 10.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1473017084127854		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 1.1473017084127854 | validation: 0.8866468264412771]
	TIME [epoch: 10.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9477362765421746		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 0.9477362765421746 | validation: 1.2059541707600188]
	TIME [epoch: 10.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7630996086741042		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 0.7630996086741042 | validation: 0.9720697803176478]
	TIME [epoch: 10.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9088889606738004		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 0.9088889606738004 | validation: 0.7841685589485285]
	TIME [epoch: 10.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7202017997096773		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 0.7202017997096773 | validation: 0.8872067990603663]
	TIME [epoch: 10.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.787258669591542		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.787258669591542 | validation: 0.893164903682262]
	TIME [epoch: 10.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.818474779422165		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 0.818474779422165 | validation: 0.9159934547819799]
	TIME [epoch: 10.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8111201570922745		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 0.8111201570922745 | validation: 1.111998260343202]
	TIME [epoch: 10.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8627476799960899		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 0.8627476799960899 | validation: 0.78320043120634]
	TIME [epoch: 10.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8392036002953704		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 0.8392036002953704 | validation: 1.260593732095847]
	TIME [epoch: 10.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1185168452380552		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 1.1185168452380552 | validation: 0.8507586459622359]
	TIME [epoch: 10.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7966416525113217		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 0.7966416525113217 | validation: 0.8378182723077521]
	TIME [epoch: 10.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9792416834171845		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 0.9792416834171845 | validation: 1.0732032641745954]
	TIME [epoch: 10.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7667788446197659		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 0.7667788446197659 | validation: 0.9808148132256542]
	TIME [epoch: 10.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9132614942350529		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 0.9132614942350529 | validation: 1.4130717415255338]
	TIME [epoch: 10.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9708365420652946		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.9708365420652946 | validation: 1.0398276706489338]
	TIME [epoch: 10.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9285541014927141		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 0.9285541014927141 | validation: 0.7999824331006322]
	TIME [epoch: 10.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7198534845544755		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 0.7198534845544755 | validation: 0.9986426160271902]
	TIME [epoch: 10.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.991319041249754		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 0.991319041249754 | validation: 0.7427821989234119]
	TIME [epoch: 10.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.940470819235235		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.940470819235235 | validation: 1.3351818954849972]
	TIME [epoch: 10.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9623853587864991		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 0.9623853587864991 | validation: 0.7760312780478071]
	TIME [epoch: 10.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9630078974627458		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 0.9630078974627458 | validation: 1.6250150752634789]
	TIME [epoch: 10.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5060044184103534		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 1.5060044184103534 | validation: 1.0721529913385524]
	TIME [epoch: 10.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.905610017105891		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 0.905610017105891 | validation: 1.1891198193858066]
	TIME [epoch: 10.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9167488118089073		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.9167488118089073 | validation: 1.3679349589795498]
	TIME [epoch: 10.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9214841365178603		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.9214841365178603 | validation: 1.1468584996587818]
	TIME [epoch: 10.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9529239868332284		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.9529239868332284 | validation: 1.678794800562277]
	TIME [epoch: 10.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0694782046573694		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 1.0694782046573694 | validation: 1.010509387020519]
	TIME [epoch: 10.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8919329467740944		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.8919329467740944 | validation: 1.1962043914893543]
	TIME [epoch: 10.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9384197707907568		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 0.9384197707907568 | validation: 1.0131867758188706]
	TIME [epoch: 10.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8178186334704174		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.8178186334704174 | validation: 1.351627557117181]
	TIME [epoch: 10.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1537196534865237		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 1.1537196534865237 | validation: 0.7373556471401743]
	TIME [epoch: 10.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7344500413752453		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 0.7344500413752453 | validation: 1.315744611766049]
	TIME [epoch: 10.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8308982799982451		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 0.8308982799982451 | validation: 1.1101098378571947]
	TIME [epoch: 10.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9928086362325205		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 0.9928086362325205 | validation: 0.6466817029103654]
	TIME [epoch: 10.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7048266532963836		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 0.7048266532963836 | validation: 0.8243767363453407]
	TIME [epoch: 10.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7543327255445027		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 0.7543327255445027 | validation: 0.9119109664752364]
	TIME [epoch: 10.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8817000672619579		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 0.8817000672619579 | validation: 1.9999950312971086]
	TIME [epoch: 10.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.067272202545651		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 1.067272202545651 | validation: 0.8195022234423334]
	TIME [epoch: 10.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8248604522624561		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 0.8248604522624561 | validation: 0.7012321450780021]
	TIME [epoch: 10.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7820614776924429		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 0.7820614776924429 | validation: 0.7089523935788605]
	TIME [epoch: 10.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6473176981018238		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 0.6473176981018238 | validation: 0.8891235286643258]
	TIME [epoch: 10.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9106748041537689		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.9106748041537689 | validation: 0.8953157216462472]
	TIME [epoch: 10.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.91842954303916		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 0.91842954303916 | validation: 1.0398103148309599]
	TIME [epoch: 10.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8551685006088275		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 0.8551685006088275 | validation: 0.7901302626143175]
	TIME [epoch: 10.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8397294487684981		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 0.8397294487684981 | validation: 1.1848850580784076]
	TIME [epoch: 10.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8338908059677497		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 0.8338908059677497 | validation: 0.641236175505368]
	TIME [epoch: 10.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8042882893845388		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 0.8042882893845388 | validation: 1.0221683598532654]
	TIME [epoch: 10.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7318279393447543		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 0.7318279393447543 | validation: 0.6338583352758925]
	TIME [epoch: 10.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8334696062484914		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 0.8334696062484914 | validation: 0.639234896017966]
	TIME [epoch: 10.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6128480755332513		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 0.6128480755332513 | validation: 0.7200960659459724]
	TIME [epoch: 10.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7919887274677142		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 0.7919887274677142 | validation: 0.8045534824550127]
	TIME [epoch: 10.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7568637576872874		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 0.7568637576872874 | validation: 0.613256768503454]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6607950393939385		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 0.6607950393939385 | validation: 0.7295135022927164]
	TIME [epoch: 10.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6801871155191085		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 0.6801871155191085 | validation: 0.5637042574139989]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7370273768755604		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 0.7370273768755604 | validation: 0.706243506404954]
	TIME [epoch: 10.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.897511482058056		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 0.897511482058056 | validation: 1.0638986522315117]
	TIME [epoch: 10.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9460216008644148		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 0.9460216008644148 | validation: 1.3820077160676036]
	TIME [epoch: 10.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7507402485074413		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 0.7507402485074413 | validation: 0.8853793225182284]
	TIME [epoch: 10.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6695035280360633		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 0.6695035280360633 | validation: 0.7084850262854389]
	TIME [epoch: 10.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6840286807860538		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 0.6840286807860538 | validation: 0.9008169175900548]
	TIME [epoch: 10.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7072190674348179		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 0.7072190674348179 | validation: 0.8637643268113141]
	TIME [epoch: 10.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7561810012452864		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 0.7561810012452864 | validation: 0.9101920282414421]
	TIME [epoch: 10.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6300115603288059		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 0.6300115603288059 | validation: 0.6266978945043079]
	TIME [epoch: 10.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7878025958055803		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 0.7878025958055803 | validation: 0.7636412209712568]
	TIME [epoch: 10.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6649879904990252		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 0.6649879904990252 | validation: 0.6625894642404083]
	TIME [epoch: 10.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6124073823950689		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 0.6124073823950689 | validation: 0.5690683076106572]
	TIME [epoch: 10.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6295249532700524		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 0.6295249532700524 | validation: 0.5257656579610839]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6164009786041851		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 0.6164009786041851 | validation: 0.702367706222688]
	TIME [epoch: 10.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6297044187996		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 0.6297044187996 | validation: 0.7031103928483458]
	TIME [epoch: 10.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6358609667226004		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 0.6358609667226004 | validation: 0.6252583358227913]
	TIME [epoch: 10.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926926722813983		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 0.6926926722813983 | validation: 0.6376144326802898]
	TIME [epoch: 10.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.889668686029099		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 0.889668686029099 | validation: 0.7818250985147025]
	TIME [epoch: 10.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.712694930620893		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 0.712694930620893 | validation: 0.6146219343961498]
	TIME [epoch: 10.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.715744173440651		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 0.715744173440651 | validation: 0.608882498150218]
	TIME [epoch: 10.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6571945997384686		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 0.6571945997384686 | validation: 0.6023701968145734]
	TIME [epoch: 10.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7136963218044947		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 0.7136963218044947 | validation: 1.2497824670332114]
	TIME [epoch: 10.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3411521882426467		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 1.3411521882426467 | validation: 0.7452368902910388]
	TIME [epoch: 10.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5692731060877039		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 0.5692731060877039 | validation: 0.7704793436885009]
	TIME [epoch: 10.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5874206004372741		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 0.5874206004372741 | validation: 0.5113036472716475]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495028356238634		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 0.5495028356238634 | validation: 1.643586622153501]
	TIME [epoch: 10.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0623523586425443		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 1.0623523586425443 | validation: 0.5680987459295163]
	TIME [epoch: 10.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6590036969089775		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 0.6590036969089775 | validation: 0.7677570090974035]
	TIME [epoch: 10.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6177359852666839		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 0.6177359852666839 | validation: 0.8713248938386622]
	TIME [epoch: 10.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6853792615000537		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 0.6853792615000537 | validation: 1.2077027479934415]
	TIME [epoch: 10.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.761954252347118		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 0.761954252347118 | validation: 0.6123120440312791]
	TIME [epoch: 10.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7136624494618049		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 0.7136624494618049 | validation: 0.599569260977907]
	TIME [epoch: 10.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6905604950001438		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 0.6905604950001438 | validation: 0.8087410321326611]
	TIME [epoch: 10.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159275239216069		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 0.6159275239216069 | validation: 0.7010158578605961]
	TIME [epoch: 10.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6486796168222857		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 0.6486796168222857 | validation: 0.621173312742298]
	TIME [epoch: 10.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546937541353512		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.5546937541353512 | validation: 0.8516549322601789]
	TIME [epoch: 10.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6814177926796581		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.6814177926796581 | validation: 0.5460051603800163]
	TIME [epoch: 10.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5757823549502863		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.5757823549502863 | validation: 0.510453347086887]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5639411168301607		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 0.5639411168301607 | validation: 0.9027011127548977]
	TIME [epoch: 10.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7321901042380785		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.7321901042380785 | validation: 0.6065980876627587]
	TIME [epoch: 10.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4997266452744176		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.4997266452744176 | validation: 0.8993530075799262]
	TIME [epoch: 10.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6602595004705967		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.6602595004705967 | validation: 0.6649026661905209]
	TIME [epoch: 10.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6163963152840152		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 0.6163963152840152 | validation: 0.6740640590210208]
	TIME [epoch: 10.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185805632876569		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 0.6185805632876569 | validation: 0.9860444344559074]
	TIME [epoch: 10.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7351035084812902		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.7351035084812902 | validation: 0.63146326374518]
	TIME [epoch: 10.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6023026087446235		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.6023026087446235 | validation: 0.6511272419785411]
	TIME [epoch: 10.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317594836707923		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.6317594836707923 | validation: 0.7780391467067008]
	TIME [epoch: 10.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277965010592326		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.6277965010592326 | validation: 0.7694783436142627]
	TIME [epoch: 10.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6746914737606827		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 0.6746914737606827 | validation: 0.5781998089876784]
	TIME [epoch: 10.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.685979700454037		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 0.685979700454037 | validation: 0.6420814796362585]
	TIME [epoch: 10.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6048604517158562		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.6048604517158562 | validation: 0.9202446429154023]
	TIME [epoch: 10.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7661508225888289		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.7661508225888289 | validation: 0.6839224749910985]
	TIME [epoch: 10.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5900834189464359		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 0.5900834189464359 | validation: 0.8589689838004038]
	TIME [epoch: 10.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7819919962778796		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.7819919962778796 | validation: 0.9285757500435711]
	TIME [epoch: 10.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6520143481090526		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.6520143481090526 | validation: 0.694170741471593]
	TIME [epoch: 10.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6453068653662167		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.6453068653662167 | validation: 1.1053676387414946]
	TIME [epoch: 10.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7947477096501077		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 0.7947477096501077 | validation: 1.0225688247211229]
	TIME [epoch: 10.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7420025415356232		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.7420025415356232 | validation: 0.8535678878907232]
	TIME [epoch: 10.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.702412092772871		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.702412092772871 | validation: 0.7236004110627201]
	TIME [epoch: 10.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5799075158761635		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.5799075158761635 | validation: 0.49431187915845914]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6238498142894221		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 0.6238498142894221 | validation: 0.8369278654072408]
	TIME [epoch: 10.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6936312048970399		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.6936312048970399 | validation: 0.6523784346005863]
	TIME [epoch: 10.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7007514697681579		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.7007514697681579 | validation: 0.7200862693798624]
	TIME [epoch: 10.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7544350444301402		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.7544350444301402 | validation: 0.5578810051685129]
	TIME [epoch: 10.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5454263379005194		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.5454263379005194 | validation: 0.5575809590152827]
	TIME [epoch: 10.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8564377416494235		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.8564377416494235 | validation: 0.5474485530949151]
	TIME [epoch: 10.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5515019974838625		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 0.5515019974838625 | validation: 0.751635056077833]
	TIME [epoch: 10.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546401440798301		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.5546401440798301 | validation: 0.48062033117115316]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49903487524968837		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 0.49903487524968837 | validation: 1.380103849357277]
	TIME [epoch: 10.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5884721286981875		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 1.5884721286981875 | validation: 1.0012806720510241]
	TIME [epoch: 10.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7502980445337968		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.7502980445337968 | validation: 0.7613670340592166]
	TIME [epoch: 10.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.733660043462419		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.733660043462419 | validation: 1.081963672839408]
	TIME [epoch: 10.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7166380094190612		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.7166380094190612 | validation: 0.5086011871427024]
	TIME [epoch: 10.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5891812746964413		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.5891812746964413 | validation: 0.9184759302257799]
	TIME [epoch: 10.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391453154162801		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 0.6391453154162801 | validation: 0.5724687550195648]
	TIME [epoch: 10.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356729333737731		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 0.6356729333737731 | validation: 0.5512445364019105]
	TIME [epoch: 10.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288561134842247		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.5288561134842247 | validation: 0.5635780931831884]
	TIME [epoch: 10.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6721580789129195		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 0.6721580789129195 | validation: 0.5776538379407616]
	TIME [epoch: 10.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4779120199594657		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.4779120199594657 | validation: 0.8283708231967168]
	TIME [epoch: 10.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6912792647560858		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.6912792647560858 | validation: 0.5198845764572357]
	TIME [epoch: 10.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6686735851608699		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.6686735851608699 | validation: 0.7247597751218178]
	TIME [epoch: 10.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7888303302937725		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.7888303302937725 | validation: 0.6704180343700799]
	TIME [epoch: 10.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48697202725692657		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.48697202725692657 | validation: 0.5721168990752686]
	TIME [epoch: 10.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5327672864756149		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.5327672864756149 | validation: 0.679004580769655]
	TIME [epoch: 10.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117081816474571		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 0.6117081816474571 | validation: 0.6548553285719254]
	TIME [epoch: 10.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5354325203163205		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.5354325203163205 | validation: 0.5823281404590337]
	TIME [epoch: 10.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45082282882086827		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.45082282882086827 | validation: 0.899461635045456]
	TIME [epoch: 10.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8408533582201516		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.8408533582201516 | validation: 0.6116430158497734]
	TIME [epoch: 10.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5401106087703822		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.5401106087703822 | validation: 0.8160256849998967]
	TIME [epoch: 10.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.597832724228343		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.597832724228343 | validation: 0.5513765856637877]
	TIME [epoch: 10.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5815859173818715		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.5815859173818715 | validation: 0.7696733493667788]
	TIME [epoch: 10.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.85441871506286		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.85441871506286 | validation: 0.6858801400533369]
	TIME [epoch: 10.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6668179184607264		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.6668179184607264 | validation: 0.6011551079903861]
	TIME [epoch: 10.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6702397825102246		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.6702397825102246 | validation: 0.7440671045542315]
	TIME [epoch: 10.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6293375156636111		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.6293375156636111 | validation: 0.5967885604935264]
	TIME [epoch: 10.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5549365718996574		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 0.5549365718996574 | validation: 0.8182937337401316]
	TIME [epoch: 10.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8980782039849181		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.8980782039849181 | validation: 0.6685841129546559]
	TIME [epoch: 10.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6674051812013416		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.6674051812013416 | validation: 0.7134069536945344]
	TIME [epoch: 10.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999405621150126		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.5999405621150126 | validation: 0.8731292734542092]
	TIME [epoch: 10.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6470246317520035		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.6470246317520035 | validation: 0.6278287659689538]
	TIME [epoch: 10.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7940184117894229		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.7940184117894229 | validation: 0.7637241449203765]
	TIME [epoch: 10.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7340447474230141		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.7340447474230141 | validation: 0.5381466352190385]
	TIME [epoch: 10.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6541733685699683		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.6541733685699683 | validation: 1.0393614426809545]
	TIME [epoch: 10.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7123635957746957		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.7123635957746957 | validation: 0.5103318269837803]
	TIME [epoch: 10.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5716801550783558		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 0.5716801550783558 | validation: 0.704910473077468]
	TIME [epoch: 10.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7137928918750156		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.7137928918750156 | validation: 0.6284177103348134]
	TIME [epoch: 10.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8700397643844934		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.8700397643844934 | validation: 0.6103546622595508]
	TIME [epoch: 10.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5696424093211254		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.5696424093211254 | validation: 0.5802879449386742]
	TIME [epoch: 10.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6137830032491618		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.6137830032491618 | validation: 2.40311393461802]
	TIME [epoch: 10.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2379571123611806		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 2.2379571123611806 | validation: 0.6528236069373062]
	TIME [epoch: 10.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7959956645379181		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.7959956645379181 | validation: 0.5218796454490946]
	TIME [epoch: 10.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6151491908336684		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.6151491908336684 | validation: 0.5939943277228968]
	TIME [epoch: 10.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7559532746620015		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.7559532746620015 | validation: 0.9779278842532194]
	TIME [epoch: 10.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8523544111560908		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.8523544111560908 | validation: 0.5606617161397786]
	TIME [epoch: 10.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5406016695558247		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.5406016695558247 | validation: 1.2558282275053274]
	TIME [epoch: 10.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8401637374122635		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.8401637374122635 | validation: 0.5814227096858083]
	TIME [epoch: 10.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6858663080144807		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.6858663080144807 | validation: 0.755479854355801]
	TIME [epoch: 10.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7207709601484049		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.7207709601484049 | validation: 0.566501064051533]
	TIME [epoch: 10.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5830728151767464		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.5830728151767464 | validation: 0.7650482610040816]
	TIME [epoch: 10.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945250274138089		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.5945250274138089 | validation: 0.7460474762056899]
	TIME [epoch: 10.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6850611957998587		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.6850611957998587 | validation: 1.0981941049364357]
	TIME [epoch: 10.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7530302252120149		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.7530302252120149 | validation: 0.6605712593372975]
	TIME [epoch: 10.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5753622758027006		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.5753622758027006 | validation: 0.8052321411923258]
	TIME [epoch: 10.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6615187098945545		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.6615187098945545 | validation: 0.6553209201933734]
	TIME [epoch: 10.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6675705415565796		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.6675705415565796 | validation: 0.6410577637843656]
	TIME [epoch: 10.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6986958570723042		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.6986958570723042 | validation: 0.7097982261150153]
	TIME [epoch: 10.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6292420738256587		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.6292420738256587 | validation: 0.5929119239916036]
	TIME [epoch: 10.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5878245433415719		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.5878245433415719 | validation: 0.47835944822847815]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178257181881937		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.5178257181881937 | validation: 0.4934005720404589]
	TIME [epoch: 10.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5486496189775452		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.5486496189775452 | validation: 0.7107734449023809]
	TIME [epoch: 10.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6331309580571596		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.6331309580571596 | validation: 0.5837056559821727]
	TIME [epoch: 10.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6771544892119481		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.6771544892119481 | validation: 0.7024229758414184]
	TIME [epoch: 10.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6854679414211965		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.6854679414211965 | validation: 0.7419284410873721]
	TIME [epoch: 10.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5497911997426834		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.5497911997426834 | validation: 0.5674938977142086]
	TIME [epoch: 10.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6883718524915496		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.6883718524915496 | validation: 1.0131925182505352]
	TIME [epoch: 10.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8504182764368275		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.8504182764368275 | validation: 0.6626137046386295]
	TIME [epoch: 10.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6127805353927027		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.6127805353927027 | validation: 0.4795881841148068]
	TIME [epoch: 10.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4752657486157791		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.4752657486157791 | validation: 0.606640678464118]
	TIME [epoch: 10.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49604343614389174		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.49604343614389174 | validation: 0.4811456955893341]
	TIME [epoch: 10.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5869666402090121		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.5869666402090121 | validation: 0.9691341563007865]
	TIME [epoch: 10.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232723002374511		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.7232723002374511 | validation: 0.530772317163803]
	TIME [epoch: 10.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749027555639011		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.5749027555639011 | validation: 0.49045049869599366]
	TIME [epoch: 10.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5075604165754257		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.5075604165754257 | validation: 0.6159560430204214]
	TIME [epoch: 10.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4913386257634939		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.4913386257634939 | validation: 0.7462875499789127]
	TIME [epoch: 10.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6129950411189691		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.6129950411189691 | validation: 0.5051803219921713]
	TIME [epoch: 10.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5617011988154996		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.5617011988154996 | validation: 0.6079369988724749]
	TIME [epoch: 10.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5482231828730229		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.5482231828730229 | validation: 0.5955920469162697]
	TIME [epoch: 10.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4896563343400978		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.4896563343400978 | validation: 0.5551333268899394]
	TIME [epoch: 10.2 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5561960587908914		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.5561960587908914 | validation: 0.7558815139257005]
	TIME [epoch: 10.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5789259785813186		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.5789259785813186 | validation: 1.0900367244511338]
	TIME [epoch: 10.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8027664231537456		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.8027664231537456 | validation: 0.560001700887526]
	TIME [epoch: 10.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4444359019762444		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.4444359019762444 | validation: 0.7988032972083898]
	TIME [epoch: 10.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.712008747652578		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.712008747652578 | validation: 0.6896041371960564]
	TIME [epoch: 10.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6688171312736712		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.6688171312736712 | validation: 0.6986645120178011]
	TIME [epoch: 10.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6020534376462077		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.6020534376462077 | validation: 0.5464415490474366]
	TIME [epoch: 10.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49216854664786175		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.49216854664786175 | validation: 0.4293597690573552]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.684506859009626		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.684506859009626 | validation: 1.881974974180177]
	TIME [epoch: 10.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2126022840066604		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 1.2126022840066604 | validation: 0.6444204866560432]
	TIME [epoch: 10.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42424847935718635		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.42424847935718635 | validation: 0.5963833639437459]
	TIME [epoch: 10.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6219371858660321		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.6219371858660321 | validation: 0.4165119997462883]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44511234105255576		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.44511234105255576 | validation: 0.4102355841310103]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5654106431761071		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.5654106431761071 | validation: 0.44698362909468414]
	TIME [epoch: 10.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.679056620960567		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.679056620960567 | validation: 0.5368267596306309]
	TIME [epoch: 10.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5338623081667455		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.5338623081667455 | validation: 0.5753882926601384]
	TIME [epoch: 10.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277299038329591		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.6277299038329591 | validation: 0.6278316297049847]
	TIME [epoch: 10.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.674273593083811		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.674273593083811 | validation: 0.48649717596873787]
	TIME [epoch: 10.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5633470032837649		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.5633470032837649 | validation: 0.5372991215441595]
	TIME [epoch: 10.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.465658371169995		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.465658371169995 | validation: 0.6137753090206164]
	TIME [epoch: 10.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5988446594169367		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.5988446594169367 | validation: 0.49959895707034807]
	TIME [epoch: 10.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4525841195691697		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.4525841195691697 | validation: 0.49977983925174735]
	TIME [epoch: 10.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5302812904039877		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.5302812904039877 | validation: 0.5010506084531268]
	TIME [epoch: 10.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42624747826877885		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.42624747826877885 | validation: 0.4809816645609202]
	TIME [epoch: 10.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5635455893391259		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.5635455893391259 | validation: 0.49744050870551504]
	TIME [epoch: 10.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44853585085622216		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.44853585085622216 | validation: 0.7343857876037823]
	TIME [epoch: 10.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8538392535098621		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.8538392535098621 | validation: 0.6447197830639686]
	TIME [epoch: 10.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840114105685769		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.5840114105685769 | validation: 0.44531627208838176]
	TIME [epoch: 10.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4274397928066357		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.4274397928066357 | validation: 0.9276824367271863]
	TIME [epoch: 10.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6965119458364356		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.6965119458364356 | validation: 0.4310346202047821]
	TIME [epoch: 10.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5904471240842419		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.5904471240842419 | validation: 0.563481121073675]
	TIME [epoch: 10.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5695799650992376		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.5695799650992376 | validation: 0.7857112034963334]
	TIME [epoch: 10.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7003944601587169		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.7003944601587169 | validation: 0.5665364868767806]
	TIME [epoch: 10.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7434973675549065		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.7434973675549065 | validation: 0.8419502866794366]
	TIME [epoch: 10.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5754434473057104		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.5754434473057104 | validation: 0.44273143127522474]
	TIME [epoch: 10.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49738056129274266		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.49738056129274266 | validation: 0.5603204467070849]
	TIME [epoch: 10.2 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4731500879218782		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.4731500879218782 | validation: 0.49475608092989726]
	TIME [epoch: 10.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4449536106664011		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.4449536106664011 | validation: 0.8402923553507935]
	TIME [epoch: 10.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6547970498506851		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.6547970498506851 | validation: 0.8727430882410258]
	TIME [epoch: 10.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6684149404088329		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.6684149404088329 | validation: 0.528875506898163]
	TIME [epoch: 10.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5020456054820869		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.5020456054820869 | validation: 0.5004027490991139]
	TIME [epoch: 10.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48054557532451386		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.48054557532451386 | validation: 0.6412874756148509]
	TIME [epoch: 10.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5380050747993751		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.5380050747993751 | validation: 0.9766809925219075]
	TIME [epoch: 10.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6930081383278226		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.6930081383278226 | validation: 0.498803102798998]
	TIME [epoch: 10.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5971244827061796		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.5971244827061796 | validation: 0.8070346700042909]
	TIME [epoch: 10.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5686603725507092		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.5686603725507092 | validation: 0.6412754804897077]
	TIME [epoch: 10.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6910740214243639		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.6910740214243639 | validation: 0.7265183456027146]
	TIME [epoch: 10.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5152487575798483		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.5152487575798483 | validation: 1.2150134665261088]
	TIME [epoch: 10.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8417893381305002		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.8417893381305002 | validation: 0.6486325455247214]
	TIME [epoch: 10.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8519659937918134		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.8519659937918134 | validation: 0.8361080166299829]
	TIME [epoch: 10.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5795380277485663		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.5795380277485663 | validation: 0.4825243834744007]
	TIME [epoch: 10.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390750943537411		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.6390750943537411 | validation: 0.8427994383357512]
	TIME [epoch: 10.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351186329977315		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.6351186329977315 | validation: 0.8809011016904609]
	TIME [epoch: 10.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7100817794775097		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.7100817794775097 | validation: 0.7212836053833648]
	TIME [epoch: 10.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5717746687637644		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.5717746687637644 | validation: 0.4759083904882223]
	TIME [epoch: 10.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44440897370298416		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.44440897370298416 | validation: 0.6058549135879117]
	TIME [epoch: 10.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5480152645474348		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.5480152645474348 | validation: 1.0502062029144485]
	TIME [epoch: 10.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8664678975495054		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.8664678975495054 | validation: 0.5609310822090622]
	TIME [epoch: 10.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6027907797477259		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.6027907797477259 | validation: 0.7387481372246295]
	TIME [epoch: 10.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6815131454720115		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.6815131454720115 | validation: 0.8886182968219218]
	TIME [epoch: 10.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8172692077843188		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.8172692077843188 | validation: 0.9434047713262017]
	TIME [epoch: 10.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6631326108110446		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.6631326108110446 | validation: 0.6078602306459224]
	TIME [epoch: 10.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6537396750698248		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.6537396750698248 | validation: 0.5142810965425844]
	TIME [epoch: 10.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6072868935331696		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.6072868935331696 | validation: 0.7678951157078353]
	TIME [epoch: 10.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6166460475669584		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.6166460475669584 | validation: 0.5633749527742532]
	TIME [epoch: 10.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.982170451406469		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.982170451406469 | validation: 0.6363634276754718]
	TIME [epoch: 10.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4856480315835318		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.4856480315835318 | validation: 0.6798116021063164]
	TIME [epoch: 10.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5101416810614423		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.5101416810614423 | validation: 0.4884973924403927]
	TIME [epoch: 10.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411828501275908		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.6411828501275908 | validation: 0.530143193865246]
	TIME [epoch: 10.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5422664884561608		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.5422664884561608 | validation: 0.5686537475024227]
	TIME [epoch: 10.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7348437437049606		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.7348437437049606 | validation: 0.5557176578232094]
	TIME [epoch: 10.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6438799216924802		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.6438799216924802 | validation: 0.791180462678156]
	TIME [epoch: 10.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5993291412880246		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.5993291412880246 | validation: 0.4656370449223212]
	TIME [epoch: 10.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4990447416200678		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.4990447416200678 | validation: 0.6361457615112792]
	TIME [epoch: 10.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340077686180021		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.5340077686180021 | validation: 0.6256505732560996]
	TIME [epoch: 10.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399699083139924		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.5399699083139924 | validation: 0.7728621375916462]
	TIME [epoch: 10.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6258547946391676		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.6258547946391676 | validation: 0.6410152030086342]
	TIME [epoch: 10.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5464318783724993		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.5464318783724993 | validation: 0.7632510306887619]
	TIME [epoch: 10.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6138281783490012		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 1.6138281783490012 | validation: 0.7577256152892657]
	TIME [epoch: 10.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7068191781983314		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.7068191781983314 | validation: 0.8606153835555685]
	TIME [epoch: 10.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5987625082282404		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.5987625082282404 | validation: 0.5376677292915815]
	TIME [epoch: 10.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49692220365481826		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.49692220365481826 | validation: 0.49072198470062695]
	TIME [epoch: 10.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5393646486985781		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.5393646486985781 | validation: 0.6467422093662936]
	TIME [epoch: 10.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200501376855863		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.6200501376855863 | validation: 0.7484108237840096]
	TIME [epoch: 10.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6339873185393092		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.6339873185393092 | validation: 0.6677533900639032]
	TIME [epoch: 10.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5325097306718403		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.5325097306718403 | validation: 0.717671298675304]
	TIME [epoch: 10.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.729982999960504		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.729982999960504 | validation: 0.7328661423585147]
	TIME [epoch: 10.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6371622719615504		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.6371622719615504 | validation: 0.778220968852954]
	TIME [epoch: 10.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.586962119438109		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.586962119438109 | validation: 0.6551564154043178]
	TIME [epoch: 10.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6225414318946946		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.6225414318946946 | validation: 0.7002079585829045]
	TIME [epoch: 10.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322365403077641		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.5322365403077641 | validation: 0.6289054034638563]
	TIME [epoch: 10.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263949365851373		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.5263949365851373 | validation: 0.6090142800111542]
	TIME [epoch: 10.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6927248183448024		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.6927248183448024 | validation: 0.806279641503431]
	TIME [epoch: 10.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5873970677683505		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.5873970677683505 | validation: 0.5968548558414071]
	TIME [epoch: 10.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520106342469584		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.5520106342469584 | validation: 0.5542186022008785]
	TIME [epoch: 10.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6112595097107374		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.6112595097107374 | validation: 0.6365867677709849]
	TIME [epoch: 10.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5179999173880048		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.5179999173880048 | validation: 0.6608076370118603]
	TIME [epoch: 10.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616842901333298		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.4616842901333298 | validation: 0.4504444717883138]
	TIME [epoch: 14.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48750942297163774		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.48750942297163774 | validation: 0.4767440163988118]
	TIME [epoch: 10.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4818618228014386		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.4818618228014386 | validation: 0.6689940801780927]
	TIME [epoch: 10.2 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49105154308573		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.49105154308573 | validation: 0.5149783924613167]
	TIME [epoch: 10.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47335237988131273		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.47335237988131273 | validation: 0.561888524462376]
	TIME [epoch: 10.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5092998492996099		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.5092998492996099 | validation: 0.6052653634865326]
	TIME [epoch: 10.2 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44994120242286784		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.44994120242286784 | validation: 0.568495712964163]
	TIME [epoch: 10.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.526509092835981		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.526509092835981 | validation: 0.5544256371869305]
	TIME [epoch: 10.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4963678402189494		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.4963678402189494 | validation: 0.6103523643365454]
	TIME [epoch: 10.2 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5582438871581019		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.5582438871581019 | validation: 0.5584718359414916]
	TIME [epoch: 10.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49068978154089454		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.49068978154089454 | validation: 0.5500139679368392]
	TIME [epoch: 10.2 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6028134910110922		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.6028134910110922 | validation: 0.8183611154318291]
	TIME [epoch: 10.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8331480208876911		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.8331480208876911 | validation: 0.6797038811446439]
	TIME [epoch: 10.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5959469363748625		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.5959469363748625 | validation: 0.6133427665433783]
	TIME [epoch: 10.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6103837698938929		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.6103837698938929 | validation: 0.6620378252543941]
	TIME [epoch: 10.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6698038956022533		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.6698038956022533 | validation: 0.6873308151043267]
	TIME [epoch: 10.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5804306254016545		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.5804306254016545 | validation: 0.5963819918478597]
	TIME [epoch: 10.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197641953422596		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.5197641953422596 | validation: 0.6747280262643386]
	TIME [epoch: 10.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5733495653876454		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.5733495653876454 | validation: 0.5498632641811451]
	TIME [epoch: 10.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5675456535456613		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.5675456535456613 | validation: 0.5768675794154053]
	TIME [epoch: 10.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182041737892602		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.5182041737892602 | validation: 0.8036877274970471]
	TIME [epoch: 10.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6122234504080082		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.6122234504080082 | validation: 0.670154674733788]
	TIME [epoch: 10.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7309533131911566		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.7309533131911566 | validation: 0.5600409316906905]
	TIME [epoch: 10.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5823828622483427		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.5823828622483427 | validation: 0.5964832548602946]
	TIME [epoch: 10.2 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5415959402743531		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.5415959402743531 | validation: 0.6583501232570166]
	TIME [epoch: 10.2 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6584808721664717		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.6584808721664717 | validation: 0.7415917872709392]
	TIME [epoch: 10.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5802086823796824		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.5802086823796824 | validation: 0.6347930440222499]
	TIME [epoch: 10.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6098342554527011		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.6098342554527011 | validation: 0.6839544048805462]
	TIME [epoch: 10.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025649410659558		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.7025649410659558 | validation: 0.6757201529985527]
	TIME [epoch: 10.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7535759648216966		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.7535759648216966 | validation: 1.1756033289374836]
	TIME [epoch: 10.2 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8018365439838411		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.8018365439838411 | validation: 0.6475861486895375]
	TIME [epoch: 10.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259581904543001		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.5259581904543001 | validation: 0.5860744682974203]
	TIME [epoch: 10.2 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7413269198496271		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.7413269198496271 | validation: 0.739898959296991]
	TIME [epoch: 10.2 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9935397712837739		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.9935397712837739 | validation: 0.7381098222260235]
	TIME [epoch: 10.2 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5331640360223199		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.5331640360223199 | validation: 0.6448654356529996]
	TIME [epoch: 10.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7284908069773957		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.7284908069773957 | validation: 1.3801990807388893]
	TIME [epoch: 10.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8828470440700098		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.8828470440700098 | validation: 0.8550103721030738]
	TIME [epoch: 10.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232062514204318		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.7232062514204318 | validation: 0.5240297520146258]
	TIME [epoch: 10.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46653934527056273		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.46653934527056273 | validation: 0.5282052139271888]
	TIME [epoch: 10.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6592742723331356		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.6592742723331356 | validation: 0.7153730841134484]
	TIME [epoch: 10.2 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5629051708056807		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.5629051708056807 | validation: 0.5907119652188288]
	TIME [epoch: 10.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5492627302818567		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.5492627302818567 | validation: 0.5968129716657926]
	TIME [epoch: 10.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5148073414659816		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.5148073414659816 | validation: 0.5441014919756593]
	TIME [epoch: 10.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5573353472213769		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.5573353472213769 | validation: 0.5880854952614799]
	TIME [epoch: 10.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.566148477806222		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.566148477806222 | validation: 0.7411379626456843]
	TIME [epoch: 10.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024738939987013		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.6024738939987013 | validation: 0.6526904733377162]
	TIME [epoch: 10.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5292456584475452		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.5292456584475452 | validation: 0.5885091617708805]
	TIME [epoch: 10.2 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.525278605289461		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.525278605289461 | validation: 0.7490535130131397]
	TIME [epoch: 10.2 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452893736229317		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.5452893736229317 | validation: 0.5079441328452644]
	TIME [epoch: 10.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5511751740585482		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.5511751740585482 | validation: 0.5374443929603396]
	TIME [epoch: 10.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5112239032472362		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.5112239032472362 | validation: 0.7637473209032227]
	TIME [epoch: 10.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5799087429801013		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.5799087429801013 | validation: 0.6336668047547364]
	TIME [epoch: 10.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233195316395238		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.5233195316395238 | validation: 0.4050156558045601]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4019965576179828		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.4019965576179828 | validation: 0.39342273649481563]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37767575050664765		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.37767575050664765 | validation: 0.5354544575403385]
	TIME [epoch: 10.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41501769082549156		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.41501769082549156 | validation: 0.4900782622635355]
	TIME [epoch: 10.2 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.627710123471708		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.627710123471708 | validation: 0.5018212433583793]
	TIME [epoch: 10.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5204416397263252		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.5204416397263252 | validation: 0.6520172834789857]
	TIME [epoch: 10.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.193546661655405		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 1.193546661655405 | validation: 0.5442934883633724]
	TIME [epoch: 10.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5083041824289178		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.5083041824289178 | validation: 0.6388337636356088]
	TIME [epoch: 10.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7733659412168069		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.7733659412168069 | validation: 0.6859110552979596]
	TIME [epoch: 10.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5363427002367861		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.5363427002367861 | validation: 0.5205196502829231]
	TIME [epoch: 10.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6091960377836516		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.6091960377836516 | validation: 0.786649610371816]
	TIME [epoch: 10.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5533094865274142		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.5533094865274142 | validation: 0.571721542860119]
	TIME [epoch: 10.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.640568171576735		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.640568171576735 | validation: 0.590376164040007]
	TIME [epoch: 10.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6621886102578709		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.6621886102578709 | validation: 1.0631569267494274]
	TIME [epoch: 10.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7006685831304803		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.7006685831304803 | validation: 0.5385114108423347]
	TIME [epoch: 10.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.695838741703404		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.695838741703404 | validation: 1.0601989890057184]
	TIME [epoch: 10.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.313808217658157		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 1.313808217658157 | validation: 1.0810632720849498]
	TIME [epoch: 10.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9298014824140669		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.9298014824140669 | validation: 0.7343554097898162]
	TIME [epoch: 10.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6746625020649732		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.6746625020649732 | validation: 0.5024488062087833]
	TIME [epoch: 10.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49496190836502435		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.49496190836502435 | validation: 0.5836414730053486]
	TIME [epoch: 10.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2990562071181957		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 1.2990562071181957 | validation: 0.6911438022196711]
	TIME [epoch: 10.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7185657086881507		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.7185657086881507 | validation: 0.614586527653696]
	TIME [epoch: 10.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7116844238046109		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.7116844238046109 | validation: 0.734386871633647]
	TIME [epoch: 10.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6442866323772923		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.6442866323772923 | validation: 0.7902805112221094]
	TIME [epoch: 10.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6199663066931921		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.6199663066931921 | validation: 0.5959452124662087]
	TIME [epoch: 10.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5775259200125406		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.5775259200125406 | validation: 0.5543359371779618]
	TIME [epoch: 10.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5712410711887358		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.5712410711887358 | validation: 0.6586926053385264]
	TIME [epoch: 10.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5690877906936633		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.5690877906936633 | validation: 0.564314746201416]
	TIME [epoch: 10.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7787386930349924		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.7787386930349924 | validation: 0.651770919206701]
	TIME [epoch: 10.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5184542079613778		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.5184542079613778 | validation: 0.5830981256278236]
	TIME [epoch: 10.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.456927006515201		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.456927006515201 | validation: 0.536267307958593]
	TIME [epoch: 10.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5881210615254517		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.5881210615254517 | validation: 0.6507810812272087]
	TIME [epoch: 10.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5582684208505808		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.5582684208505808 | validation: 0.5037781106903572]
	TIME [epoch: 10.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6809888629308171		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.6809888629308171 | validation: 0.9779569872669457]
	TIME [epoch: 10.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7736288322839509		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.7736288322839509 | validation: 0.600128899742929]
	TIME [epoch: 10.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161129304421752		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.5161129304421752 | validation: 0.5495806855435481]
	TIME [epoch: 10.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645556808314297		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.6645556808314297 | validation: 0.6308343307344549]
	TIME [epoch: 10.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4964043290934999		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.4964043290934999 | validation: 0.6340781959421408]
	TIME [epoch: 10.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347471990366912		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.6347471990366912 | validation: 0.5234420859363492]
	TIME [epoch: 10.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5007204383858144		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.5007204383858144 | validation: 0.5650657250339117]
	TIME [epoch: 10.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7724676652157219		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.7724676652157219 | validation: 1.1847384217526342]
	TIME [epoch: 10.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7720293785736536		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.7720293785736536 | validation: 0.49688282343371415]
	TIME [epoch: 10.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39873909357201504		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.39873909357201504 | validation: 0.5657779329023808]
	TIME [epoch: 10.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5800485548218328		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.5800485548218328 | validation: 0.7222399118823799]
	TIME [epoch: 10.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5047533034892282		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.5047533034892282 | validation: 0.5835980202373391]
	TIME [epoch: 10.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5018800398138201		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.5018800398138201 | validation: 0.50321270091245]
	TIME [epoch: 10.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.425999748061974		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.425999748061974 | validation: 0.5238586187507492]
	TIME [epoch: 10.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4028718613705219		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.4028718613705219 | validation: 0.5692807707706953]
	TIME [epoch: 10.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4898568041570268		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.4898568041570268 | validation: 0.6133806617309888]
	TIME [epoch: 10.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4841113942662373		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.4841113942662373 | validation: 0.7682926229985598]
	TIME [epoch: 10.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8044133058830507		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.8044133058830507 | validation: 0.9977099685779185]
	TIME [epoch: 10.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7183535009628372		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.7183535009628372 | validation: 0.49186473026585786]
	TIME [epoch: 10.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5176230621384676		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.5176230621384676 | validation: 0.538449750531951]
	TIME [epoch: 10.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6163720434528959		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.6163720434528959 | validation: 0.44444619209007796]
	TIME [epoch: 10.2 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41197269793519453		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.41197269793519453 | validation: 0.6566912952331315]
	TIME [epoch: 10.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4729199452736202		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.4729199452736202 | validation: 0.525679202957466]
	TIME [epoch: 10.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.469537664456493		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.469537664456493 | validation: 0.528445498938461]
	TIME [epoch: 10.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5160228326909796		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.5160228326909796 | validation: 0.5920412192133754]
	TIME [epoch: 10.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5816681352603645		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.5816681352603645 | validation: 0.4636758965711142]
	TIME [epoch: 10.2 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4428173378010877		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.4428173378010877 | validation: 0.6654362307916867]
	TIME [epoch: 10.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4785671140065751		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.4785671140065751 | validation: 0.6731687177121168]
	TIME [epoch: 10.2 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.492830947743906		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.492830947743906 | validation: 0.542138942020071]
	TIME [epoch: 10.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44158198099403745		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.44158198099403745 | validation: 0.5158434768318807]
	TIME [epoch: 10.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4702219719871448		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.4702219719871448 | validation: 0.5580311212517832]
	TIME [epoch: 10.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6182769381516134		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.6182769381516134 | validation: 0.7186291709173372]
	TIME [epoch: 10.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5092063745688384		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.5092063745688384 | validation: 0.5521699941117046]
	TIME [epoch: 10.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.568598791159346		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.568598791159346 | validation: 0.4909226728564571]
	TIME [epoch: 10.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5292107865954454		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.5292107865954454 | validation: 0.5023732974661549]
	TIME [epoch: 10.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278507380612834		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.5278507380612834 | validation: 0.6257827343714777]
	TIME [epoch: 10.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44451804462465905		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.44451804462465905 | validation: 0.5445884807540131]
	TIME [epoch: 10.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7053982556593743		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.7053982556593743 | validation: 0.5103801598830872]
	TIME [epoch: 10.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4022912381363738		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.4022912381363738 | validation: 0.46090566569566505]
	TIME [epoch: 10.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5106146981581248		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.5106146981581248 | validation: 0.6043332448098572]
	TIME [epoch: 10.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6019598433017239		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.6019598433017239 | validation: 0.6004923541041813]
	TIME [epoch: 10.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5165839902799665		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.5165839902799665 | validation: 0.6719007565540329]
	TIME [epoch: 10.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5142120327834082		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.5142120327834082 | validation: 0.44839372370053426]
	TIME [epoch: 10.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45521029908336297		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.45521029908336297 | validation: 0.48184145012268886]
	TIME [epoch: 10.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5067737313668648		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.5067737313668648 | validation: 0.7831224406081809]
	TIME [epoch: 10.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8081365040096546		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.8081365040096546 | validation: 0.9937383818063701]
	TIME [epoch: 10.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8616594574427612		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.8616594574427612 | validation: 0.46025289091746696]
	TIME [epoch: 10.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44103980958014277		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.44103980958014277 | validation: 0.7083348061096075]
	TIME [epoch: 10.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085927444124783		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.5085927444124783 | validation: 0.5553541260806611]
	TIME [epoch: 10.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49162278440446433		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.49162278440446433 | validation: 0.5160129275571597]
	TIME [epoch: 10.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194955816291259		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.5194955816291259 | validation: 0.5517361142899057]
	TIME [epoch: 10.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308752036814586		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.5308752036814586 | validation: 0.6556285885061659]
	TIME [epoch: 10.2 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.044235773247415		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 1.044235773247415 | validation: 0.6589633797629726]
	TIME [epoch: 10.2 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5459679488624964		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.5459679488624964 | validation: 0.40821160223074715]
	TIME [epoch: 10.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4507911555361123		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.4507911555361123 | validation: 0.47319073981177057]
	TIME [epoch: 10.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46404759007415813		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.46404759007415813 | validation: 0.6497331076658809]
	TIME [epoch: 10.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6224165239783861		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.6224165239783861 | validation: 0.9295484587668199]
	TIME [epoch: 10.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784856613546		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.6784856613546 | validation: 0.7409351242487392]
	TIME [epoch: 10.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8378990766832114		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.8378990766832114 | validation: 0.6889892475472553]
	TIME [epoch: 10.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6444016141641151		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.6444016141641151 | validation: 0.6715291790574429]
	TIME [epoch: 10.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6719249166386245		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.6719249166386245 | validation: 0.7204668424654496]
	TIME [epoch: 10.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5353236033401831		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.5353236033401831 | validation: 0.5823598579488702]
	TIME [epoch: 10.2 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6174283775634654		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.6174283775634654 | validation: 0.6733964823414516]
	TIME [epoch: 10.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5641111193651467		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.5641111193651467 | validation: 0.6734613683048424]
	TIME [epoch: 10.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8851348512649743		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.8851348512649743 | validation: 0.8155793442018291]
	TIME [epoch: 10.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552677476197497		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.5552677476197497 | validation: 0.5336142382888468]
	TIME [epoch: 10.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5701466002465765		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.5701466002465765 | validation: 0.5148594746928589]
	TIME [epoch: 10.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41187605908814595		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.41187605908814595 | validation: 0.4386878722319791]
	TIME [epoch: 10.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178781438984047		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.4178781438984047 | validation: 0.5574945329474934]
	TIME [epoch: 10.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4964865420162375		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.4964865420162375 | validation: 0.6736621137423657]
	TIME [epoch: 10.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213063149736493		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.5213063149736493 | validation: 0.513822620206305]
	TIME [epoch: 10.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9096329874049071		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.9096329874049071 | validation: 1.2763684524840941]
	TIME [epoch: 10.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8936174860736912		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.8936174860736912 | validation: 0.4619500439121339]
	TIME [epoch: 10.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42345663324212063		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.42345663324212063 | validation: 0.5862340118998383]
	TIME [epoch: 10.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42482662839892543		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.42482662839892543 | validation: 0.4290551559726654]
	TIME [epoch: 10.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4524800488497487		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.4524800488497487 | validation: 0.4987076609013812]
	TIME [epoch: 10.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42793296135782183		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.42793296135782183 | validation: 0.45452218115932597]
	TIME [epoch: 10.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4215518459443034		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.4215518459443034 | validation: 0.46779970848370284]
	TIME [epoch: 10.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42147215263411064		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.42147215263411064 | validation: 0.5067358064467581]
	TIME [epoch: 10.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5015750475131431		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.5015750475131431 | validation: 0.6024180313340877]
	TIME [epoch: 10.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3951785444629993		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.3951785444629993 | validation: 0.4210952028289907]
	TIME [epoch: 10.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40593874791161316		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.40593874791161316 | validation: 0.5056790693080275]
	TIME [epoch: 10.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5002074842846096		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.5002074842846096 | validation: 0.44692600408008093]
	TIME [epoch: 10.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3517831073767771		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.3517831073767771 | validation: 0.4784373018578064]
	TIME [epoch: 10.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6162816270958731		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.6162816270958731 | validation: 0.5714261986950718]
	TIME [epoch: 10.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5963776670409695		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.5963776670409695 | validation: 0.6023805910550063]
	TIME [epoch: 10.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45340231738322584		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.45340231738322584 | validation: 0.45804977749542863]
	TIME [epoch: 10.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4311720078607035		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.4311720078607035 | validation: 0.49557125024514903]
	TIME [epoch: 10.2 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38619891299469034		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.38619891299469034 | validation: 0.41832836272209906]
	TIME [epoch: 10.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4242867126849287		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.4242867126849287 | validation: 0.5626936134337958]
	TIME [epoch: 10.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6005481359061237		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.6005481359061237 | validation: 0.5422037149197592]
	TIME [epoch: 10.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5016956164832862		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.5016956164832862 | validation: 0.4731413355844555]
	TIME [epoch: 10.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3984877730387134		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.3984877730387134 | validation: 0.5309714285687731]
	TIME [epoch: 10.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949385963377781		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.3949385963377781 | validation: 0.5232437078483035]
	TIME [epoch: 10.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37402475803984164		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.37402475803984164 | validation: 0.3586070051395272]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_770.pth
	Model improved!!!
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5655915165470083		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.5655915165470083 | validation: 0.4904567565128287]
	TIME [epoch: 10.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5959576689237716		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.5959576689237716 | validation: 0.42466381269876363]
	TIME [epoch: 10.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3588225125248681		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.3588225125248681 | validation: 0.47070493673446834]
	TIME [epoch: 10.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40668875439219104		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.40668875439219104 | validation: 0.5537094280409371]
	TIME [epoch: 10.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5195409660842226		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.5195409660842226 | validation: 0.4681789011043821]
	TIME [epoch: 10.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4138523145589483		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.4138523145589483 | validation: 0.509764941337765]
	TIME [epoch: 10.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308466672714623		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.6308466672714623 | validation: 0.6795217530433861]
	TIME [epoch: 10.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6602313589376829		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.6602313589376829 | validation: 0.474689649802137]
	TIME [epoch: 10.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5081924074820683		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.5081924074820683 | validation: 0.6819606483441271]
	TIME [epoch: 10.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7363261078637247		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.7363261078637247 | validation: 0.6844540333595842]
	TIME [epoch: 10.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5888088159638141		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.5888088159638141 | validation: 0.4081121544022386]
	TIME [epoch: 10.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6553604822524306		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.6553604822524306 | validation: 0.7435693378307812]
	TIME [epoch: 10.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7503102223683851		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.7503102223683851 | validation: 0.6147713575599779]
	TIME [epoch: 10.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254144041906955		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.5254144041906955 | validation: 0.5618136172140646]
	TIME [epoch: 10.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48291721491968326		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.48291721491968326 | validation: 0.37989296279532647]
	TIME [epoch: 10.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42571389359542106		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.42571389359542106 | validation: 0.480813386015418]
	TIME [epoch: 10.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4110974896094273		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.4110974896094273 | validation: 0.6491224168137437]
	TIME [epoch: 10.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5556908573242016		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.5556908573242016 | validation: 0.6772107892195932]
	TIME [epoch: 10.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4299521420867146		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.4299521420867146 | validation: 0.4056961700049607]
	TIME [epoch: 10.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3589689610372897		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.3589689610372897 | validation: 0.3969257619609978]
	TIME [epoch: 10.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085057441580073		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.5085057441580073 | validation: 0.5635279386133555]
	TIME [epoch: 10.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4004043072460052		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.4004043072460052 | validation: 0.4445452093867001]
	TIME [epoch: 10.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5989624740338904		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.5989624740338904 | validation: 0.6068004077790284]
	TIME [epoch: 10.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6165923941513641		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.6165923941513641 | validation: 0.4975246280239208]
	TIME [epoch: 10.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6411326314709872		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.6411326314709872 | validation: 0.5254711741570247]
	TIME [epoch: 10.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4463538998737566		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.4463538998737566 | validation: 0.4409046724522727]
	TIME [epoch: 10.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.324174062352505		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.324174062352505 | validation: 0.412645714259663]
	TIME [epoch: 10.2 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39214406326967793		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.39214406326967793 | validation: 0.3904368262427707]
	TIME [epoch: 10.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4687780907537885		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.4687780907537885 | validation: 0.643149431800826]
	TIME [epoch: 10.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243738671427304		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.5243738671427304 | validation: 0.4929815479759795]
	TIME [epoch: 10.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6082001591577963		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.6082001591577963 | validation: 0.5295431464644357]
	TIME [epoch: 10.2 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4591196824284923		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.4591196824284923 | validation: 0.699601462716618]
	TIME [epoch: 10.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426332571691179		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.5426332571691179 | validation: 0.6421868942613875]
	TIME [epoch: 10.2 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164129406874152		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.5164129406874152 | validation: 0.707512703048031]
	TIME [epoch: 10.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5874786801406707		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.5874786801406707 | validation: 0.5060391433265464]
	TIME [epoch: 10.2 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4871311631552411		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.4871311631552411 | validation: 0.4615709537639562]
	TIME [epoch: 10.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3784672743879954		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.3784672743879954 | validation: 0.3798132646782333]
	TIME [epoch: 10.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39687622700941716		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.39687622700941716 | validation: 0.4417814935311817]
	TIME [epoch: 10.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4144384384101386		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.4144384384101386 | validation: 0.3943382437128355]
	TIME [epoch: 10.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3773294635514878		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.3773294635514878 | validation: 0.35912794626797195]
	TIME [epoch: 10.2 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37263848839563957		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.37263848839563957 | validation: 0.5019721083198976]
	TIME [epoch: 10.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4369207845310569		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.4369207845310569 | validation: 0.46655724778435087]
	TIME [epoch: 10.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36348944395362887		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.36348944395362887 | validation: 0.3740616108493322]
	TIME [epoch: 10.2 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255676373036102		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.5255676373036102 | validation: 0.43799188928671884]
	TIME [epoch: 10.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3339592908046155		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.3339592908046155 | validation: 0.43580289915777026]
	TIME [epoch: 10.2 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46209659246518864		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.46209659246518864 | validation: 0.4469485159312505]
	TIME [epoch: 10.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41898251160278904		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.41898251160278904 | validation: 0.41965838229591357]
	TIME [epoch: 10.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33540584608002744		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.33540584608002744 | validation: 0.43873092793393426]
	TIME [epoch: 10.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36619072516522805		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.36619072516522805 | validation: 0.3650842343032407]
	TIME [epoch: 10.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3525915877859024		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.3525915877859024 | validation: 0.44812883322815905]
	TIME [epoch: 10.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4779617626727587		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.4779617626727587 | validation: 0.6646223323726471]
	TIME [epoch: 10.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39615459062570413		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.39615459062570413 | validation: 0.43721558540115263]
	TIME [epoch: 10.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6831817495948692		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.6831817495948692 | validation: 0.41506632187101067]
	TIME [epoch: 10.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36660047414169106		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.36660047414169106 | validation: 0.4525442989715927]
	TIME [epoch: 10.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3346268281778563		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.3346268281778563 | validation: 0.4764945826780818]
	TIME [epoch: 10.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42999213155063043		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.42999213155063043 | validation: 0.49201040493938036]
	TIME [epoch: 10.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4840473328365945		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.4840473328365945 | validation: 0.6273329261959202]
	TIME [epoch: 10.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4849477989392346		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.4849477989392346 | validation: 0.6103860924138679]
	TIME [epoch: 10.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4261779329504912		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.4261779329504912 | validation: 0.5127853588699389]
	TIME [epoch: 10.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5495904308310013		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.5495904308310013 | validation: 0.47329106839914203]
	TIME [epoch: 10.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38215238804711904		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.38215238804711904 | validation: 0.5246728945857139]
	TIME [epoch: 10.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6329484790210484		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.6329484790210484 | validation: 0.5302928957605731]
	TIME [epoch: 10.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5595770956455703		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.5595770956455703 | validation: 0.7071999392110866]
	TIME [epoch: 10.2 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6228166605310823		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.6228166605310823 | validation: 0.49238495882592476]
	TIME [epoch: 10.2 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3901151351984721		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.3901151351984721 | validation: 0.5830773759786921]
	TIME [epoch: 10.2 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4689699311449941		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.4689699311449941 | validation: 0.5205309227315701]
	TIME [epoch: 10.2 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6909109766323842		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.6909109766323842 | validation: 0.47568644201083554]
	TIME [epoch: 10.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3742827365663629		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.3742827365663629 | validation: 0.41317898412650894]
	TIME [epoch: 10.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3159865771918125		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.3159865771918125 | validation: 0.4891503647817648]
	TIME [epoch: 10.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3700028433520785		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.3700028433520785 | validation: 0.6690669877701271]
	TIME [epoch: 10.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6539459149224858		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.6539459149224858 | validation: 0.4857306212215475]
	TIME [epoch: 10.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4744804354625935		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.4744804354625935 | validation: 0.4402048830994694]
	TIME [epoch: 10.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3810844947851008		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.3810844947851008 | validation: 0.5272652026566556]
	TIME [epoch: 10.2 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5993626767641348		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.5993626767641348 | validation: 0.4010302343063942]
	TIME [epoch: 10.2 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3918952336239044		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.3918952336239044 | validation: 0.6189317279050134]
	TIME [epoch: 10.2 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3903212602970173		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.3903212602970173 | validation: 0.3987557586693529]
	TIME [epoch: 10.2 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42915084222698663		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.42915084222698663 | validation: 0.8228039491499777]
	TIME [epoch: 10.2 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4883770624798981		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.4883770624798981 | validation: 0.39449019747612923]
	TIME [epoch: 10.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4631238132279331		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.4631238132279331 | validation: 0.5758457904656361]
	TIME [epoch: 10.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5334556135282451		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.5334556135282451 | validation: 0.5361045039934159]
	TIME [epoch: 10.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4459538177539614		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.4459538177539614 | validation: 0.482986223835745]
	TIME [epoch: 10.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3513832431284911		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.3513832431284911 | validation: 0.3836670869048133]
	TIME [epoch: 10.2 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34785074327814963		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.34785074327814963 | validation: 0.40286349448970965]
	TIME [epoch: 10.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.499717575328988		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.499717575328988 | validation: 0.4590287385733517]
	TIME [epoch: 10.2 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3702946705435289		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.3702946705435289 | validation: 0.4515626379499271]
	TIME [epoch: 10.2 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3363659178813566		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.3363659178813566 | validation: 0.4785042122747798]
	TIME [epoch: 10.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.366760462380818		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.366760462380818 | validation: 0.38606266930617755]
	TIME [epoch: 10.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3932802809617809		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.3932802809617809 | validation: 0.5255168987056061]
	TIME [epoch: 10.2 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45429628191806026		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.45429628191806026 | validation: 0.5221511865784738]
	TIME [epoch: 10.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5599027126177216		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.5599027126177216 | validation: 0.41012791688506756]
	TIME [epoch: 10.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42870571812188346		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.42870571812188346 | validation: 0.6141087884991734]
	TIME [epoch: 10.2 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4831994973962037		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.4831994973962037 | validation: 0.5200602978582203]
	TIME [epoch: 10.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4972939829523158		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.4972939829523158 | validation: 0.6457008149429473]
	TIME [epoch: 10.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5966005005708686		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.5966005005708686 | validation: 0.4598256912523084]
	TIME [epoch: 10.2 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977333503916721		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.3977333503916721 | validation: 0.40259819774683053]
	TIME [epoch: 10.2 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119918874538436		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.4119918874538436 | validation: 0.46032307451938265]
	TIME [epoch: 10.2 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5445825148119365		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.5445825148119365 | validation: 1.4436759776962054]
	TIME [epoch: 10.2 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0724231761132104		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 1.0724231761132104 | validation: 0.503269927769353]
	TIME [epoch: 10.2 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5097104309962452		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.5097104309962452 | validation: 0.5656473706499908]
	TIME [epoch: 10.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5240774396817293		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.5240774396817293 | validation: 0.4738142638873285]
	TIME [epoch: 10.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.447921223643034		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.447921223643034 | validation: 0.5197184820277376]
	TIME [epoch: 10.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4314438737328075		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.4314438737328075 | validation: 0.5587625372911829]
	TIME [epoch: 10.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6261142887421723		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.6261142887421723 | validation: 0.5420413362999407]
	TIME [epoch: 10.2 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210613354571932		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.4210613354571932 | validation: 0.42482906787005087]
	TIME [epoch: 10.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31656948445074223		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.31656948445074223 | validation: 0.4024268261152924]
	TIME [epoch: 10.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38106758529182977		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.38106758529182977 | validation: 0.45370036836748484]
	TIME [epoch: 10.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4704070028923086		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.4704070028923086 | validation: 0.533331147513393]
	TIME [epoch: 10.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4926490823315053		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.4926490823315053 | validation: 0.5259077528108047]
	TIME [epoch: 10.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4367613552285311		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.4367613552285311 | validation: 0.37805423684161166]
	TIME [epoch: 10.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34332077208025563		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.34332077208025563 | validation: 0.44210804172458906]
	TIME [epoch: 10.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36012445945632326		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.36012445945632326 | validation: 0.34191261503505843]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_881.pth
	Model improved!!!
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33221867388396914		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.33221867388396914 | validation: 0.4495928572771669]
	TIME [epoch: 10.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43420607549553286		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.43420607549553286 | validation: 0.5406150433038514]
	TIME [epoch: 10.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.484642812912054		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.484642812912054 | validation: 0.5212965079603413]
	TIME [epoch: 10.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43432938650665764		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.43432938650665764 | validation: 0.41611127698091877]
	TIME [epoch: 10.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3845458901634661		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.3845458901634661 | validation: 0.49976304159667906]
	TIME [epoch: 10.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46757541614757325		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.46757541614757325 | validation: 0.5661025024687022]
	TIME [epoch: 10.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.424390894440585		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.424390894440585 | validation: 0.4334245785170057]
	TIME [epoch: 10.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3528321985833376		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.3528321985833376 | validation: 0.3973615083587575]
	TIME [epoch: 10.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37484140251188347		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.37484140251188347 | validation: 0.4336215705324215]
	TIME [epoch: 10.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38573723341297034		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.38573723341297034 | validation: 0.5810720890513531]
	TIME [epoch: 10.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37122868858585695		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.37122868858585695 | validation: 0.3859430632193772]
	TIME [epoch: 10.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34062029302315905		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.34062029302315905 | validation: 0.4240236949337002]
	TIME [epoch: 10.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35475328142744333		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.35475328142744333 | validation: 0.6934741793340399]
	TIME [epoch: 10.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334205580141294		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.6334205580141294 | validation: 0.4071218473540166]
	TIME [epoch: 10.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4414312217189261		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.4414312217189261 | validation: 0.43569799532078113]
	TIME [epoch: 10.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35835678572438295		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.35835678572438295 | validation: 0.5403278731471868]
	TIME [epoch: 10.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3671320405397819		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.3671320405397819 | validation: 0.4432551274848754]
	TIME [epoch: 10.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38499976163325067		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.38499976163325067 | validation: 0.3988988116893634]
	TIME [epoch: 10.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36369133130829445		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.36369133130829445 | validation: 0.4036457224969857]
	TIME [epoch: 10.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33315924946413766		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.33315924946413766 | validation: 0.4655768881548574]
	TIME [epoch: 10.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3906306563410249		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.3906306563410249 | validation: 0.4064574117287867]
	TIME [epoch: 10.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2950746765605935		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.2950746765605935 | validation: 0.34775777691374843]
	TIME [epoch: 10.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31998367751718015		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.31998367751718015 | validation: 0.4805493740528015]
	TIME [epoch: 10.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4526584138405559		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.4526584138405559 | validation: 0.5440858303369313]
	TIME [epoch: 10.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41728115537869126		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.41728115537869126 | validation: 0.4620616987994553]
	TIME [epoch: 10.2 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37509582258448326		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.37509582258448326 | validation: 0.37761156161349296]
	TIME [epoch: 10.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3549986923310415		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.3549986923310415 | validation: 0.3723271077809565]
	TIME [epoch: 10.2 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3325456508355032		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.3325456508355032 | validation: 0.3985026875502761]
	TIME [epoch: 10.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3416318959129109		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.3416318959129109 | validation: 0.40747258341260556]
	TIME [epoch: 10.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4549394618696164		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.4549394618696164 | validation: 0.34908998576317773]
	TIME [epoch: 10.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40830659424873395		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.40830659424873395 | validation: 0.6245307350873937]
	TIME [epoch: 10.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4853956833704095		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.4853956833704095 | validation: 0.42794605990742923]
	TIME [epoch: 10.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35175440706684513		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.35175440706684513 | validation: 0.35514819374846285]
	TIME [epoch: 10.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3244322334699281		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.3244322334699281 | validation: 0.35219422444613313]
	TIME [epoch: 10.2 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.339698305768722		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.339698305768722 | validation: 0.404840195804652]
	TIME [epoch: 10.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44168439694635825		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.44168439694635825 | validation: 0.477056615662773]
	TIME [epoch: 10.2 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3797076250298767		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.3797076250298767 | validation: 0.3961324469127338]
	TIME [epoch: 10.2 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43041523842033413		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.43041523842033413 | validation: 0.550818148963906]
	TIME [epoch: 10.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4517893279727632		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.4517893279727632 | validation: 0.4270756368159478]
	TIME [epoch: 10.2 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3965669186677207		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.3965669186677207 | validation: 0.47629833078908285]
	TIME [epoch: 10.2 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3761376402567514		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.3761376402567514 | validation: 0.43062539256823346]
	TIME [epoch: 10.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33915021980612703		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.33915021980612703 | validation: 0.36165119248411914]
	TIME [epoch: 10.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420415517325679		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.3420415517325679 | validation: 0.5010298362961192]
	TIME [epoch: 10.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3699925032861643		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.3699925032861643 | validation: 0.4116887827805789]
	TIME [epoch: 10.2 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4243560065272002		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.4243560065272002 | validation: 0.5246764397074146]
	TIME [epoch: 10.2 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3780770904237024		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.3780770904237024 | validation: 0.44535070345145733]
	TIME [epoch: 10.2 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45499600787402394		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.45499600787402394 | validation: 0.4796641929650876]
	TIME [epoch: 10.2 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35560334341239325		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.35560334341239325 | validation: 0.4208543898366891]
	TIME [epoch: 10.2 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3997582582499266		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.3997582582499266 | validation: 0.548816802837498]
	TIME [epoch: 10.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45907391648561335		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.45907391648561335 | validation: 0.5206467836489975]
	TIME [epoch: 10.2 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4143382034268209		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.4143382034268209 | validation: 0.4277540316109716]
	TIME [epoch: 10.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3600723965717251		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.3600723965717251 | validation: 0.41317740475060116]
	TIME [epoch: 10.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32464656894455707		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.32464656894455707 | validation: 0.4287126972878889]
	TIME [epoch: 10.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3593581652779411		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.3593581652779411 | validation: 0.45656986594169874]
	TIME [epoch: 10.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3139721541875251		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.3139721541875251 | validation: 0.4027825823769258]
	TIME [epoch: 10.2 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3117503137049021		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.3117503137049021 | validation: 0.4140039103237633]
	TIME [epoch: 10.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2912529875835005		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.2912529875835005 | validation: 0.35998435394350425]
	TIME [epoch: 10.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2943115321984092		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.2943115321984092 | validation: 0.46682716320228795]
	TIME [epoch: 10.2 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36937610690294337		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.36937610690294337 | validation: 0.5256772810923515]
	TIME [epoch: 10.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35703368009645875		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.35703368009645875 | validation: 0.4040146312681534]
	TIME [epoch: 10.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3391693365367116		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.3391693365367116 | validation: 0.3924305051029857]
	TIME [epoch: 10.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3557526698676556		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.3557526698676556 | validation: 0.378360585760239]
	TIME [epoch: 10.2 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3269043827130441		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.3269043827130441 | validation: 0.34695210102320234]
	TIME [epoch: 10.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4061271744718157		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.4061271744718157 | validation: 0.4853354087081862]
	TIME [epoch: 10.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177126655104229		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.4177126655104229 | validation: 0.35148764215006906]
	TIME [epoch: 10.2 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27454007031110617		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.27454007031110617 | validation: 0.355156704105658]
	TIME [epoch: 10.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33270431056612526		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.33270431056612526 | validation: 0.3133774270104485]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45611533138600874		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.45611533138600874 | validation: 0.4342106141799253]
	TIME [epoch: 10.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3829537560728996		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.3829537560728996 | validation: 0.3931537947088913]
	TIME [epoch: 10.2 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2972560435233845		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.2972560435233845 | validation: 0.32750254400865303]
	TIME [epoch: 10.2 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31233984155034433		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.31233984155034433 | validation: 0.41228487178082746]
	TIME [epoch: 10.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4342431930246399		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.4342431930246399 | validation: 0.4772103178337328]
	TIME [epoch: 10.2 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49518735973839123		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.49518735973839123 | validation: 0.49501614311084174]
	TIME [epoch: 10.2 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36221273903797346		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.36221273903797346 | validation: 0.39323529065973717]
	TIME [epoch: 10.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3117501773036129		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.3117501773036129 | validation: 0.47341113136498353]
	TIME [epoch: 10.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35332627153454144		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.35332627153454144 | validation: 0.45043495093048835]
	TIME [epoch: 10.2 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46122353743201244		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.46122353743201244 | validation: 0.5753831029066497]
	TIME [epoch: 10.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4382662961810226		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.4382662961810226 | validation: 0.35832215309258725]
	TIME [epoch: 10.2 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29559355575890456		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.29559355575890456 | validation: 0.4545336777204208]
	TIME [epoch: 10.2 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3674937068336383		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.3674937068336383 | validation: 0.45830168812346045]
	TIME [epoch: 10.2 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3838528317094788		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.3838528317094788 | validation: 0.46931322024168126]
	TIME [epoch: 10.2 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4125380172345479		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.4125380172345479 | validation: 0.4573952404415288]
	TIME [epoch: 10.2 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3508927647564337		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.3508927647564337 | validation: 0.39502788943915185]
	TIME [epoch: 10.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3280177304543859		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.3280177304543859 | validation: 0.39434112821332135]
	TIME [epoch: 10.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6581273578637965		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.6581273578637965 | validation: 0.43918247528880494]
	TIME [epoch: 10.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3309236809760273		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.3309236809760273 | validation: 0.49713974083085916]
	TIME [epoch: 10.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3755173674683964		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.3755173674683964 | validation: 0.3691665362637895]
	TIME [epoch: 10.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34300347392027647		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.34300347392027647 | validation: 0.41052744552876724]
	TIME [epoch: 10.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3413259394370109		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.3413259394370109 | validation: 0.4559835712049347]
	TIME [epoch: 10.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39088610336484797		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.39088610336484797 | validation: 0.49188162880507313]
	TIME [epoch: 10.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48297884693848914		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.48297884693848914 | validation: 0.49709985012317304]
	TIME [epoch: 10.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43404851148491674		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.43404851148491674 | validation: 0.6324059884443749]
	TIME [epoch: 10.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41731161118546767		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.41731161118546767 | validation: 0.359409810659306]
	TIME [epoch: 10.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302420022411926		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.3302420022411926 | validation: 0.40715556783337503]
	TIME [epoch: 10.2 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3373427950426048		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.3373427950426048 | validation: 0.4414792013449902]
	TIME [epoch: 10.2 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37727788795487666		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.37727788795487666 | validation: 0.37613309314669613]
	TIME [epoch: 10.2 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32486885345595284		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.32486885345595284 | validation: 0.36300492584973026]
	TIME [epoch: 10.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018233242418037		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.3018233242418037 | validation: 0.3663375789917462]
	TIME [epoch: 10.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285978766029358		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.3285978766029358 | validation: 0.48044426928136025]
	TIME [epoch: 10.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.407424257588489		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.407424257588489 | validation: 0.3637161596699393]
	TIME [epoch: 10.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35227304202017534		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.35227304202017534 | validation: 0.41170823087901354]
	TIME [epoch: 10.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3530332159594164		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.3530332159594164 | validation: 0.4544330201127255]
	TIME [epoch: 10.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48199874545116755		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.48199874545116755 | validation: 0.568336054959199]
	TIME [epoch: 10.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4832178434180661		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.4832178434180661 | validation: 0.36661083408824396]
	TIME [epoch: 10.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30881518703931576		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.30881518703931576 | validation: 0.3221953523394068]
	TIME [epoch: 10.2 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35244038173632186		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.35244038173632186 | validation: 0.42648208211381133]
	TIME [epoch: 10.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4170826559754895		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.4170826559754895 | validation: 0.44803845853644786]
	TIME [epoch: 10.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3372883953045839		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.3372883953045839 | validation: 0.34479462010427936]
	TIME [epoch: 10.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166208348238129		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.3166208348238129 | validation: 0.43648087023640814]
	TIME [epoch: 10.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299913717435743		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.3299913717435743 | validation: 0.3296119879912962]
	TIME [epoch: 10.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217448884601959		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.3217448884601959 | validation: 0.39123799188448344]
	TIME [epoch: 10.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34254511730334625		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.34254511730334625 | validation: 0.4039064318712041]
	TIME [epoch: 10.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3394253508365277		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.3394253508365277 | validation: 0.4190386060745131]
	TIME [epoch: 10.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.344720863466344		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.344720863466344 | validation: 0.3629290025429344]
	TIME [epoch: 10.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36094938600458815		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.36094938600458815 | validation: 0.3921601646569502]
	TIME [epoch: 10.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42280182808867944		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.42280182808867944 | validation: 0.5219302632346111]
	TIME [epoch: 10.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41930255777314934		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.41930255777314934 | validation: 0.3774777058727343]
	TIME [epoch: 10.2 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29226678531234834		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.29226678531234834 | validation: 0.3885695492900368]
	TIME [epoch: 10.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3553439420682003		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.3553439420682003 | validation: 0.41110826747289375]
	TIME [epoch: 10.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2941649521707679		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.2941649521707679 | validation: 0.37257479601034355]
	TIME [epoch: 10.2 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2956116690448175		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.2956116690448175 | validation: 0.43514748317795593]
	TIME [epoch: 10.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3839146797353029		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.3839146797353029 | validation: 0.5151699485611083]
	TIME [epoch: 10.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3976392207496071		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.3976392207496071 | validation: 0.36440050896934867]
	TIME [epoch: 10.2 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30389223654402125		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.30389223654402125 | validation: 0.47428169867503117]
	TIME [epoch: 10.2 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4175253487146966		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.4175253487146966 | validation: 0.41333056174990457]
	TIME [epoch: 10.2 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5071238900550612		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.5071238900550612 | validation: 0.4371045614102802]
	TIME [epoch: 10.2 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3065606113003669		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.3065606113003669 | validation: 0.4598266047665895]
	TIME [epoch: 10.2 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36765113710040953		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.36765113710040953 | validation: 0.38163034418363895]
	TIME [epoch: 10.2 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2860268830399472		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.2860268830399472 | validation: 0.38204414293760197]
	TIME [epoch: 10.2 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.292368365053821		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.292368365053821 | validation: 0.3620297294464943]
	TIME [epoch: 10.2 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45113584134211226		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.45113584134211226 | validation: 0.6758819101152331]
	TIME [epoch: 10.2 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.496699013432516		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.496699013432516 | validation: 0.3641156326385795]
	TIME [epoch: 10.2 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29790688235190127		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.29790688235190127 | validation: 0.3303491923136096]
	TIME [epoch: 10.2 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29299741926142486		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.29299741926142486 | validation: 0.41889922419141357]
	TIME [epoch: 10.2 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3744559060993953		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.3744559060993953 | validation: 0.3138879559394493]
	TIME [epoch: 10.2 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3250560620401509		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.3250560620401509 | validation: 0.3665739834941147]
	TIME [epoch: 10.2 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3198897962158266		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.3198897962158266 | validation: 0.441966073371232]
	TIME [epoch: 10.2 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5030033388083993		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.5030033388083993 | validation: 0.44311172408064214]
	TIME [epoch: 10.2 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3628486919693019		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.3628486919693019 | validation: 0.3094740468724808]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1020.pth
	Model improved!!!
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29416058583983407		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.29416058583983407 | validation: 0.5029636875457615]
	TIME [epoch: 10.2 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4206744110941125		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.4206744110941125 | validation: 0.34974436100160944]
	TIME [epoch: 10.2 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3540355282643822		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.3540355282643822 | validation: 0.5122500600358909]
	TIME [epoch: 10.2 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4071955627636189		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.4071955627636189 | validation: 0.4365178301728125]
	TIME [epoch: 10.2 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35836148489093167		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.35836148489093167 | validation: 0.3261218371043401]
	TIME [epoch: 10.2 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29707386920756645		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.29707386920756645 | validation: 0.4021147892715006]
	TIME [epoch: 10.2 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31745099855290604		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.31745099855290604 | validation: 0.3467341208845733]
	TIME [epoch: 10.2 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3120937868176573		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.3120937868176573 | validation: 0.45221582248258585]
	TIME [epoch: 10.2 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35655595641714866		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.35655595641714866 | validation: 0.3642658707421096]
	TIME [epoch: 10.2 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42321932614266944		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.42321932614266944 | validation: 0.4534994628076421]
	TIME [epoch: 10.2 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40177033633154624		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.40177033633154624 | validation: 0.3361779167928391]
	TIME [epoch: 10.2 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3627737270620294		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.3627737270620294 | validation: 0.4088943281651995]
	TIME [epoch: 10.2 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3184018929191665		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.3184018929191665 | validation: 0.3708687398551759]
	TIME [epoch: 10.2 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42164913079191446		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.42164913079191446 | validation: 0.40641989284155977]
	TIME [epoch: 10.2 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38249829406513935		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.38249829406513935 | validation: 0.34264508244004716]
	TIME [epoch: 10.2 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35156136428582707		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.35156136428582707 | validation: 0.4309499015093667]
	TIME [epoch: 10.2 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38210984111442164		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.38210984111442164 | validation: 0.33692424842013863]
	TIME [epoch: 10.2 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297449992818028		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.297449992818028 | validation: 0.3993962175683252]
	TIME [epoch: 10.2 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35211120314110933		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.35211120314110933 | validation: 0.3208381243231622]
	TIME [epoch: 10.2 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.284603392900734		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.284603392900734 | validation: 0.3408937657711917]
	TIME [epoch: 10.2 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27719385143471614		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.27719385143471614 | validation: 0.47032953306756]
	TIME [epoch: 10.2 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6068442933209688		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.6068442933209688 | validation: 0.4812118107852544]
	TIME [epoch: 10.2 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38498030541925476		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.38498030541925476 | validation: 0.3619049990010965]
	TIME [epoch: 10.2 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29926217078945777		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.29926217078945777 | validation: 0.34287252100581767]
	TIME [epoch: 10.2 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.293335078590618		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.293335078590618 | validation: 0.37360625171371764]
	TIME [epoch: 10.2 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032103374349381		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.3032103374349381 | validation: 0.4182640430018951]
	TIME [epoch: 10.2 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35366987410303724		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.35366987410303724 | validation: 0.45411429093417893]
	TIME [epoch: 10.2 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33238119369802743		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.33238119369802743 | validation: 0.3888952401231171]
	TIME [epoch: 10.2 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2976080290006479		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.2976080290006479 | validation: 0.45280694306489117]
	TIME [epoch: 10.2 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42846079932868336		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.42846079932868336 | validation: 0.40267614454797274]
	TIME [epoch: 10.2 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48880803084632074		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.48880803084632074 | validation: 0.38699040489161624]
	TIME [epoch: 10.2 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29834898437624424		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.29834898437624424 | validation: 0.36383100031506954]
	TIME [epoch: 10.2 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2996179702138878		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.2996179702138878 | validation: 0.3439022936517288]
	TIME [epoch: 10.2 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31264394017692104		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.31264394017692104 | validation: 0.42475993931499234]
	TIME [epoch: 10.2 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3919829883899731		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.3919829883899731 | validation: 0.4353229288851905]
	TIME [epoch: 10.2 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3802634089207116		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.3802634089207116 | validation: 0.41893171952756125]
	TIME [epoch: 10.2 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36990705117478057		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.36990705117478057 | validation: 0.39568448391511774]
	TIME [epoch: 10.2 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4491523770455707		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.4491523770455707 | validation: 0.5085142299250264]
	TIME [epoch: 10.2 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37923502330857894		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.37923502330857894 | validation: 0.4490367516167797]
	TIME [epoch: 10.2 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3728110550131505		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.3728110550131505 | validation: 0.4881499719171165]
	TIME [epoch: 10.2 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40876043757727987		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.40876043757727987 | validation: 0.44247063137509945]
	TIME [epoch: 10.2 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30455018591799565		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.30455018591799565 | validation: 0.3586964553287831]
	TIME [epoch: 10.2 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31818117609998936		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.31818117609998936 | validation: 0.3735723700459137]
	TIME [epoch: 10.2 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3207861092639832		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.3207861092639832 | validation: 0.3461355097245368]
	TIME [epoch: 10.2 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29260172397852874		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.29260172397852874 | validation: 0.3140252330927511]
	TIME [epoch: 10.2 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3045795504092521		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.3045795504092521 | validation: 0.3631641699882862]
	TIME [epoch: 10.2 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31484458170790647		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.31484458170790647 | validation: 0.3285774421441073]
	TIME [epoch: 10.2 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308026501875975		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.308026501875975 | validation: 0.4184089581493716]
	TIME [epoch: 10.2 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3270132310382165		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.3270132310382165 | validation: 0.3493898481700519]
	TIME [epoch: 10.2 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31531730521260465		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.31531730521260465 | validation: 0.3430396002365403]
	TIME [epoch: 10.2 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3282014797925748		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.3282014797925748 | validation: 0.4376353973042351]
	TIME [epoch: 10.2 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49205136875678174		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.49205136875678174 | validation: 0.37117176261699086]
	TIME [epoch: 10.2 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29160455802896906		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.29160455802896906 | validation: 0.38971699983725816]
	TIME [epoch: 10.2 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.432995868979894		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.432995868979894 | validation: 0.43556062484035835]
	TIME [epoch: 10.2 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38216488108723945		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.38216488108723945 | validation: 0.46766049166792073]
	TIME [epoch: 10.2 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.377094716531429		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.377094716531429 | validation: 0.34867585122276923]
	TIME [epoch: 10.2 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27442825065647825		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.27442825065647825 | validation: 0.34437889101068214]
	TIME [epoch: 10.2 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2835009767071936		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.2835009767071936 | validation: 0.33395455147526565]
	TIME [epoch: 10.2 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3579873162234827		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.3579873162234827 | validation: 0.618732819427179]
	TIME [epoch: 10.2 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6589645668378022		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.6589645668378022 | validation: 0.3506583834042054]
	TIME [epoch: 10.2 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29916541886432385		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.29916541886432385 | validation: 0.3778740527151564]
	TIME [epoch: 10.2 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30060492285581236		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.30060492285581236 | validation: 0.3781328729073317]
	TIME [epoch: 10.2 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30683691870844926		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.30683691870844926 | validation: 0.348110956098579]
	TIME [epoch: 10.2 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27089266306180937		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.27089266306180937 | validation: 0.35542312777359925]
	TIME [epoch: 10.2 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3570119491237847		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.3570119491237847 | validation: 0.5774370106202413]
	TIME [epoch: 10.2 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4135191872043089		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.4135191872043089 | validation: 0.3374396667269518]
	TIME [epoch: 10.2 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2858380478958745		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.2858380478958745 | validation: 0.34770946115087015]
	TIME [epoch: 10.2 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961002958805403		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.2961002958805403 | validation: 0.3288132377308871]
	TIME [epoch: 10.2 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332376454434243		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.332376454434243 | validation: 0.34592061426868526]
	TIME [epoch: 10.2 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2862695516521806		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.2862695516521806 | validation: 0.3393068226314333]
	TIME [epoch: 10.2 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30554747049594727		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.30554747049594727 | validation: 0.38218219223262223]
	TIME [epoch: 10.2 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40814321552599464		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.40814321552599464 | validation: 0.4499862843249659]
	TIME [epoch: 10.2 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018995132160047		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.3018995132160047 | validation: 0.3535945430349308]
	TIME [epoch: 10.2 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3696171324421727		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.3696171324421727 | validation: 0.35682941465674867]
	TIME [epoch: 10.2 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297456365405162		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.297456365405162 | validation: 0.3410644304396196]
	TIME [epoch: 10.2 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31393286762475103		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.31393286762475103 | validation: 0.4245530172359869]
	TIME [epoch: 10.2 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32659271452706873		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.32659271452706873 | validation: 0.33368909122856055]
	TIME [epoch: 10.2 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2820605866196245		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.2820605866196245 | validation: 0.4124549293678515]
	TIME [epoch: 10.2 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.366892736439291		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.366892736439291 | validation: 0.4082805506222323]
	TIME [epoch: 10.2 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3653504053643694		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.3653504053643694 | validation: 0.34714024908108976]
	TIME [epoch: 10.2 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3359746464766658		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.3359746464766658 | validation: 0.3988451625335672]
	TIME [epoch: 10.2 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34270190045671817		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.34270190045671817 | validation: 0.3886816147112553]
	TIME [epoch: 10.2 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945930555477643		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.2945930555477643 | validation: 0.3936398727337179]
	TIME [epoch: 10.2 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30223992024550833		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.30223992024550833 | validation: 0.3224302248506858]
	TIME [epoch: 10.2 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3206504936330856		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.3206504936330856 | validation: 0.39398230182792904]
	TIME [epoch: 10.2 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28658425827398254		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.28658425827398254 | validation: 0.336594792717937]
	TIME [epoch: 10.2 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2857010893053341		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.2857010893053341 | validation: 0.3934532957722429]
	TIME [epoch: 10.2 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29083573823015907		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.29083573823015907 | validation: 0.3785422821722385]
	TIME [epoch: 10.2 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34528384957348457		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.34528384957348457 | validation: 0.40854139049486565]
	TIME [epoch: 10.2 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31507946477523996		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.31507946477523996 | validation: 0.42201882912707434]
	TIME [epoch: 10.2 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3926072860216404		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.3926072860216404 | validation: 0.5377989814280095]
	TIME [epoch: 10.2 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3939521619207301		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.3939521619207301 | validation: 0.39434349104353045]
	TIME [epoch: 10.2 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30227661740047795		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.30227661740047795 | validation: 0.33486855907008506]
	TIME [epoch: 10.2 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29512477884954047		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.29512477884954047 | validation: 0.3493776802148578]
	TIME [epoch: 10.2 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28897572785752984		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.28897572785752984 | validation: 0.37560943837713]
	TIME [epoch: 10.2 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3429544019847929		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.3429544019847929 | validation: 0.362645030030741]
	TIME [epoch: 10.2 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3072109596860444		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.3072109596860444 | validation: 0.33541281277300855]
	TIME [epoch: 10.2 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2861203871660579		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.2861203871660579 | validation: 0.34396127904971585]
	TIME [epoch: 10.2 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063498268558836		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.3063498268558836 | validation: 0.36962389038666194]
	TIME [epoch: 10.2 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28153006570698225		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.28153006570698225 | validation: 0.34423925260576854]
	TIME [epoch: 10.2 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.266029449897466		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.266029449897466 | validation: 0.3739641710997557]
	TIME [epoch: 10.2 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2858772897409326		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.2858772897409326 | validation: 0.384259179721214]
	TIME [epoch: 10.2 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29197510881767813		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.29197510881767813 | validation: 0.4176948527610637]
	TIME [epoch: 10.2 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31134064983942195		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.31134064983942195 | validation: 0.36145792402635096]
	TIME [epoch: 10.2 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749189762465408		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.2749189762465408 | validation: 0.3059460587041378]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1125.pth
	Model improved!!!
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.279661110529325		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.279661110529325 | validation: 0.3135319400269302]
	TIME [epoch: 10.2 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3304324593834256		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.3304324593834256 | validation: 0.3000779456609896]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1127.pth
	Model improved!!!
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29116546187556264		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.29116546187556264 | validation: 0.4244415132329795]
	TIME [epoch: 10.2 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3326197002877481		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.3326197002877481 | validation: 0.35344802380266394]
	TIME [epoch: 10.2 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26347907668573317		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.26347907668573317 | validation: 0.34274567742358025]
	TIME [epoch: 10.2 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30324247899025164		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.30324247899025164 | validation: 0.36028146463513316]
	TIME [epoch: 10.2 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3636507778958348		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.3636507778958348 | validation: 0.5511506356779486]
	TIME [epoch: 10.2 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006240874629213		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.4006240874629213 | validation: 0.39020467112049767]
	TIME [epoch: 10.2 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3452557257722761		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.3452557257722761 | validation: 0.39315132971735317]
	TIME [epoch: 10.2 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31367708696747093		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.31367708696747093 | validation: 0.3391209621944719]
	TIME [epoch: 10.2 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29603133982355134		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.29603133982355134 | validation: 0.39814134743271357]
	TIME [epoch: 10.2 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3248960614424884		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.3248960614424884 | validation: 0.36852454404604323]
	TIME [epoch: 10.2 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29700793827246474		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.29700793827246474 | validation: 0.34965491162837026]
	TIME [epoch: 10.2 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28979767430752446		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.28979767430752446 | validation: 0.34586793251596776]
	TIME [epoch: 10.2 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26901176022489387		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.26901176022489387 | validation: 0.3467366165794299]
	TIME [epoch: 10.2 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28745734291547104		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.28745734291547104 | validation: 0.3451040867692966]
	TIME [epoch: 10.2 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27152880848009436		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.27152880848009436 | validation: 0.3447107735938056]
	TIME [epoch: 10.2 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2711581851857562		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.2711581851857562 | validation: 0.34820288020855017]
	TIME [epoch: 10.2 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30496986738814336		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.30496986738814336 | validation: 0.34275234014350403]
	TIME [epoch: 10.2 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2688027965459446		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.2688027965459446 | validation: 0.30104253825683863]
	TIME [epoch: 10.2 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.255277683879655		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.255277683879655 | validation: 0.28603271314801293]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2668894725259393		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.2668894725259393 | validation: 0.35109400324478596]
	TIME [epoch: 10.2 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2564900879392772		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.2564900879392772 | validation: 0.31034089156605144]
	TIME [epoch: 10.2 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29688571925132806		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.29688571925132806 | validation: 0.3833814066736907]
	TIME [epoch: 10.2 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3468623213203736		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.3468623213203736 | validation: 0.4174445371194163]
	TIME [epoch: 10.2 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3123732790369972		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.3123732790369972 | validation: 0.33870312733930413]
	TIME [epoch: 10.2 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27232757458155593		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.27232757458155593 | validation: 0.2754094393460333]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1152.pth
	Model improved!!!
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3753322316161466		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.3753322316161466 | validation: 0.44350008169308425]
	TIME [epoch: 10.2 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3877827025412412		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.3877827025412412 | validation: 0.3735307306453403]
	TIME [epoch: 10.2 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3266091361695935		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.3266091361695935 | validation: 0.34609857722272624]
	TIME [epoch: 10.2 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28734270719843846		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.28734270719843846 | validation: 0.29226511570336483]
	TIME [epoch: 10.2 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25618800501973366		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.25618800501973366 | validation: 0.31798820683821616]
	TIME [epoch: 10.2 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26653109769968875		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.26653109769968875 | validation: 0.3002381045279545]
	TIME [epoch: 10.2 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26823874268079223		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.26823874268079223 | validation: 0.34116051689024723]
	TIME [epoch: 10.2 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28879042029756097		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.28879042029756097 | validation: 0.3262049508377749]
	TIME [epoch: 10.2 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29763772739638705		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.29763772739638705 | validation: 0.3499638610470185]
	TIME [epoch: 10.2 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30485498732765043		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.30485498732765043 | validation: 0.3953801941657472]
	TIME [epoch: 10.2 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27540808102420633		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.27540808102420633 | validation: 0.3445003124264507]
	TIME [epoch: 10.2 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2430176137277546		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.2430176137277546 | validation: 0.2960908001974446]
	TIME [epoch: 10.2 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25739413100691333		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.25739413100691333 | validation: 0.32105059636600225]
	TIME [epoch: 10.2 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2520642825660088		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.2520642825660088 | validation: 0.320775088910636]
	TIME [epoch: 10.2 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23366944006662282		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.23366944006662282 | validation: 0.28714503249687423]
	TIME [epoch: 10.2 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2289157177676841		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.2289157177676841 | validation: 0.3129892815856968]
	TIME [epoch: 10.2 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.293722970464548		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.293722970464548 | validation: 0.3709188116085572]
	TIME [epoch: 10.2 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3579796552059253		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.3579796552059253 | validation: 0.32431284947460115]
	TIME [epoch: 10.2 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24934469275206225		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.24934469275206225 | validation: 0.3007106629941918]
	TIME [epoch: 10.2 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799271484054717		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.2799271484054717 | validation: 0.33696026326653894]
	TIME [epoch: 10.2 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44475751225116006		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.44475751225116006 | validation: 0.45198159603296306]
	TIME [epoch: 10.2 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3546257869852801		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.3546257869852801 | validation: 0.45728217448914865]
	TIME [epoch: 10.2 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3722412469884106		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.3722412469884106 | validation: 0.40707672450105803]
	TIME [epoch: 10.2 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3500409673017991		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.3500409673017991 | validation: 0.325897139481144]
	TIME [epoch: 10.2 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625713791826606		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.2625713791826606 | validation: 0.3122004065666922]
	TIME [epoch: 10.2 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24114937841300335		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.24114937841300335 | validation: 0.32451791613625924]
	TIME [epoch: 10.2 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26317970424475606		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.26317970424475606 | validation: 0.3007961028520059]
	TIME [epoch: 10.2 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27039939350839454		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.27039939350839454 | validation: 0.29850006394599055]
	TIME [epoch: 10.2 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24658577235333587		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.24658577235333587 | validation: 0.3091391029859847]
	TIME [epoch: 10.2 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25037995013468495		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.25037995013468495 | validation: 0.3432610071955783]
	TIME [epoch: 10.2 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24223800702703419		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.24223800702703419 | validation: 0.30182834825425314]
	TIME [epoch: 10.2 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2631188433326346		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.2631188433326346 | validation: 0.29104464394616075]
	TIME [epoch: 10.2 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.258293914917645		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.258293914917645 | validation: 0.3363130595253165]
	TIME [epoch: 10.2 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2742829577248726		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.2742829577248726 | validation: 0.29610762681583547]
	TIME [epoch: 10.2 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24514293521020236		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.24514293521020236 | validation: 0.3339002455377967]
	TIME [epoch: 10.2 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23802687518790083		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.23802687518790083 | validation: 0.3665139569770019]
	TIME [epoch: 10.2 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30547827857963217		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.30547827857963217 | validation: 0.37923088742360817]
	TIME [epoch: 10.2 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2806621846645408		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.2806621846645408 | validation: 0.3774087788134625]
	TIME [epoch: 10.2 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40619191770512264		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.40619191770512264 | validation: 0.41920142704671554]
	TIME [epoch: 10.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3770570187455129		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.3770570187455129 | validation: 0.4443943742920536]
	TIME [epoch: 10.2 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33787279168650003		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.33787279168650003 | validation: 0.32607454558958]
	TIME [epoch: 10.2 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26617817360601503		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.26617817360601503 | validation: 0.31655433628305785]
	TIME [epoch: 10.2 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2720521515456952		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.2720521515456952 | validation: 0.31690639659918945]
	TIME [epoch: 10.2 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.258663123052179		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.258663123052179 | validation: 0.3029802764060452]
	TIME [epoch: 10.2 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24726886812908733		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.24726886812908733 | validation: 0.30305986051093653]
	TIME [epoch: 10.2 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24414168092990157		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.24414168092990157 | validation: 0.32232217035821153]
	TIME [epoch: 10.2 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27620548937832756		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.27620548937832756 | validation: 0.31590185589652836]
	TIME [epoch: 10.2 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26114136385769615		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.26114136385769615 | validation: 0.358931929904119]
	TIME [epoch: 10.2 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3322824492663307		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.3322824492663307 | validation: 0.3412233227268527]
	TIME [epoch: 10.2 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.265028602090615		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.265028602090615 | validation: 0.33716968648908086]
	TIME [epoch: 10.2 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24932203299753136		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.24932203299753136 | validation: 0.3463544337913345]
	TIME [epoch: 10.2 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2666029555302435		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.2666029555302435 | validation: 0.3635599213600518]
	TIME [epoch: 10.2 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2884219494090504		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.2884219494090504 | validation: 0.335205645607512]
	TIME [epoch: 10.2 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26542146793954446		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.26542146793954446 | validation: 0.34172240603838433]
	TIME [epoch: 10.2 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26920510560402183		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.26920510560402183 | validation: 0.3259432115356112]
	TIME [epoch: 10.2 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2587137296689212		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.2587137296689212 | validation: 0.28175298688640565]
	TIME [epoch: 10.2 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30427023144233367		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.30427023144233367 | validation: 0.34587356540552877]
	TIME [epoch: 10.2 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.261872660542745		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.261872660542745 | validation: 0.3216458477958563]
	TIME [epoch: 10.2 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2774299967237207		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.2774299967237207 | validation: 0.33082920108238534]
	TIME [epoch: 10.2 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2978438229461805		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.2978438229461805 | validation: 0.35964662756136095]
	TIME [epoch: 10.2 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30424644714330273		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.30424644714330273 | validation: 0.3290926005535105]
	TIME [epoch: 10.2 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2595336437301062		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.2595336437301062 | validation: 0.3099087694512154]
	TIME [epoch: 10.2 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26220383348162823		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.26220383348162823 | validation: 0.28227586789240344]
	TIME [epoch: 10.2 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.285268234502473		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.285268234502473 | validation: 0.35444373013683417]
	TIME [epoch: 10.2 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299296360202927		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.3299296360202927 | validation: 0.33226388355552333]
	TIME [epoch: 10.2 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26706207394622716		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.26706207394622716 | validation: 0.3327827527104348]
	TIME [epoch: 10.2 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26830865896878653		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.26830865896878653 | validation: 0.37099397517773464]
	TIME [epoch: 10.2 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2832796710275746		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.2832796710275746 | validation: 0.31318666323566563]
	TIME [epoch: 10.2 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25701473114170054		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.25701473114170054 | validation: 0.3373855587212366]
	TIME [epoch: 10.2 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2840819456478171		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.2840819456478171 | validation: 0.392833091100745]
	TIME [epoch: 10.2 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3002522934156629		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.3002522934156629 | validation: 0.3753406843073154]
	TIME [epoch: 10.2 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825267533098107		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.2825267533098107 | validation: 0.29680732662865345]
	TIME [epoch: 10.2 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24815951553977364		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.24815951553977364 | validation: 0.3200356760380764]
	TIME [epoch: 10.2 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25953204549682213		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.25953204549682213 | validation: 0.30977502428438625]
	TIME [epoch: 10.2 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26165377809095414		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.26165377809095414 | validation: 0.3301419457845816]
	TIME [epoch: 10.2 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.273562289385911		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.273562289385911 | validation: 0.30089903413304436]
	TIME [epoch: 10.2 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3249658329457459		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.3249658329457459 | validation: 0.3471455217227299]
	TIME [epoch: 10.2 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25893762169842144		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.25893762169842144 | validation: 0.3233924904245689]
	TIME [epoch: 10.2 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28717427077553104		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.28717427077553104 | validation: 0.372805401644588]
	TIME [epoch: 10.2 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31918503251996305		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.31918503251996305 | validation: 0.36219363874260185]
	TIME [epoch: 10.2 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27908694490488883		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.27908694490488883 | validation: 0.3474497600438119]
	TIME [epoch: 10.2 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26900909413543894		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.26900909413543894 | validation: 0.32126177147973733]
	TIME [epoch: 10.2 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27519581892437095		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.27519581892437095 | validation: 0.3720392794978157]
	TIME [epoch: 10.2 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28636894346666064		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.28636894346666064 | validation: 0.3084056648856231]
	TIME [epoch: 10.2 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27736516846036646		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.27736516846036646 | validation: 0.36215713247809833]
	TIME [epoch: 10.2 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28419537584620624		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.28419537584620624 | validation: 0.29829110074074594]
	TIME [epoch: 10.2 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3337890251043893		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.3337890251043893 | validation: 0.3613626801028501]
	TIME [epoch: 10.2 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33853616217214855		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.33853616217214855 | validation: 0.3227779079523586]
	TIME [epoch: 10.2 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2751171885075011		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.2751171885075011 | validation: 0.3130287801782034]
	TIME [epoch: 10.2 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4312751817428916		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.4312751817428916 | validation: 0.5896438958057408]
	TIME [epoch: 10.2 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314625909716068		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.5314625909716068 | validation: 0.35859321436988867]
	TIME [epoch: 10.2 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2518801177957246		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.2518801177957246 | validation: 0.29100605669930063]
	TIME [epoch: 10.2 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2315721797359025		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.2315721797359025 | validation: 0.31118072011424497]
	TIME [epoch: 10.2 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2876373966892151		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.2876373966892151 | validation: 0.259984170408728]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1246.pth
	Model improved!!!
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23765884958974412		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.23765884958974412 | validation: 0.30665469587290456]
	TIME [epoch: 10.2 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2855137156316193		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.2855137156316193 | validation: 0.31125377824100314]
	TIME [epoch: 10.2 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24153691920979906		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.24153691920979906 | validation: 0.3515119598897853]
	TIME [epoch: 10.2 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25301449235569723		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.25301449235569723 | validation: 0.31080431934461134]
	TIME [epoch: 10.2 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24508047879810907		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.24508047879810907 | validation: 0.30320860684960393]
	TIME [epoch: 10.2 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24365759415437105		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.24365759415437105 | validation: 0.2970980033960467]
	TIME [epoch: 10.2 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.276082326506154		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.276082326506154 | validation: 0.37585808597480247]
	TIME [epoch: 10.2 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32014585648427174		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.32014585648427174 | validation: 0.33778191588926687]
	TIME [epoch: 10.2 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2552900823324288		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.2552900823324288 | validation: 0.33705663313172624]
	TIME [epoch: 10.2 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27449337803583246		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.27449337803583246 | validation: 0.41665113037760376]
	TIME [epoch: 10.2 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3239573057075792		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.3239573057075792 | validation: 0.32364618654333865]
	TIME [epoch: 10.2 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2612446952381549		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.2612446952381549 | validation: 0.29884461048151506]
	TIME [epoch: 10.2 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29600950177909324		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.29600950177909324 | validation: 0.4413895739512118]
	TIME [epoch: 10.2 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31008426203603057		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.31008426203603057 | validation: 0.28168311788759987]
	TIME [epoch: 10.2 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25186280087555535		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.25186280087555535 | validation: 0.3201683347847912]
	TIME [epoch: 10.2 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25168274051146466		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.25168274051146466 | validation: 0.32257417669077015]
	TIME [epoch: 10.2 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2790812754334822		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.2790812754334822 | validation: 0.3799494055742537]
	TIME [epoch: 10.2 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2900014707604274		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.2900014707604274 | validation: 0.34083456634831893]
	TIME [epoch: 10.2 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27557448336947254		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.27557448336947254 | validation: 0.3645929812524942]
	TIME [epoch: 10.2 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953206377643281		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.2953206377643281 | validation: 0.34457603387888525]
	TIME [epoch: 10.2 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2558344567648902		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.2558344567648902 | validation: 0.3253548460680848]
	TIME [epoch: 10.2 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24662770653465077		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.24662770653465077 | validation: 0.28577591474421676]
	TIME [epoch: 10.2 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2571246872965581		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.2571246872965581 | validation: 0.3307583121176442]
	TIME [epoch: 10.2 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2937253492732589		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.2937253492732589 | validation: 0.39384192959045694]
	TIME [epoch: 10.2 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36393543196782224		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.36393543196782224 | validation: 0.3593226546002529]
	TIME [epoch: 10.2 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2666650307006041		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.2666650307006041 | validation: 0.3370710085651427]
	TIME [epoch: 10.2 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27391195948626124		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.27391195948626124 | validation: 0.2960590342687995]
	TIME [epoch: 10.2 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28785926911616255		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.28785926911616255 | validation: 0.38691877693566595]
	TIME [epoch: 10.2 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3783376216234967		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.3783376216234967 | validation: 0.44380144872783506]
	TIME [epoch: 10.2 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.346312293898639		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.346312293898639 | validation: 0.35038496773848243]
	TIME [epoch: 10.2 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2687416043624632		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.2687416043624632 | validation: 0.2867528831053493]
	TIME [epoch: 10.2 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24560432947007443		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.24560432947007443 | validation: 0.310476796512109]
	TIME [epoch: 10.2 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26230359373683065		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.26230359373683065 | validation: 0.2897037992424076]
	TIME [epoch: 10.2 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507848624242192		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.2507848624242192 | validation: 0.3303753361816246]
	TIME [epoch: 10.2 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2535879990375164		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.2535879990375164 | validation: 0.3577952105304153]
	TIME [epoch: 10.2 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2622192110028704		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.2622192110028704 | validation: 0.33249405713400343]
	TIME [epoch: 10.2 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.261192099900158		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.261192099900158 | validation: 0.3818937790874874]
	TIME [epoch: 10.2 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32615197706492816		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.32615197706492816 | validation: 0.33594062987926526]
	TIME [epoch: 10.2 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24767276744773845		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.24767276744773845 | validation: 0.2836573903246744]
	TIME [epoch: 10.2 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23135162454925448		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.23135162454925448 | validation: 0.2942337896764589]
	TIME [epoch: 10.2 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22350221103339307		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.22350221103339307 | validation: 0.2747633723865943]
	TIME [epoch: 10.2 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22879431172207226		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.22879431172207226 | validation: 0.3480901383330903]
	TIME [epoch: 10.2 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2758804021252353		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.2758804021252353 | validation: 0.3353629069481626]
	TIME [epoch: 10.2 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29909016427210044		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.29909016427210044 | validation: 0.38132987344994435]
	TIME [epoch: 10.2 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32650554349104166		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.32650554349104166 | validation: 0.41963761371161573]
	TIME [epoch: 10.2 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35365753494653596		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.35365753494653596 | validation: 0.384934921341193]
	TIME [epoch: 10.2 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32493091156867515		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.32493091156867515 | validation: 0.33967821470823306]
	TIME [epoch: 10.2 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25724923728752225		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.25724923728752225 | validation: 0.30888189928024934]
	TIME [epoch: 10.2 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.241349462644579		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.241349462644579 | validation: 0.31870316551860195]
	TIME [epoch: 10.2 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588061104664296		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.2588061104664296 | validation: 0.29381146742016184]
	TIME [epoch: 10.2 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26752922043429506		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.26752922043429506 | validation: 0.306872353148302]
	TIME [epoch: 10.2 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2212884016115487		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.2212884016115487 | validation: 0.2306815292045574]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1298.pth
	Model improved!!!
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21714210723020894		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.21714210723020894 | validation: 0.28862497211366267]
	TIME [epoch: 10.2 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22816615543932023		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.22816615543932023 | validation: 0.30216931986243384]
	TIME [epoch: 10.2 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23969257768121727		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.23969257768121727 | validation: 0.2586332424927311]
	TIME [epoch: 10.2 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299193524072866		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.2299193524072866 | validation: 0.26595474365468297]
	TIME [epoch: 10.2 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22766836670490337		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.22766836670490337 | validation: 0.33286863638585695]
	TIME [epoch: 10.2 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24184843792399618		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.24184843792399618 | validation: 0.2569928210944898]
	TIME [epoch: 10.2 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2520486445859688		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.2520486445859688 | validation: 0.2674202386079495]
	TIME [epoch: 10.2 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24358232431398413		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.24358232431398413 | validation: 0.2814908227839854]
	TIME [epoch: 10.2 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27540507724017355		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.27540507724017355 | validation: 0.266572679361781]
	TIME [epoch: 10.2 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21512133513667187		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.21512133513667187 | validation: 0.2653220429503621]
	TIME [epoch: 10.2 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25465665462993015		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.25465665462993015 | validation: 0.37394375298702853]
	TIME [epoch: 10.2 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29893188896650524		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.29893188896650524 | validation: 0.31893677923128866]
	TIME [epoch: 10.2 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2494191035964448		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.2494191035964448 | validation: 0.23852994339742836]
	TIME [epoch: 10.2 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20915812906098874		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.20915812906098874 | validation: 0.2568265583986775]
	TIME [epoch: 10.2 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21587686139421444		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.21587686139421444 | validation: 0.280442251142888]
	TIME [epoch: 10.2 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22969239319788418		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.22969239319788418 | validation: 0.2819011326982053]
	TIME [epoch: 10.2 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22737512774537616		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.22737512774537616 | validation: 0.2691596844674961]
	TIME [epoch: 10.2 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22282278897623709		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.22282278897623709 | validation: 0.3069014953922544]
	TIME [epoch: 10.2 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2923140429158329		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.2923140429158329 | validation: 0.31180341108232895]
	TIME [epoch: 10.2 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2553578483652005		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.2553578483652005 | validation: 0.31358649210597356]
	TIME [epoch: 10.2 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23810793083066759		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.23810793083066759 | validation: 0.3026626945142554]
	TIME [epoch: 10.2 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26365324437208804		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.26365324437208804 | validation: 0.34879174315536526]
	TIME [epoch: 10.2 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26046802407398795		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.26046802407398795 | validation: 0.2654047390834562]
	TIME [epoch: 10.2 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2553766287756944		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.2553766287756944 | validation: 0.29567252972159913]
	TIME [epoch: 10.2 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23648942416408372		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.23648942416408372 | validation: 0.2970398066770699]
	TIME [epoch: 10.2 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2578150553069197		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.2578150553069197 | validation: 0.3148028120548298]
	TIME [epoch: 10.2 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2935232597636053		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.2935232597636053 | validation: 0.2909462597770585]
	TIME [epoch: 10.2 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23853092684128124		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.23853092684128124 | validation: 0.28030597466456375]
	TIME [epoch: 10.2 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2605004489787466		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.2605004489787466 | validation: 0.2763884163617946]
	TIME [epoch: 10.2 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21234306382654858		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.21234306382654858 | validation: 0.27740822817947847]
	TIME [epoch: 10.2 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22605533454499965		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.22605533454499965 | validation: 0.28080444035221247]
	TIME [epoch: 10.2 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2387925539528121		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.2387925539528121 | validation: 0.26530081949910267]
	TIME [epoch: 10.2 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23886239327487976		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.23886239327487976 | validation: 0.2911858390463182]
	TIME [epoch: 10.2 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25889296179593424		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.25889296179593424 | validation: 0.3267611918522262]
	TIME [epoch: 10.2 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23843316112215981		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.23843316112215981 | validation: 0.2716581950870162]
	TIME [epoch: 10.2 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22958411752339627		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.22958411752339627 | validation: 0.2627501058451947]
	TIME [epoch: 10.2 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22734462115397217		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.22734462115397217 | validation: 0.27137310157132033]
	TIME [epoch: 10.2 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22242650511708922		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.22242650511708922 | validation: 0.2609521402147469]
	TIME [epoch: 10.2 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2579777933553072		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.2579777933553072 | validation: 0.2766302677958063]
	TIME [epoch: 10.2 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23481275395647513		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.23481275395647513 | validation: 0.3198586110608753]
	TIME [epoch: 10.2 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24200374668979213		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.24200374668979213 | validation: 0.27165096094879937]
	TIME [epoch: 10.2 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2251198577136056		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.2251198577136056 | validation: 0.2702238361207686]
	TIME [epoch: 10.2 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23321758716649638		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.23321758716649638 | validation: 0.29484880625741056]
	TIME [epoch: 10.2 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24453893270402077		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.24453893270402077 | validation: 0.35215073902882915]
	TIME [epoch: 10.2 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26390988373404245		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.26390988373404245 | validation: 0.27610243774234655]
	TIME [epoch: 10.2 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2335692408755714		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.2335692408755714 | validation: 0.2763730867309647]
	TIME [epoch: 10.2 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23321098123449038		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.23321098123449038 | validation: 0.2657164771539511]
	TIME [epoch: 10.2 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23352543100138395		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.23352543100138395 | validation: 0.28934139231985306]
	TIME [epoch: 10.2 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2431468908884394		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.2431468908884394 | validation: 0.31796163862683574]
	TIME [epoch: 10.2 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2264543330212095		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.2264543330212095 | validation: 0.27011624458246447]
	TIME [epoch: 10.2 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2783954087485142		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.2783954087485142 | validation: 0.3593581263707955]
	TIME [epoch: 10.2 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30493340737776153		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.30493340737776153 | validation: 0.25210160908972945]
	TIME [epoch: 10.2 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22782621647994766		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.22782621647994766 | validation: 0.3386287904722559]
	TIME [epoch: 10.2 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042834923696005		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.3042834923696005 | validation: 0.2977000535553341]
	TIME [epoch: 10.2 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35154190235837934		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.35154190235837934 | validation: 0.43071477569549693]
	TIME [epoch: 10.2 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3549252356678762		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.3549252356678762 | validation: 0.27691809977533915]
	TIME [epoch: 10.2 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28691712879066295		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.28691712879066295 | validation: 0.29697360396049355]
	TIME [epoch: 10.2 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2956018585185188		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.2956018585185188 | validation: 0.34328748939436]
	TIME [epoch: 10.2 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28639754247185856		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.28639754247185856 | validation: 0.2519620731470743]
	TIME [epoch: 10.2 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22889721514735273		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.22889721514735273 | validation: 0.2917593499761156]
	TIME [epoch: 10.2 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24186726033271988		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.24186726033271988 | validation: 0.35592240461711944]
	TIME [epoch: 10.2 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638208279353565		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.2638208279353565 | validation: 0.2742322535765778]
	TIME [epoch: 10.2 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25322385206324965		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.25322385206324965 | validation: 0.26595884439428935]
	TIME [epoch: 10.2 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2344402781141805		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.2344402781141805 | validation: 0.2742641424835985]
	TIME [epoch: 10.2 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23045257201735128		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.23045257201735128 | validation: 0.2890114976429285]
	TIME [epoch: 10.2 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27633849034978025		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.27633849034978025 | validation: 0.3803066811481541]
	TIME [epoch: 10.2 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4863428930941752		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.4863428930941752 | validation: 0.48687671540960453]
	TIME [epoch: 10.2 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39783734032387175		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.39783734032387175 | validation: 0.34501735906695424]
	TIME [epoch: 10.2 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30412009706906046		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.30412009706906046 | validation: 0.3120780046810834]
	TIME [epoch: 10.2 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26176417241006483		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.26176417241006483 | validation: 0.32994983470620026]
	TIME [epoch: 10.2 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638626913083241		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.2638626913083241 | validation: 0.28471217162123064]
	TIME [epoch: 10.2 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21861241698771794		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.21861241698771794 | validation: 0.27202969143231437]
	TIME [epoch: 10.2 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.247391072329664		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.247391072329664 | validation: 0.28646669703177946]
	TIME [epoch: 10.2 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2238221065625252		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.2238221065625252 | validation: 0.25987079013974773]
	TIME [epoch: 10.2 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2547818380226691		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.2547818380226691 | validation: 0.3385239133074579]
	TIME [epoch: 10.2 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27967570719690815		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.27967570719690815 | validation: 0.3661088270272103]
	TIME [epoch: 10.2 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2926629145831843		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.2926629145831843 | validation: 0.32388004528952324]
	TIME [epoch: 10.2 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24710569391092796		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.24710569391092796 | validation: 0.2742154120346352]
	TIME [epoch: 10.2 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205804252704305		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.2205804252704305 | validation: 0.29629484208640083]
	TIME [epoch: 10.2 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30866093209921186		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.30866093209921186 | validation: 0.35180460053647833]
	TIME [epoch: 10.2 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34449880269637057		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.34449880269637057 | validation: 0.4693750230412897]
	TIME [epoch: 10.2 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43264432813531306		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.43264432813531306 | validation: 0.42024885378208593]
	TIME [epoch: 10.2 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34621139776925897		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.34621139776925897 | validation: 0.41827941550508146]
	TIME [epoch: 10.2 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3127274174317058		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.3127274174317058 | validation: 0.39158731257950935]
	TIME [epoch: 10.2 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086899141640926		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.3086899141640926 | validation: 0.39292465628446976]
	TIME [epoch: 10.2 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31517194399748366		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.31517194399748366 | validation: 0.37106782285896645]
	TIME [epoch: 10.2 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29543424676127406		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.29543424676127406 | validation: 0.3511453570176353]
	TIME [epoch: 10.2 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2838040150284701		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.2838040150284701 | validation: 0.31741568186006464]
	TIME [epoch: 10.2 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2549849395959055		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.2549849395959055 | validation: 0.3162807266523715]
	TIME [epoch: 10.2 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26262472201092507		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.26262472201092507 | validation: 0.3205336478595095]
	TIME [epoch: 10.2 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2615537666215418		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.2615537666215418 | validation: 0.3316303037253479]
	TIME [epoch: 10.2 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2550444365118768		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.2550444365118768 | validation: 0.29016291989939785]
	TIME [epoch: 10.2 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2565318196676579		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.2565318196676579 | validation: 0.35291982576738995]
	TIME [epoch: 10.2 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31196145913050527		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.31196145913050527 | validation: 0.36262419190829176]
	TIME [epoch: 10.2 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059374052460686		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.3059374052460686 | validation: 0.3328089875723926]
	TIME [epoch: 10.2 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27256425383267224		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.27256425383267224 | validation: 0.2976796133403806]
	TIME [epoch: 10.2 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24811260207886487		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.24811260207886487 | validation: 0.2882957218681524]
	TIME [epoch: 10.2 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2250325900136226		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.2250325900136226 | validation: 0.29545646970590234]
	TIME [epoch: 10.2 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.240124920163359		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.240124920163359 | validation: 0.32487839112049643]
	TIME [epoch: 10.2 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2521326674273703		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.2521326674273703 | validation: 0.3460732525430825]
	TIME [epoch: 10.2 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2709342223875766		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.2709342223875766 | validation: 0.30228462469422035]
	TIME [epoch: 10.2 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24390557792585574		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.24390557792585574 | validation: 0.3488260879107453]
	TIME [epoch: 10.2 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2441878642321233		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.2441878642321233 | validation: 0.2696605222025744]
	TIME [epoch: 10.2 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27638519408178636		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.27638519408178636 | validation: 0.3195607976818913]
	TIME [epoch: 10.2 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24986080199955651		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.24986080199955651 | validation: 0.3490781639129871]
	TIME [epoch: 10.2 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2557972941621788		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.2557972941621788 | validation: 0.27374417086760827]
	TIME [epoch: 10.2 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22588688531642095		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.22588688531642095 | validation: 0.2752532103127577]
	TIME [epoch: 10.2 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22758621724837616		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.22758621724837616 | validation: 0.2720771189420921]
	TIME [epoch: 10.2 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2388629611477798		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.2388629611477798 | validation: 0.3100756318371728]
	TIME [epoch: 10.2 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054496472636631		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.3054496472636631 | validation: 0.35792112817215854]
	TIME [epoch: 10.2 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30157905930229534		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.30157905930229534 | validation: 0.35532399994654174]
	TIME [epoch: 10.2 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2722747392092678		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.2722747392092678 | validation: 0.27969187222391406]
	TIME [epoch: 10.2 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24637663664992301		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.24637663664992301 | validation: 0.27288673951003395]
	TIME [epoch: 10.2 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243776128578273		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.243776128578273 | validation: 0.3400610791204753]
	TIME [epoch: 10.2 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33762167836015367		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.33762167836015367 | validation: 0.3464052225786454]
	TIME [epoch: 10.2 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27290902482550755		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.27290902482550755 | validation: 0.2248461735644911]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1414.pth
	Model improved!!!
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2044694573081301		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.2044694573081301 | validation: 0.26248197564802417]
	TIME [epoch: 10.2 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2537467815181741		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.2537467815181741 | validation: 0.27962597483222756]
	TIME [epoch: 10.2 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26181873793491334		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.26181873793491334 | validation: 0.300494078437064]
	TIME [epoch: 10.2 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29793906423599487		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.29793906423599487 | validation: 0.38938528494592617]
	TIME [epoch: 10.2 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2736884948218207		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.2736884948218207 | validation: 0.2450741341536122]
	TIME [epoch: 10.2 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.211643977455172		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.211643977455172 | validation: 0.2864630729789273]
	TIME [epoch: 10.2 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3044695354481495		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.3044695354481495 | validation: 0.3984584707608508]
	TIME [epoch: 10.2 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34197999733063467		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.34197999733063467 | validation: 0.27445911795124156]
	TIME [epoch: 10.2 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2238219694611209		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.2238219694611209 | validation: 0.2731933181589306]
	TIME [epoch: 10.2 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2182734905488067		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.2182734905488067 | validation: 0.25103720374064503]
	TIME [epoch: 10.2 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27210220006608077		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.27210220006608077 | validation: 0.25514843163302275]
	TIME [epoch: 10.2 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2344533223419362		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.2344533223419362 | validation: 0.2929070558405459]
	TIME [epoch: 10.2 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2484169907811488		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.2484169907811488 | validation: 0.26432204000230586]
	TIME [epoch: 10.2 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2342511561281798		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.2342511561281798 | validation: 0.2754739043267542]
	TIME [epoch: 10.2 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27800311946613526		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.27800311946613526 | validation: 0.353055110616161]
	TIME [epoch: 10.2 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35766841842018476		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.35766841842018476 | validation: 0.30311675771334434]
	TIME [epoch: 10.2 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26526660011581027		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.26526660011581027 | validation: 0.24692363706661705]
	TIME [epoch: 10.2 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23117642998798082		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.23117642998798082 | validation: 0.2993493524873319]
	TIME [epoch: 10.2 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25165737297961915		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.25165737297961915 | validation: 0.26527410034950594]
	TIME [epoch: 10.2 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25201860928594344		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.25201860928594344 | validation: 0.32875296553811256]
	TIME [epoch: 10.2 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27519626411074727		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.27519626411074727 | validation: 0.2944662722085636]
	TIME [epoch: 10.2 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2668910953020568		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.2668910953020568 | validation: 0.3365885739625544]
	TIME [epoch: 10.2 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29110326790948615		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.29110326790948615 | validation: 0.2830090681264807]
	TIME [epoch: 10.2 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21470314034396445		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.21470314034396445 | validation: 0.2702268575080266]
	TIME [epoch: 10.2 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2742461657162438		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.2742461657162438 | validation: 0.34513452829736785]
	TIME [epoch: 10.2 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41603707005688795		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.41603707005688795 | validation: 0.3839159437516237]
	TIME [epoch: 10.2 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3210716742682089		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.3210716742682089 | validation: 0.3324617641486906]
	TIME [epoch: 10.2 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3661402517763327		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.3661402517763327 | validation: 0.351679439414487]
	TIME [epoch: 10.2 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285963834079291		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.3285963834079291 | validation: 0.26377628680498744]
	TIME [epoch: 10.2 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2724319769541993		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.2724319769541993 | validation: 0.2956609301233813]
	TIME [epoch: 10.2 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2466913757395738		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.2466913757395738 | validation: 0.2819085697189071]
	TIME [epoch: 10.2 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23230882586022386		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.23230882586022386 | validation: 0.25811129516633907]
	TIME [epoch: 10.2 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23531696724821027		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.23531696724821027 | validation: 0.28452608619343445]
	TIME [epoch: 10.2 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24170092490951073		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.24170092490951073 | validation: 0.24144144849354968]
	TIME [epoch: 10.2 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29035953591975844		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.29035953591975844 | validation: 0.3686969590734404]
	TIME [epoch: 10.2 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31975597371592157		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.31975597371592157 | validation: 0.3369329176375026]
	TIME [epoch: 10.2 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26781604846138124		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.26781604846138124 | validation: 0.2646095176361646]
	TIME [epoch: 10.2 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21605394575264153		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.21605394575264153 | validation: 0.2582911106346786]
	TIME [epoch: 10.2 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26040435013999574		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.26040435013999574 | validation: 0.3073475995946956]
	TIME [epoch: 10.2 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24975638823052906		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.24975638823052906 | validation: 0.2837987565172622]
	TIME [epoch: 10.2 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22367407288387992		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.22367407288387992 | validation: 0.25868513359053436]
	TIME [epoch: 10.2 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2289975576255264		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.2289975576255264 | validation: 0.24898458959741795]
	TIME [epoch: 10.2 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21585457993315565		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.21585457993315565 | validation: 0.22999826570454304]
	TIME [epoch: 10.2 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22001105565283274		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.22001105565283274 | validation: 0.27093243226891295]
	TIME [epoch: 10.2 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21409546305794178		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.21409546305794178 | validation: 0.2884406503906185]
	TIME [epoch: 10.2 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24310540170557243		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.24310540170557243 | validation: 0.24440616543481475]
	TIME [epoch: 10.2 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2262129877241616		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.2262129877241616 | validation: 0.33961164395329024]
	TIME [epoch: 10.2 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28224581384578756		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.28224581384578756 | validation: 0.3014962766326999]
	TIME [epoch: 10.2 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2983056095191479		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.2983056095191479 | validation: 0.2865248116529102]
	TIME [epoch: 10.2 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24041362009864983		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.24041362009864983 | validation: 0.2656344521958682]
	TIME [epoch: 10.2 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22950241707712182		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.22950241707712182 | validation: 0.2590405103101513]
	TIME [epoch: 10.2 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21463276195571762		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.21463276195571762 | validation: 0.25691335442004126]
	TIME [epoch: 10.2 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22269543530320696		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.22269543530320696 | validation: 0.2595447369973607]
	TIME [epoch: 10.2 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21762758875047203		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.21762758875047203 | validation: 0.26371061686595376]
	TIME [epoch: 10.2 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23150695099927746		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.23150695099927746 | validation: 0.3119570700780884]
	TIME [epoch: 10.2 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28362896852498193		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.28362896852498193 | validation: 0.326066528492605]
	TIME [epoch: 10.2 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507237859984221		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.2507237859984221 | validation: 0.2616609613197767]
	TIME [epoch: 10.2 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22207784433078448		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.22207784433078448 | validation: 0.28694358338434833]
	TIME [epoch: 10.2 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22030453635834238		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.22030453635834238 | validation: 0.26972427981126507]
	TIME [epoch: 10.2 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24021714717093898		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.24021714717093898 | validation: 0.29034277173571815]
	TIME [epoch: 10.2 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131691874904589		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.3131691874904589 | validation: 0.42116412055431507]
	TIME [epoch: 10.2 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3278581656729622		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.3278581656729622 | validation: 0.287001268278598]
	TIME [epoch: 10.2 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24141998325060188		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.24141998325060188 | validation: 0.24518075011057272]
	TIME [epoch: 10.2 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24050316689232468		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.24050316689232468 | validation: 0.3339484950980976]
	TIME [epoch: 10.2 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2793769355385548		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.2793769355385548 | validation: 0.31685988550599]
	TIME [epoch: 10.2 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24127064918217084		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.24127064918217084 | validation: 0.2525958891864227]
	TIME [epoch: 10.2 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22393116360987392		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.22393116360987392 | validation: 0.2628579434797551]
	TIME [epoch: 10.2 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22243147004134337		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.22243147004134337 | validation: 0.2657418327624513]
	TIME [epoch: 10.2 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21120244521808096		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.21120244521808096 | validation: 0.2814142652723335]
	TIME [epoch: 10.2 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26911234378066773		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.26911234378066773 | validation: 0.24728509022904682]
	TIME [epoch: 10.2 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21501513852221196		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.21501513852221196 | validation: 0.24330215691043353]
	TIME [epoch: 10.2 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21319287589115232		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.21319287589115232 | validation: 0.28475365689176907]
	TIME [epoch: 10.2 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21927437004366976		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.21927437004366976 | validation: 0.28583484562667383]
	TIME [epoch: 10.2 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19790385738718713		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.19790385738718713 | validation: 0.2987431265818558]
	TIME [epoch: 10.2 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22949985636954096		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.22949985636954096 | validation: 0.24717427370454892]
	TIME [epoch: 10.2 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22604805815043666		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.22604805815043666 | validation: 0.2436445109221353]
	TIME [epoch: 10.2 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1970851938079689		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.1970851938079689 | validation: 0.2675830124440844]
	TIME [epoch: 10.2 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2284126544959752		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.2284126544959752 | validation: 0.3011629636151957]
	TIME [epoch: 10.2 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24099921300198357		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.24099921300198357 | validation: 0.2789243655306914]
	TIME [epoch: 10.2 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23406230549721987		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.23406230549721987 | validation: 0.2583869569139047]
	TIME [epoch: 10.2 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2503476455678849		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.2503476455678849 | validation: 0.23405787100796852]
	TIME [epoch: 10.2 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19692721261464846		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.19692721261464846 | validation: 0.26378258217223244]
	TIME [epoch: 10.2 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22406891093433695		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.22406891093433695 | validation: 0.24796699040407372]
	TIME [epoch: 10.2 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27383421721490464		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.27383421721490464 | validation: 0.310043178323416]
	TIME [epoch: 10.2 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26793384736042525		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.26793384736042525 | validation: 0.2875518271936216]
	TIME [epoch: 10.2 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22992106486067043		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.22992106486067043 | validation: 0.29339348553812655]
	TIME [epoch: 10.2 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22781125651096362		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.22781125651096362 | validation: 0.23334538687022324]
	TIME [epoch: 10.2 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2156296115853885		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.2156296115853885 | validation: 0.26929358004972714]
	TIME [epoch: 10.2 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23730716899560078		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.23730716899560078 | validation: 0.2580647618952926]
	TIME [epoch: 10.2 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21335964767691587		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.21335964767691587 | validation: 0.24792628918790996]
	TIME [epoch: 10.2 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2143804639340566		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.2143804639340566 | validation: 0.21946447503212216]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1505.pth
	Model improved!!!
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937292520015193		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.1937292520015193 | validation: 0.235015028424261]
	TIME [epoch: 10.2 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19753428864536512		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.19753428864536512 | validation: 0.24661299081241936]
	TIME [epoch: 10.2 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2012766858904623		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.2012766858904623 | validation: 0.24936525533670492]
	TIME [epoch: 10.2 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21486918519745962		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.21486918519745962 | validation: 0.22969334666409608]
	TIME [epoch: 10.2 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20068149228659288		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.20068149228659288 | validation: 0.26650044281531493]
	TIME [epoch: 10.2 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22062800594990217		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.22062800594990217 | validation: 0.25336554668486577]
	TIME [epoch: 10.2 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21518942759652182		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.21518942759652182 | validation: 0.2624393173159767]
	TIME [epoch: 10.2 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20682865511882076		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.20682865511882076 | validation: 0.2368381393775394]
	TIME [epoch: 10.2 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20022365925282246		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.20022365925282246 | validation: 0.2309899929066732]
	TIME [epoch: 10.2 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19763218172837452		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.19763218172837452 | validation: 0.22027325122277383]
	TIME [epoch: 10.2 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20333636227581686		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.20333636227581686 | validation: 0.26564220749576556]
	TIME [epoch: 10.2 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20192468716938228		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.20192468716938228 | validation: 0.2654996613845582]
	TIME [epoch: 10.2 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271620761645882		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.2271620761645882 | validation: 0.2797213163689266]
	TIME [epoch: 10.2 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21682152953729977		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.21682152953729977 | validation: 0.2357935385442682]
	TIME [epoch: 10.2 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19484284486888148		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.19484284486888148 | validation: 0.24735617089828985]
	TIME [epoch: 10.2 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183640736430342		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.2183640736430342 | validation: 0.28295383872713964]
	TIME [epoch: 10.2 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2633355884214047		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.2633355884214047 | validation: 0.3271430878340489]
	TIME [epoch: 10.2 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2421011001909105		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.2421011001909105 | validation: 0.2477870523392675]
	TIME [epoch: 10.2 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20754593928685847		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.20754593928685847 | validation: 0.22107117836344514]
	TIME [epoch: 10.2 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20664970293162846		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.20664970293162846 | validation: 0.3001152834153277]
	TIME [epoch: 10.2 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2072082998639663		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.2072082998639663 | validation: 0.24532003964833402]
	TIME [epoch: 10.2 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21956182741178001		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.21956182741178001 | validation: 0.2529079592198004]
	TIME [epoch: 10.2 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1971100652688343		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.1971100652688343 | validation: 0.22611816426215392]
	TIME [epoch: 10.2 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1909222232450484		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.1909222232450484 | validation: 0.2249805602827297]
	TIME [epoch: 10.2 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20914369965123533		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.20914369965123533 | validation: 0.26727060221985843]
	TIME [epoch: 10.2 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20505990867204912		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.20505990867204912 | validation: 0.24795076926615772]
	TIME [epoch: 10.2 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21174174781899824		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.21174174781899824 | validation: 0.21188878971565864]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1532.pth
	Model improved!!!
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21244680139205147		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.21244680139205147 | validation: 0.2869897072502371]
	TIME [epoch: 10.2 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.246671807782131		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.246671807782131 | validation: 0.2550372686788446]
	TIME [epoch: 10.2 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20617883857428126		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.20617883857428126 | validation: 0.23632183750469085]
	TIME [epoch: 10.2 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913072917996809		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.1913072917996809 | validation: 0.22262679438796876]
	TIME [epoch: 10.2 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19731617004049218		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.19731617004049218 | validation: 0.24049299174323996]
	TIME [epoch: 10.2 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19693753386655363		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.19693753386655363 | validation: 0.26199070970255267]
	TIME [epoch: 10.2 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20697930081621543		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.20697930081621543 | validation: 0.24368074440827348]
	TIME [epoch: 10.2 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17944614093767908		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.17944614093767908 | validation: 0.2517012669330442]
	TIME [epoch: 10.2 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19629859730914553		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.19629859730914553 | validation: 0.23190499050150762]
	TIME [epoch: 10.2 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20631566689731465		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.20631566689731465 | validation: 0.24478348765998972]
	TIME [epoch: 10.2 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084311861941583		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.2084311861941583 | validation: 0.22600779248019842]
	TIME [epoch: 10.2 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20573007892622433		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.20573007892622433 | validation: 0.23808488449960372]
	TIME [epoch: 10.2 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1957045407755442		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.1957045407755442 | validation: 0.26432734739343955]
	TIME [epoch: 10.2 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.212451070541895		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.212451070541895 | validation: 0.2808047159886273]
	TIME [epoch: 10.2 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21279790921525885		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.21279790921525885 | validation: 0.27152011437253054]
	TIME [epoch: 10.2 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23731770472282196		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.23731770472282196 | validation: 0.30079649485182364]
	TIME [epoch: 10.2 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20361299635918137		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.20361299635918137 | validation: 0.25796846105446253]
	TIME [epoch: 10.2 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19683493588364218		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.19683493588364218 | validation: 0.24419973995205382]
	TIME [epoch: 10.2 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1864058324429468		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.1864058324429468 | validation: 0.2502911894955545]
	TIME [epoch: 10.2 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20201286803489057		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.20201286803489057 | validation: 0.2830622424938868]
	TIME [epoch: 10.2 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21138558081715395		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.21138558081715395 | validation: 0.2434810699090616]
	TIME [epoch: 10.2 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.195624190883278		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.195624190883278 | validation: 0.23360806808015322]
	TIME [epoch: 10.2 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18127873841659176		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.18127873841659176 | validation: 0.26638050831617277]
	TIME [epoch: 10.2 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009262577561451		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.2009262577561451 | validation: 0.247339675773927]
	TIME [epoch: 10.2 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18400706713264103		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.18400706713264103 | validation: 0.25698968515031695]
	TIME [epoch: 10.2 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18701560165514278		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.18701560165514278 | validation: 0.25228397059935675]
	TIME [epoch: 10.2 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21741782900796175		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.21741782900796175 | validation: 0.2896048170837256]
	TIME [epoch: 10.2 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22191937821110636		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.22191937821110636 | validation: 0.2600999799219528]
	TIME [epoch: 10.2 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22324496366240876		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.22324496366240876 | validation: 0.26487505343593004]
	TIME [epoch: 10.2 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20683410478888292		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.20683410478888292 | validation: 0.2536188779919143]
	TIME [epoch: 10.2 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19212368290080756		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.19212368290080756 | validation: 0.2536249860323406]
	TIME [epoch: 10.2 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20587840455631815		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.20587840455631815 | validation: 0.2739549893217973]
	TIME [epoch: 10.2 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22422491021847782		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.22422491021847782 | validation: 0.2563198314365354]
	TIME [epoch: 10.2 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19850145239413772		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.19850145239413772 | validation: 0.23343424111696812]
	TIME [epoch: 10.2 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2019624407073651		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.2019624407073651 | validation: 0.2943992654096807]
	TIME [epoch: 10.2 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23667076646358956		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.23667076646358956 | validation: 0.25746644533024254]
	TIME [epoch: 10.2 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20284163087002094		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.20284163087002094 | validation: 0.3122314505428019]
	TIME [epoch: 10.2 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24990659856352077		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.24990659856352077 | validation: 0.24404731541172855]
	TIME [epoch: 10.2 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24384694528369977		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.24384694528369977 | validation: 0.2429404480902399]
	TIME [epoch: 10.2 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2033125498807901		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.2033125498807901 | validation: 0.26746915940556726]
	TIME [epoch: 10.2 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20547332193261547		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.20547332193261547 | validation: 0.2764901381203928]
	TIME [epoch: 10.2 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19621039416123823		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.19621039416123823 | validation: 0.2642189698269589]
	TIME [epoch: 10.2 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20479805391252537		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.20479805391252537 | validation: 0.25638979708650267]
	TIME [epoch: 10.2 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22977075885015824		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.22977075885015824 | validation: 0.24975806965878733]
	TIME [epoch: 10.2 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18743947299723482		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.18743947299723482 | validation: 0.25649454784297826]
	TIME [epoch: 10.2 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20818969393929515		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.20818969393929515 | validation: 0.23659733589275306]
	TIME [epoch: 10.2 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200542963042732		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.200542963042732 | validation: 0.2553625470801431]
	TIME [epoch: 10.2 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19536115107812102		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.19536115107812102 | validation: 0.2132556786416455]
	TIME [epoch: 10.2 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19109297301675485		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.19109297301675485 | validation: 0.2524038394378764]
	TIME [epoch: 10.2 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1807858976420093		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.1807858976420093 | validation: 0.24627484469522426]
	TIME [epoch: 10.2 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19855663684622757		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.19855663684622757 | validation: 0.2508404236826233]
	TIME [epoch: 10.2 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1883022955086422		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.1883022955086422 | validation: 0.23413284216616814]
	TIME [epoch: 10.2 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18853135656222136		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.18853135656222136 | validation: 0.22593559845391273]
	TIME [epoch: 10.2 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805613022728167		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.1805613022728167 | validation: 0.23493966353831736]
	TIME [epoch: 10.2 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19755538767319974		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.19755538767319974 | validation: 0.2867579193751717]
	TIME [epoch: 10.2 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2083413063197737		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.2083413063197737 | validation: 0.2795896256574514]
	TIME [epoch: 10.2 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.216637966519765		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.216637966519765 | validation: 0.27560317560377856]
	TIME [epoch: 10.2 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21365733896575864		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.21365733896575864 | validation: 0.2528530873021841]
	TIME [epoch: 10.2 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18520271139470398		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.18520271139470398 | validation: 0.26448805868259917]
	TIME [epoch: 10.2 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18947273564661188		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.18947273564661188 | validation: 0.2515772086984099]
	TIME [epoch: 10.2 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885895710937961		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.1885895710937961 | validation: 0.23603316469140626]
	TIME [epoch: 10.2 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1925084519351939		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.1925084519351939 | validation: 0.2553087370918606]
	TIME [epoch: 10.2 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18586808068421248		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.18586808068421248 | validation: 0.28053109913611024]
	TIME [epoch: 10.2 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20272643911095187		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.20272643911095187 | validation: 0.28111887900893906]
	TIME [epoch: 10.2 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19378900815019137		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.19378900815019137 | validation: 0.26056155240162965]
	TIME [epoch: 10.2 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19355553472300202		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.19355553472300202 | validation: 0.26200777421079413]
	TIME [epoch: 10.2 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19238464018599816		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.19238464018599816 | validation: 0.23505832281786912]
	TIME [epoch: 10.2 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2062561164075075		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.2062561164075075 | validation: 0.27866469127724197]
	TIME [epoch: 10.2 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018119329849108		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.2018119329849108 | validation: 0.2707373650889149]
	TIME [epoch: 10.2 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22553173178339883		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.22553173178339883 | validation: 0.2810890492278175]
	TIME [epoch: 10.2 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24800575401708008		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.24800575401708008 | validation: 0.30341531690179985]
	TIME [epoch: 10.2 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22435042897918578		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.22435042897918578 | validation: 0.2870150019969582]
	TIME [epoch: 10.2 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21251854777405402		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.21251854777405402 | validation: 0.24984487358282828]
	TIME [epoch: 10.2 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2164967330042209		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.2164967330042209 | validation: 0.2651489502916838]
	TIME [epoch: 10.2 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2169579445912475		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.2169579445912475 | validation: 0.2961157595564281]
	TIME [epoch: 10.2 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25629861094804257		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.25629861094804257 | validation: 0.30925985960647207]
	TIME [epoch: 10.2 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700343680875025		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.2700343680875025 | validation: 0.3031966555138642]
	TIME [epoch: 10.2 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23792125565040237		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.23792125565040237 | validation: 0.28917779209976485]
	TIME [epoch: 10.2 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205305131348559		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.205305131348559 | validation: 0.2519001308591753]
	TIME [epoch: 10.2 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20593339321362839		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.20593339321362839 | validation: 0.30651143021096366]
	TIME [epoch: 10.2 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19818410572403578		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.19818410572403578 | validation: 0.2449578232808668]
	TIME [epoch: 10.2 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19765981849991593		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.19765981849991593 | validation: 0.2634778131754672]
	TIME [epoch: 10.2 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20926865124517838		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.20926865124517838 | validation: 0.27349647603230454]
	TIME [epoch: 10.2 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18869765264903662		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.18869765264903662 | validation: 0.26350866651060595]
	TIME [epoch: 10.2 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1958841688763198		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.1958841688763198 | validation: 0.26768253161610156]
	TIME [epoch: 10.2 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19976956991491363		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.19976956991491363 | validation: 0.279236623071256]
	TIME [epoch: 10.2 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20897077352413168		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.20897077352413168 | validation: 0.28102035760429983]
	TIME [epoch: 10.2 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20156327774577543		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.20156327774577543 | validation: 0.267456016947375]
	TIME [epoch: 10.2 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19509590740212313		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.19509590740212313 | validation: 0.2783729482960277]
	TIME [epoch: 10.2 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21345559826963667		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.21345559826963667 | validation: 0.26133643487682373]
	TIME [epoch: 10.2 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20161779839389168		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.20161779839389168 | validation: 0.2689160752997474]
	TIME [epoch: 10.2 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.202952615592566		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.202952615592566 | validation: 0.2827769845045952]
	TIME [epoch: 10.2 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23592984097977543		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.23592984097977543 | validation: 0.30260105103579227]
	TIME [epoch: 10.2 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2413377937559988		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.2413377937559988 | validation: 0.3242387665658534]
	TIME [epoch: 10.2 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21514931059437203		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.21514931059437203 | validation: 0.26713312319277854]
	TIME [epoch: 10.2 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18825798131042099		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.18825798131042099 | validation: 0.25082747384094045]
	TIME [epoch: 10.2 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18809180870344402		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.18809180870344402 | validation: 0.23014051544695982]
	TIME [epoch: 10.2 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17054788399398935		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.17054788399398935 | validation: 0.24654637869248622]
	TIME [epoch: 10.2 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18195944288027022		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.18195944288027022 | validation: 0.23864722460660515]
	TIME [epoch: 10.2 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18417449618157394		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.18417449618157394 | validation: 0.22986298512681774]
	TIME [epoch: 10.2 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17955661233236758		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.17955661233236758 | validation: 0.24643062955816183]
	TIME [epoch: 10.2 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1791031442959333		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.1791031442959333 | validation: 0.2404559793691872]
	TIME [epoch: 10.2 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17411300975808483		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.17411300975808483 | validation: 0.24249770809010096]
	TIME [epoch: 10.2 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18412758650027578		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.18412758650027578 | validation: 0.23137097043243757]
	TIME [epoch: 10.2 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18900977621625664		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.18900977621625664 | validation: 0.25773549977207943]
	TIME [epoch: 10.2 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19933580750088614		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.19933580750088614 | validation: 0.2416317116543185]
	TIME [epoch: 10.2 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19706742506531336		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.19706742506531336 | validation: 0.2535675300559212]
	TIME [epoch: 10.2 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18972356335023788		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.18972356335023788 | validation: 0.24004299545774035]
	TIME [epoch: 10.2 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17138561468762975		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.17138561468762975 | validation: 0.2500678994148877]
	TIME [epoch: 10.2 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22426264416518418		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.22426264416518418 | validation: 0.26940883598035587]
	TIME [epoch: 10.2 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299662569280086		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.2299662569280086 | validation: 0.23695710584695767]
	TIME [epoch: 10.2 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19931340770558043		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.19931340770558043 | validation: 0.23845112509495228]
	TIME [epoch: 10.2 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1870808856162573		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.1870808856162573 | validation: 0.2532660834730795]
	TIME [epoch: 10.2 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20790713310430595		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.20790713310430595 | validation: 0.24472825851972319]
	TIME [epoch: 10.2 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19064390992946206		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.19064390992946206 | validation: 0.2198544774301849]
	TIME [epoch: 10.2 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1868888456171091		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.1868888456171091 | validation: 0.23067779719494014]
	TIME [epoch: 10.2 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2048230107616928		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.2048230107616928 | validation: 0.2590596097934643]
	TIME [epoch: 10.2 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.226293860398756		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.226293860398756 | validation: 0.2398449929366138]
	TIME [epoch: 10.2 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1994948329534781		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.1994948329534781 | validation: 0.2580213724255595]
	TIME [epoch: 10.2 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21874658383258527		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.21874658383258527 | validation: 0.2836860421137466]
	TIME [epoch: 10.2 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22533793740663421		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.22533793740663421 | validation: 0.24285574847510163]
	TIME [epoch: 10.2 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20070272408228843		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.20070272408228843 | validation: 0.22651446082762142]
	TIME [epoch: 10.2 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21308448188467852		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.21308448188467852 | validation: 0.24209388353351993]
	TIME [epoch: 10.2 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19596042320535345		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.19596042320535345 | validation: 0.24039617447702719]
	TIME [epoch: 10.2 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18810084427163046		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.18810084427163046 | validation: 0.27199201599809125]
	TIME [epoch: 10.2 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20064524632572303		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.20064524632572303 | validation: 0.2403211667642848]
	TIME [epoch: 10.2 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21673941745627845		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.21673941745627845 | validation: 0.26869366465712646]
	TIME [epoch: 10.2 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19496229056452577		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.19496229056452577 | validation: 0.2522691737726365]
	TIME [epoch: 10.2 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20012286245587269		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.20012286245587269 | validation: 0.26689854498234633]
	TIME [epoch: 10.2 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21813718024548195		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.21813718024548195 | validation: 0.22490991347464587]
	TIME [epoch: 10.2 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19013451763824818		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.19013451763824818 | validation: 0.2600846460494932]
	TIME [epoch: 10.2 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18935674321127402		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.18935674321127402 | validation: 0.22024026320887977]
	TIME [epoch: 10.2 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19379925561868272		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.19379925561868272 | validation: 0.2307372662127012]
	TIME [epoch: 10.2 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19514942015865938		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.19514942015865938 | validation: 0.22577951115833186]
	TIME [epoch: 10.2 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934335735170925		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.1934335735170925 | validation: 0.25367651373688715]
	TIME [epoch: 10.2 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2590399754796506		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.2590399754796506 | validation: 0.3162623799036981]
	TIME [epoch: 10.2 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.250374288749811		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.250374288749811 | validation: 0.28065768365871696]
	TIME [epoch: 10.2 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20145458469661137		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.20145458469661137 | validation: 0.2387631218726279]
	TIME [epoch: 10.2 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17577410362152504		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.17577410362152504 | validation: 0.24446338520270794]
	TIME [epoch: 10.2 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.182619569891264		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.182619569891264 | validation: 0.24180995620857984]
	TIME [epoch: 10.2 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17788987756232089		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.17788987756232089 | validation: 0.2316175946854975]
	TIME [epoch: 10.2 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18251380013449292		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.18251380013449292 | validation: 0.21506179391650615]
	TIME [epoch: 10.2 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18302453714874398		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.18302453714874398 | validation: 0.2302934243718744]
	TIME [epoch: 10.2 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18766090709910926		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.18766090709910926 | validation: 0.2452750645791597]
	TIME [epoch: 10.2 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1981833218577999		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.1981833218577999 | validation: 0.24428476180568673]
	TIME [epoch: 10.2 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20191213235852876		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.20191213235852876 | validation: 0.23632377227045567]
	TIME [epoch: 10.2 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20061474443697694		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.20061474443697694 | validation: 0.23992426176980083]
	TIME [epoch: 10.2 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18552625104912135		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.18552625104912135 | validation: 0.21694568661687147]
	TIME [epoch: 10.2 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882424119176942		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.1882424119176942 | validation: 0.2445444820029946]
	TIME [epoch: 10.2 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17845589768042958		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.17845589768042958 | validation: 0.23639918355181164]
	TIME [epoch: 10.2 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18726949221165992		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.18726949221165992 | validation: 0.23761301731593698]
	TIME [epoch: 10.2 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1777922683775151		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.1777922683775151 | validation: 0.19921944050469073]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1684.pth
	Model improved!!!
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18155597666792048		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.18155597666792048 | validation: 0.2377890086184346]
	TIME [epoch: 10.2 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19446277364712014		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.19446277364712014 | validation: 0.21452185953032832]
	TIME [epoch: 10.2 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18347386426462683		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.18347386426462683 | validation: 0.21851925950341208]
	TIME [epoch: 10.2 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16908630007492498		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.16908630007492498 | validation: 0.2431726052572946]
	TIME [epoch: 10.2 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17898083694389577		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.17898083694389577 | validation: 0.21554930015323925]
	TIME [epoch: 10.2 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18861433370535705		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.18861433370535705 | validation: 0.21157200912473195]
	TIME [epoch: 10.2 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20156012844398505		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.20156012844398505 | validation: 0.2504692312399595]
	TIME [epoch: 10.2 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17827788339974		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.17827788339974 | validation: 0.24457152560028397]
	TIME [epoch: 10.2 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1760338688922733		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.1760338688922733 | validation: 0.23918343774388692]
	TIME [epoch: 10.2 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18411470974892227		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.18411470974892227 | validation: 0.24357222296903266]
	TIME [epoch: 10.2 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19025637346529306		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.19025637346529306 | validation: 0.22381829942616022]
	TIME [epoch: 10.2 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23909730727107487		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.23909730727107487 | validation: 0.2972514946979012]
	TIME [epoch: 10.2 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2541215667172231		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.2541215667172231 | validation: 0.26382412170215325]
	TIME [epoch: 10.2 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23336950343632665		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.23336950343632665 | validation: 0.2817948116876168]
	TIME [epoch: 10.2 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2430735045462769		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.2430735045462769 | validation: 0.24877725826069758]
	TIME [epoch: 10.2 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21282738985041588		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.21282738985041588 | validation: 0.26660245763269125]
	TIME [epoch: 10.2 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2354086345406965		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.2354086345406965 | validation: 0.25075935123331183]
	TIME [epoch: 10.2 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19557809020776884		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.19557809020776884 | validation: 0.24534171564075538]
	TIME [epoch: 10.2 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18322375103169747		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.18322375103169747 | validation: 0.2432950714338575]
	TIME [epoch: 10.2 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19359043398832035		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.19359043398832035 | validation: 0.2379300178830549]
	TIME [epoch: 10.2 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19221226824908794		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.19221226824908794 | validation: 0.23202846743875363]
	TIME [epoch: 10.2 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19582638067645786		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.19582638067645786 | validation: 0.23580982999909578]
	TIME [epoch: 10.2 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1971398521410011		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.1971398521410011 | validation: 0.21961357474566384]
	TIME [epoch: 10.2 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1903633601112244		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.1903633601112244 | validation: 0.21388069641336152]
	TIME [epoch: 10.2 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21978209695037365		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.21978209695037365 | validation: 0.2682987672315693]
	TIME [epoch: 10.2 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23788410613489203		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.23788410613489203 | validation: 0.24354366144632159]
	TIME [epoch: 10.2 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2135223144016639		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.2135223144016639 | validation: 0.23767041950672935]
	TIME [epoch: 10.2 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18713421711761322		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.18713421711761322 | validation: 0.22123605936685678]
	TIME [epoch: 10.2 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17566300038767685		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.17566300038767685 | validation: 0.23445438930098766]
	TIME [epoch: 10.2 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19306547783107508		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.19306547783107508 | validation: 0.2505649017382001]
	TIME [epoch: 10.2 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20618383990706043		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.20618383990706043 | validation: 0.2576085830931457]
	TIME [epoch: 10.2 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20591470291420277		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.20591470291420277 | validation: 0.23638277566870927]
	TIME [epoch: 10.2 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19411600571250537		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.19411600571250537 | validation: 0.2504244757456404]
	TIME [epoch: 10.2 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20060379543647655		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.20060379543647655 | validation: 0.23213102931519414]
	TIME [epoch: 10.2 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20773500238037235		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.20773500238037235 | validation: 0.24993997353561576]
	TIME [epoch: 10.2 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2218795433035893		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.2218795433035893 | validation: 0.2667957277373632]
	TIME [epoch: 10.2 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21018151784313782		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.21018151784313782 | validation: 0.24292171667676918]
	TIME [epoch: 10.2 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19066635566981188		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.19066635566981188 | validation: 0.2435197856968449]
	TIME [epoch: 10.2 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1923215090675093		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.1923215090675093 | validation: 0.22170288220684506]
	TIME [epoch: 10.2 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16897490237641416		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.16897490237641416 | validation: 0.2315096755132592]
	TIME [epoch: 10.2 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18305495061529514		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.18305495061529514 | validation: 0.21868491949028468]
	TIME [epoch: 10.2 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18123538066273065		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.18123538066273065 | validation: 0.23184560393307455]
	TIME [epoch: 10.2 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19354219568145298		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.19354219568145298 | validation: 0.24096871779908768]
	TIME [epoch: 10.2 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19260911831942382		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.19260911831942382 | validation: 0.22833058932667022]
	TIME [epoch: 10.2 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19596443568882654		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.19596443568882654 | validation: 0.22210036797571137]
	TIME [epoch: 10.2 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17881840072238		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.17881840072238 | validation: 0.223469229484622]
	TIME [epoch: 10.2 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1859682046839247		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.1859682046839247 | validation: 0.21956872316242637]
	TIME [epoch: 10.2 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18673414203058503		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.18673414203058503 | validation: 0.2373982803294527]
	TIME [epoch: 10.2 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18044751250625496		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.18044751250625496 | validation: 0.2318993932156947]
	TIME [epoch: 10.2 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2332563079087681		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.2332563079087681 | validation: 0.3226336860498899]
	TIME [epoch: 10.2 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27601657129919893		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.27601657129919893 | validation: 0.24289696936273308]
	TIME [epoch: 10.2 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20593960598102856		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.20593960598102856 | validation: 0.23790495371782855]
	TIME [epoch: 10.2 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.201858525884615		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.201858525884615 | validation: 0.2480707083336775]
	TIME [epoch: 10.2 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2425307072734401		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.2425307072734401 | validation: 0.26554587938754265]
	TIME [epoch: 10.2 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.293823517793711		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.293823517793711 | validation: 0.3506807130906895]
	TIME [epoch: 10.2 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3265167458703246		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.3265167458703246 | validation: 0.2702914532354565]
	TIME [epoch: 10.2 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23434706163938684		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.23434706163938684 | validation: 0.22864154536720527]
	TIME [epoch: 10.2 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21573284374204738		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.21573284374204738 | validation: 0.23168368950378412]
	TIME [epoch: 10.2 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21842308344673683		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.21842308344673683 | validation: 0.24045955556427273]
	TIME [epoch: 10.2 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20596229823386142		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.20596229823386142 | validation: 0.20593686838407263]
	TIME [epoch: 10.2 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1841633756970549		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.1841633756970549 | validation: 0.21345892112936693]
	TIME [epoch: 10.2 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1865645559597629		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.1865645559597629 | validation: 0.24151526964560904]
	TIME [epoch: 10.2 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1843305690238759		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.1843305690238759 | validation: 0.2134506191032275]
	TIME [epoch: 10.2 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18319644919184405		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.18319644919184405 | validation: 0.2076583273700475]
	TIME [epoch: 10.2 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18932255684846647		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.18932255684846647 | validation: 0.20902944506097176]
	TIME [epoch: 10.2 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19098419289046464		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.19098419289046464 | validation: 0.2449056133945428]
	TIME [epoch: 10.2 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20226011808060126		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.20226011808060126 | validation: 0.2818025183038115]
	TIME [epoch: 10.2 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21502597346524746		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.21502597346524746 | validation: 0.22745452548903497]
	TIME [epoch: 10.2 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934921472277788		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.1934921472277788 | validation: 0.22081494057469958]
	TIME [epoch: 10.2 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1868709233951042		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.1868709233951042 | validation: 0.2273510733316274]
	TIME [epoch: 10.2 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18947165393090382		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.18947165393090382 | validation: 0.23803620891426439]
	TIME [epoch: 10.2 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19788092251882458		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.19788092251882458 | validation: 0.24934551076850156]
	TIME [epoch: 10.2 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19715307988918152		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.19715307988918152 | validation: 0.23252953263156642]
	TIME [epoch: 10.2 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19842658408398312		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.19842658408398312 | validation: 0.2549581675922814]
	TIME [epoch: 10.2 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22323006417814306		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.22323006417814306 | validation: 0.2530583682837595]
	TIME [epoch: 10.2 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2424400383685441		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.2424400383685441 | validation: 0.27592946498420445]
	TIME [epoch: 10.2 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22005429077061694		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.22005429077061694 | validation: 0.23714758452607942]
	TIME [epoch: 10.2 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19033800924073688		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.19033800924073688 | validation: 0.2390479684604795]
	TIME [epoch: 10.2 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22759237614543776		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.22759237614543776 | validation: 0.258428830258571]
	TIME [epoch: 10.2 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2125810625706123		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.2125810625706123 | validation: 0.2615868994433273]
	TIME [epoch: 10.2 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20774114796932067		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.20774114796932067 | validation: 0.20917570105558447]
	TIME [epoch: 10.2 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1808861607833304		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.1808861607833304 | validation: 0.21424850940657209]
	TIME [epoch: 10.2 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1910303743453738		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.1910303743453738 | validation: 0.23321589723440966]
	TIME [epoch: 10.2 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694123574451552		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.18694123574451552 | validation: 0.2132818337847875]
	TIME [epoch: 10.2 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1896900894111755		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.1896900894111755 | validation: 0.2340458040475821]
	TIME [epoch: 10.2 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19464725451147818		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.19464725451147818 | validation: 0.249619424962911]
	TIME [epoch: 10.2 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24997107056761755		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.24997107056761755 | validation: 0.25849494467735734]
	TIME [epoch: 10.2 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22686856436653682		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.22686856436653682 | validation: 0.2499046686280247]
	TIME [epoch: 10.2 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2272176223680415		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.2272176223680415 | validation: 0.21486278093569092]
	TIME [epoch: 10.2 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22640166917579596		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.22640166917579596 | validation: 0.2320379543356612]
	TIME [epoch: 10.2 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19895118211264257		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.19895118211264257 | validation: 0.23406009563033497]
	TIME [epoch: 10.2 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19454449864465767		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.19454449864465767 | validation: 0.22554261870469938]
	TIME [epoch: 10.2 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19754387032179194		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.19754387032179194 | validation: 0.22972951378212628]
	TIME [epoch: 10.2 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20299240217559616		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.20299240217559616 | validation: 0.23693095669605574]
	TIME [epoch: 10.2 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1962509721195694		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.1962509721195694 | validation: 0.2365673443974241]
	TIME [epoch: 10.2 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19463375796157867		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.19463375796157867 | validation: 0.230265847654982]
	TIME [epoch: 10.2 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20125950332987325		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.20125950332987325 | validation: 0.2592777059462638]
	TIME [epoch: 10.2 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2463298454760094		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.2463298454760094 | validation: 0.27513047515713474]
	TIME [epoch: 10.2 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23467868120301674		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.23467868120301674 | validation: 0.2349419959052338]
	TIME [epoch: 10.2 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21392427962271152		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.21392427962271152 | validation: 0.23830472539611536]
	TIME [epoch: 10.2 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2121242099868467		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.2121242099868467 | validation: 0.22943817739024575]
	TIME [epoch: 10.2 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20474304622136819		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.20474304622136819 | validation: 0.25411319798415405]
	TIME [epoch: 10.2 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184726659740375		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.184726659740375 | validation: 0.22655784565091586]
	TIME [epoch: 10.2 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853667739704485		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.1853667739704485 | validation: 0.21887285814041785]
	TIME [epoch: 10.2 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18207866087192198		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.18207866087192198 | validation: 0.2167704888163533]
	TIME [epoch: 10.2 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118350477603975		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.2118350477603975 | validation: 0.24658425001470835]
	TIME [epoch: 10.2 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19406025518572653		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.19406025518572653 | validation: 0.2471440564663902]
	TIME [epoch: 10.2 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937191256647195		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.1937191256647195 | validation: 0.24588171352783833]
	TIME [epoch: 10.2 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18743456158010446		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.18743456158010446 | validation: 0.22484400346371713]
	TIME [epoch: 10.2 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19496455004903204		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.19496455004903204 | validation: 0.22169884399236017]
	TIME [epoch: 10.2 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18507693423793384		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.18507693423793384 | validation: 0.24951290858158195]
	TIME [epoch: 10.2 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19894092336122027		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.19894092336122027 | validation: 0.2185843854916625]
	TIME [epoch: 10.2 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18715243994862008		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.18715243994862008 | validation: 0.20697954618109918]
	TIME [epoch: 10.2 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18752669380263004		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.18752669380263004 | validation: 0.24221653566200638]
	TIME [epoch: 10.2 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18660464942106686		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.18660464942106686 | validation: 0.2328616775095692]
	TIME [epoch: 10.2 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19934977134631132		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.19934977134631132 | validation: 0.23190375144143516]
	TIME [epoch: 10.2 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185887920851187		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.185887920851187 | validation: 0.23029262800555197]
	TIME [epoch: 10.2 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19431087711882816		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.19431087711882816 | validation: 0.24615945887906665]
	TIME [epoch: 10.2 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2315896166247878		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.2315896166247878 | validation: 0.26312254904922566]
	TIME [epoch: 10.2 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2365592447416276		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.2365592447416276 | validation: 0.2468602330918739]
	TIME [epoch: 10.2 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2039820309695335		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.2039820309695335 | validation: 0.22124060231707332]
	TIME [epoch: 10.2 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21200928164069416		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.21200928164069416 | validation: 0.26029320522363975]
	TIME [epoch: 10.2 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2231707639264922		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.2231707639264922 | validation: 0.24040311671257467]
	TIME [epoch: 10.2 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22116199394971786		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.22116199394971786 | validation: 0.24447245731802256]
	TIME [epoch: 10.2 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19308444445711725		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.19308444445711725 | validation: 0.22758681004497378]
	TIME [epoch: 10.2 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18594473115561733		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.18594473115561733 | validation: 0.22449508331007878]
	TIME [epoch: 10.2 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18036072246875684		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.18036072246875684 | validation: 0.2198831503530763]
	TIME [epoch: 10.2 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17715526891182623		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.17715526891182623 | validation: 0.22888472125299444]
	TIME [epoch: 10.2 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17693408593547677		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.17693408593547677 | validation: 0.19536544035484965]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1813.pth
	Model improved!!!
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1894361246417667		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.1894361246417667 | validation: 0.21891374610783282]
	TIME [epoch: 10.3 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18454304721533193		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.18454304721533193 | validation: 0.24363075035816173]
	TIME [epoch: 10.3 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18034740309588893		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.18034740309588893 | validation: 0.20354631713699284]
	TIME [epoch: 10.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18618214073974754		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.18618214073974754 | validation: 0.21308236348170934]
	TIME [epoch: 10.2 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18612568586469397		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.18612568586469397 | validation: 0.21247956511472585]
	TIME [epoch: 10.2 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1818428521894172		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.1818428521894172 | validation: 0.20973506328114486]
	TIME [epoch: 10.2 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18069136176819714		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.18069136176819714 | validation: 0.2225789535144725]
	TIME [epoch: 10.2 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17759203817022523		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.17759203817022523 | validation: 0.225197215513764]
	TIME [epoch: 10.2 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17790063828108477		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.17790063828108477 | validation: 0.2329182605793077]
	TIME [epoch: 10.2 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17741332481545294		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.17741332481545294 | validation: 0.2248931314165172]
	TIME [epoch: 10.2 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728667459537873		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.1728667459537873 | validation: 0.22374659337555414]
	TIME [epoch: 10.2 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17884321043875467		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.17884321043875467 | validation: 0.2334675758582506]
	TIME [epoch: 10.2 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16824740216909834		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.16824740216909834 | validation: 0.2381463864957822]
	TIME [epoch: 10.2 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751818632676933		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.1751818632676933 | validation: 0.23155497025338115]
	TIME [epoch: 10.2 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18609601847654614		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.18609601847654614 | validation: 0.2544779158270813]
	TIME [epoch: 10.2 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19488971293369933		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.19488971293369933 | validation: 0.2205111665687574]
	TIME [epoch: 10.2 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18557883319497445		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.18557883319497445 | validation: 0.249136680599398]
	TIME [epoch: 10.2 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21161704553517607		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.21161704553517607 | validation: 0.24039498542612633]
	TIME [epoch: 10.2 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21481394169061369		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.21481394169061369 | validation: 0.2431174640297176]
	TIME [epoch: 10.2 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19468286228230886		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.19468286228230886 | validation: 0.1944145138307781]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1833.pth
	Model improved!!!
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718861609011172		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.1718861609011172 | validation: 0.22174562851745067]
	TIME [epoch: 10.2 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17837629292003526		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.17837629292003526 | validation: 0.22195084658634312]
	TIME [epoch: 10.2 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18036820680196214		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.18036820680196214 | validation: 0.2334681545743176]
	TIME [epoch: 10.2 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16982902397326965		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.16982902397326965 | validation: 0.23931051630236597]
	TIME [epoch: 10.2 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17806042021827453		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.17806042021827453 | validation: 0.24425906099025754]
	TIME [epoch: 10.2 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16692075133227569		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.16692075133227569 | validation: 0.2350494107041572]
	TIME [epoch: 10.2 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18992635967823762		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.18992635967823762 | validation: 0.23175438209561222]
	TIME [epoch: 10.2 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21544574533549396		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.21544574533549396 | validation: 0.23833758279076128]
	TIME [epoch: 10.2 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2047722898211751		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.2047722898211751 | validation: 0.24602636707281506]
	TIME [epoch: 10.2 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2093624638396876		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.2093624638396876 | validation: 0.24581273244175225]
	TIME [epoch: 10.2 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2368269702800736		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.2368269702800736 | validation: 0.21957378738956335]
	TIME [epoch: 10.2 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20575640028629344		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.20575640028629344 | validation: 0.24443163702818804]
	TIME [epoch: 10.2 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1951497174652528		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.1951497174652528 | validation: 0.23153097805586623]
	TIME [epoch: 10.2 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18479814165670272		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.18479814165670272 | validation: 0.23315732290794253]
	TIME [epoch: 10.2 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17959639373072717		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.17959639373072717 | validation: 0.23619874841906044]
	TIME [epoch: 10.2 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1811438731786126		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.1811438731786126 | validation: 0.20734473684082552]
	TIME [epoch: 10.2 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18597509159869155		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.18597509159869155 | validation: 0.2282648254637744]
	TIME [epoch: 10.2 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1943437371676942		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.1943437371676942 | validation: 0.24746379391257436]
	TIME [epoch: 10.2 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2184414667466168		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.2184414667466168 | validation: 0.258780282177302]
	TIME [epoch: 10.2 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2104633799176529		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.2104633799176529 | validation: 0.21429122609405965]
	TIME [epoch: 10.2 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1794355074482175		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.1794355074482175 | validation: 0.23942528510547917]
	TIME [epoch: 10.2 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17785406042751717		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.17785406042751717 | validation: 0.23091120508348673]
	TIME [epoch: 10.2 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1818126982437796		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.1818126982437796 | validation: 0.23642611785767728]
	TIME [epoch: 10.2 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18543654034080795		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.18543654034080795 | validation: 0.24545225953208627]
	TIME [epoch: 10.2 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18329349480688523		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.18329349480688523 | validation: 0.23265629114010736]
	TIME [epoch: 10.2 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18296632189527146		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.18296632189527146 | validation: 0.21154803032146471]
	TIME [epoch: 10.2 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19446610693968747		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.19446610693968747 | validation: 0.24022422326427162]
	TIME [epoch: 10.2 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19672107083942392		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.19672107083942392 | validation: 0.2356022565324573]
	TIME [epoch: 10.2 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18903360968535982		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.18903360968535982 | validation: 0.2199475766720065]
	TIME [epoch: 10.2 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17532111349450477		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.17532111349450477 | validation: 0.2317220043505346]
	TIME [epoch: 10.2 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18086166395778253		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.18086166395778253 | validation: 0.22289262416802413]
	TIME [epoch: 10.2 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17506389920497778		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.17506389920497778 | validation: 0.24257450193501462]
	TIME [epoch: 10.2 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1965718822467126		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.1965718822467126 | validation: 0.25047587545852656]
	TIME [epoch: 10.2 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19912551973897422		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.19912551973897422 | validation: 0.2249805794766351]
	TIME [epoch: 10.2 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18749838626648244		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.18749838626648244 | validation: 0.19699499043724442]
	TIME [epoch: 10.2 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16773838139086536		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.16773838139086536 | validation: 0.20171679591601815]
	TIME [epoch: 10.2 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16592621248410935		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.16592621248410935 | validation: 0.23122777023762203]
	TIME [epoch: 10.2 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724210178001949		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.1724210178001949 | validation: 0.20267734596286346]
	TIME [epoch: 10.2 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16929536704740208		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.16929536704740208 | validation: 0.23628185526694329]
	TIME [epoch: 10.2 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16892388791604981		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.16892388791604981 | validation: 0.20017141325442825]
	TIME [epoch: 10.2 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1695721969952518		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.1695721969952518 | validation: 0.18784695652940528]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1874.pth
	Model improved!!!
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17122693099519393		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.17122693099519393 | validation: 0.23292573946179382]
	TIME [epoch: 10.2 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.180026534651803		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.180026534651803 | validation: 0.22024947893358193]
	TIME [epoch: 10.2 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21837700632564494		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.21837700632564494 | validation: 0.22217467248366937]
	TIME [epoch: 10.2 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22410252928227242		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.22410252928227242 | validation: 0.2517705464992459]
	TIME [epoch: 10.2 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2251521769119079		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.2251521769119079 | validation: 0.22615465298030152]
	TIME [epoch: 10.2 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18898940004006573		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.18898940004006573 | validation: 0.23559075285963274]
	TIME [epoch: 10.2 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17395846252885336		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.17395846252885336 | validation: 0.2025454467606493]
	TIME [epoch: 10.2 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17422391266214896		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.17422391266214896 | validation: 0.204215073484157]
	TIME [epoch: 10.2 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1898552265505326		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.1898552265505326 | validation: 0.24263328124547387]
	TIME [epoch: 10.2 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1827961198103122		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.1827961198103122 | validation: 0.23036264902533446]
	TIME [epoch: 10.2 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18574090336672686		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.18574090336672686 | validation: 0.24143404799050405]
	TIME [epoch: 10.2 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19945512532110427		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.19945512532110427 | validation: 0.23860528255363814]
	TIME [epoch: 10.2 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911839418489739		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.1911839418489739 | validation: 0.21224381298347042]
	TIME [epoch: 10.2 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882660594142855		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.1882660594142855 | validation: 0.21837471010023088]
	TIME [epoch: 10.2 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.177351943613095		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.177351943613095 | validation: 0.21456428382290507]
	TIME [epoch: 10.2 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19505333693342175		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.19505333693342175 | validation: 0.22900790201018514]
	TIME [epoch: 10.2 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18797350068483154		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.18797350068483154 | validation: 0.24051487524172552]
	TIME [epoch: 10.2 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789521006694217		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.1789521006694217 | validation: 0.22102065169791135]
	TIME [epoch: 10.2 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17043428110626652		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.17043428110626652 | validation: 0.18761977409034714]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1893.pth
	Model improved!!!
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17118799858091086		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.17118799858091086 | validation: 0.2440868492205388]
	TIME [epoch: 10.2 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18037306944669101		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.18037306944669101 | validation: 0.23634272425445044]
	TIME [epoch: 10.2 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17471357281571984		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.17471357281571984 | validation: 0.2419698841328743]
	TIME [epoch: 10.2 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18421371026574782		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.18421371026574782 | validation: 0.20634871774046154]
	TIME [epoch: 10.2 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18040496766442587		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.18040496766442587 | validation: 0.20423878744774493]
	TIME [epoch: 10.2 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17376254689128107		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.17376254689128107 | validation: 0.2296078686443463]
	TIME [epoch: 10.2 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17631345245883984		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.17631345245883984 | validation: 0.2390260359766853]
	TIME [epoch: 10.2 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17353604559881936		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.17353604559881936 | validation: 0.19857926311639085]
	TIME [epoch: 10.2 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1811170703385979		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.1811170703385979 | validation: 0.2345174242322852]
	TIME [epoch: 10.2 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17604541358910628		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.17604541358910628 | validation: 0.21840782918007093]
	TIME [epoch: 10.2 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17476304093899628		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.17476304093899628 | validation: 0.24409485253520136]
	TIME [epoch: 10.2 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1919674303654662		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.1919674303654662 | validation: 0.2423337117090928]
	TIME [epoch: 10.2 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18431912079265875		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.18431912079265875 | validation: 0.23445973490715005]
	TIME [epoch: 10.2 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17458914499682085		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.17458914499682085 | validation: 0.24016365664308204]
	TIME [epoch: 10.2 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19015421889439293		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.19015421889439293 | validation: 0.2364965850508074]
	TIME [epoch: 10.2 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1896197173301553		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.1896197173301553 | validation: 0.20533305792028406]
	TIME [epoch: 10.2 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18260853686193307		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.18260853686193307 | validation: 0.2424758423687588]
	TIME [epoch: 10.2 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17605633324248832		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.17605633324248832 | validation: 0.23120558280582473]
	TIME [epoch: 10.2 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19171317051559114		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.19171317051559114 | validation: 0.23683842364422653]
	TIME [epoch: 10.2 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2050413678858541		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.2050413678858541 | validation: 0.21911903981971073]
	TIME [epoch: 10.2 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18947362097956286		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.18947362097956286 | validation: 0.24449770286919872]
	TIME [epoch: 10.2 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17965688349384007		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.17965688349384007 | validation: 0.24153656634840961]
	TIME [epoch: 10.2 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18312453049623575		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.18312453049623575 | validation: 0.22808014742664584]
	TIME [epoch: 10.2 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17801005850271495		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.17801005850271495 | validation: 0.19782859189601024]
	TIME [epoch: 10.2 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17285595114464747		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.17285595114464747 | validation: 0.2142306851915714]
	TIME [epoch: 10.2 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17989506674454184		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.17989506674454184 | validation: 0.19710717060424465]
	TIME [epoch: 10.2 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17069226342764482		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.17069226342764482 | validation: 0.23030810826380502]
	TIME [epoch: 10.2 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17611170113423474		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.17611170113423474 | validation: 0.22762141002680572]
	TIME [epoch: 10.2 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18114641085287134		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.18114641085287134 | validation: 0.2359555992611765]
	TIME [epoch: 10.2 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17052948949947613		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.17052948949947613 | validation: 0.23018099816757237]
	TIME [epoch: 10.2 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698337060375812		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.1698337060375812 | validation: 0.19849551188809111]
	TIME [epoch: 10.2 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17542924121884157		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.17542924121884157 | validation: 0.22601708323488015]
	TIME [epoch: 10.2 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023486780285668		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.17023486780285668 | validation: 0.23407880401480285]
	TIME [epoch: 10.2 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17225000721289074		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.17225000721289074 | validation: 0.22927221357792424]
	TIME [epoch: 10.2 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16218032297220364		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.16218032297220364 | validation: 0.20311276764623007]
	TIME [epoch: 10.2 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18000411388972876		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.18000411388972876 | validation: 0.22143527480435565]
	TIME [epoch: 10.2 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1822782302520917		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.1822782302520917 | validation: 0.20172061440985772]
	TIME [epoch: 10.2 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18941163666247518		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.18941163666247518 | validation: 0.19729715697553396]
	TIME [epoch: 10.2 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17518153735281045		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.17518153735281045 | validation: 0.2395866929643247]
	TIME [epoch: 10.2 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18394557922370475		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.18394557922370475 | validation: 0.21973677642983194]
	TIME [epoch: 10.2 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20510655859493002		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.20510655859493002 | validation: 0.2536652616552467]
	TIME [epoch: 10.2 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2161712892187735		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.2161712892187735 | validation: 0.2367363430022928]
	TIME [epoch: 10.2 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20955212131577		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.20955212131577 | validation: 0.239575332905276]
	TIME [epoch: 10.2 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20131266886669405		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.20131266886669405 | validation: 0.2055229058340317]
	TIME [epoch: 10.2 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19119957334963666		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.19119957334963666 | validation: 0.21687750387270227]
	TIME [epoch: 10.2 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885086384323232		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.1885086384323232 | validation: 0.21431700370848866]
	TIME [epoch: 10.2 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18070726665932718		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.18070726665932718 | validation: 0.19680224622770903]
	TIME [epoch: 10.2 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1705376373638296		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.1705376373638296 | validation: 0.20839414130022443]
	TIME [epoch: 10.2 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2019284109687603		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.2019284109687603 | validation: 0.22119887634055793]
	TIME [epoch: 10.2 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19084268429821638		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.19084268429821638 | validation: 0.20006167834560992]
	TIME [epoch: 10.2 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17246390134817374		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.17246390134817374 | validation: 0.21476681797539243]
	TIME [epoch: 10.2 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1684685284293482		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.1684685284293482 | validation: 0.19707414923941996]
	TIME [epoch: 10.2 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16725384057861664		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.16725384057861664 | validation: 0.207225404828994]
	TIME [epoch: 10.2 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17652730496700877		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.17652730496700877 | validation: 0.23327540018854165]
	TIME [epoch: 10.2 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18111606179427855		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.18111606179427855 | validation: 0.2184342405383049]
	TIME [epoch: 10.2 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16963667362804966		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.16963667362804966 | validation: 0.23452639198365555]
	TIME [epoch: 10.2 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1820639038516103		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.1820639038516103 | validation: 0.21997421370778777]
	TIME [epoch: 10.2 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18152789082720747		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.18152789082720747 | validation: 0.2462120823504076]
	TIME [epoch: 10.2 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17764651720483643		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.17764651720483643 | validation: 0.20811855715426972]
	TIME [epoch: 10.2 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17659106478357536		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.17659106478357536 | validation: 0.2019643685744554]
	TIME [epoch: 10.2 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1766497891414323		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.1766497891414323 | validation: 0.22978324931581712]
	TIME [epoch: 10.2 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19253764740247775		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.19253764740247775 | validation: 0.22212271158803645]
	TIME [epoch: 10.2 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20576209870111684		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.20576209870111684 | validation: 0.2606357347268568]
	TIME [epoch: 10.2 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19615662452975172		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.19615662452975172 | validation: 0.23439905413404283]
	TIME [epoch: 10.2 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1796421089696016		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.1796421089696016 | validation: 0.23583684692175183]
	TIME [epoch: 10.2 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19354635495283357		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.19354635495283357 | validation: 0.23996235441909103]
	TIME [epoch: 10.2 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20501603405901553		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.20501603405901553 | validation: 0.2216371286984523]
	TIME [epoch: 10.2 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20549479926501726		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.20549479926501726 | validation: 0.2335746355471874]
	TIME [epoch: 10.2 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18603671090317384		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.18603671090317384 | validation: 0.24163781177491317]
	TIME [epoch: 10.2 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18580091318234654		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.18580091318234654 | validation: 0.21610738567595364]
	TIME [epoch: 10.2 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17588071507153796		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.17588071507153796 | validation: 0.2294456427233158]
	TIME [epoch: 10.2 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675450334645286		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.1675450334645286 | validation: 0.19081299005871757]
	TIME [epoch: 10.2 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17784389177562007		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.17784389177562007 | validation: 0.2084777248739848]
	TIME [epoch: 10.2 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17376685880791118		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.17376685880791118 | validation: 0.21944147529688132]
	TIME [epoch: 10.2 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16922286754984603		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.16922286754984603 | validation: 0.2292067511730626]
	TIME [epoch: 10.2 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17869158123438295		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.17869158123438295 | validation: 0.22387632263225526]
	TIME [epoch: 10.2 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17954676475519346		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.17954676475519346 | validation: 0.21638286683563138]
	TIME [epoch: 10.2 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16482941280397895		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.16482941280397895 | validation: 0.20317130026422583]
	TIME [epoch: 10.2 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18042141804480955		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.18042141804480955 | validation: 0.23303219080226753]
	TIME [epoch: 10.2 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18636266121222006		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.18636266121222006 | validation: 0.238949918962846]
	TIME [epoch: 10.2 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18013625328365868		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.18013625328365868 | validation: 0.25146975917681075]
	TIME [epoch: 10.2 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18210757968865346		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.18210757968865346 | validation: 0.23167843717086123]
	TIME [epoch: 10.2 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18280760687103373		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.18280760687103373 | validation: 0.19549741032554543]
	TIME [epoch: 10.2 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17476573470897563		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.17476573470897563 | validation: 0.21030769651055436]
	TIME [epoch: 10.2 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1794248809996081		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.1794248809996081 | validation: 0.20973999798155107]
	TIME [epoch: 10.2 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1827120207910396		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.1827120207910396 | validation: 0.2108001697598531]
	TIME [epoch: 10.2 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1813942019255062		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.1813942019255062 | validation: 0.24598968453987025]
	TIME [epoch: 10.2 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730158758707415		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.1730158758707415 | validation: 0.19540775966194612]
	TIME [epoch: 10.2 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17606620284306368		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.17606620284306368 | validation: 0.20479741751520258]
	TIME [epoch: 10.2 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16641066085853753		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.16641066085853753 | validation: 0.2204222317969795]
	TIME [epoch: 10.2 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16964382324305072		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.16964382324305072 | validation: 0.19374923115621162]
	TIME [epoch: 10.2 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644248749080311		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.1644248749080311 | validation: 0.21848534929979072]
	TIME [epoch: 10.2 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17410916390630504		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.17410916390630504 | validation: 0.1981650696500947]
	TIME [epoch: 10.2 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728423047697126		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.1728423047697126 | validation: 0.22190653387470846]
	TIME [epoch: 10.2 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717567415256618		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.1717567415256618 | validation: 0.19966199395127363]
	TIME [epoch: 10.2 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718959302902454		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.1718959302902454 | validation: 0.19623306228014906]
	TIME [epoch: 10.2 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681483127650226		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.1681483127650226 | validation: 0.2238402310685355]
	TIME [epoch: 10.2 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16494600850710345		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.16494600850710345 | validation: 0.21205618624413536]
	TIME [epoch: 10.2 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16627663090905193		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.16627663090905193 | validation: 0.21653446469637058]
	TIME [epoch: 10.2 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1702981263849283		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.1702981263849283 | validation: 0.21743141107335412]
	TIME [epoch: 10.2 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1617409081249607		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.1617409081249607 | validation: 0.18617700013775879]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1994.pth
	Model improved!!!
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16580182803531554		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.16580182803531554 | validation: 0.18575109050026029]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1_fix_noise/tr_study6/model_tr_study6_r5_20240219_190822/states/model_tr_study6_1995.pth
	Model improved!!!
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17273147236751524		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.17273147236751524 | validation: 0.2181169295778369]
	TIME [epoch: 10.2 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1662359914569142		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.1662359914569142 | validation: 0.1997697527974253]
	TIME [epoch: 10.2 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16701376522363975		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.16701376522363975 | validation: 0.19763921609857982]
	TIME [epoch: 10.2 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651314397420815		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.1651314397420815 | validation: 0.20334329200542287]
	TIME [epoch: 10.2 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17191640673590988		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.17191640673590988 | validation: 0.22136254220267568]
	TIME [epoch: 10.2 sec]
Finished training in 20518.737 seconds.
