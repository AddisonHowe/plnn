{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for testing DeepPhi models trained on synthetic binary decision data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "\n",
    "import equinox as eqx\n",
    "\n",
    "from plnn.models import DeepPhiPLNN\n",
    "from plnn.dataset import get_dataloaders\n",
    "from plnn.data_generation.plnn_animator import PLNNSimulationAnimator\n",
    "from plnn.io import load_model_from_directory, load_model_training_metadata\n",
    "from plnn.loss_functions import select_loss_function\n",
    "from plnn.optimizers import get_dt_schedule\n",
    "from plnn.model_training import validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = None\n",
    "SAVE_ANIMATION = False\n",
    "\n",
    "BASEOUTDIR = f\"./out/test_models_synbindec\"   # Output directory\n",
    "BASEDIR = \"../data/trained_models/plnn_synbindec\"  # Directory containing models\n",
    "\n",
    "# Model directory\n",
    "MODEL_DIR = \"model_phi1_1a_v_mmd1_20240704_134102\"\n",
    "\n",
    "MODEL_NAME = MODEL_DIR[0:-16]  # strip time to get model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing training data\n",
    "DATDIRBASE = f\"../data/training_data\"\n",
    "DATDIR = f\"{DATDIRBASE}/data_{MODEL_DIR[6:13]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running as a script, overwrite parameters with command line args\n",
    "\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "SCRIPT = not is_notebook()\n",
    "\n",
    "if SCRIPT:\n",
    "    import tqdm as tqdm\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--basedir\", type=str, \n",
    "                        default=\"data/trained_models/facs\")\n",
    "    parser.add_argument(\"--modeldir\", type=str, required=True)\n",
    "    parser.add_argument(\"--modelname\", type=str, required=True)\n",
    "    parser.add_argument(\"--datdirbase\", type=str, \n",
    "                        default=\"data/training_data/facs\")\n",
    "    parser.add_argument(\"--datdir\", type=str, required=True)\n",
    "    parser.add_argument(\"--baseoutdir\", type=str, \n",
    "                        default=\"notebooks/out/test_models_facs\")\n",
    "    parser.add_argument(\"--save_animation\", action='store_true')\n",
    "    parser.add_argument(\"--seed\", type=int, default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    BASEDIR = args.basedir\n",
    "    MODEL_DIR = args.modeldir\n",
    "    MODEL_NAME = args.modelname\n",
    "    DATDIRBASE = args.datdirbase\n",
    "    DATDIR = f\"{DATDIRBASE}/{args.datdir}\"\n",
    "    BASEOUTDIR = args.baseoutdir\n",
    "    SAVE_ANIMATION = args.save_animation\n",
    "    SEED = args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=SEED)\n",
    "\n",
    "modeldir = f\"{BASEDIR}/{MODEL_DIR}\"\n",
    "\n",
    "OUTDIR = f\"{BASEOUTDIR}/{MODEL_DIR}\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "datdir_train = f\"{DATDIR}/training\"\n",
    "datdir_valid = f\"{DATDIR}/validation\"\n",
    "datdir_test = f\"{DATDIR}/testing\"\n",
    "\n",
    "nsims_train = np.genfromtxt(f\"{datdir_train}/nsims.txt\", dtype=int)\n",
    "nsims_valid = np.genfromtxt(f\"{datdir_valid}/nsims.txt\", dtype=int)\n",
    "\n",
    "try:\n",
    "    nsims_test = np.genfromtxt(f\"{datdir_test}/nsims.txt\", dtype=int)\n",
    "except FileNotFoundError as e:\n",
    "    msg = f\"{e} Reverting to validation data instead.\"\n",
    "    warnings.warn(msg)\n",
    "    datdir_test = f\"{DATDIR}/validation\"\n",
    "    nsims_test = np.genfromtxt(f\"{datdir_test}/nsims.txt\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: multiscale\n",
      "bw_range: None\n",
      "Calculuating `dt_hist` to match length of `sigma_hist`\n",
      "Loading model `model_phi1_1a_v_mmd1` at epoch 1220 from file: ../data/trained_models/plnn_synbindec/model_phi1_1a_v_mmd1_20240704_134102/states/model_phi1_1a_v_mmd1_1220.pth.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model, hyperparams, idx, model_name, model_fpath = load_model_from_directory(\n",
    "    modeldir, \n",
    "    subdir=\"states\",\n",
    "    idx='best',\n",
    "    model_class=DeepPhiPLNN,\n",
    "    dtype=jnp.float64,\n",
    ")\n",
    "\n",
    "# Load the argument dictionary and training run dictionary\n",
    "logged_args, run_dict = load_model_training_metadata(\n",
    "    modeldir,\n",
    "    load_all=True\n",
    ")\n",
    "\n",
    "loss_id = logged_args['loss']\n",
    "kernel = logged_args.get('kernel', 'multiscale')\n",
    "bw_range = logged_args.get('bw_range')\n",
    "print('kernel:', kernel)\n",
    "print('bw_range:', bw_range)\n",
    "loss_fn = select_loss_function(\n",
    "    loss_id, \n",
    "    kernel=kernel,\n",
    "    bw_range=bw_range,\n",
    ")\n",
    "\n",
    "loss_train = run_dict['loss_hist_train']\n",
    "loss_valid = run_dict['loss_hist_valid']\n",
    "sigma_hist = run_dict['sigma_hist']\n",
    "lr_hist = run_dict['learning_rate_hist']\n",
    "dt_hist = run_dict['dt_hist']\n",
    "\n",
    "try:\n",
    "    if dt_hist is None or len(dt_hist) < len(sigma_hist):\n",
    "        print(\"Calculuating `dt_hist` to match length of `sigma_hist`\")\n",
    "        dt_schedule = get_dt_schedule(logged_args['dt_schedule'], logged_args)\n",
    "        dt_hist = np.array([dt_schedule(i) for i in range(len(sigma_hist))])\n",
    "except (RuntimeError, TypeError) as e:\n",
    "    print(\"Could not calculate `dt_hist` to match length of `sigma_hist`\")\n",
    "    print(e)\n",
    "\n",
    "print(f\"Loading model `{model_name}` at epoch {idx} from file: {model_fpath}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets using parameters:\n",
      "\tncells_sample: 0\n",
      "\tdataset base length: 300\n",
      "\tlength_multiplier: 1\n",
      "\tdataset length: 300\n",
      "\tbatch size: 20\n",
      "\tdataloader length: 15\n"
     ]
    }
   ],
   "source": [
    "ncells_sample = logged_args['ncells_sample']\n",
    "length_multiplier = logged_args['passes_per_epoch']\n",
    "batch_size = 20\n",
    "\n",
    "_, _, test_loader, _, _, test_dset = get_dataloaders(\n",
    "    datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "    shuffle_train=False,\n",
    "    return_datasets=True,\n",
    "    include_test_data=True,\n",
    "    datdir_test=datdir_test, nsims_test=nsims_test, shuffle_test=True,\n",
    "    batch_size_test=batch_size,  # TODO: Batch Testing\n",
    "    ncells_sample=ncells_sample,\n",
    "    length_multiplier=length_multiplier,\n",
    "    seed=rng.integers(2**32)\n",
    ")\n",
    "\n",
    "print(\"Loaded datasets using parameters:\")\n",
    "print(\"\\tncells_sample:\", ncells_sample)\n",
    "print(\"\\tdataset base length:\", test_dset.get_baselength())\n",
    "print(\"\\tlength_multiplier:\", length_multiplier)\n",
    "print(\"\\tdataset length:\", len(test_dset))\n",
    "print(\"\\tbatch size:\", batch_size)\n",
    "print(\"\\tdataloader length:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform model evaluation on the testing data\n",
    "Perform one pass through the testing dataset, computing the loss as done in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrandom.PRNGKey(seed=rng.integers(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def compute_loss(model, x, y, loss_fn, key):\n",
    "    t0, y0, t1, sigparams = x\n",
    "    y_pred = model(t0, t1, y0, sigparams, key)\n",
    "    return loss_fn(y_pred, y), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614852c2cb53457cbf108f81798d24a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0017063467427825304\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "n = len(test_loader)\n",
    "running_vloss = 0.0\n",
    "for i, data in enumerate(tqdm.tqdm(test_loader, disable=SCRIPT)):\n",
    "    inputs, y1 = data\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    loss = eqx.filter_jit(validation_step)(model, inputs, y1, loss_fn, subkey)\n",
    "    running_vloss += loss.item()\n",
    "\n",
    "avg_loss = running_vloss / n\n",
    "jax.block_until_ready(avg_loss)\n",
    "\n",
    "print(\"Average loss:\", avg_loss)\n",
    "\n",
    "# Save the resulting average loss value in the output directory.\n",
    "np.save(f\"{OUTDIR}/avg_testing_loss.npy\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_model = eqx.tree_at(lambda m: m.dt0, model, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda89d031c85468c8804229d8dd5f0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "n = len(test_loader)\n",
    "running_vloss = 0.0\n",
    "for i, data in enumerate(tqdm.tqdm(test_loader, disable=SCRIPT)):\n",
    "    inputs, y1 = data\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    loss = eqx.filter_jit(validation_step)(faster_model, inputs, y1, loss_fn, subkey)\n",
    "    running_vloss += loss.item()\n",
    "\n",
    "avg_loss = running_vloss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.00176436445366792\n"
     ]
    }
   ],
   "source": [
    "avg_loss = running_vloss / n\n",
    "print(\"Average loss:\", avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Testing\n",
    "\n",
    "Construct a testing dataloader that does not shuffle the data.\n",
    "For each datapoint, run the forward model multiple times (for multiple values of `dt`).\n",
    "Determine the distribution of the loss for each datapoint.\n",
    "See if there is a correlation between the loss and time, or between the loss and experimental condition.\n",
    "Run the same sort of trial for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, valid_loader, test_loader, _, valid_dset, test_dset = get_dataloaders(\n",
    "    datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "    return_datasets=True,\n",
    "    include_test_data=True,\n",
    "    shuffle_train=False,\n",
    "    shuffle_valid=False,\n",
    "    shuffle_test=False,\n",
    "    datdir_test=datdir_test, \n",
    "    nsims_test=nsims_test, \n",
    "    batch_size_test=1,  # Needs to be 1 otherwise loss is averaged\n",
    "    ncells_sample=ncells_sample,\n",
    "    length_multiplier=1,\n",
    "    seed=rng.integers(2**32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c51f5234c594170bb2c8e29b2d55b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NITERS):\n\u001b[1;32m     15\u001b[0m     key, subkey \u001b[38;5;241m=\u001b[39m jrandom\u001b[38;5;241m.\u001b[39msplit(key, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfaster_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubkey\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     results[i, k] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/pjit.py:257\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 257\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_params_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m   executable \u001b[38;5;241m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    260\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(executable, out_tree, args_flat, out_flat)\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/pjit.py:168\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m   dispatch\u001b[38;5;241m.\u001b[39mcheck_arg(arg)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pxla\u001b[38;5;241m.\u001b[39mDeviceAssignmentMismatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    170\u001b[0m   fails, \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/core.py:2740\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2736\u001b[0m axis_main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((axis_frame(a)\u001b[38;5;241m.\u001b[39mmain_trace \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m used_axis_names(\u001b[38;5;28mself\u001b[39m, params)),\n\u001b[1;32m   2737\u001b[0m                 default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28mgetattr\u001b[39m(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   2738\u001b[0m top_trace \u001b[38;5;241m=\u001b[39m (top_trace \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m axis_main \u001b[38;5;129;01mor\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m<\u001b[39m top_trace\u001b[38;5;241m.\u001b[39mlevel\n\u001b[1;32m   2739\u001b[0m              \u001b[38;5;28;01melse\u001b[39;00m axis_main\u001b[38;5;241m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2740\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/pjit.py:1245\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1242\u001b[0m donated_argnums \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(donated_invars) \u001b[38;5;28;01mif\u001b[39;00m d]\n\u001b[1;32m   1243\u001b[0m has_explicit_sharding \u001b[38;5;241m=\u001b[39m _pjit_explicit_sharding(\n\u001b[1;32m   1244\u001b[0m     in_shardings, out_shardings, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_argnums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhas_explicit_sharding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/pjit.py:1229\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_impl_cache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs_):\n\u001b[0;32m-> 1229\u001b[0m   out_flat, compiled \u001b[38;5;241m=\u001b[39m \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m      \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m      \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m   fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m   1235\u001b[0m       compiled, tree_structure(out_flat), args, out_flat)\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out_flat, fastpath_data\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/pjit.py:1185\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1179\u001b[0m   distributed_debug_log((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning pjit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md function\u001b[39m\u001b[38;5;124m\"\u001b[39m, name),\n\u001b[1;32m   1180\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_shardings\u001b[39m\u001b[38;5;124m\"\u001b[39m, in_shardings),\n\u001b[1;32m   1181\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_shardings\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_shardings),\n\u001b[1;32m   1182\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract args\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmap\u001b[39m(xla\u001b[38;5;241m.\u001b[39mabstractify, args)),\n\u001b[1;32m   1183\u001b[0m                         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfingerprint\u001b[39m\u001b[38;5;124m\"\u001b[39m, fingerprint))\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1185\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsafe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, compiled\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1187\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_nans\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdebug_infs\u001b[38;5;241m.\u001b[39mvalue  \u001b[38;5;66;03m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Documents/Projects/plnn/env/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py:1151\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_effects \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_unordered_effects\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_host_callbacks):\n\u001b[1;32m   1150\u001b[0m   input_bufs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_tokens_to_inputs(input_bufs)\n\u001b[0;32m-> 1151\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   1153\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m   result_token_bufs \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_prefix_into_single_device_arrays(\n\u001b[1;32m   1155\u001b[0m       \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_effects))\n\u001b[1;32m   1156\u001b[0m   sharded_runtime_token \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mconsume_token()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NITERS = 10  # Number of iterations per datapoint\n",
    "\n",
    "loader = test_loader\n",
    "\n",
    "times = np.nan * np.ones(len(loader))\n",
    "conditions = np.nan * np.empty([len(loader), 2, 4])\n",
    "results = np.nan * np.empty([len(loader), NITERS])\n",
    "\n",
    "for i, data in enumerate(tqdm.tqdm(loader)):\n",
    "    inputs, y1 = data\n",
    "    times[i] = inputs[0][0]\n",
    "    conditions[i,:] = inputs[-1][0]\n",
    "    for k in range(NITERS):\n",
    "    \n",
    "        key, subkey = jrandom.split(key, 2)\n",
    "        loss = validation_step(\n",
    "            faster_model, inputs, y1, loss_fn, subkey\n",
    "        )\n",
    "        results[i, k] = loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "plt.plot(results.mean(axis=1))\n",
    "\n",
    "# sns.lineplot(data=results, x=\"timepoint\", y=\"signal\", hue=\"event\", errorbar=('sd', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(\n",
    "        model,\n",
    "        loader,\n",
    "        niters,\n",
    "        key, \n",
    "):\n",
    "    n = len(loader)\n",
    "    times = np.nan * np.ones(n)\n",
    "    conditions = np.nan * np.empty([n, 2, 4])\n",
    "    losses = np.nan * np.empty([n, niters])\n",
    "\n",
    "    # validation_stepper = eqx.filter_jit(validation_step)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def batch_stepper(model, inputs, y1, loss_fn, keys):\n",
    "        subkeys = jrandom.split(key, niters)\n",
    "        losses = jax.vmap(validation_step, (None, None, None, None, 0))(\n",
    "            model, inputs, y1, loss_fn, subkeys\n",
    "        )\n",
    "        return losses\n",
    "\n",
    "    for i, data in enumerate(tqdm.tqdm(loader)):\n",
    "        inputs, y1 = data\n",
    "        times[i] = inputs[0][0]\n",
    "        conditions[i,:] = inputs[-1][0]\n",
    "        key, subkey = jrandom.split(key, 2)        \n",
    "        losses[i,:] = batch_stepper(model, inputs, y1, loss_fn, subkey)\n",
    "\n",
    "    return losses, times, conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jrandom.split(key, 2)\n",
    "results = run_trial(faster_model, loader, 10, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = results[0]\n",
    "\n",
    "plt.plot(losses.mean(axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLES = 1\n",
    "NITERS_PER_DATUM = 10\n",
    "SCAN_DT0 = [0.1, 0.05, 0.01, 0.005]\n",
    "\n",
    "TRAIN_RESULTS = {}\n",
    "\n",
    "def get_loader(\n",
    "        valid_or_test, *, \n",
    "        length_multiplier=1,\n",
    "        ncells_sample=ncells_sample,\n",
    "        seed=None\n",
    "):\n",
    "    _, valid_loader, test_loader, _, valid_dset, test_dset = get_dataloaders(\n",
    "        datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "        return_datasets=True,\n",
    "        include_test_data=True,\n",
    "        shuffle_train=False,\n",
    "        shuffle_valid=False,\n",
    "        shuffle_test=False,\n",
    "        datdir_test=datdir_test, \n",
    "        nsims_test=nsims_test, \n",
    "        batch_size_train=1,\n",
    "        batch_size_valid=1,\n",
    "        batch_size_test=1,  # Needs to be 1 otherwise loss is averaged\n",
    "        ncells_sample=ncells_sample,\n",
    "        length_multiplier=length_multiplier,\n",
    "        seed=seed\n",
    "    )\n",
    "    return {'valid': valid_loader, 'test': test_loader}[valid_or_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt0 in SCAN_DT0:\n",
    "    TRAIN_RESULTS[dt0] = []\n",
    "    model = eqx.tree_at(lambda m: m.dt0, model, dt0)\n",
    "    \n",
    "    loader = get_loader('valid', rng.integers(2**32))\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    res = run_trial(\n",
    "        model, loader, NITERS_PER_DATUM, subkey\n",
    "    )\n",
    "    TRAIN_RESULTS[dt0].append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"{OUTDIR}/saved_train_results.okl\", 'wb') as f:\n",
    "    pickle.dump(TRAIN_RESULTS, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial2(\n",
    "        model, \n",
    "        ncells_sample,\n",
    "        train_valid_test,\n",
    "        n_resamp,\n",
    "        n_reps,\n",
    "        batch_size,\n",
    "        key,\n",
    "        rng=None,\n",
    "):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    loader = get_loader(\n",
    "        train_valid_test, \n",
    "        length_multiplier=n_resamp, \n",
    "        ncells_sample=ncells_sample,\n",
    "        seed=rng.integers(2**32)\n",
    "    )\n",
    "    n = len(loader)\n",
    "    \n",
    "    times = np.nan * np.ones(n)\n",
    "    conditions = np.nan * np.ones([n, 2, 4])\n",
    "    losses = np.nan * np.ones([n, n_reps])\n",
    "\n",
    "    inputs_array = []\n",
    "    y1_array = []\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        inputs, y1 = data\n",
    "        times[i] = inputs[0][0]\n",
    "        conditions[i,:] = inputs[-1][0]\n",
    "        inputs_array.append(inputs)\n",
    "        y1_array.append(y1)\n",
    "    \n",
    "    inputs_array = jax.tree_map(lambda *x: jnp.stack(x), *inputs_array)\n",
    "    y1_array = jnp.array(y1_array)\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def validation_step_ntimes(n_reps, model, inputs, y1, loss_fn, key):\n",
    "        subkeys = jrandom.split(key, n_reps)\n",
    "        losses = jax.vmap(validation_step, (None, None, None, None, 0))(\n",
    "            model, inputs, y1, loss_fn, subkeys\n",
    "        )\n",
    "        return losses\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def step_ntimes_vectorized(\n",
    "            n_reps, model, inputs_arr, y1_arr, loss_fn, key,\n",
    "    ):\n",
    "        subkeys = jrandom.split(key, len(y1_arr))\n",
    "        res = jax.vmap(validation_step_ntimes, (None, None, 0, 0, None, 0))(\n",
    "            n_reps, model, inputs_arr, y1_arr, loss_fn, subkeys\n",
    "        )\n",
    "        return res\n",
    "\n",
    "    \n",
    "    nbatches = n // batch_size + (n % batch_size != 0)\n",
    "    \n",
    "    count = 0\n",
    "    for batch_idx in tqdm.tqdm(range(nbatches)):\n",
    "        time0 = time.time()\n",
    "        key, subkey = jrandom.split(key, 2)\n",
    "        idx0 = count\n",
    "        idx1 = min(count + batch_size, n)\n",
    "        \n",
    "        partial_inputs_array = [arr[idx0:idx1] for arr in inputs_array]\n",
    "        partial_y1_array = y1_array[idx0:idx1]\n",
    "\n",
    "        results = step_ntimes_vectorized(\n",
    "            n_reps, model, partial_inputs_array, partial_y1_array, loss_fn, key\n",
    "        )\n",
    "        losses[idx0:idx1] = results\n",
    "        count += len(results)\n",
    "        print(f\"  time: {time.time() - time0} \")\n",
    "\n",
    "    return losses, times, conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_loader('test', length_multiplier=1, seed=rng.integers(2**32))\n",
    "print(\"dataloader length:\", len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRESAMP = 20\n",
    "NREPS = 10\n",
    "\n",
    "key, subkey = jrandom.split(key, 2)\n",
    "results = run_trial2(\n",
    "    faster_model, ncells_sample, \"test\",\n",
    "    n_resamp=NRESAMP,\n",
    "    n_reps=NREPS,\n",
    "    batch_size=40,\n",
    "    key=subkey,\n",
    "    rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTIMES = 6\n",
    "NRESAMP = 20\n",
    "NREPS = 10\n",
    "NCONDS = int(len(results) // NTIMES // NRESAMP)\n",
    "\n",
    "losses = results[:]\n",
    "losses = losses.reshape([NRESAMP, NCONDS, NTIMES, NREPS])\n",
    "losses = losses.transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "print(\"(NCONDS, NTIMES, NRESAMP, NREPS):\", losses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(2, 1)\n",
    "\n",
    "for sampidx in range(NRESAMP):\n",
    "    vals1 = losses[0, :, sampidx, :].mean(1)\n",
    "    vals2 = losses[1, :, sampidx, :].mean(1)\n",
    "    ax1.plot(vals1)\n",
    "    ax2.plot(vals2)\n",
    "    ax1.set_title(\"Condition 1\")\n",
    "    ax2.set_title(\"Condition 2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "timepoints = np.arange(2, 5, 0.5) + 0.25\n",
    "\n",
    "for condidx in range(NCONDS):\n",
    "    avg_losses_over_reps = losses[condidx].mean(-1)\n",
    "    mean_loss_over_samps = avg_losses_over_reps.mean(-1)\n",
    "    std_loss_over_samps = avg_losses_over_reps.std(-1)\n",
    "    # ax.plot(std_loss_over_samps, label=f'Cond {condidx+1}')\n",
    "    print(std_loss_over_samps)\n",
    "    \n",
    "    ax.errorbar(\n",
    "        timepoints, \n",
    "        mean_loss_over_samps, \n",
    "        yerr=2*std_loss_over_samps,\n",
    "        capsize=3, linestyle=\"--\", label=f\"Cond {condidx + 1}\"\n",
    "    )\n",
    "\n",
    "ax.set_xlim(2, 5)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"timepoint\")\n",
    "plt.show()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
