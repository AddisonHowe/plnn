{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for testing DeepPhi models trained on FACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import Namespace\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "\n",
    "import equinox as eqx\n",
    "\n",
    "from plnn.models import DeepPhiPLNN\n",
    "from plnn.dataset import get_dataloaders\n",
    "from plnn.data_generation.plnn_animator import PLNNSimulationAnimator\n",
    "from plnn.io import load_model_from_directory, load_model_training_metadata\n",
    "from plnn.loss_functions import select_loss_function\n",
    "from plnn.optimizers import get_dt_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = None\n",
    "SAVE_ANIMATION = False\n",
    "\n",
    "BASEOUTDIR = f\"./out/test_models_facs\"   # Output directory\n",
    "BASEDIR = \"../data/trained_models/facs\"  # Directory containing models\n",
    "\n",
    "# Model directory\n",
    "MODEL_DIR = \"model_facs_v3_dec1b_2dpca_v12_20240716_142138\"\n",
    "\n",
    "MODEL_NAME = MODEL_DIR[0:-16]  # strip time to get model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing training data\n",
    "if 'facs_v2' in MODEL_DIR:\n",
    "    DATDIRBASE = \"../data/training_data/facs_v2\"\n",
    "elif 'facs_v3' in MODEL_DIR:\n",
    "    DATDIRBASE = \"../data/training_data/facs_v3\"\n",
    "else:\n",
    "    DATDIRBASE = \"../data/training_data/facs\"\n",
    "\n",
    "\n",
    "if \"dec1a_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec1/transition1_subset_epi_tr_ce_an_pc12\"\n",
    "elif \"dec1b_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12\"\n",
    "elif \"dec2a_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec2/transition2_subset_ce_pn_m_pc12\"\n",
    "elif \"dec2b_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12\"\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot determine DATDIR from MODEL_DIR!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running as a script, overwrite parameters with command line args\n",
    "\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "SCRIPT = not is_notebook()\n",
    "\n",
    "if SCRIPT:\n",
    "    import tqdm as tqdm\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--basedir\", type=str, \n",
    "                        default=\"data/trained_models/facs\")\n",
    "    parser.add_argument(\"--modeldir\", type=str, required=True)\n",
    "    parser.add_argument(\"--modelname\", type=str, required=True)\n",
    "    parser.add_argument(\"--datdirbase\", type=str, \n",
    "                        default=\"data/training_data/facs\")\n",
    "    parser.add_argument(\"--datdir\", type=str, required=True)\n",
    "    parser.add_argument(\"--baseoutdir\", type=str, \n",
    "                        default=\"notebooks/out/test_models_facs\")\n",
    "    parser.add_argument(\"--save_animation\", action='store_true')\n",
    "    parser.add_argument(\"--seed\", type=int, default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    BASEDIR = args.basedir\n",
    "    MODEL_DIR = args.modeldir\n",
    "    MODEL_NAME = args.modelname\n",
    "    DATDIRBASE = args.datdirbase\n",
    "    DATDIR = f\"{DATDIRBASE}/{args.datdir}\"\n",
    "    BASEOUTDIR = args.baseoutdir\n",
    "    SAVE_ANIMATION = args.save_animation\n",
    "    SEED = args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=SEED)\n",
    "\n",
    "modeldir = f\"{BASEDIR}/{MODEL_DIR}\"\n",
    "\n",
    "OUTDIR = f\"{BASEOUTDIR}/{MODEL_DIR}\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "datdir_train = f\"{DATDIR}/training\"\n",
    "datdir_valid = f\"{DATDIR}/validation\"\n",
    "datdir_test = f\"{DATDIR}/testing\"\n",
    "\n",
    "nsims_train = np.genfromtxt(f\"{datdir_train}/nsims.txt\", dtype=int)\n",
    "nsims_valid = np.genfromtxt(f\"{datdir_valid}/nsims.txt\", dtype=int)\n",
    "\n",
    "try:\n",
    "    nsims_test = np.genfromtxt(f\"{datdir_test}/nsims.txt\", dtype=int)\n",
    "except FileNotFoundError as e:\n",
    "    msg = f\"{e} Reverting to validation data instead.\"\n",
    "    warnings.warn(msg)\n",
    "    datdir_test = f\"{DATDIR}/validation\"\n",
    "    nsims_test = np.genfromtxt(f\"{datdir_test}/nsims.txt\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model, hyperparams, idx, model_name, model_fpath = load_model_from_directory(\n",
    "    modeldir, \n",
    "    subdir=\"states\",\n",
    "    idx='best',\n",
    "    model_class=DeepPhiPLNN,\n",
    "    dtype=jnp.float64,\n",
    ")\n",
    "\n",
    "# Load the argument dictionary and training run dictionary\n",
    "logged_args, run_dict = load_model_training_metadata(\n",
    "    modeldir,\n",
    "    load_all=True\n",
    ")\n",
    "\n",
    "loss_id = logged_args['loss']\n",
    "loss_fn = select_loss_function(\n",
    "    loss_id, \n",
    "    kernel=logged_args.get('kernel'),\n",
    "    bw_range=logged_args.get('bw_range'),\n",
    ")\n",
    "\n",
    "loss_train = run_dict['loss_hist_train']\n",
    "loss_valid = run_dict['loss_hist_valid']\n",
    "sigma_hist = run_dict['sigma_hist']\n",
    "lr_hist = run_dict['learning_rate_hist']\n",
    "dt_hist = run_dict['dt_hist']\n",
    "\n",
    "try:\n",
    "    if dt_hist is None or len(dt_hist) < len(sigma_hist):\n",
    "        print(\"Calculuating `dt_hist` to match length of `sigma_hist`\")\n",
    "        dt_schedule = get_dt_schedule(logged_args['dt_schedule'], logged_args)\n",
    "        dt_hist = np.array([dt_schedule(i) for i in range(len(sigma_hist))])\n",
    "except (RuntimeError, TypeError) as e:\n",
    "    print(\"Could not calculate `dt_hist` to match length of `sigma_hist`\")\n",
    "    print(e)\n",
    "\n",
    "print(f\"Loading model `{model_name}` at epoch {idx} from file: {model_fpath}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncells_sample = logged_args['ncells_sample']\n",
    "length_multiplier = logged_args['passes_per_epoch']\n",
    "\n",
    "_, _, test_loader, _, _, test_dset = get_dataloaders(\n",
    "    datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "    shuffle_train=False,\n",
    "    return_datasets=True,\n",
    "    include_test_data=True,\n",
    "    datdir_test=datdir_test, nsims_test=nsims_test, shuffle_test=True,\n",
    "    batch_size_test=20,  # TODO: Batch Testing\n",
    "    ncells_sample=ncells_sample,\n",
    "    length_multiplier=length_multiplier,\n",
    "    seed=rng.integers(2**32)\n",
    ")\n",
    "\n",
    "print(\"Loaded datasets using parameters:\")\n",
    "print(\"\\tncells_sample:\", ncells_sample)\n",
    "print(\"\\tlength_multiplier:\", length_multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform model evaluation on the testing data\n",
    "Perform one pass through the testing dataset, computing the loss as done in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrandom.PRNGKey(seed=rng.integers(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def compute_loss(model, x, y, loss_fn, key):\n",
    "    t0, y0, t1, sigparams = x\n",
    "    y_pred = model(t0, t1, y0, sigparams, key)\n",
    "    return loss_fn(y_pred, y), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plnn.model_training import validation_step\n",
    "import time\n",
    "\n",
    "time0 = time.time()\n",
    "n = len(test_loader)\n",
    "running_vloss = 0.0\n",
    "for i, data in enumerate(tqdm.tqdm(test_loader, disable=SCRIPT)):\n",
    "    inputs, y1 = data\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    loss = eqx.filter_jit(validation_step)(model, inputs, y1, loss_fn, subkey)\n",
    "    running_vloss += loss.item()\n",
    "\n",
    "avg_loss = running_vloss / n\n",
    "jax.block_until_ready(avg_loss)\n",
    "\n",
    "print(\"Average loss:\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the resulting average loss value in the output directory.\n",
    "np.save(f\"{OUTDIR}/avg_testing_loss.npy\", avg_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
