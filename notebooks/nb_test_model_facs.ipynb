{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for testing DeepPhi models trained on FACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "\n",
    "import equinox as eqx\n",
    "\n",
    "from plnn.models import DeepPhiPLNN\n",
    "from plnn.dataset import get_dataloaders\n",
    "from plnn.data_generation.plnn_animator import PLNNSimulationAnimator\n",
    "from plnn.io import load_model_from_directory, load_model_training_metadata\n",
    "from plnn.loss_functions import select_loss_function\n",
    "from plnn.optimizers import get_dt_schedule\n",
    "from plnn.model_training import validation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = None\n",
    "SAVE_ANIMATION = False\n",
    "\n",
    "BASEOUTDIR = f\"./out/test_models_facs\"   # Output directory\n",
    "BASEDIR = \"../data/trained_models/facs\"  # Directory containing models\n",
    "\n",
    "# Model directory\n",
    "MODEL_DIR = \"model_facs_v3_dec1b_2dpca_v12b_20240719_005108\"\n",
    "\n",
    "MODEL_NAME = MODEL_DIR[0:-16]  # strip time to get model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing training data\n",
    "if 'facs_v2' in MODEL_DIR:\n",
    "    DATDIRBASE = \"../data/training_data/facs_v2\"\n",
    "elif 'facs_v3' in MODEL_DIR:\n",
    "    DATDIRBASE = \"../data/training_data/facs_v3\"\n",
    "else:\n",
    "    DATDIRBASE = \"../data/training_data/facs\"\n",
    "\n",
    "\n",
    "if \"dec1a_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec1/transition1_subset_epi_tr_ce_an_pc12\"\n",
    "elif \"dec1b_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12\"\n",
    "elif \"dec2a_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec2/transition2_subset_ce_pn_m_pc12\"\n",
    "elif \"dec2b_2dpca\" in MODEL_DIR:\n",
    "    DATDIR = f\"{DATDIRBASE}/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12\"\n",
    "else:\n",
    "    raise RuntimeError(\"Cannot determine DATDIR from MODEL_DIR!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running as a script, overwrite parameters with command line args\n",
    "\n",
    "def is_notebook() -> bool:\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__ # type: ignore\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "SCRIPT = not is_notebook()\n",
    "\n",
    "if SCRIPT:\n",
    "    import tqdm as tqdm\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--basedir\", type=str, \n",
    "                        default=\"data/trained_models/facs\")\n",
    "    parser.add_argument(\"--modeldir\", type=str, required=True)\n",
    "    parser.add_argument(\"--modelname\", type=str, required=True)\n",
    "    parser.add_argument(\"--datdirbase\", type=str, \n",
    "                        default=\"data/training_data/facs\")\n",
    "    parser.add_argument(\"--datdir\", type=str, required=True)\n",
    "    parser.add_argument(\"--baseoutdir\", type=str, \n",
    "                        default=\"notebooks/out/test_models_facs\")\n",
    "    parser.add_argument(\"--save_animation\", action='store_true')\n",
    "    parser.add_argument(\"--seed\", type=int, default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    BASEDIR = args.basedir\n",
    "    MODEL_DIR = args.modeldir\n",
    "    MODEL_NAME = args.modelname\n",
    "    DATDIRBASE = args.datdirbase\n",
    "    DATDIR = f\"{DATDIRBASE}/{args.datdir}\"\n",
    "    BASEOUTDIR = args.baseoutdir\n",
    "    SAVE_ANIMATION = args.save_animation\n",
    "    SEED = args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=SEED)\n",
    "\n",
    "modeldir = f\"{BASEDIR}/{MODEL_DIR}\"\n",
    "\n",
    "OUTDIR = f\"{BASEOUTDIR}/{MODEL_DIR}\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "datdir_train = f\"{DATDIR}/training\"\n",
    "datdir_valid = f\"{DATDIR}/validation\"\n",
    "datdir_test = f\"{DATDIR}/testing\"\n",
    "\n",
    "nsims_train = np.genfromtxt(f\"{datdir_train}/nsims.txt\", dtype=int)\n",
    "nsims_valid = np.genfromtxt(f\"{datdir_valid}/nsims.txt\", dtype=int)\n",
    "\n",
    "try:\n",
    "    nsims_test = np.genfromtxt(f\"{datdir_test}/nsims.txt\", dtype=int)\n",
    "except FileNotFoundError as e:\n",
    "    msg = f\"{e} Reverting to validation data instead.\"\n",
    "    warnings.warn(msg)\n",
    "    datdir_test = f\"{DATDIR}/validation\"\n",
    "    nsims_test = np.genfromtxt(f\"{datdir_test}/nsims.txt\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model, hyperparams, idx, model_name, model_fpath = load_model_from_directory(\n",
    "    modeldir, \n",
    "    subdir=\"states\",\n",
    "    idx='best',\n",
    "    model_class=DeepPhiPLNN,\n",
    "    dtype=jnp.float64,\n",
    ")\n",
    "\n",
    "# Load the argument dictionary and training run dictionary\n",
    "logged_args, run_dict = load_model_training_metadata(\n",
    "    modeldir,\n",
    "    load_all=True\n",
    ")\n",
    "\n",
    "loss_id = logged_args['loss']\n",
    "loss_fn = select_loss_function(\n",
    "    loss_id, \n",
    "    kernel=logged_args.get('kernel'),\n",
    "    bw_range=logged_args.get('bw_range'),\n",
    ")\n",
    "\n",
    "loss_train = run_dict['loss_hist_train']\n",
    "loss_valid = run_dict['loss_hist_valid']\n",
    "sigma_hist = run_dict['sigma_hist']\n",
    "lr_hist = run_dict['learning_rate_hist']\n",
    "dt_hist = run_dict['dt_hist']\n",
    "\n",
    "try:\n",
    "    if dt_hist is None or len(dt_hist) < len(sigma_hist):\n",
    "        print(\"Calculuating `dt_hist` to match length of `sigma_hist`\")\n",
    "        dt_schedule = get_dt_schedule(logged_args['dt_schedule'], logged_args)\n",
    "        dt_hist = np.array([dt_schedule(i) for i in range(len(sigma_hist))])\n",
    "except (RuntimeError, TypeError) as e:\n",
    "    print(\"Could not calculate `dt_hist` to match length of `sigma_hist`\")\n",
    "    print(e)\n",
    "\n",
    "print(f\"Loading model `{model_name}` at epoch {idx} from file: {model_fpath}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncells_sample = logged_args['ncells_sample']\n",
    "length_multiplier = logged_args['passes_per_epoch']\n",
    "batch_size = 20\n",
    "\n",
    "_, _, test_loader, _, _, test_dset = get_dataloaders(\n",
    "    datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "    shuffle_train=False,\n",
    "    return_datasets=True,\n",
    "    include_test_data=True,\n",
    "    datdir_test=datdir_test, nsims_test=nsims_test, shuffle_test=True,\n",
    "    batch_size_test=batch_size,  # TODO: Batch Testing\n",
    "    ncells_sample=ncells_sample,\n",
    "    length_multiplier=length_multiplier,\n",
    "    seed=rng.integers(2**32)\n",
    ")\n",
    "\n",
    "print(\"Loaded datasets using parameters:\")\n",
    "print(\"\\tncells_sample:\", ncells_sample)\n",
    "print(\"\\tdataset base length:\", test_dset.get_baselength())\n",
    "print(\"\\tlength_multiplier:\", length_multiplier)\n",
    "print(\"\\tdataset length:\", len(test_dset))\n",
    "print(\"\\tbatch size:\", batch_size)\n",
    "print(\"\\tdataloader length:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform model evaluation on the testing data\n",
    "Perform one pass through the testing dataset, computing the loss as done in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrandom.PRNGKey(seed=rng.integers(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def compute_loss(model, x, y, loss_fn, key):\n",
    "    t0, y0, t1, sigparams = x\n",
    "    y_pred = model(t0, t1, y0, sigparams, key)\n",
    "    return loss_fn(y_pred, y), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "n = len(test_loader)\n",
    "running_vloss = 0.0\n",
    "for i, data in enumerate(tqdm.tqdm(test_loader, disable=SCRIPT)):\n",
    "    inputs, y1 = data\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    loss = eqx.filter_jit(validation_step)(model, inputs, y1, loss_fn, subkey)\n",
    "    running_vloss += loss.item()\n",
    "\n",
    "avg_loss = running_vloss / n\n",
    "jax.block_until_ready(avg_loss)\n",
    "\n",
    "print(\"Average loss:\", avg_loss)\n",
    "\n",
    "# Save the resulting average loss value in the output directory.\n",
    "np.save(f\"{OUTDIR}/avg_testing_loss.npy\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_model = eqx.tree_at(lambda m: m.dt0, model, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = time.time()\n",
    "n = len(test_loader)\n",
    "running_vloss = 0.0\n",
    "for i, data in enumerate(tqdm.tqdm(test_loader, disable=SCRIPT)):\n",
    "    inputs, y1 = data\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    loss = eqx.filter_jit(validation_step)(faster_model, inputs, y1, loss_fn, subkey)\n",
    "    running_vloss += loss.item()\n",
    "\n",
    "avg_loss = running_vloss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = running_vloss / n\n",
    "print(\"Average loss:\", avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Testing\n",
    "\n",
    "Construct a testing dataloader that does not shuffle the data.\n",
    "For each datapoint, run the forward model multiple times (for multiple values of `dt`).\n",
    "Determine the distribution of the loss for each datapoint.\n",
    "See if there is a correlation between the loss and time, or between the loss and experimental condition.\n",
    "Run the same sort of trial for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, valid_loader, test_loader, _, valid_dset, test_dset = get_dataloaders(\n",
    "    datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "    return_datasets=True,\n",
    "    include_test_data=True,\n",
    "    shuffle_train=False,\n",
    "    shuffle_valid=False,\n",
    "    shuffle_test=False,\n",
    "    datdir_test=datdir_test, \n",
    "    nsims_test=nsims_test, \n",
    "    batch_size_test=1,  # Needs to be 1 otherwise loss is averaged\n",
    "    ncells_sample=ncells_sample,\n",
    "    length_multiplier=1,\n",
    "    seed=rng.integers(2**32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NITERS = 10  # Number of iterations per datapoint\n",
    "\n",
    "loader = test_loader\n",
    "\n",
    "times = np.nan * np.ones(len(loader))\n",
    "conditions = np.nan * np.empty([len(loader), 2, 4])\n",
    "results = np.nan * np.empty([len(loader), NITERS])\n",
    "\n",
    "for i, data in enumerate(tqdm.tqdm(loader)):\n",
    "    inputs, y1 = data\n",
    "    times[i] = inputs[0][0]\n",
    "    conditions[i,:] = inputs[-1][0]\n",
    "    for k in range(NITERS):\n",
    "    \n",
    "        key, subkey = jrandom.split(key, 2)\n",
    "        loss = validation_step(\n",
    "            faster_model, inputs, y1, loss_fn, subkey\n",
    "        )\n",
    "        results[i, k] = loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "plt.plot(results.mean(axis=1))\n",
    "\n",
    "# sns.lineplot(data=results, x=\"timepoint\", y=\"signal\", hue=\"event\", errorbar=('sd', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(\n",
    "        model,\n",
    "        loader,\n",
    "        niters,\n",
    "        key, \n",
    "):\n",
    "    n = len(loader)\n",
    "    times = np.nan * np.ones(n)\n",
    "    conditions = np.nan * np.empty([n, 2, 4])\n",
    "    losses = np.nan * np.empty([n, niters])\n",
    "\n",
    "    # validation_stepper = eqx.filter_jit(validation_step)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def batch_stepper(model, inputs, y1, loss_fn, keys):\n",
    "        subkeys = jrandom.split(key, niters)\n",
    "        losses = jax.vmap(validation_step, (None, None, None, None, 0))(\n",
    "            model, inputs, y1, loss_fn, subkeys\n",
    "        )\n",
    "        return losses\n",
    "\n",
    "    for i, data in enumerate(tqdm.tqdm(loader)):\n",
    "        inputs, y1 = data\n",
    "        times[i] = inputs[0][0]\n",
    "        conditions[i,:] = inputs[-1][0]\n",
    "        key, subkey = jrandom.split(key, 2)        \n",
    "        losses[i,:] = batch_stepper(model, inputs, y1, loss_fn, subkey)\n",
    "\n",
    "    return losses, times, conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jrandom.split(key, 2)\n",
    "results = run_trial(faster_model, loader, 10, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = results[0]\n",
    "\n",
    "plt.plot(losses.mean(axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLES = 1\n",
    "NITERS_PER_DATUM = 10\n",
    "SCAN_DT0 = [0.1, 0.05, 0.01, 0.005]\n",
    "\n",
    "TRAIN_RESULTS = {}\n",
    "\n",
    "def get_loader(\n",
    "        valid_or_test, *, \n",
    "        length_multiplier=1,\n",
    "        ncells_sample=ncells_sample,\n",
    "        seed=None\n",
    "):\n",
    "    _, valid_loader, test_loader, _, valid_dset, test_dset = get_dataloaders(\n",
    "        datdir_train, datdir_valid, nsims_train, nsims_valid,\n",
    "        return_datasets=True,\n",
    "        include_test_data=True,\n",
    "        shuffle_train=False,\n",
    "        shuffle_valid=False,\n",
    "        shuffle_test=False,\n",
    "        datdir_test=datdir_test, \n",
    "        nsims_test=nsims_test, \n",
    "        batch_size_train=1,\n",
    "        batch_size_valid=1,\n",
    "        batch_size_test=1,  # Needs to be 1 otherwise loss is averaged\n",
    "        ncells_sample=ncells_sample,\n",
    "        length_multiplier=length_multiplier,\n",
    "        seed=seed\n",
    "    )\n",
    "    return {'valid': valid_loader, 'test': test_loader}[valid_or_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt0 in SCAN_DT0:\n",
    "    TRAIN_RESULTS[dt0] = []\n",
    "    model = eqx.tree_at(lambda m: m.dt0, model, dt0)\n",
    "    \n",
    "    loader = get_loader('valid', rng.integers(2**32))\n",
    "    key, subkey = jrandom.split(key, 2)\n",
    "    res = run_trial(\n",
    "        model, loader, NITERS_PER_DATUM, subkey\n",
    "    )\n",
    "    TRAIN_RESULTS[dt0].append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"{OUTDIR}/saved_train_results.okl\", 'wb') as f:\n",
    "    pickle.dump(TRAIN_RESULTS, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial2(\n",
    "        model, \n",
    "        ncells_sample,\n",
    "        train_valid_test,\n",
    "        n_resamp,\n",
    "        n_reps,\n",
    "        batch_size,\n",
    "        key,\n",
    "        rng=None,\n",
    "):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    loader = get_loader(\n",
    "        train_valid_test, \n",
    "        length_multiplier=n_resamp, \n",
    "        ncells_sample=ncells_sample,\n",
    "        seed=rng.integers(2**32)\n",
    "    )\n",
    "    n = len(loader)\n",
    "    \n",
    "    times = np.nan * np.ones(n)\n",
    "    conditions = np.nan * np.ones([n, 2, 4])\n",
    "    losses = np.nan * np.ones([n, n_reps])\n",
    "\n",
    "    inputs_array = []\n",
    "    y1_array = []\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        inputs, y1 = data\n",
    "        times[i] = inputs[0][0]\n",
    "        conditions[i,:] = inputs[-1][0]\n",
    "        inputs_array.append(inputs)\n",
    "        y1_array.append(y1)\n",
    "    \n",
    "    inputs_array = jax.tree_map(lambda *x: jnp.stack(x), *inputs_array)\n",
    "    y1_array = jnp.array(y1_array)\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def validation_step_ntimes(n_reps, model, inputs, y1, loss_fn, key):\n",
    "        subkeys = jrandom.split(key, n_reps)\n",
    "        losses = jax.vmap(validation_step, (None, None, None, None, 0))(\n",
    "            model, inputs, y1, loss_fn, subkeys\n",
    "        )\n",
    "        return losses\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def step_ntimes_vectorized(\n",
    "            n_reps, model, inputs_arr, y1_arr, loss_fn, key,\n",
    "    ):\n",
    "        subkeys = jrandom.split(key, len(y1_arr))\n",
    "        res = jax.vmap(validation_step_ntimes, (None, None, 0, 0, None, 0))(\n",
    "            n_reps, model, inputs_arr, y1_arr, loss_fn, subkeys\n",
    "        )\n",
    "        return res\n",
    "\n",
    "    \n",
    "    nbatches = n // batch_size + (n % batch_size != 0)\n",
    "    \n",
    "    count = 0\n",
    "    for batch_idx in tqdm.tqdm(range(nbatches)):\n",
    "        time0 = time.time()\n",
    "        key, subkey = jrandom.split(key, 2)\n",
    "        idx0 = count\n",
    "        idx1 = min(count + batch_size, n)\n",
    "        \n",
    "        partial_inputs_array = [arr[idx0:idx1] for arr in inputs_array]\n",
    "        partial_y1_array = y1_array[idx0:idx1]\n",
    "\n",
    "        results = step_ntimes_vectorized(\n",
    "            n_reps, model, partial_inputs_array, partial_y1_array, loss_fn, key\n",
    "        )\n",
    "        losses[idx0:idx1] = results\n",
    "        count += len(results)\n",
    "        print(f\"  time: {time.time() - time0} \")\n",
    "\n",
    "    return losses, times, conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_loader('test', length_multiplier=1, seed=rng.integers(2**32))\n",
    "print(\"dataloader length:\", len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRESAMP = 20\n",
    "NREPS = 10\n",
    "\n",
    "key, subkey = jrandom.split(key, 2)\n",
    "results = run_trial2(\n",
    "    faster_model, ncells_sample, \"test\",\n",
    "    n_resamp=NRESAMP,\n",
    "    n_reps=NREPS,\n",
    "    batch_size=40,\n",
    "    key=subkey,\n",
    "    rng=rng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTIMES = 6\n",
    "NRESAMP = 20\n",
    "NREPS = 10\n",
    "NCONDS = int(len(results) // NTIMES // NRESAMP)\n",
    "\n",
    "losses = results[:]\n",
    "losses = losses.reshape([NRESAMP, NCONDS, NTIMES, NREPS])\n",
    "losses = losses.transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "print(\"(NCONDS, NTIMES, NRESAMP, NREPS):\", losses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(2, 1)\n",
    "\n",
    "for sampidx in range(NRESAMP):\n",
    "    vals1 = losses[0, :, sampidx, :].mean(1)\n",
    "    vals2 = losses[1, :, sampidx, :].mean(1)\n",
    "    ax1.plot(vals1)\n",
    "    ax2.plot(vals2)\n",
    "    ax1.set_title(\"Condition 1\")\n",
    "    ax2.set_title(\"Condition 2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "timepoints = np.arange(2, 5, 0.5) + 0.25\n",
    "\n",
    "for condidx in range(NCONDS):\n",
    "    avg_losses_over_reps = losses[condidx].mean(-1)\n",
    "    mean_loss_over_samps = avg_losses_over_reps.mean(-1)\n",
    "    std_loss_over_samps = avg_losses_over_reps.std(-1)\n",
    "    # ax.plot(std_loss_over_samps, label=f'Cond {condidx+1}')\n",
    "    print(std_loss_over_samps)\n",
    "    \n",
    "    ax.errorbar(\n",
    "        timepoints, \n",
    "        mean_loss_over_samps, \n",
    "        yerr=2*std_loss_over_samps,\n",
    "        capsize=3, linestyle=\"--\", label=f\"Cond {condidx + 1}\"\n",
    "    )\n",
    "\n",
    "ax.set_xlim(2, 5)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"timepoint\")\n",
    "plt.show()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
